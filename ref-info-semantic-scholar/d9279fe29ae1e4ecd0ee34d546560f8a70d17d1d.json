{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144398147"
                        ],
                        "name": "L. Sigal",
                        "slug": "L.-Sigal",
                        "structuredName": {
                            "firstName": "Leonid",
                            "lastName": "Sigal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sigal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Discriminative part models have also been used in conjunction with generative body models, as we do here."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1570800,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "46626dce354feb5e21fde1095cd436e2a7d0c03a",
            "isKey": false,
            "numCitedBy": 262,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Part-based tree-structured models have been widely used for 2D articulated human pose-estimation. These approaches admit efficient inference algorithms while capturing the important kinematic constraints of the human body as a graphical model. These methods often fail however when multiple body parts fit the same image region resulting in global pose estimates that poorly explain the overall image evidence. Attempts to solve this problem have focused on the use of strong prior models that are limited to learned activities such as walking. We argue that the problem actually lies with the image observations and not with the prior. In particular, image evidence for each body part is estimated independently of other parts without regard to self-occlusion. To address this we introduce occlusion-sensitive local likelihoods that approximate the global image likelihood using per-pixel hidden binary variables that encode the occlusion relationships between parts. This occlusion reasoning introduces interactions between non-adjacent body parts creating loops in the underlying graphical model. We deal with this using an extension of an approximate belief propagation algorithm (PAMPAS). The algorithm recovers the real-valued 2D pose of the body in the presence of occlusions, does not require strong priors over body pose and does a quantitatively better job of explaining image evidence than previous methods."
            },
            "slug": "Measure-Locally,-Reason-Globally:-Articulated-Pose-Sigal-Black",
            "title": {
                "fragments": [],
                "text": "Measure Locally, Reason Globally: Occlusion-sensitive Articulated Pose Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An extension of an approximate belief propagation algorithm (PAMPAS) that recovers the real-valued 2D pose of the body in the presence of occlusions, does not require strong priors over body pose and does a quantitatively better job of explaining image evidence than previous methods."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2649483"
                        ],
                        "name": "M. Lee",
                        "slug": "M.-Lee",
                        "structuredName": {
                            "firstName": "Mun",
                            "lastName": "Lee",
                            "middleNames": [
                                "Wai"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144422657"
                        ],
                        "name": "I. Cohen",
                        "slug": "I.-Cohen",
                        "structuredName": {
                            "firstName": "Isaac",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Cohen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our paper, however, directly integrates the part detectors and uses them as the appearance model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1888970,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2203112e8323c52950df0503126adc3af18098ad",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the problem of estimating human body pose in static images. This problem is challenging due to the high dimensional state space of body poses, the presence of pose ambiguity, and the need to segment the human body in an image. We use an image generative approach by modeling the human kinematics, the shape and the clothing probabilistically. These models are used for deriving a good likelihood measure to evaluate samples in the solution, space. We adopt a data-driven MCMC framework for searching the solution space efficiently. Our observation data include the face, head-shoulders contour, skin color blobs, and ridges; and they provide evidences on the positions of the head, shoulders and limbs. To translate these inferences into pose hypotheses, we introduce the use of 'proposal maps', which is an efficient way of consolidating the evidence and generating 3D pose candidates during the MCMC search. As experimental results show, the proposed technique estimates the human 3D pose accurately on various test images."
            },
            "slug": "Proposal-maps-driven-MCMC-for-estimating-human-body-Lee-Cohen",
            "title": {
                "fragments": [],
                "text": "Proposal maps driven MCMC for estimating human body pose in static images"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An image generative approach is used by modeling the human kinematics, the shape and the clothing probabilistically, used for deriving a good likelihood measure to evaluate samples in the solution, space and introduces the use of 'proposal maps', which is an efficient way of consolidating the evidence and generating 3D pose candidates during the MCMC search."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144398147"
                        ],
                        "name": "L. Sigal",
                        "slug": "L.-Sigal",
                        "structuredName": {
                            "firstName": "Leonid",
                            "lastName": "Sigal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sigal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2105795"
                        ],
                        "name": "Michael J. Black",
                        "slug": "Michael-J.-Black",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Black",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael J. Black"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our paper, however, directly integrates the part detectors and uses them as the appearance model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15432502,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "006e1bcc23ceb22ca42752879480bbdbebd222ae",
            "isKey": false,
            "numCitedBy": 134,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a hierarchical process for inferring the 3D pose of a person from monocular images. First we infer a learned view-based 2D body model from a single image using non-parametric belief propagation. This approach integrates information from bottom-up body-part proposal processes and deals with self-occlusion to compute distributions over limb poses. Then, we exploit a learned Mixture of Experts model to infer a distribution of 3D poses conditioned on 2D poses. This approach is more general than recent work on inferring 3D pose directly from silhouettes since the 2D body model provides a richer representation that includes the 2D joint angles and the poses of limbs that may be unobserved in the silhouette. We demonstrate the method in a laboratory setting where we evaluate the accuracy of the 3D poses against ground truth data. We also estimate 3D body pose in a monocular image sequence. The resulting 3D estimates are sufficiently accurate to serve as proposals for the Bayesian inference of 3D human motion over time"
            },
            "slug": "Predicting-3D-People-from-2D-Pictures-Sigal-Black",
            "title": {
                "fragments": [],
                "text": "Predicting 3D People from 2D Pictures"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "A hierarchical process for inferring the 3D pose of a person from monocular images using a learned view-based 2D body model from a single image using non-parametric belief propagation and a learned Mixture of Experts model to infer a distribution of 3D poses conditioned on 2D poses."
            },
            "venue": {
                "fragments": [],
                "text": "AMDO"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2898850"
                        ],
                        "name": "R\u00e9mi Ronfard",
                        "slug": "R\u00e9mi-Ronfard",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Ronfard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R\u00e9mi Ronfard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 202
                            }
                        ],
                        "text": "In [18] the approach has been demonstrated to work without background substraction by relying on a discriminative appearance model, but while still using rather simple image features (Gaussian derivatives)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Our paper, however, directly integrates the part detectors and uses them as the appearance model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9478443,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ac7f973658b55563f4d56e5b763c9049dd1034e0",
            "isKey": false,
            "numCitedBy": 292,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "Detecting people in images is a key problem for video indexing, browsing and retrieval. The main difficulties are the large appearance variations caused by action, clothing, illumination, viewpoint and scale. Our goal is to find people in static video frames using learned models of both the appearance of body parts (head, limbs, hands), and of the geometry of their assemblies. We build on Forsyth & Fleck's general 'body plan' methodology and Felzenszwalb & Huttenlocher's dynamic programming approach for efficiently assembling candidate parts into 'pictorial structures'. However we replace the rather simple part detectors used in these works with dedicated detectors learned for each body part using SupportVector Machines (SVMs) or RelevanceVector Machines (RVMs). We are not aware of any previous work using SVMs to learn articulated body plans, however they have been used to detect both whole pedestrians and combinations of rigidly positioned subimages (typically, upper body, arms, and legs) in street scenes, under a wide range of illumination, pose and clothing variations. RVMs are SVM-like classifiers that offer a well-founded probabilistic interpretation and improved sparsity for reduced computation. We demonstrate their benefits experimentally in a series of results showing great promise for learning detectors in more general situations."
            },
            "slug": "Learning-to-Parse-Pictures-of-People-Ronfard-Schmid",
            "title": {
                "fragments": [],
                "text": "Learning to Parse Pictures of People"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work builds on Forsyth & Fleck's general 'body plan' methodology and Felzenszwalb & Huttenlocher's dynamic programming approach for efficiently assembling candidate parts into 'pictorial structures' but replaces the rather simple part detectors used in these works with dedicated detectors learned for each body part using SupportVector Machines (SVMs) or Relevance Vector Machines (RVMs)."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108130121"
                        ],
                        "name": "Jiayong Zhang",
                        "slug": "Jiayong-Zhang",
                        "structuredName": {
                            "firstName": "Jiayong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiayong Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33642939"
                        ],
                        "name": "Jiebo Luo",
                        "slug": "Jiebo-Luo",
                        "structuredName": {
                            "firstName": "Jiebo",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiebo Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143980462"
                        ],
                        "name": "R. Collins",
                        "slug": "R.-Collins",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Collins",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Collins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689241"
                        ],
                        "name": "Yanxi Liu",
                        "slug": "Yanxi-Liu",
                        "structuredName": {
                            "firstName": "Yanxi",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yanxi Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our paper, however, directly integrates the part detectors and uses them as the appearance model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5064803,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "212425def3dc2c3024138e73e95db0a2c21906bb",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a 3-level hierarchical model for localizing human bodies in still images from arbitrary viewpoints. We first fit a simple tree-structured model defined on a small landmark set along the body contours by Dynamic Programming (DP). The output is a series of proposal maps that encode the probabilities of partial body configurations. Next, we fit a mixture of view-dependent models by Sequential Monte Carlo (SMC), which handles self-occlusion, anthropometric constraints, and large viewpoint changes. DP and SMC are designed to search in opposite directions such that the DP proposals are utilized effectively to initialize and guide the SMC inference. This hybrid strategy of combining deterministic and stochastic search ensures both the robustness and efficiency of DP, and the accuracy of SMC. Finally, we fit an expanded mixture model with increased landmark density through local optimization. The model hierarchy is trained on a large number of gait images. Extensive tests on cluttered images with varying poses including walking, dancing and various types of sports activities demonstrate the feasibility of the proposed approach."
            },
            "slug": "Body-Localization-in-Still-Images-Using-Models-and-Zhang-Luo",
            "title": {
                "fragments": [],
                "text": "Body Localization in Still Images Using Hierarchical Models and Hybrid Search"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A 3-level hierarchical model for localizing human bodies in still images from arbitrary viewpoints by Dynamic Programming, Sequential Monte Carlo, and an expanded mixture model with increased landmark density through local optimization is presented."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143891655"
                        ],
                        "name": "Hao Jiang",
                        "slug": "Hao-Jiang",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144891282"
                        ],
                        "name": "David R. Martin",
                        "slug": "David-R.-Martin",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Martin",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David R. Martin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 61
                            }
                        ],
                        "text": "In [5] discriminative training is combined with strong appearance representation based on HOG features, however the model is applied to detection only."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9525456,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ddd2d8490849949e2306b6b23e61925383e76b37",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel global pose estimation method to detect body parts of articulated objects in images based on non-tree graph models. There are two kinds of edges defined in the body part relation graph: Strong (tree) edges corresponding to the body plan that can enforce any type of constraint, and weak (non-tree) edges that express exclusion constraints arising from inter-part occlusion and symmetry conditions. We express optimal part localization as a multiple shortest path problem in a set of correlated trellises constructed from the graph model. Strong model edges generate the trellises, while weak model edges prohibit implausible poses by generating exclusion constraints among trellis nodes and edges. The optimization may be expressed as an integer linear program and solved using a novel two-stage relaxation scheme. Experiments show that the proposed method has a high chance of obtaining the globally optimal pose at low computational cost."
            },
            "slug": "Global-pose-estimation-using-non-tree-models-Jiang-Martin",
            "title": {
                "fragments": [],
                "text": "Global pose estimation using non-tree models"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A novel global pose estimation method to detect body parts of articulated objects in images based on non-tree graph models that expresses optimal part localization as a multiple shortest path problem in a set of correlated trellises constructed from the graph model."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1774881"
                        ],
                        "name": "M. Bergtholdt",
                        "slug": "M.-Bergtholdt",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Bergtholdt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bergtholdt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40569085"
                        ],
                        "name": "J\u00f6rg H. Kappes",
                        "slug": "J\u00f6rg-H.-Kappes",
                        "structuredName": {
                            "firstName": "J\u00f6rg",
                            "lastName": "Kappes",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J\u00f6rg H. Kappes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067705802"
                        ],
                        "name": "S. Schmidt",
                        "slug": "S.-Schmidt",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Schmidt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Schmidt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679944"
                        ],
                        "name": "C. Schn\u00f6rr",
                        "slug": "C.-Schn\u00f6rr",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Schn\u00f6rr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schn\u00f6rr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 76
                            }
                        ],
                        "text": "Our paper, however, directly integrates the part detectors and uses them as the appearance model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18765157,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "88dc6973f51b6b2e86aa53d1e73d68520e326022",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "Object detection is one of the key components in modern computer vision systems. While the detection of a specific rigid object under changing viewpoints was considered hard just a few years ago, current research strives to detect and recognize classes of non-rigid, articulated objects. Hampered by the omnipresent confusing information due to clutter and occlusion, the focus has shifted from holistic approaches for object detection to representations of individual object parts linked by structural information, along with richer contextual descriptions of object configurations. Along this line of research, we present a practicable and expandable probabilistic framework for parts-based object class representation, enabling the detection of rigid and articulated object classes in arbitrary views. We investigate learning of this representation from labelled training images and infer globally optimal solutions to the contextual MAP-detection problem, using A*-search with a novel lower-bound as admissible heuristic. An assessment of the inference performance of Belief-Propagation and Tree-Reweighted Belief Propagation is obtained as a by-product. The generality of our approach is demonstrated on four different datasets utilizing domain dependent information cues."
            },
            "slug": "A-Study-of-Parts-Based-Object-Class-Detection-Using-Bergtholdt-Kappes",
            "title": {
                "fragments": [],
                "text": "A Study of Parts-Based Object Class Detection Using Complete Graphs"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work presents a practicable and expandable probabilistic framework for parts-based object class representation, enabling the detection of rigid and articulated object classes in arbitrary views and investigates learning of this representation from labelled training images and infer globally optimal solutions to the contextual MAP-detection problem."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114833718"
                        ],
                        "name": "Xiaofeng Ren",
                        "slug": "Xiaofeng-Ren",
                        "structuredName": {
                            "firstName": "Xiaofeng",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaofeng Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 135
                            }
                        ],
                        "text": "Other work has focused on discriminative tree models [16, 18], but due to the use of simple features, these methods fall short in terms of performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3025856,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "42a359e88ced86b7497b4a116a1c606a5266632b",
            "isKey": false,
            "numCitedBy": 252,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of this work is to recover human body configurations from static images. Without assuming a priori knowledge of scale, pose or appearance, this problem is extremely challenging and demands the use of all possible sources of information. We develop a framework which can incorporate arbitrary pairwise constraints between body parts, such as scale compatibility, relative position, symmetry of clothing and smooth contour connections between parts. We detect candidate body parts from bottom-up using parallelism, and use various pairwise configuration constraints to assemble them together into body configurations. To find the most probable configuration, we solve an integer quadratic programming problem with a standard technique using linear approximations. Approximate IQP allows us to incorporate much more information than the traditional dynamic programming and remains computationally efficient. 15 hand-labeled images are used to train the low-level part detector and learn the pairwise constraints. We show test results on a variety of images."
            },
            "slug": "Recovering-human-body-configurations-using-pairwise-Ren-Berg",
            "title": {
                "fragments": [],
                "text": "Recovering human body configurations using pairwise constraints between parts"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A framework which can incorporate arbitrary pairwise constraints between body parts, such as scale compatibility, relative position, symmetry of clothing and smooth contour connections between parts is developed."
            },
            "venue": {
                "fragments": [],
                "text": "Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685089"
                        ],
                        "name": "Pedro F. Felzenszwalb",
                        "slug": "Pedro-F.-Felzenszwalb",
                        "structuredName": {
                            "firstName": "Pedro",
                            "lastName": "Felzenszwalb",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pedro F. Felzenszwalb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145689002"
                        ],
                        "name": "David A. McAllester",
                        "slug": "David-A.-McAllester",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "McAllester",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. McAllester"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our paper, however, directly integrates the part detectors and uses them as the appearance model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14327585,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "860a9d55d87663ca88e74b3ca357396cd51733d0",
            "isKey": false,
            "numCitedBy": 2622,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a discriminatively trained, multiscale, deformable part model for object detection. Our system achieves a two-fold improvement in average precision over the best performance in the 2006 PASCAL person detection challenge. It also outperforms the best results in the 2007 challenge in ten out of twenty categories. The system relies heavily on deformable parts. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL challenge. Our system also relies heavily on new methods for discriminative training. We combine a margin-sensitive approach for data mining hard negative examples with a formalism we call latent SVM. A latent SVM, like a hidden CRF, leads to a non-convex training problem. However, a latent SVM is semi-convex and the training problem becomes convex once latent information is specified for the positive examples. We believe that our training methods will eventually make possible the effective use of more latent information such as hierarchical (grammar) models and models involving latent three dimensional pose."
            },
            "slug": "A-discriminatively-trained,-multiscale,-deformable-Felzenszwalb-McAllester",
            "title": {
                "fragments": [],
                "text": "A discriminatively trained, multiscale, deformable part model"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A discriminatively trained, multiscale, deformable part model for object detection, which achieves a two-fold improvement in average precision over the best performance in the 2006 PASCAL person detection challenge and outperforms the best results in the 2007 challenge in ten out of twenty categories."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781120"
                        ],
                        "name": "C. Sminchisescu",
                        "slug": "C.-Sminchisescu",
                        "structuredName": {
                            "firstName": "Cristian",
                            "lastName": "Sminchisescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Sminchisescu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our paper, however, directly integrates the part detectors and uses them as the appearance model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": "\u221d p(l0) \u00b7 N\u220f\ni=0\np(di|li) \u00b7 \u220f\n(i,j)\u2208E\np(li|lj), (5)\nChallenges."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13096240,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6853fa964ce06d21e1728946b3315d538890708e",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new method for training deformable models. Assume that we have training images where part locations have been labeled. Typically, one fits a model by maximizing the likelihood of the part labels. Alternatively, one could fit a model such that, when the model is run on the training images, it finds the parts. We do this by maximizing the conditional likelihood of the training data. We formulate model-learning as parameter estimation in a conditional random field (CRF). Initializing parameters with their maximum likelihood estimates, we reach the global optimum by gradient ascent. We present a learning algorithm that searches exhaustively over all part locations in an image without relying on feature detectors. This provides millions of examples of training data, and seems to avoid over-fitting issues known with CRFs. Results for part localization are relatively scarce in the community. We present results on three established datasets; Caltech motorbikes [8], USC people [19], and Weizmann horses [3]. In the Caltech set we significantly outperform the state-of-the-art [6]. For the challenging people dataset, we present results that are comparable to [19], but are obtained using a significantly more generic model (devoid of a face or skin detector). Our model is general enough to find other articulated objects; we use it to recover poses of horses in the challenging Weizmann database."
            },
            "slug": "Training-Deformable-Models-for-Localization-Ramanan-Sminchisescu",
            "title": {
                "fragments": [],
                "text": "Training Deformable Models for Localization"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A learning algorithm that searches exhaustively over all part locations in an image without relying on feature detectors is presented, and seems to avoid over-fitting issues known with CRFs."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {},
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 0,
        "totalPages": 0
    },
    "page_url": "https://www.semanticscholar.org/paper/Pictorial-structures-revisited:-People-detection-Andriluka-Roth/d9279fe29ae1e4ecd0ee34d546560f8a70d17d1d?sort=total-citations"
}