{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144097639"
                        ],
                        "name": "Igor Fedorov",
                        "slug": "Igor-Fedorov",
                        "structuredName": {
                            "firstName": "Igor",
                            "lastName": "Fedorov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Igor Fedorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722180"
                        ],
                        "name": "Ryan P. Adams",
                        "slug": "Ryan-P.-Adams",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Adams",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan P. Adams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39045061"
                        ],
                        "name": "Matthew Mattina",
                        "slug": "Matthew-Mattina",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Mattina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Mattina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3313708"
                        ],
                        "name": "P. Whatmough",
                        "slug": "P.-Whatmough",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Whatmough",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Whatmough"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[22] incorporate the maximal working memory size of an operator into their optimisation goal."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 168169895,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "90460ac9de7dc3b83c3d249514e5a6ec4ba7c4d1",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "The vast majority of processors in the world are actually microcontroller units (MCUs), which find widespread use performing simple control tasks in applications ranging from automobiles to medical devices and office equipment. The Internet of Things (IoT) promises to inject machine learning into many of these every-day objects via tiny, cheap MCUs. However, these resource-impoverished hardware platforms severely limit the complexity of machine learning models that can be deployed. For example, although convolutional neural networks (CNNs) achieve state-of-the-art results on many visual recognition tasks, CNN inference on MCUs is challenging due to severe finite memory limitations. To circumvent the memory challenge associated with CNNs, various alternatives have been proposed that do fit within the memory budget of an MCU, albeit at the cost of prediction accuracy. This paper challenges the idea that CNNs are not suitable for deployment on MCUs. We demonstrate that it is possible to automatically design CNNs which generalize well, while also being small enough to fit onto memory-limited MCUs. Our Sparse Architecture Search method combines neural architecture search with pruning in a single, unified approach, which learns superior models on four popular IoT datasets. The CNNs we find are more accurate and up to $4.35\\times$ smaller than previous approaches, while meeting the strict MCU working memory constraint."
            },
            "slug": "SpArSe:-Sparse-Architecture-Search-for-CNNs-on-Fedorov-Adams",
            "title": {
                "fragments": [],
                "text": "SpArSe: Sparse Architecture Search for CNNs on Resource-Constrained Microcontrollers"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is demonstrated that it is possible to automatically design CNNs which generalize well, while also being small enough to fit onto memory-limited MCUs, and the CNNs found are more accurate and up to $4.35 times smaller than previous approaches, while meeting the strict MCU working memory constraint."
            },
            "venue": {
                "fragments": [],
                "text": "NeurIPS"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144948031"
                        ],
                        "name": "N. Lane",
                        "slug": "N.-Lane",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Lane",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Lane"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144623952"
                        ],
                        "name": "S. Bhattacharya",
                        "slug": "S.-Bhattacharya",
                        "structuredName": {
                            "firstName": "Sourav",
                            "lastName": "Bhattacharya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bhattacharya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737522"
                        ],
                        "name": "Petko Georgiev",
                        "slug": "Petko-Georgiev",
                        "structuredName": {
                            "firstName": "Petko",
                            "lastName": "Georgiev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Petko Georgiev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779159"
                        ],
                        "name": "Claudio Forlivesi",
                        "slug": "Claudio-Forlivesi",
                        "structuredName": {
                            "firstName": "Claudio",
                            "lastName": "Forlivesi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Claudio Forlivesi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072513626"
                        ],
                        "name": "Lei Jiao",
                        "slug": "Lei-Jiao",
                        "structuredName": {
                            "firstName": "Lei",
                            "lastName": "Jiao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lei Jiao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1994899"
                        ],
                        "name": "Lorena Qendro",
                        "slug": "Lorena-Qendro",
                        "structuredName": {
                            "firstName": "Lorena",
                            "lastName": "Qendro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lorena Qendro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1776175"
                        ],
                        "name": "F. Kawsar",
                        "slug": "F.-Kawsar",
                        "structuredName": {
                            "firstName": "Fahim",
                            "lastName": "Kawsar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Kawsar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 69
                            }
                        ],
                        "text": "One can obtain a smaller neural network by using layer decomposition [9, 10], pruning [11, 12], quantisation [13] and binarisation [14, 15], distillation [16] or exploiting sparsity [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15599732,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d594839932b3ec17b2f0e30f00d1095937eabf74",
            "isKey": false,
            "numCitedBy": 379,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Breakthroughs from the field of deep learning are radically changing how sensor data are interpreted to extract the high-level information needed by mobile apps. It is critical that the gains in inference accuracy that deep models afford become embedded in future generations of mobile apps. In this work, we present the design and implementation of DeepX, a software accelerator for deep learning execution. DeepX signif- icantly lowers the device resources (viz. memory, computation, energy) required by deep learning that currently act as a severe bottleneck to mobile adoption. The foundation of DeepX is a pair of resource control algorithms, designed for the inference stage of deep learning, that: (1) decompose monolithic deep model network architectures into unit- blocks of various types, that are then more efficiently executed by heterogeneous local device processors (e.g., GPUs, CPUs); and (2), perform principled resource scaling that adjusts the architecture of deep models to shape the overhead each unit-blocks introduces. Experiments show, DeepX can allow even large-scale deep learning models to execute efficently on modern mobile processors and significantly outperform existing solutions, such as cloud-based offloading."
            },
            "slug": "DeepX:-A-Software-Accelerator-for-Low-Power-Deep-on-Lane-Bhattacharya",
            "title": {
                "fragments": [],
                "text": "DeepX: A Software Accelerator for Low-Power Deep Learning Inference on Mobile Devices"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Experiments show, DeepX can allow even large-scale deep learning models to execute efficently on modern mobile processors and significantly outperform existing solutions, such as cloud-based offloading."
            },
            "venue": {
                "fragments": [],
                "text": "2016 15th ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11543879"
                        ],
                        "name": "Benoit Jacob",
                        "slug": "Benoit-Jacob",
                        "structuredName": {
                            "firstName": "Benoit",
                            "lastName": "Jacob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benoit Jacob"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "68988581"
                        ],
                        "name": "S. Kligys",
                        "slug": "S.-Kligys",
                        "structuredName": {
                            "firstName": "Skirmantas",
                            "lastName": "Kligys",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kligys"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Bo Chen",
                        "slug": "Bo-Chen",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2717876"
                        ],
                        "name": "Menglong Zhu",
                        "slug": "Menglong-Zhu",
                        "structuredName": {
                            "firstName": "Menglong",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Menglong Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113728429"
                        ],
                        "name": "Matthew Tang",
                        "slug": "Matthew-Tang",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144727050"
                        ],
                        "name": "Andrew G. Howard",
                        "slug": "Andrew-G.-Howard",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Howard",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew G. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2595180"
                        ],
                        "name": "Hartwig Adam",
                        "slug": "Hartwig-Adam",
                        "structuredName": {
                            "firstName": "Hartwig",
                            "lastName": "Adam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hartwig Adam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741985"
                        ],
                        "name": "Dmitry Kalenichenko",
                        "slug": "Dmitry-Kalenichenko",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Kalenichenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dmitry Kalenichenko"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 109
                            }
                        ],
                        "text": "One can obtain a smaller neural network by using layer decomposition [9, 10], pruning [11, 12], quantisation [13] and binarisation [14, 15], distillation [16] or exploiting sparsity [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 39867659,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "59d0d7ccec2db66cad20cac5721ce54a8a058294",
            "isKey": false,
            "numCitedBy": 1284,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "The rising popularity of intelligent mobile devices and the daunting computational cost of deep learning-based models call for efficient and accurate on-device inference schemes. We propose a quantization scheme that allows inference to be carried out using integer-only arithmetic, which can be implemented more efficiently than floating point inference on commonly available integer-only hardware. We also co-design a training procedure to preserve end-to-end model accuracy post quantization. As a result, the proposed quantization scheme improves the tradeoff between accuracy and on-device latency. The improvements are significant even on MobileNets, a model family known for run-time efficiency, and are demonstrated in ImageNet classification and COCO detection on popular CPUs."
            },
            "slug": "Quantization-and-Training-of-Neural-Networks-for-Jacob-Kligys",
            "title": {
                "fragments": [],
                "text": "Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A quantization scheme is proposed that allows inference to be carried out using integer- only arithmetic, which can be implemented more efficiently than floating point inference on commonly available integer-only hardware."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144297561"
                        ],
                        "name": "Kevin Siu",
                        "slug": "Kevin-Siu",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Siu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Siu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40083980"
                        ],
                        "name": "Dylan Malone Stuart",
                        "slug": "Dylan-Malone-Stuart",
                        "structuredName": {
                            "firstName": "Dylan",
                            "lastName": "Stuart",
                            "middleNames": [
                                "Malone"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dylan Malone Stuart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144361709"
                        ],
                        "name": "M. Mahmoud",
                        "slug": "M.-Mahmoud",
                        "structuredName": {
                            "firstName": "Mostafa",
                            "lastName": "Mahmoud",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mahmoud"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782536"
                        ],
                        "name": "Andreas Moshovos",
                        "slug": "Andreas-Moshovos",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Moshovos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Moshovos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Concerns about the memory usage of neural networks and data movement during execution are also discussed in neural network accelerator chip design literature [29\u201331]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 56170541,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fcbeb634e3c69302a8622fc03eb6085a3b67379f",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "The rapid pace and successful application of machine learning research and development has seen widespread deployment of deep convolutional neural networks (CNNs). Alongside these algorithmic efforts, the compute- and memory-intensive nature of CNNs has stimulated a large amount of work in the field of hardware acceleration for these networks. In this paper, we profile the memory requirements of CNNs in terms of both on-chip memory size and off-chip memory bandwidth, in order to understand the impact of the memory system on accelerator design. We show that there are fundamental tradeoffs between performance, bandwidth, and on-chip memory. Further, this paper explores how the wide variety of CNNs for different application domains each have fundamentally different characteristics. We show that bandwidth and memory requirements for different networks, and occasionally for different layers within a network, can each vary by multiple orders of magnitude. This makes designing fast and efficient hardware for all CNN applications difficult. To remedy this, we outline heuristic design points that attempt to optimize for select dataflow scenarios."
            },
            "slug": "Memory-Requirements-for-Convolutional-Neural-Siu-Stuart",
            "title": {
                "fragments": [],
                "text": "Memory Requirements for Convolutional Neural Network Hardware Accelerators"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that bandwidth and memory requirements for different networks, and occasionally for different layers within a network, can each vary by multiple orders of magnitude, which makes designing fast and efficient hardware for all CNN applications difficult."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE International Symposium on Workload Characterization (IISWC)"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065227961"
                        ],
                        "name": "Georgios Georgiadis",
                        "slug": "Georgios-Georgiadis",
                        "structuredName": {
                            "firstName": "Georgios",
                            "lastName": "Georgiadis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Georgios Georgiadis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 182
                            }
                        ],
                        "text": "One can obtain a smaller neural network by using layer decomposition [9, 10], pruning [11, 12], quantisation [13] and binarisation [14, 15], distillation [16] or exploiting sparsity [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 54483352,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b8495b6f77dac227fd23b608f1ad44c338eaa679",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "The deep learning revolution brought us an extensive array of neural network architectures that achieve state-of-the-art performance in a wide variety of Computer Vision tasks including among others, classification, detection and segmentation. In parallel, we have also been observing an unprecedented demand in computational and memory requirements, rendering the efficient use of neural networks in low-powered devices virtually unattainable. Towards this end, we propose a three-stage compression and acceleration pipeline that sparsifies, quantizes and entropy encodes activation maps of Convolutional Neural Networks. Sparsification increases the representational power of activation maps leading to both acceleration of inference and higher model accuracy. Inception-V3 and MobileNet-V1 can be accelerated by as much as 1.6x with an increase in accuracy of 0.38% and 0.54% on the ImageNet and CIFAR-10 datasets respectively. Quantizing and entropy coding the sparser activation maps lead to higher compression over the baseline, reducing the memory cost of the network execution. Inception-V3 and MobileNet-V1 activation maps, quantized to 16 bits, are compressed by as much as 6x with an increase in accuracy of 0.36% and 0.55% respectively."
            },
            "slug": "Accelerating-Convolutional-Neural-Networks-via-Map-Georgiadis",
            "title": {
                "fragments": [],
                "text": "Accelerating Convolutional Neural Networks via Activation Map Compression"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A three-stage compression and acceleration pipeline that sparsifies, quantizes and entropy encodes activation maps of Convolutional Neural Networks is proposed, leading to both acceleration of inference and higher model accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49890233"
                        ],
                        "name": "Yundong Zhang",
                        "slug": "Yundong-Zhang",
                        "structuredName": {
                            "firstName": "Yundong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yundong Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40622167"
                        ],
                        "name": "Naveen Suda",
                        "slug": "Naveen-Suda",
                        "structuredName": {
                            "firstName": "Naveen",
                            "lastName": "Suda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naveen Suda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1891108"
                        ],
                        "name": "Liangzhen Lai",
                        "slug": "Liangzhen-Lai",
                        "structuredName": {
                            "firstName": "Liangzhen",
                            "lastName": "Lai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liangzhen Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144137038"
                        ],
                        "name": "V. Chandra",
                        "slug": "V.-Chandra",
                        "structuredName": {
                            "firstName": "Vikas",
                            "lastName": "Chandra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Chandra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 104
                            }
                        ],
                        "text": "Compact deep learning models have been built for use on wearables devices [26] and for keyword spotting [27, 28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1125974,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a3d4dbd03355d6b4972d7cb9257ccccdd6d33923",
            "isKey": false,
            "numCitedBy": 227,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Keyword spotting (KWS) is a critical component for enabling speech based user interactions on smart devices. It requires real-time response and high accuracy for good user experience. Recently, neural networks have become an attractive choice for KWS architecture because of their superior accuracy compared to traditional speech processing algorithms. Due to its always-on nature, KWS application has highly constrained power budget and typically runs on tiny microcontrollers with limited memory and compute capability. The design of neural network architecture for KWS must consider these constraints. In this work, we perform neural network architecture evaluation and exploration for running KWS on resource-constrained microcontrollers. We train various neural network architectures for keyword spotting published in literature to compare their accuracy and memory/compute requirements. We show that it is possible to optimize these neural network architectures to fit within the memory and compute constraints of microcontrollers without sacrificing accuracy. We further explore the depthwise separable convolutional neural network (DS-CNN) and compare it against other neural network architectures. DS-CNN achieves an accuracy of 95.4%, which is ~10% higher than the DNN model with similar number of parameters."
            },
            "slug": "Hello-Edge:-Keyword-Spotting-on-Microcontrollers-Zhang-Suda",
            "title": {
                "fragments": [],
                "text": "Hello Edge: Keyword Spotting on Microcontrollers"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that it is possible to optimize these neural network architectures to fit within the memory and compute constraints of microcontrollers without sacrificing accuracy, and the depthwise separable convolutional neural network (DS-CNN) is explored and compared against other neural network architecture."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144623952"
                        ],
                        "name": "S. Bhattacharya",
                        "slug": "S.-Bhattacharya",
                        "structuredName": {
                            "firstName": "Sourav",
                            "lastName": "Bhattacharya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bhattacharya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144948031"
                        ],
                        "name": "N. Lane",
                        "slug": "N.-Lane",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Lane",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Lane"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": "Compact deep learning models have been built for use on wearables devices [26] and for keyword spotting [27, 28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15762813,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "187a78ebfe654e9c1d3e8d070c8845a49c1d1a42",
            "isKey": false,
            "numCitedBy": 181,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep learning has revolutionized the way sensor data are analyzed and interpreted. The accuracy gains these approaches offer make them attractive for the next generation of mobile, wearable and embedded sensory applications. However, state-of-the-art deep learning algorithms typically require a significant amount of device and processor resources, even just for the inference stages that are used to discriminate high-level classes from low-level data. The limited availability of memory, computation, and energy on mobile and embedded platforms thus pose a significant challenge to the adoption of these powerful learning techniques. In this paper, we propose SparseSep, a new approach that leverages the sparsification of fully connected layers and separation of convolutional kernels to reduce the resource requirements of popular deep learning algorithms. As a result, SparseSep allows large-scale DNNs and CNNs to run efficiently on mobile and embedded hardware with only minimal impact on inference accuracy. We experiment using SparseSep across a variety of common processors such as the Qualcomm Snapdragon 400, ARM Cortex M0 and M3, and Nvidia Tegra K1, and show that it allows inference for various deep models to execute more efficiently; for example, on average requiring 11.3 times less memory and running 13.3 times faster on these representative platforms."
            },
            "slug": "Sparsification-and-Separation-of-Deep-Learning-for-Bhattacharya-Lane",
            "title": {
                "fragments": [],
                "text": "Sparsification and Separation of Deep Learning Layers for Constrained Resource Inference on Wearables"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper proposes SparseSep, a new approach that leverages the sparsification of fully connected layers and separation of convolutional kernels to reduce the resource requirements of popular deep learning algorithms, and allows large-scale DNNs and CNNs to run efficiently on mobile and embedded hardware with only minimal impact on inference accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "SenSys"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2038164264"
                        ],
                        "name": "Georgiadis Georgios",
                        "slug": "Georgiadis-Georgios",
                        "structuredName": {
                            "firstName": "Georgiadis",
                            "lastName": "Georgios",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Georgiadis Georgios"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "troller hardware. One can obtain a smaller neural network by using layer decomposition [9, 10], pruning [11, 12], quantisation [13] and binarisation [14, 15], distillation [16] or exploiting sparsity [17]. Popular mobile-friendly CNN architectures include 2 MobileNet [18] and Shuf\ufb02eNet [19]. MNasNet [20] and Ef\ufb01cientNet [21] develop architecture search algorithms to design a network within a certain \ufb02"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 229296305,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6101aafc92cb62a32b454bd5302fe87a73e6589",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "The deep learning revolution brought us an extensive array of neural network architectures that achieve state-of-the-art performance in a wide variety of Computer Vision tasks including among others, classification, detection and segmentation. In parallel, we have also been observing an unprecedented demand in computational and memory requirements, rendering the efficient use of neural networks in low-powered devices virtually unattainable. Towards this end, we propose a three-stage compression and acceleration pipeline that sparsifies, quantizes and entropy encodes activation maps of Convolutional Neural Networks. Sparsification increases the representational power of activation maps leading to both acceleration of inference and higher model accuracy. Inception-V3 and MobileNet-V1 can be accelerated by as much as $1.6\\times$ with an increase in accuracy of $0.38\\%$ and $0.54\\%$ on the ImageNet and CIFAR-10 datasets respectively. Quantizing and entropy coding the sparser activation maps lead to higher compression over the baseline, reducing the memory cost of the network execution. Inception-V3 and MobileNet-V1 activation maps, quantized to $16$ bits, are compressed by as much as $6\\times$ with an increase in accuracy of $0.36\\%$ and $0.55\\%$ respectively."
            },
            "slug": "Accelerating-Convolutional-Neural-Networks-via-Map-Georgios",
            "title": {
                "fragments": [],
                "text": "Accelerating Convolutional Neural Networks via Activation Map Compression"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A three-stage compression and acceleration pipeline that sparsifies, quantizes and entropy encodes activation maps of Convolutional Neural Networks is proposed, leading to both acceleration of inference and higher model accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "CVPR 2019"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790421"
                        ],
                        "name": "A. Parashar",
                        "slug": "A.-Parashar",
                        "structuredName": {
                            "firstName": "Angshuman",
                            "lastName": "Parashar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Parashar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1998820"
                        ],
                        "name": "Minsoo Rhu",
                        "slug": "Minsoo-Rhu",
                        "structuredName": {
                            "firstName": "Minsoo",
                            "lastName": "Rhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minsoo Rhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3374545"
                        ],
                        "name": "Anurag Mukkara",
                        "slug": "Anurag-Mukkara",
                        "structuredName": {
                            "firstName": "Anurag",
                            "lastName": "Mukkara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anurag Mukkara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2274681"
                        ],
                        "name": "A. Puglielli",
                        "slug": "A.-Puglielli",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Puglielli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Puglielli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3172075"
                        ],
                        "name": "Rangharajan Venkatesan",
                        "slug": "Rangharajan-Venkatesan",
                        "structuredName": {
                            "firstName": "Rangharajan",
                            "lastName": "Venkatesan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rangharajan Venkatesan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2125244"
                        ],
                        "name": "Brucek Khailany",
                        "slug": "Brucek-Khailany",
                        "structuredName": {
                            "firstName": "Brucek",
                            "lastName": "Khailany",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brucek Khailany"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775477"
                        ],
                        "name": "J. Emer",
                        "slug": "J.-Emer",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Emer",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Emer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715863"
                        ],
                        "name": "S. Keckler",
                        "slug": "S.-Keckler",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Keckler",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Keckler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80724002"
                        ],
                        "name": "W. Dally",
                        "slug": "W.-Dally",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dally",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dally"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Concerns about the memory usage of neural networks and data movement during execution are also discussed in neural network accelerator chip design literature [29\u201331]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1775161,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "402f850dff86fb601d34b2841e6083ac0f928edd",
            "isKey": false,
            "numCitedBy": 742,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional Neural Networks (CNNs) have emerged as a fundamental technology for machine learning. High performance and extreme energy efficiency are critical for deployments of CNNs, especially in mobile platforms such as autonomous vehicles, cameras, and electronic personal assistants. This paper introduces the Sparse CNN (SCNN) accelerator architecture, which improves performance and energy efficiency by exploiting the zero-valued weights that stem from network pruning during training and zero-valued activations that arise from the common ReLU operator. Specifically, SCNN employs a novel dataflow that enables maintaining the sparse weights and activations in a compressed encoding, which eliminates unnecessary data transfers and reduces storage requirements. Furthermore, the SCNN dataflow facilitates efficient delivery of those weights and activations to a multiplier array, where they are extensively reused; product accumulation is performed in a novel accumulator array. On contemporary neural networks, SCNN can improve both performance and energy by a factor of 2.7\u00d7 and 2.3\u00d7, respectively, over a comparably provisioned dense CNN accelerator."
            },
            "slug": "SCNN:-An-accelerator-for-compressed-sparse-neural-Parashar-Rhu",
            "title": {
                "fragments": [],
                "text": "SCNN: An accelerator for compressed-sparse convolutional neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The Sparse CNN (SCNN) accelerator architecture is introduced, which improves performance and energy efficiency by exploiting thezero-valued weights that stem from network pruning during training and zero-valued activations that arise from the common ReLU operator."
            },
            "venue": {
                "fragments": [],
                "text": "2017 ACM/IEEE 44th Annual International Symposium on Computer Architecture (ISCA)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2388466"
                        ],
                        "name": "Matthieu Courbariaux",
                        "slug": "Matthieu-Courbariaux",
                        "structuredName": {
                            "firstName": "Matthieu",
                            "lastName": "Courbariaux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthieu Courbariaux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477463"
                        ],
                        "name": "Itay Hubara",
                        "slug": "Itay-Hubara",
                        "structuredName": {
                            "firstName": "Itay",
                            "lastName": "Hubara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Itay Hubara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1912398"
                        ],
                        "name": "Daniel Soudry",
                        "slug": "Daniel-Soudry",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Soudry",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Soudry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1387872181"
                        ],
                        "name": "Ran El-Yaniv",
                        "slug": "Ran-El-Yaniv",
                        "structuredName": {
                            "firstName": "Ran",
                            "lastName": "El-Yaniv",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ran El-Yaniv"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14796162,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6eecc808d4c74e7d0d7ef6b8a4112c985ced104d",
            "isKey": false,
            "numCitedBy": 1753,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a method to train Binarized Neural Networks (BNNs) - neural networks with binary weights and activations at run-time. At training-time the binary weights and activations are used for computing the parameters gradients. During the forward pass, BNNs drastically reduce memory size and accesses, and replace most arithmetic operations with bit-wise operations, which is expected to substantially improve power-efficiency. To validate the effectiveness of BNNs we conduct two sets of experiments on the Torch7 and Theano frameworks. On both, BNNs achieved nearly state-of-the-art results over the MNIST, CIFAR-10 and SVHN datasets. Last but not least, we wrote a binary matrix multiplication GPU kernel with which it is possible to run our MNIST BNN 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classification accuracy. The code for training and running our BNNs is available on-line."
            },
            "slug": "Binarized-Neural-Networks:-Training-Deep-Neural-and-Courbariaux-Hubara",
            "title": {
                "fragments": [],
                "text": "Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A binary matrix multiplication GPU kernel is written with which it is possible to run the MNIST BNN 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classification accuracy."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401656657"
                        ],
                        "name": "J. Fern\u00e1ndez-Marqu\u00e9s",
                        "slug": "J.-Fern\u00e1ndez-Marqu\u00e9s",
                        "structuredName": {
                            "firstName": "Javier",
                            "lastName": "Fern\u00e1ndez-Marqu\u00e9s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fern\u00e1ndez-Marqu\u00e9s"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31701529"
                        ],
                        "name": "V. W. Tseng",
                        "slug": "V.-W.-Tseng",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Tseng",
                            "middleNames": [
                                "Wen-Sheng"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. W. Tseng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144623952"
                        ],
                        "name": "S. Bhattacharya",
                        "slug": "S.-Bhattacharya",
                        "structuredName": {
                            "firstName": "Sourav",
                            "lastName": "Bhattacharya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bhattacharya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144948031"
                        ],
                        "name": "N. Lane",
                        "slug": "N.-Lane",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Lane",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Lane"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 104
                            }
                        ],
                        "text": "Compact deep learning models have been built for use on wearables devices [26] and for keyword spotting [27, 28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52105662,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37bc843a934d636f75010663d5f66d794e84c25e",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Lightweight keyword spotting (KWS) applications are often used to trigger the execution of more complex speech recognition algorithms that are computationally demanding and therefore cannot be constantly running on the device. Often KWS applications are executed in small microcontrollers with very constrained memory (e.g. 128kB) and compute capabilities (e.g. CPU at 80MHz) limiting the complexity of deployable KWS systems. We present a compact binary architecture with 60% fewer parameters and 50% fewer operations (OP) during inference compared to the current state of the art for KWS applications at the cost of 3.4% accuracy drop. It makes use of binary orthogonal codes to analyse speech features from a voice command resulting in a model with minimal memory footprint and computationally cheap, making possible its deployment in very resource-constrained microcontrollers with less than 30kB of on-chip memory. Our technique offers a different perspective to how filters in neural networks could be constructed at inference time instead of directly loading them from disk."
            },
            "slug": "On-the-fly-deterministic-binary-filters-for-memory-Fern\u00e1ndez-Marqu\u00e9s-Tseng",
            "title": {
                "fragments": [],
                "text": "On-the-fly deterministic binary filters for memory efficient keyword spotting applications on embedded devices"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A compact binary architecture with 60% fewer parameters and 50% fewer operations (OP) during inference compared to the current state of the art for KWS applications at the cost of 3.4% accuracy drop is presented."
            },
            "venue": {
                "fragments": [],
                "text": "EMDL@MobiSys"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2094572"
                        ],
                        "name": "Manoj Alwani",
                        "slug": "Manoj-Alwani",
                        "structuredName": {
                            "firstName": "Manoj",
                            "lastName": "Alwani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manoj Alwani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118024233"
                        ],
                        "name": "Han Chen",
                        "slug": "Han-Chen",
                        "structuredName": {
                            "firstName": "Han",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Han Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1843152"
                        ],
                        "name": "M. Ferdman",
                        "slug": "M.-Ferdman",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Ferdman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ferdman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2719024"
                        ],
                        "name": "Peter Milder",
                        "slug": "Peter-Milder",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Milder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Milder"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[23] propose not to materialise an output tensor of a large convolution operation in memory at all, and compute its individual output elements as needed by succeeding operators."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5804465,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72ed74f00d0f7312f7ed96d93ed43f0052d526bc",
            "isKey": false,
            "numCitedBy": 360,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep convolutional neural networks (CNNs) are rapidly becoming the dominant approach to computer vision and a major component of many other pervasive machine learning tasks, such as speech recognition, natural language processing, and fraud detection. As a result, accelerators for efficiently evaluating CNNs are rapidly growing in popularity. The conventional approaches to designing such CNN accelerators is to focus on creating accelerators to iteratively process the CNN layers. However, by processing each layer to completion, the accelerator designs must use off-chip memory to store intermediate data between layers, because the intermediate data are too large to fit on chip. In this work, we observe that a previously unexplored dimension exists in the design space of CNN accelerators that focuses on the dataflow across convolutional layers. We find that we are able to fuse the processing of multiple CNN layers by modifying the order in which the input data are brought on chip, enabling caching of intermediate data between the evaluation of adjacent CNN layers. We demonstrate the effectiveness of our approach by constructing a fused-layer CNN accelerator for the first five convolutional layers of the VGGNet-E network and comparing it to the state-of-the-art accelerator implemented on a Xilinx Virtex-7 FPGA. We find that, by using 362KB of on-chip storage, our fused-layer accelerator minimizes off-chip feature map data transfer, reducing the total transfer by 95%, from 77MB down to 3.6MB per image."
            },
            "slug": "Fused-layer-CNN-accelerators-Alwani-Chen",
            "title": {
                "fragments": [],
                "text": "Fused-layer CNN accelerators"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work finds that a previously unexplored dimension exists in the design space of CNN accelerators that focuses on the dataflow across convolutional layers, and is able to fuse the processing of multiple CNN layers by modifying the order in which the input data are brought on chip, enabling caching of intermediate data between the evaluation of adjacent CNN layers."
            },
            "venue": {
                "fragments": [],
                "text": "2016 49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2841893"
                        ],
                        "name": "Aakanksha Chowdhery",
                        "slug": "Aakanksha-Chowdhery",
                        "structuredName": {
                            "firstName": "Aakanksha",
                            "lastName": "Chowdhery",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aakanksha Chowdhery"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47941411"
                        ],
                        "name": "P. Warden",
                        "slug": "P.-Warden",
                        "structuredName": {
                            "firstName": "Pete",
                            "lastName": "Warden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Warden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789737"
                        ],
                        "name": "Jonathon Shlens",
                        "slug": "Jonathon-Shlens",
                        "structuredName": {
                            "firstName": "Jonathon",
                            "lastName": "Shlens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathon Shlens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144727050"
                        ],
                        "name": "Andrew G. Howard",
                        "slug": "Andrew-G.-Howard",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Howard",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew G. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "147961415"
                        ],
                        "name": "Rocky Rhodes",
                        "slug": "Rocky-Rhodes",
                        "structuredName": {
                            "firstName": "Rocky",
                            "lastName": "Rhodes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rocky Rhodes"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "We use one of the winning submissions of the Visual Wake Words competition [25], called SwiftNet Cell [34, 35], as it has only 250KB of parameters and contains many branches, which enables us to showcase the benefits of reordering."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 129
                            }
                        ],
                        "text": "The development of low-power machine learning models is fostered by the TinyML Summit [24] and the Visual Wake Words competition [25], which looked for performant MCU-sized CNNs for person detection."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 189762389,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "98658bf480db76a44c50a027379a6f526cf728e8",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The emergence of Internet of Things (IoT) applications requires intelligence on the edge. Microcontrollers provide a low-cost compute platform to deploy intelligent IoT applications using machine learning at scale, but have extremely limited on-chip memory and compute capability. To deploy computer vision on such devices, we need tiny vision models that fit within a few hundred kilobytes of memory footprint in terms of peak usage and model size on device storage. To facilitate the development of microcontroller friendly models, we present a new dataset, Visual Wake Words, that represents a common microcontroller vision use-case of identifying whether a person is present in the image or not, and provides a realistic benchmark for tiny vision models. Within a limited memory footprint of 250 KB, several state-of-the-art mobile models achieve accuracy of 85-90% on the Visual Wake Words dataset. We anticipate the proposed dataset will advance the research on tiny vision models that can push the pareto-optimal boundary in terms of accuracy versus memory usage for microcontroller applications."
            },
            "slug": "Visual-Wake-Words-Dataset-Chowdhery-Warden",
            "title": {
                "fragments": [],
                "text": "Visual Wake Words Dataset"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new dataset, Visual Wake Words, is presented that represents a common microcontroller vision use-case of identifying whether a person is present in the image or not, and provides a realistic benchmark for tiny vision models."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143840275"
                        ],
                        "name": "Song Han",
                        "slug": "Song-Han",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3123774"
                        ],
                        "name": "Huizi Mao",
                        "slug": "Huizi-Mao",
                        "structuredName": {
                            "firstName": "Huizi",
                            "lastName": "Mao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huizi Mao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80724002"
                        ],
                        "name": "W. Dally",
                        "slug": "W.-Dally",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dally",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dally"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "One can obtain a smaller neural network by using layer decomposition [9, 10], pruning [11, 12], quantisation [13] and binarisation [14, 15], distillation [16] or exploiting sparsity [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2134321,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "642d0f49b7826adcf986616f4af77e736229990f",
            "isKey": false,
            "numCitedBy": 5732,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural networks are both computationally intensive and memory intensive, making them difficult to deploy on embedded systems with limited hardware resources. To address this limitation, we introduce \"deep compression\", a three stage pipeline: pruning, trained quantization and Huffman coding, that work together to reduce the storage requirement of neural networks by 35x to 49x without affecting their accuracy. Our method first prunes the network by learning only the important connections. Next, we quantize the weights to enforce weight sharing, finally, we apply Huffman coding. After the first two steps we retrain the network to fine tune the remaining connections and the quantized centroids. Pruning, reduces the number of connections by 9x to 13x; Quantization then reduces the number of bits that represent each connection from 32 to 5. On the ImageNet dataset, our method reduced the storage required by AlexNet by 35x, from 240MB to 6.9MB, without loss of accuracy. Our method reduced the size of VGG-16 by 49x from 552MB to 11.3MB, again with no loss of accuracy. This allows fitting the model into on-chip SRAM cache rather than off-chip DRAM memory. Our compression method also facilitates the use of complex neural networks in mobile applications where application size and download bandwidth are constrained. Benchmarked on CPU, GPU and mobile GPU, compressed network has 3x to 4x layerwise speedup and 3x to 7x better energy efficiency."
            },
            "slug": "Deep-Compression:-Compressing-Deep-Neural-Network-Han-Mao",
            "title": {
                "fragments": [],
                "text": "Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work introduces \"deep compression\", a three stage pipeline: pruning, trained quantization and Huffman coding, that work together to reduce the storage requirement of neural networks by 35x to 49x without affecting their accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120805419"
                        ],
                        "name": "Mingxing Tan",
                        "slug": "Mingxing-Tan",
                        "structuredName": {
                            "firstName": "Mingxing",
                            "lastName": "Tan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mingxing Tan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Bo Chen",
                        "slug": "Bo-Chen",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34320634"
                        ],
                        "name": "Ruoming Pang",
                        "slug": "Ruoming-Pang",
                        "structuredName": {
                            "firstName": "Ruoming",
                            "lastName": "Pang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruoming Pang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053781980"
                        ],
                        "name": "Vijay Vasudevan",
                        "slug": "Vijay-Vasudevan",
                        "structuredName": {
                            "firstName": "Vijay",
                            "lastName": "Vasudevan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vijay Vasudevan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "MNasNet [20] and EfficientNet [21] develop architecture search algorithms to design a network within a certain floating-point operation count or memory budget."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 51891697,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "693c97ecedb0a84539b7162c95e89fa3cd84ca73",
            "isKey": false,
            "numCitedBy": 1613,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Designing convolutional neural networks (CNN) for mobile devices is challenging because mobile models need to be small and fast, yet still accurate. Although significant efforts have been dedicated to design and improve mobile CNNs on all dimensions, it is very difficult to manually balance these trade-offs when there are so many architectural possibilities to consider. In this paper, we propose an automated mobile neural architecture search (MNAS) approach, which explicitly incorporate model latency into the main objective so that the search can identify a model that achieves a good trade-off between accuracy and latency. Unlike previous work, where latency is considered via another, often inaccurate proxy (e.g., FLOPS), our approach directly measures real-world inference latency by executing the model on mobile phones. To further strike the right balance between flexibility and search space size, we propose a novel factorized hierarchical search space that encourages layer diversity throughout the network. Experimental results show that our approach consistently outperforms state-of-the-art mobile CNN models across multiple vision tasks. On the ImageNet classification task, our MnasNet achieves 75.2% top-1 accuracy with 78ms latency on a Pixel phone, which is 1.8\u00d7 faster than MobileNetV2 with 0.5% higher accuracy and 2.3\u00d7 faster than NASNet with 1.2% higher accuracy. Our MnasNet also achieves better mAP quality than MobileNets for COCO object detection. Code is at https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet."
            },
            "slug": "MnasNet:-Platform-Aware-Neural-Architecture-Search-Tan-Chen",
            "title": {
                "fragments": [],
                "text": "MnasNet: Platform-Aware Neural Architecture Search for Mobile"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An automated mobile neural architecture search (MNAS) approach, which explicitly incorporate model latency into the main objective so that the search can identify a model that achieves a good trade-off between accuracy and latency."
            },
            "venue": {
                "fragments": [],
                "text": "2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50875121"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "Xiangyu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148927556"
                        ],
                        "name": "Xinyu Zhou",
                        "slug": "Xinyu-Zhou",
                        "structuredName": {
                            "firstName": "Xinyu",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinyu Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3287035"
                        ],
                        "name": "Mengxiao Lin",
                        "slug": "Mengxiao-Lin",
                        "structuredName": {
                            "firstName": "Mengxiao",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mengxiao Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 80
                            }
                        ],
                        "text": "Popular mobile-friendly CNN architectures include MobileNet [18] and ShuffleNet [19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 24982157,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9da734397acd7ff7c557960c62fb1b400b27bd89",
            "isKey": false,
            "numCitedBy": 3251,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce an extremely computation-efficient CNN architecture named ShuffleNet, which is designed specially for mobile devices with very limited computing power (e.g., 10-150 MFLOPs). The new architecture utilizes two new operations, pointwise group convolution and channel shuffle, to greatly reduce computation cost while maintaining accuracy. Experiments on ImageNet classification and MS COCO object detection demonstrate the superior performance of ShuffleNet over other structures, e.g. lower top-1 error (absolute 7.8%) than recent MobileNet [12] on ImageNet classification task, under the computation budget of 40 MFLOPs. On an ARM-based mobile device, ShuffleNet achieves ~13\u00c3\u2014 actual speedup over AlexNet while maintaining comparable accuracy."
            },
            "slug": "ShuffleNet:-An-Extremely-Efficient-Convolutional-Zhang-Zhou",
            "title": {
                "fragments": [],
                "text": "ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "An extremely computation-efficient CNN architecture named ShuffleNet is introduced, which is designed specially for mobile devices with very limited computing power (e.g., 10-150 MFLOPs), to greatly reduce computation cost while maintaining accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120805419"
                        ],
                        "name": "Mingxing Tan",
                        "slug": "Mingxing-Tan",
                        "structuredName": {
                            "firstName": "Mingxing",
                            "lastName": "Tan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mingxing Tan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "MNasNet [20] and EfficientNet [21] develop architecture search algorithms to design a network within a certain floating-point operation count or memory budget."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 167217261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f2eda8077dc7a69bb2b4e0a1a086cf054adb3f9",
            "isKey": false,
            "numCitedBy": 5194,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up MobileNets and ResNet. \nTo go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves state-of-the-art 84.4% top-1 / 97.1% top-5 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet. Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7%), Flowers (98.8%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters. Source code is at this https URL."
            },
            "slug": "EfficientNet:-Rethinking-Model-Scaling-for-Neural-Tan-Le",
            "title": {
                "fragments": [],
                "text": "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A new scaling method is proposed that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient and is demonstrated the effectiveness of this method on scaling up MobileNets and ResNet."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3461946"
                        ],
                        "name": "Hsin-Pai Cheng",
                        "slug": "Hsin-Pai-Cheng",
                        "structuredName": {
                            "firstName": "Hsin-Pai",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hsin-Pai Cheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150326293"
                        ],
                        "name": "Tunhou Zhang",
                        "slug": "Tunhou-Zhang",
                        "structuredName": {
                            "firstName": "Tunhou",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tunhou Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11932602"
                        ],
                        "name": "Yukun Yang",
                        "slug": "Yukun-Yang",
                        "structuredName": {
                            "firstName": "Yukun",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yukun Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067808802"
                        ],
                        "name": "Feng Yan",
                        "slug": "Feng-Yan",
                        "structuredName": {
                            "firstName": "Feng",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Feng Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "151482330"
                        ],
                        "name": "Shiyu Li",
                        "slug": "Shiyu-Li",
                        "structuredName": {
                            "firstName": "Shiyu",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shiyu Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145909699"
                        ],
                        "name": "Harris Teague",
                        "slug": "Harris-Teague",
                        "structuredName": {
                            "firstName": "Harris",
                            "lastName": "Teague",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Harris Teague"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51208601"
                        ],
                        "name": "H. Li",
                        "slug": "H.-Li",
                        "structuredName": {
                            "firstName": "Hai",
                            "lastName": "Li",
                            "middleNames": [
                                "Helen"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5442167"
                        ],
                        "name": "Yiran Chen",
                        "slug": "Yiran-Chen",
                        "structuredName": {
                            "firstName": "Yiran",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiran Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 44
                            }
                        ],
                        "text": "Including the framework overhead (\u2248200KB for SwiftNet Cell, proportional to the number of tensors), this made a sufficient difference to make the model\u2019s memory footprint fit within SRAM.3 We also check the overhead introduced by replacing a static memory allocator with a dynamic one by running MobileNet-v1-based [37] person detection model (from the Tensorflow Lite Micro repository [33])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 102
                            }
                        ],
                        "text": "We use one of the winning submissions of the Visual Wake Words competition [25], called SwiftNet Cell [34, 35], as it has only 250KB of parameters and contains many branches, which enables us to showcase the benefits of reordering."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 195218506,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2dd259eefa6dc3246cb63ee481b447864da7830c",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Designing neural architectures for edge devices is subject to constraints of accuracy, inference latency, and computational cost. Traditionally, researchers manually craft deep neural networks to meet the needs of mobile devices. Neural Architecture Search (NAS) was proposed to automate the neural architecture design without requiring extensive domain expertise and significant manual efforts. Recent works utilized NAS to design mobile models by taking into account hardware constraints and achieved state-of-the-art accuracy with fewer parameters and less computational cost measured in Multiply-accumulates (MACs). To find highly compact neural architectures, existing works relies on predefined cells and directly applying width multiplier, which may potentially limit the model flexibility, reduce the useful feature map information, and cause accuracy drop. To conquer this issue, we propose GRAM(GRAph propagation as Meta-knowledge) that adopts fine-grained (node-wise) search method and accumulates the knowledge learned in updates into a meta-graph. As a result, GRAM can enable more flexible search space and achieve higher search efficiency. Without the constraints of predefined cell or blocks, we propose a new structure-level pruning method to remove redundant operations in neural architectures. SwiftNet, which is a set of models discovered by GRAM, outperforms MobileNet-V2 by 2.15x higher accuracy density and 2.42x faster with similar accuracy. Compared with FBNet, SwiftNet reduces the search cost by 26x and achieves 2.35x higher accuracy density and 1.47x speedup while preserving similar accuracy. SwiftNetcan obtain 63.28% top-1 accuracy on ImageNet-1K with only 53M MACs and 2.07M parameters. The corresponding inference latency is only 19.09 ms on Google Pixel 1."
            },
            "slug": "SwiftNet:-Using-Graph-Propagation-as-Meta-knowledge-Cheng-Zhang",
            "title": {
                "fragments": [],
                "text": "SwiftNet: Using Graph Propagation as Meta-knowledge to Search Highly Representative Neural Architectures"
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153522427"
                        ],
                        "name": "Chenghao Cai",
                        "slug": "Chenghao-Cai",
                        "structuredName": {
                            "firstName": "Chenghao",
                            "lastName": "Cai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chenghao Cai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36213393"
                        ],
                        "name": "Dengfeng Ke",
                        "slug": "Dengfeng-Ke",
                        "structuredName": {
                            "firstName": "Dengfeng",
                            "lastName": "Ke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dengfeng Ke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110198899"
                        ],
                        "name": "Yanyan Xu",
                        "slug": "Yanyan-Xu",
                        "structuredName": {
                            "firstName": "Yanyan",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yanyan Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724626"
                        ],
                        "name": "Kaile Su",
                        "slug": "Kaile-Su",
                        "structuredName": {
                            "firstName": "Kaile",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaile Su"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 69
                            }
                        ],
                        "text": "One can obtain a smaller neural network by using layer decomposition [9, 10], pruning [11, 12], quantisation [13] and binarisation [14, 15], distillation [16] or exploiting sparsity [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 32240897,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6ff2b53c25213fa7210b6a51f84e7c517f1ad558",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a new fast training methodology for learning of Deep Neural Networks (DNNs) via Singular Value Decomposition (SVD). The fast training methodology uses a supervised pre-adjusting process to adjust roughly parameters of weight matrices of DNNs and change distributions of singular values. SVD is applied to pre-adjusted DNNs, reducing quantities of parameters in DNNs. An unconventional Back Propagation (BP) algorithm is used to train the models restructured by SVD, which has lower time complexity than the conventional BP algorithm. Experimental results indicate that on Large Vocabulary Continuous Speech Recognition (LVCSR) tasks, using the fast training methodology, the unconventional BP algorithm achieves almost 2 times speed-up without any loss of recognition performance and almost 4 times speed-up with only a tiny loss of recognition performance."
            },
            "slug": "Fast-Learning-of-Deep-Neural-Networks-via-Singular-Cai-Ke",
            "title": {
                "fragments": [],
                "text": "Fast Learning of Deep Neural Networks via Singular Value Decomposition"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Experimental results indicate that on Large Vocabulary Continuous Speech Recognition (LVCSR) tasks, using the fast training methodology, the unconventional BP algorithm achieves almost 2 times speed-up without any loss of recognition performance and almost 4 times speed up with only a tiny loss of Recognition performance."
            },
            "venue": {
                "fragments": [],
                "text": "PRICAI"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144727050"
                        ],
                        "name": "Andrew G. Howard",
                        "slug": "Andrew-G.-Howard",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Howard",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew G. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2717876"
                        ],
                        "name": "Menglong Zhu",
                        "slug": "Menglong-Zhu",
                        "structuredName": {
                            "firstName": "Menglong",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Menglong Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Bo Chen",
                        "slug": "Bo-Chen",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741985"
                        ],
                        "name": "Dmitry Kalenichenko",
                        "slug": "Dmitry-Kalenichenko",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Kalenichenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dmitry Kalenichenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108301072"
                        ],
                        "name": "Weijun Wang",
                        "slug": "Weijun-Wang",
                        "structuredName": {
                            "firstName": "Weijun",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weijun Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47447630"
                        ],
                        "name": "Tobias Weyand",
                        "slug": "Tobias-Weyand",
                        "structuredName": {
                            "firstName": "Tobias",
                            "lastName": "Weyand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tobias Weyand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2612392"
                        ],
                        "name": "M. Andreetto",
                        "slug": "M.-Andreetto",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Andreetto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Andreetto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2595180"
                        ],
                        "name": "Hartwig Adam",
                        "slug": "Hartwig-Adam",
                        "structuredName": {
                            "firstName": "Hartwig",
                            "lastName": "Adam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hartwig Adam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12670695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3647d6d0f151dc05626449ee09cc7bce55be497e",
            "isKey": false,
            "numCitedBy": 10323,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization."
            },
            "slug": "MobileNets:-Efficient-Convolutional-Neural-Networks-Howard-Zhu",
            "title": {
                "fragments": [],
                "text": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work introduces two simple global hyper-parameters that efficiently trade off between latency and accuracy and demonstrates the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2368067"
                        ],
                        "name": "Barret Zoph",
                        "slug": "Barret-Zoph",
                        "structuredName": {
                            "firstName": "Barret",
                            "lastName": "Zoph",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barret Zoph"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053781980"
                        ],
                        "name": "Vijay Vasudevan",
                        "slug": "Vijay-Vasudevan",
                        "structuredName": {
                            "firstName": "Vijay",
                            "lastName": "Vasudevan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vijay Vasudevan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789737"
                        ],
                        "name": "Jonathon Shlens",
                        "slug": "Jonathon-Shlens",
                        "structuredName": {
                            "firstName": "Jonathon",
                            "lastName": "Shlens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathon Shlens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1397917613"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc V.",
                            "lastName": "Le",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 71
                            }
                        ],
                        "text": "However, more recent architectures, such as ResNet [4], Inception [5], NasNet [6], introduce divergent processing paths where the same tensor can be processed by several layers, i.e. their computation graph is no longer linear and has branches."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 1
                            }
                        ],
                        "text": "MNasNet [20] and EfficientNet [21] develop architecture search algorithms to design a network within a certain floating-point operation count or memory budget."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 78
                            }
                        ],
                        "text": "However, more recent architectures, such as ResNet [4], Inception [5], NasNet [6], introduce divergent processing paths where the same tensor can be processed by several layers, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12227989,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0611891b9e8a7c5731146097b6f201578f47b2f",
            "isKey": false,
            "numCitedBy": 3538,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "Developing neural network image classification models often requires significant architecture engineering. In this paper, we study a method to learn the model architectures directly on the dataset of interest. As this approach is expensive when the dataset is large, we propose to search for an architectural building block on a small dataset and then transfer the block to a larger dataset. The key contribution of this work is the design of a new search space (which we call the \"NASNet search space\") which enables transferability. In our experiments, we search for the best convolutional layer (or \"cell\") on the CIFAR-10 dataset and then apply this cell to the ImageNet dataset by stacking together more copies of this cell, each with their own parameters to design a convolutional architecture, which we name a \"NASNet architecture\". We also introduce a new regularization technique called ScheduledDropPath that significantly improves generalization in the NASNet models. On CIFAR-10 itself, a NASNet found by our method achieves 2.4% error rate, which is state-of-the-art. Although the cell is not searched for directly on ImageNet, a NASNet constructed from the best cell achieves, among the published works, state-of-the-art accuracy of 82.7% top-1 and 96.2% top-5 on ImageNet. Our model is 1.2% better in top-1 accuracy than the best human-invented architectures while having 9 billion fewer FLOPS - a reduction of 28% in computational demand from the previous state-of-the-art model. When evaluated at different levels of computational cost, accuracies of NASNets exceed those of the state-of-the-art human-designed models. For instance, a small version of NASNet also achieves 74% top-1 accuracy, which is 3.1% better than equivalently-sized, state-of-the-art models for mobile platforms. Finally, the image features learned from image classification are generically useful and can be transferred to other computer vision problems. On the task of object detection, the learned features by NASNet used with the Faster-RCNN framework surpass state-of-the-art by 4.0% achieving 43.1% mAP on the COCO dataset."
            },
            "slug": "Learning-Transferable-Architectures-for-Scalable-Zoph-Vasudevan",
            "title": {
                "fragments": [],
                "text": "Learning Transferable Architectures for Scalable Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper proposes to search for an architectural building block on a small dataset and then transfer the block to a larger dataset and introduces a new regularization technique called ScheduledDropPath that significantly improves generalization in the NASNet models."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 90
                            }
                        ],
                        "text": "Classic neural network architectures, such as the original multilayer perceptron, AlexNet [2], VGG [3], consist of a linear sequence of layers, which are iteratively applied to transform the input."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 195908774,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "isKey": false,
            "numCitedBy": 82046,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry."
            },
            "slug": "ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever",
            "title": {
                "fragments": [],
                "text": "ImageNet classification with deep convolutional neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A large, deep convolutional neural network was trained to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes and employed a recently developed regularization method called \"dropout\" that proved to be very effective."
            },
            "venue": {
                "fragments": [],
                "text": "Commun. ACM"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2574060"
                        ],
                        "name": "Christian Szegedy",
                        "slug": "Christian-Szegedy",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Szegedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Szegedy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054165706"
                        ],
                        "name": "S. Ioffe",
                        "slug": "S.-Ioffe",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Ioffe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ioffe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2657155"
                        ],
                        "name": "Vincent Vanhoucke",
                        "slug": "Vincent-Vanhoucke",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Vanhoucke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Vanhoucke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122113652"
                        ],
                        "name": "Alexander A. Alemi",
                        "slug": "Alexander-A.-Alemi",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Alemi",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander A. Alemi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 56
                            }
                        ],
                        "text": "However, more recent architectures, such as ResNet [4], Inception [5], NasNet [6], introduce divergent processing paths where the same tensor can be processed by several layers, i.e. their computation graph is no longer linear and has branches."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 66
                            }
                        ],
                        "text": "However, more recent architectures, such as ResNet [4], Inception [5], NasNet [6], introduce divergent processing paths where the same tensor can be processed by several layers, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1023605,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5c26ab8767d046cb6e32d959fdf726aee89bb62",
            "isKey": false,
            "numCitedBy": 8225,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "\n \n Very deep convolutional networks have been central to the largest advances in image recognition performance in recent years. One example is the Inception architecture that has been shown to achieve very good performance at relatively low computational cost. Recently, the introduction of residual connections in conjunction with a more traditional architecture has yielded state-of-the-art performance in the 2015 ILSVRC challenge; its performance was similar to the latest generation Inception-v3 network. This raises the question: Are there any benefits to combining Inception architectures with residual connections? Here we give clear empirical evidence that training with residual connections accelerates the training of Inception networks significantly. There is also some evidence of residual Inception networks outperforming similarly expensive Inception networks without residual connections by a thin margin. We also present several new streamlined architectures for both residual and non-residual Inception networks. These variations improve the single-frame recognition performance on the ILSVRC 2012 classification task significantly. We further demonstrate how proper activation scaling stabilizes the training of very wide residual Inception networks. With an ensemble of three residual and one Inception-v4 networks, we achieve 3.08% top-5 error on the test set of the ImageNet classification (CLS) challenge.\n \n"
            },
            "slug": "Inception-v4,-Inception-ResNet-and-the-Impact-of-on-Szegedy-Ioffe",
            "title": {
                "fragments": [],
                "text": "Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Clear empirical evidence that training with residual connections accelerates the training of Inception networks significantly is given and several new streamlined architectures for both residual and non-residual Inception Networks are presented."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144882893"
                        ],
                        "name": "M. Sandler",
                        "slug": "M.-Sandler",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Sandler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sandler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144727050"
                        ],
                        "name": "Andrew G. Howard",
                        "slug": "Andrew-G.-Howard",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Howard",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew G. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2717876"
                        ],
                        "name": "Menglong Zhu",
                        "slug": "Menglong-Zhu",
                        "structuredName": {
                            "firstName": "Menglong",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Menglong Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3422677"
                        ],
                        "name": "A. Zhmoginov",
                        "slug": "A.-Zhmoginov",
                        "structuredName": {
                            "firstName": "Andrey",
                            "lastName": "Zhmoginov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zhmoginov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34192119"
                        ],
                        "name": "Liang-Chieh Chen",
                        "slug": "Liang-Chieh-Chen",
                        "structuredName": {
                            "firstName": "Liang-Chieh",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liang-Chieh Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 303,
                                "start": 294
                            }
                        ],
                        "text": "Including the framework overhead (\u2248200KB for SwiftNet Cell, proportional to the number of tensors), this made a sufficient difference to make the model\u2019s memory footprint fit within SRAM.3 We also check the overhead introduced by replacing a static memory allocator with a dynamic one by running MobileNet-v1-based [37] person detection model (from the Tensorflow Lite Micro repository [33])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "For example, authors of MobileNet [18] note that a building block of their model has a channel-wise operation, whose output is accumulated into another tensor, which allows processing the input tensor in parts."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "Popular mobile-friendly CNN architectures include MobileNet [18] and ShuffleNet [19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4555207,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4",
            "isKey": false,
            "numCitedBy": 7406,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a new mobile architecture, MobileNetV2, that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes. We also describe efficient ways of applying these mobile models to object detection in a novel framework we call SSDLite. Additionally, we demonstrate how to build mobile semantic segmentation models through a reduced form of DeepLabv3 which we call Mobile DeepLabv3. is based on an inverted residual structure where the shortcut connections are between the thin bottleneck layers. The intermediate expansion layer uses lightweight depthwise convolutions to filter features as a source of non-linearity. Additionally, we find that it is important to remove non-linearities in the narrow layers in order to maintain representational power. We demonstrate that this improves performance and provide an intuition that led to this design. Finally, our approach allows decoupling of the input/output domains from the expressiveness of the transformation, which provides a convenient framework for further analysis. We measure our performance on ImageNet [1] classification, COCO object detection [2], VOC image segmentation [3]. We evaluate the trade-offs between accuracy, and number of operations measured by multiply-adds (MAdd), as well as actual latency, and the number of parameters."
            },
            "slug": "MobileNetV2:-Inverted-Residuals-and-Linear-Sandler-Howard",
            "title": {
                "fragments": [],
                "text": "MobileNetV2: Inverted Residuals and Linear Bottlenecks"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A new mobile architecture, MobileNetV2, is described that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes and allows decoupling of the input/output domains from the expressiveness of the transformation."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 154
                            }
                        ],
                        "text": "One can obtain a smaller neural network by using layer decomposition [9, 10], pruning [11, 12], quantisation [13] and binarisation [14, 15], distillation [16] or exploiting sparsity [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7200347,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c908739fbff75f03469d13d4a1a07de3414ee19",
            "isKey": false,
            "numCitedBy": 8901,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel."
            },
            "slug": "Distilling-the-Knowledge-in-a-Neural-Network-Hinton-Vinyals",
            "title": {
                "fragments": [],
                "text": "Distilling the Knowledge in a Neural Network"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work shows that it can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model and introduces a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771551"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3080683"
                        ],
                        "name": "Shaoqing Ren",
                        "slug": "Shaoqing-Ren",
                        "structuredName": {
                            "firstName": "Shaoqing",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoqing Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 44
                            }
                        ],
                        "text": "However, more recent architectures, such as ResNet [4], Inception [5], NasNet [6], introduce divergent processing paths where the same tensor can be processed by several layers, i.e. their computation graph is no longer linear and has branches."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 51
                            }
                        ],
                        "text": "However, more recent architectures, such as ResNet [4], Inception [5], NasNet [6], introduce divergent processing paths where the same tensor can be processed by several layers, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206594692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "isKey": false,
            "numCitedBy": 97653,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation."
            },
            "slug": "Deep-Residual-Learning-for-Image-Recognition-He-Zhang",
            "title": {
                "fragments": [],
                "text": "Deep Residual Learning for Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work presents a residual learning framework to ease the training of networks that are substantially deeper than those used previously, and provides comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34838386"
                        ],
                        "name": "K. Simonyan",
                        "slug": "K.-Simonyan",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Simonyan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Simonyan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 99
                            }
                        ],
                        "text": "Classic neural network architectures, such as the original multilayer perceptron, AlexNet [2], VGG [3], consist of a linear sequence of layers, which are iteratively applied to transform the input."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14124313,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb42cf88027de515750f230b23b1a057dc782108",
            "isKey": false,
            "numCitedBy": 63195,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision."
            },
            "slug": "Very-Deep-Convolutional-Networks-for-Large-Scale-Simonyan-Zisserman",
            "title": {
                "fragments": [],
                "text": "Very Deep Convolutional Networks for Large-Scale Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This work investigates the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting using an architecture with very small convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073063"
                        ],
                        "name": "Lucas Theis",
                        "slug": "Lucas-Theis",
                        "structuredName": {
                            "firstName": "Lucas",
                            "lastName": "Theis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lucas Theis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46400982"
                        ],
                        "name": "I. Korshunova",
                        "slug": "I.-Korshunova",
                        "structuredName": {
                            "firstName": "Iryna",
                            "lastName": "Korshunova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Korshunova"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41203992"
                        ],
                        "name": "Alykhan Tejani",
                        "slug": "Alykhan-Tejani",
                        "structuredName": {
                            "firstName": "Alykhan",
                            "lastName": "Tejani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alykhan Tejani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108066"
                        ],
                        "name": "Ferenc Husz\u00e1r",
                        "slug": "Ferenc-Husz\u00e1r",
                        "structuredName": {
                            "firstName": "Ferenc",
                            "lastName": "Husz\u00e1r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ferenc Husz\u00e1r"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 86
                            }
                        ],
                        "text": "One can obtain a smaller neural network by using layer decomposition [9, 10], pruning [11, 12], quantisation [13] and binarisation [14, 15], distillation [16] or exploiting sparsity [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 32429255,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d4d3008262697d379d0cb1642e39a8e0c756ab2c",
            "isKey": false,
            "numCitedBy": 132,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Predicting human fixations from images has recently seen large improvements by leveraging deep representations which were pretrained for object recognition. However, as we show in this paper, these networks are highly overparameterized for the task of fixation prediction. We first present a simple yet principled greedy pruning method which we call Fisher pruning. Through a combination of knowledge distillation and Fisher pruning, we obtain much more runtime-efficient architectures for saliency prediction, achieving a 10x speedup for the same AUC performance as a state of the art network on the CAT2000 dataset. Speeding up single-image gaze prediction is important for many real-world applications, but it is also a crucial step in the development of video saliency models, where the amount of data to be processed is substantially larger."
            },
            "slug": "Faster-gaze-prediction-with-dense-networks-and-Theis-Korshunova",
            "title": {
                "fragments": [],
                "text": "Faster gaze prediction with dense networks and Fisher pruning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Through a combination of knowledge distillation and Fisher pruning, this paper obtains much more runtime-efficient architectures for saliency prediction, achieving a 10x speedup for the same AUC performance as a state of the art network on the CAT2000 dataset."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144764327"
                        ],
                        "name": "M. Horowitz",
                        "slug": "M.-Horowitz",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Horowitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Horowitz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 155
                            }
                        ],
                        "text": "an SD-card, typically has a high capacity but is slow [7] and power-costly to access (\u2248100x more energy required to read a value outside of on-chip memory [8])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 22028726,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "947620a1854655ed91a86b90d12695e05be85983",
            "isKey": false,
            "numCitedBy": 716,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Our challenge is clear: The drive for performance and the end of voltage scaling have made power, and not the number of transistors, the principal factor limiting further improvements in computing performance. Continuing to scale compute performance will require the creation and effective use of new specialized compute engines, and will require the participation of application experts to be successful. If we play our cards right, and develop the tools that allow our customers to become part of the design process, we will create a new wave of innovative and efficient computing devices."
            },
            "slug": "1.1-Computing's-energy-problem-(and-what-we-can-do-Horowitz",
            "title": {
                "fragments": [],
                "text": "1.1 Computing's energy problem (and what we can do about it)"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "If the drive for performance and the end of voltage scaling have made power, and not the number of transistors, the principal factor limiting further improvements in computing performance, a new wave of innovative and efficient computing devices will be created."
            },
            "venue": {
                "fragments": [],
                "text": "2014 IEEE International Solid-State Circuits Conference Digest of Technical Papers (ISSCC)"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2522169"
                        ],
                        "name": "Milad Alizadeh",
                        "slug": "Milad-Alizadeh",
                        "structuredName": {
                            "firstName": "Milad",
                            "lastName": "Alizadeh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Milad Alizadeh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401656657"
                        ],
                        "name": "J. Fern\u00e1ndez-Marqu\u00e9s",
                        "slug": "J.-Fern\u00e1ndez-Marqu\u00e9s",
                        "structuredName": {
                            "firstName": "Javier",
                            "lastName": "Fern\u00e1ndez-Marqu\u00e9s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fern\u00e1ndez-Marqu\u00e9s"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144948031"
                        ],
                        "name": "N. Lane",
                        "slug": "N.-Lane",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Lane",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Lane"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681954"
                        ],
                        "name": "Y. Gal",
                        "slug": "Y.-Gal",
                        "structuredName": {
                            "firstName": "Yarin",
                            "lastName": "Gal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Gal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 131
                            }
                        ],
                        "text": "One can obtain a smaller neural network by using layer decomposition [9, 10], pruning [11, 12], quantisation [13] and binarisation [14, 15], distillation [16] or exploiting sparsity [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 108364915,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "a2980c4ab69e017e72ca36db0ac3a0a427ff1aee",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-Empirical-study-of-Binary-Neural-Networks'-Alizadeh-Fern\u00e1ndez-Marqu\u00e9s",
            "title": {
                "fragments": [],
                "text": "An Empirical study of Binary Neural Networks' Optimisation"
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717349"
                        ],
                        "name": "D. Knuth",
                        "slug": "D.-Knuth",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Knuth",
                            "middleNames": [
                                "Ervin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Knuth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696569"
                        ],
                        "name": "J. Szwarcfiter",
                        "slug": "J.-Szwarcfiter",
                        "structuredName": {
                            "firstName": "Jayme",
                            "lastName": "Szwarcfiter",
                            "middleNames": [
                                "Luiz"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Szwarcfiter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 249,
                                "start": 245
                            }
                        ],
                        "text": "A computation graph is a directed acyclic graph (DAG) and any topological order of its nodes would produce a valid execution schedule; in general, enumerating all topological orders of a DAG is an explored problem in graph algorithms literature [32]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 38411309,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "1ee5f0c2a6af1b2aa250a97e87b32f5322476827",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Structured-Program-to-Generate-all-Topological-Knuth-Szwarcfiter",
            "title": {
                "fragments": [],
                "text": "A Structured Program to Generate all Topological Sorting Arrangements"
            },
            "venue": {
                "fragments": [],
                "text": "Inf. Process. Lett."
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50579876"
                        ],
                        "name": "Yu-hsin Chen",
                        "slug": "Yu-hsin-Chen",
                        "structuredName": {
                            "firstName": "Yu-hsin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu-hsin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145984583"
                        ],
                        "name": "T. Krishna",
                        "slug": "T.-Krishna",
                        "structuredName": {
                            "firstName": "Tushar",
                            "lastName": "Krishna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Krishna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775477"
                        ],
                        "name": "J. Emer",
                        "slug": "J.-Emer",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Emer",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Emer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691305"
                        ],
                        "name": "V. Sze",
                        "slug": "V.-Sze",
                        "structuredName": {
                            "firstName": "Vivienne",
                            "lastName": "Sze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Sze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Concerns about the memory usage of neural networks and data movement during execution are also discussed in neural network accelerator chip design literature [29\u201331]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207882941,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "835e99de573ae34766fcf879617f5c9ea13d397e",
            "isKey": false,
            "numCitedBy": 1227,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Eyeriss is an accelerator for state-of-the-art deep convolutional neural networks (CNNs). It optimizes for the energy efficiency of the entire system, including the accelerator chip and off-chip DRAM, for various CNN shapes by reconfiguring the architecture. CNNs are widely used in modern AI systems but also bring challenges on throughput and energy efficiency to the underlying hardware. This is because its computation requires a large amount of data, creating significant data movement from on-chip and off-chip that is more energy-consuming than computation. Minimizing data movement energy cost for any CNN shape, therefore, is the key to high throughput and energy efficiency. Eyeriss achieves these goals by using a proposed processing dataflow, called row stationary (RS), on a spatial architecture with 168 processing elements. RS dataflow reconfigures the computation mapping of a given shape, which optimizes energy efficiency by maximally reusing data locally to reduce expensive data movement, such as DRAM accesses. Compression and data gating are also applied to further improve energy efficiency. Eyeriss processes the convolutional layers at 35 frames/s and 0.0029 DRAM access/multiply and accumulation (MAC) for AlexNet at 278 mW (batch size  $N = 4$ ), and 0.7 frames/s and 0.0035 DRAM access/MAC for VGG-16 at 236 mW ( $N = 3$ )."
            },
            "slug": "Eyeriss:-An-Energy-Efficient-Reconfigurable-for-Chen-Krishna",
            "title": {
                "fragments": [],
                "text": "Eyeriss: An Energy-Efficient Reconfigurable Accelerator for Deep Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "Eyeriss is an accelerator for state-of-the-art deep convolutional neural networks (CNNs) that optimizes for the energy efficiency of the entire system, including the accelerator chip and off-chip DRAM, for various CNN shapes by reconfiguring the architecture."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Journal of Solid-State Circuits"
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "TensorFlow Lite Micro"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "TensorFlow Contributors , \u201c TensorFlow Lite Micro"
            },
            "venue": {
                "fragments": [],
                "text": "Information Processing Letters"
            },
            "year": 1974
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bus Speed (Default Speed/High Speed/UHS/SD Express)"
            },
            "venue": {
                "fragments": [],
                "text": "SD Association"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 44
                            }
                        ],
                        "text": "Including the framework overhead (\u2248200KB for SwiftNet Cell, proportional to the number of tensors), this made a sufficient difference to make the model\u2019s memory footprint fit within SRAM.3 We also check the overhead introduced by replacing a static memory allocator with a dynamic one by running MobileNet-v1-based [37] person detection model (from the Tensorflow Lite Micro repository [33])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 102
                            }
                        ],
                        "text": "We use one of the winning submissions of the Visual Wake Words competition [25], called SwiftNet Cell [34, 35], as it has only 250KB of parameters and contains many branches, which enables us to showcase the benefits of reordering."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "QTravelers Visual Wake Words contest submission."
            },
            "venue": {
                "fragments": [],
                "text": "https: //github.com/newwhitecheng/vwwc19-submission (Accessed Sep 2019),"
            },
            "year": 2019
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "NUCLEO-F767ZI development board"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "STM32 High Performance MCUs"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 11,
            "methodology": 21
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 38,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Neural-networks-on-microcontrollers:-saving-memory-Liberis-Lane/1f1cfca32bba330c4dd8a8e3ec5d728d686d0c92?sort=total-citations"
}