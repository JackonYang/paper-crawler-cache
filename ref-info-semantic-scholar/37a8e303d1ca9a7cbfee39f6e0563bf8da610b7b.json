{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149970173"
                        ],
                        "name": "Lianmin Zheng",
                        "slug": "Lianmin-Zheng",
                        "structuredName": {
                            "firstName": "Lianmin",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lianmin Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51195858"
                        ],
                        "name": "Chengfan Jia",
                        "slug": "Chengfan-Jia",
                        "structuredName": {
                            "firstName": "Chengfan",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chengfan Jia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118254471"
                        ],
                        "name": "Minmin Sun",
                        "slug": "Minmin-Sun",
                        "structuredName": {
                            "firstName": "Minmin",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minmin Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146045513"
                        ],
                        "name": "Zhao Wu",
                        "slug": "Zhao-Wu",
                        "structuredName": {
                            "firstName": "Zhao",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhao Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "17813719"
                        ],
                        "name": "Cody Hao Yu",
                        "slug": "Cody-Hao-Yu",
                        "structuredName": {
                            "firstName": "Cody",
                            "lastName": "Yu",
                            "middleNames": [
                                "Hao"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cody Hao Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1411406011"
                        ],
                        "name": "Ameer Haj-Ali",
                        "slug": "Ameer-Haj-Ali",
                        "structuredName": {
                            "firstName": "Ameer",
                            "lastName": "Haj-Ali",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ameer Haj-Ali"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Yida Wang",
                        "slug": "Yida-Wang",
                        "structuredName": {
                            "firstName": "Yida",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yida Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146156715"
                        ],
                        "name": "Jun Yang",
                        "slug": "Jun-Yang",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2720913"
                        ],
                        "name": "Danyang Zhuo",
                        "slug": "Danyang-Zhuo",
                        "structuredName": {
                            "firstName": "Danyang",
                            "lastName": "Zhuo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Danyang Zhuo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145741786"
                        ],
                        "name": "Koushik Sen",
                        "slug": "Koushik-Sen",
                        "structuredName": {
                            "firstName": "Koushik",
                            "lastName": "Sen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Koushik Sen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49988044"
                        ],
                        "name": "Joseph E. Gonzalez",
                        "slug": "Joseph-E.-Gonzalez",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Gonzalez",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph E. Gonzalez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144467753"
                        ],
                        "name": "I. Stoica",
                        "slug": "I.-Stoica",
                        "structuredName": {
                            "firstName": "Ion",
                            "lastName": "Stoica",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Stoica"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 219
                            }
                        ],
                        "text": "A sketch K\u03b1 is a high-level tensor program structure derived by applying a sequence of transformations to the na\u00efve tensor program of \u03b1 (K\u03b1 contains information like loop tile structures, how to fuse loops, cache nodes [27]), and there is a set of possible sketches for \u03b1 , denoted byK\u03b1 ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 148
                            }
                        ],
                        "text": "To show the existence of feature relationships, we collect the tensor programsmeasured on an NVIDIAGPU (P100) by an existing deep learning compiler [27] during the process of optimizing a set of conv2d operators from a DNN, SSD ResNet50."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "For example, to optimize an operator, Ansor [27], a searchbased compilation method, needs about 1,000 measurement trials to converge in general, which consumes thousands of seconds."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 128
                            }
                        ],
                        "text": "fetching (using all threads in a block to cache the input data the block needs in shared memory [4]), memory load vectorization [27]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 152
                            }
                        ],
                        "text": "Each operator is associated with an optimized tensor program, which is the best tensor program found by an optimization method, like autoTVM [5], Ansor [27],"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": "The size of K\u03b1 is rather small, which can be enumerated [27], e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": ", tile sizes, loop auto unrolling pragmas) [27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "For example, the multi-level tiling method used in [27] tiles the loop nests in an \u201cSSSRRSRS\u201d structure, where \u201cS\u201d means a tile level of space loops and \u201cR\u201d means a tile level of reduction loops."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 61
                            }
                        ],
                        "text": "Instead, we use the search space defined in an existing work [27], which has comprehensive coverage of optimizations on tensor programs and enables flexible optimization combinations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "Experiments are conducted on both popular DNN operators and DNN operator sets, where Ansor [27] and ST [19] are baselines."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 219636278,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6ebbdc79a3553e8ad2996d6d03987bfaeb448e82",
            "isKey": true,
            "numCitedBy": 94,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "High-performance tensor programs are crucial to guarantee efficient execution of deep learning models. However, obtaining performant tensor programs for different operators on various hardware platforms is notoriously difficult. Currently, deep learning systems rely on vendor-provided kernel libraries or various search strategies to get performant tensor programs. These approaches either require significant engineering efforts in developing platform-specific optimization code or fall short in finding high-performance programs due to restricted search space and ineffective exploration strategy. \nWe present Ansor, a tensor program generation framework for deep learning applications. Compared with existing search strategies, Ansor explores much more optimization combinations by sampling programs from a hierarchical representation of the search space. Ansor then fine-tunes the sampled programs with evolutionary search and a learned cost model to identify the best programs. Ansor can find high-performance programs that are outside the search space of existing state-of-the-art approaches. Besides, Ansor utilizes a scheduler to simultaneously optimize multiple subgraphs in a set of deep neural networks. Our evaluation shows that Ansor improves the execution performance of deep neural networks on the Intel CPU, ARM CPU, and NVIDIA GPU by up to $3.8\\times$, $2.6\\times$, and $1.7 \\times$, respectively."
            },
            "slug": "Ansor-:-Generating-High-Performance-Tensor-Programs-Zheng-Jia",
            "title": {
                "fragments": [],
                "text": "Ansor : Generating High-Performance Tensor Programs for Deep Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "Ansor is presented, a tensor program generation framework for deep learning applications that can find high-performance programs that are outside the search space of existing state-of-the-art approaches."
            },
            "venue": {
                "fragments": [],
                "text": "OSDI"
            },
            "year": 2020
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1913774"
                        ],
                        "name": "Tianqi Chen",
                        "slug": "Tianqi-Chen",
                        "structuredName": {
                            "firstName": "Tianqi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianqi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149970173"
                        ],
                        "name": "Lianmin Zheng",
                        "slug": "Lianmin-Zheng",
                        "structuredName": {
                            "firstName": "Lianmin",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lianmin Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2621619"
                        ],
                        "name": "Eddie Q. Yan",
                        "slug": "Eddie-Q.-Yan",
                        "structuredName": {
                            "firstName": "Eddie",
                            "lastName": "Yan",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eddie Q. Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732910"
                        ],
                        "name": "Ziheng Jiang",
                        "slug": "Ziheng-Jiang",
                        "structuredName": {
                            "firstName": "Ziheng",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ziheng Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47108160"
                        ],
                        "name": "T. Moreau",
                        "slug": "T.-Moreau",
                        "structuredName": {
                            "firstName": "Thierry",
                            "lastName": "Moreau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Moreau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717411"
                        ],
                        "name": "L. Ceze",
                        "slug": "L.-Ceze",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Ceze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ceze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730156"
                        ],
                        "name": "Carlos Guestrin",
                        "slug": "Carlos-Guestrin",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Guestrin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlos Guestrin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144695691"
                        ],
                        "name": "A. Krishnamurthy",
                        "slug": "A.-Krishnamurthy",
                        "structuredName": {
                            "firstName": "Arvind",
                            "lastName": "Krishnamurthy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krishnamurthy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 135
                            }
                        ],
                        "text": "For the backend compiler to tune an operator, the search cost can be set to the maximum number of measurement trials of it (many works [5, 27] require us to limit the number of measurement trials"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 98
                            }
                        ],
                        "text": "Please note that given other categories of search spaces, like the template-based search space in [5], the reuse-based optimization idea (Section 5) can also be applied."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 63
                            }
                        ],
                        "text": "As for better costmodels, transfer learning is used by autoTVM [5] to make use of the historical data collected during optimizing pre-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 141
                            }
                        ],
                        "text": "Each operator is associated with an optimized tensor program, which is the best tensor program found by an optimization method, like autoTVM [5], Ansor [27],"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 29160233,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb91c2f8d3cac0b655a39be318b603334eb18987",
            "isKey": true,
            "numCitedBy": 181,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a learning-based framework to optimize tensor programs for deep learning workloads. Efficient implementations of tensor operators, such as matrix multiplication and high dimensional convolution, are key enablers of effective deep learning systems. However, existing systems rely on manually optimized libraries such as cuDNN where only a narrow range of server class GPUs are well-supported. The reliance on hardware-specific operator libraries limits the applicability of high-level graph optimizations and incurs significant engineering costs when deploying to new hardware targets. We use learning to remove this engineering burden. We learn domain-specific statistical cost models to guide the search of tensor operator implementations over billions of possible program variants. We further accelerate the search by effective model transfer across workloads. Experimental results show that our framework delivers performance competitive with state-of-the-art hand-tuned libraries for low-power CPU, mobile GPU, and server-class GPU."
            },
            "slug": "Learning-to-Optimize-Tensor-Programs-Chen-Zheng",
            "title": {
                "fragments": [],
                "text": "Learning to Optimize Tensor Programs"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A learning-based framework to optimize tensor programs for deep learning workloads that learns domain-specific statistical cost models to guide the search of tensor operator implementations over billions of possible program variants and accelerates the search by effective model transfer across workloads."
            },
            "venue": {
                "fragments": [],
                "text": "NeurIPS"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112111675"
                        ],
                        "name": "Minjia Zhang",
                        "slug": "Minjia-Zhang",
                        "structuredName": {
                            "firstName": "Minjia",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minjia Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2024722802"
                        ],
                        "name": "Menghao Li",
                        "slug": "Menghao-Li",
                        "structuredName": {
                            "firstName": "Menghao",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Menghao Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116627318"
                        ],
                        "name": "Chi Wang",
                        "slug": "Chi-Wang",
                        "structuredName": {
                            "firstName": "Chi",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chi Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47629126"
                        ],
                        "name": "Mingqin Li",
                        "slug": "Mingqin-Li",
                        "structuredName": {
                            "firstName": "Mingqin",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mingqin Li"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 88
                            }
                        ],
                        "text": "To save the overall search time of a set of optimization tasks, Ansor [27] and DynaTune [26] dynamically allocate time slots to tasks,"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 79
                            }
                        ],
                        "text": "To save the overall search time of a set of optimization tasks, Ansor [27] and DynaTune [26] dynamically allocate time slots to tasks, instead of sequentially optimizing them."
                    },
                    "intents": []
                }
            ],
            "corpusId": 235614271,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b8a4e778549f89da6352ae18208654f32621d0db",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, the DL compiler, together with Learning to Compile has proven to be a powerful technique for optimizing deep learning models. However, existing methods focus on accelerating the convergence speed of the individual tensor operator rather than the convergence speed of the entire model, which results in long optimization time to obtain a desired latency. In this paper, we present a new method called DynaTune, which provides significantly faster convergence speed to optimize a DNN model. In particular, we consider a Multi-Armed Bandit (MAB) model for the tensor program optimization problem. We use UCB to handle the decision-making of time-slot-based optimization, and we devise a Bayesian belief model that allows predicting the potential performance gain of each operator with uncertainty quantification, which guides the optimization process. We evaluate and compare DynaTune with the state-of-the-art DL compiler. The experiment results show that DynaTune is 1.2\u20132.4 times faster to achieve the same optimization quality for a range of models across different hardware architectures."
            },
            "slug": "DynaTune:-Dynamic-Tensor-Program-Optimization-in-Zhang-Li",
            "title": {
                "fragments": [],
                "text": "DynaTune: Dynamic Tensor Program Optimization in Deep Neural Network Compilation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new method called DynaTune is presented, which provides significantly faster convergence speed to optimize a DNN model, and a Bayesian belief model is devised that allows predicting the potential performance gain of each operator with uncertainty quantification, which guides the optimization process."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2021
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800919"
                        ],
                        "name": "Nicolas Vasilache",
                        "slug": "Nicolas-Vasilache",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Vasilache",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Vasilache"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054833547"
                        ],
                        "name": "O. Zinenko",
                        "slug": "O.-Zinenko",
                        "structuredName": {
                            "firstName": "Oleksandr",
                            "lastName": "Zinenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Zinenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2097631216"
                        ],
                        "name": "Theodoros Theodoridis",
                        "slug": "Theodoros-Theodoridis",
                        "structuredName": {
                            "firstName": "Theodoros",
                            "lastName": "Theodoridis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Theodoros Theodoridis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47316088"
                        ],
                        "name": "Priya Goyal",
                        "slug": "Priya-Goyal",
                        "structuredName": {
                            "firstName": "Priya",
                            "lastName": "Goyal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Priya Goyal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2375710"
                        ],
                        "name": "Zach DeVito",
                        "slug": "Zach-DeVito",
                        "structuredName": {
                            "firstName": "Zach",
                            "lastName": "DeVito",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zach DeVito"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16521420"
                        ],
                        "name": "William S. Moses",
                        "slug": "William-S.-Moses",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Moses",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "William S. Moses"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772079"
                        ],
                        "name": "Sven Verdoolaege",
                        "slug": "Sven-Verdoolaege",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Verdoolaege",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sven Verdoolaege"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144187067"
                        ],
                        "name": "Andrew Adams",
                        "slug": "Andrew-Adams",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Adams",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Adams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145509576"
                        ],
                        "name": "Albert Cohen",
                        "slug": "Albert-Cohen",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Albert Cohen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 27
                            }
                        ],
                        "text": "Tensor Comprehensions (TC) [22] leverages polyhedral compilation and auto-tuning (on specified parameters) to optimize operators."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 3
                            }
                        ],
                        "text": "TC [20, 22] uses a compilation cache to reuse the tensor programs in a way similar to ST: it can directly apply the transformation steps in an optimized tensor program of another similar operator, or alternatively it can use that set of trans-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 253,
                                "start": 245
                            }
                        ],
                        "text": "We can also consider combining our search method with existing methods to improve the optimization effectiveness and efficiency, like using the tensor programs in our pruned search space as the starting points of the genetic search algorithm in [22, 27]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 44014988,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cae9d90524cccac5081666985d5d055b71697cee",
            "isKey": true,
            "numCitedBy": 284,
            "numCiting": 102,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep learning models with convolutional and recurrent networks are now ubiquitous and analyze massive amounts of audio, image, video, text and graph data, with applications in automatic translation, speech-to-text, scene understanding, ranking user preferences, ad placement, etc. Competing frameworks for building these networks such as TensorFlow, Chainer, CNTK, Torch/PyTorch, Caffe1/2, MXNet and Theano, explore different tradeoffs between usability and expressiveness, research or production orientation and supported hardware. They operate on a DAG of computational operators, wrapping high-performance libraries such as CUDNN (for NVIDIA GPUs) or NNPACK (for various CPUs), and automate memory allocation, synchronization, distribution. Custom operators are needed where the computation does not fit existing high-performance library calls, usually at a high engineering cost. This is frequently required when new operators are invented by researchers: such operators suffer a severe performance penalty, which limits the pace of innovation. Furthermore, even if there is an existing runtime call these frameworks can use, it often doesn't offer optimal performance for a user's particular network architecture and dataset, missing optimizations between operators as well as optimizations that can be done knowing the size and shape of data. Our contributions include (1) a language close to the mathematics of deep learning called Tensor Comprehensions offering both imperative and declarative styles, (2) a polyhedral Just-In-Time compiler to convert a mathematical description of a deep learning DAG into a CUDA kernel with delegated memory management and synchronization, also providing optimizations such as operator fusion and specialization for specific sizes, (3) a compilation cache populated by an autotuner. [Abstract cutoff]"
            },
            "slug": "Tensor-Comprehensions:-Framework-Agnostic-Machine-Vasilache-Zinenko",
            "title": {
                "fragments": [],
                "text": "Tensor Comprehensions: Framework-Agnostic High-Performance Machine Learning Abstractions"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A language close to the mathematics of deep learning called Tensor Comprehensions offering both imperative and declarative styles, a polyhedral Just-In-Time compiler to convert a mathematical description of a deep learning DAG into a CUDA kernel with delegated memory management and synchronization, and a compilation cache populated by an autotuner are contributed."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1561195919"
                        ],
                        "name": "Size Zheng",
                        "slug": "Size-Zheng",
                        "structuredName": {
                            "firstName": "Size",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Size Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144884036"
                        ],
                        "name": "Yun Liang",
                        "slug": "Yun-Liang",
                        "structuredName": {
                            "firstName": "Yun",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yun Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146294770"
                        ],
                        "name": "Shuo Wang",
                        "slug": "Shuo-Wang",
                        "structuredName": {
                            "firstName": "Shuo",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuo Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1562383765"
                        ],
                        "name": "Renze Chen",
                        "slug": "Renze-Chen",
                        "structuredName": {
                            "firstName": "Renze",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Renze Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1561622231"
                        ],
                        "name": "Kaiwen Sheng",
                        "slug": "Kaiwen-Sheng",
                        "structuredName": {
                            "firstName": "Kaiwen",
                            "lastName": "Sheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiwen Sheng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 19
                            }
                        ],
                        "text": "The range for B is [28, 112], and hence B can be {28, 32, 49, 56, 64, 98, 112}."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 108
                            }
                        ],
                        "text": "For example, \u03b1, \u03b2 are 2 conv2d operators with I(L\u03b1 ) of shape [1, 64, 14, 14, 64, 3, 3] and I(L\u03b2 ) of shape [1, 64, 28, 28, 64, 1, 1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 60
                            }
                        ],
                        "text": "Figure 2: A conv2d example (in NCHW layout; inputX of shape [1, 512, 28, 28]; kernel of shape [128, 512, 1, 1]; stride and dilation are 1; padding"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "FlexTensor [28] automatically generates a search space of an operator by enumerating the transformation steps in a specific order."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 310,
                                "start": 294
                            }
                        ],
                        "text": "Using this multi-level tiling method on the conv2d in Figure 2, denoted by\u03b1 , if we tileL\u03b1 = {nn, ff, yy, xx, rc, ry, rx} (listed from the outermost loop to the innermost loop) in the way that, nn, ff, yy, xx all have 5 tile levels which are [1, 1, 1, 1, 1], [4, 1, 8, 2, 2], [14, 1, 1, 1, 2], [1, 1, 28, 1, 1] respectively, and rc, ry, rx all have 3 tile levels which are [4, 64, 2], [1, 1, 1], [1, 1, 1] respectively, then after reordering the loop tiles according to the \u201cSSSRRSRS\u201d structure, fusing loop tiles on the same level and doing thread binding, we can get the major part of the tensor program in Figure 2b."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 174
                            }
                        ],
                        "text": ", a conv2d operator \u03b31 with K\u03b1 = K\u03b31 and I(L\u03b31 ) of shape [1, 64, 14, 14, 64, 1, 1], or a conv2d operator \u03b32 with K\u03b1 = K\u03b32 and I(L\u03b32 ) of shape [1, 64, 12, 12, 64, 1, 1] (or [1, 64, 28, 28, 64, 3, 3])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 39
                            }
                        ],
                        "text": "The BShape, TShape, LShape of S\u2217 \u03b2 are [1, 32, 2, 28], ( [1, 1, 1, 1], [1, 4, 2, 1]), [4, 1, 1], respec-"
                    },
                    "intents": []
                }
            ],
            "corpusId": 212687780,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d84e056bc71e98424912a43f04471600f12804aa",
            "isKey": true,
            "numCitedBy": 54,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "Tensor computation plays a paramount role in a broad range of domains, including machine learning, data analytics, and scientific computing. The wide adoption of tensor computation and its huge computation cost has led to high demand for flexible, portable, and high-performance library implementation on heterogeneous hardware accelerators such as GPUs and FPGAs. However, the current tensor library implementation mainly requires programmers to manually design low-level implementation and optimize from the algorithm, architecture, and compilation perspectives. Such a manual development process often takes months or even years, which falls far behind the rapid evolution of the application algorithms. In this paper, we introduce FlexTensor, which is a schedule exploration and optimization framework for tensor computation on heterogeneous systems. FlexTensor can optimize tensor computation programs without human interference, allowing programmers to only work on high-level programming abstraction without considering the hardware platform details. FlexTensor systematically explores the optimization design spaces that are composed of many different schedules for different hardware. Then, FlexTensor combines different exploration techniques, including heuristic method and machine learning method to find the optimized schedule configuration. Finally, based on the results of exploration, customized schedules are automatically generated for different hardware. In the experiments, we test 12 different kinds of tensor computations with totally hundreds of test cases and FlexTensor achieves average 1.83x performance speedup on NVIDIA V100 GPU compared to cuDNN; 1.72x performance speedup on Intel Xeon CPU compared to MKL-DNN for 2D convolution; 1.5x performance speedup on Xilinx VU9P FPGA compared to OpenCL baselines; 2.21x speedup on NVIDIA V100 GPU compared to the state-of-the-art."
            },
            "slug": "FlexTensor:-An-Automatic-Schedule-Exploration-and-Zheng-Liang",
            "title": {
                "fragments": [],
                "text": "FlexTensor: An Automatic Schedule Exploration and Optimization Framework for Tensor Computation on Heterogeneous System"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "FlexTensor can optimize tensor computation programs without human interference, allowing programmers to only work on high-level programming abstraction without considering the hardware platform details."
            },
            "venue": {
                "fragments": [],
                "text": "ASPLOS"
            },
            "year": 2020
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056775119"
                        ],
                        "name": "Byung Hoon Ahn",
                        "slug": "Byung-Hoon-Ahn",
                        "structuredName": {
                            "firstName": "Byung",
                            "lastName": "Ahn",
                            "middleNames": [
                                "Hoon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Byung Hoon Ahn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51930667"
                        ],
                        "name": "Prannoy Pilligundla",
                        "slug": "Prannoy-Pilligundla",
                        "structuredName": {
                            "firstName": "Prannoy",
                            "lastName": "Pilligundla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Prannoy Pilligundla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112229"
                        ],
                        "name": "A. Yazdanbakhsh",
                        "slug": "A.-Yazdanbakhsh",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Yazdanbakhsh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yazdanbakhsh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696563"
                        ],
                        "name": "H. Esmaeilzadeh",
                        "slug": "H.-Esmaeilzadeh",
                        "structuredName": {
                            "firstName": "Hadi",
                            "lastName": "Esmaeilzadeh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Esmaeilzadeh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 15
                            }
                        ],
                        "text": "Then the first [1, 2, 1, 1] indicates the second dimension of the BShape is divided into two parts by virtual split [4, 27], and the second [1, 1, 4, 4] is the shape of the output tensor"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 87
                            }
                        ],
                        "text": "The remaining loop length is hence 2, and the final tile sizes related to this loop is [2, 2, 2, 1, 2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 274,
                                "start": 259
                            }
                        ],
                        "text": "Using this multi-level tiling method on the conv2d in Figure 2, denoted by\u03b1 , if we tileL\u03b1 = {nn, ff, yy, xx, rc, ry, rx} (listed from the outermost loop to the innermost loop) in the way that, nn, ff, yy, xx all have 5 tile levels which are [1, 1, 1, 1, 1], [4, 1, 8, 2, 2], [14, 1, 1, 1, 2], [1, 1, 28, 1, 1] respectively, and rc, ry, rx all have 3 tile levels which are [4, 64, 2], [1, 1, 1], [1, 1, 1] respectively, then after reordering the loop tiles according to the \u201cSSSRRSRS\u201d structure, fusing loop tiles on the same level and doing thread binding, we can get the major part of the tensor program in Figure 2b."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 79
                            }
                        ],
                        "text": "For example, the LShape for a conv2d operator with 3 reduction loops cannot be [4, 2, 1] in our method."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 54
                            }
                        ],
                        "text": "Given the above BShape, suppose the TShape of S\u03b1 is ( [1, 2, 1, 1], [1, 1, 4, 4])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 209483589,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e4c965324f9773ec3111686a4abe53ea61c89f7c",
            "isKey": true,
            "numCitedBy": 35,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "Achieving faster execution with shorter compilation time can foster further diversity and innovation in neural networks. However, the current paradigm of executing neural networks either relies on hand-optimized libraries, traditional compilation heuristics, or very recently genetic algorithms and other stochastic methods. These methods suffer from frequent costly hardware measurements rendering them not only too time consuming but also suboptimal. As such, we devise a solution that can learn to quickly adapt to a previously unseen design space for code optimization, both accelerating the search and improving the output performance. This solution dubbed CHAMELEON leverages reinforcement learning whose solution takes fewer steps to converge, and develops an adaptive sampling algorithm that not only focuses on the costly samples (real hardware measurements) on representative points but also uses a domain knowledge inspired logic to improve the samples itself. Experimentation with real hardware shows that CHAMELEON provides 4.45\u00d7speed up in optimization time over AutoTVM, while also improving inference time of the modern deep networks by 5.6%."
            },
            "slug": "Chameleon:-Adaptive-Code-Optimization-for-Expedited-Ahn-Pilligundla",
            "title": {
                "fragments": [],
                "text": "Chameleon: Adaptive Code Optimization for Expedited Deep Neural Network Compilation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work leverages reinforcement learning whose solution takes fewer steps to converge, and develops an adaptive sampling algorithm that not only focuses on the costly samples on representative points but also uses a domain knowledge inspired logic to improve the samples itself."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2020
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3050154"
                        ],
                        "name": "Haichen Shen",
                        "slug": "Haichen-Shen",
                        "structuredName": {
                            "firstName": "Haichen",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haichen Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "24961975"
                        ],
                        "name": "Jared Roesch",
                        "slug": "Jared-Roesch",
                        "structuredName": {
                            "firstName": "Jared",
                            "lastName": "Roesch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jared Roesch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2119232594"
                        ],
                        "name": "Zhi Chen",
                        "slug": "Zhi-Chen",
                        "structuredName": {
                            "firstName": "Zhi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2283009"
                        ],
                        "name": "Wei Chen",
                        "slug": "Wei-Chen",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115859471"
                        ],
                        "name": "Yong Wu",
                        "slug": "Yong-Wu",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yong Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112144126"
                        ],
                        "name": "Mu Li",
                        "slug": "Mu-Li",
                        "structuredName": {
                            "firstName": "Mu",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mu Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153403129"
                        ],
                        "name": "Vin Sharma",
                        "slug": "Vin-Sharma",
                        "structuredName": {
                            "firstName": "Vin",
                            "lastName": "Sharma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vin Sharma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2272813"
                        ],
                        "name": "Zachary Tatlock",
                        "slug": "Zachary-Tatlock",
                        "structuredName": {
                            "firstName": "Zachary",
                            "lastName": "Tatlock",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zachary Tatlock"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Yida Wang",
                        "slug": "Yida-Wang",
                        "structuredName": {
                            "firstName": "Yida",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yida Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 167
                            }
                        ],
                        "text": "Since the sequence length in input can be any value (no greater than 512), the number of possible input data shapes for an operator in BERT can be exponentially large [17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 219305367,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "81981169f8e15166b249b99270d1f7a9e75f9ae4",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Modern deep neural networks increasingly make use of features such as dynamic control flow, data structures and dynamic tensor shapes. Existing deep learning systems focus on optimizing and executing static neural networks which assume a pre-determined model architecture and input data shapes--assumptions which are violated by dynamic neural networks. Therefore, executing dynamic models with deep learning systems is currently both inflexible and sub-optimal, if not impossible. Optimizing dynamic neural networks is more challenging than static neural networks; optimizations must consider all possible execution paths and tensor shapes. This paper proposes Nimble, a high-performance and flexible system to optimize, compile, and execute dynamic neural networks on multiple platforms. Nimble handles model dynamism by introducing a dynamic type system, a set of dynamism-oriented optimizations, and a light-weight virtual machine runtime. Our evaluation demonstrates that Nimble outperforms state-of-the-art deep learning frameworks and runtime systems for dynamic neural networks by up to 20x on hardware platforms including Intel CPUs, ARM CPUs, and Nvidia GPUs."
            },
            "slug": "Nimble:-Efficiently-Compiling-Dynamic-Neural-for-Shen-Roesch",
            "title": {
                "fragments": [],
                "text": "Nimble: Efficiently Compiling Dynamic Neural Networks for Model Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Nimble is proposed, a high-performance and flexible system to optimize, compile, and execute dynamic neural networks on multiple platforms that handles model dynamism by introducing a dynamic type system, a set of dynamism-oriented optimizations, and a light-weight virtual machine runtime."
            },
            "venue": {
                "fragments": [],
                "text": "MLSys"
            },
            "year": 2021
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1913774"
                        ],
                        "name": "Tianqi Chen",
                        "slug": "Tianqi-Chen",
                        "structuredName": {
                            "firstName": "Tianqi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianqi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47108160"
                        ],
                        "name": "T. Moreau",
                        "slug": "T.-Moreau",
                        "structuredName": {
                            "firstName": "Thierry",
                            "lastName": "Moreau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Moreau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732910"
                        ],
                        "name": "Ziheng Jiang",
                        "slug": "Ziheng-Jiang",
                        "structuredName": {
                            "firstName": "Ziheng",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ziheng Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149970173"
                        ],
                        "name": "Lianmin Zheng",
                        "slug": "Lianmin-Zheng",
                        "structuredName": {
                            "firstName": "Lianmin",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lianmin Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2621619"
                        ],
                        "name": "Eddie Q. Yan",
                        "slug": "Eddie-Q.-Yan",
                        "structuredName": {
                            "firstName": "Eddie",
                            "lastName": "Yan",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eddie Q. Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3050154"
                        ],
                        "name": "Haichen Shen",
                        "slug": "Haichen-Shen",
                        "structuredName": {
                            "firstName": "Haichen",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haichen Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37270394"
                        ],
                        "name": "M. Cowan",
                        "slug": "M.-Cowan",
                        "structuredName": {
                            "firstName": "Meghan",
                            "lastName": "Cowan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Cowan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2185540"
                        ],
                        "name": "Leyuan Wang",
                        "slug": "Leyuan-Wang",
                        "structuredName": {
                            "firstName": "Leyuan",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Leyuan Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49994783"
                        ],
                        "name": "Yuwei Hu",
                        "slug": "Yuwei-Hu",
                        "structuredName": {
                            "firstName": "Yuwei",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuwei Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717411"
                        ],
                        "name": "L. Ceze",
                        "slug": "L.-Ceze",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Ceze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ceze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730156"
                        ],
                        "name": "Carlos Guestrin",
                        "slug": "Carlos-Guestrin",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Guestrin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlos Guestrin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144695691"
                        ],
                        "name": "A. Krishnamurthy",
                        "slug": "A.-Krishnamurthy",
                        "structuredName": {
                            "firstName": "Arvind",
                            "lastName": "Krishnamurthy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krishnamurthy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 116
                            }
                        ],
                        "text": "Then the first [1, 2, 1, 1] indicates the second dimension of the BShape is divided into two parts by virtual split [4, 27], and the second [1, 1, 4, 4] is the shape of the output tensor"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 161
                            }
                        ],
                        "text": "The iteration variables of the first three space loop tile levels are bound respectively to BlockIdx, virtual threads (for reducing shared memory bank conflicts [4]), and ThreadIdx in GPU."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 58
                            }
                        ],
                        "text": "Suppose a conv2d operator \u03b1 has an output tensor of shape [1, 4, 16, 16] (the shape dimensions correspond to batch size, kernel number, height, width)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 96
                            }
                        ],
                        "text": "fetching (using all threads in a block to cache the input data the block needs in shared memory [4]), memory load vectorization [27]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 274,
                                "start": 259
                            }
                        ],
                        "text": "Using this multi-level tiling method on the conv2d in Figure 2, denoted by\u03b1 , if we tileL\u03b1 = {nn, ff, yy, xx, rc, ry, rx} (listed from the outermost loop to the innermost loop) in the way that, nn, ff, yy, xx all have 5 tile levels which are [1, 1, 1, 1, 1], [4, 1, 8, 2, 2], [14, 1, 1, 1, 2], [1, 1, 28, 1, 1] respectively, and rc, ry, rx all have 3 tile levels which are [4, 64, 2], [1, 1, 1], [1, 1, 1] respectively, then after reordering the loop tiles according to the \u201cSSSRRSRS\u201d structure, fusing loop tiles on the same level and doing thread binding, we can get the major part of the tensor program in Figure 2b."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 68
                            }
                        ],
                        "text": "Given the above BShape, suppose the TShape of S\u03b1 is ( [1, 2, 1, 1], [1, 1, 4, 4])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 31
                            }
                        ],
                        "text": "Then if the BShape of an S\u03b1 is [1, 4, 8, 8], it means in S\u03b1 a thread block needs to compute half of the height and the width of each output channel in each batch, and there are 4"
                    },
                    "intents": []
                }
            ],
            "corpusId": 52939079,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df013a17ab84d5403361da4538a04d574f58be83",
            "isKey": true,
            "numCitedBy": 713,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "There is an increasing need to bring machine learning to a wide diversity of hardware devices. Current frameworks rely on vendor-specific operator libraries and optimize for a narrow range of server-class GPUs. Deploying workloads to new platforms -- such as mobile phones, embedded devices, and accelerators (e.g., FPGAs, ASICs) -- requires significant manual effort. We propose TVM, a compiler that exposes graph-level and operator-level optimizations to provide performance portability to deep learning workloads across diverse hardware back-ends. TVM solves optimization challenges specific to deep learning, such as high-level operator fusion, mapping to arbitrary hardware primitives, and memory latency hiding. It also automates optimization of low-level programs to hardware characteristics by employing a novel, learning-based cost modeling method for rapid exploration of code optimizations. Experimental results show that TVM delivers performance across hardware back-ends that are competitive with state-of-the-art, hand-tuned libraries for low-power CPU, mobile GPU, and server-class GPUs. We also demonstrate TVM's ability to target new accelerator back-ends, such as the FPGA-based generic deep learning accelerator. The system is open sourced and in production use inside several major companies."
            },
            "slug": "TVM:-An-Automated-End-to-End-Optimizing-Compiler-Chen-Moreau",
            "title": {
                "fragments": [],
                "text": "TVM: An Automated End-to-End Optimizing Compiler for Deep Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "TVM is a compiler that exposes graph-level and operator-level optimizations to provide performance portability to deep learning workloads across diverse hardware back-ends and automates optimization of low-level programs to hardware characteristics by employing a novel, learning-based cost modeling method for rapid exploration of code optimizations."
            },
            "venue": {
                "fragments": [],
                "text": "OSDI"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39172707"
                        ],
                        "name": "Jacob Devlin",
                        "slug": "Jacob-Devlin",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Devlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jacob Devlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744179"
                        ],
                        "name": "Ming-Wei Chang",
                        "slug": "Ming-Wei-Chang",
                        "structuredName": {
                            "firstName": "Ming-Wei",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Wei Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2544107"
                        ],
                        "name": "Kenton Lee",
                        "slug": "Kenton-Lee",
                        "structuredName": {
                            "firstName": "Kenton",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenton Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3259253"
                        ],
                        "name": "Kristina Toutanova",
                        "slug": "Kristina-Toutanova",
                        "structuredName": {
                            "firstName": "Kristina",
                            "lastName": "Toutanova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristina Toutanova"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 93
                            }
                        ],
                        "text": "By comparing the results on ResNet50(L) with those on ResNet50, and comparing the results on BERT(L) with those on BERT-Base, we can see that the more operators with the same type and the same sketch set to be optimized, the higher the speedup ETO can bring, and there can be no or just small drop of the overall normalized performance (due to the operator frequency)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 94
                            }
                        ],
                        "text": "For multiple DNNs, we prepare 2 DNN sets: ResNet50 with batch size being 1, 16 (ResNet50(L)); BERT-Base and BERT-Large with batch size 1, 16, and sequence length being 64, 128 (BERT(L))."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 69
                            }
                        ],
                        "text": "For example, for the 5 different batch matmul operators in BERT-Base [7], there are only 4 possible reuse pairs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 24
                            }
                        ],
                        "text": "Another example is BERT [7] for input with dynamic shapes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 79
                            }
                        ],
                        "text": "The respective best TShapes are ( [1, 1, 1, 1], [1, 4, 2, 2]), ( [1, 1, 1, 1], [1, 2, 1, 7]), ( [1, 1, 1, 1], [1, 4, 2, 1])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "Although on DCGAN and BERT(L), ST performs slightly better than ETO with 1.004\u00d7 and 1.018\u00d7 throughput respectively, ETO outperforms ST in most cases, with up to 1.8\u00d7 throughput, because ST\u2019s similarity model is not effective enough (Section 1) and the reuse-based tuner has optimization effectiveness superiority over ST\u2019s TopK reuse method."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "On DCGAN and BERT-Base, the throughput by ETO is higher than that by Ansor, so the corresponding results of \u201cAnsor same\u201d is not shown in Figure 10."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 195
                            }
                        ],
                        "text": "variant of Inception-ResNet-V2 (1D-IR) [9] for tasks like 1D data classification, R2Plus1D-ResNet18 [21] (R(2+1D)) for action recognition, DCGAN [15] generator for image generation, and BERTBase [7] (sequence length is 128) for language understanding."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 146
                            }
                        ],
                        "text": "For the absolute difference of the weighted latency sum between ETO and Ansor, in most cases, it is less than 0.5 ms; on R(2+1)D it is 1.9 ms; on BERT(L) it is 32.9 ms."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 299,
                                "start": 295
                            }
                        ],
                        "text": "For single DNNs, we prepare: ResNet50 [10], MobileNetV2 [16] and ResNeSt50 [25] for image classification, 1D variant of Inception-ResNet-V2 (1D-IR) [9] for tasks like 1D data classification, R2Plus1D-ResNet18 [21] (R(2+1D)) for action recognition, DCGAN [15] generator for image generation, and BERTBase [7] (sequence length is 128) for language understanding."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 135
                            }
                        ],
                        "text": "Since the sequence length in input can be any value (no greater than 512), the number of possible input data shapes for an operator in BERT can be exponentially large [17]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "The reason for the big 32.9ms difference on BERT(L) is that the frequency of an operator will magnify the performance loss in the final weighted latency sum."
                    },
                    "intents": []
                }
            ],
            "corpusId": 52967399,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "isKey": true,
            "numCitedBy": 35053,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement)."
            },
            "slug": "BERT:-Pre-training-of-Deep-Bidirectional-for-Devlin-Chang",
            "title": {
                "fragments": [],
                "text": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A new language representation model, BERT, designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers, which can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3003738"
                        ],
                        "name": "Sharan Chetlur",
                        "slug": "Sharan-Chetlur",
                        "structuredName": {
                            "firstName": "Sharan",
                            "lastName": "Chetlur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sharan Chetlur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2266717"
                        ],
                        "name": "Cliff Woolley",
                        "slug": "Cliff-Woolley",
                        "structuredName": {
                            "firstName": "Cliff",
                            "lastName": "Woolley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cliff Woolley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2101730"
                        ],
                        "name": "Philippe Vandermersch",
                        "slug": "Philippe-Vandermersch",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Vandermersch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philippe Vandermersch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145611200"
                        ],
                        "name": "Jonathan M. Cohen",
                        "slug": "Jonathan-M.-Cohen",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Cohen",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan M. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066786849"
                        ],
                        "name": "J. Tran",
                        "slug": "J.-Tran",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Tran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2301680"
                        ],
                        "name": "Bryan Catanzaro",
                        "slug": "Bryan-Catanzaro",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "Catanzaro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bryan Catanzaro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782282"
                        ],
                        "name": "Evan Shelhamer",
                        "slug": "Evan-Shelhamer",
                        "structuredName": {
                            "firstName": "Evan",
                            "lastName": "Shelhamer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Evan Shelhamer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 8
                            }
                        ],
                        "text": ", cuDNN [6]) provided by the AI-hardware vendors, or search-based compilation [1, 3\u20135, 27, 28] which automatically optimizes an operator (or a set of operators connected with each other)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12330432,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31c36d445367ba204244bb74893c5654e31c3869",
            "isKey": false,
            "numCitedBy": 1419,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a library that provides optimized implementations for deep learning primitives. Deep learning workloads are computationally intensive, and optimizing the kernels of deep learning workloads is difficult and time-consuming. As parallel architectures evolve, kernels must be reoptimized for new processors, which makes maintaining codebases difficult over time. Similar issues have long been addressed in the HPC community by libraries such as the Basic Linear Algebra Subroutines (BLAS) [2]. However, there is no analogous library for deep learning. Without such a library, researchers implementing deep learning workloads on parallel processors must create and optimize their own implementations of the main computational kernels, and this work must be repeated as new parallel processors emerge. To address this problem, we have created a library similar in intent to BLAS, with optimized routines for deep learning workloads. Our implementation contains routines for GPUs, and similarly to the BLAS library, could be implemented for other platforms. The library is easy to integrate into existing frameworks, and provides optimized performance and memory usage. For example, integrating cuDNN into Caffe, a popular framework for convolutional networks, improves performance by 36% on a standard model while also reducing memory consumption."
            },
            "slug": "cuDNN:-Efficient-Primitives-for-Deep-Learning-Chetlur-Woolley",
            "title": {
                "fragments": [],
                "text": "cuDNN: Efficient Primitives for Deep Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A library similar in intent to BLAS, with optimized routines for deep learning workloads, that contains routines for GPUs, and similarly to the BLAS library, could be implemented for other platforms."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144187067"
                        ],
                        "name": "Andrew Adams",
                        "slug": "Andrew-Adams",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Adams",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Adams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "151076950"
                        ],
                        "name": "Karima Ma",
                        "slug": "Karima-Ma",
                        "structuredName": {
                            "firstName": "Karima",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karima Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144413718"
                        ],
                        "name": "Luke Anderson",
                        "slug": "Luke-Anderson",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Anderson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Anderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758245"
                        ],
                        "name": "Riyadh Baghdadi",
                        "slug": "Riyadh-Baghdadi",
                        "structuredName": {
                            "firstName": "Riyadh",
                            "lastName": "Baghdadi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Riyadh Baghdadi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775024"
                        ],
                        "name": "Tzu-Mao Li",
                        "slug": "Tzu-Mao-Li",
                        "structuredName": {
                            "firstName": "Tzu-Mao",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tzu-Mao Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3282136"
                        ],
                        "name": "Micha\u00ebl Gharbi",
                        "slug": "Micha\u00ebl-Gharbi",
                        "structuredName": {
                            "firstName": "Micha\u00ebl",
                            "lastName": "Gharbi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Micha\u00ebl Gharbi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32163737"
                        ],
                        "name": "Benoit Steiner",
                        "slug": "Benoit-Steiner",
                        "structuredName": {
                            "firstName": "Benoit",
                            "lastName": "Steiner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benoit Steiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111936975"
                        ],
                        "name": "Steven Johnson",
                        "slug": "Steven-Johnson",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2789576"
                        ],
                        "name": "Kayvon Fatahalian",
                        "slug": "Kayvon-Fatahalian",
                        "structuredName": {
                            "firstName": "Kayvon",
                            "lastName": "Fatahalian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kayvon Fatahalian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145403226"
                        ],
                        "name": "F. Durand",
                        "slug": "F.-Durand",
                        "structuredName": {
                            "firstName": "Fr\u00e9do",
                            "lastName": "Durand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Durand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401885963"
                        ],
                        "name": "Jonathan Ragan-Kelley",
                        "slug": "Jonathan-Ragan-Kelley",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Ragan-Kelley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Ragan-Kelley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 60
                            }
                        ],
                        "text": "Figure 2: A conv2d example (in NCHW layout; inputX of shape [1, 512, 28, 28]; kernel of shape [128, 512, 1, 1]; stride and dilation are 1; padding"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 242
                            }
                        ],
                        "text": "Using this multi-level tiling method on the conv2d in Figure 2, denoted by\u03b1 , if we tileL\u03b1 = {nn, ff, yy, xx, rc, ry, rx} (listed from the outermost loop to the innermost loop) in the way that, nn, ff, yy, xx all have 5 tile levels which are [1, 1, 1, 1, 1], [4, 1, 8, 2, 2], [14, 1, 1, 1, 2], [1, 1, 28, 1, 1] respectively, and rc, ry, rx all have 3 tile levels which are [4, 64, 2], [1, 1, 1], [1, 1, 1] respectively, then after reordering the loop tiles according to the \u201cSSSRRSRS\u201d structure, fusing loop tiles on the same level and doing thread binding, we can get the major part of the tensor program in Figure 2b."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 84
                            }
                        ],
                        "text": "For example, the r ls in the second loop nest of Figure 2a form a 3D space of shape [512, 1, 1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 196834556,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f90a7bc396e205b204d5d6066a10162f84b128f9",
            "isKey": false,
            "numCitedBy": 122,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new algorithm to automatically schedule Halide programs for high-performance image processing and deep learning. We significantly improve upon the performance of previous methods, which considered a limited subset of schedules. We define a parameterization of possible schedules much larger than prior methods and use a variant of beam search to search over it. The search optimizes runtime predicted by a cost model based on a combination of new derived features and machine learning. We train the cost model by generating and featurizing hundreds of thousands of random programs and schedules. We show that this approach operates effectively with or without autotuning. It produces schedules which are on average almost twice as fast as the existing Halide autoscheduler without autotuning, or more than twice as fast with, and is the first automatic scheduling algorithm to significantly outperform human experts on average."
            },
            "slug": "Learning-to-optimize-halide-with-tree-search-and-Adams-Ma",
            "title": {
                "fragments": [],
                "text": "Learning to optimize halide with tree search and random programs"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This work presents a new algorithm to automatically schedule Halide programs for high-performance image processing and deep learning that produces schedules which are on average almost twice as fast as the existing Halide autoscheduler without autotuning, or more than two as fast with, and is the first automatic scheduling algorithm to significantly outperform human experts on average."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Graph."
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144413718"
                        ],
                        "name": "Luke Anderson",
                        "slug": "Luke-Anderson",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Anderson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Anderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144187067"
                        ],
                        "name": "Andrew Adams",
                        "slug": "Andrew-Adams",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Adams",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Adams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "151076950"
                        ],
                        "name": "Karima Ma",
                        "slug": "Karima-Ma",
                        "structuredName": {
                            "firstName": "Karima",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karima Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775024"
                        ],
                        "name": "Tzu-Mao Li",
                        "slug": "Tzu-Mao-Li",
                        "structuredName": {
                            "firstName": "Tzu-Mao",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tzu-Mao Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401885963"
                        ],
                        "name": "Jonathan Ragan-Kelley",
                        "slug": "Jonathan-Ragan-Kelley",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Ragan-Kelley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Ragan-Kelley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 7
                            }
                        ],
                        "text": "Halide [1, 3] supports the one-shot mode of searching, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 62
                            }
                        ],
                        "text": "For example, \u03b1, \u03b2 are 2 conv2d operators with I(L\u03b1 ) of shape [1, 64, 14, 14, 64, 3, 3] and I(L\u03b2 ) of shape [1, 64, 28, 28, 64, 1, 1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 14
                            }
                        ],
                        "text": "A recent work [3] improves [1] by partitioning the search space of options into buckets according to the structural"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 174
                            }
                        ],
                        "text": ", a conv2d operator \u03b31 with K\u03b1 = K\u03b31 and I(L\u03b31 ) of shape [1, 64, 14, 14, 64, 1, 1], or a conv2d operator \u03b32 with K\u03b1 = K\u03b32 and I(L\u03b32 ) of shape [1, 64, 12, 12, 64, 1, 1] (or [1, 64, 28, 28, 64, 3, 3])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 62
                            }
                        ],
                        "text": "Halide uses importance sampling [1] and hierarchical sampling [3] to select candidates tensor programs for measurement."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 229156162,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74b1b2a18019535be8077c9cfba9582174c43977",
            "isKey": true,
            "numCitedBy": 4,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new algorithm to automatically generate high-performance GPU implementations of complex imaging and machine learning pipelines, directly from high-level Halide algorithm code. It is fully automatic, requiring no schedule templates or hand-optimized kernels, and it targets a diverse range of computations which is significantly broader than existing autoschedulers. We address the scalability challenge of extending previous approaches to schedule large real world programs, while enabling a broad set of program rewrites that take into account the nested parallelism and memory hierarchy introduced by GPU architectures. We achieve this using a hierarchical sampling strategy that groups programs into buckets based on their structural similarity, then samples representatives to be evaluated, allowing us to explore a large space by only considering a subset of the space, and a pre-pass that 'freezes' decisions for the lowest cost sections of a program, allowing more time to be spent on the important stages. We then apply an efficient cost model combining machine learning, program analysis, and GPU architecture knowledge. Our method scales combinatorially better with respect to the deeper nested parallelism required by GPUs compared to previous work. We evaluate its performance on a diverse suite of real-world imaging and machine learning pipelines. We demonstrate results that are on average 1.66X faster than existing automatic solutions (up to 5X), and competitive with what the best human experts were able to achieve in an active effort to beat our automatic results."
            },
            "slug": "Learning-to-Schedule-Halide-Pipelines-for-the-GPU-Anderson-Adams",
            "title": {
                "fragments": [],
                "text": "Learning to Schedule Halide Pipelines for the GPU"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "A new algorithm to automatically generate high-performance GPU implementations of complex imaging and machine learning pipelines, directly from high-level Halide algorithm code is presented, fully automatic, requiring no schedule templates or hand-optimized kernels, and it targets a diverse range of computations which is significantly broader than existing autoschedulers."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2020
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144882893"
                        ],
                        "name": "M. Sandler",
                        "slug": "M.-Sandler",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Sandler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sandler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144727050"
                        ],
                        "name": "Andrew G. Howard",
                        "slug": "Andrew-G.-Howard",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Howard",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew G. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2717876"
                        ],
                        "name": "Menglong Zhu",
                        "slug": "Menglong-Zhu",
                        "structuredName": {
                            "firstName": "Menglong",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Menglong Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3422677"
                        ],
                        "name": "A. Zhmoginov",
                        "slug": "A.-Zhmoginov",
                        "structuredName": {
                            "firstName": "Andrey",
                            "lastName": "Zhmoginov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zhmoginov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34192119"
                        ],
                        "name": "Liang-Chieh Chen",
                        "slug": "Liang-Chieh-Chen",
                        "structuredName": {
                            "firstName": "Liang-Chieh",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liang-Chieh Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 0
                            }
                        ],
                        "text": "MobileNetV2 has 81 1-hop bridge operators and 121 bridge operators in total."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 32
                            }
                        ],
                        "text": "We run three variants of ETO on MobileNetV2 and ResNet50: \u201c0 Bridge Operator\u201d means we do not generate bridge operators in the reuse pair selector; \u201c1 Hop Bridge Operators\u201d means we only generate 1-hop bridge operators (this is the method we adopt); \u201cAll Bridge Operators\u201d means we generate all the bridge operators."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": "For single DNNs, we prepare: ResNet50 [10], MobileNetV2 [16] and ResNeSt50 [25] for image classification, 1D"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 58
                            }
                        ],
                        "text": "Suppose a conv2d operator \u03b1 has an output tensor of shape [1, 4, 16, 16] (the shape dimensions correspond to batch size, kernel number, height, width)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 3
                            }
                        ],
                        "text": "On MobileNetV2, the normalized throughput difference is less than 2%, and the absolute difference of the weighted latency sum is less than 0.01 ms."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 44
                            }
                        ],
                        "text": "For single DNNs, we prepare: ResNet50 [10], MobileNetV2 [16] and ResNeSt50 [25] for image classification, 1D variant of Inception-ResNet-V2 (1D-IR) [9] for tasks like 1D data classification, R2Plus1D-ResNet18 [21] (R(2+1D)) for action recognition, DCGAN [15] generator for image generation, and BERTBase [7] (sequence length is 128) for language understanding."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 115
                            }
                        ],
                        "text": "Compared with \u201c1 Hop Bridge Operators\u201d, the search time of \u201cAll Bridge Operators\u201d is shorter on ResNet50 but longer on MobileNetV2 because we cannot estimate the cost of each reuse pair perfectly."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 151
                            }
                        ],
                        "text": "This result shows that 1-hop bridge operators already generate sufficient reuse pairs which are likely to be chosen to save the overall search time on MobileNetV2 and ResNet50."
                    },
                    "intents": []
                }
            ],
            "corpusId": 4555207,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4",
            "isKey": true,
            "numCitedBy": 7407,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a new mobile architecture, MobileNetV2, that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes. We also describe efficient ways of applying these mobile models to object detection in a novel framework we call SSDLite. Additionally, we demonstrate how to build mobile semantic segmentation models through a reduced form of DeepLabv3 which we call Mobile DeepLabv3. is based on an inverted residual structure where the shortcut connections are between the thin bottleneck layers. The intermediate expansion layer uses lightweight depthwise convolutions to filter features as a source of non-linearity. Additionally, we find that it is important to remove non-linearities in the narrow layers in order to maintain representational power. We demonstrate that this improves performance and provide an intuition that led to this design. Finally, our approach allows decoupling of the input/output domains from the expressiveness of the transformation, which provides a convenient framework for further analysis. We measure our performance on ImageNet [1] classification, COCO object detection [2], VOC image segmentation [3]. We evaluate the trade-offs between accuracy, and number of operations measured by multiply-adds (MAdd), as well as actual latency, and the number of parameters."
            },
            "slug": "MobileNetV2:-Inverted-Residuals-and-Linear-Sandler-Howard",
            "title": {
                "fragments": [],
                "text": "MobileNetV2: Inverted Residuals and Linear Bottlenecks"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A new mobile architecture, MobileNetV2, is described that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes and allows decoupling of the input/output domains from the expressiveness of the transformation."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771551"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3080683"
                        ],
                        "name": "Shaoqing Ren",
                        "slug": "Shaoqing-Ren",
                        "structuredName": {
                            "firstName": "Shaoqing",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoqing Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 28
                            }
                        ],
                        "text": "By comparing the results on ResNet50(L) with those on ResNet50, and comparing the results on BERT(L) with those on BERT-Base, we can see that the more operators with the same type and the same sketch set to be optimized, the higher the speedup ETO can bring, and there can be no or just small drop of the overall normalized performance (due to the operator frequency)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 42
                            }
                        ],
                        "text": "For multiple DNNs, we prepare 2 DNN sets: ResNet50 with batch size being 1, 16 (ResNet50(L)); BERT-Base and BERT-Large with batch size 1, 16, and sequence length being 64, 128 (BERT(L))."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 48
                            }
                        ],
                        "text": "We run three variants of ETO on MobileNetV2 and ResNet50: \u201c0 Bridge Operator\u201d means we do not generate bridge operators in the reuse pair selector; \u201c1 Hop Bridge Operators\u201d means we only generate 1-hop bridge operators (this is the method we adopt); \u201cAll Bridge Operators\u201d means we generate all the bridge operators."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 236,
                                "start": 228
                            }
                        ],
                        "text": "To show the existence of feature relationships, we collect the tensor programsmeasured on an NVIDIAGPU (P100) by an existing deep learning compiler [27] during the process of optimizing a set of conv2d operators from a DNN, SSD ResNet50."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 38
                            }
                        ],
                        "text": "For single DNNs, we prepare: ResNet50 [10], MobileNetV2 [16] and ResNeSt50 [25] for image classification, 1D"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "ResNet50 has 44 1-hop bridge operators and 49 bridge operators in total."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 29
                            }
                        ],
                        "text": "For single DNNs, we prepare: ResNet50 [10], MobileNetV2 [16] and ResNeSt50 [25] for image classification, 1D variant of Inception-ResNet-V2 (1D-IR) [9] for tasks like 1D data classification, R2Plus1D-ResNet18 [21] (R(2+1D)) for action recognition, DCGAN [15] generator for image generation, and BERTBase [7] (sequence length is 128) for language understanding."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 92
                            }
                        ],
                        "text": "Compared with \u201c1 Hop Bridge Operators\u201d, the search time of \u201cAll Bridge Operators\u201d is shorter on ResNet50 but longer on MobileNetV2 because we cannot estimate the cost of each reuse pair perfectly."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 74
                            }
                        ],
                        "text": "The absolute difference of the weighted latency sum among the variants on ResNet50 is also small, i.e., 0.2 ms."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 3
                            }
                        ],
                        "text": "On ResNet50, the normalized throughput difference between \u201c1 Hop Bridge Operators\u201d and \u201cAll Bridge Operators\u201d is only 0.6%, and \u201c0 Bridge Operator\u201d performs about 7% better than the other two variants, because \u201c0 Bridge Operator\u201d uses the backend compiler to optimize 8 operators out of the 20 conv2d in ResNet50 and gets better tensor programs for some operators."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 47
                            }
                        ],
                        "text": ", ST puts the 20 conv2d operators in ResNet-50 [10] in 7 groups in our experiments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 202
                            }
                        ],
                        "text": "More importantly, transformation steps cannot be shared between two operators that are not similar enough, and this may limit the optimization efficiency of ST, e.g., ST puts the 20 conv2d operators in ResNet-50 [10] in 7 groups in our experiments."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 167
                            }
                        ],
                        "text": "This result shows that 1-hop bridge operators already generate sufficient reuse pairs which are likely to be chosen to save the overall search time on MobileNetV2 and ResNet50."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 363,
                                "start": 355
                            }
                        ],
                        "text": "For each type \ud835\udf0f , we collect operators from popular deep learning models or from the experiments of Ansor [27], and set their batch sizes to be 1 and 16 to get a set A\ud835\udf0f : the CAP and FRB operators are from [27], and operators of the other types are randomly sampled, respectively, from an operator set in Table 2 (the WIN operators are from the operators in ResNet50 which can be computed using the Winograd algorithm) and its 1-hop bridge operators."
                    },
                    "intents": []
                }
            ],
            "corpusId": 206594692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "isKey": true,
            "numCitedBy": 97664,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation."
            },
            "slug": "Deep-Residual-Learning-for-Image-Recognition-He-Zhang",
            "title": {
                "fragments": [],
                "text": "Deep Residual Learning for Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work presents a residual learning framework to ease the training of networks that are substantially deeper than those used previously, and provides comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38909097"
                        ],
                        "name": "Alec Radford",
                        "slug": "Alec-Radford",
                        "structuredName": {
                            "firstName": "Alec",
                            "lastName": "Radford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alec Radford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2096458"
                        ],
                        "name": "Luke Metz",
                        "slug": "Luke-Metz",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Metz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luke Metz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2127604"
                        ],
                        "name": "Soumith Chintala",
                        "slug": "Soumith-Chintala",
                        "structuredName": {
                            "firstName": "Soumith",
                            "lastName": "Chintala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Soumith Chintala"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 116
                            }
                        ],
                        "text": "In fact,\nAnsor can only find tensor programs with 59.7% normalized performance using the same search time as ETO on T2D, which means ETO is faster than Ansor in searching performant tensor programs for T2D."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 254,
                                "start": 250
                            }
                        ],
                        "text": "We evaluate ETO on 10 types of deep learning operators, which are: 1D, 2D, and 3D convolution (C1D, C2D, C3D respectively), batch matrix multiplication (BMM), group convolution (GRP), depthwise convolution (DEP) [12], transposed 2D convolution (T2D) [15], capsule 2D convolution (CAP) [11], Winograd 2D convolution (WIN) [13], and frobenius norm (FRB)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 12
                            }
                        ],
                        "text": "Although on DCGAN and BERT(L), ST performs slightly better than ETO with 1.004\u00d7 and 1.018\u00d7 throughput respectively, ETO outperforms ST in most cases, with up to 1.8\u00d7 throughput, because ST\u2019s similarity model is not effective enough (Section 1) and the reuse-based tuner has optimization effectiveness superiority over ST\u2019s TopK reuse method."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "On DCGAN and BERT-Base, the throughput by ETO is higher than that by Ansor, so the corresponding results of \u201cAnsor same\u201d is not shown in Figure 10."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 145
                            }
                        ],
                        "text": "variant of Inception-ResNet-V2 (1D-IR) [9] for tasks like 1D data classification, R2Plus1D-ResNet18 [21] (R(2+1D)) for action recognition, DCGAN [15] generator for image generation, and BERTBase [7] (sequence length is 128) for language understanding."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 253,
                                "start": 248
                            }
                        ],
                        "text": "For single DNNs, we prepare: ResNet50 [10], MobileNetV2 [16] and ResNeSt50 [25] for image classification, 1D variant of Inception-ResNet-V2 (1D-IR) [9] for tasks like 1D data classification, R2Plus1D-ResNet18 [21] (R(2+1D)) for action recognition, DCGAN [15] generator for image generation, and BERTBase [7] (sequence length is 128) for language understanding."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "On T2D, ETO achieves 94.7% performance compared with Ansor, but is 4.8\u00d7 faster than \u201cAnsor best\u201d."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11758569,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8388f1be26329fa45e5807e968a641ce170ea078",
            "isKey": true,
            "numCitedBy": 9983,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations."
            },
            "slug": "Unsupervised-Representation-Learning-with-Deep-Radford-Metz",
            "title": {
                "fragments": [],
                "text": "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work introduces a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrates that they are a strong candidate for unsupervised learning."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73175007"
                        ],
                        "name": "Andrew Lavin",
                        "slug": "Andrew-Lavin",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Lavin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Lavin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145565184"
                        ],
                        "name": "Scott Gray",
                        "slug": "Scott-Gray",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Gray",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott Gray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 38
                            }
                        ],
                        "text": "The composite sketch of the collected WIN operators has four sub-sketches: two unroll-constant-tensor sub-sketches, a multi-level tile sub-sketch and a two-level tile sub-sketch."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 325,
                                "start": 321
                            }
                        ],
                        "text": "We evaluate ETO on 10 types of deep learning operators, which are: 1D, 2D, and 3D convolution (C1D, C2D, C3D respectively), batch matrix multiplication (BMM), group convolution (GRP), depthwise convolution (DEP) [12], transposed 2D convolution (T2D) [15], capsule 2D convolution (CAP) [11], Winograd 2D convolution (WIN) [13], and frobenius norm (FRB)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 8
                            }
                        ],
                        "text": "For the WIN operator involving a composite sketch, since the loop nest with the multi-level tile sub-sketch accounts for a large percentage of its latency, the search simplification for other sub-sketches does not degrade the effectiveness of ETO: the average normalized performance is 114.1%."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "For all types of operators we collect, except FRB and WIN, their possible sketches are multi-level tile sketches (Section 5.1)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 318,
                                "start": 315
                            }
                        ],
                        "text": "For each type \ud835\udf0f , we collect operators from popular deep learning models or from the experiments of Ansor [27], and set their batch sizes to be 1 and 16 to get a set A\ud835\udf0f : the CAP and FRB operators are from [27], and operators of the other types are randomly sampled, respectively, from an operator set in Table 2 (the WIN operators are from the operators in ResNet50 which can be computed using the Winograd algorithm) and its 1-hop bridge operators."
                    },
                    "intents": []
                }
            ],
            "corpusId": 962822,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5eadd6f059d742d76441fd0a635a21694dd7392",
            "isKey": true,
            "numCitedBy": 617,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep convolutional neural networks take GPU-days of computation to train on large data sets. Pedestrian detection for self driving cars requires very low latency. Image recognition for mobile phones is constrained by limited processing resources. The success of convolutional neural networks in these situations is limited by how fast we can compute them. Conventional FFT based convolution is fast for large filters, but state of the art convolutional neural networks use small, 3 3 filters. We introduce a new class of fast algorithms for convolutional neural networks using Winograd's minimal filtering algorithms. The algorithms compute minimal complexity convolution over small tiles, which makes them fast with small filters and small batch sizes. We benchmark a GPU implementation of our algorithm with the VGG network and show state of the art throughput at batch sizes from 1 to 64."
            },
            "slug": "Fast-Algorithms-for-Convolutional-Neural-Networks-Lavin-Gray",
            "title": {
                "fragments": [],
                "text": "Fast Algorithms for Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A new class of fast algorithms for convolutional neural networks is introduced using Winograd's minimal filtering algorithms, which compute minimal complexity convolution over small tiles, which makes them fast with small filters and small batch sizes."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144727050"
                        ],
                        "name": "Andrew G. Howard",
                        "slug": "Andrew-G.-Howard",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Howard",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew G. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2717876"
                        ],
                        "name": "Menglong Zhu",
                        "slug": "Menglong-Zhu",
                        "structuredName": {
                            "firstName": "Menglong",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Menglong Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Bo Chen",
                        "slug": "Bo-Chen",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741985"
                        ],
                        "name": "Dmitry Kalenichenko",
                        "slug": "Dmitry-Kalenichenko",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Kalenichenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dmitry Kalenichenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108301072"
                        ],
                        "name": "Weijun Wang",
                        "slug": "Weijun-Wang",
                        "structuredName": {
                            "firstName": "Weijun",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weijun Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47447630"
                        ],
                        "name": "Tobias Weyand",
                        "slug": "Tobias-Weyand",
                        "structuredName": {
                            "firstName": "Tobias",
                            "lastName": "Weyand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tobias Weyand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2612392"
                        ],
                        "name": "M. Andreetto",
                        "slug": "M.-Andreetto",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Andreetto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Andreetto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2595180"
                        ],
                        "name": "Hartwig Adam",
                        "slug": "Hartwig-Adam",
                        "structuredName": {
                            "firstName": "Hartwig",
                            "lastName": "Adam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hartwig Adam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 77
                            }
                        ],
                        "text": "TopK can sometimes find relatively good tensor programs on average, e.g., on DEP and FRB, but it fails to do this on most of the other types of operators, e.g., the 39.9% average normalized throughput on C2D."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 144
                            }
                        ],
                        "text": ", a conv2d operator \u03b31 with K\u03b1 = K\u03b31 and I(L\u03b31 ) of shape [1, 64, 14, 14, 64, 1, 1], or a conv2d operator \u03b32 with K\u03b1 = K\u03b32 and I(L\u03b32 ) of shape [1, 64, 12, 12, 64, 1, 1] (or [1, 64, 28, 28, 64, 3, 3])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 15
                            }
                        ],
                        "text": "For the tested DEP operators, although the average normalized performance is 84.0%, the worst and the best normalized performance is 12.8% and 182.4% respectively, the reason may be that in the tested reuse pairs, the operators in a reuse pairs are not guaranteed to be similar for TopK to perform well on (while the normalized performance by ETO is in the range of [87.9%, 192.4%])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 212
                            }
                        ],
                        "text": "We evaluate ETO on 10 types of deep learning operators, which are: 1D, 2D, and 3D convolution (C1D, C2D, C3D respectively), batch matrix multiplication (BMM), group convolution (GRP), depthwise convolution (DEP) [12], transposed 2D convolution (T2D) [15], capsule 2D convolution (CAP) [11], Winograd 2D convolution (WIN) [13], and frobenius norm (FRB)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12670695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3647d6d0f151dc05626449ee09cc7bce55be497e",
            "isKey": true,
            "numCitedBy": 10324,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization."
            },
            "slug": "MobileNets:-Efficient-Convolutional-Neural-Networks-Howard-Zhu",
            "title": {
                "fragments": [],
                "text": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work introduces two simple global hyper-parameters that efficiently trade off between latency and accuracy and demonstrates the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687325"
                        ],
                        "name": "Du Tran",
                        "slug": "Du-Tran",
                        "structuredName": {
                            "firstName": "Du",
                            "lastName": "Tran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Du Tran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46506697"
                        ],
                        "name": "Heng Wang",
                        "slug": "Heng-Wang",
                        "structuredName": {
                            "firstName": "Heng",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Heng Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732879"
                        ],
                        "name": "L. Torresani",
                        "slug": "L.-Torresani",
                        "structuredName": {
                            "firstName": "Lorenzo",
                            "lastName": "Torresani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Torresani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4439383"
                        ],
                        "name": "Jamie Ray",
                        "slug": "Jamie-Ray",
                        "structuredName": {
                            "firstName": "Jamie",
                            "lastName": "Ray",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jamie Ray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2210374"
                        ],
                        "name": "Manohar Paluri",
                        "slug": "Manohar-Paluri",
                        "structuredName": {
                            "firstName": "Manohar",
                            "lastName": "Paluri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manohar Paluri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 191
                            }
                        ],
                        "text": "For single DNNs, we prepare: ResNet50 [10], MobileNetV2 [16] and ResNeSt50 [25] for image classification, 1D variant of Inception-ResNet-V2 (1D-IR) [9] for tasks like 1D data classification, R2Plus1D-ResNet18 [21] (R(2+1D)) for action recognition, DCGAN [15] generator for image generation, and BERTBase [7] (sequence length is 128) for language understanding."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 100
                            }
                        ],
                        "text": "variant of Inception-ResNet-V2 (1D-IR) [9] for tasks like 1D data classification, R2Plus1D-ResNet18 [21] (R(2+1D)) for action recognition, DCGAN [15] generator for image generation, and BERTBase [7] (sequence length is 128) for language understanding."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206596999,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "89c3050522a0bb9820c32dc7444e003ef0d3e2e4",
            "isKey": false,
            "numCitedBy": 1425,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we discuss several forms of spatiotemporal convolutions for video analysis and study their effects on action recognition. Our motivation stems from the observation that 2D CNNs applied to individual frames of the video have remained solid performers in action recognition. In this work we empirically demonstrate the accuracy advantages of 3D CNNs over 2D CNNs within the framework of residual learning. Furthermore, we show that factorizing the 3D convolutional filters into separate spatial and temporal components yields significantly gains in accuracy. Our empirical study leads to the design of a new spatiotemporal convolutional block \"R(2+1)D\" which produces CNNs that achieve results comparable or superior to the state-of-the-art on Sports-1M, Kinetics, UCF101, and HMDB51."
            },
            "slug": "A-Closer-Look-at-Spatiotemporal-Convolutions-for-Tran-Wang",
            "title": {
                "fragments": [],
                "text": "A Closer Look at Spatiotemporal Convolutions for Action Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A new spatiotemporal convolutional block \"R(2+1)D\" is designed which produces CNNs that achieve results comparable or superior to the state-of-the-art on Sports-1M, Kinetics, UCF101, and HMDB51."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143752292"
                        ],
                        "name": "S. Sabour",
                        "slug": "S.-Sabour",
                        "structuredName": {
                            "firstName": "Sara",
                            "lastName": "Sabour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sabour"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27737461"
                        ],
                        "name": "Nicholas Frosst",
                        "slug": "Nicholas-Frosst",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Frosst",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicholas Frosst"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 172
                            }
                        ],
                        "text": "For each type \ud835\udf0f , we collect operators from popular deep learning models or from the experiments of Ansor [27], and set their batch sizes to be 1 and 16 to get a set A\ud835\udf0f : the CAP and FRB operators are from [27], and operators of the other types are randomly sampled, respectively, from an operator set in Table 2 (the WIN operators are from the operators in ResNet50 which can be computed using the Winograd algorithm) and its 1-hop bridge operators."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 289,
                                "start": 285
                            }
                        ],
                        "text": "We evaluate ETO on 10 types of deep learning operators, which are: 1D, 2D, and 3D convolution (C1D, C2D, C3D respectively), batch matrix multiplication (BMM), group convolution (GRP), depthwise convolution (DEP) [12], transposed 2D convolution (T2D) [15], capsule 2D convolution (CAP) [11], Winograd 2D convolution (WIN) [13], and frobenius norm (FRB)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 65203110,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "603caed9430283db6c7f43169555c8d18e97a281",
            "isKey": false,
            "numCitedBy": 687,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Matrix-capsules-with-EM-routing-Hinton-Sabour",
            "title": {
                "fragments": [],
                "text": "Matrix capsules with EM routing"
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2236416"
                        ],
                        "name": "Dimitri Watel",
                        "slug": "Dimitri-Watel",
                        "structuredName": {
                            "firstName": "Dimitri",
                            "lastName": "Watel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dimitri Watel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3220066"
                        ],
                        "name": "Marc-Antoine Weisser",
                        "slug": "Marc-Antoine-Weisser",
                        "structuredName": {
                            "firstName": "Marc-Antoine",
                            "lastName": "Weisser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc-Antoine Weisser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 89
                            }
                        ],
                        "text": "algorithm for reuse pair selection with bridge operators is implemented in Java based on [23, 24]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 232,
                                "start": 228
                            }
                        ],
                        "text": "To select reuse pairs, we also build an OC graphG = (V , E) ofA, but the reuse pair selection problem is now regarded as a directed steiner tree problem on G , which can be solved by an existing fast |A|-approximation algorithm [23] in O ( |A||E | |A|2) time."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 26583315,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "626434a07a56c0a127d122e8fb6b7c0d17f1c608",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The directed Steiner tree (DST) NP-hard problem asks, considering a directed weighted graph with n nodes and m arcs, a node r called root and a set of k nodes X called terminals, for a minimum cost directed tree rooted at r spanning X. The best known polynomial approximation ratio for DST is a $$O(k^\\varepsilon )$$O(k\u03b5)-approximation greedy algorithm. However, a much faster k-approximation, returning the shortest paths from r to X, is generally used in practice. We give two new algorithms : a fast k-approximation called Greedy$$_\\text {FLAC}$$FLAC running in $$O(m \\log (n)k + \\min (m, nk)nk^2)$$O(mlog(n)k+min(m,nk)nk2) and a $$O(\\sqrt{k})$$O(k)-approximation called Greedy$$_\\text {FLAC}^\\triangleright $$FLAC\u25b9 running in $$O(nm + n^2 \\log (n)k +n^2 k^3)$$O(nm+n2log(n)k+n2k3). We provide computational results to show that, Greedy$$_\\text {FLAC}$$FLAC rivals in practice with the running time of the fast k-approximation and returns solution with smaller cost in practice."
            },
            "slug": "A-practical-greedy-approximation-for-the-directed-Watel-Weisser",
            "title": {
                "fragments": [],
                "text": "A practical greedy approximation for the directed Steiner tree problem"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A new \\(O(\\sqrt{k})\\)-approximation greedy algorithm called Greedy is given, derived from a new fast \\(k\\)- approximation algorithm calledGreedy, running in time at most \\(O(n m k^2)\\)."
            },
            "venue": {
                "fragments": [],
                "text": "J. Comb. Optim."
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 57
                            }
                        ],
                        "text": "The other 39 curves can be found in the technical report [8], and they are very similar to Figure 5 since the definition of feature value ranges (Equations (1) to (3)) and the search methods are independent of operator types (like Algorithm 1 works for all types of operators with the multi-level tile sketch)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 145
                            }
                        ],
                        "text": "We evaluate TopK on another data set for FRB by setting larger batch sizes and smaller reduction loops (the data set description can be found in [8]), where the respective best tensor program in the search space of Ansor are different for the operators, and the average normalized performance of it drops to 78."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 48
                            }
                        ],
                        "text": "We provide more details in our technical report [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 49
                            }
                        ],
                        "text": "The detailed analysis is in the technical report [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 274,
                                "start": 259
                            }
                        ],
                        "text": "Using this multi-level tiling method on the conv2d in Figure 2, denoted by\u03b1 , if we tileL\u03b1 = {nn, ff, yy, xx, rc, ry, rx} (listed from the outermost loop to the innermost loop) in the way that, nn, ff, yy, xx all have 5 tile levels which are [1, 1, 1, 1, 1], [4, 1, 8, 2, 2], [14, 1, 1, 1, 2], [1, 1, 28, 1, 1] respectively, and rc, ry, rx all have 3 tile levels which are [4, 64, 2], [1, 1, 1], [1, 1, 1] respectively, then after reordering the loop tiles according to the \u201cSSSRRSRS\u201d structure, fusing loop tiles on the same level and doing thread binding, we can get the major part of the tensor program in Figure 2b."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 31
                            }
                        ],
                        "text": "Then if the BShape of an S\u03b1 is [1, 4, 8, 8], it means in S\u03b1 a thread block needs to compute half of the height and the width of each output channel in each batch, and there are 4"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ETO: Accelerating Optimization of DNN Operators by High-Performance Tensor Program Reuse"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2021
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32163737"
                        ],
                        "name": "Benoit Steiner",
                        "slug": "Benoit-Steiner",
                        "structuredName": {
                            "firstName": "Benoit",
                            "lastName": "Steiner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benoit Steiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059804383"
                        ],
                        "name": "Chris Cummins",
                        "slug": "Chris-Cummins",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Cummins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Cummins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111909709"
                        ],
                        "name": "Horace He",
                        "slug": "Horace-He",
                        "structuredName": {
                            "firstName": "Horace",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Horace He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2476647"
                        ],
                        "name": "H. Leather",
                        "slug": "H.-Leather",
                        "structuredName": {
                            "firstName": "Hugh",
                            "lastName": "Leather",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Leather"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "A recent work [18] designs a cost model, which can be pretrained, using LSTM over engineered features to accurately estimate the expected performance of a partial schedule."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 248990788,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a58f3dc57087946490a00e2eacf93497ff668cb5",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Value-Learning-for-Throughput-Optimization-of-Deep-Steiner-Cummins",
            "title": {
                "fragments": [],
                "text": "Value Learning for Throughput Optimization of Deep Learning Workloads"
            },
            "venue": {
                "fragments": [],
                "text": "MLSys"
            },
            "year": 2021
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1D-Inception-ResNet-V2-Model. hanxuh-hub"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "CUDA C++ Programming Guide"
            },
            "venue": {
                "fragments": [],
                "text": "NVIDIA"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Variable tensor sizes support for TC. Tensor Comprehension"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2018
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 14,
            "methodology": 17
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 25,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/ETO:-Accelerating-Optimization-of-DNN-Operators-by-Fang-Shen/37a8e303d1ca9a7cbfee39f6e0563bf8da610b7b?sort=total-citations"
}