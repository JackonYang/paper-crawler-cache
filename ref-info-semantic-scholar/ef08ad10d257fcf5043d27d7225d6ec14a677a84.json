{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2733057"
                        ],
                        "name": "Xiangyu Zhao",
                        "slug": "Xiangyu-Zhao",
                        "structuredName": {
                            "firstName": "Xiangyu",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangyu Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48570713"
                        ],
                        "name": "L. Zhang",
                        "slug": "L.-Zhang",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775738"
                        ],
                        "name": "Zhuoye Ding",
                        "slug": "Zhuoye-Ding",
                        "structuredName": {
                            "firstName": "Zhuoye",
                            "lastName": "Ding",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhuoye Ding"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50559722"
                        ],
                        "name": "Dawei Yin",
                        "slug": "Dawei-Yin",
                        "structuredName": {
                            "firstName": "Dawei",
                            "lastName": "Yin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dawei Yin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109917536"
                        ],
                        "name": "Y. Zhao",
                        "slug": "Y.-Zhao",
                        "structuredName": {
                            "firstName": "Yihong",
                            "lastName": "Zhao",
                            "middleNames": [
                                "Eric"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736632"
                        ],
                        "name": "Jiliang Tang",
                        "slug": "Jiliang-Tang",
                        "structuredName": {
                            "firstName": "Jiliang",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiliang Tang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "[33, 34] propose a novel page-wise recommendation framework based on deep reinforcement learning, which can optimize a page of"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6953978,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "63bce48a68c027f8f7df7ed5cd6e99d9e3ac14e9",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Recommender systems play a crucial role in mitigating the problem of information overload by suggesting users' personalized items or services. The vast majority of traditional recommender systems consider the recommendation procedure as a static process and make recommendations following a fixed strategy. In this paper, we propose a novel recommender system with the capability of continuously improving its strategies during the interactions with users. We model the sequential interactions between users and a recommender system as a Markov Decision Process (MDP) and leverage Reinforcement Learning (RL) to automatically learn the optimal strategies via recommending trial-and-error items and receiving reinforcements of these items from users' feedbacks. In particular, we introduce an online user-agent interacting environment simulator, which can pre-train and evaluate model parameters offline before applying the model online. Moreover, we validate the importance of list-wise recommendations during the interactions between users and agent, and develop a novel approach to incorporate them into the proposed framework LIRD for list-wide recommendations. The experimental results based on a real-world e-commerce dataset demonstrate the effectiveness of the proposed framework."
            },
            "slug": "Deep-Reinforcement-Learning-for-List-wise-Zhao-Zhang",
            "title": {
                "fragments": [],
                "text": "Deep Reinforcement Learning for List-wise Recommendations"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper proposes a novel recommender system with the capability of continuously improving its strategies during the interactions with users and introduces an online user-agent interacting environment simulator, which can pre-train and evaluate model parameters offline before applying the model online."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2733057"
                        ],
                        "name": "Xiangyu Zhao",
                        "slug": "Xiangyu-Zhao",
                        "structuredName": {
                            "firstName": "Xiangyu",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangyu Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143916459"
                        ],
                        "name": "Long Xia",
                        "slug": "Long-Xia",
                        "structuredName": {
                            "firstName": "Long",
                            "lastName": "Xia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Long Xia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48570713"
                        ],
                        "name": "L. Zhang",
                        "slug": "L.-Zhang",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775738"
                        ],
                        "name": "Zhuoye Ding",
                        "slug": "Zhuoye-Ding",
                        "structuredName": {
                            "firstName": "Zhuoye",
                            "lastName": "Ding",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhuoye Ding"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50559722"
                        ],
                        "name": "Dawei Yin",
                        "slug": "Dawei-Yin",
                        "structuredName": {
                            "firstName": "Dawei",
                            "lastName": "Yin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dawei Yin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736632"
                        ],
                        "name": "Jiliang Tang",
                        "slug": "Jiliang-Tang",
                        "structuredName": {
                            "firstName": "Jiliang",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiliang Tang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "[33, 34] propose a novel page-wise recommendation framework based on deep reinforcement learning, which can optimize a page of"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 24131880,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5956c34032126185d8ad19695e4a1a191c08b5a1",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Recommender systems can mitigate the information overload problem by suggesting users' personalized items. In real-world recommendations such as e-commerce, a typical interaction between the system and its users is - users are recommended a page of items and provide feedback; and then the system recommends a new page of items. To effectively capture such interaction for recommendations, we need to solve two key problems - (1) how to update recommending strategy according to user's real-time feedback, and 2) how to generate a page of items with proper display, which pose tremendous challenges to traditional recommender systems. In this paper, we study the problem of page-wise recommendations aiming to address aforementioned two challenges simultaneously. In particular, we propose a principled approach to jointly generate a set of complementary items and the corresponding strategy to display them in a 2-D page; and propose a novel page-wise recommendation framework based on deep reinforcement learning, DeepPage, which can optimize a page of items with proper display based on real-time feedback from users. The experimental results based on a real-world e-commerce dataset demonstrate the effectiveness of the proposed framework."
            },
            "slug": "Deep-reinforcement-learning-for-page-wise-Zhao-Xia",
            "title": {
                "fragments": [],
                "text": "Deep reinforcement learning for page-wise recommendations"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A principled approach to jointly generate a set of complementary items and the corresponding strategy to display them in a 2-D page is proposed and a novel page-wise recommendation framework based on deep reinforcement learning, DeepPage, which can optimize a page of items with proper display based on real-time feedback from users is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "RecSys"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777934740"
                        ],
                        "name": "Qingyun Wu",
                        "slug": "Qingyun-Wu",
                        "structuredName": {
                            "firstName": "Qingyun",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qingyun Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31825390"
                        ],
                        "name": "Hongning Wang",
                        "slug": "Hongning-Wang",
                        "structuredName": {
                            "firstName": "Hongning",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hongning Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33888728"
                        ],
                        "name": "Liangjie Hong",
                        "slug": "Liangjie-Hong",
                        "structuredName": {
                            "firstName": "Liangjie",
                            "lastName": "Hong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liangjie Hong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145170932"
                        ],
                        "name": "Yue Shi",
                        "slug": "Yue-Shi",
                        "structuredName": {
                            "firstName": "Yue",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yue Shi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "of Qvalues between target item a and enemy item aE at state (s+,s\u2212), which is controlled by a non-negative parameter \u03b1. Note that since user\u2019s preference is relatively stable during a short time slot [30], we assume that user will give same feedback to aE at state (s+,s\u2212). For example, if RA recommends item a5 at state s2, the user will still skip a5. The gradient of loss function can be computed as: "
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 21731567,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fba0a105b03a3acaab8d0b08d873584401c0d074",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work, we propose to improve long-term user engagement in a recommender system from the perspective of sequential decision optimization, where users' click and return behaviors are directly modeled for online optimization. A bandit-based solution is formulated to balance three competing factors during online learning, including exploitation for immediate click, exploitation for expected future clicks, and exploration of unknowns for model estimation. We rigorously prove that with a high probability our proposed solution achieves a sublinear upper regret bound in maximizing cumulative clicks from a population of users in a given period of time, while a linear regret is inevitable if a user's temporal return behavior is not considered when making the recommendations. Extensive experimentation on both simulations and a large-scale real-world dataset collected from Yahoo frontpage news recommendation log verified the effectiveness and significant improvement of our proposed algorithm compared with several state-of-the-art online learning baselines for recommendation."
            },
            "slug": "Returning-is-Believing:-Optimizing-Long-term-User-Wu-Wang",
            "title": {
                "fragments": [],
                "text": "Returning is Believing: Optimizing Long-term User Engagement in Recommender Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work rigorously proves that with a high probability its proposed solution achieves a sublinear upper regret bound in maximizing cumulative clicks from a population of users in a given period of time, while a linear regret is inevitable if a user's temporal return behavior is not considered when making the recommendations."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32879304"
                        ],
                        "name": "T. Mahmood",
                        "slug": "T.-Mahmood",
                        "structuredName": {
                            "firstName": "Tariq",
                            "lastName": "Mahmood",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Mahmood"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40169260"
                        ],
                        "name": "F. Ricci",
                        "slug": "F.-Ricci",
                        "structuredName": {
                            "firstName": "Francesco",
                            "lastName": "Ricci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Ricci"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "s [23, 24]. Typically, a recommendation procedure can be modeled as interactions between users and recommender agent (RA). It consistsoftwophases:1)usermodelconstructionand2)recommendation generation [14]. During the interaction, the recommender agent builds a user model to learn users\u2019 preferences based on users\u2019 information or feedback. Then, the recommender agent generates a list of items that best"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1676041,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6d4e75f0cdaf3294b2202178e0652c48c1ee49f",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Recommender systems are intelligent E-commerce applications that assist users in a decision-making process by offering personalized product recommendations during an interaction session. Quite recently, conversational approaches have been introduced in order to support more interactive recommendation sessions. Notwithstanding the increased interactivity offered by these approaches, the system employs an interaction strategy that is specified apriori (at design time) and followed quite rigidly during the interaction. In this paper, we present a new type of recommender system which is capable of learning autonomously an adaptive interaction strategy for assisting the users in acquiring their interaction goals. We view the recommendation process as a sequential decision problem and we model it as a Markov Decision Process (MDP). We learn a model of the user behavior, and use it to acquire the adaptive strategy using Reinforcement Learning (RL) techniques. In this context, the system learns the optimal strategy by observing the consequences of its actions on the users and also on the final outcome of the recommendation session. We apply our approach within an existing travel recommender system which uses a rigid, non-adaptive support strategy for advising a user in refining a query to a travel product catalogue. The initial results demonstrate the value of our approach and show that our system is able to improve the non-adaptive strategy in order to learn an optimal (adaptive) recommendation strategy."
            },
            "slug": "Learning-and-adaptivity-in-interactive-recommender-Mahmood-Ricci",
            "title": {
                "fragments": [],
                "text": "Learning and adaptivity in interactive recommender systems"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A new type of recommender system is presented which is capable of learning autonomously an adaptive interaction strategy for assisting the users in acquiring their interaction goals and improves the non-adaptive strategy in order to learn an optimal recommendation strategy."
            },
            "venue": {
                "fragments": [],
                "text": "ICEC"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1583098764"
                        ],
                        "name": "Shuai Zhang",
                        "slug": "Shuai-Zhang",
                        "structuredName": {
                            "firstName": "Shuai",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuai Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082966"
                        ],
                        "name": "Lina Yao",
                        "slug": "Lina-Yao",
                        "structuredName": {
                            "firstName": "Lina",
                            "lastName": "Yao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lina Yao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735962"
                        ],
                        "name": "Aixin Sun",
                        "slug": "Aixin-Sun",
                        "structuredName": {
                            "firstName": "Aixin",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aixin Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144447820"
                        ],
                        "name": "Yi Tay",
                        "slug": "Yi-Tay",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Tay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Tay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 292,
                                "start": 288
                            }
                        ],
                        "text": "The other topic closely related to this category is deep learning based recommender system, which is able to effectively capture the non-linear and non-trivial user-item relationships, and enables the codification of more complex abstractions as data representations in the higher layers [32]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 22475926,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b6f172def2f4b37ea85969b4d99e789c647726b",
            "isKey": false,
            "numCitedBy": 627,
            "numCiting": 316,
            "paperAbstract": {
                "fragments": [],
                "text": "With the growing volume of online information, recommender systems have been an effective strategy to overcome information overload. The utility of recommender systems cannot be overstated, given their widespread adoption in many web applications, along with their potential impact to ameliorate many problems related to over-choice. In recent years, deep learning has garnered considerable interest in many research fields such as computer vision and natural language processing, owing not only to stellar performance but also to the attractive property of learning feature representations from scratch. The influence of deep learning is also pervasive, recently demonstrating its effectiveness when applied to information retrieval and recommender systems research. The field of deep learning in recommender system is flourishing. This article aims to provide a comprehensive review of recent research efforts on deep learning-based recommender systems. More concretely, we provide and devise a taxonomy of deep learning-based recommendation models, along with a comprehensive summary of the state of the art. Finally, we expand on current trends and provide new perspectives pertaining to this new and exciting development of the field."
            },
            "slug": "Deep-Learning-Based-Recommender-System-Zhang-Yao",
            "title": {
                "fragments": [],
                "text": "Deep Learning Based Recommender System"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A taxonomy of deep learning-based recommendation models is provided and a comprehensive summary of the state of the art is provided, along with new perspectives pertaining to this new and exciting development of the field."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Comput. Surv."
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32879304"
                        ],
                        "name": "T. Mahmood",
                        "slug": "T.-Mahmood",
                        "structuredName": {
                            "firstName": "Tariq",
                            "lastName": "Mahmood",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Mahmood"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40169260"
                        ],
                        "name": "F. Ricci",
                        "slug": "F.-Ricci",
                        "structuredName": {
                            "firstName": "Francesco",
                            "lastName": "Ricci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Ricci"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[15] adopted the reinforcement learning technique to observe the responses of users in a conversational recommender, with the aim to maximize a numerical cumulative reward function modeling the benefit that users get from each"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16096663,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e388ec401853d4db2471b620fac8e1c3cc334b7",
            "isKey": false,
            "numCitedBy": 258,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Conversational recommender systems (CRSs) assist online users in their information-seeking and decision making tasks by supporting an interactive process. Although these processes could be rather diverse, CRSs typically follow a fixed strategy, e.g., based on critiquing or on iterative query reformulation. In a previous paper, we proposed a novel recommendation model that allows conversational systems to autonomously improve a fixed strategy and eventually learn a better one using reinforcement learning techniques. This strategy is optimal for the given model of the interaction and it is adapted to the users' behaviors. In this paper we validate our approach in an online CRS by means of a user study involving several hundreds of testers. We show that the optimal strategy is different from the fixed one, and supports more effective and efficient interaction sessions."
            },
            "slug": "Improving-recommender-systems-with-adaptive-Mahmood-Ricci",
            "title": {
                "fragments": [],
                "text": "Improving recommender systems with adaptive conversational strategies"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that the optimal strategy is different from the fixed one, and supports more effective and efficient interaction sessions, and allows conversational systems to autonomously improve a fixed strategy and eventually learn a better one using reinforcement learning techniques."
            },
            "venue": {
                "fragments": [],
                "text": "HT '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3061599"
                        ],
                        "name": "N. Taghipour",
                        "slug": "N.-Taghipour",
                        "structuredName": {
                            "firstName": "Nima",
                            "lastName": "Taghipour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Taghipour"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695547"
                        ],
                        "name": "A. Kardan",
                        "slug": "A.-Kardan",
                        "structuredName": {
                            "firstName": "Ahmad",
                            "lastName": "Kardan",
                            "middleNames": [
                                "Agha"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kardan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3354354"
                        ],
                        "name": "S. S. Ghidary",
                        "slug": "S.-S.-Ghidary",
                        "structuredName": {
                            "firstName": "Saeed",
                            "lastName": "Ghidary",
                            "middleNames": [
                                "Shiry"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. S. Ghidary"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "sponses of users in a conversational recommender, with the aim to maximize a numerical cumulative reward function modeling the benefit that users get from each recommendation session. Taghipour et al.[27, 28] modeled web page recommendation as a Q-Learning problem and learned to make recommendations from web usage data as the actions rather than discovering explicit patterns from the data. The system inhe"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16079357,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b361fc8e42111a25946b4cf6fe04a857accda4ce",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Information overload is no longer news; the explosive growth of the Internet has made this issue increasingly serious for Web users. Users are very often overwhelmed by the huge amount of information and are faced with a big challenge to find the most relevant information in the right time. Recommender systems aim at pruning this information space and directing users toward the items that best meet their needs and interests. Web Recommendation has been an active application area in Web Mining and Machine Learning research. In this paper we propose a novel machine learning perspective toward the problem, based on reinforcement learning. Unlike other recommender systems, our system does not use the static patterns discovered from web usage data, instead it learns to make recommendations as the actions it performs in each situation. We model the problem as Q-Learning while employing concepts and techniques commonly applied in the web usage mining domain. We propose that the reinforcement learning paradigm provides an appropriate model for the recommendation problem, as well as a framework in which the system constantly interacts with the user and learns from her behavior. Our experimental evaluations support our claims and demonstrate how this approach can improve the quality of web recommendations."
            },
            "slug": "Usage-based-web-recommendations:-a-reinforcement-Taghipour-Kardan",
            "title": {
                "fragments": [],
                "text": "Usage-based web recommendations: a reinforcement learning approach"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper proposes that the reinforcement learning paradigm provides an appropriate model for the recommendation problem, as well as a framework in which the system constantly interacts with the user and learns from her behavior, and how this approach can improve the quality of web recommendations."
            },
            "venue": {
                "fragments": [],
                "text": "RecSys '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3061599"
                        ],
                        "name": "N. Taghipour",
                        "slug": "N.-Taghipour",
                        "structuredName": {
                            "firstName": "Nima",
                            "lastName": "Taghipour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Taghipour"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695547"
                        ],
                        "name": "A. Kardan",
                        "slug": "A.-Kardan",
                        "structuredName": {
                            "firstName": "Ahmad",
                            "lastName": "Kardan",
                            "middleNames": [
                                "Agha"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kardan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "sponses of users in a conversational recommender, with the aim to maximize a numerical cumulative reward function modeling the benefit that users get from each recommendation session. Taghipour et al.[27, 28] modeled web page recommendation as a Q-Learning problem and learned to make recommendations from web usage data as the actions rather than discovering explicit patterns from the data. The system inhe"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "ify items with small immediate rewards but making big contributions to the rewards for future recommendations. Efforts have been made on utilizing reinforcement learning for recommender systems [25], [27]. For instance, the work [25] modeled the recommender system as a MDP process and estimated the transition probability and then the Q-value table. However, these methods may become inflexible with the"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18057521,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d8514c3b645790b20a8664d818a39febe46ab1f6",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Different efforts have been made to address the problem of information overload on the Internet. Recommender systems aim at directing users through this information space, toward the resources that best meet their needs and interests. Web Content Recommendation has been an active application area for Information Filtering, Web Mining and Machine Learning research. Recent studies show that combining the conceptual and usage information can improve the quality of web recommendations. In this paper we exploit this idea to enhance a reinforcement learning framework, primarily devised for web recommendations based on web usage data. A hybrid web recommendation method is proposed by making use of the conceptual relationships among web resources to derive a novel model of the problem, enriched with semantic knowledge about the usage behavior. With our hybrid model for the web page recommendation problem we show the apt and flexibility of the reinforcement learning framework in the web recommendation domain, and demonstrate how it can be extended in order to incorporate various sources of information. We evaluate our method under different settings and show how this method can improve the overall quality of web recommendations."
            },
            "slug": "A-hybrid-web-recommender-system-based-on-Q-learning-Taghipour-Kardan",
            "title": {
                "fragments": [],
                "text": "A hybrid web recommender system based on Q-learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A hybrid web recommendation method is proposed by making use of the conceptual relationships among web resources to derive a novel model of the problem, enriched with semantic knowledge about the usage behavior, and it is demonstrated how this method can improve the overall quality of web recommendations."
            },
            "venue": {
                "fragments": [],
                "text": "SAC '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2507883"
                        ],
                        "name": "Bal\u00e1zs Hidasi",
                        "slug": "Bal\u00e1zs-Hidasi",
                        "structuredName": {
                            "firstName": "Bal\u00e1zs",
                            "lastName": "Hidasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bal\u00e1zs Hidasi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713164"
                        ],
                        "name": "Alexandros Karatzoglou",
                        "slug": "Alexandros-Karatzoglou",
                        "structuredName": {
                            "firstName": "Alexandros",
                            "lastName": "Karatzoglou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexandros Karatzoglou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2666397"
                        ],
                        "name": "L. Baltrunas",
                        "slug": "L.-Baltrunas",
                        "structuredName": {
                            "firstName": "Linas",
                            "lastName": "Baltrunas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baltrunas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754164"
                        ],
                        "name": "D. Tikk",
                        "slug": "D.-Tikk",
                        "structuredName": {
                            "firstName": "Domonkos",
                            "lastName": "Tikk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tikk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 162
                            }
                        ],
                        "text": "Here we leverage GRU rather than Long Short-Term Memory (LSTM) because that GRU outperforms LSTM for capturing users\u2019 sequential behaviors in recommendation task [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11810482,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dfb1e7d1559fbc2eb63761bc170061d256496bdf",
            "isKey": false,
            "numCitedBy": 1369,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We apply recurrent neural networks (RNN) on a new domain, namely recommender systems. Real-life recommender systems often face the problem of having to base recommendations only on short session-based data (e.g. a small sportsware website) instead of long user histories (as in the case of Netflix). In this situation the frequently praised matrix factorization approaches are not accurate. This problem is usually overcome in practice by resorting to item-to-item recommendations, i.e. recommending similar items. We argue that by modeling the whole session, more accurate recommendations can be provided. We therefore propose an RNN-based approach for session-based recommendations. Our approach also considers practical aspects of the task and introduces several modifications to classic RNNs such as a ranking loss function that make it more viable for this specific problem. Experimental results on two data-sets show marked improvements over widely used approaches."
            },
            "slug": "Session-based-Recommendations-with-Recurrent-Neural-Hidasi-Karatzoglou",
            "title": {
                "fragments": [],
                "text": "Session-based Recommendations with Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is argued that by modeling the whole session, more accurate recommendations can be provided by an RNN-based approach for session-based recommendations, and introduced several modifications to classic RNNs such as a ranking loss function that make it more viable for this specific problem."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144741762"
                        ],
                        "name": "P. Resnick",
                        "slug": "P.-Resnick",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Resnick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Resnick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070970"
                        ],
                        "name": "H. Varian",
                        "slug": "H.-Varian",
                        "structuredName": {
                            "firstName": "Hal",
                            "lastName": "Varian",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Varian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "s and preferences. Recommender systems have become increasingly popular in recent years, and have been utilized in a variety of domains including movies, music, books, search queries, and social tags [23, 24]. Typically, a recommendation procedure can be modeled as interactions between users and recommender agent (RA). It consistsoftwophases:1)usermodelconstructionand2)recommendation generation [14]. Duri"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1381259,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dbdabdf9e653e11eb4d44f69f645a564622220b3",
            "isKey": false,
            "numCitedBy": 2816,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Recommender systems assist and augment this natural social process. In a typical recommender system people provide recommendations as inputs, which the system then aggregates and directs to appropriate recipients. In some cases the primary transformation is in the aggregation; in others the system\u2019s value lies in its ability to make good matches between the recommenders and those seeking recommendations. The developers of the first recommender system, Tapestry [1], coined the phrase \u201ccollaborative filtering\u201d and several others have adopted it. We prefer the more general term \u201crecommender system\u201d for two reasons. First, recommenders may not explictly collaborate with recipients, who may be unknown to each other. Second, recommendations may suggest particularly interesting items, in addition to indicating those that should be filtered out. This special section includes descriptions of five recommender systems. A sixth article analyzes incentives for provision of recommendations. Figure 1 places the systems in a technical design space defined by five dimensions. First, the contents of an evaluation can be anything from a single bit (recommended or not) to unstructured textual annotations. Second, recommendations may be entered explicitly, but several systems gather implicit evaluations: GroupLens monitors users\u2019 reading times; PHOAKS mines Usenet articles for mentions of URLs; and Siteseer mines personal bookmark lists. Third, recommendations may be anonymous, tagged with the source\u2019s identity, or tagged with a pseudonym. The fourth dimension, and one of the richest areas for exploration, is how to aggregate evaluations. GroupLens, PHOAKS, and Siteseer employ variants on weighted voting. Fab takes that one step further to combine evaluations with content analysis. ReferralWeb combines suggested links between people to form longer referral chains. Finally, the (perhaps aggregated) evaluations may be used in several ways: negative recommendations may be filtered out, the items may be sorted according to numeric evaluations, or evaluations may accompany items in a display. Figures 2 and 3 identify dimensions of the domain space: The kinds of items being recommended and the people among whom evaluations are shared. Consider, first, the domain of items. The sheer volume is an important variable: Detailed textual reviews of restaurants or movies may be practical, but applying the same approach to thousands of daily Netnews messages would not. Ephemeral media such as netnews (most news servers throw away articles after one or two weeks) place a premium on gathering and distributing evaluations quickly, while evaluations for 19th century books can be gathered at a more leisurely pace. The last dimension describes the cost structure of choices people make about the items. Is it very costly to miss IT IS OFTEN NECESSARY TO MAKE CHOICES WITHOUT SUFFICIENT personal experience of the alternatives. In everyday life, we rely on"
            },
            "slug": "Recommender-systems-Resnick-Varian",
            "title": {
                "fragments": [],
                "text": "Recommender systems"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This special section includes descriptions of five recommender systems, which provide recommendations as inputs, which the system then aggregates and directs to appropriate recipients, and which combine evaluations with content analysis."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143884151"
                        ],
                        "name": "Hanh T. H. Nguyen",
                        "slug": "Hanh-T.-H.-Nguyen",
                        "structuredName": {
                            "firstName": "Hanh",
                            "lastName": "Nguyen",
                            "middleNames": [
                                "T.",
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanh T. H. Nguyen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2794970"
                        ],
                        "name": "Martin Wistuba",
                        "slug": "Martin-Wistuba",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wistuba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin Wistuba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782863"
                        ],
                        "name": "Josif Grabocka",
                        "slug": "Josif-Grabocka",
                        "structuredName": {
                            "firstName": "Josif",
                            "lastName": "Grabocka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josif Grabocka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2282727"
                        ],
                        "name": "Lucas Drumond",
                        "slug": "Lucas-Drumond",
                        "structuredName": {
                            "firstName": "Lucas",
                            "lastName": "Drumond",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lucas Drumond"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388781075"
                        ],
                        "name": "L. Schmidt-Thieme",
                        "slug": "L.-Schmidt-Thieme",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Schmidt-Thieme",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Schmidt-Thieme"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "apture the non-linear and non-trivial user-item relationships, and enables the codification of more complex abstractions as data representations in the higher layers [32]. For instance, Nguyen et al. [20] proposed a personalized tag recommender system based on CNN. It utilizes constitutional and max-pooling layer to get visual features from patches of images. Wu et al. [31] designed a session-based re"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4666321,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df37e2fa58670e917c22a4b7de6686afca99d348",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Social media services deploy tag recommendation systems to facilitate the process of tagging objects which depends on the information of both the user\u2019s preferences and the tagged object. However, most image tag recommender systems do not consider the additional information provided by the uploaded image but rely only on textual information, or make use of simple low-level image features. In this paper, we propose a personalized deep learning approach for the image tag recommendation that considers the user\u2019s preferences, as well as visual information. We employ Convolutional Neural Networks (CNNs), which already provide excellent performance for image classification and recognition, to obtain visual features from images in a supervised way. We provide empirical evidence that features selected in this fashion improve the capability of tag recommender systems, compared to the current state of the art that is using hand-crafted visual features, or is solely based on the tagging history information. The proposed method yields up to at least two percent accuracy improvement in two real world datasets, namely NUS-WIDE and Flickr-PTR."
            },
            "slug": "Personalized-Deep-Learning-for-Tag-Recommendation-Nguyen-Wistuba",
            "title": {
                "fragments": [],
                "text": "Personalized Deep Learning for Tag Recommendation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes a personalized deep learning approach for the image tag recommendation that considers the user\u2019s preferences, as well as visual information, and employs Convolutional Neural Networks (CNNs) to obtain visual features from images in a supervised way."
            },
            "venue": {
                "fragments": [],
                "text": "PAKDD"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719532"
                        ],
                        "name": "Guy Shani",
                        "slug": "Guy-Shani",
                        "structuredName": {
                            "firstName": "Guy",
                            "lastName": "Shani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guy Shani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099028"
                        ],
                        "name": "D. Heckerman",
                        "slug": "D.-Heckerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heckerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heckerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680506"
                        ],
                        "name": "R. Brafman",
                        "slug": "R.-Brafman",
                        "structuredName": {
                            "firstName": "Ronen",
                            "lastName": "Brafman",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Brafman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "orcement learning to automatically learn the optimal recommendation strategies. Indeed, reinforcement learning have been widely examined in recommendation field. The MDP-Based CF model in Shani et al.[25] can be viewed as approximating a partial observable MDP (POMDP) by using a finite rather than unbounded window of past history to define the current state. To reduce the high computational and repres"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": " identify items with small immediate rewards but making big contributions to the rewards for future recommendations. Efforts have been made on utilizing reinforcement learning for recommender systems [25], [27]. For instance, the work [25] modeled the recommender system as a MDP process and estimated the transition probability and then the Q-value table. However, these methods may become inflexible wi"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "mendations, i.e., to make users order the recommended items, while completely overlooking whether these recommended items will lead to more likely or more profitable (long-term) rewards in the future [25]. In this paper, we consider the recommendation procedure as sequential interactions between users and recommender agent; and leverage Reinforcement Learning (RL) to automatically learn the optimal re"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 875571,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b739b106b585c963cca70a10f38e564cc9d98cc",
            "isKey": true,
            "numCitedBy": 748,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Typical Recommender systems adopt a static view of the recommendation process and treat it as a prediction problem. We argue that it is more appropriate to view the problem of generating recommendations as a sequential decision problem and, consequently, that Markov decision processes (MDP) provide a more appropriate model for Recommender systems. MDPs introduce two benefits: they take into account the long-term effects of each recommendation, and they take into account the expected value of each recommendation. To succeed in practice, an MDP-based Recommender system must employ a strong initial model; and the bulk of this paper is concerned with the generation of such a model. In particular, we suggest the use of an n-gram predictive model for generating the initial MDP. Our n-gram model induces a Markovchain model of user behavior whose predictive accuracy is greater than that of existing predictive models. We describe our predictive model in detail and evaluate its performance on real data. In addition, we show how the model can be used in an MDP-based Recommender system."
            },
            "slug": "An-MDP-Based-Recommender-System-Shani-Heckerman",
            "title": {
                "fragments": [],
                "text": "An MDP-Based Recommender System"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The use of an n-gram predictive model is suggested for generating the initial MDP, which induces a Markovchain model of user behavior whose predictive accuracy is greater than that of existing predictive models."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29241448"
                        ],
                        "name": "S. Ahrens",
                        "slug": "S.-Ahrens",
                        "structuredName": {
                            "firstName": "Sophie",
                            "lastName": "Ahrens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ahrens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 510077,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f51a9f05e9a295262999a37278f8b07dd4f4a91",
            "isKey": false,
            "numCitedBy": 2179,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Beyond NDCG: behavioral testing of recommender systems Collaborative Knowledge Base Embedding for Recommender ...Recommender Systems Based On Personality Traits: Could GitHub microsoft/recommenders: Best Practices on Classifying Different Types of Recommender Systems | BluePi5 Problems of Recommender Systems ReadWriteBuilding recommender systems with Azure Machine Learning Building Recommender Systems with Machine Learning and AI Research paper recommender systems a random-walk based In-Depth Guide: How Recommender Systems Work | Built InRecSys \u2013 ACM Recommender SystemsR Pubsure Check Research Manuscript Online To Avoid Desk Matrix factorization (recommender systems) WikipediaIntroduction to Recommender Systems | Tryolabs[1606.07792] Wide & Deep Learning for Recommender Systems13 The Net?ix Recommender System: Algorithms, Business 10 Datasets One Must Know To Build Recommender SystemsRecommender Systems in Keras | Movie Recommendations using Deep Matrix Factorization Models for Recommender Systems(PDF) Recommender Systems Handbook ResearchGateIntroduction to recommender systems | by Baptiste Rocca An Easy Introduction to Machine Learning Recommender SystemsRecommender Systems Datasets Computer ScienceDeep Learning Based Recommender Systems | by Sciforce Towards the Next Generation of Recommender Systems: A Cold-Start Problem in Recommender Systems and its Recommender System Application Developments: A SurveyRUCAIBox \u00b7 GitHub16. Recommender Systems \u2014 Dive into Deep Learning 0.17.1 Recommendation Systems Stanford UniversityRecommender system WikipediaMachine Learning for Recommender systems \u2014 Part 1 Five Types of Recommender Systems and The APP SolutionsRecSys 2020 (Online) ACM Recommender Systems\"A Theory-Driven Design Framework for Social Recommender Evaluation Metrics for Recommender Systems | by Claire Jun 03, 2018 \u00b7 Recommender systems are one of the most successful and widespread application of machine learning technologies in business. There were many people on waiting list that could not attend our MLMU Essay about racial inequality essay on earthquake of nepal 2015 history essay graphic organizer, essay on man alexander pope anemia case study nursing systems based a paper recommender random-walk approach Research, violence essay romeo and juliet, soccer essay scholarships media and culture essay topics. Dystopian argumentative essay.Avoid desk rejection and make sure your research manuscript is submission ready with R Pubsure. Journal submission was never easier. Get your personalized manuscript check report online and revise your manuscript to make it perfect. Explore new features like plagiarism check, journal recommender and downloadable word file with R Pubsure Pro Plan.Apr 30, 2021 \u00b7 Recommender systems are lifesavers in the infinite seething sea of ecommerce, improving customer experience. Recommender engines are eliminating the tyranny of choice, smoothing the way for Jun 02, 2019 \u00b7 Recommender systems are really critical in some industries as they can generate a huge amount of income when they are efficient or also be a way to stand out significantly from competitors. As a proof of the importance of recommender systems, we can mention that, a few years ago, Netflix organised a challenges (the \u201cNetflix prize\u201d) where Recommender systems can be defined as programs which attempt to recommend the most suitable items (products or services) to particular users (individuals or businesses) by predicting a user\u2019s interest in an item based on related information about the items, the users and the interactions between items and users [1]. TheRecommender Systems Based On Personality Traits: Could Human Psychological Aspects Influence The Computer Decision Making Process?|Maria Augusta Silveira Netto Nunes, Aiaa/Asme Adaptive Structures Forum: April 18-19, 1996/Salt Lake City, Ut|AIAA (American Institute Of Aeronautics, Alzheimers Disease (Encyclopedia Of Health)|William A. Check, ...Sep 27, 2010 \u00b7 Social recommender systems utilize data regarding users\u2019 social relationships in filtering relevant information to users. To date, results show that incorporating social relationship data \u2013 beyond consumption profile similarity \u2013 is beneficial only in a very limited set of cases. The main conjecture of this study is that the inconclusive results are, at least to some extent, due ...Nov 14, 2015 \u00b7 Recommender systems are defined as recommendation inputs given by the people, which the system then aggregates and directs to appropriate recipients. It can be further defined as a system that produces individualized recommendations as output or has the effect of guiding the user in a personalized way to interesting objects in a larger space of Jun 24, 2016 \u00b7 In this paper, we present Wide & Deep learning---jointly trained wide linear models and deep neural networks---to combine the benefits of memorization and generalization for recommender systems. We productionized and evaluated the system on Google Play, a commercial mobile app store with over one billion active users and over one million apps.Jan 28, 2009 \u00b7 On the topic of user preferences, recommender systems may also incorrectly label users \u2013 a la this classic Wall St Journal story from 2002, If TiVo Thinks You Are Gay, The 16th ACM Recommender Systems Conference will take place in Seattle from Sept. 18 23, 2022. Latest News Sept 30, 2021: RecSys 2022 will come back to the United States.Sep 26, 2021 \u00b7 The recommender systems face a problem in recommending items to users in case there is very little data available related to the user or item. This is called the cold-start problem. Here in this article, we will discuss the cold-start problems faced by the recommender system with their causes and approaches to overcome this issue.The Net?ix Recommender System: Algorithms, Business Value, and Innovation CARLOS A. GOMEZ-URIBE and NEIL HUNT, Net?ix, Inc. This article discusses the various algorithms that make up the Net?ix recommender system, and describes its business purpose. We also describe the role of search and related algorithms, which for us turns into a16. Recommender Systems\u00b6. Shuai Zhang (Amazon), Aston Zhang (Amazon), and Yi Tay (Google). Recommender systems are widely employed in industry and are ubiquitous in our daily lives. These systems are utilized in a number of areas such as online shopping sites (e.g., amazon.com), music/movie services site (e.g., Netflix and Spotify), mobile application stores ...Recommender Systems (RSs) are software tools and techniques providing suggestions for items to be of use to a user. In this introductory chapter we ...The ACM Recommender Systems conference (RecSys) is the premier international forum for the presentation of new research results, systems and techniques in the broad field of recommender systems. Recommendation is a particular form of information filtering, that exploits past behaviors and user similarities to generate a list of information May 09, 2018 \u00b7 Recommender systems have different ways of being evaluated and the answer which evaluation method to choose depends on your goal. If you're solely interested in recommending the top 5 items (i.e. the most probable items the user will interact with), you don\u2019t need to consider the predictions regarding the rest of the items when conducting the Nov 27, 2021 \u00b7 Building Recommender Systems with Machine Learning and AI: Help people discover new products and content with deep learning, neural networks, and machine learning recommendations, 2nd Edition. Learn how to build recommender systems from one of Amazon\u2019s pioneers in the field.Recommender systems usually make personalized recommendation with user-item interaction ratings, implicit feedback and auxiliary information. Matrix factorization is the basic idea to predict a per-sonalized ranking over a set of items for an indi-vidual user with the similarities among users and items. In this paper, we propose a novel matrixrecommender systems are attracting increasing attention. For ex-ample, Yu et al. [30] uses a heterogeneous information network to represent users, items, item attributes, and the interlinked relation-ships in a knowledge base. They extract meta-path based latentMay 01, 2019 \u00b7 Recommender systems keep customers on a businesses\u2019 site longer, they interact with more products/content, and it suggests products or content a customer is likely to purchase or engage with as a store sales associate might. Below, we\u2019ll show you what this repository is, and how it eases pain points for data scientists building and Recommender Systems and Personalization Datasets. Julian McAuley, UCSD. Description. This page contains a collection of datasets that have been collected for research by our lab. Datasets contain the following features: user/item interactions; star ratings; timestamps; product reviews; social networks; item-to-item relationships (e.g May 02, 2021 \u00b7 This article was published as a part of the Data Science Blogathon.. Introduction. With the ever-increasing data on the web over years, Recommender Systems (RS) have come in to the picture ranging from e-commerce to e-resource. Today, big giants like Netflix, Amazon, YouTube, etc. use RS to help users find information of use to improve their experience and ...recommender systems."
            },
            "slug": "Recommender-Systems-Ahrens",
            "title": {
                "fragments": [],
                "text": "Recommender Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Recommender systems can be defined as programs which attempt to recommend the most suitable items (products or services) to particular users (individuals or businesses) by predicting a user\u2019s interest in an item based on related information about the items, the users and the interactions between items and users."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747150"
                        ],
                        "name": "R. Burke",
                        "slug": "R.-Burke",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Burke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Burke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3970,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5880b9bc3f75f4649b8ec819c3f983a14fca9927",
            "isKey": false,
            "numCitedBy": 3923,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "Recommender systems represent user preferences for the purpose of suggesting items to purchase or examine. They have become fundamental applications in electronic commerce and information access, providing suggestions that effectively prune large information spaces so that users are directed toward those items that best meet their needs and preferences. A variety of techniques have been proposed for performing recommendation, including content-based, collaborative, knowledge-based and other techniques. To improve performance, these methods have sometimes been combined in hybrid recommenders. This paper surveys the landscape of actual and possible hybrid recommenders, and introduces a novel hybrid, EntreeC, a system that combines knowledge-based recommendation and collaborative filtering to recommend restaurants. Further, we show that semantic ratings obtained from the knowledge-based part of the system enhance the effectiveness of collaborative filtering."
            },
            "slug": "Hybrid-Recommender-Systems:-Survey-and-Experiments-Burke",
            "title": {
                "fragments": [],
                "text": "Hybrid Recommender Systems: Survey and Experiments"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper surveys the landscape of actual and possible hybrid recommenders, and introduces a novel hybrid, EntreeC, a system that combines knowledge-based recommendation and collaborative filtering to recommend restaurants, and shows that semantic ratings obtained from the knowledge- based part of the system enhance the effectiveness of collaborative filtering."
            },
            "venue": {
                "fragments": [],
                "text": "User Modeling and User-Adapted Interaction"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1814162"
                        ],
                        "name": "Peter Sunehag",
                        "slug": "Peter-Sunehag",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Sunehag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Sunehag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115604214"
                        ],
                        "name": "Richard Evans",
                        "slug": "Richard-Evans",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Evans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richard Evans"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1387885286"
                        ],
                        "name": "Gabriel Dulac-Arnold",
                        "slug": "Gabriel-Dulac-Arnold",
                        "structuredName": {
                            "firstName": "Gabriel",
                            "lastName": "Dulac-Arnold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gabriel Dulac-Arnold"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3185820"
                        ],
                        "name": "Yori Zwols",
                        "slug": "Yori-Zwols",
                        "structuredName": {
                            "firstName": "Yori",
                            "lastName": "Zwols",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yori Zwols"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40813836"
                        ],
                        "name": "D. Visentin",
                        "slug": "D.-Visentin",
                        "structuredName": {
                            "firstName": "Daniela",
                            "lastName": "Visentin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Visentin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48303781"
                        ],
                        "name": "Ben Coppin",
                        "slug": "Ben-Coppin",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Coppin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ben Coppin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[26] introduced agents that successfully address sequential decision problems with high-dimensional combinatorial state and action spaces."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 506846,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66c4c5d02093a1d1a82e877341da7f30ef5d3199",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Many real-world problems come with action spaces represented as feature vectors. Although high-dimensional control is a largely unsolved problem, there has recently been progress for modest dimensionalities. Here we report on a successful attempt at addressing problems of dimensionality as high as $2000$, of a particular form. Motivated by important applications such as recommendation systems that do not fit the standard reinforcement learning frameworks, we introduce Slate Markov Decision Processes (slate-MDPs). A Slate-MDP is an MDP with a combinatorial action space consisting of slates (tuples) of primitive actions of which one is executed in an underlying MDP. The agent does not control the choice of this executed action and the action might not even be from the slate, e.g., for recommendation systems for which all recommendations can be ignored. We use deep Q-learning based on feature representations of both the state and action to learn the value of whole slates. Unlike existing methods, we optimize for both the combinatorial and sequential aspects of our tasks. The new agent's superiority over agents that either ignore the combinatorial or sequential long-term value aspect is demonstrated on a range of environments with dynamics from a real-world recommendation system. Further, we use deep deterministic policy gradients to learn a policy that for each position of the slate, guides attention towards the part of the action space in which the value is the highest and we only evaluate actions in this area. The attention is used within a sequentially greedy procedure leveraging submodularity. Finally, we show how introducing risk-seeking can dramatically improve the agents performance and ability to discover more far reaching strategies."
            },
            "slug": "Deep-Reinforcement-Learning-with-Attention-for-with-Sunehag-Evans",
            "title": {
                "fragments": [],
                "text": "Deep Reinforcement Learning with Attention for Slate Markov Decision Processes with High-Dimensional States and Actions"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The new agent's superiority over agents that either ignore the combinatorial or sequential long-term value aspect is demonstrated on a range of environments with dynamics from a real-world recommendation system."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778725"
                        ],
                        "name": "J. Breese",
                        "slug": "J.-Breese",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Breese",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Breese"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099028"
                        ],
                        "name": "D. Heckerman",
                        "slug": "D.-Heckerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heckerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heckerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772349"
                        ],
                        "name": "C. Kadie",
                        "slug": "C.-Kadie",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Kadie",
                            "middleNames": [
                                "Myers"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Kadie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 215
                            }
                        ],
                        "text": "Collaborative filtering [13] is the most successful and the most widely used technique, which is based on the hypothesis that people often get the best recommendations from someone with similar tastes to themselves [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 29
                            }
                        ],
                        "text": "\u2022 CF: Collaborative filtering[3] is a method of making automatic predictions about the interests of a user by collecting preference information from many users, which is based on the hypothesis that people often get the best recommendations from someone with similar tastes to themselves."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2885948,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36b4a92c8eca6fd6d1b8588fc1fd0e3f89a16623",
            "isKey": false,
            "numCitedBy": 5689,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Collaborative filtering or recommender systems use a database about user preferences to predict additional topics or products a new user might like. In this paper we describe several algorithms designed for this task, including techniques based on correlation coefficients, vector-based similarity calculations, and statistical Bayesian methods. We compare the predictive accuracy of the various methods in a set of representative problem domains. We use two basic classes of evaluation metrics. The first characterizes accuracy over a set of individual predictions in terms of average absolute deviation. The second estimates the utility of a ranked list of suggested items. This metric uses an estimate of the probability that a user will see a recommendation in an ordered list. \n \nExperiments were run for datasets associated with 3 application areas, 4 experimental protocols, and the 2 evaluation metr rics for the various algorithms. Results indicate that for a wide range of conditions, Bayesian networks with decision trees at each node and correlation methods outperform Bayesian-clustering and vector-similarity methods. Between correlation and Bayesian networks, the preferred method depends on the nature of the dataset, nature of the application (ranked versus one-by-one presentation), and the availability of votes with which to make predictions. Other considerations include the size of database, speed of predictions, and learning time."
            },
            "slug": "Empirical-Analysis-of-Predictive-Algorithms-for-Breese-Heckerman",
            "title": {
                "fragments": [],
                "text": "Empirical Analysis of Predictive Algorithms for Collaborative Filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "Several algorithms designed for collaborative filtering or recommender systems are described, including techniques based on correlation coefficients, vector-based similarity calculations, and statistical Bayesian methods, to compare the predictive accuracy of the various methods in a set of representative problem domains."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680327"
                        ],
                        "name": "G. Dupret",
                        "slug": "G.-Dupret",
                        "structuredName": {
                            "firstName": "Georges",
                            "lastName": "Dupret",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Dupret"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703777"
                        ],
                        "name": "Benjamin Piwowarski",
                        "slug": "Benjamin-Piwowarski",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Piwowarski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Piwowarski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 59
                            }
                        ],
                        "text": "These skipped items influence user\u2019s click/order behaviors [6], which can help us gain better understandings about users\u2019 preferences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7992408,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4752e8858dd67002b16b281e115655307ec3c974",
            "isKey": false,
            "numCitedBy": 425,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Search engine click logs provide an invaluable source of relevance information but this information is biased because we ignore which documents from the result list the users have actually seen before and after they clicked. Otherwise, we could estimate document relevance by simple counting. In this paper, we propose a set of assumptions on user browsing behavior that allows the estimation of the probability that a document is seen, thereby providing an unbiased estimate of document relevance. To train, test and compare our model to the best alternatives described in the Literature, we gather a large set of real data and proceed to an extensive cross-validation experiment. Our solution outperforms very significantly all previous models. As a side effect, we gain insight into the browsing behavior of users and we can compare it to the conclusions of an eye-tracking experiments by Joachims et al. [12]. In particular, our findings confirm that a user almost always see the document directly after a clicked document. They also explain why documents situated just after a very relevant document are clicked more often."
            },
            "slug": "A-user-browsing-model-to-predict-search-engine-data-Dupret-Piwowarski",
            "title": {
                "fragments": [],
                "text": "A user browsing model to predict search engine click data from past observations."
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is confirmed that a user almost always see the document directly after a clicked document, and why documents situated just after a very relevant document are clicked more often is explained."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30182834"
                        ],
                        "name": "G. Linden",
                        "slug": "G.-Linden",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Linden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Linden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157122032"
                        ],
                        "name": "Brent Smith",
                        "slug": "Brent-Smith",
                        "structuredName": {
                            "firstName": "Brent",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brent Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073999382"
                        ],
                        "name": "J. York",
                        "slug": "J.-York",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "York",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. York"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "Collaborative filtering [13] is the most successful and the most widely used technique, which is based on the hypothesis that people often get the best recommendations from someone with similar tastes to themselves [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14604122,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "da8b0378174bc25ed174be36a1c725787b81854d",
            "isKey": false,
            "numCitedBy": 5536,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Recommendation algorithms are best known for their use on e-commerce Web sites, where they use input about a customer's interests to generate a list of recommended items. Many applications use only the items that customers purchase and explicitly rate to represent their interests, but they can also use other attributes, including items viewed, demographic data, subject interests, and favorite artists. At Amazon.com, we use recommendation algorithms to personalize the online store for each customer. The store radically changes based on customer interests, showing programming titles to a software engineer and baby toys to a new mother. There are three common approaches to solving the recommendation problem: traditional collaborative filtering, cluster models, and search-based methods. Here, we compare these methods with our algorithm, which we call item-to-item collaborative filtering. Unlike traditional collaborative filtering, our algorithm's online computation scales independently of the number of customers and number of items in the product catalog. Our algorithm produces recommendations in real-time, scales to massive data sets, and generates high quality recommendations."
            },
            "slug": "Amazon.com-Recommendations:-Item-to-Item-Filtering-Linden-Smith",
            "title": {
                "fragments": [],
                "text": "Amazon.com Recommendations: Item-to-Item Collaborative Filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work compares three common approaches to solving the recommendation problem: traditional collaborative filtering, cluster models, and search-based methods, and their algorithm, which is called item-to-item collaborative filtering."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Internet Comput."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797655"
                        ],
                        "name": "R. Mooney",
                        "slug": "R.-Mooney",
                        "structuredName": {
                            "firstName": "Raymond",
                            "lastName": "Mooney",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mooney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143747945"
                        ],
                        "name": "Loriene Roy",
                        "slug": "Loriene-Roy",
                        "structuredName": {
                            "firstName": "Loriene",
                            "lastName": "Roy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Loriene Roy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ely used technique, which is based on the hypothesis that people often get the best recommendations from someone with similar tastes to themselves[3]. Another common approach is contentbased filtering[17], which tries to recommend items with similar properties to those that a user ordered in the past. Knowledge-based systems[1] recommend items based on specific domain knowledge about how certain item "
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3261775,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "09622b0c84bf812814af5b64b0c83dce796899c4",
            "isKey": false,
            "numCitedBy": 1543,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "Recommender systems improve access to relevant products and information by making personalized suggestions based on previous examples of a user's likes and dislikes. Most existing recommender systems use collaborative filtering methods that base recommendations on other users' preferences. By contrast,content-based methods use information about an item itself to make suggestions.This approach has the advantage of being able to recommend previously unrated items to users with unique interests and to provide explanations for its recommendations. We describe a content-based book recommending system that utilizes information extraction and a machine-learning algorithm for text categorization. Initial experimental results demonstrate that this approach can produce accurate recommendations."
            },
            "slug": "Content-based-book-recommending-using-learning-for-Mooney-Roy",
            "title": {
                "fragments": [],
                "text": "Content-based book recommending using learning for text categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work describes a content-based book recommending system that utilizes information extraction and a machine-learning algorithm for text categorization and shows initial experimental results demonstrate that this approach can produce accurate recommendations."
            },
            "venue": {
                "fragments": [],
                "text": "DL '00"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2843982"
                        ],
                        "name": "Steffen Rendle",
                        "slug": "Steffen-Rendle",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Rendle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steffen Rendle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17265929,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df93596d4ed71d2863532c063c4c693711216abf",
            "isKey": false,
            "numCitedBy": 1819,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we introduce Factorization Machines (FM) which are a new model class that combines the advantages of Support Vector Machines (SVM) with factorization models. Like SVMs, FMs are a general predictor working with any real valued feature vector. In contrast to SVMs, FMs model all interactions between variables using factorized parameters. Thus they are able to estimate interactions even in problems with huge sparsity (like recommender systems) where SVMs fail. We show that the model equation of FMs can be calculated in linear time and thus FMs can be optimized directly. So unlike nonlinear SVMs, a transformation in the dual form is not necessary and the model parameters can be estimated directly without the need of any support vector in the solution. We show the relationship to SVMs and the advantages of FMs for parameter estimation in sparse settings. On the other hand there are many different factorization models like matrix factorization, parallel factor analysis or specialized models like SVD++, PITF or FPMC. The drawback of these models is that they are not applicable for general prediction tasks but work only with special input data. Furthermore their model equations and optimization algorithms are derived individually for each task. We show that FMs can mimic these models just by specifying the input data (i.e. the feature vectors). This makes FMs easily applicable even for users without expert knowledge in factorization models."
            },
            "slug": "Factorization-Machines-Rendle",
            "title": {
                "fragments": [],
                "text": "Factorization Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "Factorization Machines (FM) are introduced which are a new model class that combines the advantages of Support Vector Machines (SVM) with factorization models and can mimic these models just by specifying the input data (i.e. the feature vectors)."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE International Conference on Data Mining"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2768186"
                        ],
                        "name": "K. J\u00e4rvelin",
                        "slug": "K.-J\u00e4rvelin",
                        "structuredName": {
                            "firstName": "Kalervo",
                            "lastName": "J\u00e4rvelin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. J\u00e4rvelin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2732839"
                        ],
                        "name": "Jaana Kek\u00e4l\u00e4inen",
                        "slug": "Jaana-Kek\u00e4l\u00e4inen",
                        "structuredName": {
                            "firstName": "Jaana",
                            "lastName": "Kek\u00e4l\u00e4inen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jaana Kek\u00e4l\u00e4inen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 81
                            }
                        ],
                        "text": "As we consider our offline test task as a reranking task, we select MAP [29] and NDCG@40 [9] as the metrics to evaluate the performance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 89
                            }
                        ],
                        "text": "As we consider our offline test task as a reranking task, we select MAP [29] and NDCG@40 [9] as the metrics to evaluate"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1981391,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8490234d79b47e459824dcf87c1e288211a3c964",
            "isKey": false,
            "numCitedBy": 4079,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Modern large retrieval environments tend to overwhelm their users by their large output. Since all documents are not of equal relevance to their users, highly relevant documents should be identified and ranked first for presentation. In order to develop IR techniques in this direction, it is necessary to develop evaluation approaches and methods that credit IR methods for their ability to retrieve highly relevant documents. This can be done by extending traditional evaluation methods, that is, recall and precision based on binary relevance judgments, to graded relevance judgments. Alternatively, novel measures based on graded relevance judgments may be developed. This article proposes several novel measures that compute the cumulative gain the user obtains by examining the retrieval result up to a given ranked position. The first one accumulates the relevance scores of retrieved documents along the ranked result list. The second one is similar but applies a discount factor to the relevance scores in order to devaluate late-retrieved documents. The third one computes the relative-to-the-ideal performance of IR techniques, based on the cumulative gain they are able to yield. These novel measures are defined and discussed and their use is demonstrated in a case study using TREC data: sample system run results for 20 queries in TREC-7. As a relevance base we used novel graded relevance judgments on a four-point scale. The test results indicate that the proposed measures credit IR methods for their ability to retrieve highly relevant documents and allow testing of statistical significance of effectiveness differences. The graphs based on the measures also provide insight into the performance IR techniques and allow interpretation, for example, from the user point of view."
            },
            "slug": "Cumulated-gain-based-evaluation-of-IR-techniques-J\u00e4rvelin-Kek\u00e4l\u00e4inen",
            "title": {
                "fragments": [],
                "text": "Cumulated gain-based evaluation of IR techniques"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This article proposes several novel measures that compute the cumulative gain the user obtains by examining the retrieval result up to a given ranked position, and test results indicate that the proposed measures credit IR methods for their ability to retrieve highly relevant documents and allow testing of statistical significance of effectiveness differences."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40169260"
                        ],
                        "name": "F. Ricci",
                        "slug": "F.-Ricci",
                        "structuredName": {
                            "firstName": "Francesco",
                            "lastName": "Ricci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Ricci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732091"
                        ],
                        "name": "L. Rokach",
                        "slug": "L.-Rokach",
                        "structuredName": {
                            "firstName": "Lior",
                            "lastName": "Rokach",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rokach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762969"
                        ],
                        "name": "Bracha Shapira",
                        "slug": "Bracha-Shapira",
                        "structuredName": {
                            "firstName": "Bracha",
                            "lastName": "Shapira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bracha Shapira"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 181
                            }
                        ],
                        "text": "Recommender systems have become increasingly popular in recent years, and have been utilized in a variety of domains including movies, music, books, search queries, and social tags [23, 24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 35569873,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "24f1a3ec9d02abcd3b5ed7f511b9d8017213954a",
            "isKey": false,
            "numCitedBy": 2226,
            "numCiting": 128,
            "paperAbstract": {
                "fragments": [],
                "text": "Recommender Systems (RSs) are software tools and techniques providing suggestions for items to be of use to a user. In this introductory chapter we briefly discuss basic RS ideas and concepts. Our main goal is to delineate, in a coherent and structured way, the chapters included in this handbook and to help the reader navigate the extremely rich and detailed content that the handbook offers."
            },
            "slug": "Introduction-to-Recommender-Systems-Handbook-Ricci-Rokach",
            "title": {
                "fragments": [],
                "text": "Introduction to Recommender Systems Handbook"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The main goal is to delineate, in a coherent and structured way, the chapters included in this handbook and to help the reader navigate the extremely rich and detailed content that the handbook offers."
            },
            "venue": {
                "fragments": [],
                "text": "Recommender Systems Handbook"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39263338"
                        ],
                        "name": "Longxin Lin",
                        "slug": "Longxin-Lin",
                        "structuredName": {
                            "firstName": "Longxin",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Longxin Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "s according to Equation (5) or Equation (7) (lines 13-18). In the algorithm, we introduce widely used techniques to train our framework. For example, we utilize a technique known as experience replay [12] (lines 1,12), and introduce separated evaluation and target networks [16], which can help smooth the learning and Algorithm 1 Off-policy Training of DEERS Framework. 1: Initialize the capacity of rep"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60875658,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54c4cf3a8168c1b70f91cf78a3dc98b671935492",
            "isKey": false,
            "numCitedBy": 934,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "Reinforcement learning agents are adaptive, reactive, and self-supervised. The aim of this dissertation is to extend the state of the art of reinforcement learning and enable its applications to complex robot-learning problems. In particular, it focuses on two issues. First, learning from sparse and delayed reinforcement signals is hard and in general a slow process. Techniques for reducing learning time must be devised. Second, most existing reinforcement learning methods assume that the world is a Markov decision process. This assumption is too strong for many robot tasks of interest. \nThis dissertation demonstrates how we can possibly overcome the slow learning problem and tackle non-Markovian environments, making reinforcement learning more practical for realistic robot tasks: (1) Reinforcement learning can be naturally integrated with artificial neural networks to obtain high-quality generalization, resulting in a significant learning speedup. Neural networks are used in this dissertation, and they generalize effectively even in the presence of noise and a large of binary and real-valued inputs. (2) Reinforcement learning agents can save many learning trials by using an action model, which can be learned on-line. With a model, an agent can mentally experience the effects of its actions without actually executing them. Experience replay is a simple technique that implements this idea, and is shown to be effective in reducing the number of action executions required. (3) Reinforcement learning agents can take advantage of instructive training instances provided by human teachers, resulting in a significant learning speedup. Teaching can also help learning agents avoid local optima during the search for optimal control. Simulation experiments indicate that even a small amount of teaching can save agents many learning trials. (4) Reinforcement learning agents can significantly reduce learning time by hierarchical learning--they first solve elementary learning problems and then combine solutions to the elementary problems to solve a complex problem. Simulation experiments indicate that a robot with hierarchical learning can solve a complex problem, which otherwise is hardly solvable within a reasonable time. (5) Reinforcement learning agents can deal with a wide range of non-Markovian environments by having a memory of their past. Three memory architectures are discussed. They work reasonably well for a variety of simple problems. One of them is also successfully applied to a nontrivial non-Markovian robot task. \nThe results of this dissertation rely on computer simulation, including (1) an agent operating in a dynamic and hostile environment and (2) a mobile robot operating in a noisy and non-Markovian environment. The robot simulator is physically realistic. This dissertation concludes that it is possible to build artificial agents than can acquire complex control policies effectively by reinforcement learning."
            },
            "slug": "Reinforcement-learning-for-robots-using-neural-Lin",
            "title": {
                "fragments": [],
                "text": "Reinforcement learning for robots using neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This dissertation concludes that it is possible to build artificial agents than can acquire complex control policies effectively by reinforcement learning and enable its applications to complex robot-learning problems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3255983"
                        ],
                        "name": "Volodymyr Mnih",
                        "slug": "Volodymyr-Mnih",
                        "structuredName": {
                            "firstName": "Volodymyr",
                            "lastName": "Mnih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volodymyr Mnih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145824029"
                        ],
                        "name": "David Silver",
                        "slug": "David-Silver",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Silver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Silver"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2460849"
                        ],
                        "name": "Ioannis Antonoglou",
                        "slug": "Ioannis-Antonoglou",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Antonoglou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ioannis Antonoglou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688276"
                        ],
                        "name": "Daan Wierstra",
                        "slug": "Daan-Wierstra",
                        "structuredName": {
                            "firstName": "Daan",
                            "lastName": "Wierstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daan Wierstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3137672"
                        ],
                        "name": "Martin A. Riedmiller",
                        "slug": "Martin-A.-Riedmiller",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Riedmiller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin A. Riedmiller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 140
                            }
                        ],
                        "text": "For example, we utilize a technique known as experience replay [12] (lines 1,11,12), and introduce separated evaluation and target networks [16], which can help smooth the learning and avoid the divergence of parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 24
                            }
                        ],
                        "text": "For the architecture of Deep Q-network, we leverage a 5-layer neural network, in which the first 3 layers are separated for positive and negative signals, and the last 2 layers connects both positive and negative signals, and outputs the Q-value of a given state and action."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "\u2022 DEERS-p: We use a Deep Q-network[16] with embeddings of users\u2019 historical clicked/ordered items (state) and a recommended item (action) as input, and train this baseline following Eq."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15238391,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2319a491378867c7049b3da055c5df60e1671158",
            "isKey": true,
            "numCitedBy": 7462,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them."
            },
            "slug": "Playing-Atari-with-Deep-Reinforcement-Learning-Mnih-Kavukcuoglu",
            "title": {
                "fragments": [],
                "text": "Playing Atari with Deep Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This work presents the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning, which outperforms all previous approaches on six of the games and surpasses a human expert on three of them."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804488"
                        ],
                        "name": "T. Degris",
                        "slug": "T.-Degris",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Degris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Degris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144542337"
                        ],
                        "name": "Martha White",
                        "slug": "Martha-White",
                        "structuredName": {
                            "firstName": "Martha",
                            "lastName": "White",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martha White"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699645"
                        ],
                        "name": "R. Sutton",
                        "slug": "R.-Sutton",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Sutton",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sutton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 183
                            }
                        ],
                        "text": "For storing transitions stage: given the state st , the recommender agent first recommends an item at from a fixed off-policy b(st ) (line 7), which follows a standard off-policy way [5]; then the agent observes the reward rt from users (line 8) and updates the state to st+1 (line 9) and try to find the competitor item Algorithm 1 Off-policy Training of DEERS Framework."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10513082,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0067343a36c0292f36e627eb353f751c8a39f99a",
            "isKey": false,
            "numCitedBy": 326,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the first actor-critic algorithm for off-policy reinforcement learning. Our algorithm is online and incremental, and its per-time-step complexity scales linearly with the number of learned weights. Previous work on actor-critic algorithms is limited to the on-policy setting and does not take advantage of the recent advances in off-policy gradient temporal-difference learning. Off-policy techniques, such as Greedy-GQ, enable a target policy to be learned while following and obtaining data from another (behavior) policy. For many problems, however, actor-critic methods are more practical than action value methods (like Greedy-GQ) because they explicitly represent the policy; consequently, the policy can be stochastic and utilize a large action space. In this paper, we illustrate how to practically combine the generality and learning potential of off-policy learning with the flexibility in action selection given by actor-critic methods. We derive an incremental, linear time and space complexity algorithm that includes eligibility traces, prove convergence under assumptions similar to previous off-policy algorithms, and empirically show better or comparable performance to existing algorithms on standard reinforcement-learning benchmark problems."
            },
            "slug": "Off-Policy-Actor-Critic-Degris-White",
            "title": {
                "fragments": [],
                "text": "Off-Policy Actor-Critic"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper derives an incremental, linear time and space complexity algorithm that includes eligibility traces, proves convergence under assumptions similar to previous off-policy algorithms, and empirically show better or comparable performance to existing algorithms on standard reinforcement-learning benchmark problems."
            },
            "venue": {
                "fragments": [],
                "text": "ICML 2012"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735081"
                        ],
                        "name": "A. Turpin",
                        "slug": "A.-Turpin",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Turpin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Turpin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732541"
                        ],
                        "name": "F. Scholer",
                        "slug": "F.-Scholer",
                        "structuredName": {
                            "firstName": "Falk",
                            "lastName": "Scholer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Scholer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 68
                            }
                        ],
                        "text": "As we consider our offline test task as a reranking task, we select MAP [29] and NDCG@40 [9] as the metrics to evaluate the performance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "As we consider our offline test task as a reranking task, we select MAP [29] and NDCG@40 [9] as the metrics to evaluate"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9810253,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "84fcd3ce562b810b18a0dedb62b6144876939f97",
            "isKey": false,
            "numCitedBy": 388,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Several recent studies have demonstrated that the type of improvements in information retrieval system effectiveness reported in forums such as SIGIR and TREC do not translate into a benefit for users. Two of the studies used an instance recall task, and a third used a question answering task, so perhaps it is unsurprising that the precision based measures of IR system effectiveness on one-shot query evaluation do not correlate with user performance on these tasks. In this study, we evaluate two different information retrieval tasks on TREC Web-track data: a precision-based user task, measured by the length of time that users need to find a single document that is relevant to a TREC topic; and, a simple recall-based task, represented by the total number of relevant documents that users can identify within five minutes. Users employ search engines with controlled mean average precision (MAP) of between 55% and 95%. Our results show that there is no significant relationship between system effectiveness measured by MAP and the precision-based task. A significant, but weak relationship is present for the precision at one document returned metric. A weak relationship is present between MAP and the simple recall-based task."
            },
            "slug": "User-performance-versus-precision-measures-for-Turpin-Scholer",
            "title": {
                "fragments": [],
                "text": "User performance versus precision measures for simple search tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This study evaluates two different information retrieval tasks on TREC Web-track data: a precision-based user task, measured by the length of time that users need to find a single document that is relevant to a TREC topic; and, a simple recall-based task, represented by the total number of relevant documents that users can identify within five minutes."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731761"
                        ],
                        "name": "M. Hauskrecht",
                        "slug": "M.-Hauskrecht",
                        "structuredName": {
                            "firstName": "Milos",
                            "lastName": "Hauskrecht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hauskrecht"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ounded window of past history to define the current state. To reduce the high computational and representational complexity of POMDP, three strategies have been developed: value function approximation[7], policy based optimization [19, 21], and stochastic sampling [10]. Furthermore, Mahmood et al.[15] adopted the reinforcement learning technique to observe the responses of users in a conversational r"
                    },
                    "intents": []
                }
            ],
            "corpusId": 509727,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4ffa4488efaf9b348433d8acc675253e52793df",
            "isKey": false,
            "numCitedBy": 76,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Partially observable Markov decision processes (POMDPs) allow one to model complex dynamic decision or control problems that include both action outcome uncertainty and imperfect observability. The control problem is formulated as a dynamic optimization problem with a value function combining costs or rewards from multiple steps. In this paper we propose, analyse and test various incremental methods for computing bounds on the value function for control problems with infinite discounted horizon criteria. The methods described and tested include novel incremental versions of grid-based linear interpolation method and simple lower bound method with Sondik's updates. Both of these can work with arbitrary points of the belief space and can be enhanced by various heuristic point selection strategies. Also introduced is a new method for computing an initial upper bound - the fast informed bound method. This method is able to improve significantly on the standard and commonly used upper bound computed by the MDP-based method. The quality of resulting bounds are tested on a maze navigation problem with 20 states, 6 actions and 8 observations."
            },
            "slug": "Incremental-Methods-for-Computing-Bounds-in-Markov-Hauskrecht",
            "title": {
                "fragments": [],
                "text": "Incremental Methods for Computing Bounds in Partially Observable Markov Decision Processes"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Novel incremental versions of grid-based linear interpolation method and simple lower bound method with Sondik's updates are introduced and a new method for computing an initial upper bound - the fast informed bound method is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056642528"
                        ],
                        "name": "M. Kearns",
                        "slug": "M.-Kearns",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kearns",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kearns"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144830983"
                        ],
                        "name": "Y. Mansour",
                        "slug": "Y.-Mansour",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Mansour",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Mansour"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "uce the high computational and representational complexity of POMDP, three strategies have been developed: value function approximation[7], policy based optimization [19, 21], and stochastic sampling [10]. Furthermore, Mahmood et al.[15] adopted the reinforcement learning technique to observe the responses of users in a conversational recommender, with the aim to maximize a numerical cumulative reward"
                    },
                    "intents": []
                }
            ],
            "corpusId": 5390069,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9cbaf9fd844fc405a7d086cb942c8e2594937c08",
            "isKey": false,
            "numCitedBy": 606,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "A critical issue for the application of Markov decision processes (MDPs) to realistic problems is how the complexity of planning scales with the size of the MDP. In stochastic environments with very large or infinite state spaces, traditional planning and reinforcement learning algorithms may be inapplicable, since their running time typically grows linearly with the state space size in the worst case. In this paper we present a new algorithm that, given only a generative model (a natural and common type of simulator) for an arbitrary MDP, performs on-line, near-optimal planning with a per-state running time that has no dependence on the number of states. The running time is exponential in the horizon time (which depends only on the discount factor \u03b3 and the desired degree of approximation to the optimal policy). Our algorithm thus provides a different complexity trade-off than classical algorithms such as value iteration\u2014rather than scaling linearly in both horizon time and state space size, our running time trades an exponential dependence on the former in exchange for no dependence on the latter.Our algorithm is based on the idea of sparse sampling. We prove that a randomly sampled look-ahead tree that covers only a vanishing fraction of the full look-ahead tree nevertheless suffices to compute near-optimal actions from any state of an MDP. Practical implementations of the algorithm are discussed, and we draw ties to our related recent results on finding a near-best strategy from a given class of strategies in very large partially observable MDPs (Kearns, Mansour, & Ng. Neural information processing systems 13, to appear)."
            },
            "slug": "A-Sparse-Sampling-Algorithm-for-Near-Optimal-in-Kearns-Mansour",
            "title": {
                "fragments": [],
                "text": "A Sparse Sampling Algorithm for Near-Optimal Planning in Large Markov Decision Processes"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper presents a new algorithm that, given only a generative model (a natural and common type of simulator) for an arbitrary MDP, performs on-line, near-optimal planning with a per-state running time that has no dependence on the number of states."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760402"
                        ],
                        "name": "A. Moore",
                        "slug": "A.-Moore",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Moore",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8483722"
                        ],
                        "name": "C. Atkeson",
                        "slug": "C.-Atkeson",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Atkeson",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Atkeson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "s 1,11,12), and introduce separated evaluation and target networks [16], which can help smooth the learning and avoid the divergence of parameters. Moreover, we leverage prioritized sampling strategy [18] to assist the framework learning from the most important historical transitions. 3.4 Offline Test In the previous subsection, we have discussed how to train a DQNbased recommender model. Now we forma"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 38901226,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e21956fdbc06204db7984aacea09db7eda6355ad",
            "isKey": true,
            "numCitedBy": 434,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new algorithm, prioritized sweeping, for efficient prediction and control of stochastic Markov systems. Incremental learning methods such as temporal differencing and Q-learning have real-time performance. Classical methods are slower, but more accurate, because they make full use of the observations. Prioritized sweeping aims for the best of both worlds. It uses all previous experiences both to prioritize important dynamic programming sweeps and to guide the exploration of state-space. We compare prioritized sweeping with other reinforcement learning schemes for a number of different stochastic optimal control problems. It successfully solves large state-space real-time problems with which other methods have difficulty."
            },
            "slug": "Prioritized-Sweeping:-Reinforcement-Learning-with-Moore-Atkeson",
            "title": {
                "fragments": [],
                "text": "Prioritized Sweeping: Reinforcement Learning with Less Data and Less Time"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work presents a new algorithm, prioritized sweeping, for efficient prediction and control of stochastic Markov systems, which successfully solves large state-space real-time problems with which other methods have difficulty."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 172
                            }
                        ],
                        "text": "To reduce the high computational and representational complexity of POMDP, three strategies have been developed: value function approximation[7], policy based optimization [19, 21], and stochastic sampling [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11691568,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d51fe3976ab4f4dc60745433c8638a2ecc3bf123",
            "isKey": false,
            "numCitedBy": 488,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new approach to the problem of searching a space of policies for a Markov decision process (MDP) or a partially observable Markov decision process (POMDP), given a model. Our approach is based on the following observation: Any (PO)MDP can be transformed into an \"equivalent\" POMDP in which all state transitions (given the current state and action) are deterministic. This reduces the general problem of policy search to one in which we need only consider POMDPs with deterministic transitions. We give a natural way of estimating the value of all policies in these transformed POMDPs. Policy search is then simply performed by searching for a policy with high estimated value. We also establish conditions under which our value estimates will be good, recovering theoretical results similar to those of Kearns, Mansour and Ng [7], but with \"sample complexity\" bounds that have only a polynomial rather than exponential dependence on the horizon time. Our method applies to arbitrary POMDPs, including ones with infinite state and action spaces. We also present empirical results for our approach on a small discrete problem, and on a complex continuous state/continuous action problem involving learning to ride a bicycle."
            },
            "slug": "PEGASUS:-A-policy-search-method-for-large-MDPs-and-Ng-Jordan",
            "title": {
                "fragments": [],
                "text": "PEGASUS: A policy search method for large MDPs and POMDPs"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "This work proposes a new approach to the problem of searching a space of policies for a Markov decision process (MDP) or a partially observable Markov decisions process (POMDP), given a model, based on the following observation: Any (PO)MDP can be transformed into an \"equivalent\" POMDP in which all state transitions are deterministic."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715227"
                        ],
                        "name": "A. Kobsa",
                        "slug": "A.-Kobsa",
                        "structuredName": {
                            "firstName": "Alfred",
                            "lastName": "Kobsa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kobsa"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 110
                            }
                        ],
                        "text": "Hybrid recommender systems are based on the combination of the above mentioned two or more types of techniques[4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17528304,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "efd8eb52071f3c67c7cbb38417ad6544f04a4822",
            "isKey": false,
            "numCitedBy": 455,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "User modeling has made considerable progress during its existence now of more than a decade. Particularly in the last few years, the need has been recognized in many application areas for software systems to automatically adapt to their current users. As a result, research on user modeling has extended into many disciplines which are concerned with the development of interactive computer systems that are used by heterogeneous user populations. These fields include Intelligent Interfaces, Active and Passive Help Systems, Guidance Systems, Hypertext Systems, Intelligent Information Retrieval, Natural-Language Systems, Intelligent Tutoring Systems, and Cooperative Expert Systems. Applications in office machines, consumer electronics and automobiles are also being envisioned. Several recent empirical evaluations provide support for the usefulness of user-adaptation in the investigated application domains."
            },
            "slug": "User-Modeling-and-User-Adapted-Interaction-Kobsa",
            "title": {
                "fragments": [],
                "text": "User Modeling and User-Adapted Interaction"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Several recent empirical evaluations provide support for the usefulness of user-adaptation in the investigated application domains."
            },
            "venue": {
                "fragments": [],
                "text": "User Modeling and User-Adapted Interaction"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1807041"
                        ],
                        "name": "P. Poupart",
                        "slug": "P.-Poupart",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Poupart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Poupart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145646162"
                        ],
                        "name": "Craig Boutilier",
                        "slug": "Craig-Boutilier",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Boutilier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Craig Boutilier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "o define the current state. To reduce the high computational and representational complexity of POMDP, three strategies have been developed: value function approximation[7], policy based optimization [19, 21], and stochastic sampling [10]. Furthermore, Mahmood et al.[15] adopted the reinforcement learning technique to observe the responses of users in a conversational recommender, with the aim to maximize"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2753517,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "034aa3cd119f2be0b3195c84707db031dc362cba",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Existing algorithms for discrete partially observable Markov decision processes can at best solve problems of a few thousand states due to two important sources of intractability: the curse of dimensionality and the policy space complexity. This paper describes a new algorithm (VDCBPI) that mitigates both sources of intractability by combining the Value Directed Compression (VDC) technique [13] with Bounded Policy Iteration (BPI) [14]. The scalability of VDCBPI is demonstrated on synthetic network management problems with up to 33 million states."
            },
            "slug": "VDCBPI:-an-Approximate-Scalable-Algorithm-for-Large-Poupart-Boutilier",
            "title": {
                "fragments": [],
                "text": "VDCBPI: an Approximate Scalable Algorithm for Large POMDPs"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new algorithm (VDCBPI) that mitigates both sources of intractability by combining the Value Directed Compression (VDC) technique with Bounded Policy Iteration (BPI) is described."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144873562"
                        ],
                        "name": "R. Bellman",
                        "slug": "R.-Bellman",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Bellman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bellman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "he expected return based on state s and action a. The optimal action-value function Q\u2217(s,a), which has the maximum expected return achievable by the optimal policy, should follow the Bellman equation [2] as: Q\u2217(s,a)= Es\u2032 r +\u03b3max a\u2032 Q\u2217(s\u2032,a\u2032)|s,a . (1) In real recommender systems, the state and action spaces are enormous, thus estimating the action-value function Q\u2217(s,a)by usingtheBellmanequationforea"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 24158615,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "a4361a4bd93e207fb4cf263a63c24ead39cc2076",
            "isKey": false,
            "numCitedBy": 7971,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Little has been done in the study of these intriguing questions, and I do not wish to give the impression that any extensive set of ideas exists that could be called a \"theory.\" What is quite surprising, as far as the histories of science and philosophy are concerned, is that the major impetus for the fantastic growth of interest in brain processes, both psychological and physiological, has come from a device, a machine, the digital computer. In dealing with a human being and a human society, we enjoy the luxury of being irrational, illogical, inconsistent, and incomplete, and yet of coping. In operating a computer, we must meet the rigorous requirements for detailed instructions and absolute precision. If we understood the ability of the human mind to make effective decisions when confronted by complexity, uncertainty, and irrationality then we could use computers a million times more effectively than we do. Recognition of this fact has been a motivation for the spurt of research in the field of neurophysiology. The more we study the information processing aspects of the mind, the more perplexed and impressed we become. It will be a very long time before we understand these processes sufficiently to reproduce them. In any case, the mathematician sees hundreds and thousands of formidable new problems in dozens of blossoming areas, puzzles galore, and challenges to his heart's content. He may never resolve some of these, but he will never be bored. What more can he ask?"
            },
            "slug": "Dynamic-Programming-Bellman",
            "title": {
                "fragments": [],
                "text": "Dynamic Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The more the authors study the information processing aspects of the mind, the more perplexed and impressed they become, and it will be a very long time before they understand these processes sufficiently to reproduce them."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1966
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1854500"
                        ],
                        "name": "R. Akerkar",
                        "slug": "R.-Akerkar",
                        "structuredName": {
                            "firstName": "Rajendra",
                            "lastName": "Akerkar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Akerkar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2482430"
                        ],
                        "name": "P. Sajja",
                        "slug": "P.-Sajja",
                        "structuredName": {
                            "firstName": "Priti",
                            "lastName": "Sajja",
                            "middleNames": [
                                "Srinivas"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sajja"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 23
                            }
                        ],
                        "text": "Knowledge-based systems[1] recommend items based on specific domain knowledge about how certain item features meet users needs and preferences and how the item is useful for the user."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5817219,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d9e3125df2a6373664b53fe042d193b04e9d6c99",
            "isKey": false,
            "numCitedBy": 654,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Knowledge Based Systems (KBS) are systems that use artificial intelligence techniques in the problem solving process. This text is designed to develop an appreciation of KBS and their architecture and to help users understand a broad variety of knowledge based techniques for decision support and planning. It assumes basic computer science skills and a math background that includes set theory, relations, elementary probability, and introductory concepts of artificial intelligence. Each of the 12 chapters are designed to be modular providing instructors with the flexibility to model the book to their own course needs. Exercises are incorporated throughout the text to highlight certain aspects of the material being presented and to stimulate thought and discussion."
            },
            "slug": "Knowledge-Based-Systems-Akerkar-Sajja",
            "title": {
                "fragments": [],
                "text": "Knowledge Based Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This text is designed to develop an appreciation of KBS and their architecture and to help users understand a broad variety of knowledge based techniques for decision support and planning."
            },
            "venue": {
                "fragments": [],
                "text": "Encyclopedia of GIS"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708077"
                        ],
                        "name": "S. Eddy",
                        "slug": "S.-Eddy",
                        "structuredName": {
                            "firstName": "Sean",
                            "lastName": "Eddy",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Eddy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5352062,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ff45297a6643f88389e8993229b1c27dfed93768",
            "isKey": false,
            "numCitedBy": 4677,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "Sequence alignment methods often use something called a 'dynamic programming' algorithm. What is dynamic programming and how does it work?"
            },
            "slug": "What-is-dynamic-programming-Eddy",
            "title": {
                "fragments": [],
                "text": "What is dynamic programming?"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "Sequence alignment methods often use something called a 'dynamic programming' algorithm, which can be a good idea or a bad idea, depending on the method used."
            },
            "venue": {
                "fragments": [],
                "text": "Nature Biotechnology"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765710"
                        ],
                        "name": "Sai Wu",
                        "slug": "Sai-Wu",
                        "structuredName": {
                            "firstName": "Sai",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sai Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3419100"
                        ],
                        "name": "Weichao Ren",
                        "slug": "Weichao-Ren",
                        "structuredName": {
                            "firstName": "Weichao",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weichao Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116576876"
                        ],
                        "name": "Chengchao Yu",
                        "slug": "Chengchao-Yu",
                        "structuredName": {
                            "firstName": "Chengchao",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chengchao Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46965289"
                        ],
                        "name": "Gang Chen",
                        "slug": "Gang-Chen",
                        "structuredName": {
                            "firstName": "Gang",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gang Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2712862"
                        ],
                        "name": "D. Zhang",
                        "slug": "D.-Zhang",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1410028038"
                        ],
                        "name": "Jing Zhu",
                        "slug": "Jing-Zhu",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Zhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[31] designed a session-based recommendation model for real-world ecommerce website."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14507813,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39a4dba0230ed0dfb60f03db59a808dd4f5bbd42",
            "isKey": false,
            "numCitedBy": 116,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Each user session in an e-commerce system can be modeled as a sequence of web pages, indicating how the user interacts with the system and makes his/her purchase. A typical recommendation approach, e.g., Collaborative Filtering, generates its results at the beginning of each session, listing the most likely purchased items. However, such approach fails to exploit current viewing history of the user and hence, is unable to provide a real-time customized recommendation service. In this paper, we build a deep recurrent neural network to address the problem. The network tracks how users browse the website using multiple hidden layers. Each hidden layer models how the combinations of webpages are accessed and in what order. To reduce the processing cost, the network only records a finite number of states, while the old states collapse into a single history state. Our model refreshes the recommendation result each time when user opens a new web page. As user's session continues, the recommendation result is gradually refined. Furthermore, we integrate the recurrent neural network with a Feedfoward network which represents the user-item correlations to increase the prediction accuracy. Our approach has been applied to Kaola (http://www.kaola.com), an e-commerce website powered by the NetEase technologies. It shows a significant improvement over previous recommendation service."
            },
            "slug": "Personal-recommendation-using-deep-recurrent-neural-Wu-Ren",
            "title": {
                "fragments": [],
                "text": "Personal recommendation using deep recurrent neural networks in NetEase"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A deep recurrent neural network is built which represents the user-item correlations to increase the prediction accuracy and refreshes the recommendation result each time when user opens a new web page."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE 32nd International Conference on Data Engineering (ICDE)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39455775"
                        ],
                        "name": "Omer Levy",
                        "slug": "Omer-Levy",
                        "structuredName": {
                            "firstName": "Omer",
                            "lastName": "Levy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Omer Levy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2089067"
                        ],
                        "name": "Yoav Goldberg",
                        "slug": "Yoav-Goldberg",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Goldberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoav Goldberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "story. We treat each item as a word and the clicked items in one recommendation session as a sentence. Then, we can obtain dense and low-dimensional vector representations for items via word embedding[11]. !&quot;#$%%&quot;&amp;&apos;&quot;() *+&quot;&amp;, -.&quot;( !&quot;#$%&amp;&apos; ! &quot; ()$)&quot;&apos; # &quot; *+),-.&apos; $ &quot; # &quot;%&amp; ! Figure 2: The agent-user interactions in"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1190093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4c018bcc8ea707b83247866bdc8ccb87cd9f5da",
            "isKey": false,
            "numCitedBy": 1632,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We analyze skip-gram with negative-sampling (SGNS), a word embedding method introduced by Mikolov et al., and show that it is implicitly factorizing a word-context matrix, whose cells are the pointwise mutual information (PMI) of the respective word and context pairs, shifted by a global constant. We find that another embedding method, NCE, is implicitly factorizing a similar matrix, where each cell is the (shifted) log conditional probability of a word given its context. We show that using a sparse Shifted Positive PMI word-context matrix to represent words improves results on two word similarity tasks and one of two analogy tasks. When dense low-dimensional vectors are preferred, exact factorization with SVD can achieve solutions that are at least as good as SGNS's solutions for word similarity tasks. On analogy questions SGNS remains superior to SVD. We conjecture that this stems from the weighted nature of SGNS's factorization."
            },
            "slug": "Neural-Word-Embedding-as-Implicit-Matrix-Levy-Goldberg",
            "title": {
                "fragments": [],
                "text": "Neural Word Embedding as Implicit Matrix Factorization"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that using a sparse Shifted Positive PMI word-context matrix to represent words improves results on two word similarity tasks and one of two analogy tasks, and conjecture that this stems from the weighted nature of SGNS's factorization."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": ""
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": ""
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": ""
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dynamic programming. Courier Corporation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2013
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": ""
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": ""
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2013
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": ""
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "[33, 34] propose a novel page-wise recommendation framework based on deep reinforcement learning, which can optimize a page of items with proper display based on real-time feedback from users."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Deep Reinforcement Learning for List-wise Recommendations. arXiv preprint arXiv:1801.00209 (2017)"
            },
            "venue": {
                "fragments": [],
                "text": "Applied Data Science Track Paper  KDD 2018,"
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": ""
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2018
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": ""
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[5]; then the agent observes the reward rt from users (line 8) and updates the state to st+1 (line 9) and try to find the competitor item at (line 10); and finally the recommender agent stores transitions (st ,at , rt , st+1,at /null) into replay memory D (line 11)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Off-policy actorcritic"
            },
            "venue": {
                "fragments": [],
                "text": "arXiv preprint arXiv:1205.4839"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": ""
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": ""
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": ""
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": ""
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": ""
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": ""
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": ""
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 22,
            "methodology": 14
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 55,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Recommendations-with-Negative-Feedback-via-Pairwise-Zhao-Zhang/ef08ad10d257fcf5043d27d7225d6ec14a677a84?sort=total-citations"
}