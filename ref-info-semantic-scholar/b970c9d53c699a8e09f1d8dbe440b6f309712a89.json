{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706809"
                        ],
                        "name": "Marc'Aurelio Ranzato",
                        "slug": "Marc'Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Marc'Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc'Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 41
                            }
                        ],
                        "text": ", 2008) or using unsupervised objectives (Ranzato et al., 2007b; Kavukcuoglu et al., 2009; Jarrett et al., 2009; Lee et al., 2009)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 148
                            }
                        ],
                        "text": "However, recent works have focused on training with an auxiliary task (Ahmed et al., 2008) or using unsupervised objectives (Ranzato et al., 2007b; Kavukcuoglu et al., 2009; Jarrett et al., 2009; Lee et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 152
                            }
                        ],
                        "text": "In some recent versions of ConvNets, the pooling also pools similar features at the same location, in addition to the same feature at nearby locations (Kavukcuoglu et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10516905,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54a9c2553138932426faebcaa67a63a84a56b55d",
            "isKey": false,
            "numCitedBy": 314,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Several recently-proposed architectures for high-performance object recognition are composed of two main stages: a feature extraction stage that extracts locally-invariant feature vectors from regularly spaced image patches, and a somewhat generic supervised classifier. The first stage is often composed of three main modules: (1) a bank of filters (often oriented edge detectors); (2) a non-linear transform, such as a point-wise squashing functions, quantization, or normalization; (3) a spatial pooling operation which combines the outputs of similar filters over neighboring regions. We propose a method that automatically learns such feature extractors in an unsupervised fashion by simultaneously learning the filters and the pooling units that combine multiple filter outputs together. The method automatically generates topographic maps of similar filters that extract features of orientations, scales, and positions. These similar filters are pooled together, producing locally-invariant outputs. The learned feature descriptors give comparable results as SIFT on image recognition tasks for which SIFT is well suited, and better results than SIFT on tasks for which SIFT is less well suited."
            },
            "slug": "Learning-invariant-features-through-topographic-Kavukcuoglu-Ranzato",
            "title": {
                "fragments": [],
                "text": "Learning invariant features through topographic filter maps"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work proposes a method that automatically learns feature extractors in an unsupervised fashion by simultaneously learning the filters and the pooling units that combine multiple filter outputs together."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256269"
                        ],
                        "name": "C. Farabet",
                        "slug": "C.-Farabet",
                        "structuredName": {
                            "firstName": "Cl\u00e9ment",
                            "lastName": "Farabet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Farabet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35130633"
                        ],
                        "name": "Cyril Poulet",
                        "slug": "Cyril-Poulet",
                        "structuredName": {
                            "firstName": "Cyril",
                            "lastName": "Poulet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cyril Poulet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2183554"
                        ],
                        "name": "Jefferson Y. Han",
                        "slug": "Jefferson-Y.-Han",
                        "structuredName": {
                            "firstName": "Jefferson",
                            "lastName": "Han",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jefferson Y. Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 67
                            }
                        ],
                        "text": "The pipelined implementation of this 2D convolver (as described in Farabet et al. (2009)), computes Equation 8 at every clock cycle.\ny1,i,j = x2,i,j +\nK\u22121\u2211\nm=0\nK\u22121\u2211\nn=0\nx1,i+m,j+nw1,m,n (8)\nIn equation 8 x1,i,j is a value in the input plane, w1,m,n is a value in a K\u00d7K convolution kernel, x2,i,j is\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 107
                            }
                        ],
                        "text": "It can also perform on-thefly subsampling (spatial pooling), and simple dot-products (linear classifiers) (Farabet et al., 2009),\n\u2022 the middle row PTs contain general purpose operators (squaring and dividing are necessary for divisive normalization),\n\u2022 the bottom row PTs implement non-linear\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5339694,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "07956c7cf9bf4267b86d52aa4143c17a4aa5d0d6",
            "isKey": false,
            "numCitedBy": 328,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional Networks (ConvNets) are biologicallyinspired hierarchical architectures that can be trained to perform a variety of detection, recognition and segmentation tasks. ConvNets have a feed-forward architecture consisting of multiple linear convolution filters interspersed with pointwise non-linear squashing functions. This paper presents an efficient implementation of ConvNets on a low-end DSPoriented Field Programmable Gate Array (FPGA). The implementation exploits the inherent parallelism of ConvNets and takes full advantage of multiple hardware multiplyaccumulate units on the FPGA. The entire system uses a single FPGA with an external memory module, and no extra parts. A network compiler software was implemented, which takes a description of a trained ConvNet and compiles it into a sequence of instructions for the ConvNet Processor (CNP). A ConvNet face detection system was implemented and tested. Face detection on a 512 \u00d7 384 frame takes 100ms (10 frames per second), which corresponds to an average performance of 3.4\u00d7109 connections per second for this 340 million connection network. The design can be used for low-power, lightweight embedded vision systems for micro-UAVs and other small robots."
            },
            "slug": "CNP:-An-FPGA-based-processor-for-Convolutional-Farabet-Poulet",
            "title": {
                "fragments": [],
                "text": "CNP: An FPGA-based processor for Convolutional Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The implementation exploits the inherent parallelism of ConvNets and takes full advantage of multiple hardware multiplyaccumulate units on the FPGA and can be used for low-power, lightweight embedded vision systems for micro-UAVs and other small robots."
            },
            "venue": {
                "fragments": [],
                "text": "2009 International Conference on Field Programmable Logic and Applications"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13919023"
                        ],
                        "name": "F. Huang",
                        "slug": "F.-Huang",
                        "structuredName": {
                            "firstName": "Fu",
                            "lastName": "Huang",
                            "middleNames": [
                                "Jie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 28
                            }
                        ],
                        "text": "In LeCun et al. (1998b) and Huang and LeCun (2006), pure supervised learning is used to update the parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9123239,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cf03fdf52dd6e4249cbbdbd0bffbbbe5ca389feb",
            "isKey": false,
            "numCitedBy": 349,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "The detection and recognition of generic object categories with invariance to viewpoint, illumination, and clutter requires the combination of a feature extractor and a classifier. We show that architectures such as convolutional networks are good at learning invariant features, but not always optimal for classification, while Support Vector Machines are good at producing decision surfaces from wellbehaved feature vectors, but cannot learn complicated invariances. We present a hybrid system where a convolutional network is trained to detect and recognize generic objects, and a Gaussian-kernel SVM is trained from the features learned by the convolutional network. Results are given on a large generic object recognition task with six categories (human figures, four-legged animals, airplanes, trucks, cars, and \"none of the above\"), with multiple instances of each object category under various poses, illuminations, and backgrounds. On the test set, which contains different object instances than the training set, an SVM alone yields a 43.3% error rate, a convolutional net alone yields 7.2% and an SVM on top of features produced by the convolutional net yields 5.9%."
            },
            "slug": "Large-scale-Learning-with-SVM-and-Convolutional-for-Huang-LeCun",
            "title": {
                "fragments": [],
                "text": "Large-scale Learning with SVM and Convolutional for Generic Object Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that architectures such as convolutional networks are good at learning invariant features, but not always optimal for classification, while Support Vector Machines are good for producing decision surfaces from wellbehaved feature vectors, but cannot learn complicated invariances."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2077257730"
                        ],
                        "name": "Kevin Jarrett",
                        "slug": "Kevin-Jarrett",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Jarrett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Jarrett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706809"
                        ],
                        "name": "Marc'Aurelio Ranzato",
                        "slug": "Marc'Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Marc'Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc'Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 3
                            }
                        ],
                        "text": "In Jarrett et al. (2009), using abs and normalization non-linearities, unsupervised pre-training, and supervised global refinement has been shown to yield excellent performance on the Caltech-101 dataset with only 30 training samples per category (more on this below)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 41
                            }
                        ],
                        "text": ", 2008) or using unsupervised objectives (Ranzato et al., 2007b; Kavukcuoglu et al., 2009; Jarrett et al., 2009; Lee et al., 2009)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 174
                            }
                        ],
                        "text": "However, recent works have focused on training with an auxiliary task (Ahmed et al., 2008) or using unsupervised objectives (Ranzato et al., 2007b; Kavukcuoglu et al., 2009; Jarrett et al., 2009; Lee et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 62
                            }
                        ],
                        "text": "A more detailed study on this particular case can be found in Jarrett et al. (2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206769720,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f88427d7aa8225e47f946ac41a0667d7b69ac52",
            "isKey": false,
            "numCitedBy": 2093,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "In many recent object recognition systems, feature extraction stages are generally composed of a filter bank, a non-linear transformation, and some sort of feature pooling layer. Most systems use only one stage of feature extraction in which the filters are hard-wired, or two stages where the filters in one or both stages are learned in supervised or unsupervised mode. This paper addresses three questions: 1. How does the non-linearities that follow the filter banks influence the recognition accuracy? 2. does learning the filter banks in an unsupervised or supervised manner improve the performance over random filters or hardwired filters? 3. Is there any advantage to using an architecture with two stages of feature extraction, rather than one? We show that using non-linearities that include rectification and local contrast normalization is the single most important ingredient for good accuracy on object recognition benchmarks. We show that two stages of feature extraction yield better accuracy than one. Most surprisingly, we show that a two-stage system with random filters can yield almost 63% recognition rate on Caltech-101, provided that the proper non-linearities and pooling layers are used. Finally, we show that with supervised refinement, the system achieves state-of-the-art performance on NORB dataset (5.6%) and unsupervised pre-training followed by supervised refinement produces good accuracy on Caltech-101 (\u226b 65%), and the lowest known error rate on the undistorted, unprocessed MNIST dataset (0.53%)."
            },
            "slug": "What-is-the-best-multi-stage-architecture-for-Jarrett-Kavukcuoglu",
            "title": {
                "fragments": [],
                "text": "What is the best multi-stage architecture for object recognition?"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is shown that using non-linearities that include rectification and local contrast normalization is the single most important ingredient for good accuracy on object recognition benchmarks and that two stages of feature extraction yield better accuracy than one."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13919023"
                        ],
                        "name": "F. Huang",
                        "slug": "F.-Huang",
                        "structuredName": {
                            "firstName": "Fu",
                            "lastName": "Huang",
                            "middleNames": [
                                "Jie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 27
                            }
                        ],
                        "text": "Multiple object detection (LeCun et al., 2004) or online learning for adaptive robot guidance (Hadsell et al., 2009) are tasks that will be largely improved by this system."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 26
                            }
                        ],
                        "text": "Multiple object detection (LeCun et al., 2004) or online learning for adaptive robot guidance (Hadsell et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 712708,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f354310098e09c1e1dc88758fca36767fd9d084d",
            "isKey": false,
            "numCitedBy": 1321,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We assess the applicability of several popular learning methods for the problem of recognizing generic visual categories with invariance to pose, lighting, and surrounding clutter. A large dataset comprising stereo image pairs of 50 uniform-colored toys under 36 azimuths, 9 elevations, and 6 lighting conditions was collected (for a total of 194,400 individual images). The objects were 10 instances of 5 generic categories: four-legged animals, human figures, airplanes, trucks, and cars. Five instances of each category were used for training, and the other five for testing. Low-resolution grayscale images of the objects with various amounts of variability and surrounding clutter were used for training and testing. Nearest neighbor methods, support vector machines, and convolutional networks, operating on raw pixels or on PCA-derived features were tested. Test error rates for unseen object instances placed on uniform backgrounds were around 13% for SVM and 7% for convolutional nets. On a segmentation/recognition task with highly cluttered images, SVM proved impractical, while convolutional nets yielded 16/7% error. A real-time version of the system was implemented that can detect and classify objects in natural scenes at around 10 frames per second."
            },
            "slug": "Learning-methods-for-generic-object-recognition-to-LeCun-Huang",
            "title": {
                "fragments": [],
                "text": "Learning methods for generic object recognition with invariance to pose and lighting"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A real-time version of the system was implemented that can detect and classify objects in natural scenes at around 10 frames per second and proved impractical, while convolutional nets yielded 16/7% error."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706809"
                        ],
                        "name": "Marc'Aurelio Ranzato",
                        "slug": "Marc'Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Marc'Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc'Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13919023"
                        ],
                        "name": "F. Huang",
                        "slug": "F.-Huang",
                        "structuredName": {
                            "firstName": "Fu",
                            "lastName": "Huang",
                            "middleNames": [
                                "Jie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "90841478"
                        ],
                        "name": "Y-Lan Boureau",
                        "slug": "Y-Lan-Boureau",
                        "structuredName": {
                            "firstName": "Y-Lan",
                            "lastName": "Boureau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y-Lan Boureau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 125
                            }
                        ],
                        "text": "However, recent works have focused on training with an auxiliary task (Ahmed et al., 2008) or using unsupervised objectives (Ranzato et al., 2007b; Kavukcuoglu et al., 2009; Jarrett et al., 2009; Lee et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 51
                            }
                        ],
                        "text": "The best previously reported error rate was 0.60% (Ranzato et al., 2007a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 87
                            }
                        ],
                        "text": "Recent research in deep learning (Hinton and Salakhutdinov, 2006; Bengio et al., 2007; Ranzato et al., 2007a) has shown that unsupervised learning can be used to train each stage one after the other using only unlabeled data, reducing the requirement for labeled\nsamples significantly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11398758,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ccd52aff02b0f902f4ce7247c4fee7273014c41c",
            "isKey": false,
            "numCitedBy": 1093,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an unsupervised method for learning a hierarchy of sparse feature detectors that are invariant to small shifts and distortions. The resulting feature extractor consists of multiple convolution filters, followed by a feature-pooling layer that computes the max of each filter output within adjacent windows, and a point-wise sigmoid non-linearity. A second level of larger and more invariant features is obtained by training the same algorithm on patches of features from the first level. Training a supervised classifier on these features yields 0.64% error on MNIST, and 54% average recognition rate on Caltech 101 with 30 training samples per category. While the resulting architecture is similar to convolutional networks, the layer-wise unsupervised training procedure alleviates the over-parameterization problems that plague purely supervised learning procedures, and yields good performance with very few labeled training samples."
            },
            "slug": "Unsupervised-Learning-of-Invariant-Feature-with-to-Ranzato-Huang",
            "title": {
                "fragments": [],
                "text": "Unsupervised Learning of Invariant Feature Hierarchies with Applications to Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "An unsupervised method for learning a hierarchy of sparse feature detectors that are invariant to small shifts and distortions that alleviates the over-parameterization problems that plague purely supervised learning procedures, and yields good performance with very few labeled training samples."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144723337"
                        ],
                        "name": "Christophe Garcia",
                        "slug": "Christophe-Garcia",
                        "structuredName": {
                            "firstName": "Christophe",
                            "lastName": "Garcia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christophe Garcia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1812064"
                        ],
                        "name": "M. Delakis",
                        "slug": "M.-Delakis",
                        "structuredName": {
                            "firstName": "Manolis",
                            "lastName": "Delakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Delakis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 148
                            }
                        ],
                        "text": "\u2026et al., 2003; Chellapilla et al., 2006),\n\u2022 detection in images, including faces with record accuracy and real-time performance (Vaillant et al., 1994; Garcia and Delakis, 2004; Osadchy et al., 2007; Nasse et al., 2009), license plates and faces in Google\u2019s StreetView (Frome et al., 2009), or\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 95
                            }
                        ],
                        "text": ", 2006), \u2022 detection in images, including faces with record accuracy and real-time performance (Vaillant et al., 1994; Garcia and Delakis, 2004; Osadchy et al., 2007; Nasse et al., 2009), license plates and faces in Google\u2019s StreetView (Frome et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2557058,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68a859142ef42196e6a56305b8c6ac4cb2c9326e",
            "isKey": false,
            "numCitedBy": 587,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a novel face detection approach based on a convolutional neural architecture, designed to robustly detect highly variable face patterns, rotated up to /spl plusmn/20 degrees in image plane and turned up to /spl plusmn/60 degrees, in complex real world images. The proposed system automatically synthesizes simple problem-specific feature extractors from a training set of face and nonface patterns, without making any assumptions or using any hand-made design concerning the features to extract or the areas of the face pattern to analyze. The face detection procedure acts like a pipeline of simple convolution and subsampling modules that treat the raw input image as a whole. We therefore show that an efficient face detection system does not require any costly local preprocessing before classification of image areas. The proposed scheme provides very high detection rate with a particularly low level of false positives, demonstrated on difficult test sets, without requiring the use of multiple networks for handling difficult cases. We present extensive experimental results illustrating the efficiency of the proposed approach on difficult test sets and including an in-depth sensitivity analysis with respect to the degrees of variability of the face patterns."
            },
            "slug": "Convolutional-face-finder:-a-neural-architecture-Garcia-Delakis",
            "title": {
                "fragments": [],
                "text": "Convolutional face finder: a neural architecture for fast and robust face detection"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that an efficient face detection system does not require any costly local preprocessing before classification of image areas, and provides very high detection rate with a particularly low level of false positives, demonstrated on difficult test sets, without requiring the use of multiple networks for handling difficult cases."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2243801"
                        ],
                        "name": "Jim Mutch",
                        "slug": "Jim-Mutch",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Mutch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jim Mutch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1427294,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9e65fcb0e04174577f211d702d3f837e3624c5b",
            "isKey": false,
            "numCitedBy": 548,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We apply a biologically inspired model of visual object recognition to the multiclass object categorization problem. Our model modifies that of Serre, Wolf, and Poggio. As in that work, we first apply Gabor filters at all positions and scales; feature complexity and position/scale invariance are then built up by alternating template matching and max pooling operations. We refine the approach in several biologically plausible ways, using simple versions of sparsification and lateral inhibition. We demonstrate the value of retaining some position and scale information above the intermediate feature level. Using feature selection we arrive at a model that performs better with fewer features. Our final model is tested on the Caltech 101 object categories and the UIUC car localization task, in both cases achieving state-of-the-art performance. The results strengthen the case for using this class of model in computer vision."
            },
            "slug": "Multiclass-Object-Recognition-with-Sparse,-Features-Mutch-Lowe",
            "title": {
                "fragments": [],
                "text": "Multiclass Object Recognition with Sparse, Localized Features"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A biologically inspired model of visual object recognition to the multiclass object categorization problem, modifies that of Serre, Wolf, and Poggio, and demonstrates the value of retaining some position and scale information above the intermediate feature level."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256269"
                        ],
                        "name": "C. Farabet",
                        "slug": "C.-Farabet",
                        "structuredName": {
                            "firstName": "Cl\u00e9ment",
                            "lastName": "Farabet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Farabet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1940285"
                        ],
                        "name": "B. Martini",
                        "slug": "B.-Martini",
                        "structuredName": {
                            "firstName": "Berin",
                            "lastName": "Martini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Martini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2447628"
                        ],
                        "name": "Polina Akselrod",
                        "slug": "Polina-Akselrod",
                        "structuredName": {
                            "firstName": "Polina",
                            "lastName": "Akselrod",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Polina Akselrod"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39576799"
                        ],
                        "name": "S. Talay",
                        "slug": "S.-Talay",
                        "structuredName": {
                            "firstName": "Sel\u00e7uk",
                            "lastName": "Talay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Talay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2889774"
                        ],
                        "name": "E. Culurciello",
                        "slug": "E.-Culurciello",
                        "structuredName": {
                            "firstName": "Eugenio",
                            "lastName": "Culurciello",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Culurciello"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 106
                            }
                        ],
                        "text": "Figure 2 shows a data-flow architecture whose goal is to process homogeneous streams of data in parallel (Farabet et al., 2010)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6542026,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3c82b476162d2d006e02180530875a64af18154",
            "isKey": false,
            "numCitedBy": 223,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a scalable hardware architecture to implement large-scale convolutional neural networks and state-of-the-art multi-layered artificial vision systems. This system is fully digital and is a modular vision engine with the goal of performing real-time detection, recognition and segmentation of mega-pixel images. We present a performance comparison between a software, FPGA and ASIC implementation that shows a speed up in custom hardware implementations."
            },
            "slug": "Hardware-accelerated-convolutional-neural-networks-Farabet-Martini",
            "title": {
                "fragments": [],
                "text": "Hardware accelerated convolutional neural networks for synthetic vision systems"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This system is fully digital and is a modular vision engine with the goal of performing real-time detection, recognition and segmentation of mega-pixel images."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2010 IEEE International Symposium on Circuits and Systems"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1981539"
                        ],
                        "name": "Thomas Serre",
                        "slug": "Thomas-Serre",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Serre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Serre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145128145"
                        ],
                        "name": "Lior Wolf",
                        "slug": "Lior-Wolf",
                        "structuredName": {
                            "firstName": "Lior",
                            "lastName": "Wolf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lior Wolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 36
                            }
                        ],
                        "text": "Other models like HMAX-type models (Serre et al., 2005; Mutch and Lowe, 2006) and convolutional networks use two more layers of successive feature extractors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 20
                            }
                        ],
                        "text": "Poggio\u2019s lab at MIT (Serre et al., 2005; Mutch and Lowe, 2006), which uses hard-wired Gabor filters in the first stage, and a simple unsupervised random template selection algorithm for the second stage."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 124
                            }
                        ],
                        "text": "Notable examples include Mozer\u2019s visual models (Mozer, 1991), and the so-called HMAX family of models from T. Poggio\u2019s lab at MIT (Serre et al., 2005; Mutch and Lowe, 2006), which uses hard-wired Gabor filters in the first stage, and a simple unsupervised random template selection algorithm for the second stage."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 129
                            }
                        ],
                        "text": "Notable examples include Mozer\u2019s visual models (Mozer, 1991), and the so-called HMAX family of models from T. Poggio\u2019s lab at MIT (Serre et al., 2005; Mutch and Lowe, 2006), which uses hard-wired Gabor filters in the first stage, and a simple unsupervised random template selection algorithm for the\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 153
                            }
                        ],
                        "text": "This hardware can also be used to accelerate the execution (and partial learning) of recent vision algorithms like SIFT and HMAX (Lazebnik et al., 2006; Serre et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 260426,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "040c23e5a409fbdedd5032263dfcb1a4d7dfd200",
            "isKey": true,
            "numCitedBy": 970,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a novel set of features for robust object recognition. Each element of this set is a complex feature obtained by combining position- and scale-tolerant edge-detectors over neighboring positions and multiple orientations. Our system's architecture is motivated by a quantitative model of visual cortex. We show that our approach exhibits excellent recognition performance and outperforms several state-of-the-art systems on a variety of image datasets including many different object categories. We also demonstrate that our system is able to learn from very few examples. The performance of the approach constitutes a suggestive plausibility proof for a class of feedforward models of object recognition in cortex."
            },
            "slug": "Object-recognition-with-features-inspired-by-visual-Serre-Wolf",
            "title": {
                "fragments": [],
                "text": "Object recognition with features inspired by visual cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The performance of the approach constitutes a suggestive plausibility proof for a class of feedforward models of object recognition in cortex and exhibits excellent recognition performance and outperforms several state-of-the-art systems on a variety of image datasets including many different object categories."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "147984118"
                        ],
                        "name": "R. Vaillant",
                        "slug": "R.-Vaillant",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Vaillant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Vaillant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3208918"
                        ],
                        "name": "C. Monrocq",
                        "slug": "C.-Monrocq",
                        "structuredName": {
                            "firstName": "Christophe",
                            "lastName": "Monrocq",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Monrocq"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9326933"
                        ],
                        "name": "Y. L. Cun",
                        "slug": "Y.-L.-Cun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "Cun",
                            "middleNames": [
                                "le"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. L. Cun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 16690291,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc7fa2cf9d7d2b3aca4fa22271412831e9a61e22",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Presents an algorithm for the detection of faces in images using shared-weight replicated neural networks. A neural net forms rough hypotheses about the position of faces. These hypotheses are then verified using a second neural network. The algorithm applies to images where the size of the faces is unknown a priori. The computational time which is necessary for the complete processing of an image is reasonable. With a classical workstation an image of size 512*512 is treated in 50 seconds including smoothing and normalization of the image. This algorithm can be easily installed on a more specialized machine as the major part of the operation is based on convolutions with kernels of size 5*5 or 8*8. In this paper, the authors assume that the face are well oriented in the image. It is possible to eliminate this assumption by following an approach similar to the one used for the scale problem. A net is trained to be insensitive to the precise orientation of the face. This kind of segmentation algorithm can be applied to other problems where the objects to be detected cannot be characterized easily by its outline or by classical primitives in image processing."
            },
            "slug": "An-original-approach-for-the-localization-of-in-Vaillant-Monrocq",
            "title": {
                "fragments": [],
                "text": "An original approach for the localization of objects in images"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "An algorithm for the detection of faces in images using shared-weight replicated neural networks, trained to be insensitive to the precise orientation of the face by following an approach similar to the one used for the scale problem."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 82
                            }
                        ],
                        "text": "1.1 Convolutional Networks\nconvolutional network!overview\nConvolutional Networks (LeCun et al., 1990, 1998b) are trainable architec-\ntures composed of multiple stages."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 149
                            }
                        ],
                        "text": "\u2026optical character recognition (OCR) to object detection, scene segmentation, and robot navigation:\n\u2022 check reading (handwriting recognition) at AT&T (LeCun et al., 1998b) and Microsoft (Simard et al., 2003; Chellapilla et al., 2006),\n\u2022 detection in images, including faces with record accuracy and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 50
                            }
                        ],
                        "text": "\u2022 check reading (handwriting recognition) at AT&T (LeCun et al., 1998b) and Microsoft (Simard et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 3
                            }
                        ],
                        "text": "In LeCun et al. (1998b) and Huang and LeCun (2006), pure supervised learning is used to update the parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 23
                            }
                        ],
                        "text": "Large-Scale FPGA-based Convolutional Networks\nCle\u0301ment Farabet1, Yann LeCun1, Koray Kavukcuoglu1, Eugenio Culurciello2, Berin Martini2,\nPolina Akselrod2, Selcuk Talay2\n1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 35
                            }
                        ],
                        "text": "May 2, 2011\nLarge-Scale FPGA-Based Convolutional Networks Micro-robots, unmanned aerial vehicles (UAVs), imaging sensor networks, wireless phones, and other embedded vision systems all require low cost and high-speed implementations of synthetic vision systems capable of recognizing and categorizing objects in a scene."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 38
                            }
                        ],
                        "text": "Details of the procedure are given in LeCun et al. (1998b), and methods for efficient training are detailed in LeCun et al. (1998a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 0
                            }
                        ],
                        "text": "Convolutional Networks (ConvNets) are an answer to the first question."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 225
                            }
                        ],
                        "text": "The approach was very successful, and led to several implementations, ranging from optical character recognition (OCR) to object detection, scene segmentation, and robot navigation:\n\u2022 check reading (handwriting recognition) at AT&T (LeCun et al., 1998b) and Microsoft (Simard et al., 2003; Chellapilla et al., 2006),\n\u2022 detection in images, including faces with record accuracy and real-time performance (Vaillant et al., 1994; Garcia and Delakis, 2004; Osadchy et al., 2007; Nasse et al., 2009), license plates and faces in Google\u2019s StreetView (Frome et al., 2009), or customers\u2019 gender and age at NEC,\n\u2022 more experimental detection of hands/gestures (Nowlan and Platt, 1995), logos and text (Delakis and Garcia, 2008),\n\u2022 vision-based navigation for off-road robots: in the DARPA-sponsored LAGR program, ConvNets were used for long-range obstacle detection (Hadsell et al., 2009)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": false,
            "numCitedBy": 35623,
            "numCiting": 246,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48950628"
                        ],
                        "name": "N. Dalal",
                        "slug": "N.-Dalal",
                        "structuredName": {
                            "firstName": "Navneet",
                            "lastName": "Dalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dalal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206590483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cec734d7097ab6b1e60d95228ffd64248eb89d66",
            "isKey": false,
            "numCitedBy": 29465,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds."
            },
            "slug": "Histograms-of-oriented-gradients-for-human-Dalal-Triggs",
            "title": {
                "fragments": [],
                "text": "Histograms of oriented gradients for human detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection, and the influence of each stage of the computation on performance is studied."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35086944"
                        ],
                        "name": "Viren Jain",
                        "slug": "Viren-Jain",
                        "structuredName": {
                            "firstName": "Viren",
                            "lastName": "Jain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Viren Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144924970"
                        ],
                        "name": "H. Seung",
                        "slug": "H.-Seung",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Seung",
                            "middleNames": [
                                "Sebastian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Seung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In Jarrett et al. (2009), using abs and normalization non-linearities, unsupervised pre-training, and supervised global refinement has been shown to yield excellent performance on the Caltech-101 dataset with only 30 training samples per category (more on this below)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14260640,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b2af2a2f2d1be22ebf473f7e0f501f1f5c02f222",
            "isKey": false,
            "numCitedBy": 735,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an approach to low-level vision that combines two main ideas: the use of convolutional networks as an image processing architecture and an unsupervised learning procedure that synthesizes training samples from specific noise models. We demonstrate this approach on the challenging problem of natural image denoising. Using a test set with a hundred natural images, we find that convolutional networks provide comparable and in some cases superior performance to state of the art wavelet and Markov random field (MRF) methods. Moreover, we find that a convolutional network offers similar performance in the blind de-noising setting as compared to other techniques in the non-blind setting. We also show how convolutional networks are mathematically related to MRF approaches by presenting a mean field theory for an MRF specially designed for image denoising. Although these approaches are related, convolutional networks avoid computational difficulties in MRF approaches that arise from probabilistic learning and inference. This makes it possible to learn image processing architectures that have a high degree of representational power (we train models with over 15,000 parameters), but whose computational expense is significantly less than that associated with inference in MRF approaches with even hundreds of parameters."
            },
            "slug": "Natural-Image-Denoising-with-Convolutional-Networks-Jain-Seung",
            "title": {
                "fragments": [],
                "text": "Natural Image Denoising with Convolutional Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "An approach to low-level vision is presented that combines the use of convolutional networks as an image processing architecture and an unsupervised learning procedure that synthesizes training samples from specific noise models to avoid computational difficulties in MRF approaches that arise from probabilistic learning and inference."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2315504"
                        ],
                        "name": "R. Hadsell",
                        "slug": "R.-Hadsell",
                        "structuredName": {
                            "firstName": "Raia",
                            "lastName": "Hadsell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hadsell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3142556"
                        ],
                        "name": "Pierre Sermanet",
                        "slug": "Pierre-Sermanet",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Sermanet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierre Sermanet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144050629"
                        ],
                        "name": "J. Ben",
                        "slug": "J.-Ben",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Ben",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ben"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767093"
                        ],
                        "name": "A. Erkan",
                        "slug": "A.-Erkan",
                        "structuredName": {
                            "firstName": "Ayse",
                            "lastName": "Erkan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Erkan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085624"
                        ],
                        "name": "Marco Scoffier",
                        "slug": "Marco-Scoffier",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Scoffier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Scoffier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145636949"
                        ],
                        "name": "Urs Muller",
                        "slug": "Urs-Muller",
                        "structuredName": {
                            "firstName": "Urs",
                            "lastName": "Muller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Urs Muller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 3
                            }
                        ],
                        "text": "In Hadsell et al. (2009), the system is pre-trained off-line using a combination of unsupervised learning (as described in section 1.3) and supervised learning."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 282,
                                "start": 262
                            }
                        ],
                        "text": "\u2026and age at NEC,\n\u2022 more experimental detection of hands/gestures (Nowlan and Platt, 1995), logos and text (Delakis and Garcia, 2008),\n\u2022 vision-based navigation for off-road robots: in the DARPA-sponsored LAGR program, ConvNets were used for long-range obstacle detection (Hadsell et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 55
                            }
                        ],
                        "text": ", 2004) or online learning for adaptive robot guidance (Hadsell et al., 2009) are tasks that will be largely improved by this system."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 137
                            }
                        ],
                        "text": "\u2022 vision-based navigation for off-road robots: in the DARPA-sponsored LAGR program, ConvNets were used for long-range obstacle detection (Hadsell et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 95
                            }
                        ],
                        "text": "Multiple object detection (LeCun et al., 2004) or online learning for adaptive robot guidance (Hadsell et al., 2009) are tasks that will be largely improved by this system."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5277920,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d8f527d1a96b0dae209daa6a241cf3255a6ec0d",
            "isKey": false,
            "numCitedBy": 227,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Most vision\u2010based approaches to mobile robotics suffer from the limitations imposed by stereo obstacle detection, which is short range and prone to failure. We present a self\u2010supervised learning process for long\u2010range vision that is able to accurately classify complex terrain at distances up to the horizon, thus allowing superior strategic planning. The success of the learning process is due to the self\u2010supervised training data that are generated on every frame: robust, visually consistent labels from a stereo module; normalized wide\u2010context input windows; and a discriminative and concise feature representation. A deep hierarchical network is trained to extract informative and meaningful features from an input image, and the features are used to train a real\u2010time classifier to predict traversability. The trained classifier sees obstacles and paths from 5 to more than 100 m, far beyond the maximum stereo range of 12 m, and adapts very quickly to new environments. The process was developed and tested on the LAGR (Learning Applied to Ground Robots) mobile robot. Results from a ground truth data set, as well as field test results, are given. \u00a9 2009 Wiley Periodicals, Inc."
            },
            "slug": "Learning-long\u2010range-vision-for-autonomous-off\u2010road-Hadsell-Sermanet",
            "title": {
                "fragments": [],
                "text": "Learning long\u2010range vision for autonomous off\u2010road driving"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work presents a self\u2010supervised learning process for long\u2010range vision that is able to accurately classify complex terrain at distances up to the horizon, thus allowing superior strategic planning."
            },
            "venue": {
                "fragments": [],
                "text": "J. Field Robotics"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638694"
                        ],
                        "name": "Adam Coates",
                        "slug": "Adam-Coates",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Coates",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Coates"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3128990"
                        ],
                        "name": "P. Baumstarck",
                        "slug": "P.-Baumstarck",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Baumstarck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Baumstarck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 130
                            }
                        ],
                        "text": "Graphics Processing Units (GPUs) are becoming a common alternative to custom hardware in vision applications, as demonstrated in (Coates et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1971409,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1828eaa8750ee188111b92deae5c7f67323e723f",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of robotic object detection of such objects as mugs, cups, and staplers in indoor environments. While object detection has made significant progress in recent years, many current approaches involve extremely complex algorithms, and are prohibitively slow when applied to large scale robotic settings. In this paper, we describe an object detection system that is designed to scale gracefully to large data sets and leverages upward trends in computational power (as exemplified by Graphics Processing Unit (GPU) technology) and memory. We show that our GPU-based detector is up to 90 times faster than a well-optimized software version and can be easily trained on millions of examples. Using inexpensive off-the-shelf hardware, it can recognize multiple object types reliably in just a few seconds per frame."
            },
            "slug": "Scalable-learning-for-object-detection-with-GPU-Coates-Baumstarck",
            "title": {
                "fragments": [],
                "text": "Scalable learning for object detection with GPU hardware"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper describes an object detection system that is designed to scale gracefully to large data sets and leverages upward trends in computational power (as exemplified by Graphics Processing Unit (GPU) technology) and memory."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE/RSJ International Conference on Intelligent Robots and Systems"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 67
                            }
                        ],
                        "text": "Some recognition systems use a single stage of feature extractors (Lazebnik et al., 2006; Dalal and Triggs, 2005; Berg et al., 2005; Pinto et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "Other models like HMAX-type models (Serre et al., 2005; Mutch and Lowe, 2006) and convolutional networks use two more layers of successive feature extractors."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "Notable examples include Mozer\u2019s visual models (Mozer, 1991), and the so-called HMAX family of models from T. Poggio\u2019s lab at MIT (Serre et al., 2005; Mutch and Lowe, 2006), which uses hard-wired Gabor filters in the first stage, and a simple unsupervised random template selection algorithm for the second stage."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 130
                            }
                        ],
                        "text": "This hardware can also be used to accelerate the execution (and partial learning) of recent vision algorithms like SIFT and HMAX (Lazebnik et al., 2006; Serre et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 88
                            }
                        ],
                        "text": "The result is on par with the popular model based on SIFT and pyramid match kernel SVM (Lazebnik et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 34
                            }
                        ],
                        "text": "A Pyramid Match Kernel (PMK) SVM (Lazebnik et al., 2006) classifier can also be seen as another layer of feature extraction since it performs a K-means based feature extraction followed by local histogramming."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2421251,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6dbaff29d3898cf60f63f5a34cb9610ebb75220c",
            "isKey": true,
            "numCitedBy": 8359,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence. This technique works by partitioning the image into increasingly fine sub-regions and computing histograms of local features found inside each sub-region. The resulting \"spatial pyramid\" is a simple and computationally efficient extension of an orderless bag-of-features image representation, and it shows significantly improved performance on challenging scene categorization tasks. Specifically, our proposed method exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories. The spatial pyramid framework also offers insights into the success of several recently proposed image descriptions, including Torralba\u2019s \"gist\" and Lowe\u2019s SIFT descriptors."
            },
            "slug": "Beyond-Bags-of-Features:-Spatial-Pyramid-Matching-Lazebnik-Schmid",
            "title": {
                "fragments": [],
                "text": "Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence that exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685538"
                        ],
                        "name": "Tamara L. Berg",
                        "slug": "Tamara-L.-Berg",
                        "structuredName": {
                            "firstName": "Tamara",
                            "lastName": "Berg",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tamara L. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 114
                            }
                        ],
                        "text": "Some recognition systems use a single stage of feature extractors (Lazebnik et al., 2006; Dalal and Triggs, 2005; Berg et al., 2005; Pinto et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6055435,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "12c7fc38debaf3589e712973642246bd54fe63b3",
            "isKey": false,
            "numCitedBy": 957,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We approach recognition in the framework of deformable shape matching, relying on a new algorithm for finding correspondences between feature points. This algorithm sets up correspondence as an integer quadratic programming problem, where the cost function has terms based on similarity of corresponding geometric blur point descriptors as well as the geometric distortion between pairs of corresponding feature points. The algorithm handles outliers, and thus enables matching of exemplars to query images in the presence of occlusion and clutter. Given the correspondences, we estimate an aligning transform, typically a regularized thin plate spline, resulting in a dense correspondence between the two shapes. Object recognition is then handled in a nearest neighbor framework where the distance between exemplar and query is the matching cost between corresponding points. We show results on two datasets. One is the Caltech 101 dataset (Fei-Fei, Fergus and Perona), an extremely challenging dataset with large intraclass variation. Our approach yields a 48% correct classification rate, compared to Fei-Fei et al 's 16%. We also show results for localizing frontal and profile faces that are comparable to special purpose approaches tuned to faces."
            },
            "slug": "Shape-matching-and-object-recognition-using-low-Berg-Berg",
            "title": {
                "fragments": [],
                "text": "Shape matching and object recognition using low distortion correspondences"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This work approaches recognition in the framework of deformable shape matching, relying on a new algorithm for finding correspondences between feature points, and shows results for localizing frontal and profile faces that are comparable to special purpose approaches tuned to faces."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706809"
                        ],
                        "name": "Marc'Aurelio Ranzato",
                        "slug": "Marc'Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Marc'Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc'Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 145
                            }
                        ],
                        "text": "The unsupervised method we propose, to learn the filter coefficients in the filter bank layers, is called Predictive Sparse Decomposition (PSD) (Kavukcuoglu et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 231,
                                "start": 205
                            }
                        ],
                        "text": "1 Unsupervised Training with Predictive Sparse Decomposition The unsupervised method we propose, to learn the filter coefficients in the filter bank layers, is called Predictive Sparse Decomposition (PSD) (Kavukcuoglu et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "PSD trains a non-linear feed-forward regressor (or encoder) C(X,K) = g.(tanh(X \u2217 k+ b)) to approximate the sparse solution Z\u2217."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5931210,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c63ef05c5f9c424b5cfeeed90dbe35eedf6cb8ec",
            "isKey": false,
            "numCitedBy": 242,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Adaptive sparse coding methods learn a possibly overcomplete set of basis functions, such that natural image patches can be reconstructed by linearly combining a small subset of these bases. The applicability of these methods to visual object recognition tasks has been limited because of the prohibitive cost of the optimization algorithms required to compute the sparse representation. In this work we propose a simple and efficient algorithm to learn basis functions. After training, this model also provides a fast and smooth approximator to the optimal representation, achieving even better accuracy than exact sparse coding algorithms on visual object recognition tasks."
            },
            "slug": "Fast-Inference-in-Sparse-Coding-Algorithms-with-to-Kavukcuoglu-Ranzato",
            "title": {
                "fragments": [],
                "text": "Fast Inference in Sparse Coding Algorithms with Applications to Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This work proposes a simple and efficient algorithm to learn basis functions, which provides a fast and smooth approximator to the optimal representation, achieving even better accuracy than exact sparse coding algorithms on visual object recognition tasks."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708655"
                        ],
                        "name": "B. Olshausen",
                        "slug": "B.-Olshausen",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Olshausen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Olshausen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49649079"
                        ],
                        "name": "D. Field",
                        "slug": "D.-Field",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Field",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Field"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 52
                            }
                        ],
                        "text": "Similar to the well-known sparse coding algorithms (Olshausen and Field, 1997), inputs are approximated as a sparse linear combination of dictionary elements."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14208692,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "2805537bec87a6177037b18f9a3a9d3f1038867b",
            "isKey": false,
            "numCitedBy": 3579,
            "numCiting": 71,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Sparse-coding-with-an-overcomplete-basis-set:-A-by-Olshausen-Field",
            "title": {
                "fragments": [],
                "text": "Sparse coding with an overcomplete basis set: A strategy employed by V1?"
            },
            "venue": {
                "fragments": [],
                "text": "Vision Research"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143629707"
                        ],
                        "name": "Amr Ahmed",
                        "slug": "Amr-Ahmed",
                        "structuredName": {
                            "firstName": "Amr",
                            "lastName": "Ahmed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amr Ahmed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144782042"
                        ],
                        "name": "Kai Yu",
                        "slug": "Kai-Yu",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143836295"
                        ],
                        "name": "W. Xu",
                        "slug": "W.-Xu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144768792"
                        ],
                        "name": "Yihong Gong",
                        "slug": "Yihong-Gong",
                        "structuredName": {
                            "firstName": "Yihong",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yihong Gong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143977260"
                        ],
                        "name": "E. Xing",
                        "slug": "E.-Xing",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Xing",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Xing"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 70
                            }
                        ],
                        "text": "However, recent works have focused on training with an auxiliary task (Ahmed et al., 2008) or using unsupervised objectives (Ranzato et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 71
                            }
                        ],
                        "text": "However, recent works have focused on training with an auxiliary task (Ahmed et al., 2008) or using unsupervised objectives (Ranzato et al., 2007b; Kavukcuoglu et al., 2009; Jarrett et al., 2009; Lee et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 65
                            }
                        ],
                        "text": "Several works at NEC have also shown that using auxiliary tasks (Ahmed et al., 2008; Weston et al., 2008) helps regularizing the system and produces excellent performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 485740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0dadb25842ef596a0f676c04cbd3dad4e1876964",
            "isKey": false,
            "numCitedBy": 169,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Building visual recognition models that adapt across different domains is a challenging task for computer vision. While feature-learning machines in the form of hierarchial feed-forward models (e.g., convolutional neural networks) showed promise in this direction, they are still difficult to train especially when few training examples are available. In this paper, we present a framework for training hierarchical feed-forward models for visual recognition, using transfer learning from pseudo tasks. These pseudo tasks are automatically constructed from data without supervision and comprise a set of simple pattern-matching operations. We show that these pseudo tasks induce an informative inverse-Wishart prior on the functional behavior of the network, offering an effective way to incorporate useful prior knowledge into the network training. In addition to being extremely simple to implement, and adaptable across different domains with little or no extra tuning, our approach achieves promising results on challenging visual recognition tasks, including object recognition, gender recognition, and ethnicity recognition."
            },
            "slug": "Training-Hierarchical-Feed-Forward-Visual-Models-Ahmed-Yu",
            "title": {
                "fragments": [],
                "text": "Training Hierarchical Feed-Forward Visual Recognition Models Using Transfer Learning from Pseudo-Tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents a framework for training hierarchical feed-forward models for visual recognition, using transfer learning from pseudo tasks, and shows that these pseudo tasks induce an informative inverse-Wishart prior on the functional behavior of the network, offering an effective way to incorporate useful prior knowledge into the network training."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2557686"
                        ],
                        "name": "Fabian Nasse",
                        "slug": "Fabian-Nasse",
                        "structuredName": {
                            "firstName": "Fabian",
                            "lastName": "Nasse",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fabian Nasse"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2020614"
                        ],
                        "name": "Christian Thurau",
                        "slug": "Christian-Thurau",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Thurau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Thurau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749475"
                        ],
                        "name": "G. Fink",
                        "slug": "G.-Fink",
                        "structuredName": {
                            "firstName": "Gernot",
                            "lastName": "Fink",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Fink"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 143
                            }
                        ],
                        "text": "\u2026in images, including faces with record accuracy and real-time performance (Vaillant et al., 1994; Garcia and Delakis, 2004; Osadchy et al., 2007; Nasse et al., 2009), license plates and faces in Google\u2019s StreetView (Frome et al., 2009), or customers\u2019 gender and age at NEC,\n\u2022 more\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 95
                            }
                        ],
                        "text": ", 2006), \u2022 detection in images, including faces with record accuracy and real-time performance (Vaillant et al., 1994; Garcia and Delakis, 2004; Osadchy et al., 2007; Nasse et al., 2009), license plates and faces in Google\u2019s StreetView (Frome et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1067914,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "61e5522564e9563181c4016a212fee0561794759",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we consider the problem of face detection under pose variations. Unlike other contributions, a focus of this work resides within efficient implementation utilizing the computational powers of modern graphics cards. The proposed system consists of a parallelized implementation of convolutional neural networks (CNNs) with a special emphasize on also parallelizing the detection process. Experimental validation in a smart conference room with 4 active ceiling-mounted cameras shows a dramatic speed-gain under real-life conditions."
            },
            "slug": "Face-Detection-Using-GPU-Based-Convolutional-Neural-Nasse-Thurau",
            "title": {
                "fragments": [],
                "text": "Face Detection Using GPU-Based Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The proposed system consists of a parallelized implementation of convolutional neural networks with a special emphasize on also parallelizing the detection process, which shows a dramatic speed-gain under real-life conditions."
            },
            "venue": {
                "fragments": [],
                "text": "CAIP"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706809"
                        ],
                        "name": "Marc'Aurelio Ranzato",
                        "slug": "Marc'Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Marc'Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc'Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "90841478"
                        ],
                        "name": "Y-Lan Boureau",
                        "slug": "Y-Lan-Boureau",
                        "structuredName": {
                            "firstName": "Y-Lan",
                            "lastName": "Boureau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y-Lan Boureau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 125
                            }
                        ],
                        "text": "However, recent works have focused on training with an auxiliary task (Ahmed et al., 2008) or using unsupervised objectives (Ranzato et al., 2007b; Kavukcuoglu et al., 2009; Jarrett et al., 2009; Lee et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 51
                            }
                        ],
                        "text": "The best previously reported error rate was 0.60% (Ranzato et al., 2007a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 87
                            }
                        ],
                        "text": "Recent research in deep learning (Hinton and Salakhutdinov, 2006; Bengio et al., 2007; Ranzato et al., 2007a) has shown that unsupervised learning can be used to train each stage one after the other using only unlabeled data, reducing the requirement for labeled\nsamples significantly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5867279,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41fef1a197fab9684a4608b725d3ae72e1ab4b39",
            "isKey": false,
            "numCitedBy": 826,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Unsupervised learning algorithms aim to discover the structure hidden in the data, and to learn representations that are more suitable as input to a supervised machine than the raw input. Many unsupervised methods are based on reconstructing the input from the representation, while constraining the representation to have certain desirable properties (e.g. low dimension, sparsity, etc). Others are based on approximating density by stochastically reconstructing the input from the representation. We describe a novel and efficient algorithm to learn sparse representations, and compare it theoretically and experimentally with a similar machine trained probabilistically, namely a Restricted Boltzmann Machine. We propose a simple criterion to compare and select different unsupervised machines based on the trade-off between the reconstruction error and the information content of the representation. We demonstrate this method by extracting features from a dataset of handwritten numerals, and from a dataset of natural image patches. We show that by stacking multiple levels of such machines and by training sequentially, high-order dependencies between the input observed variables can be captured."
            },
            "slug": "Sparse-Feature-Learning-for-Deep-Belief-Networks-Ranzato-Boureau",
            "title": {
                "fragments": [],
                "text": "Sparse Feature Learning for Deep Belief Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work proposes a simple criterion to compare and select different unsupervised machines based on the trade-off between the reconstruction error and the information content of the representation, and describes a novel and efficient algorithm to learn sparse representations."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697141"
                        ],
                        "name": "Honglak Lee",
                        "slug": "Honglak-Lee",
                        "structuredName": {
                            "firstName": "Honglak",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Honglak Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785346"
                        ],
                        "name": "Roger B. Grosse",
                        "slug": "Roger-B.-Grosse",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Grosse",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roger B. Grosse"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2615814"
                        ],
                        "name": "R. Ranganath",
                        "slug": "R.-Ranganath",
                        "structuredName": {
                            "firstName": "Rajesh",
                            "lastName": "Ranganath",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ranganath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 41
                            }
                        ],
                        "text": ", 2008) or using unsupervised objectives (Ranzato et al., 2007b; Kavukcuoglu et al., 2009; Jarrett et al., 2009; Lee et al., 2009)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 196
                            }
                        ],
                        "text": "However, recent works have focused on training with an auxiliary task (Ahmed et al., 2008) or using unsupervised objectives (Ranzato et al., 2007b; Kavukcuoglu et al., 2009; Jarrett et al., 2009; Lee et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 3
                            }
                        ],
                        "text": "In Lee et al. (2009), good accuracy was obtained on the same set using a very different unsupervised method based on sparse Restricted Boltzmann Machines."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12008458,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e80f755bcbf10479afd2338cec05211fdbd325c",
            "isKey": false,
            "numCitedBy": 2528,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "There has been much interest in unsupervised learning of hierarchical generative models such as deep belief networks. Scaling such models to full-sized, high-dimensional images remains a difficult problem. To address this problem, we present the convolutional deep belief network, a hierarchical generative model which scales to realistic image sizes. This model is translation-invariant and supports efficient bottom-up and top-down probabilistic inference. Key to our approach is probabilistic max-pooling, a novel technique which shrinks the representations of higher layers in a probabilistically sound way. Our experiments show that the algorithm learns useful high-level visual features, such as object parts, from unlabeled images of objects and natural scenes. We demonstrate excellent performance on several visual recognition tasks and show that our model can perform hierarchical (bottom-up and top-down) inference over full-sized images."
            },
            "slug": "Convolutional-deep-belief-networks-for-scalable-of-Lee-Grosse",
            "title": {
                "fragments": [],
                "text": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The convolutional deep belief network is presented, a hierarchical generative model which scales to realistic image sizes and is translation-invariant and supports efficient bottom-up and top-down probabilistic inference."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144153718"
                        ],
                        "name": "H. T. Kung",
                        "slug": "H.-T.-Kung",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Kung",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. T. Kung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1858965,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "256bbe8e9fa3f5b72c24f1037ab734f9e7dd01c4",
            "isKey": false,
            "numCitedBy": 2228,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "f High-performance, special-purpose computer systems are typically used to meet specific application requirements or to off-load computations that are especially taxing to general-purpose computers. As hardware cost and size continue to drop and processing requirements become well-understood in areas such as signal and image processing, more special-purpose systems are being constructed. However, since most of these systems are built on an ad hoc basis for specific tasks, methodological work in this area is rare. Because the knowledge gaited from individual experiences is neither accumulated nor properly organized, the same errors are repeated. I/O and computation imbalance is a notable example-often, the fact that I/O interfaces cannot keep up with device speed is discovered only after constructing a high-speed, special-purpose device. We intend to help correct this ad hoc approach by providing a general guideline-specifically, the concept of systolic architecture, a general methodology for mapping high-level computations into hardware structures. In a systolic system, data flows from the computer memcory in a rhythmic fashion, passing through many processing elements before it returns to memory, much as blood circulates to and from the heart. The system works like an autombbile assembly line where different people work on the same car at different times and many cars are assembled simultaneously. An assembly line is always linear, however, and systolic systems are sometimes two-dimensional. They can be rectangular, triangular, or hexagonal to make use of higher degrees of parallelism. Moreover, to implement a variety of computations, data flow in a systolic system may be at multiple speeds in multiple directions-both inputs and (partial) results flow, whereas only results flow in classical pipelined systems. Generally speaking, a systolic system is easy to implement because of its regularity and easy to reconfigure (to meet various outside constraints) because of its modularity. The systolic architectural concept was developed at Carnegie-Mellon University,'17 and versions of systolic processors are being designed and built by several industrial and governmental organizations.840 This article reviews the basic principle of systolic architectures and explains why they should result in cost-effective, highperformance special-purpose systems for a wide range of problems."
            },
            "slug": "Why-systolic-architectures-Kung",
            "title": {
                "fragments": [],
                "text": "Why systolic architectures?"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The basic principle of systolic architectures is reviewed and it is explained why they should result in cost-effective, highperformance special-purpose systems for a wide range of problems."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30017846"
                        ],
                        "name": "N. Pinto",
                        "slug": "N.-Pinto",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Pinto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Pinto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2042941"
                        ],
                        "name": "D. Cox",
                        "slug": "D.-Cox",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cox",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1865831"
                        ],
                        "name": "J. DiCarlo",
                        "slug": "J.-DiCarlo",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "DiCarlo",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. DiCarlo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 39
                            }
                        ],
                        "text": "From the same institute, Pinto et al. (Pinto et al., 2008) have identified the most appropriate non-linearities and normalizations by running systematic experiments with a single-stage architecture using GPU-based parallel hardware."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "(Pinto et al., 2008) have identified the most appropriate non-linearities and normalizations by running systematic experiments with a single-stage architecture using GPU-based parallel hardware."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 133
                            }
                        ],
                        "text": "Some recognition systems use a single stage of feature extractors (Lazebnik et al., 2006; Dalal and Triggs, 2005; Berg et al., 2005; Pinto et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 108
                            }
                        ],
                        "text": "The local contrast normalization layer is inspired by visual neuroscience models (Lyu and Simoncelli, 2008; Pinto et al., 2008)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5955557,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "688b6fbc3c5c06e254961f70de9d855d3d008d09",
            "isKey": true,
            "numCitedBy": 586,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Progress in understanding the brain mechanisms underlying vision requires the construction of computational models that not only emulate the brain's anatomy and physiology, but ultimately match its performance on visual tasks. In recent years, \u201cnatural\u201d images have become popular in the study of vision and have been used to show apparently impressive progress in building such models. Here, we challenge the use of uncontrolled \u201cnatural\u201d images in guiding that progress. In particular, we show that a simple V1-like model\u2014a neuroscientist's \u201cnull\u201d model, which should perform poorly at real-world visual object recognition tasks\u2014outperforms state-of-the-art object recognition systems (biologically inspired and otherwise) on a standard, ostensibly natural image recognition test. As a counterpoint, we designed a \u201csimpler\u201d recognition test to better span the real-world variation in object pose, position, and scale, and we show that this test correctly exposes the inadequacy of the V1-like model. Taken together, these results demonstrate that tests based on uncontrolled natural images can be seriously misleading, potentially guiding progress in the wrong direction. Instead, we reexamine what it means for images to be natural and argue for a renewed focus on the core problem of object recognition\u2014real-world image variation."
            },
            "slug": "Why-is-Real-World-Visual-Object-Recognition-Hard-Pinto-Cox",
            "title": {
                "fragments": [],
                "text": "Why is Real-World Visual Object Recognition Hard?"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that a simple V1-like model\u2014a neuroscientist's \u201cnull\u201d model\u2014outperforms state-of-the-art object recognition systems (biologically inspired and otherwise) on a standard, ostensibly natural image recognition test."
            },
            "venue": {
                "fragments": [],
                "text": "PLoS Comput. Biol."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794837"
                        ],
                        "name": "Siwei Lyu",
                        "slug": "Siwei-Lyu",
                        "structuredName": {
                            "firstName": "Siwei",
                            "lastName": "Lyu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Siwei Lyu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689350"
                        ],
                        "name": "Eero P. Simoncelli",
                        "slug": "Eero-P.-Simoncelli",
                        "structuredName": {
                            "firstName": "Eero",
                            "lastName": "Simoncelli",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eero P. Simoncelli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7415524,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "25d92fe0ab92ae57bd8fed87c95fa9a207ec61aa",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe a nonlinear image representation based on divisive normalization that is designed to match the statistical properties of photographic images, as well as the perceptual sensitivity of biological visual systems. We decompose an image using a multi-scale oriented representation, and use studentpsilas t as a model of the dependencies within local clusters of coefficients. We then show that normalization of each coefficient by the square root of a linear combination of the amplitudes of the coefficients in the cluster reduces statistical dependencies. We further show that the resulting divisive normalization transform is invertible and provide an efficient iterative inversion algorithm. Finally, we probe the statistical and perceptual advantages of this image representation by examining its robustness to added noise, and using it to enhance image contrast."
            },
            "slug": "Nonlinear-image-representation-using-divisive-Lyu-Simoncelli",
            "title": {
                "fragments": [],
                "text": "Nonlinear image representation using divisive normalization"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper decomposes an image using a multi-scale oriented representation, and uses studentpsilas t as a model of the dependencies within local clusters of coefficients to show that normalization of each coefficient by the square root of a linear combination of the amplitudes of the coefficients in the cluster reduces statistical dependencies."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802785"
                        ],
                        "name": "S. Nowlan",
                        "slug": "S.-Nowlan",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Nowlan",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nowlan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189092"
                        ],
                        "name": "John C. Platt",
                        "slug": "John-C.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Platt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 149
                            }
                        ],
                        "text": "\u2026license plates and faces in Google\u2019s StreetView (Frome et al., 2009), or customers\u2019 gender and age at NEC,\n\u2022 more experimental detection of hands/gestures (Nowlan and Platt, 1995), logos and text (Delakis and Garcia, 2008),\n\u2022 vision-based navigation for off-road robots: in the DARPA-sponsored\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 94
                            }
                        ],
                        "text": ", 2009), or customers\u2019 gender and age at NEC, \u2022 more experimental detection of hands/gestures (Nowlan and Platt, 1995), logos and text (Delakis and Garcia, 2008),"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9066905,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b234385356cb10d448908cef49584bece15d94b",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a system that can track a hand in a sequence of video frames and recognize hand gestures in a user-independent manner. The system locates the hand in each video frame and determines if the hand is open or closed. The tracking system is able to track the hand to within \u00b110 pixels of its correct location in 99.7% of the frames from a test set containing video sequences from 18 different individuals captured in 18 different room environments. The gesture recognition network correctly determines if the hand being tracked is open or closed in 99.1% of the frames in this test set. The system has been designed to operate in real time with existing hardware."
            },
            "slug": "A-Convolutional-Neural-Network-Hand-Tracker-Nowlan-Platt",
            "title": {
                "fragments": [],
                "text": "A Convolutional Neural Network Hand Tracker"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A system that can track a hand in a sequence of video frames and recognize hand gestures in a user-independent manner and is designed to operate in real time with existing hardware is described."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700737"
                        ],
                        "name": "Margarita Osadchy",
                        "slug": "Margarita-Osadchy",
                        "structuredName": {
                            "firstName": "Margarita",
                            "lastName": "Osadchy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Margarita Osadchy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111207598"
                        ],
                        "name": "Matthew L. Miller",
                        "slug": "Matthew-L.-Miller",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Miller",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew L. Miller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 95
                            }
                        ],
                        "text": ", 2006), \u2022 detection in images, including faces with record accuracy and real-time performance (Vaillant et al., 1994; Garcia and Delakis, 2004; Osadchy et al., 2007; Nasse et al., 2009), license plates and faces in Google\u2019s StreetView (Frome et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 148
                            }
                        ],
                        "text": "\u2026et al., 2006),\n\u2022 detection in images, including faces with record accuracy and real-time performance (Vaillant et al., 1994; Garcia and Delakis, 2004; Osadchy et al., 2007; Nasse et al., 2009), license plates and faces in Google\u2019s StreetView (Frome et al., 2009), or customers\u2019 gender and age at\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 688047,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b728a7442ca158f895d07c11c77d302269a832d",
            "isKey": false,
            "numCitedBy": 410,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a novel method for real-time, simultaneous multi-view face detection and facial pose estimation. The method employs a convolutional network to map face images to points on a manifold, parametrized by pose, and non-face images to points far from that manifold. This network is trained by optimizing a loss function of three variables: image, pose, and face/non-face label. We test the resulting system, in a single configuration, on three standard data sets - one for frontal pose, one for rotated faces, and one for profiles - and find that its performance on each set is comparable to previous multi-view face detectors that can only handle one form of pose variation. We also show experimentally that the system's accuracy on both face detection and pose estimation is improved by training for the two tasks together."
            },
            "slug": "Synergistic-Face-Detection-and-Pose-Estimation-with-Osadchy-LeCun",
            "title": {
                "fragments": [],
                "text": "Synergistic Face Detection and Pose Estimation with Energy-Based Models"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A novel method for real-time, simultaneous multi-view face detection and facial pose estimation that employs a convolutional network to map face images to points on a manifold, parametrized by pose, and non-face images to Points far from that manifold is described."
            },
            "venue": {
                "fragments": [],
                "text": "Toward Category-Level Object Recognition"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809791"
                        ],
                        "name": "K. Chellapilla",
                        "slug": "K.-Chellapilla",
                        "structuredName": {
                            "firstName": "Kumar",
                            "lastName": "Chellapilla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Chellapilla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2139615"
                        ],
                        "name": "Michael Shilman",
                        "slug": "Michael-Shilman",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Shilman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Shilman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2812486"
                        ],
                        "name": "P. Simard",
                        "slug": "P.-Simard",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Simard",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Simard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 23
                            }
                        ],
                        "text": ", 1998b) and Microsoft (Simard et al., 2003; Chellapilla et al., 2006), \u2022 detection in images, including faces with record accuracy and real-time performance (Vaillant et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 265,
                                "start": 256
                            }
                        ],
                        "text": "The approach was very successful, and led to several implementations, ranging from optical character recognition (OCR) to object detection, scene segmentation, and robot navigation:\n\u2022 check reading (handwriting recognition) at AT&T (LeCun et al., 1998b) and Microsoft (Simard et al., 2003; Chellapilla et al., 2006),\n\u2022 detection in images, including faces with record accuracy and real-time performance (Vaillant et al., 1994; Garcia and Delakis, 2004; Osadchy et al., 2007; Nasse et al., 2009), license plates and faces in Google\u2019s StreetView (Frome et al., 2009), or customers\u2019 gender and age at NEC,\n\u2022 more experimental detection of hands/gestures (Nowlan and Platt, 1995), logos and text (Delakis and Garcia, 2008),\n\u2022 vision-based navigation for off-road robots: in the DARPA-sponsored LAGR program, ConvNets were used for long-range obstacle detection (Hadsell et al., 2009)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 149
                            }
                        ],
                        "text": "\u2026scene segmentation, and robot navigation:\n\u2022 check reading (handwriting recognition) at AT&T (LeCun et al., 1998b) and Microsoft (Simard et al., 2003; Chellapilla et al., 2006),\n\u2022 detection in images, including faces with record accuracy and real-time performance (Vaillant et al., 1994; Garcia and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14708207,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "86c42bc5f1552ad42a5853249cb56241f7307d2c",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Conventional approaches to combining classifiers improve accuracy at the cost of increased processing. We propose a novel search based approach to automatically combine multiple classifiers in a cascade to obtain the desired tradeoff between classification speed and classification accuracy. The search procedure only updates the rejection thresholds (one for each constituent classier) in the cascade, consequently no new classifiers are added and no training is necessary. A branch-and-bound version of depth-first-search with efficient pruning is proposed for finding the optimal thresholds for the cascade. It produces optimal solutions under arbitrary user specified speed and accuracy constraints. The effectiveness of the approach is demonstrated on handwritten character recognition by finding a) the fastest possible combination given an upper bound on classification error, and also b) the most accurate combination given a lower bound on speed."
            },
            "slug": "Optimally-combining-a-cascade-of-classifiers-Chellapilla-Shilman",
            "title": {
                "fragments": [],
                "text": "Optimally combining a cascade of classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A novel search based approach to automatically combine multiple classifiers in a cascade to obtain the desired tradeoff between classification speed and classification accuracy is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Electronic Imaging"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1812064"
                        ],
                        "name": "M. Delakis",
                        "slug": "M.-Delakis",
                        "structuredName": {
                            "firstName": "Manolis",
                            "lastName": "Delakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Delakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144723337"
                        ],
                        "name": "Christophe Garcia",
                        "slug": "Christophe-Garcia",
                        "structuredName": {
                            "firstName": "Christophe",
                            "lastName": "Garcia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christophe Garcia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 142
                            }
                        ],
                        "text": "\u2026(Frome et al., 2009), or customers\u2019 gender and age at NEC,\n\u2022 more experimental detection of hands/gestures (Nowlan and Platt, 1995), logos and text (Delakis and Garcia, 2008),\n\u2022 vision-based navigation for off-road robots: in the DARPA-sponsored LAGR program, ConvNets were used for\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 135
                            }
                        ],
                        "text": ", 2009), or customers\u2019 gender and age at NEC, \u2022 more experimental detection of hands/gestures (Nowlan and Platt, 1995), logos and text (Delakis and Garcia, 2008),"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11518,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fd790b061082571e20be7892ce4a97e156497c9f",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Text detection is an important preliminary step before text can be recognized in unconstrained image environments. We present an approach based on convolutional neural networks to detect and localize horizontal text lines from raw color pixels. The network learns to extract and combine its own set of features through learning instead of using hand-crafted ones. Learning was also used in order to precisely localize the text lines by simply training the network to reject badly-cut text and without any use of tedious knowledge-based postprocessing. Although the network was trained with synthetic examples, experimental results demonstrated that it can outperform other methods on the real-world test set of ICDAR\u201903."
            },
            "slug": "text-Detection-with-Convolutional-Neural-Networks-Delakis-Garcia",
            "title": {
                "fragments": [],
                "text": "text Detection with Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This work presents an approach based on convolutional neural networks to detect and localize horizontal text lines from raw color pixels and demonstrates that it can outperform other methods on the real-world test set of ICDAR\u201903."
            },
            "venue": {
                "fragments": [],
                "text": "VISAPP"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37274089"
                        ],
                        "name": "D. Henderson",
                        "slug": "D.-Henderson",
                        "structuredName": {
                            "firstName": "Donnie",
                            "lastName": "Henderson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Henderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2799635"
                        ],
                        "name": "R. Howard",
                        "slug": "R.-Howard",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Howard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34859193"
                        ],
                        "name": "W. Hubbard",
                        "slug": "W.-Hubbard",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Hubbard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hubbard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041866"
                        ],
                        "name": "L. Jackel",
                        "slug": "L.-Jackel",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Jackel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jackel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 148
                            }
                        ],
                        "text": "Some ConvNets dispense with the separate pooling layer entirely, but use strides larger than one in the filter bank layer to reduce the resolution (LeCun et al., 1989; Simard et al., 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 18
                            }
                        ],
                        "text": "The innovation in LeCun et al. (1989, 1990) was to simplify the architecture and to\nuse the back-propagation algorithm to train the entire system in a supervised fashion."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2542741,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "86ab4cae682fbd49c5a5bedb630e5a40fa7529f6",
            "isKey": false,
            "numCitedBy": 2955,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an application of back-propagation networks to handwritten digit recognition. Minimal preprocessing of the data was required, but architecture of the network was highly constrained and specifically designed for the task. The input of the network consists of normalized images of isolated digits. The method has 1% error rate and about a 9% reject rate on zipcode digits provided by the U.S. Postal Service."
            },
            "slug": "Handwritten-Digit-Recognition-with-a-Network-LeCun-Boser",
            "title": {
                "fragments": [],
                "text": "Handwritten Digit Recognition with a Back-Propagation Network"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "Minimal preprocessing of the data was required, but architecture of the network was highly constrained and specifically designed for the task, and has 1% error rate and about a 9% reject rate on zipcode digits provided by the U.S. Postal Service."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144473519"
                        ],
                        "name": "M. Mozer",
                        "slug": "M.-Mozer",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Mozer",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mozer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 47
                            }
                        ],
                        "text": "Notable examples include Mozer\u2019s visual models (Mozer, 1991), and the so-called HMAX family of models from T. Poggio\u2019s lab at MIT (Serre et al., 2005; Mutch and Lowe, 2006), which uses hard-wired Gabor filters in the first stage, and a simple unsupervised random template selection algorithm for the\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 47
                            }
                        ],
                        "text": "Notable examples include Mozer\u2019s visual models (Mozer, 1991), and the so-called HMAX family of models from T."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5125059,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "1762498d7ef09cc706b551c54ce6894a7b2ee14d",
            "isKey": false,
            "numCitedBy": 209,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "\"The Perception of Multiple Objects \"describes a neurally inspired computational model of two-dimensional object recognition and spatial attention that can explain many characteristics of human visual perception. The model, called MORSEL (named for its ability to perform Multiple Object Recognition and attentional Selection), is unique in providing a broad and unified explanation for a wide range of experimental psychological data on visual perception and attention. Although it draws on existing theoretical perspectives from cognitive psychology, it is a fully mechanistic account, not just a functional-level theory.MORSEL has been trained to recognize letters and words in various positions on its \"retina.\" Following training, it can also recognize several items at once, subject to capacity limitations. The model makes predictions about what sorts of information the visual system can process in parallel and what sorts must be processed serially.Through simulation experiments, chiefly in letter and word perception, MORSEL has been shown to account for a variety of psychological phenomena, including perceptual errors that arise when several items appear simultaneously in the visual field, facilitatory effects of context and redundant information, attentional phenomena, visual search performance, and behaviors exhibited by neurological patients with acquired dyslexia."
            },
            "slug": "Perception-of-multiple-objects-a-connectionist-Mozer",
            "title": {
                "fragments": [],
                "text": "Perception of multiple objects - a connectionist approach"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The model, called MORSEL, is unique in providing a broad and unified explanation for a wide range of experimental psychological data on visual perception and attention, and draws on existing theoretical perspectives from cognitive psychology."
            },
            "venue": {
                "fragments": [],
                "text": "Neural network modeling and connectionism"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2279670"
                        ],
                        "name": "Andrea Frome",
                        "slug": "Andrea-Frome",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Frome",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrea Frome"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2450108"
                        ],
                        "name": "G. Cheung",
                        "slug": "G.-Cheung",
                        "structuredName": {
                            "firstName": "German",
                            "lastName": "Cheung",
                            "middleNames": [
                                "K.",
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cheung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1859983"
                        ],
                        "name": "Ahmad Abdulkader",
                        "slug": "Ahmad-Abdulkader",
                        "structuredName": {
                            "firstName": "Ahmad",
                            "lastName": "Abdulkader",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ahmad Abdulkader"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1935554"
                        ],
                        "name": "M. Zennaro",
                        "slug": "M.-Zennaro",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Zennaro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Zennaro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115595151"
                        ],
                        "name": "Bo Wu",
                        "slug": "Bo-Wu",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726358"
                        ],
                        "name": "A. Bissacco",
                        "slug": "A.-Bissacco",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Bissacco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bissacco"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2595180"
                        ],
                        "name": "Hartwig Adam",
                        "slug": "Hartwig-Adam",
                        "structuredName": {
                            "firstName": "Hartwig",
                            "lastName": "Adam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hartwig Adam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2665814"
                        ],
                        "name": "H. Neven",
                        "slug": "H.-Neven",
                        "structuredName": {
                            "firstName": "Hartmut",
                            "lastName": "Neven",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Neven"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073317450"
                        ],
                        "name": "Luc Vincent",
                        "slug": "Luc-Vincent",
                        "structuredName": {
                            "firstName": "Luc",
                            "lastName": "Vincent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luc Vincent"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 535,
                                "start": 520
                            }
                        ],
                        "text": "The approach was very successful, and led to several implementations, ranging from optical character recognition (OCR) to object detection, scene segmentation, and robot navigation:\n\u2022 check reading (handwriting recognition) at AT&T (LeCun et al., 1998b) and Microsoft (Simard et al., 2003; Chellapilla et al., 2006),\n\u2022 detection in images, including faces with record accuracy and real-time performance (Vaillant et al., 1994; Garcia and Delakis, 2004; Osadchy et al., 2007; Nasse et al., 2009), license plates and faces in Google\u2019s StreetView (Frome et al., 2009), or customers\u2019 gender and age at NEC,\n\u2022 more experimental detection of hands/gestures (Nowlan and Platt, 1995), logos and text (Delakis and Garcia, 2008),\n\u2022 vision-based navigation for off-road robots: in the DARPA-sponsored LAGR program, ConvNets were used for long-range obstacle detection (Hadsell et al., 2009)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 150
                            }
                        ],
                        "text": "\u2026performance (Vaillant et al., 1994; Garcia and Delakis, 2004; Osadchy et al., 2007; Nasse et al., 2009), license plates and faces in Google\u2019s StreetView (Frome et al., 2009), or customers\u2019 gender and age at NEC,\n\u2022 more experimental detection of hands/gestures (Nowlan and Platt, 1995), logos and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1964985,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01cb576adb5657959e0d925f0d510ed602648813",
            "isKey": false,
            "numCitedBy": 199,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The last two years have witnessed the introduction and rapid expansion of products based upon large, systematically-gathered, street-level image collections, such as Google Street View, EveryScape, and Mapjack. In the process of gathering images of public spaces, these projects also capture license plates, faces, and other information considered sensitive from a privacy standpoint. In this work, we present a system that addresses the challenge of automatically detecting and blurring faces and license plates for the purpose of privacy protection in Google Street View. Though some in the field would claim face detection is \u201csolved\u201d, we show that state-of-the-art face detectors alone are not sufficient to achieve the recall desired for large-scale privacy protection. In this paper we present a system that combines a standard sliding-window detector tuned for a high recall, low-precision operating point with a fast post-processing stage that is able to remove additional false positives by incorporating domain-specific information not available to the sliding-window detector. Using a completely automatic system, we are able to sufficiently blur more than 89% of faces and 94 \u2013 96% of license plates in evaluation sets sampled from Google Street View imagery."
            },
            "slug": "Large-scale-privacy-protection-in-Google-Street-Frome-Cheung",
            "title": {
                "fragments": [],
                "text": "Large-scale privacy protection in Google Street View"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work presents a system that combines a standard sliding-window detector tuned for a high recall, low-precision operating point with a fast post-processing stage that is able to remove additional false positives by incorporating domain-specific information not available to the sliding- window detector."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 12th International Conference on Computer Vision"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3087941"
                        ],
                        "name": "Pascal Lamblin",
                        "slug": "Pascal-Lamblin",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Lamblin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Lamblin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32384143"
                        ],
                        "name": "D. Popovici",
                        "slug": "D.-Popovici",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Popovici",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Popovici"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777528"
                        ],
                        "name": "H. Larochelle",
                        "slug": "H.-Larochelle",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Larochelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Larochelle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 33
                            }
                        ],
                        "text": "Recent research in deep learning (Hinton and Salakhutdinov, 2006; Bengio et al., 2007; Ranzato et al., 2007a) has shown that unsupervised learning can be used to train each stage one after the other using only unlabeled data, reducing the requirement for labeled"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 66
                            }
                        ],
                        "text": "Recent research in deep learning (Hinton and Salakhutdinov, 2006; Bengio et al., 2007; Ranzato et al., 2007a) has shown that unsupervised learning can be used to train each stage one after the other using only unlabeled data, reducing the requirement for labeled\nsamples significantly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14201947,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "355d44f53428b1ac4fb2ab468d593c720640e5bd",
            "isKey": false,
            "numCitedBy": 3486,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Complexity theory of circuits strongly suggests that deep architectures can be much more efficient (sometimes exponentially) than shallow architectures, in terms of computational elements required to represent some functions. Deep multi-layer neural networks have many levels of non-linearities allowing them to compactly represent highly non-linear and highly-varying functions. However, until recently it was not clear how to train such deep networks, since gradient-based optimization starting from random initialization appears to often get stuck in poor solutions. Hinton et al. recently introduced a greedy layer-wise unsupervised learning algorithm for Deep Belief Networks (DBN), a generative model with many layers of hidden causal variables. In the context of the above optimization problem, we study this algorithm empirically and explore variants to better understand its success and extend it to cases where the inputs are continuous or where the structure of the input distribution is not revealing enough about the variable to be predicted in a supervised task. Our experiments also confirm the hypothesis that the greedy layer-wise unsupervised training strategy mostly helps the optimization, by initializing weights in a region near a good local minimum, giving rise to internal distributed representations that are high-level abstractions of the input, bringing better generalization."
            },
            "slug": "Greedy-Layer-Wise-Training-of-Deep-Networks-Bengio-Lamblin",
            "title": {
                "fragments": [],
                "text": "Greedy Layer-Wise Training of Deep Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "These experiments confirm the hypothesis that the greedy layer-wise unsupervised training strategy mostly helps the optimization, by initializing weights in a region near a good local minimum, giving rise to internal distributed representations that are high-level abstractions of the input, bringing better generalization."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2812486"
                        ],
                        "name": "P. Simard",
                        "slug": "P.-Simard",
                        "structuredName": {
                            "firstName": "Patrice",
                            "lastName": "Simard",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Simard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38767254"
                        ],
                        "name": "David Steinkraus",
                        "slug": "David-Steinkraus",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Steinkraus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Steinkraus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189092"
                        ],
                        "name": "John C. Platt",
                        "slug": "John-C.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Platt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 23
                            }
                        ],
                        "text": ", 1998b) and Microsoft (Simard et al., 2003; Chellapilla et al., 2006), \u2022 detection in images, including faces with record accuracy and real-time performance (Vaillant et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 168
                            }
                        ],
                        "text": "Some ConvNets dispense with the separate pooling layer entirely, but use strides larger than one in the filter bank layer to reduce the resolution (LeCun et al., 1989; Simard et al., 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 149
                            }
                        ],
                        "text": "\u2026to object detection, scene segmentation, and robot navigation:\n\u2022 check reading (handwriting recognition) at AT&T (LeCun et al., 1998b) and Microsoft (Simard et al., 2003; Chellapilla et al., 2006),\n\u2022 detection in images, including faces with record accuracy and real-time performance (Vaillant et\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 265,
                                "start": 256
                            }
                        ],
                        "text": "The approach was very successful, and led to several implementations, ranging from optical character recognition (OCR) to object detection, scene segmentation, and robot navigation:\n\u2022 check reading (handwriting recognition) at AT&T (LeCun et al., 1998b) and Microsoft (Simard et al., 2003; Chellapilla et al., 2006),\n\u2022 detection in images, including faces with record accuracy and real-time performance (Vaillant et al., 1994; Garcia and Delakis, 2004; Osadchy et al., 2007; Nasse et al., 2009), license plates and faces in Google\u2019s StreetView (Frome et al., 2009), or customers\u2019 gender and age at NEC,\n\u2022 more experimental detection of hands/gestures (Nowlan and Platt, 1995), logos and text (Delakis and Garcia, 2008),\n\u2022 vision-based navigation for off-road robots: in the DARPA-sponsored LAGR program, ConvNets were used for long-range obstacle detection (Hadsell et al., 2009)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 4659176,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5562a56da3a96dae82add7de705e2bd841eb00fc",
            "isKey": true,
            "numCitedBy": 2455,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural networks are a powerful technology forclassification of visual inputs arising from documents.However, there is a confusing plethora of different neuralnetwork methods that are used in the literature and inindustry. This paper describes a set of concrete bestpractices that document analysis researchers can use toget good results with neural networks. The mostimportant practice is getting a training set as large aspossible: we expand the training set by adding a newform of distorted data. The next most important practiceis that convolutional neural networks are better suited forvisual document tasks than fully connected networks. Wepropose that a simple \"do-it-yourself\" implementation ofconvolution with a flexible architecture is suitable formany visual document problems. This simpleconvolutional neural network does not require complexmethods, such as momentum, weight decay, structure-dependentlearning rates, averaging layers, tangent prop,or even finely-tuning the architecture. The end result is avery simple yet general architecture which can yieldstate-of-the-art performance for document analysis. Weillustrate our claims on the MNIST set of English digitimages."
            },
            "slug": "Best-practices-for-convolutional-neural-networks-to-Simard-Steinkraus",
            "title": {
                "fragments": [],
                "text": "Best practices for convolutional neural networks applied to visual document analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A set of concrete bestpractices that document analysis researchers can use to get good results with neural networks, including a simple \"do-it-yourself\" implementation of convolution with a flexible architecture suitable for many visual document problems."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47953439"
                        ],
                        "name": "R\u00e9gis Vaillant",
                        "slug": "R\u00e9gis-Vaillant",
                        "structuredName": {
                            "firstName": "R\u00e9gis",
                            "lastName": "Vaillant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R\u00e9gis Vaillant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3208918"
                        ],
                        "name": "C. Monrocq",
                        "slug": "C.-Monrocq",
                        "structuredName": {
                            "firstName": "Christophe",
                            "lastName": "Monrocq",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Monrocq"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9326933"
                        ],
                        "name": "Y. L. Cun",
                        "slug": "Y.-L.-Cun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "Cun",
                            "middleNames": [
                                "le"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. L. Cun"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 147
                            }
                        ],
                        "text": "\u2026and Microsoft (Simard et al., 2003; Chellapilla et al., 2006),\n\u2022 detection in images, including faces with record accuracy and real-time performance (Vaillant et al., 1994; Garcia and Delakis, 2004; Osadchy et al., 2007; Nasse et al., 2009), license plates and faces in Google\u2019s StreetView\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 95
                            }
                        ],
                        "text": ", 2006), \u2022 detection in images, including faces with record accuracy and real-time performance (Vaillant et al., 1994; Garcia and Delakis, 2004; Osadchy et al., 2007; Nasse et al., 2009), license plates and faces in Google\u2019s StreetView (Frome et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62763570,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "09ebd9ad4fa21c0d56433ac57a4cd69e94c72281",
            "isKey": false,
            "numCitedBy": 287,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "An original approach is presented for the localisation of objects in an image which approach is neuronal and has two steps. In the first step, a rough localisation is performed by presenting each pixel with its neighbourhood to a neural net which is able to indicate whether this pixel and its neighbourhood are the image of the search object. This first filter does not discriminate for position. From its result, areas which might contain an image of the object can be selected. In the second step, these areas are presented to another neural net which can determine the exact position of the object in each area. This algorithm is applied to the problem of localising faces in images."
            },
            "slug": "Original-approach-for-the-localisation-of-objects-Vaillant-Monrocq",
            "title": {
                "fragments": [],
                "text": "Original approach for the localisation of objects in images"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "An original approach is presented for the localisation of objects in an image which approach is neuronal and has two steps and is applied to the problem of localising faces in images."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37274089"
                        ],
                        "name": "D. Henderson",
                        "slug": "D.-Henderson",
                        "structuredName": {
                            "firstName": "Donnie",
                            "lastName": "Henderson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Henderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2799635"
                        ],
                        "name": "R. Howard",
                        "slug": "R.-Howard",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Howard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34859193"
                        ],
                        "name": "W. Hubbard",
                        "slug": "W.-Hubbard",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Hubbard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hubbard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041866"
                        ],
                        "name": "L. Jackel",
                        "slug": "L.-Jackel",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Jackel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jackel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 148
                            }
                        ],
                        "text": "Some ConvNets dispense with the separate pooling layer entirely, but use strides larger than one in the filter bank layer to reduce the resolution (LeCun et al., 1989; Simard et al., 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 18
                            }
                        ],
                        "text": "The innovation in LeCun et al. (1989, 1990) was to simplify the architecture and to\nuse the back-propagation algorithm to train the entire system in a supervised fashion."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 41312633,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8e8f3c8d4418c8d62e306538c9c1292635e9d27",
            "isKey": false,
            "numCitedBy": 7920,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification."
            },
            "slug": "Backpropagation-Applied-to-Handwritten-Zip-Code-LeCun-Boser",
            "title": {
                "fragments": [],
                "text": "Backpropagation Applied to Handwritten Zip Code Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This paper demonstrates how constraints from the task domain can be integrated into a backpropagation network through the architecture of the network, successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3160228"
                        ],
                        "name": "K. Fukushima",
                        "slug": "K.-Fukushima",
                        "structuredName": {
                            "firstName": "Kunihiko",
                            "lastName": "Fukushima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukushima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3126340"
                        ],
                        "name": "S. Miyake",
                        "slug": "S.-Miyake",
                        "structuredName": {
                            "firstName": "Sei",
                            "lastName": "Miyake",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Miyake"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2357880,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9aec973227713cd45f156090d82a3056cca8060f",
            "isKey": false,
            "numCitedBy": 698,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neocognitron:-A-new-algorithm-for-pattern-tolerant-Fukushima-Miyake",
            "title": {
                "fragments": [],
                "text": "Neocognitron: A new algorithm for pattern recognition tolerant of deformations and shifts in position"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388546388"
                        ],
                        "name": "Grgoire Montavon",
                        "slug": "Grgoire-Montavon",
                        "structuredName": {
                            "firstName": "Grgoire",
                            "lastName": "Montavon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Grgoire Montavon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1382473772"
                        ],
                        "name": "Genevive Orr",
                        "slug": "Genevive-Orr",
                        "structuredName": {
                            "firstName": "Genevive",
                            "lastName": "Orr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Genevive Orr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068918803"
                        ],
                        "name": "Klaus-Robert Mller",
                        "slug": "Klaus-Robert-Mller",
                        "structuredName": {
                            "firstName": "Klaus-Robert",
                            "lastName": "Mller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Klaus-Robert Mller"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39578794,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b305c18d17fd6a17e8e52a21bcd680220d322cc3",
            "isKey": false,
            "numCitedBy": 610,
            "numCiting": 112,
            "paperAbstract": {
                "fragments": [],
                "text": "The twenty last years have been marked by an increase in available data and computing power. In parallel to this trend, the focus of neural network research and the practice of training neural networks has undergone a number of important changes, for example, use of deep learning machines. The second edition of the book augments the first edition with more tricks, which have resulted from 14 years of theory and experimentation by some of the world's most prominent neural network researchers. These tricks can make a substantial difference (in terms of speed, ease of implementation, and accuracy) when it comes to putting algorithms to work on real problems."
            },
            "slug": "Neural-Networks:-Tricks-of-the-Trade-Montavon-Orr",
            "title": {
                "fragments": [],
                "text": "Neural Networks: Tricks of the Trade"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The second edition of the book augments the first edition with more tricks, which have resulted from 14 years of theory and experimentation by some of the world's most prominent neural network researchers."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644050191"
                        ],
                        "name": "G. LoweDavid",
                        "slug": "G.-LoweDavid",
                        "structuredName": {
                            "firstName": "G",
                            "lastName": "LoweDavid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. LoweDavid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 174065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cab9c4b571761203ed4c3a4c5a07dd615f57a91",
            "isKey": false,
            "numCitedBy": 25753,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are ..."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-LoweDavid",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1658773,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e",
            "isKey": false,
            "numCitedBy": 14754,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such \u201cautoencoder\u201d networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data."
            },
            "slug": "Reducing-the-Dimensionality-of-Data-with-Neural-Hinton-Salakhutdinov",
            "title": {
                "fragments": [],
                "text": "Reducing the Dimensionality of Data with Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work describes an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064414118"
                        ],
                        "name": "F. Ning",
                        "slug": "F.-Ning",
                        "structuredName": {
                            "firstName": "F.",
                            "lastName": "Ning",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Ning"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3252902"
                        ],
                        "name": "D. Delhomme",
                        "slug": "D.-Delhomme",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Delhomme",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Delhomme"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1453335150"
                        ],
                        "name": "F. Piano",
                        "slug": "F.-Piano",
                        "structuredName": {
                            "firstName": "F.",
                            "lastName": "Piano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Piano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2622897"
                        ],
                        "name": "P. Barbano",
                        "slug": "P.-Barbano",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Barbano",
                            "middleNames": [
                                "Emilio"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Barbano"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 293,
                                "start": 276
                            }
                        ],
                        "text": "\u2026as the robot runs, using labels provided by a short-range stereovision system (see videos at http://www.cs.nyu.edu/~yann/research/lagr),\n\u2022 interesting new applications include image restoration (Jain and Seung, 2008) and image segmentation, particularly for biological images (Ning et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 165
                            }
                        ],
                        "text": "edu/~yann/research/lagr), \u2022 interesting new applications include image restoration (Jain and Seung, 2008) and image segmentation, particularly for biological images (Ning et al., 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7801317,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "c029513aef54460ef6a468ff83f549d7ffbb646b",
            "isKey": false,
            "numCitedBy": 261,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a trainable system for analyzing videos of developing C. elegans embryos. The system automatically detects, segments, and locates cells and nuclei in microscopic images. The system was designed as the central component of a fully automated phenotyping system. The system contains three modules 1) a convolutional network trained to classify each pixel into five categories: cell wall, cytoplasm, nucleus membrane, nucleus, outside medium; 2) an energy-based model, which cleans up the output of the convolutional network by learning local consistency constraints that must be satisfied by label images; 3) a set of elastic models of the embryo at various stages of development that are matched to the label images."
            },
            "slug": "Toward-automatic-phenotyping-of-developing-embryos-Ning-Delhomme",
            "title": {
                "fragments": [],
                "text": "Toward automatic phenotyping of developing embryos from videos"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A trainable system for analyzing videos of developing C. elegans embryos that automatically detects, segments, and locates cells and nuclei in microscopic images and contains a set of elastic models of the embryo at various stages of development that are matched to the label images."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690704"
                        ],
                        "name": "Edward A. Lee",
                        "slug": "Edward-A.-Lee",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Lee",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edward A. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815712"
                        ],
                        "name": "D. Messerschmitt",
                        "slug": "D.-Messerschmitt",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Messerschmitt",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Messerschmitt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9981963,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "840546d540c4f090851c426fe823dc5b655002f9",
            "isKey": false,
            "numCitedBy": 1427,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Large grain data flow (LGDF) programming is natural and convenient for describing digital signal processing (DSP) systems, but its runtime overhead is costly in real time or cost-sensitive applications. In some situations, designers are not willing to squander computing resources for the sake of programmer convenience. This is particularly true when the target machine is a programmable DSP chip. However, the runtime overhead inherent in most LGDF implementations is not required for most signal processing systems because such systems are mostly synchronous (in the DSP sense). Synchronous data flow (SDF) differs from traditional data flow in that the amount of data produced and consumed by a data flow node is specified a priori for each input and output. This is equivalent to specifying the relative sample rates in signal processing system. This means that the scheduling of SDF nodes need not be done at runtime, but can be done at compile time (statically), so the runtime overhead evaporates. The sample rates can all be different, which is not true of most current data-driven digital signal processing programming methodologies. Synchronous data flow is closely related to computation graphs, a special case of Petri nets. This self-contained paper develops the theory necessary to statically schedule SDF programs on single or multiple processors. A class of static (compile time) scheduling algorithms is proven valid, and specific algorithms are given for scheduling SDF systems onto single or multiple processors."
            },
            "slug": "Static-Scheduling-of-Synchronous-Data-Flow-Programs-Lee-Messerschmitt",
            "title": {
                "fragments": [],
                "text": "Static Scheduling of Synchronous Data Flow Programs for Digital Signal Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This self-contained paper develops the theory necessary to statically schedule SDF programs on single or multiple processors, and a class of static (compile time) scheduling algorithms is proven valid, and specific algorithms are given for scheduling SDF systems onto single ormultiple processors."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799147"
                        ],
                        "name": "F. Ratle",
                        "slug": "F.-Ratle",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Ratle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Ratle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3232655"
                        ],
                        "name": "H. Mobahi",
                        "slug": "H.-Mobahi",
                        "structuredName": {
                            "firstName": "Hossein",
                            "lastName": "Mobahi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Mobahi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 85
                            }
                        ],
                        "text": "Several works at NEC have also shown that using auxiliary tasks (Ahmed et al., 2008; Weston et al., 2008) helps regularizing the system and produces excellent performance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 740114,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ee368e60d0b826e78f965aad8d6c7d406127104",
            "isKey": false,
            "numCitedBy": 629,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We show how nonlinear embedding algorithms popular for use with shallow semi-supervised learning techniques such as kernel methods can be applied to deep multilayer architectures, either as a regularizer at the output layer, or on each layer of the architecture. This provides a simple alternative to existing approaches to deep learning whilst yielding competitive error rates compared to those methods, and existing shallow semi-supervised techniques."
            },
            "slug": "Deep-learning-via-semi-supervised-embedding-Weston-Ratle",
            "title": {
                "fragments": [],
                "text": "Deep learning via semi-supervised embedding"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "It is shown how nonlinear embedding algorithms popular for use with shallow semi-supervised learning techniques such as kernel methods can be applied to deep multilayer architectures, either as a regularizer at the output layer, or on each layer of the architecture."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144910704"
                        ],
                        "name": "Myong Hyon Cho",
                        "slug": "Myong-Hyon-Cho",
                        "structuredName": {
                            "firstName": "Myong",
                            "lastName": "Cho",
                            "middleNames": [
                                "Hyon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Myong Hyon Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2099588"
                        ],
                        "name": "Chih-Chi Cheng",
                        "slug": "Chih-Chi-Cheng",
                        "structuredName": {
                            "firstName": "Chih-Chi",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chih-Chi Cheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726383"
                        ],
                        "name": "M. Kinsy",
                        "slug": "M.-Kinsy",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Kinsy",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kinsy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691878"
                        ],
                        "name": "G. Suh",
                        "slug": "G.-Suh",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Suh",
                            "middleNames": [
                                "Edward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Suh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695217"
                        ],
                        "name": "S. Devadas",
                        "slug": "S.-Devadas",
                        "structuredName": {
                            "firstName": "Srinivas",
                            "lastName": "Devadas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Devadas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Cho et al. (2008) presents one of the latest data-flow architectures that has several similarities to the approach presented here."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 593092,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af4deb53428742bce2971bdbe63bb4d10af2f254",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Diastolic arrays are arrays of processing elements that communicate exclusively through First-In First-Out (FIFO) queues. FIFO virtualization units enable relaxed timing of data transfers, and include hardware support to guarantee bandwidth and buffer space for all data transfers, which may follow composite paths through the network. We show that the architecture of diastolic arrays enables efficient synthesis from high-level specifications of communicating finite state machines so average throughput is maximized. Preliminary results are presented on an H.264 decoding benchmark."
            },
            "slug": "Diastolic-arrays:-Throughput-driven-reconfigurable-Cho-Cheng",
            "title": {
                "fragments": [],
                "text": "Diastolic arrays: Throughput-driven reconfigurable computing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that the architecture of diastolic arrays enables efficient synthesis from high-level specifications of communicating finite state machines so average throughput is maximized."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE/ACM International Conference on Computer-Aided Design"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065453750"
                        ],
                        "name": "James E. Hicks",
                        "slug": "James-E.-Hicks",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Hicks",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James E. Hicks"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2000338"
                        ],
                        "name": "Derek Chiou",
                        "slug": "Derek-Chiou",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Chiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Chiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35042850"
                        ],
                        "name": "B. S. Ang",
                        "slug": "B.-S.-Ang",
                        "structuredName": {
                            "firstName": "Boon",
                            "lastName": "Ang",
                            "middleNames": [
                                "Seong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. S. Ang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3285866"
                        ],
                        "name": "Arvind",
                        "slug": "Arvind",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Arvind",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arvind"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 81
                            }
                        ],
                        "text": "Several types of grids have been proposed in the past (Dennis and Misunas, 1974; Hicks et al., 1993; Kung, 1986), often trying to solve the dual latency/throughput problem, and often providing a computing fabric that is too rigid."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 186
                            }
                        ],
                        "text": "2.1 A Data-Flow Approach\ndata-flow computing The data-flow hardware architecture was initiated by Adams (1969), and quickly became an active field of research (Dennis and Misunas, 1974; Hicks et al., 1993; l. Gaudiot et al., 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 45065961,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ec363bc062d612b564116d0a801e418f1836d30d",
            "isKey": true,
            "numCitedBy": 66,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract In this paper, we examine the performance of Id, an implicitly parallel language, on Monsoon, an experimental dataflow machine. One of the precepts of our work is that the Id run-time system and compiled Id programs should run on any number of Monsoon processors without change. Our experiments running Id programs on Monsoon show that speedups of more than 7 are easily achieved on 8 processors for most of the applications that we studied. We explain the sources of overhead that limit the speedup of each of our benchmark programs. We also compare the performance of Id on a single Monsoon processor with C/Fortran on a DEC Station 5000 (MIPS R3000 processor), to establish a baseline for the efficiency of Id execution on Monsoon. We find that the execution of Id programs on one Monsoon processor takes up to three times as many cycles as the corresponding C or Fortran programs executing on a MIPS R3000 processor. We identify the sources of inefficiency on Monsoon and suggest improvements, where possible. In many cases, however, improving single processor performance will reduce parallel processor performance."
            },
            "slug": "Performance-Studies-of-Id-on-the-Monsoon-Dataflow-Hicks-Chiou",
            "title": {
                "fragments": [],
                "text": "Performance Studies of Id on the Monsoon Dataflow System"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "The performance of Id, an implicitly parallel language, on Monsoon, an experimental dataflow machine, is examined, finding that the execution of Id programs on one Monsoon processor takes up to three times as many cycles as the corresponding C or Fortran programs executing on a MIPS R3000 processor."
            },
            "venue": {
                "fragments": [],
                "text": "J. Parallel Distributed Comput."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34644975"
                        ],
                        "name": "J. Dennis",
                        "slug": "J.-Dennis",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Dennis",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dennis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2227315"
                        ],
                        "name": "David Misunas",
                        "slug": "David-Misunas",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Misunas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Misunas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3245749,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3046dfe3c1fa75108bddc75c1f11c55ece818a0e",
            "isKey": false,
            "numCitedBy": 273,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "A processor is described which can achieve highly parallel execution of programs represented in data-flow form. The language implemented incorporates conditional and iteration mechanisms, and the processor is a step toward a practical data-flow processor for a Fortran-level data-flow language. The processor has a unique architecture which avoids the problems of processor switching and memory/processor interconnecion that usually limit the degree of realizable concurrent processing. The architecture offers an unusual solution to the problem of structuring and managing a two-level memory system."
            },
            "slug": "A-preliminary-architecture-for-a-basic-data-flow-Dennis-Misunas",
            "title": {
                "fragments": [],
                "text": "A preliminary architecture for a basic data-flow processor"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A processor is described which can achieve highly parallel execution of programs represented in data-flow form and has a unique architecture which avoids the problems of processor switching and memory/processor interconnecion that usually limit the degree of realizable concurrent processing."
            },
            "venue": {
                "fragments": [],
                "text": "ISCA '75"
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144687284"
                        ],
                        "name": "Stacy H. Jones",
                        "slug": "Stacy-H.-Jones",
                        "structuredName": {
                            "firstName": "Stacy",
                            "lastName": "Jones",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stacy H. Jones"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 108
                            }
                        ],
                        "text": "Offline, the training is performed with existing software such as Lush (LeCun and Bottou, 2002) or Torch-5 (Collobert, 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 220894633,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "f8b0dbfb03595013ddc2fcfcfa415ecf1ef5aa74",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "A torch song is a song about unrequited love. The torch song originated in Tin Pan Alley music publishing houses and flourished on post-World War I vaudeville and speakeasy stages in the performances of Edith Piaf, Libby Holman, Billie Holiday, Lee Wiley, and countless others. But just who is the torch singer? What are her history and her place in history? Might her performance move beyond a blind and narcissistic obsession with doomed love affairs? Is her lament a feminist art, a cultural power play? What do her words and movements teach us about autobiography, performance, and culture? This article explores how the author\u2019s experience\u2014as a scholar, feminist, music lover, writer, and woman\u2014burns with these questions. This article enacts a performance ignited by a history of torch singers. Put on your favorite sad song and join in. And by all means, sing along."
            },
            "slug": "Torch-Jones",
            "title": {
                "fragments": [],
                "text": "Torch"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 82
                            }
                        ],
                        "text": "1.1 Convolutional Networks\nconvolutional network!overview\nConvolutional Networks (LeCun et al., 1990, 1998b) are trainable architec-\ntures composed of multiple stages."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 23
                            }
                        ],
                        "text": "Large-Scale FPGA-based Convolutional Networks\nCle\u0301ment Farabet1, Yann LeCun1, Koray Kavukcuoglu1, Eugenio Culurciello2, Berin Martini2,\nPolina Akselrod2, Selcuk Talay2\n1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 18
                            }
                        ],
                        "text": "The innovation in LeCun et al. (1989, 1990) was to simplify the architecture and to\nuse the back-propagation algorithm to train the entire system in a supervised fashion."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 35
                            }
                        ],
                        "text": "May 2, 2011\nLarge-Scale FPGA-Based Convolutional Networks Micro-robots, unmanned aerial vehicles (UAVs), imaging sensor networks, wireless phones, and other embedded vision systems all require low cost and high-speed implementations of synthetic vision systems capable of recognizing and categorizing objects in a scene."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 0
                            }
                        ],
                        "text": "Convolutional Networks (ConvNets) are an answer to the first question."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Handwritten digit recognition with a backpropagation network"
            },
            "venue": {
                "fragments": [],
                "text": "In: NIPS\u201989."
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 82
                            }
                        ],
                        "text": "1.1 Convolutional Networks\nconvolutional network!overview\nConvolutional Networks (LeCun et al., 1990, 1998b) are trainable architec-\ntures composed of multiple stages."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 149
                            }
                        ],
                        "text": "\u2026optical character recognition (OCR) to object detection, scene segmentation, and robot navigation:\n\u2022 check reading (handwriting recognition) at AT&T (LeCun et al., 1998b) and Microsoft (Simard et al., 2003; Chellapilla et al., 2006),\n\u2022 detection in images, including faces with record accuracy and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 3
                            }
                        ],
                        "text": "In LeCun et al. (1998b) and Huang and LeCun (2006), pure supervised learning is used to update the parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 23
                            }
                        ],
                        "text": "Large-Scale FPGA-based Convolutional Networks\nCle\u0301ment Farabet1, Yann LeCun1, Koray Kavukcuoglu1, Eugenio Culurciello2, Berin Martini2,\nPolina Akselrod2, Selcuk Talay2\n1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 35
                            }
                        ],
                        "text": "May 2, 2011\nLarge-Scale FPGA-Based Convolutional Networks Micro-robots, unmanned aerial vehicles (UAVs), imaging sensor networks, wireless phones, and other embedded vision systems all require low cost and high-speed implementations of synthetic vision systems capable of recognizing and categorizing objects in a scene."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 38
                            }
                        ],
                        "text": "Details of the procedure are given in LeCun et al. (1998b), and methods for efficient training are detailed in LeCun et al. (1998a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 0
                            }
                        ],
                        "text": "Convolutional Networks (ConvNets) are an answer to the first question."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 225
                            }
                        ],
                        "text": "The approach was very successful, and led to several implementations, ranging from optical character recognition (OCR) to object detection, scene segmentation, and robot navigation:\n\u2022 check reading (handwriting recognition) at AT&T (LeCun et al., 1998b) and Microsoft (Simard et al., 2003; Chellapilla et al., 2006),\n\u2022 detection in images, including faces with record accuracy and real-time performance (Vaillant et al., 1994; Garcia and Delakis, 2004; Osadchy et al., 2007; Nasse et al., 2009), license plates and faces in Google\u2019s StreetView (Frome et al., 2009), or customers\u2019 gender and age at NEC,\n\u2022 more experimental detection of hands/gestures (Nowlan and Platt, 1995), logos and text (Delakis and Garcia, 2008),\n\u2022 vision-based navigation for off-road robots: in the DARPA-sponsored LAGR program, ConvNets were used for long-range obstacle detection (Hadsell et al., 2009)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "MNIST dataset"
            },
            "venue": {
                "fragments": [],
                "text": "http://yann.lecun.com/exdb/mnist/."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37274089"
                        ],
                        "name": "D. Henderson",
                        "slug": "D.-Henderson",
                        "structuredName": {
                            "firstName": "Donnie",
                            "lastName": "Henderson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Henderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2799635"
                        ],
                        "name": "R. Howard",
                        "slug": "R.-Howard",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Howard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34859193"
                        ],
                        "name": "W. Hubbard",
                        "slug": "W.-Hubbard",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Hubbard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hubbard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041866"
                        ],
                        "name": "L. Jackel",
                        "slug": "L.-Jackel",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Jackel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jackel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723766"
                        ],
                        "name": "H. Baird",
                        "slug": "H.-Baird",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Baird",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Baird"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 82
                            }
                        ],
                        "text": "1.1 Convolutional Networks\nconvolutional network!overview\nConvolutional Networks (LeCun et al., 1990, 1998b) are trainable architec-\ntures composed of multiple stages."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 23
                            }
                        ],
                        "text": "Large-Scale FPGA-based Convolutional Networks\nCle\u0301ment Farabet1, Yann LeCun1, Koray Kavukcuoglu1, Eugenio Culurciello2, Berin Martini2,\nPolina Akselrod2, Selcuk Talay2\n1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 18
                            }
                        ],
                        "text": "The innovation in LeCun et al. (1989, 1990) was to simplify the architecture and to\nuse the back-propagation algorithm to train the entire system in a supervised fashion."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 35
                            }
                        ],
                        "text": "May 2, 2011\nLarge-Scale FPGA-Based Convolutional Networks Micro-robots, unmanned aerial vehicles (UAVs), imaging sensor networks, wireless phones, and other embedded vision systems all require low cost and high-speed implementations of synthetic vision systems capable of recognizing and categorizing objects in a scene."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 0
                            }
                        ],
                        "text": "Convolutional Networks (ConvNets) are an answer to the first question."
                    },
                    "intents": []
                }
            ],
            "corpusId": 59807675,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "3016c38f8f5f1ad479eb25ef199a5b357c999193",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Constrained-neural-network-for-unconstrained-digit-LeCun-Boser",
            "title": {
                "fragments": [],
                "text": "Constrained neural network for unconstrained handwritten digit recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34782608"
                        ],
                        "name": "G. Orr",
                        "slug": "G.-Orr",
                        "structuredName": {
                            "firstName": "Genevieve",
                            "lastName": "Orr",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Orr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145034054"
                        ],
                        "name": "K. M\u00fcller",
                        "slug": "K.-M\u00fcller",
                        "structuredName": {
                            "firstName": "Klaus-Robert",
                            "lastName": "M\u00fcller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. M\u00fcller"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 82
                            }
                        ],
                        "text": "1.1 Convolutional Networks\nconvolutional network!overview\nConvolutional Networks (LeCun et al., 1990, 1998b) are trainable architec-\ntures composed of multiple stages."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 149
                            }
                        ],
                        "text": "\u2026optical character recognition (OCR) to object detection, scene segmentation, and robot navigation:\n\u2022 check reading (handwriting recognition) at AT&T (LeCun et al., 1998b) and Microsoft (Simard et al., 2003; Chellapilla et al., 2006),\n\u2022 detection in images, including faces with record accuracy and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 3
                            }
                        ],
                        "text": "In LeCun et al. (1998b) and Huang and LeCun (2006), pure supervised learning is used to update the parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 23
                            }
                        ],
                        "text": "Large-Scale FPGA-based Convolutional Networks\nCle\u0301ment Farabet1, Yann LeCun1, Koray Kavukcuoglu1, Eugenio Culurciello2, Berin Martini2,\nPolina Akselrod2, Selcuk Talay2\n1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 35
                            }
                        ],
                        "text": "May 2, 2011\nLarge-Scale FPGA-Based Convolutional Networks Micro-robots, unmanned aerial vehicles (UAVs), imaging sensor networks, wireless phones, and other embedded vision systems all require low cost and high-speed implementations of synthetic vision systems capable of recognizing and categorizing objects in a scene."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 38
                            }
                        ],
                        "text": "Details of the procedure are given in LeCun et al. (1998b), and methods for efficient training are detailed in LeCun et al. (1998a)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 0
                            }
                        ],
                        "text": "Convolutional Networks (ConvNets) are an answer to the first question."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 225
                            }
                        ],
                        "text": "The approach was very successful, and led to several implementations, ranging from optical character recognition (OCR) to object detection, scene segmentation, and robot navigation:\n\u2022 check reading (handwriting recognition) at AT&T (LeCun et al., 1998b) and Microsoft (Simard et al., 2003; Chellapilla et al., 2006),\n\u2022 detection in images, including faces with record accuracy and real-time performance (Vaillant et al., 1994; Garcia and Delakis, 2004; Osadchy et al., 2007; Nasse et al., 2009), license plates and faces in Google\u2019s StreetView (Frome et al., 2009), or customers\u2019 gender and age at NEC,\n\u2022 more experimental detection of hands/gestures (Nowlan and Platt, 1995), logos and text (Delakis and Garcia, 2008),\n\u2022 vision-based navigation for off-road robots: in the DARPA-sponsored LAGR program, ConvNets were used for long-range obstacle detection (Hadsell et al., 2009)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 20158889,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b87274e6d9aa4e6ba5148898aa92941617d2b6ed",
            "isKey": false,
            "numCitedBy": 2643,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Efficient-BackProp-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Efficient BackProp"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks: Tricks of the Trade"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 174
                            }
                        ],
                        "text": "Extensive research has been done on the question of how to schedule dataflow computations (Lee and David, 1987), and how to represent streams and computations on streams (l. Gaudiot et al., 1994)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 209
                            }
                        ],
                        "text": "2.1 A Data-Flow Approach\ndata-flow computing The data-flow hardware architecture was initiated by Adams (1969), and quickly became an active field of research (Dennis and Misunas, 1974; Hicks et al., 1993; l. Gaudiot et al., 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stream Data Types for Signal Processing"
            },
            "venue": {
                "fragments": [],
                "text": "In Advances in Dataflow Architecture and Multithreading"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069619574"
                        ],
                        "name": "D. Adams",
                        "slug": "D.-Adams",
                        "structuredName": {
                            "firstName": "Duane",
                            "lastName": "Adams",
                            "middleNames": [
                                "Albert"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Adams"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60952942,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "df2464da7814c0a5356427198a9b9cd97f5bebd7",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-computation-model-with-data-flow-sequencing-Adams",
            "title": {
                "fragments": [],
                "text": "A computation model with data flow sequencing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 72
                            }
                        ],
                        "text": "Offline, the training is performed with existing software such as Lush (LeCun and Bottou, 2002) or Torch-5 (Collobert, 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lush Reference Manual"
            },
            "venue": {
                "fragments": [],
                "text": "Tech. rept. code available at http://lush.sourceforge.net."
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 149
                            }
                        ],
                        "text": "\u2026license plates and faces in Google\u2019s StreetView (Frome et al., 2009), or customers\u2019 gender and age at NEC,\n\u2022 more experimental detection of hands/gestures (Nowlan and Platt, 1995), logos and text (Delakis and Garcia, 2008),\n\u2022 vision-based navigation for off-road robots: in the DARPA-sponsored\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Convolutional Neural Network Hand Tracker. Pages 901\u2013908 of: Neural Information Processing Systems"
            },
            "venue": {
                "fragments": [],
                "text": "A Convolutional Neural Network Hand Tracker. Pages 901\u2013908 of: Neural Information Processing Systems"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Why systolic architectures? 300\u2013309"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 108
                            }
                        ],
                        "text": "Offline, the training is performed with existing software such as Lush (LeCun and Bottou, 2002) or Torch-5 (Collobert, 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Torch. presented at the Workshop on Machine Learning Open Source Software, NIPS"
            },
            "venue": {
                "fragments": [],
                "text": "Torch. presented at the Workshop on Machine Learning Open Source Software, NIPS"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 57
                            }
                        ],
                        "text": ", 2009), license plates and faces in Google\u2019s StreetView (Frome et al., 2009), or customers\u2019 gender and age at NEC, \u2022 more experimental detection of hands/gestures (Nowlan and Platt, 1995), logos and text (Delakis and Garcia, 2008),"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 535,
                                "start": 520
                            }
                        ],
                        "text": "The approach was very successful, and led to several implementations, ranging from optical character recognition (OCR) to object detection, scene segmentation, and robot navigation:\n\u2022 check reading (handwriting recognition) at AT&T (LeCun et al., 1998b) and Microsoft (Simard et al., 2003; Chellapilla et al., 2006),\n\u2022 detection in images, including faces with record accuracy and real-time performance (Vaillant et al., 1994; Garcia and Delakis, 2004; Osadchy et al., 2007; Nasse et al., 2009), license plates and faces in Google\u2019s StreetView (Frome et al., 2009), or customers\u2019 gender and age at NEC,\n\u2022 more experimental detection of hands/gestures (Nowlan and Platt, 1995), logos and text (Delakis and Garcia, 2008),\n\u2022 vision-based navigation for off-road robots: in the DARPA-sponsored LAGR program, ConvNets were used for long-range obstacle detection (Hadsell et al., 2009)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 150
                            }
                        ],
                        "text": "\u2026performance (Vaillant et al., 1994; Garcia and Delakis, 2004; Osadchy et al., 2007; Nasse et al., 2009), license plates and faces in Google\u2019s StreetView (Frome et al., 2009), or customers\u2019 gender and age at NEC,\n\u2022 more experimental detection of hands/gestures (Nowlan and Platt, 1995), logos and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Large-Scale Privacy Protection in Street-Level Imagery"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 37,
            "methodology": 24
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 60,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Large-Scale-FPGA-based-Convolutional-Networks-Farabet-LeCun/b970c9d53c699a8e09f1d8dbe440b6f309712a89?sort=total-citations"
}