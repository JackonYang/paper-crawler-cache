{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2368067"
                        ],
                        "name": "Barret Zoph",
                        "slug": "Barret-Zoph",
                        "structuredName": {
                            "firstName": "Barret",
                            "lastName": "Zoph",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barret Zoph"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 35
                            }
                        ],
                        "text": "A related approach was proposed by Zoph and Le (2016): the topology and hyperparameters of a deep network and LSTM network were modified through policy iteration."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12713052,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "67d968c7450878190e45ac7886746de867bf673d",
            "isKey": false,
            "numCitedBy": 3482,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural networks are powerful and flexible models that work well for many difficult learning tasks in image, speech and natural language understanding. Despite their success, neural networks are still hard to design. In this paper, we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set. On the CIFAR-10 dataset, our method, starting from scratch, can design a novel network architecture that rivals the best human-invented architecture in terms of test set accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is 0.09 percent better and 1.05x faster than the previous state-of-the-art model that used a similar architectural scheme. On the Penn Treebank dataset, our model can compose a novel recurrent cell that outperforms the widely-used LSTM cell, and other state-of-the-art baselines. Our cell achieves a test set perplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than the previous state-of-the-art model. The cell can also be transferred to the character language modeling task on PTB and achieves a state-of-the-art perplexity of 1.214."
            },
            "slug": "Neural-Architecture-Search-with-Reinforcement-Zoph-Le",
            "title": {
                "fragments": [],
                "text": "Neural Architecture Search with Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper uses a recurrent network to generate the model descriptions of neural networks and trains this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678656"
                        ],
                        "name": "I. Loshchilov",
                        "slug": "I.-Loshchilov",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Loshchilov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Loshchilov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": " recently, a studies have started to emerge with the goal of optimizing DNNs. Due to limited computational resources, they have focused on speci\u2022c parts of the design. For instance, Loshchilov et al. [33] used CMA-ES to optimize the hyperparametersofexistingDNNsobtainingstate-of-the-artresultsone.g.object recognition. Further, Fernando et al. [10] evolved a CPPN (compositional pa\u2212ern-producing network"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17098047,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "417f02dfc599699c94e732f3600d559d8e41fa17",
            "isKey": false,
            "numCitedBy": 218,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Hyperparameters of deep neural networks are often optimized by grid search, random search or Bayesian optimization. As an alternative, we propose to use the Covariance Matrix Adaptation Evolution Strategy (CMA-ES), which is known for its state-of-the-art performance in derivative-free optimization. CMA-ES has some useful invariance properties and is friendly to parallel evaluations of solutions. We provide a toy example comparing CMA-ES and state-of-the-art Bayesian optimization algorithms for tuning the hyperparameters of a convolutional neural network for the MNIST dataset on 30 GPUs in parallel."
            },
            "slug": "CMA-ES-for-Hyperparameter-Optimization-of-Deep-Loshchilov-Hutter",
            "title": {
                "fragments": [],
                "text": "CMA-ES for Hyperparameter Optimization of Deep Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This work proposes to use the Covariance Matrix Adaptation Evolution Strategy (CMA-ES), which is known for its state-of-the-art performance in derivative-free optimization, for tuning the hyperparameters of a convolutional neural network for the MNIST dataset on 30 GPUs in parallel."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143939165"
                        ],
                        "name": "Chrisantha Fernando",
                        "slug": "Chrisantha-Fernando",
                        "structuredName": {
                            "firstName": "Chrisantha",
                            "lastName": "Fernando",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chrisantha Fernando"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32689129"
                        ],
                        "name": "D. Banarse",
                        "slug": "D.-Banarse",
                        "structuredName": {
                            "firstName": "Dylan",
                            "lastName": "Banarse",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Banarse"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47447264"
                        ],
                        "name": "Malcolm Reynolds",
                        "slug": "Malcolm-Reynolds",
                        "structuredName": {
                            "firstName": "Malcolm",
                            "lastName": "Reynolds",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Malcolm Reynolds"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143923544"
                        ],
                        "name": "F. Besse",
                        "slug": "F.-Besse",
                        "structuredName": {
                            "firstName": "Frederic",
                            "lastName": "Besse",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Besse"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144846367"
                        ],
                        "name": "D. Pfau",
                        "slug": "D.-Pfau",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Pfau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pfau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3093886"
                        ],
                        "name": "Max Jaderberg",
                        "slug": "Max-Jaderberg",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Jaderberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Max Jaderberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1975889"
                        ],
                        "name": "Marc Lanctot",
                        "slug": "Marc-Lanctot",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Lanctot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc Lanctot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688276"
                        ],
                        "name": "Daan Wierstra",
                        "slug": "Daan-Wierstra",
                        "structuredName": {
                            "firstName": "Daan",
                            "lastName": "Wierstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daan Wierstra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1117341,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "99901920de0ca5e129cc2b3fbdcdd257a105f16a",
            "isKey": false,
            "numCitedBy": 88,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we introduce a differentiable version of the Compositional Pattern Producing Network, called the DPPN. Unlike a standard CPPN, the topology of a DPPN is evolved but the weights are learned. A Lamarckian algorithm, that combines evolution and learning, produces DPPNs to reconstruct an image. Our main result is that DPPNs can be evolved/trained to compress the weights of a denoising autoencoder from 157684 to roughly 200 parameters, while achieving a reconstruction accuracy comparable to a fully connected network with more than two orders of magnitude more parameters. The regularization ability of the DPPN allows it to rediscover (approximate) convolutional network architectures embedded within a fully connected architecture. Such convolutional architectures are the current state of the art for many computer vision applications, so it is satisfying that DPPNs are capable of discovering this structure rather than having to build it in by design. DPPNs exhibit better generalization when tested on the Omniglot dataset after being trained on MNIST, than directly encoded fully connected autoencoders. DPPNs are therefore a new framework for integrating learning and evolution."
            },
            "slug": "Convolution-by-Evolution:-Differentiable-Pattern-Fernando-Banarse",
            "title": {
                "fragments": [],
                "text": "Convolution by Evolution: Differentiable Pattern Producing Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This work introduces a differentiable version of the Compositional Pattern Producing Network, called the DPPN, which can be evolved/trained to compress the weights of a denoising autoencoder while achieving a reconstruction accuracy comparable to a fully connected network with more than two orders of magnitude more parameters."
            },
            "venue": {
                "fragments": [],
                "text": "GECCO"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2574060"
                        ],
                        "name": "Christian Szegedy",
                        "slug": "Christian-Szegedy",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Szegedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Szegedy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2657155"
                        ],
                        "name": "Vincent Vanhoucke",
                        "slug": "Vincent-Vanhoucke",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Vanhoucke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Vanhoucke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054165706"
                        ],
                        "name": "S. Ioffe",
                        "slug": "S.-Ioffe",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Ioffe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ioffe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789737"
                        ],
                        "name": "Jonathon Shlens",
                        "slug": "Jonathon-Shlens",
                        "structuredName": {
                            "firstName": "Jonathon",
                            "lastName": "Shlens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathon Shlens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3282833"
                        ],
                        "name": "Z. Wojna",
                        "slug": "Z.-Wojna",
                        "structuredName": {
                            "firstName": "Zbigniew",
                            "lastName": "Wojna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Wojna"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206593880,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23ffaa0fe06eae05817f527a47ac3291077f9e58",
            "isKey": false,
            "numCitedBy": 15857,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional networks are at the core of most state of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21:2% top-1 and 5:6% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3:5% top-5 error and 17:3% top-1 error on the validation set and 3:6% top-5 error on the official test set."
            },
            "slug": "Rethinking-the-Inception-Architecture-for-Computer-Szegedy-Vanhoucke",
            "title": {
                "fragments": [],
                "text": "Rethinking the Inception Architecture for Computer Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work is exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771551"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3080683"
                        ],
                        "name": "Shaoqing Ren",
                        "slug": "Shaoqing-Ren",
                        "structuredName": {
                            "firstName": "Shaoqing",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoqing Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 144
                            }
                        ],
                        "text": "Much of the recent work in deep learning has indeed focused on proposing different handdesigned architectures on new problems (Che et al. 2016; He et al. 2016; Ng et al. 2015; Szegedy et al. 2016b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 121
                            }
                        ],
                        "text": "Many of the most successful DNNs, such as GoogLeNet and ResNet are composed of modules that are repeated multiple times (He et al. 2016; Szegedy et al. 2016b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6447277,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "77f0a39b8e02686fd85b01971f8feb7f60971f80",
            "isKey": false,
            "numCitedBy": 6555,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep residual networks have emerged as a family of extremely deep architectures showing compelling accuracy and nice convergence behaviors. In this paper, we analyze the propagation formulations behind the residual building blocks, which suggest that the forward and backward signals can be directly propagated from one block to any other block, when using identity mappings as the skip connections and after-addition activation. A series of ablation experiments support the importance of these identity mappings. This motivates us to propose a new residual unit, which makes training easier and improves generalization. We report improved results using a 1001-layer ResNet on CIFAR-10 (4.62 % error) and CIFAR-100, and a 200-layer ResNet on ImageNet. Code is available at: https://github.com/KaimingHe/resnet-1k-layers."
            },
            "slug": "Identity-Mappings-in-Deep-Residual-Networks-He-Zhang",
            "title": {
                "fragments": [],
                "text": "Identity Mappings in Deep Residual Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The propagation formulations behind the residual building blocks suggest that the forward and backward signals can be directly propagated from one block to any other block, when using identity mappings as the skip connections and after-addition activation."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1944541"
                        ],
                        "name": "R. J\u00f3zefowicz",
                        "slug": "R.-J\u00f3zefowicz",
                        "structuredName": {
                            "firstName": "Rafal",
                            "lastName": "J\u00f3zefowicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. J\u00f3zefowicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2563432"
                        ],
                        "name": "Wojciech Zaremba",
                        "slug": "Wojciech-Zaremba",
                        "structuredName": {
                            "firstName": "Wojciech",
                            "lastName": "Zaremba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wojciech Zaremba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 119
                            }
                        ],
                        "text": "Recent research on LSTMs has focused in two directions: Finding variations of individual LSTM memory unit architecture (Bayer et al. 2009; Cho et al. 2014; Jozefowicz et al. 2015; Klaus et al. 2014), and discovering new ways of stitching LSTM layers into a network (Chung et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9668607,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5b8364c21155d3d2cd38ea4c8b8580beba9a3250",
            "isKey": false,
            "numCitedBy": 1395,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The Recurrent Neural Network (RNN) is an extremely powerful sequence model that is often difficult to train. The Long Short-Term Memory (LSTM) is a specific RNN architecture whose design makes it much easier to train. While wildly successful in practice, the LSTM's architecture appears to be ad-hoc so it is not clear if it is optimal, and the significance of its individual components is unclear. \n \nIn this work, we aim to determine whether the LSTM architecture is optimal or whether much better architectures exist. We conducted a thorough architecture search where we evaluated over ten thousand different RNN architectures, and identified an architecture that outperforms both the LSTM and the recently-introduced Gated Recurrent Unit (GRU) on some but not all tasks. We found that adding a bias of 1 to the LSTM's forget gate closes the gap between the LSTM and the GRU."
            },
            "slug": "An-Empirical-Exploration-of-Recurrent-Network-J\u00f3zefowicz-Zaremba",
            "title": {
                "fragments": [],
                "text": "An Empirical Exploration of Recurrent Network Architectures"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "It is found that adding a bias of 1 to the LSTM's forget gate closes the gap between the L STM and the recently-introduced Gated Recurrent Unit (GRU) on some but not all tasks."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2340579"
                        ],
                        "name": "J. Ng",
                        "slug": "J.-Ng",
                        "structuredName": {
                            "firstName": "Joe",
                            "lastName": "Ng",
                            "middleNames": [
                                "Yue-Hei"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308897"
                        ],
                        "name": "M. Hausknecht",
                        "slug": "M.-Hausknecht",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hausknecht",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hausknecht"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2259154"
                        ],
                        "name": "Sudheendra Vijayanarasimhan",
                        "slug": "Sudheendra-Vijayanarasimhan",
                        "structuredName": {
                            "firstName": "Sudheendra",
                            "lastName": "Vijayanarasimhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sudheendra Vijayanarasimhan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3089272"
                        ],
                        "name": "R. Monga",
                        "slug": "R.-Monga",
                        "structuredName": {
                            "firstName": "Rajat",
                            "lastName": "Monga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Monga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805076"
                        ],
                        "name": "G. Toderici",
                        "slug": "G.-Toderici",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Toderici",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Toderici"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4245530,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5418b2a482720e013d487a385c26fae0f017c6a6",
            "isKey": false,
            "numCitedBy": 1949,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional neural networks (CNNs) have been extensively applied for image recognition problems giving state-of-the-art results on recognition, detection, segmentation and retrieval. In this work we propose and evaluate several deep neural network architectures to combine image information across a video over longer time periods than previously attempted. We propose two methods capable of handling full length videos. The first method explores various convolutional temporal feature pooling architectures, examining the various design choices which need to be made when adapting a CNN for this task. The second proposed method explicitly models the video as an ordered sequence of frames. For this purpose we employ a recurrent neural network that uses Long Short-Term Memory (LSTM) cells which are connected to the output of the underlying CNN. Our best networks exhibit significant performance improvements over previously published results on the Sports 1 million dataset (73.1% vs. 60.9%) and the UCF-101 datasets with (88.6% vs. 88.0%) and without additional optical flow information (82.6% vs. 73.0%)."
            },
            "slug": "Beyond-short-snippets:-Deep-networks-for-video-Ng-Hausknecht",
            "title": {
                "fragments": [],
                "text": "Beyond short snippets: Deep networks for video classification"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work proposes and evaluates several deep neural network architectures to combine image information across a video over longer time periods than previously attempted, and proposes two methods capable of handling full length videos."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742820"
                        ],
                        "name": "D. Floreano",
                        "slug": "D.-Floreano",
                        "structuredName": {
                            "firstName": "Dario",
                            "lastName": "Floreano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Floreano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066182179"
                        ],
                        "name": "Peter D\u00fcrr",
                        "slug": "Peter-D\u00fcrr",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "D\u00fcrr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter D\u00fcrr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2288013"
                        ],
                        "name": "C. Mattiussi",
                        "slug": "C.-Mattiussi",
                        "structuredName": {
                            "firstName": "Claudio",
                            "lastName": "Mattiussi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Mattiussi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 104
                            }
                        ],
                        "text": "Neuroevolution techniques have been applied successfully to sequential decision tasks for three decades (Floreano et al. 2008; Lehman and Miikkulainen 2013; Montana and Davis 1989; Yao 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2942634,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cf7bdff21a875e5d043514ed0714fafae77e1492",
            "isKey": false,
            "numCitedBy": 652,
            "numCiting": 119,
            "paperAbstract": {
                "fragments": [],
                "text": "Artificial neural networks (ANNs) are applied to many real-world problems, ranging from pattern classification to robot control. In order to design a neural network for a particular task, the choice of an architecture (including the choice of a neuron model), and the choice of a learning algorithm have to be addressed. Evolutionary search methods can provide an automatic solution to these problems. New insights in both neuroscience and evolutionary biology have led to the development of increasingly powerful neuroevolution techniques over the last decade. This paper gives an overview of the most prominent methods for evolving ANNs with a special focus on recent advances in the synthesis of learning architectures."
            },
            "slug": "Neuroevolution:-from-architectures-to-learning-Floreano-D\u00fcrr",
            "title": {
                "fragments": [],
                "text": "Neuroevolution: from architectures to learning"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper gives an overview of the most prominent methods for evolving ANNs with a special focus on recent advances in the synthesis of learning architectures."
            },
            "venue": {
                "fragments": [],
                "text": "Evol. Intell."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144108062"
                        ],
                        "name": "Jasper Snoek",
                        "slug": "Jasper-Snoek",
                        "structuredName": {
                            "firstName": "Jasper",
                            "lastName": "Snoek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jasper Snoek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757324"
                        ],
                        "name": "Oren Rippel",
                        "slug": "Oren-Rippel",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Rippel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Rippel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754860"
                        ],
                        "name": "Kevin Swersky",
                        "slug": "Kevin-Swersky",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Swersky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Swersky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3450996"
                        ],
                        "name": "Ryan Kiros",
                        "slug": "Ryan-Kiros",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Kiros",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan Kiros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143758120"
                        ],
                        "name": "N. Satish",
                        "slug": "N.-Satish",
                        "structuredName": {
                            "firstName": "Nadathur",
                            "lastName": "Satish",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Satish"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789372"
                        ],
                        "name": "N. Sundaram",
                        "slug": "N.-Sundaram",
                        "structuredName": {
                            "firstName": "Narayanan",
                            "lastName": "Sundaram",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sundaram"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8176660"
                        ],
                        "name": "Md. Mostofa Ali Patwary",
                        "slug": "Md.-Mostofa-Ali-Patwary",
                        "structuredName": {
                            "firstName": "Md.",
                            "lastName": "Patwary",
                            "middleNames": [
                                "Mostofa",
                                "Ali"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Md. Mostofa Ali Patwary"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764912"
                        ],
                        "name": "Prabhat",
                        "slug": "Prabhat",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Prabhat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Prabhat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722180"
                        ],
                        "name": "Ryan P. Adams",
                        "slug": "Ryan-P.-Adams",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Adams",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan P. Adams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 31
                            }
                        ],
                        "text": "Model BLEU-4 CIDEr METEOR DNGO (Snoek et al. 2015) 26."
                    },
                    "intents": []
                }
            ],
            "corpusId": 12604141,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "93bc65d2842b8cc5f3cf72ebc5b8f75daeacea35",
            "isKey": false,
            "numCitedBy": 711,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "Bayesian optimization is an effective methodology for the global optimization of functions with expensive evaluations. It relies on querying a distribution over functions defined by a relatively cheap surrogate model. An accurate model for this distribution over functions is critical to the effectiveness of the approach, and is typically fit using Gaussian processes (GPs). However, since GPs scale cubically with the number of observations, it has been challenging to handle objectives whose optimization requires many evaluations, and as such, massively parallelizing the optimization. \n \nIn this work, we explore the use of neural networks as an alternative to GPs to model distributions over functions. We show that performing adaptive basis function regression with a neural network as the parametric form performs competitively with state-of-the-art GP-based approaches, but scales linearly with the number of data rather than cubically. This allows us to achieve a previously intractable degree of parallelism, which we apply to large scale hyperparameter optimization, rapidly finding competitive models on benchmark object recognition tasks using convolutional networks, and image caption generation using neural language models."
            },
            "slug": "Scalable-Bayesian-Optimization-Using-Deep-Neural-Snoek-Rippel",
            "title": {
                "fragments": [],
                "text": "Scalable Bayesian Optimization Using Deep Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work shows that performing adaptive basis function regression with a neural network as the parametric form performs competitively with state-of-the-art GP-based approaches, but scales linearly with the number of data rather than cubically, which allows for a previously intractable degree of parallelism."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771551"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3080683"
                        ],
                        "name": "Shaoqing Ren",
                        "slug": "Shaoqing-Ren",
                        "structuredName": {
                            "firstName": "Shaoqing",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoqing Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "TM layers, providingtheso\u2013maxwithamoredirectviewofthe current input. \u2044e motif of skip connections with a summing merge is similar to residual architectures that are currently popular in deep learning [19, 44]. Model BLEU-4 CIDEr METEOR DNGO [41] 26.7 \u2014 \u2014 Baseline [47] 27.7 85.5 23.7 Evolved 29.1 88.0 23.8 Table 3: \u2044e evolved network improves over the handdesigned baseline when trained on MSCOCO alone. han"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206594692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "isKey": true,
            "numCitedBy": 97653,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation."
            },
            "slug": "Deep-Residual-Learning-for-Image-Recognition-He-Zhang",
            "title": {
                "fragments": [],
                "text": "Deep Residual Learning for Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work presents a residual learning framework to ease the training of networks that are substantially deeper than those used previously, and provides comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726415"
                        ],
                        "name": "Alexander Toshev",
                        "slug": "Alexander-Toshev",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Toshev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander Toshev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761978"
                        ],
                        "name": "D. Erhan",
                        "slug": "D.-Erhan",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Erhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Erhan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 283,
                                "start": 262
                            }
                        ],
                        "text": "There are many known improvements that can be implemented, including ensembling diverse architectures generated by evolution, fine-tuning of the ImageNet model, using a more recent ImageNet model, and performing beam search or scheduled sampling during training (Vinyals et al. 2016) (preliminary experiments with ensembling alone suggest improvements of about 20%)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8289133,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e",
            "isKey": false,
            "numCitedBy": 628,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing. In this paper, we present a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image. The model is trained to maximize the likelihood of the target description sentence given the training image. Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions. Our model is often quite accurate, which we verify both qualitatively and quantitatively. Finally, given the recent surge of interest in this task, a competition was organized in 2015 using the newly released COCO dataset. We describe and analyze the various improvements we applied to our own baseline and show the resulting performance in the competition, which we won ex-aequo with a team from Microsoft Research."
            },
            "slug": "Show-and-Tell:-Lessons-Learned-from-the-2015-MSCOCO-Vinyals-Toshev",
            "title": {
                "fragments": [],
                "text": "Show and Tell: Lessons Learned from the 2015 MSCOCO Image Captioning Challenge"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2574060"
                        ],
                        "name": "Christian Szegedy",
                        "slug": "Christian-Szegedy",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Szegedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Szegedy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054165706"
                        ],
                        "name": "S. Ioffe",
                        "slug": "S.-Ioffe",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Ioffe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ioffe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2657155"
                        ],
                        "name": "Vincent Vanhoucke",
                        "slug": "Vincent-Vanhoucke",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Vanhoucke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Vanhoucke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122113652"
                        ],
                        "name": "Alexander A. Alemi",
                        "slug": "Alexander-A.-Alemi",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Alemi",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander A. Alemi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 176
                            }
                        ],
                        "text": "Much of the recent work in deep learning has indeed focused on proposing different handdesigned architectures on new problems (Che et al. 2016; He et al. 2016; Ng et al. 2015; Szegedy et al. 2016b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 90
                            }
                        ],
                        "text": "As is common in existing approaches, the evolved system uses a pretrained ImageNet model (Szegedy et al. 2016b) to produce initial image embeddings."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 288,
                                "start": 268
                            }
                        ],
                        "text": "\u2026long short-term memory, or LSTM (Hochreiter and Schmidhuber 1997)), which have existed since the 1990s, have improved state-of-the-art significantly in computer vision, speech, language processing, and many other areas (Collobert and Weston 2008; Graves et al. 2013; Szegedy et al. 2016b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 137
                            }
                        ],
                        "text": "Many of the most successful DNNs, such as GoogLeNet and ResNet are composed of modules that are repeated multiple times (He et al. 2016; Szegedy et al. 2016b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1023605,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5c26ab8767d046cb6e32d959fdf726aee89bb62",
            "isKey": true,
            "numCitedBy": 8225,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "\n \n Very deep convolutional networks have been central to the largest advances in image recognition performance in recent years. One example is the Inception architecture that has been shown to achieve very good performance at relatively low computational cost. Recently, the introduction of residual connections in conjunction with a more traditional architecture has yielded state-of-the-art performance in the 2015 ILSVRC challenge; its performance was similar to the latest generation Inception-v3 network. This raises the question: Are there any benefits to combining Inception architectures with residual connections? Here we give clear empirical evidence that training with residual connections accelerates the training of Inception networks significantly. There is also some evidence of residual Inception networks outperforming similarly expensive Inception networks without residual connections by a thin margin. We also present several new streamlined architectures for both residual and non-residual Inception networks. These variations improve the single-frame recognition performance on the ILSVRC 2012 classification task significantly. We further demonstrate how proper activation scaling stabilizes the training of very wide residual Inception networks. With an ensemble of three residual and one Inception-v4 networks, we achieve 3.08% top-5 error on the test set of the ImageNet classification (CLS) challenge.\n \n"
            },
            "slug": "Inception-v4,-Inception-ResNet-and-the-Impact-of-on-Szegedy-Ioffe",
            "title": {
                "fragments": [],
                "text": "Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Clear empirical evidence that training with residual connections accelerates the training of Inception networks significantly is given and several new streamlined architectures for both residual and non-residual Inception Networks are presented."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726415"
                        ],
                        "name": "Alexander Toshev",
                        "slug": "Alexander-Toshev",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Toshev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander Toshev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761978"
                        ],
                        "name": "D. Erhan",
                        "slug": "D.-Erhan",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Erhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Erhan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 159
                            }
                        ],
                        "text": "As usual, in training the text input contains the previous word of the ground truth caption; in inference it contains the previous word generated by the model (Karpathy and Fei-Fei 2015; Vinyals et al. 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 74
                            }
                        ],
                        "text": "In particular, the well-known Show and Tell image captioning architecture (Vinyals et al. 2015) is in this search space, providing a baseline with which evolution results can be compared."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 63
                            }
                        ],
                        "text": "This architecture performs better than the hand-tuned baseline (Vinyals et al. 2015) when trained on the MSCOCO data alone (Table 3)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 196
                            }
                        ],
                        "text": "As a result, there is evolutionary pressure towards networks that converge quickly: The best resulting architectures train to near convergence 6 times faster than the baseline Show and Tell model (Vinyals et al. 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 243,
                                "start": 140
                            }
                        ],
                        "text": "Deep learning has recently provided state-of-the-art performance in image captioning, and several diverse architectures have been suggested (Karpathy and Fei-Fei 2015; Vedantam et al. 2017; Vinyals et al. 2015; Xu et al. 2015; You et al. 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1169492,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0",
            "isKey": true,
            "numCitedBy": 4558,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing. In this paper, we present a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image. The model is trained to maximize the likelihood of the target description sentence given the training image. Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions. Our model is often quite accurate, which we verify both qualitatively and quantitatively. For instance, while the current state-of-the-art BLEU-1 score (the higher the better) on the Pascal dataset is 25, our approach yields 59, to be compared to human performance around 69. We also show BLEU-1 score improvements on Flickr30k, from 56 to 66, and on SBU, from 19 to 28. Lastly, on the newly released COCO dataset, we achieve a BLEU-4 of 27.7, which is the current state-of-the-art."
            },
            "slug": "Show-and-tell:-A-neural-image-caption-generator-Vinyals-Toshev",
            "title": {
                "fragments": [],
                "text": "Show and tell: A neural image caption generator"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper presents a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1846883"
                        ],
                        "name": "Kenneth O. Stanley",
                        "slug": "Kenneth-O.-Stanley",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Stanley",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth O. Stanley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686788"
                        ],
                        "name": "R. Miikkulainen",
                        "slug": "R.-Miikkulainen",
                        "structuredName": {
                            "firstName": "Risto",
                            "lastName": "Miikkulainen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Miikkulainen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ormance. \u201eird, the approach is used to build a real-world application on captioning images in the website for an online magazine. 3 EVOLUTION OF DEEP LEARNING ARCHITECTURES NEAT neuroevolution method [43] is \u2022rst extended to evolving network topology and hyperparameters of deep neural networks in DeepNEAT, and then further to coevolution of modules and blueprints for combining them in CoDeepNEAT. \u201ee a"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "design. \u201eese three aspects need to be optimized separately for each new task. \u201eis paper develops an approach for automatic design of DNNs. It is based on the existing neuroevolution technique of NEAT [43], which has been successful in evolving topologies and weights of relatively small recurrent networks in the past. In this paper, NEAT is extended to the coevolutionary optimization of components, top"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Other approaches such as SANE, ESP, and CoSyNE evolve partial neural networks and combine them into fully functional networks [12, 14, 37]. Further, techniques such as Cellular Encoding [18] and NEAT [43] have been developed to evolve the topology of the neural network, which is particularly e\u2021ective in determining the required recurrence. Neuroevolution techniques have been shown to work well in many"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 498161,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "d03c916d49268d48fde3b76a68e64af7761835e7",
            "isKey": false,
            "numCitedBy": 2994,
            "numCiting": 90,
            "paperAbstract": {
                "fragments": [],
                "text": "An important question in neuroevolution is how to gain an advantage from evolving neural network topologies along with weights. We present a method, NeuroEvolution of Augmenting Topologies (NEAT), which outperforms the best fixed-topology method on a challenging benchmark reinforcement learning task. We claim that the increased efficiency is due to (1) employing a principled method of crossover of different topologies, (2) protecting structural innovation using speciation, and (3) incrementally growing from minimal structure. We test this claim through a series of ablation studies that demonstrate that each component is necessary to the system as a whole and to each other. What results is signicantly faster learning. NEAT is also an important contribution to GAs because it shows how it is possible for evolution to both optimize and complexify solutions simultaneously, offering the possibility of evolving increasingly complex solutions over generations, and strengthening the analogy with biological evolution."
            },
            "slug": "Evolving-Neural-Networks-through-Augmenting-Stanley-Miikkulainen",
            "title": {
                "fragments": [],
                "text": "Evolving Neural Networks through Augmenting Topologies"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A method is presented, NeuroEvolution of Augmenting Topologies (NEAT), which outperforms the best fixed-topology method on a challenging benchmark reinforcement learning task and shows how it is possible for evolution to both optimize and complexify solutions simultaneously."
            },
            "venue": {
                "fragments": [],
                "text": "Evolutionary Computation"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 246,
                                "start": 221
                            }
                        ],
                        "text": "\u2026long short-term memory, or LSTM (Hochreiter and Schmidhuber 1997)), which have existed since the 1990s, have improved state-of-the-art significantly in computer vision, speech, language processing, and many other areas (Collobert and Weston 2008; Graves et al. 2013; Szegedy et al. 2016b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2617020,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "57458bc1cffe5caa45a885af986d70f723f406b4",
            "isKey": false,
            "numCitedBy": 5064,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance."
            },
            "slug": "A-unified-architecture-for-natural-language-deep-Collobert-Weston",
            "title": {
                "fragments": [],
                "text": "A unified architecture for natural language processing: deep neural networks with multitask learning"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This work describes a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense using a language model."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3035541"
                        ],
                        "name": "Klaus Greff",
                        "slug": "Klaus-Greff",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Greff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Klaus Greff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2100612"
                        ],
                        "name": "R. Srivastava",
                        "slug": "R.-Srivastava",
                        "structuredName": {
                            "firstName": "Rupesh",
                            "lastName": "Srivastava",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Srivastava"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2865775"
                        ],
                        "name": "J. Koutn\u00edk",
                        "slug": "J.-Koutn\u00edk",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Koutn\u00edk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Koutn\u00edk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714059"
                        ],
                        "name": "Bas R. Steunebrink",
                        "slug": "Bas-R.-Steunebrink",
                        "structuredName": {
                            "firstName": "Bas",
                            "lastName": "Steunebrink",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bas R. Steunebrink"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 119
                            }
                        ],
                        "text": "Recent research on LSTMs has focused in two directions: Finding variations of individual LSTM memory unit architecture (Bayer et al. 2009; Cho et al. 2014; Jozefowicz et al. 2015; Klaus et al. 2014), and discovering new ways of stitching LSTM layers into a network (Chung et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 144
                            }
                        ],
                        "text": "\u2026in two directions: Finding variations of individual LSTM memory unit architecture (Bayer et al. 2009; Cho et al. 2014; Jozefowicz et al. 2015; Klaus et al. 2014), and discovering new ways of stitching LSTM layers into a network (Chung et al. 2015; Kalchbrenner et al. 2015; Zilly et al. 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3356463,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a7976c2bacfbb194ddbe7fd10c2e50a545cf4081",
            "isKey": false,
            "numCitedBy": 3337,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "Several variants of the long short-term memory (LSTM) architecture for recurrent neural networks have been proposed since its inception in 1995. In recent years, these networks have become the state-of-the-art models for a variety of machine learning problems. This has led to a renewed interest in understanding the role and utility of various computational components of typical LSTM variants. In this paper, we present the first large-scale analysis of eight LSTM variants on three representative tasks: speech recognition, handwriting recognition, and polyphonic music modeling. The hyperparameters of all LSTM variants for each task were optimized separately using random search, and their importance was assessed using the powerful functional ANalysis Of VAriance framework. In total, we summarize the results of 5400 experimental runs ( $\\approx 15$  years of CPU time), which makes our study the largest of its kind on LSTM networks. Our results show that none of the variants can improve upon the standard LSTM architecture significantly, and demonstrate the forget gate and the output activation function to be its most critical components. We further observe that the studied hyperparameters are virtually independent and derive guidelines for their efficient adjustment."
            },
            "slug": "LSTM:-A-Search-Space-Odyssey-Greff-Srivastava",
            "title": {
                "fragments": [],
                "text": "LSTM: A Search Space Odyssey"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents the first large-scale analysis of eight LSTM variants on three representative tasks: speech recognition, handwriting recognition, and polyphonic music modeling, and observes that the studied hyperparameters are virtually independent and derive guidelines for their efficient adjustment."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Neural Networks and Learning Systems"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40360972"
                        ],
                        "name": "Abdel-rahman Mohamed",
                        "slug": "Abdel-rahman-Mohamed",
                        "structuredName": {
                            "firstName": "Abdel-rahman",
                            "lastName": "Mohamed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abdel-rahman Mohamed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 339,
                                "start": 270
                            }
                        ],
                        "text": "1998) and recurrent neural networks (in particular long short-term memory, or LSTM (Hochreiter and Schmidhuber 1997)), which have existed since the 1990s, have improved state-of-the-art significantly in computer vision, speech, language processing, and many other areas (Collobert and Weston 2008; Graves et al. 2013; Szegedy et al. 2016b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206741496,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4177ec52d1b80ed57f2e72b0f9a42365f1a8598d",
            "isKey": false,
            "numCitedBy": 6959,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Recurrent neural networks (RNNs) are a powerful model for sequential data. End-to-end training methods such as Connectionist Temporal Classification make it possible to train RNNs for sequence labelling problems where the input-output alignment is unknown. The combination of these methods with the Long Short-term Memory RNN architecture has proved particularly fruitful, delivering state-of-the-art results in cursive handwriting recognition. However RNN performance in speech recognition has so far been disappointing, with better results returned by deep feedforward networks. This paper investigates deep recurrent neural networks, which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs. When trained end-to-end with suitable regularisation, we find that deep Long Short-term Memory RNNs achieve a test set error of 17.7% on the TIMIT phoneme recognition benchmark, which to our knowledge is the best recorded score."
            },
            "slug": "Speech-recognition-with-deep-recurrent-neural-Graves-Mohamed",
            "title": {
                "fragments": [],
                "text": "Speech recognition with deep recurrent neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper investigates deep recurrent neural networks, which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE International Conference on Acoustics, Speech and Signal Processing"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2360589"
                        ],
                        "name": "Julian G. Zilly",
                        "slug": "Julian-G.-Zilly",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Zilly",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julian G. Zilly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2100612"
                        ],
                        "name": "R. Srivastava",
                        "slug": "R.-Srivastava",
                        "structuredName": {
                            "firstName": "Rupesh",
                            "lastName": "Srivastava",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Srivastava"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2865775"
                        ],
                        "name": "J. Koutn\u00edk",
                        "slug": "J.-Koutn\u00edk",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Koutn\u00edk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Koutn\u00edk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Recent research on LSTMs has focused in two directions: Finding variations of individual LSTM memory unit architecture [4, 7, 25, 28], and discovering new ways of stitching LSTM layers into a network [8, 26, 53]. Both approaches have improved performance over vanilla LSTMs, with best recent results achieved through network design. \u201ee CoDeepNEAT method incorporates both approaches: neuroevolution searches for"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 292,
                                "start": 275
                            }
                        ],
                        "text": "\u2026in two directions: Finding variations of individual LSTM memory unit architecture (Bayer et al. 2009; Cho et al. 2014; Jozefowicz et al. 2015; Klaus et al. 2014), and discovering new ways of stitching LSTM layers into a network (Chung et al. 2015; Kalchbrenner et al. 2015; Zilly et al. 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1101453,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7dba53e72c182e25e98e8f73a99d75ff69dda0c2",
            "isKey": false,
            "numCitedBy": 351,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "Many sequential processing tasks require complex nonlinear transition functions from one step to the next. However, recurrent neural networks with 'deep' transition functions remain difficult to train, even when using Long Short-Term Memory (LSTM) networks. We introduce a novel theoretical analysis of recurrent networks based on Gersgorin's circle theorem that illuminates several modeling and optimization issues and improves our understanding of the LSTM cell. Based on this analysis we propose Recurrent Highway Networks, which extend the LSTM architecture to allow step-to-step transition depths larger than one. Several language modeling experiments demonstrate that the proposed architecture results in powerful and efficient models. On the Penn Treebank corpus, solely increasing the transition depth from 1 to 10 improves word-level perplexity from 90.6 to 65.4 using the same number of parameters. On the larger Wikipedia datasets for character prediction (text8 and enwik8), RHNs outperform all previous results and achieve an entropy of 1.27 bits per character."
            },
            "slug": "Recurrent-Highway-Networks-Zilly-Srivastava",
            "title": {
                "fragments": [],
                "text": "Recurrent Highway Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A novel theoretical analysis of recurrent networks based on Gersgorin's circle theorem is introduced that illuminates several modeling and optimization issues and improves the understanding of the LSTM cell."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145842938"
                        ],
                        "name": "Faustino J. Gomez",
                        "slug": "Faustino-J.-Gomez",
                        "structuredName": {
                            "firstName": "Faustino",
                            "lastName": "Gomez",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Faustino J. Gomez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686788"
                        ],
                        "name": "R. Miikkulainen",
                        "slug": "R.-Miikkulainen",
                        "structuredName": {
                            "firstName": "Risto",
                            "lastName": "Miikkulainen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Miikkulainen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1907951,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "id": "966e41903b4aff42601a188bd7b26d71ef120d11",
            "isKey": false,
            "numCitedBy": 312,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "Many complex control problems require sophisticated solutions that are not amenable to traditional controller design. Not only is it difficult to model real world systems, but often it is unclear what kind of behavior is required to solve the task. Reinforcement learning (RL) approaches have made progress by using direct interaction with the task environment, but have so far not scaled well to large state spaces and environments that are not fully observable. In recent years, neuroevolution, the artificial evolution of neural networks, has had remarkable success in tasks that exhibit these two properties. In this paper, we compare a neuroevolution method called Cooperative Synapse Neuroevolution (CoSyNE), that uses cooperative coevolution at the level of individual synaptic weights, to a broad range of reinforcement learning algorithms on very difficult versions of the pole balancing problem that involve large (continuous) state spaces and hidden state. CoSyNE is shown to be significantly more efficient and powerful than the other methods on these tasks."
            },
            "slug": "Accelerated-Neural-Evolution-through-Cooperatively-Gomez-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Accelerated Neural Evolution through Cooperatively Coevolved Synapses"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper compares a neuroevolution method called Cooperative Synapse Neuroevolution (CoSyNE), that uses cooperative coevolution at the level of individual synaptic weights, to a broad range of reinforcement learning algorithms on very difficult versions of the pole balancing problem that involve large state spaces and hidden state."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2563432"
                        ],
                        "name": "Wojciech Zaremba",
                        "slug": "Wojciech-Zaremba",
                        "structuredName": {
                            "firstName": "Wojciech",
                            "lastName": "Zaremba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wojciech Zaremba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 163
                            }
                        ],
                        "text": "After 25 generations of neuroevolution, the best network improved the performance on PTB dataset by 5% (test-perplexity score 78) as compared to the vanilla LSTM (Zaremba et al. 2014)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17719760,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f264e8b33c0d49a692a6ce2c4bcb28588aeb7d97",
            "isKey": false,
            "numCitedBy": 1997,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a simple regularization technique for Recurrent Neural Networks (RNNs) with Long Short-Term Memory (LSTM) units. Dropout, the most successful technique for regularizing neural networks, does not work well with RNNs and LSTMs. In this paper, we show how to correctly apply dropout to LSTMs, and show that it substantially reduces overfitting on a variety of tasks. These tasks include language modeling, speech recognition, image caption generation, and machine translation."
            },
            "slug": "Recurrent-Neural-Network-Regularization-Zaremba-Sutskever",
            "title": {
                "fragments": [],
                "text": "Recurrent Neural Network Regularization"
            },
            "tldr": {
                "abstractSimilarityScore": 34,
                "text": "This paper shows how to correctly apply dropout to LSTMs, and shows that it substantially reduces overfitting on a variety of tasks."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8270717"
                        ],
                        "name": "Junyoung Chung",
                        "slug": "Junyoung-Chung",
                        "structuredName": {
                            "firstName": "Junyoung",
                            "lastName": "Chung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junyoung Chung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1854385"
                        ],
                        "name": "\u00c7aglar G\u00fcl\u00e7ehre",
                        "slug": "\u00c7aglar-G\u00fcl\u00e7ehre",
                        "structuredName": {
                            "firstName": "\u00c7aglar",
                            "lastName": "G\u00fcl\u00e7ehre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c7aglar G\u00fcl\u00e7ehre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1979489"
                        ],
                        "name": "Kyunghyun Cho",
                        "slug": "Kyunghyun-Cho",
                        "structuredName": {
                            "firstName": "Kyunghyun",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyunghyun Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 124
                            }
                        ],
                        "text": "This result is interesting because it is similar to a recent hand-designed architecture that also outperforms vanilla LSTM (Chung et al. 2015)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 230
                            }
                        ],
                        "text": "\u2026in two directions: Finding variations of individual LSTM memory unit architecture (Bayer et al. 2009; Cho et al. 2014; Jozefowicz et al. 2015; Klaus et al. 2014), and discovering new ways of stitching LSTM layers into a network (Chung et al. 2015; Kalchbrenner et al. 2015; Zilly et al. 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 72
                            }
                        ],
                        "text": "2014), and discovering new ways of stitching LSTM layers into a network (Chung et al. 2015; Kalchbrenner et al. 2015; Zilly et al. 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8577750,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d14c7e5f5cace4c925abc74c88baa474e9f31a28",
            "isKey": false,
            "numCitedBy": 654,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work, we propose a novel recurrent neural network (RNN) architecture. The proposed RNN, gated-feedback RNN (GF-RNN), extends the existing approach of stacking multiple recurrent layers by allowing and controlling signals flowing from upper recurrent layers to lower layers using a global gating unit for each pair of layers. The recurrent signals exchanged between layers are gated adaptively based on the previous hidden states and the current input. We evaluated the proposed GF-RNN with different types of recurrent units, such as tanh, long short-term memory and gated recurrent units, on the tasks of character-level language modeling and Python program evaluation. Our empirical evaluation of different RNN units, revealed that in both tasks, the GF-RNN outperforms the conventional approaches to build deep stacked RNNs. We suggest that the improvement arises because the GFRNN can adaptively assign different layers to different timescales and layer-to-layer interactions (including the top-down ones which are not usually present in a stacked RNN) by learning to gate these interactions."
            },
            "slug": "Gated-Feedback-Recurrent-Neural-Networks-Chung-G\u00fcl\u00e7ehre",
            "title": {
                "fragments": [],
                "text": "Gated Feedback Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The empirical evaluation of different RNN units revealed that the proposed gated-feedback RNN outperforms the conventional approaches to build deep stacked RNNs in the tasks of character-level language modeling and Python program evaluation."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145040409"
                        ],
                        "name": "Justin Bayer",
                        "slug": "Justin-Bayer",
                        "structuredName": {
                            "firstName": "Justin",
                            "lastName": "Bayer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Justin Bayer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688276"
                        ],
                        "name": "Daan Wierstra",
                        "slug": "Daan-Wierstra",
                        "structuredName": {
                            "firstName": "Daan",
                            "lastName": "Wierstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daan Wierstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1810053"
                        ],
                        "name": "J. Togelius",
                        "slug": "J.-Togelius",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Togelius",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Togelius"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 119
                            }
                        ],
                        "text": "Recent research on LSTMs has focused in two directions: Finding variations of individual LSTM memory unit architecture (Bayer et al. 2009; Cho et al. 2014; Jozefowicz et al. 2015; Klaus et al. 2014), and discovering new ways of stitching LSTM layers into a network (Chung et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9803542,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b7405ab47e1b6686cebcbfb1f2efdbe431fc79c",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Long Short-Term Memory (LSTM) is one of the best recent supervised sequence learning methods. Using gradient descent, it trains memory cells represented as differentiable computational graph structures. Interestingly, LSTM's cell structure seems somewhat arbitrary. In this paper we optimize its computational structure using a multi-objective evolutionary algorithm. The fitness function reflects the structure's usefulness for learning various formal languages. The evolved cells help to understand crucial features that aid sequence learning."
            },
            "slug": "Evolving-Memory-Cell-Structures-for-Sequence-Bayer-Wierstra",
            "title": {
                "fragments": [],
                "text": "Evolving Memory Cell Structures for Sequence Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper optimize LSTM's computational structure using a multi-objective evolutionary algorithm, which reflects the structure's usefulness for learning various formal languages."
            },
            "venue": {
                "fragments": [],
                "text": "ICANN"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117101253"
                        ],
                        "name": "Ke Xu",
                        "slug": "Ke-Xu",
                        "structuredName": {
                            "firstName": "Ke",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ke Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3450996"
                        ],
                        "name": "Ryan Kiros",
                        "slug": "Ryan-Kiros",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Kiros",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan Kiros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1979489"
                        ],
                        "name": "Kyunghyun Cho",
                        "slug": "Kyunghyun-Cho",
                        "structuredName": {
                            "firstName": "Kyunghyun",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyunghyun Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760871"
                        ],
                        "name": "Aaron C. Courville",
                        "slug": "Aaron-C.-Courville",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Courville",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron C. Courville"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804104"
                        ],
                        "name": "R. Zemel",
                        "slug": "R.-Zemel",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zemel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zemel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 243,
                                "start": 140
                            }
                        ],
                        "text": "Deep learning has recently provided state-of-the-art performance in image captioning, and several diverse architectures have been suggested (Karpathy and Fei-Fei 2015; Vedantam et al. 2017; Vinyals et al. 2015; Xu et al. 2015; You et al. 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1055111,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d8f2d14af5991d4f0d050d22216825cac3157bd",
            "isKey": false,
            "numCitedBy": 7357,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We describe how we can train this model in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound. We also show through visualization how the model is able to automatically learn to fix its gaze on salient objects while generating the corresponding words in the output sequence. We validate the use of attention with state-of-the-art performance on three benchmark datasets: Flickr9k, Flickr30k and MS COCO."
            },
            "slug": "Show,-Attend-and-Tell:-Neural-Image-Caption-with-Xu-Ba",
            "title": {
                "fragments": [],
                "text": "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "An attention based model that automatically learns to describe the content of images is introduced that can be trained in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2583391"
                        ],
                        "name": "Nal Kalchbrenner",
                        "slug": "Nal-Kalchbrenner",
                        "structuredName": {
                            "firstName": "Nal",
                            "lastName": "Kalchbrenner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nal Kalchbrenner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1841008"
                        ],
                        "name": "Ivo Danihelka",
                        "slug": "Ivo-Danihelka",
                        "structuredName": {
                            "firstName": "Ivo",
                            "lastName": "Danihelka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ivo Danihelka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Recent research on LSTMs has focused in two directions: Finding variations of individual LSTM memory unit architecture [4, 7, 25, 28], and discovering new ways of stitching LSTM layers into a network [8, 26, 53]. Both approaches have improved performance over vanilla LSTMs, with best recent results achieved through network design. \u201ee CoDeepNEAT method incorporates both approaches: neuroevolution searches for"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 273,
                                "start": 249
                            }
                        ],
                        "text": "\u2026in two directions: Finding variations of individual LSTM memory unit architecture (Bayer et al. 2009; Cho et al. 2014; Jozefowicz et al. 2015; Klaus et al. 2014), and discovering new ways of stitching LSTM layers into a network (Chung et al. 2015; Kalchbrenner et al. 2015; Zilly et al. 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7823468,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5b791cd374c7109693aaddee2c12d659ae4e3ec0",
            "isKey": false,
            "numCitedBy": 315,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces Grid Long Short-Term Memory, a network of LSTM cells arranged in a multidimensional grid that can be applied to vectors, sequences or higher dimensional data such as images. The network differs from existing deep LSTM architectures in that the cells are connected between network layers as well as along the spatiotemporal dimensions of the data. The network provides a unified way of using LSTM for both deep and sequential computation. We apply the model to algorithmic tasks such as 15-digit integer addition and sequence memorization, where it is able to significantly outperform the standard LSTM. We then give results for two empirical tasks. We find that 2D Grid LSTM achieves 1.47 bits per character on the Wikipedia character prediction benchmark, which is state-of-the-art among neural approaches. In addition, we use the Grid LSTM to define a novel two-dimensional translation model, the Reencoder, and show that it outperforms a phrase-based reference system on a Chinese-to-English translation task."
            },
            "slug": "Grid-Long-Short-Term-Memory-Kalchbrenner-Danihelka",
            "title": {
                "fragments": [],
                "text": "Grid Long Short-Term Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The Grid LSTM is used to define a novel two-dimensional translation model, the Reencoder, and it is shown that it outperforms a phrase-based reference system on a Chinese-to-English translation task."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145842938"
                        ],
                        "name": "Faustino J. Gomez",
                        "slug": "Faustino-J.-Gomez",
                        "structuredName": {
                            "firstName": "Faustino",
                            "lastName": "Gomez",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Faustino J. Gomez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686788"
                        ],
                        "name": "R. Miikkulainen",
                        "slug": "R.-Miikkulainen",
                        "structuredName": {
                            "firstName": "Risto",
                            "lastName": "Miikkulainen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Miikkulainen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 31
                            }
                        ],
                        "text": "Other approaches such as SANE, ESP, and CoSyNE evolve partial neural networks and combine them into fully functional networks (Gomez and Miikkulainen 1997; Gomez et al. 2008; Moriarty and Miikkulainen 1997)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "eepNEAT, called Coevolution DeepNEAT (CoDeepNEAT), is proposed. \u201ee algorithm behind CoDeepNEAT is inspired mainly by Hierarchical SANE [37] but is also in\u2026uenced by component-evolution approaches ESP [13] and CoSyNE [14]. In CoDeepNEAT, two populations of modules and blueprints are evolved separately, using the same methods as described above for DeepNEAT. \u201ee blueprint chromosome is a graph where each"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 167
                            }
                        ],
                        "text": "The algorithm behind CoDeep-NEAT is inspired mainly by Hierarchical SANE (Moriarty and Miikkulainen 1997) but is also influenced by componentevolution approaches ESP (Gomez and Miikkulainen 1999) and CoSyNE (Gomez et al. 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1554231,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e1d8c5d31ba295dcac4ec93ffdee31682c00c4b8",
            "isKey": false,
            "numCitedBy": 278,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "The success of evolutionary methods on standard control learning tasks has created a need for new benchmarks. The classic pole balancing problem is no longer difficult enough to serve as a viable yardstick for measuring the learning efficiency of these systems. The double pole case, where two poles connected to the cart must be balanced simultaneously is much more difficult, especially when velocity information is not available. In this article, we demonstrate a neuroevolution system, Enforced Sub-populations (ESP), that is used to evolve a controller for the standard double pole task and a much harder, non-Markovian version. In both cases, our results show that ESP is faster than other neuroevolution methods. In addition, we introduce an incremental method that evolves on a sequence of tasks, and utilizes a local search technique (Delta-Coding) to sustain diversity. This method enables the system to solve even more difficult versions of the task where direct evolution cannot."
            },
            "slug": "Solving-Non-Markovian-Control-Tasks-with-Gomez-Miikkulainen",
            "title": {
                "fragments": [],
                "text": "Solving Non-Markovian Control Tasks with Neuro-Evolution"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This article demonstrates a neuroevolution system, Enforced Sub-populations (ESP), that is used to evolve a controller for the standard double pole task and a much harder, non-Markovian version, and introduces an incremental method that evolves on a sequence of tasks, and utilizes a local search technique (Delta-Coding) to sustain diversity."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723475"
                        ],
                        "name": "D. Montana",
                        "slug": "D.-Montana",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Montana",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Montana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144286518"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Davis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "imization of neural networks a promising approach for the future. 2 BACKGROUND AND RELATED WORK Neuroevolution techniques have been applied successfully to sequential decision tasks for three decades [11, 31, 36, 50]. In such tasks there is no gradient available, so instead of gradient descent, evolution is used to optimize the weights of the neural network. Neuroevolution is a good approach in particular to POMD"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6336712,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "09920800fa7841c84a551d70c6101d9510e6fcc8",
            "isKey": false,
            "numCitedBy": 1119,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayered feedforward neural networks possess a number of properties which make them particularly suited to complex pattern classification problems. However, their application to some realworld problems has been hampered by the lack of a training algonthm which reliably finds a nearly globally optimal set of weights in a relatively short time. Genetic algorithms are a class of optimization procedures which are good at exploring a large and complex space in an intelligent way to find values close to the global optimum. Hence, they are well suited to the problem of training feedforward networks. In this paper, we describe a set of experiments performed on data from a sonar image classification problem. These experiments both 1) illustrate the improvements gained by using a genetic algorithm rather than backpropagation and 2) chronicle the evolution of the performance of the genetic algorithm as we added more and more domain-specific knowledge into it."
            },
            "slug": "Training-Feedforward-Neural-Networks-Using-Genetic-Montana-Davis",
            "title": {
                "fragments": [],
                "text": "Training Feedforward Neural Networks Using Genetic Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A set of experiments performed on data from a sonar image classification problem are described to illustrate the improvements gained by using a genetic algorithm rather than backpropagation and chronicle the evolution of the performance of the genetic algorithm as it added more and more domain-specific knowledge into it."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36610242"
                        ],
                        "name": "Quanzeng You",
                        "slug": "Quanzeng-You",
                        "structuredName": {
                            "firstName": "Quanzeng",
                            "lastName": "You",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quanzeng You"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41151701"
                        ],
                        "name": "Hailin Jin",
                        "slug": "Hailin-Jin",
                        "structuredName": {
                            "firstName": "Hailin",
                            "lastName": "Jin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hailin Jin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8056043"
                        ],
                        "name": "Zhaowen Wang",
                        "slug": "Zhaowen-Wang",
                        "structuredName": {
                            "firstName": "Zhaowen",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhaowen Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144823841"
                        ],
                        "name": "Chen Fang",
                        "slug": "Chen-Fang",
                        "structuredName": {
                            "firstName": "Chen",
                            "lastName": "Fang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chen Fang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33642939"
                        ],
                        "name": "Jiebo Luo",
                        "slug": "Jiebo-Luo",
                        "structuredName": {
                            "firstName": "Jiebo",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiebo Luo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 243,
                                "start": 140
                            }
                        ],
                        "text": "Deep learning has recently provided state-of-the-art performance in image captioning, and several diverse architectures have been suggested (Karpathy and Fei-Fei 2015; Vedantam et al. 2017; Vinyals et al. 2015; Xu et al. 2015; You et al. 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3120635,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf55591e09b58ea9ce8d66110d6d3000ee804bdd",
            "isKey": false,
            "numCitedBy": 1229,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatically generating a natural language description of an image has attracted interests recently both because of its importance in practical applications and because it connects two major artificial intelligence fields: computer vision and natural language processing. Existing approaches are either top-down, which start from a gist of an image and convert it into words, or bottom-up, which come up with words describing various aspects of an image and then combine them. In this paper, we propose a new algorithm that combines both approaches through a model of semantic attention. Our algorithm learns to selectively attend to semantic concept proposals and fuse them into hidden states and outputs of recurrent neural networks. The selection and fusion form a feedback connecting the top-down and bottom-up computation. We evaluate our algorithm on two public benchmarks: Microsoft COCO and Flickr30K. Experimental results show that our algorithm significantly outperforms the state-of-the-art approaches consistently across different evaluation metrics."
            },
            "slug": "Image-Captioning-with-Semantic-Attention-You-Jin",
            "title": {
                "fragments": [],
                "text": "Image Captioning with Semantic Attention"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes a new algorithm that combines top-down and bottom-up approaches to natural language description through a model of semantic attention, and significantly outperforms the state-of-the-art approaches consistently across different evaluation metrics."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748824"
                        ],
                        "name": "C. Igel",
                        "slug": "C.-Igel",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Igel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Igel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "CMA-ES for hyperparameter optimization of deep neural networks."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 8
                            }
                        ],
                        "text": "CMA-ES (Igel 2003), a technique for continuous optimization, works well on optimizing the weights as well because it can capture interactions between them."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 44
                            }
                        ],
                        "text": "For instance, Loshchilov et al. (2016) used CMA-ES to optimize the hyperparameters of existing DNNs obtaining state-of-the-art results on e.g. object recognition."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15808719,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04377cba52732168d3e55e229bae2ee1ad4d43a2",
            "isKey": true,
            "numCitedBy": 164,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We apply the CMA-ES, an evolution strategy which efficiently adapts the covariance matrix of the mutation distribution, to the optimization of the weights of neural networks for solving reinforcement learning problems. It turns out that the topology of the networks considerably influences the time to find a suitable control strategy. Still, our results with fixed network topologies are significantly better than those reported for the best evolutionary method so far, which adapts both the weights and the structure of the networks."
            },
            "slug": "Neuroevolution-for-reinforcement-learning-using-Igel",
            "title": {
                "fragments": [],
                "text": "Neuroevolution for reinforcement learning using evolution strategies"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "The CMA-ES is applied to the optimization of the weights of neural networks for solving reinforcement learning problems, and results with fixed network topologies are significantly better than those reported for the best evolutionary method so far."
            },
            "venue": {
                "fragments": [],
                "text": "The 2003 Congress on Evolutionary Computation, 2003. CEC '03."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143901532"
                        ],
                        "name": "X. Yao",
                        "slug": "X.-Yao",
                        "structuredName": {
                            "firstName": "Xin",
                            "lastName": "Yao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Yao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 181
                            }
                        ],
                        "text": "Neuroevolution techniques have been applied successfully to sequential decision tasks for three decades (Floreano et al. 2008; Lehman and Miikkulainen 2013; Montana and Davis 1989; Yao 1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61519731,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ae89454a8a41015ebe0eeab9f51fe4eee459a25",
            "isKey": false,
            "numCitedBy": 2102,
            "numCiting": 276,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning and evolution are two fundamental forms of adaptation. There has been a great interest in combining learning and evolution with artificial neural networks (ANNs) in recent years. This paper: 1) reviews different combinations between ANNs and evolutionary algorithms (EAs), including using EAs to evolve ANN connection weights, architectures, learning rules, and input features; 2) discusses different search operators which have been used in various EAs; and 3) points out possible future research directions. It is shown, through a considerably large literature review, that combinations between ANNs and EAs can lead to significantly better intelligent systems than relying on ANNs or EAs alone."
            },
            "slug": "Evolving-artificial-neural-networks-Yao",
            "title": {
                "fragments": [],
                "text": "Evolving artificial neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown, through a considerably large literature review, that combinations between ANNs and EAs can lead to significantly better intelligent systems than relying on ANNs or EAs alone."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145842938"
                        ],
                        "name": "Faustino J. Gomez",
                        "slug": "Faustino-J.-Gomez",
                        "structuredName": {
                            "firstName": "Faustino",
                            "lastName": "Gomez",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Faustino J. Gomez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686788"
                        ],
                        "name": "R. Miikkulainen",
                        "slug": "R.-Miikkulainen",
                        "structuredName": {
                            "firstName": "Risto",
                            "lastName": "Miikkulainen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Miikkulainen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ar 2017 weights as well because it can capture interactions between them. Other approaches such as SANE, ESP, and CoSyNE evolve partial neural networks and combine them into fully functional networks [12, 14, 37]. Further, techniques such as Cellular Encoding [18] and NEAT [43] have been developed to evolve the topology of the neural network, which is particularly e\u2021ective in determining the required recurren"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2209222,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8939e9298eedb90aa4f040ab8e9f16872089a495",
            "isKey": false,
            "numCitedBy": 505,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Several researchers have demonstrated how complex action sequences can be learned through neuroevolution (i.e., evolving neural networks with genetic algorithms). However, complex general behavior such as evading predators or avoiding obstacles, which is not tied to specific environments, turns out to be very difficult to evolve. Often the system discovers mechanical strategies, such as moving back and forth, that help the agent cope but are not very effective, do not appear believable, and do not generalize to new environments. The problem is that a general strategy is too difficult for the evolution system to discover directly. This article proposes an approach wherein such complex general behavior is learned incrementally, by starting with simpler behavior and gradually making the task more challenging and general. The task transitions are implemented through successive stages of Delta coding (i.e., evolving modifications), which allows even converged populations to adapt to the new task. The method is tested in the stochastic, dynamic task of prey capture and is compared with direct evolution. The incremental approach evolves more effective and more general behavior and should also scale up to harder tasks."
            },
            "slug": "Incremental-Evolution-of-Complex-General-Behavior-Gomez-Miikkulainen",
            "title": {
                "fragments": [],
                "text": "Incremental Evolution of Complex General Behavior"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This article proposes an approach wherein complex general behavior is learned incrementally, by starting with simpler behavior and gradually making the task more challenging and general, which evolves more effective and more general behavior."
            },
            "venue": {
                "fragments": [],
                "text": "Adapt. Behav."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2354728"
                        ],
                        "name": "A. Karpathy",
                        "slug": "A.-Karpathy",
                        "structuredName": {
                            "firstName": "Andrej",
                            "lastName": "Karpathy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Karpathy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8517067,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "55e022fb7581bb9e1fce678d21fb25ffbb3fbb88",
            "isKey": false,
            "numCitedBy": 2718,
            "numCiting": 103,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a model that generates natural language descriptions of images and their regions. Our approach leverages datasets of images and their sentence descriptions to learn about the inter-modal correspondences between language and visual data. Our alignment model is based on a novel combination of Convolutional Neural Networks over image regions, bidirectional Recurrent Neural Networks (RNN) over sentences, and a structured objective that aligns the two modalities through a multimodal embedding. We then describe a Multimodal Recurrent Neural Network architecture that uses the inferred alignments to learn to generate novel descriptions of image regions. We demonstrate that our alignment model produces state of the art results in retrieval experiments on Flickr8K, Flickr30K and MSCOCO datasets. We then show that the generated descriptions outperform retrieval baselines on both full images and on a new dataset of region-level annotations. Finally, we conduct large-scale analysis of our RNN language model on the Visual Genome dataset of 4.1 million captions and highlight the differences between image and region-level caption statistics."
            },
            "slug": "Deep-Visual-Semantic-Alignments-for-Generating-Karpathy-Fei-Fei",
            "title": {
                "fragments": [],
                "text": "Deep Visual-Semantic Alignments for Generating Image Descriptions"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A model that generates natural language descriptions of images and their regions based on a novel combination of Convolutional Neural Networks over image regions, bidirectional Recurrent Neural networks over sentences, and a structured objective that aligns the two modalities through a multimodal embedding is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3335364"
                        ],
                        "name": "Dzmitry Bahdanau",
                        "slug": "Dzmitry-Bahdanau",
                        "structuredName": {
                            "firstName": "Dzmitry",
                            "lastName": "Bahdanau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dzmitry Bahdanau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1979489"
                        ],
                        "name": "Kyunghyun Cho",
                        "slug": "Kyunghyun-Cho",
                        "structuredName": {
                            "firstName": "Kyunghyun",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyunghyun Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "red to simply using recurrent connections in a neural network). LSTMs have recently been shown powerful in supervised sequence processing tasks such as speech recognition [16] and machine translation [3]. Recent research on LSTMs has focused in two directions: Finding variations of individual LSTM memory unit architecture [4, 7, 25, 28], and discovering new ways of stitching LSTM layers into a networ"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11212020,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
            "isKey": false,
            "numCitedBy": 19562,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition."
            },
            "slug": "Neural-Machine-Translation-by-Jointly-Learning-to-Bahdanau-Cho",
            "title": {
                "fragments": [],
                "text": "Neural Machine Translation by Jointly Learning to Align and Translate"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and it is proposed to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1939695"
                        ],
                        "name": "Zhengping Che",
                        "slug": "Zhengping-Che",
                        "structuredName": {
                            "firstName": "Zhengping",
                            "lastName": "Che",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhengping Che"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144735626"
                        ],
                        "name": "S. Purushotham",
                        "slug": "S.-Purushotham",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Purushotham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Purushotham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1979489"
                        ],
                        "name": "Kyunghyun Cho",
                        "slug": "Kyunghyun-Cho",
                        "structuredName": {
                            "firstName": "Kyunghyun",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyunghyun Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746662"
                        ],
                        "name": "D. Sontag",
                        "slug": "D.-Sontag",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Sontag",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Sontag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47909587"
                        ],
                        "name": "Yan Liu",
                        "slug": "Yan-Liu",
                        "structuredName": {
                            "firstName": "Yan",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yan Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4900015,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd723bc768baa78b7bd3e6f28a401d6d5cfe87f8",
            "isKey": false,
            "numCitedBy": 1010,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Multivariate time series data in practical applications, such as health care, geoscience, and biology, are characterized by a variety of missing values. In time series prediction and other related tasks, it has been noted that missing values and their missing patterns are often correlated with the target labels, a.k.a., informative missingness. There is very limited work on exploiting the missing patterns for effective imputation and improving prediction performance. In this paper, we develop novel deep learning models, namely GRU-D, as one of the early attempts. GRU-D is based on Gated Recurrent Unit (GRU), a state-of-the-art recurrent neural network. It takes two representations of missing patterns, i.e., masking and time interval, and effectively incorporates them into a deep model architecture so that it not only captures the long-term temporal dependencies in time series, but also utilizes the missing patterns to achieve better prediction results. Experiments of time series classification tasks on real-world clinical datasets (MIMIC-III, PhysioNet) and synthetic datasets demonstrate that our models achieve state-of-the-art performance and provide useful insights for better understanding and utilization of missing values in time series analysis."
            },
            "slug": "Recurrent-Neural-Networks-for-Multivariate-Time-Che-Purushotham",
            "title": {
                "fragments": [],
                "text": "Recurrent Neural Networks for Multivariate Time Series with Missing Values"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Novel deep learning models are developed based on Gated Recurrent Unit, a state-of-the-art recurrent neural network that takes two representations of missing patterns, i.e., masking and time interval, and effectively incorporates them into a deep model architecture so that it not only captures the long-term temporal dependencies in time series, but also utilizes the missing patterns to achieve better prediction results."
            },
            "venue": {
                "fragments": [],
                "text": "Scientific Reports"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2327580"
                        ],
                        "name": "Rogier Koppejan",
                        "slug": "Rogier-Koppejan",
                        "structuredName": {
                            "firstName": "Rogier",
                            "lastName": "Koppejan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rogier Koppejan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766767"
                        ],
                        "name": "Shimon Whiteson",
                        "slug": "Shimon-Whiteson",
                        "structuredName": {
                            "firstName": "Shimon",
                            "lastName": "Whiteson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shimon Whiteson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8398319,
            "fieldsOfStudy": [
                "Computer Science",
                "Psychology"
            ],
            "id": "3420734ee9ea4524670e01d2f2742ccd5ca08db9",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 119,
            "paperAbstract": {
                "fragments": [],
                "text": "This article presents an extended case study in the application of neuroevolution to generalized simulated helicopter hovering, an important challenge problem for reinforcement learning. While neuroevolution is well suited to coping with the domain\u2019s complex transition dynamics and high-dimensional state and action spaces, the need to explore efficiently and learn on-line poses unusual challenges. We propose and evaluate several methods for three increasingly challenging variations of the task, including the method that won first place in the 2008 Reinforcement Learning Competition. The results demonstrate that (1) neuroevolution can be effective for complex on-line reinforcement learning tasks such as generalized helicopter hovering, (2) neuroevolution excels at finding effective helicopter hovering policies but not at learning helicopter models, (3) due to the difficulty of learning reliable models, model-based approaches to helicopter hovering are feasible only when domain expertise is available to aid the design of a suitable model representation and (4) recent advances in efficient resampling can enable neuroevolution to tackle more aggressively generalized reinforcement learning tasks."
            },
            "slug": "Neuroevolutionary-reinforcement-learning-for-of-Koppejan-Whiteson",
            "title": {
                "fragments": [],
                "text": "Neuroevolutionary reinforcement learning for generalized control of simulated helicopters"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "An extended case study in the application of neuroevolution to generalized simulated helicopter hovering, an important challenge problem for reinforcement learning, and proposes and evaluates several methods for three increasingly challenging variations of the task."
            },
            "venue": {
                "fragments": [],
                "text": "Evol. Intell."
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735300"
                        ],
                        "name": "S. Haykin",
                        "slug": "S.-Haykin",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Haykin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Haykin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713858"
                        ],
                        "name": "B. Kosko",
                        "slug": "B.-Kosko",
                        "structuredName": {
                            "firstName": "Bart",
                            "lastName": "Kosko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Kosko"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 64294544,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f42b865e20e61a954239f421b42007236e671f19",
            "isKey": false,
            "numCitedBy": 3561,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer Neural Networks trained with the backpropagation algorithm constitute the best example of a successful Gradient-Based Learning technique. Given an appropriate network architecture, Gradient-Based Learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional Neural Networks, that are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation, recognition, and language modeling. A new learning paradigm, called Graph Transformer Networks (GTN), allows such multi-module systems to be trained globally using Gradient-Based methods so as to minimize an overall performance measure. Two systems for on-line handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of Graph Transformer Networks. A Graph Transformer Network for reading bank check is also described. It uses Convolutional Neural Network character recognizers combined with global training techniques to provides record accuracy on business and personal checks. It is deployed commercially and reads several million checks per day."
            },
            "slug": "GradientBased-Learning-Applied-to-Document-Haykin-Kosko",
            "title": {
                "fragments": [],
                "text": "GradientBased Learning Applied to Document Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Various methods applied to handwritten character recognition are reviewed and compared and Convolutional Neural Networks, that are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 30
                            }
                        ],
                        "text": "convolutional neural networks (LeCun et al. 1998) and recurrent neural networks (in particular long short-term memory, or LSTM (Hochreiter and Schmidhuber 1997)), which have existed since the 1990s, have improved state-of-the-art significantly in computer vision, speech, language processing, and many other areas (Collobert and Weston 2008; Graves et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": false,
            "numCitedBy": 35623,
            "numCiting": 246,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1979489"
                        ],
                        "name": "Kyunghyun Cho",
                        "slug": "Kyunghyun-Cho",
                        "structuredName": {
                            "firstName": "Kyunghyun",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyunghyun Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3158246"
                        ],
                        "name": "Bart van Merrienboer",
                        "slug": "Bart-van-Merrienboer",
                        "structuredName": {
                            "firstName": "Bart",
                            "lastName": "Merrienboer",
                            "middleNames": [
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bart van Merrienboer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1854385"
                        ],
                        "name": "\u00c7aglar G\u00fcl\u00e7ehre",
                        "slug": "\u00c7aglar-G\u00fcl\u00e7ehre",
                        "structuredName": {
                            "firstName": "\u00c7aglar",
                            "lastName": "G\u00fcl\u00e7ehre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00c7aglar G\u00fcl\u00e7ehre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3335364"
                        ],
                        "name": "Dzmitry Bahdanau",
                        "slug": "Dzmitry-Bahdanau",
                        "structuredName": {
                            "firstName": "Dzmitry",
                            "lastName": "Bahdanau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dzmitry Bahdanau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076086"
                        ],
                        "name": "Fethi Bougares",
                        "slug": "Fethi-Bougares",
                        "structuredName": {
                            "firstName": "Fethi",
                            "lastName": "Bougares",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fethi Bougares"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144518416"
                        ],
                        "name": "Holger Schwenk",
                        "slug": "Holger-Schwenk",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Schwenk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Holger Schwenk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 119
                            }
                        ],
                        "text": "Recent research on LSTMs has focused in two directions: Finding variations of individual LSTM memory unit architecture (Bayer et al. 2009; Cho et al. 2014; Jozefowicz et al. 2015; Klaus et al. 2014), and discovering new ways of stitching LSTM layers into a network (Chung et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 139
                            }
                        ],
                        "text": "Recent research on LSTMs has focused in two directions: Finding variations of individual LSTM memory unit architecture (Bayer et al. 2009; Cho et al. 2014; Jozefowicz et al. 2015; Klaus et al. 2014), and discovering new ways of stitching LSTM layers into a network (Chung et al. 2015; Kalchbrenner\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5590763,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b544dfe355a5070b60986319a3f51fb45d1348e",
            "isKey": false,
            "numCitedBy": 15252,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a novel neural network model called RNN Encoder\u2010 Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixedlength vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder\u2010Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases."
            },
            "slug": "Learning-Phrase-Representations-using-RNN-for-Cho-Merrienboer",
            "title": {
                "fragments": [],
                "text": "Learning Phrase Representations using RNN Encoder\u2013Decoder for Statistical Machine Translation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Qualitatively, the proposed RNN Encoder\u2010Decoder model learns a semantically and syntactically meaningful representation of linguistic phrases."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694724"
                        ],
                        "name": "F. Gruau",
                        "slug": "F.-Gruau",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Gruau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Gruau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145285040"
                        ],
                        "name": "L. D. Whitley",
                        "slug": "L.-D.-Whitley",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Whitley",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. D. Whitley"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15048360,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "406e9e583450219318e1101bd02bb6a1e91f0b74",
            "isKey": false,
            "numCitedBy": 244,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "A grammar tree is used to encode a cellular developmental process that can generate whole families of Boolean neural networks for computing parity and symmetry. The development process resembles biological cell division. A genetic algorithm is used to find a grammar tree that yields both architecture and weights specifying a particular neural network for solving specific Boolean functions. The current study particularly focuses on the addition of learning to the development process and the evolution of grammar trees. Three ways of adding learning to the development process are explored. Two of these exploit the Baldwin effect by changing the fitness landscape without using Lamarckian evolution. The third strategy is Lamarckian in nature. Results for these three modes of combining learning with genetic search are compared against genetic search without learning. Our results suggest that merely using learning to change the fitness landscape can be as effective as Lamarckian strategies at improving search."
            },
            "slug": "Adding-Learning-to-the-Cellular-Development-of-and-Gruau-Whitley",
            "title": {
                "fragments": [],
                "text": "Adding Learning to the Cellular Development of Neural Networks: Evolution and the Baldwin Effect"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This study particularly focuses on the addition of learning to the development process and the evolution of grammar trees, and suggests that merely using learning to change the fitness landscape can be as effective as Lamarckian strategies at improving search."
            },
            "venue": {
                "fragments": [],
                "text": "Evolutionary Computation"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3111912"
                        ],
                        "name": "Navdeep Jaitly",
                        "slug": "Navdeep-Jaitly",
                        "structuredName": {
                            "firstName": "Navdeep",
                            "lastName": "Jaitly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Navdeep Jaitly"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": " longer time scales (as compared to simply using recurrent connections in a neural network). LSTMs have recently been shown powerful in supervised sequence processing tasks such as speech recognition [16] and machine translation [3]. Recent research on LSTMs has focused in two directions: Finding variations of individual LSTM memory unit architecture [4, 7, 25, 28], and discovering new ways of stitchi"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1166498,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0fa553cfa0cf3cbdf7a913aa2ae789a757dfb32f",
            "isKey": false,
            "numCitedBy": 1769,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a speech recognition system that directly transcribes audio data with text, without requiring an intermediate phonetic representation. The system is based on a combination of the deep bidirectional LSTM recurrent neural network architecture and the Connectionist Temporal Classification objective function. A modification to the objective function is introduced that trains the network to minimise the expectation of an arbitrary transcription loss function. This allows a direct optimisation of the word error rate, even in the absence of a lexicon or language model. The system achieves a word error rate of 27.3% on the Wall Street Journal corpus with no prior linguistic information, 21.9% with only a lexicon of allowed words, and 8.2% with a trigram language model. Combining the network with a baseline system further reduces the error rate to 6.7%."
            },
            "slug": "Towards-End-To-End-Speech-Recognition-with-Neural-Graves-Jaitly",
            "title": {
                "fragments": [],
                "text": "Towards End-To-End Speech Recognition with Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A speech recognition system that directly transcribes audio data with text, without requiring an intermediate phonetic representation is presented, based on a combination of the deep bidirectional LSTM recurrent neural network architecture and the Connectionist Temporal Classification objective function."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308557"
                        ],
                        "name": "S. Hochreiter",
                        "slug": "S.-Hochreiter",
                        "structuredName": {
                            "firstName": "Sepp",
                            "lastName": "Hochreiter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hochreiter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1915014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44d2abe2175df8153f465f6c39b68b76a0d40ab9",
            "isKey": false,
            "numCitedBy": 52390,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms."
            },
            "slug": "Long-Short-Term-Memory-Hochreiter-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Long Short-Term Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel, efficient, gradient based method called long short-term memory (LSTM) is introduced, which can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1859405"
                        ],
                        "name": "David E. Moriarty",
                        "slug": "David-E.-Moriarty",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Moriarty",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David E. Moriarty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686788"
                        ],
                        "name": "R. Miikkulainen",
                        "slug": "R.-Miikkulainen",
                        "structuredName": {
                            "firstName": "Risto",
                            "lastName": "Miikkulainen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Miikkulainen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7885480,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "3564c49d34c1642cf52606665440b8d2754510d8",
            "isKey": false,
            "numCitedBy": 341,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "This article demonstrates the advantages of a cooperative, coevolutionary search in difficult control problems. The symbiotic adaptive neuroevolution (SANE) system coevolves a population of neurons that cooperate to form a functioning neural network. In this process, neurons assume different but overlapping roles, resulting in a robust encoding of control behavior. SANE is shown to be more efficient and more adaptive and to maintain higher levels of diversity than the more common network-based population approaches. Further empirical studies illustrate the emergent neuron specializations and the different roles the neurons assume in the population."
            },
            "slug": "Forming-Neural-Networks-Through-Efficient-and-Moriarty-Miikkulainen",
            "title": {
                "fragments": [],
                "text": "Forming Neural Networks Through Efficient and Adaptive Coevolution"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "The symbiotic adaptive neuroevolution system coevolves a population of neurons that cooperate to form a functioning neural network to be more efficient and more adaptive and to maintain higher levels of diversity than the more common network-based population approaches."
            },
            "venue": {
                "fragments": [],
                "text": "Evolutionary Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802785"
                        ],
                        "name": "S. Nowlan",
                        "slug": "S.-Nowlan",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Nowlan",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nowlan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "adients from a related task (such as prediction of the next sensory inputs) are used to help search. Much of the work is based on utilizing the Baldwin e\u2021ect, where learning only a\u2021ects the selection [21]. Computationally, it is possible to utilize Lamarckian evolution as well, i.e. encode the learned weight changes back into the genome [18]. However, care must be taken to maintain diversity so that e"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2937027,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "f9197ff9fdabd2b78bfe0602365011c6699b0d66",
            "isKey": false,
            "numCitedBy": 1188,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The assumption that acquired character istics are not in\u00ad herited is ofte n taken to imply t hat t he adaptations t hat an organism learns dur ing its lifeti me cannot guide t he course of evolut ion . This infere nce is incor rec t (2). Learni ng alt ers the shape of t he search space in which evolu tio n operates and thereby pro vides good evolut ion ar y paths towa rds sets of co-adapted alleles. We demonst r at e t hat th is effect allows learning organisms to evolve much faster than their 000 \u00ad learning equivalents, even though the characteris tics acquired by t he phenotype are not communicated to the genotype."
            },
            "slug": "How-Learning-Can-Guide-Evolution-Hinton-Nowlan",
            "title": {
                "fragments": [],
                "text": "How Learning Can Guide Evolution"
            },
            "venue": {
                "fragments": [],
                "text": "Complex Syst."
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1846883"
                        ],
                        "name": "Kenneth O. Stanley",
                        "slug": "Kenneth-O.-Stanley",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Stanley",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth O. Stanley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2535195,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f18b9dde7ff8a49c3807a2dc90c0941a66dc561",
            "isKey": false,
            "numCitedBy": 653,
            "numCiting": 102,
            "paperAbstract": {
                "fragments": [],
                "text": "Natural DNA can encode complexity on an enormous scale. Researchers are attempting to achieve the same representational efficiency in computers by implementing developmental encodings, i.e. encodings that map the genotype to the phenotype through a process of growth from a small starting point to a mature form. A major challenge in in this effort is to find the right level of abstraction of biological development to capture its essential properties without introducing unnecessary inefficiencies. In this paper, a novel abstraction of natural development, called Compositional Pattern Producing Networks (CPPNs), is proposed. Unlike currently accepted abstractions such as iterative rewrite systems and cellular growth simulations, CPPNs map to the phenotype without local interaction, that is, each individual component of the phenotype is determined independently of every other component. Results produced with CPPNs through interactive evolution of two-dimensional images show that such an encoding can nevertheless produce structural motifs often attributed to more conventional developmental abstractions, suggesting that local interaction may not be essential to the desirable properties of natural encoding in the way that is usually assumed."
            },
            "slug": "Compositional-pattern-producing-networks:-A-novel-Stanley",
            "title": {
                "fragments": [],
                "text": "Compositional pattern producing networks: A novel abstraction of development"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Results produced with CPPNs through interactive evolution of two-dimensional images show that such an encoding can nevertheless produce structural motifs often attributed to more conventional developmental abstractions, suggesting that local interaction may not be essential to the desirable properties of natural encoding in the way that is usually assumed."
            },
            "venue": {
                "fragments": [],
                "text": "Genetic Programming and Evolvable Machines"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8137017"
                        ],
                        "name": "Ramakrishna Vedantam",
                        "slug": "Ramakrishna-Vedantam",
                        "structuredName": {
                            "firstName": "Ramakrishna",
                            "lastName": "Vedantam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ramakrishna Vedantam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702318"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153432684"
                        ],
                        "name": "Devi Parikh",
                        "slug": "Devi-Parikh",
                        "structuredName": {
                            "firstName": "Devi",
                            "lastName": "Parikh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Devi Parikh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732280"
                        ],
                        "name": "Gal Chechik",
                        "slug": "Gal-Chechik",
                        "structuredName": {
                            "firstName": "Gal",
                            "lastName": "Chechik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gal Chechik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 168
                            }
                        ],
                        "text": "Deep learning has recently provided state-of-the-art performance in image captioning, and several diverse architectures have been suggested (Karpathy and Fei-Fei 2015; Vedantam et al. 2017; Vinyals et al. 2015; Xu et al. 2015; You et al. 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2808607,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e782437503f2a24fd1a836a434da395bf15c88c2",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce an inference technique to produce discriminative context-aware image captions (captions that describe differences between images or visual concepts) using only generic context-agnostic training data (captions that describe a concept or an image in isolation). For example, given images and captions of siamese cat and tiger cat, we generate language that describes the siamese cat in a way that distinguishes it from tiger cat. Our key novelty is that we show how to do joint inference over a language model that is context-agnostic and a listener which distinguishes closely-related concepts. We first apply our technique to a justification task, namely to describe why an image contains a particular fine-grained category as opposed to another closely-related category of the CUB-200-2011 dataset. We then study discriminative image captioning to generate language that uniquely refers to one of two semantically-similar images in the COCO dataset. Evaluations with discriminative ground truth for justification and human studies for discriminative image captioning reveal that our approach outperforms baseline generative and speaker-listener approaches for discrimination."
            },
            "slug": "Context-Aware-Captions-from-Context-Agnostic-Vedantam-Bengio",
            "title": {
                "fragments": [],
                "text": "Context-Aware Captions from Context-Agnostic Supervision"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "An inference technique is introduced to produce discriminative context-aware image captions using only generic context-agnostic training data that generates language that uniquely refers to one of two semantically-similar images in the COCO dataset."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111834930"
                        ],
                        "name": "J. Liang",
                        "slug": "J.-Liang",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Liang",
                            "middleNames": [
                                "Zhi"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686788"
                        ],
                        "name": "R. Miikkulainen",
                        "slug": "R.-Miikkulainen",
                        "structuredName": {
                            "firstName": "Risto",
                            "lastName": "Miikkulainen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Miikkulainen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "lored in the single-level neuroevolution approach. However, a bilevel approach, where a high-level evolutionary process is employed to optimize these parameters, can search this space more e\u2021ectively [32]. With bilevel evolution, the number of parameters optimized could be extended to 15, which resulted in signi\u2022cantly be\u2212er performance. In this manner, evolution was harnessed in this example task to "
                    },
                    "intents": []
                }
            ],
            "corpusId": 215753768,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a518502a5d38435d08fce3e29e0d23210f5c5c20",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Most optimization algorithms must undergo time consuming parameter adaptation in order to optimally solve complex, real-world control tasks. Parameter adaptation is inherently a bilevel optimization problem where the lower level objective function is the performance of the control parameters discovered by an optimization algorithm and the upper level objective function is the performance of the algorithm given its parametrization. In this paper, a novel method called MetaEvolutionary Algorithm (MEA) is presented and shown to be capable of efficiently discovering optimal parameters for neuroevolution to solve control problems. In two challenging examples, double pole balancing and helicopter hovering, MEA discovers optimized parameters that result in better performance than hand tuning and other automatic methods. Bilevel optimization in general and MEA in particular, is thus a promising approach for solving difficult control tasks."
            },
            "slug": "Evolutionary-Bilevel-Optimization-for-Complex-Tasks-Liang-Miikkulainen",
            "title": {
                "fragments": [],
                "text": "Evolutionary Bilevel Optimization for Complex Control Tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A novel method called MetaEvolutionary Algorithm (MEA) is presented and shown to be capable of efficiently discovering optimal parameters for neuroevolution to solve control problems."
            },
            "venue": {
                "fragments": [],
                "text": "GECCO"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40411516"
                        ],
                        "name": "Ankur Sinha",
                        "slug": "Ankur-Sinha",
                        "structuredName": {
                            "firstName": "Ankur",
                            "lastName": "Sinha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ankur Sinha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40194127"
                        ],
                        "name": "P. Malo",
                        "slug": "P.-Malo",
                        "structuredName": {
                            "firstName": "Pekka",
                            "lastName": "Malo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Malo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153915860"
                        ],
                        "name": "Peng Xu",
                        "slug": "Peng-Xu",
                        "structuredName": {
                            "firstName": "Peng",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peng Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145080287"
                        ],
                        "name": "K. Deb",
                        "slug": "K.-Deb",
                        "structuredName": {
                            "firstName": "Kalyanmoy",
                            "lastName": "Deb",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Deb"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14471247,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f363cbdf9dd7c6524789a4139e51a5c859b6dc3c",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Many of the modern optimization algorithms contain a number of parameters that require tuning before the algorithm can be applied to a particular class of optimization problems. A proper choice of parameters may have a substantial effect on the accuracy and efficiency of the algorithm. Until recently, parameter tuning has mostly been performed using brute force strategies, such as grid search and random search. Guesses and insights about the algorithm are also used to find suitable parameters or suggest strategies to adjust them. More recent trends include the use of meta-optimization techniques. Most of these approaches are computationally expensive and do not scale when the number of parameters increases. In this paper, we propose that the parameter tuning problem is inherently a bilevel programming problem. Based on this insight, we introduce an evolutionary bilevel algorithm for parameter tuning. A few commonly used optimization algorithms (Differential Evolution and Nelder-Mead) have been chosen as test cases, whose parameters are tuned on a number of standard test problems. The bilevel approach is found to quickly converge towards the region of efficient parameters. The code for the proposed algorithm can be accessed from the website http://bilevel.org."
            },
            "slug": "A-bilevel-optimization-approach-to-automated-tuning-Sinha-Malo",
            "title": {
                "fragments": [],
                "text": "A bilevel optimization approach to automated parameter tuning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is proposed that the parameter tuning problem is inherently a bilevel programming problem and an evolutionary bileVEL algorithm for parameter tuning is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "GECCO"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756566"
                        ],
                        "name": "J. Bagnell",
                        "slug": "J.-Bagnell",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Bagnell",
                            "middleNames": [
                                "Andrew"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bagnell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753432"
                        ],
                        "name": "J. Schneider",
                        "slug": "J.-Schneider",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Schneider",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schneider"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3116531,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "84b23b154ef3083839a4da8c460a1e1c110ea63b",
            "isKey": false,
            "numCitedBy": 309,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Many control problems in the robotics field can be cast as partially observed Markovian decision problems (POMDPs), an optimal control formalism. Finding optimal solutions to such problems in general, however is known to be intractable. It has often been observed that in practice, simple structured controllers suffice for good sub-optimal control, and recent research in the artificial intelligence community has focused on policy search methods as techniques for finding sub-optimal controllers when such structured controllers do exist. Traditional model-based reinforcement learning algorithms make a certainty equivalence assumption on their learned models and calculate optimal policies for a maximum-likelihood Markovian model. We consider algorithms that evaluate and synthesize controllers under distributions of Markovian models. Previous work has demonstrated that algorithms that maximize mean reward with respect to model uncertainty leads to safer and more robust controllers. We consider briefly other performance criterion that emphasize robustness and exploration in the search for controllers, and note the relation with experiment design and active learning. To validate the power of the approach on a robotic application we demonstrate the presented learning control algorithm by flying an autonomous helicopter. We show that the controller learned is robust and delivers good performance in this real-world domain."
            },
            "slug": "Autonomous-helicopter-control-using-reinforcement-Bagnell-Schneider",
            "title": {
                "fragments": [],
                "text": "Autonomous helicopter control using reinforcement learning policy search methods"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work considers algorithms that evaluate and synthesize controllers under distributions of Markovian models and demonstrates the presented learning control algorithm by flying an autonomous helicopter and shows that the controller learned is robust and delivers good performance in this real-world domain."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164)"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686788"
                        ],
                        "name": "R. Miikkulainen",
                        "slug": "R.-Miikkulainen",
                        "structuredName": {
                            "firstName": "Risto",
                            "lastName": "Miikkulainen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Miikkulainen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696924"
                        ],
                        "name": "N. Iscoe",
                        "slug": "N.-Iscoe",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Iscoe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Iscoe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9960324"
                        ],
                        "name": "Aaron Shagrin",
                        "slug": "Aaron-Shagrin",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Shagrin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron Shagrin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066081221"
                        ],
                        "name": "Ryan Rapp",
                        "slug": "Ryan-Rapp",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Rapp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan Rapp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1970855"
                        ],
                        "name": "Sam Nazari",
                        "slug": "Sam-Nazari",
                        "structuredName": {
                            "firstName": "Sam",
                            "lastName": "Nazari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sam Nazari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057715095"
                        ],
                        "name": "P. Mcgrath",
                        "slug": "P.-Mcgrath",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Mcgrath",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Mcgrath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9956135"
                        ],
                        "name": "Cory Schoolland",
                        "slug": "Cory-Schoolland",
                        "structuredName": {
                            "firstName": "Cory",
                            "lastName": "Schoolland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cory Schoolland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49246839"
                        ],
                        "name": "E. Achkar",
                        "slug": "E.-Achkar",
                        "structuredName": {
                            "firstName": "E",
                            "lastName": "Achkar",
                            "middleNames": [
                                "J"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Achkar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9950994"
                        ],
                        "name": "Myles Brundage",
                        "slug": "Myles-Brundage",
                        "structuredName": {
                            "firstName": "Myles",
                            "lastName": "Brundage",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Myles Brundage"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1931977082"
                        ],
                        "name": "Jeremy Miller",
                        "slug": "Jeremy-Miller",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeremy Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107869290"
                        ],
                        "name": "Jonathan Epstein",
                        "slug": "Jonathan-Epstein",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Epstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Epstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36434122"
                        ],
                        "name": "Gurmeet Lamba",
                        "slug": "Gurmeet-Lamba",
                        "structuredName": {
                            "firstName": "Gurmeet",
                            "lastName": "Lamba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gurmeet Lamba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 215761174,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30a46f20fce1160aa1d8356f65132c04f259bad3",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "\n \n Conversion rate optimization (CRO) means designing an e-commerce web interface so that as many users as possible take a desired action such as registering for an account, requesting a contact, or making a purchase. Such design is usually done by hand, evaluating one change at a time through A/B testing, or evaluating all combinations of two or three variables through multivariate testing. Traditional CRO is thus limited to a small fraction of the design space only. This paper describes Sentient Ascend, an automatic CRO system that uses evolutionary search to discover effective web interfaces given a human-designed search space. Design candidates are evaluated in parallel on line with real users, making it possible to discover and utilize interactions between the design elements that are difficult to identify otherwise. A commercial product since September 2016, Ascend has been applied to numerous web interfaces across industries and search space sizes, with up to four-fold improvements over human design. Ascend can therefore be seen as massively multivariate CRO made possible by AI.\n \n"
            },
            "slug": "Sentient-Ascend:-AI-Based-Massively-Multivariate-Miikkulainen-Iscoe",
            "title": {
                "fragments": [],
                "text": "Sentient Ascend: AI-Based Massively Multivariate Conversion Rate Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Sentient Ascend is described, an automatic CRO system that uses evolutionary search to discover effective web interfaces given a human-designed search space, and can be seen as massively multivariate CRO made possible by AI."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689992"
                        ],
                        "name": "P. Abbeel",
                        "slug": "P.-Abbeel",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Abbeel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Abbeel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638694"
                        ],
                        "name": "Adam Coates",
                        "slug": "Adam-Coates",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Coates",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Coates"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39100828"
                        ],
                        "name": "M. Quigley",
                        "slug": "M.-Quigley",
                        "structuredName": {
                            "firstName": "Morgan",
                            "lastName": "Quigley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Quigley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15279814,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0bfbdafdfbcc268860fe54ae4d8f08d487bcc762",
            "isKey": false,
            "numCitedBy": 618,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Autonomous helicopter flight is widely regarded to be a highly challenging control problem. This paper presents the first successful autonomous completion on a real RC helicopter of the following four aerobatic maneuvers: forward flip and sideways roll at low speed, tail-in funnel, and nose-in funnel. Our experimental results significantly extend the state of the art in autonomous helicopter flight. We used the following approach: First we had a pilot fly the helicopter to help us find a helicopter dynamics model and a reward (cost) function. Then we used a reinforcement learning (optimal control) algorithm to find a controller that is optimized for the resulting model and reward function. More specifically, we used differential dynamic programming (DDP), an extension of the linear quadratic regulator (LQR)."
            },
            "slug": "An-Application-of-Reinforcement-Learning-to-Flight-Abbeel-Coates",
            "title": {
                "fragments": [],
                "text": "An Application of Reinforcement Learning to Aerobatic Helicopter Flight"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This paper presents the first successful autonomous completion on a real RC helicopter of the following four aerobatic maneuvers: forward flip and sideways roll at low speed, tail-in funnel, and nose- in funnel using differential dynamic programming (DDP), an extension of the linear quadratic regulator (LQR)."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734174"
                        ],
                        "name": "M. Marcus",
                        "slug": "M.-Marcus",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Marcus",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Marcus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2424234"
                        ],
                        "name": "Beatrice Santorini",
                        "slug": "Beatrice-Santorini",
                        "structuredName": {
                            "firstName": "Beatrice",
                            "lastName": "Santorini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Beatrice Santorini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2063206"
                        ],
                        "name": "Mary Ann Marcinkiewicz",
                        "slug": "Mary-Ann-Marcinkiewicz",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Marcinkiewicz",
                            "middleNames": [
                                "Ann"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mary Ann Marcinkiewicz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 56
                            }
                        ],
                        "text": "The benchmark utilizes the Penn Tree Bank (PTB) dataset (Marcus et al. 1993), which consists of 929k training words, 73k validation words, and 82k test words."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 252796,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b44fcbeea9415d400c5f5789d6b892b6f98daff",
            "isKey": false,
            "numCitedBy": 8207,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : As a result of this grant, the researchers have now published oil CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, with over 3 million words of that material assigned skeletal grammatical structure. This material now includes a fully hand-parsed version of the classic Brown corpus. About one half of the papers at the ACL Workshop on Using Large Text Corpora this past summer were based on the materials generated by this grant."
            },
            "slug": "Building-a-Large-Annotated-Corpus-of-English:-The-Marcus-Santorini",
            "title": {
                "fragments": [],
                "text": "Building a Large Annotated Corpus of English: The Penn Treebank"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "As a result of this grant, the researchers have now published on CDROM a corpus of over 4 million words of running text annotated with part-of- speech (POS) tags, which includes a fully hand-parsed version of the classic Brown corpus."
            },
            "venue": {
                "fragments": [],
                "text": "CL"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686788"
                        ],
                        "name": "R. Miikkulainen",
                        "slug": "R.-Miikkulainen",
                        "structuredName": {
                            "firstName": "Risto",
                            "lastName": "Miikkulainen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Miikkulainen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2696924"
                        ],
                        "name": "N. Iscoe",
                        "slug": "N.-Iscoe",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Iscoe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Iscoe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9960324"
                        ],
                        "name": "Aaron Shagrin",
                        "slug": "Aaron-Shagrin",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Shagrin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron Shagrin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1632356135"
                        ],
                        "name": "Ron Cordell",
                        "slug": "Ron-Cordell",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Cordell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ron Cordell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1970855"
                        ],
                        "name": "Sam Nazari",
                        "slug": "Sam-Nazari",
                        "structuredName": {
                            "firstName": "Sam",
                            "lastName": "Nazari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sam Nazari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9956135"
                        ],
                        "name": "Cory Schoolland",
                        "slug": "Cory-Schoolland",
                        "structuredName": {
                            "firstName": "Cory",
                            "lastName": "Schoolland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cory Schoolland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9950994"
                        ],
                        "name": "Myles Brundage",
                        "slug": "Myles-Brundage",
                        "structuredName": {
                            "firstName": "Myles",
                            "lastName": "Brundage",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Myles Brundage"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107869290"
                        ],
                        "name": "Jonathan Epstein",
                        "slug": "Jonathan-Epstein",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Epstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Epstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061468549"
                        ],
                        "name": "Randy Dean",
                        "slug": "Randy-Dean",
                        "structuredName": {
                            "firstName": "Randy",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Randy Dean"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36434122"
                        ],
                        "name": "Gurmeet Lamba",
                        "slug": "Gurmeet-Lamba",
                        "structuredName": {
                            "firstName": "Gurmeet",
                            "lastName": "Lamba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gurmeet Lamba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": " humans write imperfect versions of programs, and evolutionary algorithms are then used to repair them [15]; humans de\u2022ne the space of possible web designs, and evolution is used to \u2022nd e\u2021ective ones [35]. \u201eis same approach can be applied to the design of DNN architectures. \u201eis problem includes three challenges: how to design the components of the architecture, how to put them together into a full net"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 215753799,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e277e833974751cabbae02555117b7827d504c1f",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Conversion optimization means designing a web interface so that as many users as possible take a desired action on it, such as register or purchase. Such design is usually done by hand, testing one change at a time through A/B testing, or a limited number of combinations through multivariate testing, making it possible to evaluate only a small fraction of designs in a vast design space. This paper describes Sentient Ascend, an automatic conversion optimization system that uses evolutionary optimization to create effective web interface designs. Ascend makes it possible to discover and utilize interactions between the design elements that are difficult to identify otherwise. Moreover, evaluation of design candidates is done in parallel online, i.e. with a large number of real users interacting with the system. A case study on an existing media site shows that significant improvements (i.e. over 43%) are possible beyond human design. Ascend can therefore be seen as an approach to massively multivariate conversion optimization, based on a massively parallel interactive evolution."
            },
            "slug": "Conversion-rate-optimization-through-evolutionary-Miikkulainen-Iscoe",
            "title": {
                "fragments": [],
                "text": "Conversion rate optimization through evolutionary computation"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Sentient Ascend is described, an automatic conversion optimization system that uses evolutionary optimization to create effective web interface designs that makes it possible to discover and utilize interactions between the design elements that are difficult to identify otherwise."
            },
            "venue": {
                "fragments": [],
                "text": "GECCO"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39717886"
                        ],
                        "name": "Xinlei Chen",
                        "slug": "Xinlei-Chen",
                        "structuredName": {
                            "firstName": "Xinlei",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinlei Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113484216"
                        ],
                        "name": "Hao Fang",
                        "slug": "Hao-Fang",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Fang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Fang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33493200"
                        ],
                        "name": "Tsung-Yi Lin",
                        "slug": "Tsung-Yi-Lin",
                        "structuredName": {
                            "firstName": "Tsung-Yi",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tsung-Yi Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8137017"
                        ],
                        "name": "Ramakrishna Vedantam",
                        "slug": "Ramakrishna-Vedantam",
                        "structuredName": {
                            "firstName": "Ramakrishna",
                            "lastName": "Vedantam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ramakrishna Vedantam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144157872"
                        ],
                        "name": "Saurabh Gupta",
                        "slug": "Saurabh-Gupta",
                        "structuredName": {
                            "firstName": "Saurabh",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saurabh Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127283"
                        ],
                        "name": "Piotr Doll\u00e1r",
                        "slug": "Piotr-Doll\u00e1r",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Doll\u00e1r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piotr Doll\u00e1r"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699161"
                        ],
                        "name": "C. L. Zitnick",
                        "slug": "C.-L.-Zitnick",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Zitnick",
                            "middleNames": [
                                "Lawrence"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. L. Zitnick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 152
                            }
                        ],
                        "text": "Since there is no single best accepted metric for evaluating captions, the fitness function is the mean across three metrics (BLEU, METEOR, and CIDEr; (Chen et al. 2015)) normalized by their baseline values."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 84
                            }
                        ],
                        "text": "Evolved networks were trained with the open source MSCOCO image captioning dataset (Chen et al. 2015), along with a new dataset collected for this website."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2210455,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "696ca58d93f6404fea0fc75c62d1d7b378f47628",
            "isKey": false,
            "numCitedBy": 1197,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe the Microsoft COCO Caption dataset and evaluation server. When completed, the dataset will contain over one and a half million captions describing over 330,000 images. For the training and validation images, five independent human generated captions will be provided. To ensure consistency in evaluation of automatic caption generation algorithms, an evaluation server is used. The evaluation server receives candidate captions and scores them using several popular metrics, including BLEU, METEOR, ROUGE and CIDEr. Instructions for using the evaluation server are provided."
            },
            "slug": "Microsoft-COCO-Captions:-Data-Collection-and-Server-Chen-Fang",
            "title": {
                "fragments": [],
                "text": "Microsoft COCO Captions: Data Collection and Evaluation Server"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "The Microsoft COCO Caption dataset and evaluation server are described and several popular metrics, including BLEU, METEOR, ROUGE and CIDEr are used to score candidate captions."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49717577"
                        ],
                        "name": "H. Kim",
                        "slug": "H.-Kim",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Kim",
                            "middleNames": [
                                "Jin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144797536"
                        ],
                        "name": "S. Sastry",
                        "slug": "S.-Sastry",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Sastry",
                            "middleNames": [
                                "Shankar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Sastry"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7142905,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13e2d5c4d39bc58b42f9004e5b03905f847dfa0f",
            "isKey": false,
            "numCitedBy": 339,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Autonomous helicopter flight represents a challenging control problem, with complex, noisy, dynamics. In this paper, we describe a successful application of reinforcement learning to autonomous helicopter flight. We first fit a stochastic, nonlinear model of the helicopter dynamics. We then use the model to learn to hover in place, and to fly a number of maneuvers taken from an RC helicopter competition."
            },
            "slug": "Autonomous-Helicopter-Flight-via-Reinforcement-Ng-Kim",
            "title": {
                "fragments": [],
                "text": "Autonomous Helicopter Flight via Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper first fit a stochastic, nonlinear model of the helicopter dynamics, then uses the model to learn to hover in place, and to fly a number of maneuvers taken from an RC helicopter competition."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "etails are le\u203a for computational optimization systems to \u2022gure out. For instance, humans write the overall design of a so\u203aware system, and the parameters and low-level code is optimized automatically [23]; humans write imperfect versions of programs, and evolutionary algorithms are then used to repair them [15]; humans de\u2022ne the space of possible web designs, and evolution is used to \u2022nd e\u2021ective ones"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 134
                            }
                        ],
                        "text": "For instance, humans write the overall design of a software system, and the parameters and low-level code is optimized automatically (Hoos 2012); humans write imperfect versions of programs, and evolutionary algorithms are then used to repair them (Goues et al. 2012); humans define the space of\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16782174,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0543827f43efd420fff5a815060175f00b728f67",
            "isKey": false,
            "numCitedBy": 202,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Avoid premature commitment, seek design alternatives, and automatically generate performance-optimized software."
            },
            "slug": "Programming-by-optimization-Hoos",
            "title": {
                "fragments": [],
                "text": "Programming by optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "Avoid premature commitment, seek design alternatives, and automatically generate performance-optimized software to avoid wasted effort and improve quality of life."
            },
            "venue": {
                "fragments": [],
                "text": "Commun. ACM"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790474"
                        ],
                        "name": "Alexandre Bergel",
                        "slug": "Alexandre-Bergel",
                        "structuredName": {
                            "firstName": "Alexandre",
                            "lastName": "Bergel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexandre Bergel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 242262470,
            "fieldsOfStudy": [],
            "id": "1300e40a0749d41807d2f9ae093ef25744e82877",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Neuroevolution-Bergel",
            "title": {
                "fragments": [],
                "text": "Neuroevolution"
            },
            "venue": {
                "fragments": [],
                "text": "Agile Artificial Intelligence in Pharo"
            },
            "year": 2020
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 248
                            }
                        ],
                        "text": "For instance, humans write the overall design of a software system, and the parameters and low-level code is optimized automatically (Hoos 2012); humans write imperfect versions of programs, and evolutionary algorithms are then used to repair them (Goues et al. 2012); humans define the space of possible web designs, and evolution is used to find effective ones (Miikkulainen and Iscoe 2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Genprog: automatic bug correction in real programs"
            },
            "venue": {
                "fragments": [],
                "text": "ACM Transactions on Software Engineering"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evolving artificial neural networks Image captioning with semantic attention"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 21,
            "methodology": 20,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 57,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Evolving-Deep-Neural-Networks-Miikkulainen-Liang/cd7c02cab3ec4e59150657bd6660eab97def9a3a?sort=total-citations"
}