{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2732658"
                        ],
                        "name": "Brandon Reagen",
                        "slug": "Brandon-Reagen",
                        "structuredName": {
                            "firstName": "Brandon",
                            "lastName": "Reagen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brandon Reagen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3313708"
                        ],
                        "name": "P. Whatmough",
                        "slug": "P.-Whatmough",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Whatmough",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Whatmough"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3313828"
                        ],
                        "name": "Robert Adolf",
                        "slug": "Robert-Adolf",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Adolf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Adolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37408074"
                        ],
                        "name": "Saketh Rama",
                        "slug": "Saketh-Rama",
                        "structuredName": {
                            "firstName": "Saketh",
                            "lastName": "Rama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saketh Rama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3389887"
                        ],
                        "name": "Hyunkwang Lee",
                        "slug": "Hyunkwang-Lee",
                        "structuredName": {
                            "firstName": "Hyunkwang",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hyunkwang Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108166207"
                        ],
                        "name": "Sae Kyu Lee",
                        "slug": "Sae-Kyu-Lee",
                        "structuredName": {
                            "firstName": "Sae",
                            "lastName": "Lee",
                            "middleNames": [
                                "Kyu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sae Kyu Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388574431"
                        ],
                        "name": "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato",
                        "slug": "Jos\u00e9-Miguel-Hern\u00e1ndez-Lobato",
                        "structuredName": {
                            "firstName": "Jos\u00e9 Miguel",
                            "lastName": "Hern\u00e1ndez-Lobato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2255803"
                        ],
                        "name": "Gu-Yeon Wei",
                        "slug": "Gu-Yeon-Wei",
                        "structuredName": {
                            "firstName": "Gu-Yeon",
                            "lastName": "Wei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gu-Yeon Wei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1896817"
                        ],
                        "name": "D. Brooks",
                        "slug": "D.-Brooks",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Brooks",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Brooks"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "Minerva [39] also uses data quantization to save memory energy."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 44529396,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6174fe357592420826ea21d23cb35943048a83cf",
            "isKey": false,
            "numCitedBy": 312,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The continued success of Deep Neural Networks (DNNs) in classification tasks has sparked a trend of accelerating their execution with specialized hardware. While published designs easily give an order of magnitude improvement over general-purpose hardware, few look beyond an initial implementation. This paper presents Minerva, a highly automated co-design approach across the algorithm, architecture, and circuit levels to optimize DNN hardware accelerators. Compared to an established fixed-point accelerator baseline, we show that fine-grained, heterogeneous datatype optimization reduces power by 1.5\u00d7; aggressive, inline predication and pruning of small activity values further reduces power by 2.0\u00d7; and active hardware fault detection coupled with domain-aware error mitigation eliminates an additional 2.7\u00d7 through lowering SRAM voltages. Across five datasets, these optimizations provide a collective average of 8.1\u00d7 power reduction over an accelerator baseline without compromising DNN model accuracy. Minerva enables highly accurate, ultra-low power DNN accelerators (in the range of tens of milliwatts), making it feasible to deploy DNNs in power-constrained IoT and mobile devices."
            },
            "slug": "Minerva:-Enabling-Low-Power,-Highly-Accurate-Deep-Reagen-Whatmough",
            "title": {
                "fragments": [],
                "text": "Minerva: Enabling Low-Power, Highly-Accurate Deep Neural Network Accelerators"
            },
            "venue": {
                "fragments": [],
                "text": "ISCA"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143840275"
                        ],
                        "name": "Song Han",
                        "slug": "Song-Han",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3123774"
                        ],
                        "name": "Huizi Mao",
                        "slug": "Huizi-Mao",
                        "structuredName": {
                            "firstName": "Huizi",
                            "lastName": "Mao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huizi Mao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80724002"
                        ],
                        "name": "W. Dally",
                        "slug": "W.-Dally",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dally",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dally"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Performing the indexing itself involves\n1\nbit manipulations to extract four-bit Iij and an extra load (which is almost assured a cache hit)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2134321,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "642d0f49b7826adcf986616f4af77e736229990f",
            "isKey": false,
            "numCitedBy": 5732,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural networks are both computationally intensive and memory intensive, making them difficult to deploy on embedded systems with limited hardware resources. To address this limitation, we introduce \"deep compression\", a three stage pipeline: pruning, trained quantization and Huffman coding, that work together to reduce the storage requirement of neural networks by 35x to 49x without affecting their accuracy. Our method first prunes the network by learning only the important connections. Next, we quantize the weights to enforce weight sharing, finally, we apply Huffman coding. After the first two steps we retrain the network to fine tune the remaining connections and the quantized centroids. Pruning, reduces the number of connections by 9x to 13x; Quantization then reduces the number of bits that represent each connection from 32 to 5. On the ImageNet dataset, our method reduced the storage required by AlexNet by 35x, from 240MB to 6.9MB, without loss of accuracy. Our method reduced the size of VGG-16 by 49x from 552MB to 11.3MB, again with no loss of accuracy. This allows fitting the model into on-chip SRAM cache rather than off-chip DRAM memory. Our compression method also facilitates the use of complex neural networks in mobile applications where application size and download bandwidth are constrained. Benchmarked on CPU, GPU and mobile GPU, compressed network has 3x to 4x layerwise speedup and 3x to 7x better energy efficiency."
            },
            "slug": "Deep-Compression:-Compressing-Deep-Neural-Network-Han-Mao",
            "title": {
                "fragments": [],
                "text": "Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work introduces \"deep compression\", a three stage pipeline: pruning, trained quantization and Huffman coding, that work together to reduce the storage requirement of neural networks by 35x to 49x without affecting their accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7377735"
                        ],
                        "name": "Yunji Chen",
                        "slug": "Yunji-Chen",
                        "structuredName": {
                            "firstName": "Yunji",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yunji Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068286576"
                        ],
                        "name": "Tao Luo",
                        "slug": "Tao-Luo",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39419985"
                        ],
                        "name": "Shaoli Liu",
                        "slug": "Shaoli-Liu",
                        "structuredName": {
                            "firstName": "Shaoli",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoli Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145407329"
                        ],
                        "name": "Shijin Zhang",
                        "slug": "Shijin-Zhang",
                        "structuredName": {
                            "firstName": "Shijin",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shijin Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37167270"
                        ],
                        "name": "Liqiang He",
                        "slug": "Liqiang-He",
                        "structuredName": {
                            "firstName": "Liqiang",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liqiang He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110368816"
                        ],
                        "name": "Jia Wang",
                        "slug": "Jia-Wang",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3353457"
                        ],
                        "name": "Ling Li",
                        "slug": "Ling-Li",
                        "structuredName": {
                            "firstName": "Ling",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ling Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144049725"
                        ],
                        "name": "Tianshi Chen",
                        "slug": "Tianshi-Chen",
                        "structuredName": {
                            "firstName": "Tianshi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianshi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719934"
                        ],
                        "name": "Zhiwei Xu",
                        "slug": "Zhiwei-Xu",
                        "structuredName": {
                            "firstName": "Zhiwei",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhiwei Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145550877"
                        ],
                        "name": "Ninghui Sun",
                        "slug": "Ninghui-Sun",
                        "structuredName": {
                            "firstName": "Ninghui",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ninghui Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731764"
                        ],
                        "name": "O. Temam",
                        "slug": "O.-Temam",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Temam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Temam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Performing the indexing itself involves\n1\nbit manipulations to extract four-bit Iij and an extra load (which is almost assured a cache hit)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6838992,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4157ed3db4c656854e69931cb6089b64b08784b9",
            "isKey": false,
            "numCitedBy": 1065,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "Many companies are deploying services, either for consumers or industry, which are largely based on machine-learning algorithms for sophisticated processing of large amounts of data. The state-of-the-art and most popular such machine-learning algorithms are Convolutional and Deep Neural Networks (CNNs and DNNs), which are known to be both computationally and memory intensive. A number of neural network accelerators have been recently proposed which can offer high computational capacity/area ratio, but which remain hampered by memory accesses. However, unlike the memory wall faced by processors on general-purpose workloads, the CNNs and DNNs memory footprint, while large, is not beyond the capability of the on chip storage of a multi-chip system. This property, combined with the CNN/DNN algorithmic characteristics, can lead to high internal bandwidth and low external communications, which can in turn enable high-degree parallelism at a reasonable area cost. In this article, we introduce a custom multi-chip machine-learning architecture along those lines. We show that, on a subset of the largest known neural network layers, it is possible to achieve a speedup of 450.65x over a GPU, and reduce the energy by 150.31x on average for a 64-chip system. We implement the node down to the place and route at 28nm, containing a combination of custom storage and computational units, with industry-grade interconnects."
            },
            "slug": "DaDianNao:-A-Machine-Learning-Supercomputer-Chen-Luo",
            "title": {
                "fragments": [],
                "text": "DaDianNao: A Machine-Learning Supercomputer"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This article introduces a custom multi-chip machine-learning architecture, showing that, on a subset of the largest known neural network layers, it is possible to achieve a speedup of 450.65x over a GPU, and reduce the energy by 150.31x on average for a 64-chip system."
            },
            "venue": {
                "fragments": [],
                "text": "2014 47th Annual IEEE/ACM International Symposium on Microarchitecture"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1433007765"
                        ],
                        "name": "Ali Shafiee",
                        "slug": "Ali-Shafiee",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Shafiee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ali Shafiee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783032"
                        ],
                        "name": "Anirban Nag",
                        "slug": "Anirban-Nag",
                        "structuredName": {
                            "firstName": "Anirban",
                            "lastName": "Nag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anirban Nag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2358911"
                        ],
                        "name": "N. Muralimanohar",
                        "slug": "N.-Muralimanohar",
                        "structuredName": {
                            "firstName": "Naveen",
                            "lastName": "Muralimanohar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Muralimanohar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777422"
                        ],
                        "name": "R. Balasubramonian",
                        "slug": "R.-Balasubramonian",
                        "structuredName": {
                            "firstName": "Rajeev",
                            "lastName": "Balasubramonian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Balasubramonian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33102961"
                        ],
                        "name": "J. Strachan",
                        "slug": "J.-Strachan",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Strachan",
                            "middleNames": [
                                "Paul"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Strachan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707095"
                        ],
                        "name": "Miao Hu",
                        "slug": "Miao-Hu",
                        "structuredName": {
                            "firstName": "Miao",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Miao Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761983"
                        ],
                        "name": "R. Williams",
                        "slug": "R.-Williams",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Williams",
                            "middleNames": [
                                "Stanley"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3052879"
                        ],
                        "name": "Vivek Srikumar",
                        "slug": "Vivek-Srikumar",
                        "structuredName": {
                            "firstName": "Vivek",
                            "lastName": "Srikumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vivek Srikumar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 58
                            }
                        ],
                        "text": "They are unable to exploit dynamic activation sparsity [21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6329628,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9071775ebcfebddd54d879fe7e6c627673e4d305",
            "isKey": false,
            "numCitedBy": 1010,
            "numCiting": 90,
            "paperAbstract": {
                "fragments": [],
                "text": "A number of recent efforts have attempted to design accelerators for popular machine learning algorithms, such as those involving convolutional and deep neural networks (CNNs and DNNs). These algorithms typically involve a large number of multiply-accumulate (dot-product) operations. A recent project, DaDianNao, adopts a near data processing approach, where a specialized neural functional unit performs all the digital arithmetic operations and receives input weights from adjacent eDRAM banks. This work explores an in-situ processing approach, where memristor crossbar arrays not only store input weights, but are also used to perform dot-product operations in an analog manner. While the use of crossbar memory as an analog dot-product engine is well known, no prior work has designed or characterized a full-fledged accelerator based on crossbars. In particular, our work makes the following contributions: (i) We design a pipelined architecture, with some crossbars dedicated for each neural network layer, and eDRAM buffers that aggregate data between pipeline stages. (ii) We define new data encoding techniques that are amenable to analog computations and that can reduce the high overheads of analog-to-digital conversion (ADC). (iii) We define the many supporting digital components required in an analog CNN accelerator and carry out a design space exploration to identify the best balance of memristor storage/compute, ADCs, and eDRAM storage on a chip. On a suite of CNN and DNN workloads, the proposed ISAAC architecture yields improvements of 14.8\u00d7, 5.5\u00d7, and 7.5\u00d7 in throughput, energy, and computational density (respectively), relative to the state-of-the-art DaDianNao architecture."
            },
            "slug": "ISAAC:-A-Convolutional-Neural-Network-Accelerator-Shafiee-Nag",
            "title": {
                "fragments": [],
                "text": "ISAAC: A Convolutional Neural Network Accelerator with In-Situ Analog Arithmetic in Crossbars"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work explores an in-situ processing approach, where memristor crossbar arrays not only store input weights, but are also used to perform dot-product operations in an analog manner."
            },
            "venue": {
                "fragments": [],
                "text": "2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143840275"
                        ],
                        "name": "Song Han",
                        "slug": "Song-Han",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47325862"
                        ],
                        "name": "Jeff Pool",
                        "slug": "Jeff-Pool",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Pool",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeff Pool"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066786849"
                        ],
                        "name": "J. Tran",
                        "slug": "J.-Tran",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Tran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80724002"
                        ],
                        "name": "W. Dally",
                        "slug": "W.-Dally",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dally",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dally"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This motivates building a special engine that can operate on a compressed network."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2238772,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1ff9a37d766e3a4f39757f5e1b235a42dacf18ff",
            "isKey": false,
            "numCitedBy": 4076,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural networks are both computationally intensive and memory intensive, making them difficult to deploy on embedded systems. Also, conventional networks fix the architecture before training starts; as a result, training cannot improve the architecture. To address these limitations, we describe a method to reduce the storage and computation required by neural networks by an order of magnitude without affecting their accuracy by learning only the important connections. Our method prunes redundant connections using a three-step method. First, we train the network to learn which connections are important. Next, we prune the unimportant connections. Finally, we retrain the network to fine tune the weights of the remaining connections. On the ImageNet dataset, our method reduced the number of parameters of AlexNet by a factor of 9x, from 61 million to 6.7 million, without incurring accuracy loss. Similar experiments with VGG-16 found that the number of parameters can be reduced by 13x, from 138 million to 10.3 million, again with no loss of accuracy."
            },
            "slug": "Learning-both-Weights-and-Connections-for-Efficient-Han-Pool",
            "title": {
                "fragments": [],
                "text": "Learning both Weights and Connections for Efficient Neural Network"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A method to reduce the storage and computation required by neural networks by an order of magnitude without affecting their accuracy by learning only the important connections, and prunes redundant connections using a three-step method."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678776"
                        ],
                        "name": "Zidong Du",
                        "slug": "Zidong-Du",
                        "structuredName": {
                            "firstName": "Zidong",
                            "lastName": "Du",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zidong Du"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785040"
                        ],
                        "name": "Robert Fasthuber",
                        "slug": "Robert-Fasthuber",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Fasthuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Fasthuber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144049725"
                        ],
                        "name": "Tianshi Chen",
                        "slug": "Tianshi-Chen",
                        "structuredName": {
                            "firstName": "Tianshi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianshi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748620"
                        ],
                        "name": "P. Ienne",
                        "slug": "P.-Ienne",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Ienne",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Ienne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3353457"
                        ],
                        "name": "Ling Li",
                        "slug": "Ling-Li",
                        "structuredName": {
                            "firstName": "Ling",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ling Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068286576"
                        ],
                        "name": "Tao Luo",
                        "slug": "Tao-Luo",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32215073"
                        ],
                        "name": "Xiaobing Feng",
                        "slug": "Xiaobing-Feng",
                        "structuredName": {
                            "firstName": "Xiaobing",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaobing Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7377735"
                        ],
                        "name": "Yunji Chen",
                        "slug": "Yunji-Chen",
                        "structuredName": {
                            "firstName": "Yunji",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yunji Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731764"
                        ],
                        "name": "O. Temam",
                        "slug": "O.-Temam",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Temam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Temam"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "Because memory access is the bottleneck in large layers, compressing the neural network offers a solution."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11504619,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd6507b5c9deaf87bda81e59ce15b2309df0bf37",
            "isKey": false,
            "numCitedBy": 743,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years, neural network accelerators have been shown to achieve both high energy efficiency and high performance for a broad application scope within the important category of recognition and mining applications. Still, both the energy efficiency and peiformance of such accelerators remain limited by memory accesses. In this paper, we focus on image applications, arguably the most important category among recognition and mining applications. The neural networks which are state-of-the-art for these applications are Convolutional Neural Networks (CNN), and they have an important property: weights are shared among many neurons, considerably reducing the neural network memory footprint. This property allows to entirely map a CNN within an SRAM, eliminating all DRAM accesses for weights. By further hoisting this accelerator next to the image sensor, it is possible to eliminate all remaining DRAM accesses, i.e., for inputs and outputs. In this paper, we propose such a CNN accelerator, placed next to a CMOS or CCD sensor. The absence of DRAM accesses combined with a careful exploitation of the specific data access patterns within CNNs allows us to design an accelerator which is 60x more energy efficient than the previous state-of-the-art neural network accelerator. We present a fult design down to the layout at 65 nm, with a modest footprint of 4.86 mm2 and consuming only 320 mW, but still about 30x faster than high-end GPUs."
            },
            "slug": "ShiDianNao:-Shifting-vision-processing-closer-to-Du-Fasthuber",
            "title": {
                "fragments": [],
                "text": "ShiDianNao: Shifting vision processing closer to the sensor"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper proposes an accelerator which is 60x more energy efficient than the previous state-of-the-art neural network accelerator, designed down to the layout at 65 nm, with a modest footprint and consuming only 320 mW, but still about 30x faster than high-end GPUs."
            },
            "venue": {
                "fragments": [],
                "text": "2015 ACM/IEEE 42nd Annual International Symposium on Computer Architecture (ISCA)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144049725"
                        ],
                        "name": "Tianshi Chen",
                        "slug": "Tianshi-Chen",
                        "structuredName": {
                            "firstName": "Tianshi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianshi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678776"
                        ],
                        "name": "Zidong Du",
                        "slug": "Zidong-Du",
                        "structuredName": {
                            "firstName": "Zidong",
                            "lastName": "Du",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zidong Du"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145550877"
                        ],
                        "name": "Ninghui Sun",
                        "slug": "Ninghui-Sun",
                        "structuredName": {
                            "firstName": "Ninghui",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ninghui Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110368816"
                        ],
                        "name": "Jia Wang",
                        "slug": "Jia-Wang",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7514065"
                        ],
                        "name": "Chengyong Wu",
                        "slug": "Chengyong-Wu",
                        "structuredName": {
                            "firstName": "Chengyong",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chengyong Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7377735"
                        ],
                        "name": "Yunji Chen",
                        "slug": "Yunji-Chen",
                        "structuredName": {
                            "firstName": "Yunji",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yunji Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731764"
                        ],
                        "name": "O. Temam",
                        "slug": "O.-Temam",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Temam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Temam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Therefore it is preferable to create an efficient method of executing large neural networks without the latency cost of batching."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207209696,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22e477a9fdde86ab1f8f4dafdb4d88ea37e31fbd",
            "isKey": false,
            "numCitedBy": 1235,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Machine-Learning tasks are becoming pervasive in a broad range of domains, and in a broad range of systems (from embedded systems to data centers). At the same time, a small set of machine-learning algorithms (especially Convolutional and Deep Neural Networks, i.e., CNNs and DNNs) are proving to be state-of-the-art across many applications. As architectures evolve towards heterogeneous multi-cores composed of a mix of cores and accelerators, a machine-learning accelerator can achieve the rare combination of efficiency (due to the small number of target algorithms) and broad application scope. Until now, most machine-learning accelerator designs have focused on efficiently implementing the computational part of the algorithms. However, recent state-of-the-art CNNs and DNNs are characterized by their large size. In this study, we design an accelerator for large-scale CNNs and DNNs, with a special emphasis on the impact of memory on accelerator design, performance and energy. We show that it is possible to design an accelerator with a high throughput, capable of performing 452 GOP/s (key NN operations such as synaptic weight multiplications and neurons outputs additions) in a small footprint of 3.02 mm2 and 485 mW; compared to a 128-bit 2GHz SIMD processor, the accelerator is 117.87x faster, and it can reduce the total energy by 21.08x. The accelerator characteristics are obtained after layout at 65 nm. Such a high throughput in a small footprint can open up the usage of state-of-the-art machine-learning algorithms in a broad set of systems and for a broad set of applications."
            },
            "slug": "DianNao:-a-small-footprint-high-throughput-for-Chen-Du",
            "title": {
                "fragments": [],
                "text": "DianNao: a small-footprint high-throughput accelerator for ubiquitous machine-learning"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This study designs an accelerator for large-scale CNNs and DNNs, with a special emphasis on the impact of memory on accelerator design, performance and energy, and shows that it is possible to design an accelerator with a high throughput, capable of performing 452 GOP/s in a small footprint."
            },
            "venue": {
                "fragments": [],
                "text": "ASPLOS 2014"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2357931"
                        ],
                        "name": "Steven K. Esser",
                        "slug": "Steven-K.-Esser",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Esser",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven K. Esser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2408151"
                        ],
                        "name": "P. Merolla",
                        "slug": "P.-Merolla",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Merolla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Merolla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2100344"
                        ],
                        "name": "J. Arthur",
                        "slug": "J.-Arthur",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Arthur",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Arthur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34019307"
                        ],
                        "name": "A. Cassidy",
                        "slug": "A.-Cassidy",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Cassidy",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Cassidy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2730753"
                        ],
                        "name": "R. Appuswamy",
                        "slug": "R.-Appuswamy",
                        "structuredName": {
                            "firstName": "Rathinakumar",
                            "lastName": "Appuswamy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Appuswamy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2542089"
                        ],
                        "name": "Alexander Andreopoulos",
                        "slug": "Alexander-Andreopoulos",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Andreopoulos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander Andreopoulos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072283776"
                        ],
                        "name": "David J. Berg",
                        "slug": "David-J.-Berg",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Berg",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46571359"
                        ],
                        "name": "J. McKinstry",
                        "slug": "J.-McKinstry",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "McKinstry",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. McKinstry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2555407"
                        ],
                        "name": "T. Melano",
                        "slug": "T.-Melano",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Melano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Melano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3102838"
                        ],
                        "name": "D. Barch",
                        "slug": "D.-Barch",
                        "structuredName": {
                            "firstName": "Davis",
                            "lastName": "Barch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Barch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1894356"
                        ],
                        "name": "C. D. Nolfo",
                        "slug": "C.-D.-Nolfo",
                        "structuredName": {
                            "firstName": "Carmelo",
                            "lastName": "Nolfo",
                            "middleNames": [
                                "di"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. D. Nolfo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111766588"
                        ],
                        "name": "Pallab Datta",
                        "slug": "Pallab-Datta",
                        "structuredName": {
                            "firstName": "Pallab",
                            "lastName": "Datta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pallab Datta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767364"
                        ],
                        "name": "A. Amir",
                        "slug": "A.-Amir",
                        "structuredName": {
                            "firstName": "Arnon",
                            "lastName": "Amir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Amir"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736425"
                        ],
                        "name": "Brian Taba",
                        "slug": "Brian-Taba",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Taba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian Taba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712991"
                        ],
                        "name": "M. Flickner",
                        "slug": "M.-Flickner",
                        "structuredName": {
                            "firstName": "Myron",
                            "lastName": "Flickner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Flickner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1944330"
                        ],
                        "name": "D. Modha",
                        "slug": "D.-Modha",
                        "structuredName": {
                            "firstName": "Dharmendra",
                            "lastName": "Modha",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Modha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17770698,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29316449c7cc52ad326c5d1bd5b0dc5af27c1496",
            "isKey": false,
            "numCitedBy": 552,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Significance Brain-inspired computing seeks to develop new technologies that solve real-world problems while remaining grounded in the physical requirements of energy, speed, and size. Meeting these challenges requires high-performing algorithms that are capable of running on efficient hardware. Here, we adapt deep convolutional neural networks, which are today\u2019s state-of-the-art approach for machine perception in many domains, to perform classification tasks on neuromorphic hardware, which is today\u2019s most efficient platform for running neural networks. Using our approach, we demonstrate near state-of-the-art accuracy on eight datasets, while running at between 1,200 and 2,600 frames/s and using between 25 and 275 mW. Deep networks are now able to achieve human-level performance on a broad spectrum of recognition tasks. Independently, neuromorphic computing has now demonstrated unprecedented energy-efficiency through a new chip architecture based on spiking neurons, low precision synapses, and a scalable communication network. Here, we demonstrate that neuromorphic computing, despite its novel architectural primitives, can implement deep convolution networks that (i) approach state-of-the-art classification accuracy across eight standard datasets encompassing vision and speech, (ii) perform inference while preserving the hardware\u2019s underlying energy-efficiency and high throughput, running on the aforementioned datasets at between 1,200 and 2,600 frames/s and using between 25 and 275 mW (effectively >6,000 frames/s per Watt), and (iii) can be specified and trained using backpropagation with the same ease-of-use as contemporary deep learning. This approach allows the algorithmic power of deep learning to be merged with the efficiency of neuromorphic processors, bringing the promise of embedded, intelligent, brain-inspired computing one step closer."
            },
            "slug": "Convolutional-networks-for-fast,-energy-efficient-Esser-Merolla",
            "title": {
                "fragments": [],
                "text": "Convolutional networks for fast, energy-efficient neuromorphic computing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This approach allows the algorithmic power of deep learning to be merged with the efficiency of neuromorphic processors, bringing the promise of embedded, intelligent, brain-inspired computing one step closer."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1848503"
                        ],
                        "name": "Jiantao Qiu",
                        "slug": "Jiantao-Qiu",
                        "structuredName": {
                            "firstName": "Jiantao",
                            "lastName": "Qiu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiantao Qiu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146044047"
                        ],
                        "name": "Jie Wang",
                        "slug": "Jie-Wang",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067824417"
                        ],
                        "name": "Song Yao",
                        "slug": "Song-Yao",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Yao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Yao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35493564"
                        ],
                        "name": "Kaiyuan Guo",
                        "slug": "Kaiyuan-Guo",
                        "structuredName": {
                            "firstName": "Kaiyuan",
                            "lastName": "Guo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiyuan Guo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2789329"
                        ],
                        "name": "Boxun Li",
                        "slug": "Boxun-Li",
                        "structuredName": {
                            "firstName": "Boxun",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Boxun Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1848243"
                        ],
                        "name": "Erjin Zhou",
                        "slug": "Erjin-Zhou",
                        "structuredName": {
                            "firstName": "Erjin",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Erjin Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1909938"
                        ],
                        "name": "Jincheng Yu",
                        "slug": "Jincheng-Yu",
                        "structuredName": {
                            "firstName": "Jincheng",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jincheng Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50149494"
                        ],
                        "name": "Tianqi Tang",
                        "slug": "Tianqi-Tang",
                        "structuredName": {
                            "firstName": "Tianqi",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianqi Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3977801"
                        ],
                        "name": "Ningyi Xu",
                        "slug": "Ningyi-Xu",
                        "structuredName": {
                            "firstName": "Ningyi",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ningyi Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15168128"
                        ],
                        "name": "Sen Song",
                        "slug": "Sen-Song",
                        "structuredName": {
                            "firstName": "Sen",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sen Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40987227"
                        ],
                        "name": "Yu Wang",
                        "slug": "Yu-Wang",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39150998"
                        ],
                        "name": "Huazhong Yang",
                        "slug": "Huazhong-Yang",
                        "structuredName": {
                            "firstName": "Huazhong",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huazhong Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 91
                            }
                        ],
                        "text": "We perform the indexing S[Iij ] and the multiply-add only for those columns for which both Wij and aj are non-zero, so that both the sparsity of the matrix and the vector are exploited."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 82
                            }
                        ],
                        "text": "To address the output accumulators, the row number i corresponding to each weight Wij is generated by keeping a running sum of the entries of the x array."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "Neither is able to exploit weight sharing."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "Weight sharing replaces each weight Wij with a fourbit index Iij into a shared table S of 16 possible weight values."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 150
                            }
                        ],
                        "text": "With deep compression, the per-activation computation of Equation (2) becomes\nbi = ReLU\n  \u2211\nj\u2208Xi\u2229Y S[Iij ]aj\n  (3)\nWhere Xi is the set of columns j for which Wij 6= 0, Y is the set of indices j for which aj 6= 0, Iij is the index to the shared weight that replaces Wij , and S is the table of shared weights."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 86
                            }
                        ],
                        "text": "The output activations of Equation (1) are computed element-wise as:\nbi = ReLU\n  n\u22121\u2211\nj=0\nWijaj\n  (2)\nDeep Compression [23] describes a method to compress DNNs without loss of accuracy through a combination of pruning and weight sharing."
                    },
                    "intents": []
                }
            ],
            "corpusId": 207233273,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c382406fd8db2744b2a609837395e5da05e1d2ed",
            "isKey": true,
            "numCitedBy": 897,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years, convolutional neural network (CNN) based methods have achieved great success in a large number of applications and have been among the most powerful and widely used techniques in computer vision. However, CNN-based methods are com-putational-intensive and resource-consuming, and thus are hard to be integrated into embedded systems such as smart phones, smart glasses, and robots. FPGA is one of the most promising platforms for accelerating CNN, but the limited bandwidth and on-chip memory size limit the performance of FPGA accelerator for CNN. In this paper, we go deeper with the embedded FPGA platform on accelerating CNNs and propose a CNN accelerator design on embedded FPGA for Image-Net large-scale image classification. We first present an in-depth analysis of state-of-the-art CNN models and show that Convolutional layers are computational-centric and Fully-Connected layers are memory-centric. Then the dynamic-precision data quantization method and a convolver design that is efficient for all layer types in CNN are proposed to improve the bandwidth and resource utilization. Results show that only 0.4% accuracy loss is introduced by our data quantization flow for the very deep VGG16 model when 8/4-bit quantization is used. A data arrangement method is proposed to further ensure a high utilization of the external memory bandwidth. Finally, a state-of-the-art CNN, VGG16-SVD, is implemented on an embedded FPGA platform as a case study. VGG16-SVD is the largest and most accurate network that has been implemented on FPGA end-to-end so far. The system on Xilinx Zynq ZC706 board achieves a frame rate at 4.45 fps with the top-5 accuracy of 86.66% using 16-bit quantization. The average performance of convolutional layers and the full CNN is 187.8 GOP/s and 137.0 GOP/s under 150MHz working frequency, which outperform previous approaches significantly."
            },
            "slug": "Going-Deeper-with-Embedded-FPGA-Platform-for-Neural-Qiu-Wang",
            "title": {
                "fragments": [],
                "text": "Going Deeper with Embedded FPGA Platform for Convolutional Neural Network"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents an in-depth analysis of state-of-the-art CNN models and shows that Convolutional layers are computational-centric and Fully-Connected layers are memory-centric, and proposes a CNN accelerator design on embedded FPGA for Image-Net large-scale image classification."
            },
            "venue": {
                "fragments": [],
                "text": "FPGA"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638694"
                        ],
                        "name": "Adam Coates",
                        "slug": "Adam-Coates",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Coates",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Coates"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2570381"
                        ],
                        "name": "Brody Huval",
                        "slug": "Brody-Huval",
                        "structuredName": {
                            "firstName": "Brody",
                            "lastName": "Huval",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brody Huval"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2156632012"
                        ],
                        "name": "Tao Wang",
                        "slug": "Tao-Wang",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "25629078"
                        ],
                        "name": "David J. Wu",
                        "slug": "David-J.-Wu",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Wu",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2301680"
                        ],
                        "name": "Bryan Catanzaro",
                        "slug": "Bryan-Catanzaro",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "Catanzaro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bryan Catanzaro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 149
                            }
                        ],
                        "text": "In recurrent neural network (RNN), M\u00d7V operations are performed on the new input and the hidden state at each time step, producing a new hidden state and the output."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8604637,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d1208ac421cf8ff67b27d93cd19ae42b8d596f95",
            "isKey": false,
            "numCitedBy": 679,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Scaling up deep learning algorithms has been shown to lead to increased performance in benchmark tasks and to enable discovery of complex high-level features. Recent efforts to train extremely large networks (with over 1 billion parameters) have relied on cloudlike computing infrastructure and thousands of CPU cores. In this paper, we present technical details and results from our own system based on Commodity Off-The-Shelf High Performance Computing (COTS HPC) technology: a cluster of GPU servers with Infiniband interconnects and MPI. Our system is able to train 1 billion parameter networks on just 3 machines in a couple of days, and we show that it can scale to networks with over 11 billion parameters using just 16 machines. As this infrastructure is much more easily marshaled by others, the approach enables much wider-spread research with extremely large neural networks."
            },
            "slug": "Deep-learning-with-COTS-HPC-systems-Coates-Huval",
            "title": {
                "fragments": [],
                "text": "Deep learning with COTS HPC systems"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper presents technical details and results from their own system based on Commodity Off-The-Shelf High Performance Computing (COTS HPC) technology: a cluster of GPU servers with Infiniband interconnects and MPI, and shows that it can scale to networks with over 11 billion parameters using just 16 machines."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111573067"
                        ],
                        "name": "Chen Zhang",
                        "slug": "Chen-Zhang",
                        "structuredName": {
                            "firstName": "Chen",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chen Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50492686"
                        ],
                        "name": "Peng Li",
                        "slug": "Peng-Li",
                        "structuredName": {
                            "firstName": "Peng",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peng Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695860"
                        ],
                        "name": "Guangyu Sun",
                        "slug": "Guangyu-Sun",
                        "structuredName": {
                            "firstName": "Guangyu",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guangyu Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2238828"
                        ],
                        "name": "Yijin Guan",
                        "slug": "Yijin-Guan",
                        "structuredName": {
                            "firstName": "Yijin",
                            "lastName": "Guan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yijin Guan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37525788"
                        ],
                        "name": "Bingjun Xiao",
                        "slug": "Bingjun-Xiao",
                        "structuredName": {
                            "firstName": "Bingjun",
                            "lastName": "Xiao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bingjun Xiao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2259796"
                        ],
                        "name": "J. Cong",
                        "slug": "J.-Cong",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Cong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": "Previous DNN accelerators targeting ASIC and FPGA platforms [10] [41] used mostly CONV layer as benchmarks, but have few dedicated experiments on FC layers, which has significant bandwidth bottlenecks, and is widely used in RNN and LSTMs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207220904,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c91eb0f9bbae8e2d3d007db73b8422b61ed1d68",
            "isKey": false,
            "numCitedBy": 1482,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional neural network (CNN) has been widely employed for image recognition because it can achieve high accuracy by emulating behavior of optic nerves in living creatures. Recently, rapid growth of modern applications based on deep learning algorithms has further improved research and implementations. Especially, various accelerators for deep CNN have been proposed based on FPGA platform because it has advantages of high performance, reconfigurability, and fast development round, etc. Although current FPGA accelerators have demonstrated better performance over generic processors, the accelerator design space has not been well exploited. One critical problem is that the computation throughput may not well match the memory bandwidth provided an FPGA platform. Consequently, existing approaches cannot achieve best performance due to under-utilization of either logic resource or memory bandwidth. At the same time, the increasing complexity and scalability of deep learning applications aggravate this problem. In order to overcome this problem, we propose an analytical design scheme using the roofline model. For any solution of a CNN design, we quantitatively analyze its computing throughput and required memory bandwidth using various optimization techniques, such as loop tiling and transformation. Then, with the help of rooine model, we can identify the solution with best performance and lowest FPGA resource requirement. As a case study, we implement a CNN accelerator on a VC707 FPGA board and compare it to previous approaches. Our implementation achieves a peak performance of 61.62 GFLOPS under 100MHz working frequency, which outperform previous approaches significantly."
            },
            "slug": "Optimizing-FPGA-based-Accelerator-Design-for-Deep-Zhang-Li",
            "title": {
                "fragments": [],
                "text": "Optimizing FPGA-based Accelerator Design for Deep Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This work implements a CNN accelerator on a VC707 FPGA board and compares it to previous approaches, achieving a peak performance of 61.62 GFLOPS under 100MHz working frequency, which outperform previous approaches significantly."
            },
            "venue": {
                "fragments": [],
                "text": "FPGA"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684785"
                        ],
                        "name": "J. Fowers",
                        "slug": "J.-Fowers",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Fowers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fowers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682478"
                        ],
                        "name": "Kalin Ovtcharov",
                        "slug": "Kalin-Ovtcharov",
                        "structuredName": {
                            "firstName": "Kalin",
                            "lastName": "Ovtcharov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kalin Ovtcharov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145033446"
                        ],
                        "name": "K. Strauss",
                        "slug": "K.-Strauss",
                        "structuredName": {
                            "firstName": "Karin",
                            "lastName": "Strauss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Strauss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49842903"
                        ],
                        "name": "Eric S. Chung",
                        "slug": "Eric-S.-Chung",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Chung",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric S. Chung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725786"
                        ],
                        "name": "G. Stitt",
                        "slug": "G.-Stitt",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Stitt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Stitt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[45] proposed a novel sparse matrix encoding and an FPGA-optimized architecture for SPMV."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17731011,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f98b448a62391d65ca93bd9603bf64b48bb94ed9",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Sparse matrix-vector multiplication (SMVM) is a crucial primitive used in a variety of scientific and commercial applications. Despite having significant parallelism, SMVM is a challenging kernel to optimize due to its irregular memory access characteristics. Numerous studies have proposed the use of FPGAs to accelerate SMVM implementations. However, most prior approaches focus on parallelizing multiply-accumulate operations within a single row of the matrix (which limits parallelism if rows are small) and/or make inefficient uses of the memory system when fetching matrix and vector elements. In this paper, we introduce an FPGA-optimized SMVM architecture and a novel sparse matrix encoding that explicitly exposes parallelism across rows, while keeping the hardware complexity and on-chip memory usage low. This system compares favorably with prior FPGA SMVM implementations. For the over 700 University of Florida sparse matrices we evaluated, it also performs within about two thirds of CPU SMVM performance on average, even though it has 2.4x lower DRAM memory bandwidth, and within almost one third of GPU SVMV performance on average, even at 9x lower memory bandwidth. Additionally, it consumes only 25W, for power efficiencies 2.6x and 2.3x higher than CPU and GPU, respectively, based on maximum device power."
            },
            "slug": "A-High-Memory-Bandwidth-FPGA-Accelerator-for-Sparse-Fowers-Ovtcharov",
            "title": {
                "fragments": [],
                "text": "A High Memory Bandwidth FPGA Accelerator for Sparse Matrix-Vector Multiplication"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper introduces an FPGA-optimized SMVM architecture and a novel sparse matrix encoding that explicitly exposes parallelism across rows, while keeping the hardware complexity and on-chip memory usage low."
            },
            "venue": {
                "fragments": [],
                "text": "2014 IEEE 22nd Annual International Symposium on Field-Programmable Custom Computing Machines"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3093886"
                        ],
                        "name": "Max Jaderberg",
                        "slug": "Max-Jaderberg",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Jaderberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Max Jaderberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687524"
                        ],
                        "name": "A. Vedaldi",
                        "slug": "A.-Vedaldi",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Vedaldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vedaldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[22] used rank-1 filters to approximate the original convolution kernels."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17864746,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "021fc345d40d3e6332cd2ef276e2eaa5e71102e4",
            "isKey": false,
            "numCitedBy": 1154,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "The focus of this paper is speeding up the application of convolutional neural networks. While delivering impressive results across a range of computer vision and machine learning tasks, these networks are computationally demanding, limiting their deployability. Convolutional layers generally consume the bulk of the processing time, and so in this work we present two simple schemes for drastically speeding up these layers. This is achieved by exploiting cross-channel or filter redundancy to construct a low rank basis of filters that are rank-1 in the spatial domain. Our methods are architecture agnostic, and can be easily applied to existing CPU and GPU convolutional frameworks for tuneable speedup performance. We demonstrate this with a real world network designed for scene text character recognition [15], showing a possible 2.5\u00d7 speedup with no loss in accuracy, and 4.5\u00d7 speedup with less than 1% drop in accuracy, still achieving state-of-the-art on standard benchmarks."
            },
            "slug": "Speeding-up-Convolutional-Neural-Networks-with-Low-Jaderberg-Vedaldi",
            "title": {
                "fragments": [],
                "text": "Speeding up Convolutional Neural Networks with Low Rank Expansions"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "Two simple schemes for drastically speeding up convolutional neural networks are presented, achieved by exploiting cross-channel or filter redundancy to construct a low rank basis of filters that are rank-1 in the spatial domain."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3346186"
                        ],
                        "name": "Forrest N. Iandola",
                        "slug": "Forrest-N.-Iandola",
                        "structuredName": {
                            "firstName": "Forrest",
                            "lastName": "Iandola",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Forrest N. Iandola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2318023"
                        ],
                        "name": "M. Moskewicz",
                        "slug": "M.-Moskewicz",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Moskewicz",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Moskewicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059241"
                        ],
                        "name": "Khalid Ashraf",
                        "slug": "Khalid-Ashraf",
                        "structuredName": {
                            "firstName": "Khalid",
                            "lastName": "Ashraf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Khalid Ashraf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143840275"
                        ],
                        "name": "Song Han",
                        "slug": "Song-Han",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80724002"
                        ],
                        "name": "W. Dally",
                        "slug": "W.-Dally",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dally",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dally"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732330"
                        ],
                        "name": "K. Keutzer",
                        "slug": "K.-Keutzer",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Keutzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Keutzer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14136028,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "969fbdcd0717bec06228053788c2ff78bbb4daac",
            "isKey": false,
            "numCitedBy": 4092,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet). \nThe SqueezeNet architecture is available for download here: this https URL"
            },
            "slug": "SqueezeNet:-AlexNet-level-accuracy-with-50x-fewer-Iandola-Moskewicz",
            "title": {
                "fragments": [],
                "text": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <1MB model size"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work proposes a small DNN architecture called SqueezeNet, which achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters and is able to compress to less than 0.5MB (510x smaller than AlexNet)."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1816922"
                        ],
                        "name": "R. Dorrance",
                        "slug": "R.-Dorrance",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Dorrance",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dorrance"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40615963"
                        ],
                        "name": "Fengbo Ren",
                        "slug": "Fengbo-Ren",
                        "structuredName": {
                            "firstName": "Fengbo",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fengbo Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144084004"
                        ],
                        "name": "D. Markovic",
                        "slug": "D.-Markovic",
                        "structuredName": {
                            "firstName": "Dejan",
                            "lastName": "Markovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Markovic"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Performing the indexing itself involves\n1\nbit manipulations to extract four-bit Iij and an extra load (which is almost assured a cache hit)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14606606,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b45945681e477c65d1cec5cf8cd73f06fedca4c",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Sparse Matrix-Vector Multiplication (SpMxV) is a widely used mathematical operation in many high-performance scientific and engineering applications. In recent years, tuned software libraries for multi-core microprocessors (CPUs) and graphics processing units (GPUs) have become the status quo for computing SpMxV. However, the computational throughput of these libraries for sparse matrices tends to be significantly lower than that of dense matrices, mostly due to the fact that the compression formats required to efficiently store sparse matrices mismatches traditional computing architectures. This paper describes an FPGA-based SpMxV kernel that is scalable to efficiently utilize the available memory bandwidth and computing resources. Benchmarking on a Virtex-5 SX95T FPGA demonstrates an average computational efficiency of 91.85%. The kernel achieves a peak computational efficiency of 99.8%, a >50x improvement over two Intel Core i7 processors (i7-2600 and i7-4770) and showing a >300x improvement over two NVIDA GPUs (GTX 660 and GTX Titan), when running the MKL and cuSPARSE sparse-BLAS libraries, respectively. In addition, the SpMxV FPGA kernel is able to achieve higher performance than its CPU and GPU counterparts, while using only 64 single-precision processing elements, with an overall 38-50x improvement in energy efficiency."
            },
            "slug": "A-scalable-sparse-matrix-vector-multiplication-for-Dorrance-Ren",
            "title": {
                "fragments": [],
                "text": "A scalable sparse matrix-vector multiplication kernel for energy-efficient sparse-blas on FPGAs"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper describes an FPGA-based SpMxV kernel that is scalable to efficiently utilize the available memory bandwidth and computing resources and is able to achieve higher performance than its CPU and GPU counterparts, while using only 64 single-precision processing elements."
            },
            "venue": {
                "fragments": [],
                "text": "FPGA"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256269"
                        ],
                        "name": "C. Farabet",
                        "slug": "C.-Farabet",
                        "structuredName": {
                            "firstName": "Cl\u00e9ment",
                            "lastName": "Farabet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Farabet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35130633"
                        ],
                        "name": "Cyril Poulet",
                        "slug": "Cyril-Poulet",
                        "structuredName": {
                            "firstName": "Cyril",
                            "lastName": "Poulet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cyril Poulet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2183554"
                        ],
                        "name": "Jefferson Y. Han",
                        "slug": "Jefferson-Y.-Han",
                        "structuredName": {
                            "firstName": "Jefferson",
                            "lastName": "Han",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jefferson Y. Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 163
                            }
                        ],
                        "text": "Efficient implementation of convolutional layers in CNN has been intensively studied, as its data reuse and manipulation is quite suitable for customized hardware [5, 6, 10, 12, 36]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5339694,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "07956c7cf9bf4267b86d52aa4143c17a4aa5d0d6",
            "isKey": false,
            "numCitedBy": 328,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional Networks (ConvNets) are biologicallyinspired hierarchical architectures that can be trained to perform a variety of detection, recognition and segmentation tasks. ConvNets have a feed-forward architecture consisting of multiple linear convolution filters interspersed with pointwise non-linear squashing functions. This paper presents an efficient implementation of ConvNets on a low-end DSPoriented Field Programmable Gate Array (FPGA). The implementation exploits the inherent parallelism of ConvNets and takes full advantage of multiple hardware multiplyaccumulate units on the FPGA. The entire system uses a single FPGA with an external memory module, and no extra parts. A network compiler software was implemented, which takes a description of a trained ConvNet and compiles it into a sequence of instructions for the ConvNet Processor (CNP). A ConvNet face detection system was implemented and tested. Face detection on a 512 \u00d7 384 frame takes 100ms (10 frames per second), which corresponds to an average performance of 3.4\u00d7109 connections per second for this 340 million connection network. The design can be used for low-power, lightweight embedded vision systems for micro-UAVs and other small robots."
            },
            "slug": "CNP:-An-FPGA-based-processor-for-Convolutional-Farabet-Poulet",
            "title": {
                "fragments": [],
                "text": "CNP: An FPGA-based processor for Convolutional Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The implementation exploits the inherent parallelism of ConvNets and takes full advantage of multiple hardware multiplyaccumulate units on the FPGA and can be used for low-power, lightweight embedded vision systems for micro-UAVs and other small robots."
            },
            "venue": {
                "fragments": [],
                "text": "2009 International Conference on Field Programmable Logic and Applications"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2837181"
                        ],
                        "name": "Ling Zhuo",
                        "slug": "Ling-Zhuo",
                        "structuredName": {
                            "firstName": "Ling",
                            "lastName": "Zhuo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ling Zhuo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728271"
                        ],
                        "name": "V. Prasanna",
                        "slug": "V.-Prasanna",
                        "structuredName": {
                            "firstName": "Viktor",
                            "lastName": "Prasanna",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Prasanna"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 266258,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a7a5f56868e83be1e566a255bdd8076b7d4b9f1a",
            "isKey": false,
            "numCitedBy": 234,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Floating-point Sparse Matrix-Vector Multiplication (SpMXV) is a key computational kernel in scientific and engineering applications. The poor data locality of sparse matrices significantly reduces the performance of SpMXV on general-purpose processors, which rely heavily on the cache hierarchy to achieve high performance. The abundant hardware resources on current FPGAs provide new opportunities to improve the performance of SpMXV. In this paper, we propose an FPGA-based design for SpMXV. Our design accepts sparse matrices in Compressed Row Storage format, and makes no assumptions about the sparsity structure of the input matrix. The design employs IEEE-754 format double-precision floating-point multipliers/adders, and performs multiple floating-point operations as well as I/O operations in parallel. The performance of our design for SpMXV is evaluated using various sparse matrices from the scientific computing community, with the Xilinx Virtex-II Pro XC2VP70 as the target device. The MFLOPS performance increases with the hardware resources on the device as well as the available memory bandwidth. For example, when the memory bandwidth is 8 GB/s, our design achieves over 350 MFLOPS for all the test matrices. It demonstrates significant speedup over general-purpose processors particularly for matrices with very irregular sparsity structure. Besides solving SpMXV problem, our design provides a parameterized and flexible tree-based design for floating-point applications on FPGAs."
            },
            "slug": "Sparse-Matrix-Vector-multiplication-on-FPGAs-Zhuo-Prasanna",
            "title": {
                "fragments": [],
                "text": "Sparse Matrix-Vector multiplication on FPGAs"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Besides solving SpMXV problem, the design provides a parameterized and flexible tree-based design for floating-point applications on FPGAs, which demonstrates significant speedup over general-purpose processors particularly for matrices with very irregular sparsity structure."
            },
            "venue": {
                "fragments": [],
                "text": "FPGA '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73175007"
                        ],
                        "name": "Andrew Lavin",
                        "slug": "Andrew-Lavin",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Lavin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Lavin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145565184"
                        ],
                        "name": "Scott Gray",
                        "slug": "Scott-Gray",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Gray",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott Gray"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "25\u00d7 multiplications than naive convolution [33], and for each Winograd patch the 16 M \u00d7 V can be scheduled on an EIE."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 962822,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5eadd6f059d742d76441fd0a635a21694dd7392",
            "isKey": false,
            "numCitedBy": 617,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep convolutional neural networks take GPU-days of computation to train on large data sets. Pedestrian detection for self driving cars requires very low latency. Image recognition for mobile phones is constrained by limited processing resources. The success of convolutional neural networks in these situations is limited by how fast we can compute them. Conventional FFT based convolution is fast for large filters, but state of the art convolutional neural networks use small, 3 3 filters. We introduce a new class of fast algorithms for convolutional neural networks using Winograd's minimal filtering algorithms. The algorithms compute minimal complexity convolution over small tiles, which makes them fast with small filters and small batch sizes. We benchmark a GPU implementation of our algorithm with the VGG network and show state of the art throughput at batch sizes from 1 to 64."
            },
            "slug": "Fast-Algorithms-for-Convolutional-Neural-Networks-Lavin-Gray",
            "title": {
                "fragments": [],
                "text": "Fast Algorithms for Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A new class of fast algorithms for convolutional neural networks is introduced using Winograd's minimal filtering algorithms, which compute minimal complexity convolution over small tiles, which makes them fast with small filters and small batch sizes."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771649"
                        ],
                        "name": "R. Vuduc",
                        "slug": "R.-Vuduc",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Vuduc",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Vuduc"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700326"
                        ],
                        "name": "J. Demmel",
                        "slug": "J.-Demmel",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Demmel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Demmel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 139
                            }
                        ],
                        "text": "To exploit the sparsity of activations we store our encoded sparse weight matrix W in a variation of compressed sparse column (CSC) format [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12459095,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92229143e62f1f8eecdd29920836851111b6bcce",
            "isKey": false,
            "numCitedBy": 281,
            "numCiting": 321,
            "paperAbstract": {
                "fragments": [],
                "text": "This dissertation presents an automated system to generate highly efficient, platform-adapted implementations of sparse matrix kernels. We show that conventional implementations of important sparse kernels like sparse matrix-vector multiply (SpMV) have historically run at 10% or less of peak machine speed on cache-based superscalar architectures. Our implementations of SpMV, automatically tuned using a methodology based on empirical-search, can by contrast achieve up to 31% of peak machine speed, and can be up to 4\u00d7 faster. \nGiven a matrix, kernel, and machine; our approach to selecting a fast implementation consists of two steps: (1)\u00a0we identify and generate a space of reasonable implementations, and then (2)\u00a0search this space for the fastest one using a combination of heuristic models and actual experiments (i.e., running and timing the code). We build on the SPARSITY system for generating highly-tuned implementations of the SpMV kernel y \u2190 y + Ax, where A is a sparse matrix and x, y are dense vectors. We extend SPARSITY to support tuning for a variety of common non-zero patterns arising in practice, and for additional kernels like sparse triangular solve (SpTS) and computation of ATA\u00b7x (or AAT\u00b7x) and A \u03c1\u00b7x. \nWe develop new models to compute, for particular data structures and kernels, the best absolute performance (e.g., Mflop/s) we might expect on a given matrix and machine. These performance upper bounds account for the cost of memory operations at all levels of the memory hierarchy, but assume ideal instruction scheduling and low-level tuning. We evaluate our performance with respect to such bounds, finding that the generated and tuned implementations of SpMV and SpTS achieve up to 75% of the performance bound. This finding places limits on the effectiveness of additional low-level tuning (e.g., better instruction selection and scheduling). (Abstract shortened by UMI.)"
            },
            "slug": "Automatic-performance-tuning-of-sparse-matrix-Vuduc-Demmel",
            "title": {
                "fragments": [],
                "text": "Automatic performance tuning of sparse matrix kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "An automated system to generate highly efficient, platform-adapted implementations of sparse matrix kernels, and extends SPARSITY to support tuning for a variety of common non-zero patterns arising in practice, and for additional kernels like sparse triangular solve (SpTS) and computation of ATA\u00b7x and A \u03c1\u00b7x."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39978391"
                        ],
                        "name": "Yangqing Jia",
                        "slug": "Yangqing-Jia",
                        "structuredName": {
                            "firstName": "Yangqing",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yangqing Jia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782282"
                        ],
                        "name": "Evan Shelhamer",
                        "slug": "Evan-Shelhamer",
                        "structuredName": {
                            "firstName": "Evan",
                            "lastName": "Shelhamer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Evan Shelhamer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7408951"
                        ],
                        "name": "Jeff Donahue",
                        "slug": "Jeff-Donahue",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Donahue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeff Donahue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3049736"
                        ],
                        "name": "Sergey Karayev",
                        "slug": "Sergey-Karayev",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Karayev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sergey Karayev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117314646"
                        ],
                        "name": "Jonathan Long",
                        "slug": "Jonathan-Long",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Long",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Long"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2983898"
                        ],
                        "name": "Ross B. Girshick",
                        "slug": "Ross-B.-Girshick",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Girshick",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross B. Girshick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687120"
                        ],
                        "name": "S. Guadarrama",
                        "slug": "S.-Guadarrama",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Guadarrama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Guadarrama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 47
                            }
                        ],
                        "text": "We use the Image-Net dataset [8] and the Caffe [24] deep learning framework as golden model to verify the correctness of the hardware design."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 42
                            }
                        ],
                        "text": "We use the Image-Net dataset [29] and the Caffe [28] deep learning framework as golden model to verify the correctness of the hardware design."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 44
                            }
                        ],
                        "text": "The uncompressed DNN model is obtained from Caffe model zoo [28] and NeuralTalk model zoo [7]; The compressed DNN model is produced as described\nin [16], [23]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1799558,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6bdb186ec4726e00a8051119636d4df3b94043b5",
            "isKey": false,
            "numCitedBy": 13814,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments. Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community of contributors on GitHub. It powers ongoing research projects, large-scale industrial applications, and startup prototypes in vision, speech, and multimedia."
            },
            "slug": "Caffe:-Convolutional-Architecture-for-Fast-Feature-Jia-Shelhamer",
            "title": {
                "fragments": [],
                "text": "Caffe: Convolutional Architecture for Fast Feature Embedding"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Multimedia"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40081727"
                        ],
                        "name": "Emily L. Denton",
                        "slug": "Emily-L.-Denton",
                        "structuredName": {
                            "firstName": "Emily",
                            "lastName": "Denton",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Emily L. Denton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2563432"
                        ],
                        "name": "Wojciech Zaremba",
                        "slug": "Wojciech-Zaremba",
                        "structuredName": {
                            "firstName": "Wojciech",
                            "lastName": "Zaremba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wojciech Zaremba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143627859"
                        ],
                        "name": "Joan Bruna",
                        "slug": "Joan-Bruna",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Bruna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joan Bruna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7340116,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e5ae8ab688051931b4814f6d32b18391f8d1fa8d",
            "isKey": false,
            "numCitedBy": 1281,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We present techniques for speeding up the test-time evaluation of large convolutional networks, designed for object recognition tasks. These models deliver impressive accuracy, but each image evaluation requires millions of floating point operations, making their deployment on smartphones and Internet-scale clusters problematic. The computation is dominated by the convolution operations in the lower layers of the model. We exploit the redundancy present within the convolutional filters to derive approximations that significantly reduce the required computation. Using large state-of-the-art models, we demonstrate speedups of convolutional layers on both CPU and GPU by a factor of 2 x, while keeping the accuracy within 1% of the original model."
            },
            "slug": "Exploiting-Linear-Structure-Within-Convolutional-Denton-Zaremba",
            "title": {
                "fragments": [],
                "text": "Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Using large state-of-the-art models, this work demonstrates speedups of convolutional layers on both CPU and GPU by a factor of 2 x, while keeping the accuracy within 1% of the original model."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145326994"
                        ],
                        "name": "Nathan Bell",
                        "slug": "Nathan-Bell",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Bell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nathan Bell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144764367"
                        ],
                        "name": "M. Garland",
                        "slug": "M.-Garland",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Garland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Garland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14531936,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1cd294f3bcd647c8a2b2bbce47e827a8ece8b973",
            "isKey": false,
            "numCitedBy": 809,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Sparse matrix-vector multiplication (SpMV) is of singular importance in sparse linear algebra. In contrast to the uniform regularity of dense linear algebra, sparse operations encounter a broad spectrum of matrices ranging from the regular to the highly irregular. Harnessing the tremendous potential of throughput-oriented processors for sparse operations requires that we expose substantial fine-grained parallelism and impose sufficient regularity on execution paths and memory access patterns. We explore SpMV methods that are well-suited to throughput-oriented architectures like the GPU and which exploit several common sparsity classes. The techniques we propose are efficient, successfully utilizing large percentages of peak bandwidth. Furthermore, they deliver excellent total throughput, averaging 16 GFLOP/s and 10 GFLOP/s in double precision for structured grid and unstructured mesh matrices, respectively, on a GeForce GTX 285. This is roughly 2.8 times the throughput previously achieved on Cell BE and more than 10 times that of a quad-core Intel Clovertown system."
            },
            "slug": "Implementing-sparse-matrix-vector-multiplication-on-Bell-Garland",
            "title": {
                "fragments": [],
                "text": "Implementing sparse matrix-vector multiplication on throughput-oriented processors"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work explores SpMV methods that are well-suited to throughput-oriented architectures like the GPU and which exploit several common sparsity classes, including structured grid and unstructured mesh matrices."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Conference on High Performance Computing Networking, Storage and Analysis"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145326994"
                        ],
                        "name": "Nathan Bell",
                        "slug": "Nathan-Bell",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Bell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nathan Bell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144764367"
                        ],
                        "name": "M. Garland",
                        "slug": "M.-Garland",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Garland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Garland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[43] implemented data structures and algorithms for SPMV on GeForce GTX 280 GPU and achieved perfor-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11725419,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8834b05b3925e0f53b8a8b1924e89b9cde04b7d",
            "isKey": false,
            "numCitedBy": 790,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "The massive parallelism of graphics processing units (GPUs) oers tremendous performance in many high-performance computing applications. While dense linear algebra readily maps to such platforms, harnessing this potential for sparse matrix computations presents additional challenges. Given its role in iterative methods for solving sparse linear systems and eigenvalue problems, sparse matrix-vector multiplication (SpMV) is of singular importance in sparse linear algebra. In this paper we discuss data structures and algorithms for SpMV that are eciently implemented on the CUDA platform for the ne-grained parallel architecture of the GPU. Given the memory-bound nature of SpMV, we emphasize memory bandwidth eciency and compact storage formats. We consider a broad spectrum of sparse matrices, from those that are well-structured and regular to highly irregular matrices with large imbalances in the distribution of nonzeros per matrix row. We develop methods to exploit several common forms of matrix structure while oering alternatives which accommodate greater irregularity. On structured, grid-based matrices we achieve performance of 36 GFLOP/s in single precision and 16 GFLOP/s in double precision on a GeForce GTX 280 GPU. For unstructured nite-element matrices, we observe performance in excess of 15 GFLOP/s and 10 GFLOP/s in single and double precision respectively. These results compare favorably to prior state-of-the-art studies of SpMV methods on conventional multicore processors. Our double precision SpMV performance is generally two and a half times that of a Cell BE with 8 SPEs and more than ten times greater than that of a quad-core Intel Clovertown system."
            },
            "slug": "Ecient-Sparse-Matrix-Vector-Multiplication-on-CUDA-Bell-Garland",
            "title": {
                "fragments": [],
                "text": "Ecient Sparse Matrix-Vector Multiplication on CUDA"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Data structures and algorithms for SpMV that are eciently implemented on the CUDA platform for the ne-grained parallel architecture of the GPU and develop methods to exploit several common forms of matrix structure while oering alternatives which accommodate greater irregularity are developed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 81
                            }
                        ],
                        "text": "Matrix-vector multiplication (M\u00d7V) is a basic building block in a wide range of neural networks and deep learning applications."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 277,
                                "start": 274
                            }
                        ],
                        "text": "A FC layer of a DNN performs the computation\nb = f(Wa+ v) (1)\nWhere a is the input activation vector, b is the output activation vector, v is the bias, W is the weight matrix, and f is the non-linear function, typically the Rectified Linear Unit(ReLU) [22] in CNN and some RNN."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 195908774,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "isKey": false,
            "numCitedBy": 82046,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry."
            },
            "slug": "ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever",
            "title": {
                "fragments": [],
                "text": "ImageNet classification with deep convolutional neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A large, deep convolutional neural network was trained to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes and employed a recently developed regularization method called \"dropout\" that proved to be very effective."
            },
            "venue": {
                "fragments": [],
                "text": "Commun. ACM"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2574060"
                        ],
                        "name": "Christian Szegedy",
                        "slug": "Christian-Szegedy",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Szegedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Szegedy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157222093"
                        ],
                        "name": "Wei Liu",
                        "slug": "Wei-Liu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39978391"
                        ],
                        "name": "Yangqing Jia",
                        "slug": "Yangqing-Jia",
                        "structuredName": {
                            "firstName": "Yangqing",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yangqing Jia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3142556"
                        ],
                        "name": "Pierre Sermanet",
                        "slug": "Pierre-Sermanet",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Sermanet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierre Sermanet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144828948"
                        ],
                        "name": "Scott E. Reed",
                        "slug": "Scott-E.-Reed",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Reed",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott E. Reed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1838674"
                        ],
                        "name": "Dragomir Anguelov",
                        "slug": "Dragomir-Anguelov",
                        "structuredName": {
                            "firstName": "Dragomir",
                            "lastName": "Anguelov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dragomir Anguelov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761978"
                        ],
                        "name": "D. Erhan",
                        "slug": "D.-Erhan",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Erhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Erhan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2657155"
                        ],
                        "name": "Vincent Vanhoucke",
                        "slug": "Vincent-Vanhoucke",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Vanhoucke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Vanhoucke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39863668"
                        ],
                        "name": "Andrew Rabinovich",
                        "slug": "Andrew-Rabinovich",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Rabinovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Rabinovich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "EIE: Efficient Inference Engine on Compressed Deep Neural Network\nSong Han\u2217 Xingyu Liu\u2217 Huizi Mao\u2217 Jing Pu\u2217 Ardavan Pedram\u2217\nMark A. Horowitz\u2217 William J. Dally\u2217\u2020 \u2217Stanford University, \u2020NVIDIA\n{songhan,xyl,huizi,jingpu,perdavan,horowitz,dally}@stanford.edu\nAbstract\u2014State-of-the-art deep neural\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 35
                            }
                        ],
                        "text": "EIE: Efficient Inference Engine on Compressed Deep Neural Network\nSong Han\u2217 Xingyu Liu\u2217 Huizi Mao\u2217 Jing Pu\u2217 Ardavan Pedram\u2217\nMark A. Horowitz\u2217 William J. Dally\u2217\u2020 \u2217Stanford University, \u2020NVIDIA\n{songhan,xyl,huizi,jingpu,perdavan,horowitz,dally}@stanford.edu\nAbstract\u2014State-of-the-art deep neural networks (DNNs) have hundreds of millions of connections and are both computationally and memory intensive, making them difficult to deploy on embedded systems with limited hardware resources and power budgets."
                    },
                    "intents": []
                }
            ],
            "corpusId": 206592484,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e15cf50aa89fee8535703b9f9512fca5bfc43327",
            "isKey": false,
            "numCitedBy": 29917,
            "numCiting": 278,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection."
            },
            "slug": "Going-deeper-with-convolutions-Szegedy-Liu",
            "title": {
                "fragments": [],
                "text": "Going deeper with convolutions"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "A deep convolutional neural network architecture codenamed Inception is proposed that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14)."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 93
                            }
                        ],
                        "text": "RNN, including LSTM, is widely applied in speech recognition and natural language processing [31, 39, 2]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7961699,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cea967b59209c6be22829699f05b8b1ac4dc092d",
            "isKey": false,
            "numCitedBy": 15043,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT-14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous state of the art. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier."
            },
            "slug": "Sequence-to-Sequence-Learning-with-Neural-Networks-Sutskever-Vinyals",
            "title": {
                "fragments": [],
                "text": "Sequence to Sequence Learning with Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure, and finds that reversing the order of the words in all source sentences improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771551"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47114430"
                        ],
                        "name": "Jianhua Zou",
                        "slug": "Jianhua-Zou",
                        "structuredName": {
                            "firstName": "Jianhua",
                            "lastName": "Zou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianhua Zou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2063107548"
                        ],
                        "name": "Xiang Ming",
                        "slug": "Xiang-Ming",
                        "structuredName": {
                            "firstName": "Xiang",
                            "lastName": "Ming",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiang Ming"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "SVD is frequently used to reduce model size [37] [38]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1437449,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b64601d509711468f5d085261d463846f36785b2",
            "isKey": false,
            "numCitedBy": 216,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper aims to accelerate the test-time computation of deep convolutional neural networks (CNNs). Unlike existing methods that are designed for approximating linear filters or linear responses, our method takes the nonlinear units into account. We minimize the reconstruction error of the nonlinear responses, subject to a low-rank constraint which helps to reduce the complexity of filters. We develop an effective solution to this constrained nonlinear optimization problem. An algorithm is also presented for reducing the accumulated error when multiple layers are approximated. A whole-model speedup ratio of 4\u00d7 is demonstrated on a large network trained for ImageNet, while the top-5 error rate is only increased by 0.9%. Our accelerated model has a comparably fast speed as the \u201cAlexNet\u201d [11], but is 4.7% more accurate."
            },
            "slug": "Efficient-and-accurate-approximations-of-nonlinear-Zhang-Zou",
            "title": {
                "fragments": [],
                "text": "Efficient and accurate approximations of nonlinear convolutional networks"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This paper aims to accelerate the test-time computation of deep convolutional neural networks (CNNs), and takes the nonlinear units into account, subject to a low-rank constraint which helps to reduce the complexity of filters."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2358911"
                        ],
                        "name": "N. Muralimanohar",
                        "slug": "N.-Muralimanohar",
                        "structuredName": {
                            "firstName": "Naveen",
                            "lastName": "Muralimanohar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Muralimanohar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777422"
                        ],
                        "name": "R. Balasubramonian",
                        "slug": "R.-Balasubramonian",
                        "structuredName": {
                            "firstName": "Rajeev",
                            "lastName": "Balasubramonian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Balasubramonian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715454"
                        ],
                        "name": "N. Jouppi",
                        "slug": "N.-Jouppi",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Jouppi",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Jouppi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14245854,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3364bc50921a9566d61ef8cb73baa82341725e4b",
            "isKey": false,
            "numCitedBy": 787,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "\u00a9 CACTI 6.0: A Tool to Model Large Caches Naveen Muralimanohar, Rajeev Balasubramonian, Norman P. Jouppi HP Laboratories HPL-2009-85 No keywords available. Future processors will likely have large on-chip caches with a possibility of dedicating an entire die for on-chip storage in a 3D stacked design. With the ever growing disparity between transistor and wire delay, the properties of such large caches will primarily depend on the characteristics of the interconnection networks that connect various sub-modules of a cache. CACTI 6.0 is a significantly enhanced version of the tool that primarily focuses on interconnect design for large caches. In addition to strengthening the existing analytical model of the tool for dominant cache components, CACTI 6.0 includes two major extensions over earlier versions: first, the ability to model Non-Uniform Cache Access (NUCA), and second, the ability to model different types of wires, such as RC based wires with different power, delay, and area characteristics and differential low-swing buses. This report details the analytical model assumed for the newly added modules along with their validation analysis. External Posting Date: April 21, 2009 [Fulltext] Approved for External Publication Internal Posting Date: April 21, 2009 [Fulltext] Published in International Symposium on Microarchitecture, Chicago, Dec 2007. Copyright International Symposium on Microarchitecture, 2007. CACTI 6.0: A Tool to Model Large Caches Naveen Muralimanohar, Rajeev Balasubramonian, Norman P. Jouppi \u2020 School of Computing, University of Utah \u2021 Hewlett-Packard Laboratories Abstract Future processors will likely have large on-chip caches with a possibility of dedicating an entire die for on-chip storage in a 3D stacked design. With the ever growing disparity between transistor and wire delay, the properties of such large caches will primarily depend on the characteristics of the interconnection networks that connect various sub-modules of a cache. CACTI 6.0 is a significantly enhanced version of the tool that primarily focuses on interconnect design for large caches. In addition to strengthening the existing analytical model of the tool for dominant cache components, CACTI 6.0 includes two major extensions over earlier versions: first, the ability to model Non-Uniform Cache Access (NUCA), and second, the ability to model different types of wires, such as RC based wires with different power, delay, and area characteristics and differential low-swing buses. This report details the analytical model assumed for the newly added modules along with their validation analysis.Future processors will likely have large on-chip caches with a possibility of dedicating an entire die for on-chip storage in a 3D stacked design. With the ever growing disparity between transistor and wire delay, the properties of such large caches will primarily depend on the characteristics of the interconnection networks that connect various sub-modules of a cache. CACTI 6.0 is a significantly enhanced version of the tool that primarily focuses on interconnect design for large caches. In addition to strengthening the existing analytical model of the tool for dominant cache components, CACTI 6.0 includes two major extensions over earlier versions: first, the ability to model Non-Uniform Cache Access (NUCA), and second, the ability to model different types of wires, such as RC based wires with different power, delay, and area characteristics and differential low-swing buses. This report details the analytical model assumed for the newly added modules along with their validation analysis."
            },
            "slug": "CACTI-6.0:-A-Tool-to-Model-Large-Caches-Muralimanohar-Balasubramonian",
            "title": {
                "fragments": [],
                "text": "CACTI 6.0: A Tool to Model Large Caches"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "This report details the analytical model assumed for the newly added modules along with their validation analysis of CACTI 6.0, a significantly enhanced version of the tool that primarily focuses on interconnect design for large caches."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144948031"
                        ],
                        "name": "N. Lane",
                        "slug": "N.-Lane",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Lane",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Lane"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737522"
                        ],
                        "name": "Petko Georgiev",
                        "slug": "Petko-Georgiev",
                        "structuredName": {
                            "firstName": "Petko",
                            "lastName": "Georgiev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Petko Georgiev"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8553730,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6c20cd584e7258056840eb88437d69731000bb0f",
            "isKey": false,
            "numCitedBy": 232,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Sensor-equipped smartphones and wearables are transforming a variety of mobile apps ranging from health monitoring to digital assistants. However, reliably inferring user behavior and context from noisy and complex sensor data collected under mobile device constraints remains an open problem, and a key bottleneck to sensor app development. In recent years, advances in the field of deep learning have resulted in nearly unprecedented gains in related inference tasks such as speech and object recognition. However, although mobile sensing shares many of the same data modeling challenges, we have yet to see deep learning be systematically studied within the sensing domain. If deep learning could lead to significantly more robust and efficient mobile sensor inference it would revolutionize the field by rapidly expanding the number of sensor apps ready for mainstream usage. In this paper, we provide preliminary answers to this potentially game-changing question by prototyping a low-power Deep Neural Network (DNN) inference engine that exploits both the CPU and DSP of a mobile device SoC. We use this engine to study typical mobile sensing tasks (e.g., activity recognition) using DNNs, and compare results to learning techniques in more common usage. Our early findings provide illustrative examples of DNN usage that do not overburden modern mobile hardware, while also indicating how they can improve inference accuracy. Moreover, we show DNNs can gracefully scale to larger numbers of inference classes and can be flexibly partitioned across mobile and remote resources. Collectively, these results highlight the critical need for further exploration as to how the field of mobile sensing can best make use of advances in deep learning towards robust and efficient sensor inference."
            },
            "slug": "Can-Deep-Learning-Revolutionize-Mobile-Sensing-Lane-Georgiev",
            "title": {
                "fragments": [],
                "text": "Can Deep Learning Revolutionize Mobile Sensing?"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Preliminary answers to how the field of mobile sensing can best make use of advances in deep learning towards robust and efficient sensor inference are provided by prototyping a low-power Deep Neural Network inference engine that exploits both the CPU and DSP of a mobile device SoC."
            },
            "venue": {
                "fragments": [],
                "text": "HotMobile"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308557"
                        ],
                        "name": "S. Hochreiter",
                        "slug": "S.-Hochreiter",
                        "structuredName": {
                            "firstName": "Sepp",
                            "lastName": "Hochreiter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hochreiter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "Weights are represented as singleprecision floating-point numbers so such a layer requires 64MB of storage."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1915014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44d2abe2175df8153f465f6c39b68b76a0d40ab9",
            "isKey": false,
            "numCitedBy": 52390,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms."
            },
            "slug": "Long-Short-Term-Memory-Hochreiter-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Long Short-Term Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel, efficient, gradient based method called long short-term memory (LSTM) is introduced, which can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21151596"
                        ],
                        "name": "A. Monakov",
                        "slug": "A.-Monakov",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Monakov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Monakov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777324"
                        ],
                        "name": "Anton Lokhmotov",
                        "slug": "Anton-Lokhmotov",
                        "structuredName": {
                            "firstName": "Anton",
                            "lastName": "Lokhmotov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anton Lokhmotov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145481477"
                        ],
                        "name": "A. Avetisyan",
                        "slug": "A.-Avetisyan",
                        "structuredName": {
                            "firstName": "Arutyun",
                            "lastName": "Avetisyan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Avetisyan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[42] proposed a matrix storage format that improves locality, which has low memory footprint and enables automatic parameter tuning on GPU."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206743611,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce8190de5cac2b583667079502c130888783303f",
            "isKey": false,
            "numCitedBy": 250,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Graphics processors are increasingly used in scientific applications due to their high computational power, which comes from hardware with multiple-level parallelism and memory hierarchy. Sparse matrix computations frequently arise in scientific applications, for example, when solving PDEs on unstructured grids. However, traditional sparse matrix algorithms are difficult to efficiently parallelize for GPUs due to irregular patterns of memory references. In this paper we present a new storage format for sparse matrices that better employs locality, has low memory footprint and enables automatic specialization for various matrices and future devices via parameter tuning. Experimental evaluation demonstrates significant speedups compared to previously published results."
            },
            "slug": "Automatically-Tuning-Sparse-Matrix-Vector-for-GPU-Monakov-Lokhmotov",
            "title": {
                "fragments": [],
                "text": "Automatically Tuning Sparse Matrix-Vector Multiplication for GPU Architectures"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new storage format for sparse matrices is presented that better employs locality, has low memory footprint and enables automatic specialization for various matrices and future devices via parameter tuning."
            },
            "venue": {
                "fragments": [],
                "text": "HiPEAC"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34838386"
                        ],
                        "name": "K. Simonyan",
                        "slug": "K.-Simonyan",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Simonyan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Simonyan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14124313,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb42cf88027de515750f230b23b1a057dc782108",
            "isKey": false,
            "numCitedBy": 63195,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision."
            },
            "slug": "Very-Deep-Convolutional-Networks-for-Large-Scale-Simonyan-Zisserman",
            "title": {
                "fragments": [],
                "text": "Very Deep Convolutional Networks for Large-Scale Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This work investigates the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting using an architecture with very small convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736279"
                        ],
                        "name": "B. Hassibi",
                        "slug": "B.-Hassibi",
                        "structuredName": {
                            "firstName": "Babak",
                            "lastName": "Hassibi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Hassibi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2586918"
                        ],
                        "name": "D. Stork",
                        "slug": "D.-Stork",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Stork",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Stork"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In early work, network pruning proved to be a promising approach to reducing the network complexity and over-fitting [34]\u2013[36]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7057040,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a42954d4b9d0ccdf1036e0af46d87a01b94c3516",
            "isKey": false,
            "numCitedBy": 1594,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the use of information from all second order derivatives of the error function to perform network pruning (i.e., removing unimportant weights from a trained network) in order to improve generalization, simplify networks, reduce hardware or storage requirements, increase the speed of further training, and in some cases enable rule extraction. Our method, Optimal Brain Surgeon (OBS), is Significantly better than magnitude-based methods and Optimal Brain Damage [Le Cun, Denker and Solla, 1990], which often remove the wrong weights. OBS permits the pruning of more weights than other methods (for the same error on the training set), and thus yields better generalization on test data. Crucial to OBS is a recursion relation for calculating the inverse Hessian matrix H-1 from training data and structural information of the net. OBS permits a 90%, a 76%, and a 62% reduction in weights over backpropagation with weight decay on three benchmark MONK's problems [Thrun et al., 1991]. Of OBS, Optimal Brain Damage, and magnitude-based methods, only OBS deletes the correct weights from a trained XOR network in every case. Finally, whereas Sejnowski and Rosenberg [1987] used 18,000 weights in their NETtalk network, we used OBS to prune a network to just 1560 weights, yielding better generalization."
            },
            "slug": "Second-Order-Derivatives-for-Network-Pruning:-Brain-Hassibi-Stork",
            "title": {
                "fragments": [],
                "text": "Second Order Derivatives for Network Pruning: Optimal Brain Surgeon"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Of OBS, Optimal Brain Damage, and magnitude-based methods, only OBS deletes the correct weights from a trained XOR network in every case, and thus yields better generalization on test data."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2245567"
                        ],
                        "name": "M. Karafi\u00e1t",
                        "slug": "M.-Karafi\u00e1t",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Karafi\u00e1t",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Karafi\u00e1t"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1816892"
                        ],
                        "name": "L. Burget",
                        "slug": "L.-Burget",
                        "structuredName": {
                            "firstName": "Luk\u00e1\u0161",
                            "lastName": "Burget",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Burget"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1899242"
                        ],
                        "name": "J. Cernock\u00fd",
                        "slug": "J.-Cernock\u00fd",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Cernock\u00fd",
                            "middleNames": [
                                "Honza"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cernock\u00fd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2803071"
                        ],
                        "name": "S. Khudanpur",
                        "slug": "S.-Khudanpur",
                        "structuredName": {
                            "firstName": "Sanjeev",
                            "lastName": "Khudanpur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Khudanpur"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 109
                            }
                        ],
                        "text": "Matrix-vector multiplication (M\u00d7V) is a basic building block in a wide range of neural networks and deep learning applications."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 73
                            }
                        ],
                        "text": "Pruning makes matrix W sparse with density D ranging from 4% to 25% for our benchmark layers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17048224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9819b600a828a57e1cde047bbe710d3446b30da5",
            "isKey": false,
            "numCitedBy": 4935,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "A new recurrent neural network based language model (RNN LM) with applications to speech recognition is presented. Results indicate that it is possible to obtain around 50% reduction of perplexity by using mixture of several RNN LMs, compared to a state of the art backoff language model. Speech recognition experiments show around 18% reduction of word error rate on the Wall Street Journal task when comparing models trained on the same amount of data, and around 5% on the much harder NIST RT05 task, even when the backoff model is trained on much more data than the RNN LM. We provide ample empirical evidence to suggest that connectionist language models are superior to standard n-gram techniques, except their high computational (training) complexity. Index Terms: language modeling, recurrent neural networks, speech recognition"
            },
            "slug": "Recurrent-neural-network-based-language-model-Mikolov-Karafi\u00e1t",
            "title": {
                "fragments": [],
                "text": "Recurrent neural network based language model"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Results indicate that it is possible to obtain around 50% reduction of perplexity by using mixture of several RNN LMs, compared to a state of the art backoff language model."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2983898"
                        ],
                        "name": "Ross B. Girshick",
                        "slug": "Ross-B.-Girshick",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Girshick",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross B. Girshick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Sometimes v will be combined with W by appending an additional one to vector a, therefore we neglect the bias in the following paragraphs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206770307,
            "fieldsOfStudy": [
                "Computer Science",
                "Environmental Science"
            ],
            "id": "7ffdbc358b63378f07311e883dddacc9faeeaf4b",
            "isKey": false,
            "numCitedBy": 14349,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a Fast Region-based Convolutional Network method (Fast R-CNN) for object detection. Fast R-CNN builds on previous work to efficiently classify object proposals using deep convolutional networks. Compared to previous work, Fast R-CNN employs several innovations to improve training and testing speed while also increasing detection accuracy. Fast R-CNN trains the very deep VGG16 network 9x faster than R-CNN, is 213x faster at test-time, and achieves a higher mAP on PASCAL VOC 2012. Compared to SPPnet, Fast R-CNN trains VGG16 3x faster, tests 10x faster, and is more accurate. Fast R-CNN is implemented in Python and C++ (using Caffe) and is available under the open-source MIT License at https://github.com/rbgirshick/fast-rcnn."
            },
            "slug": "Fast-R-CNN-Girshick",
            "title": {
                "fragments": [],
                "text": "Fast R-CNN"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This paper proposes a Fast Region-based Convolutional Network method (Fast R-CNN) for object detection that builds on previous work to efficiently classify object proposals using deep convolutional networks."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE International Conference on Computer Vision (ICCV)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3335364"
                        ],
                        "name": "Dzmitry Bahdanau",
                        "slug": "Dzmitry-Bahdanau",
                        "structuredName": {
                            "firstName": "Dzmitry",
                            "lastName": "Bahdanau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dzmitry Bahdanau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1979489"
                        ],
                        "name": "Kyunghyun Cho",
                        "slug": "Kyunghyun-Cho",
                        "structuredName": {
                            "firstName": "Kyunghyun",
                            "lastName": "Cho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyunghyun Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 93
                            }
                        ],
                        "text": "RNN, including LSTM, is widely applied in speech recognition and natural language processing [31, 39, 2]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11212020,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5",
            "isKey": false,
            "numCitedBy": 19562,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition."
            },
            "slug": "Neural-Machine-Translation-by-Jointly-Learning-to-Bahdanau-Cho",
            "title": {
                "fragments": [],
                "text": "Neural Machine Translation by Jointly Learning to Align and Translate"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and it is proposed to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 104
                            }
                        ],
                        "text": "In convolutional neural network (CNN), fully connected layers are implemented with M\u00d7V, and more than 96% of the connections are in the FC layers [1]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": false,
            "numCitedBy": 35623,
            "numCiting": 246,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2354728"
                        ],
                        "name": "A. Karpathy",
                        "slug": "A.-Karpathy",
                        "structuredName": {
                            "firstName": "Andrej",
                            "lastName": "Karpathy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Karpathy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 12
                            }
                        ],
                        "text": "Pruning makes matrix W sparse with density D ranging from 4% to 25% for our benchmark layers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 115
                            }
                        ],
                        "text": "In object detection algorithms, an FC layer is required to run multiple times on all proposal regions, taking up to 38% computation time [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8517067,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "55e022fb7581bb9e1fce678d21fb25ffbb3fbb88",
            "isKey": false,
            "numCitedBy": 2718,
            "numCiting": 103,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a model that generates natural language descriptions of images and their regions. Our approach leverages datasets of images and their sentence descriptions to learn about the inter-modal correspondences between language and visual data. Our alignment model is based on a novel combination of Convolutional Neural Networks over image regions, bidirectional Recurrent Neural Networks (RNN) over sentences, and a structured objective that aligns the two modalities through a multimodal embedding. We then describe a Multimodal Recurrent Neural Network architecture that uses the inferred alignments to learn to generate novel descriptions of image regions. We demonstrate that our alignment model produces state of the art results in retrieval experiments on Flickr8K, Flickr30K and MSCOCO datasets. We then show that the generated descriptions outperform retrieval baselines on both full images and on a new dataset of region-level annotations. Finally, we conduct large-scale analysis of our RNN language model on the Visual Genome dataset of 4.1 million captions and highlight the differences between image and region-level caption statistics."
            },
            "slug": "Deep-Visual-Semantic-Alignments-for-Generating-Karpathy-Fei-Fei",
            "title": {
                "fragments": [],
                "text": "Deep Visual-Semantic Alignments for Generating Image Descriptions"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A model that generates natural language descriptions of images and their regions based on a novel combination of Convolutional Neural Networks over image regions, bidirectional Recurrent Neural networks over sentences, and a structured objective that aligns the two modalities through a multimodal embedding is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727849"
                        ],
                        "name": "S. Hanson",
                        "slug": "S.-Hanson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Hanson",
                            "middleNames": [
                                "Jose"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hanson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144442133"
                        ],
                        "name": "L. Pratt",
                        "slug": "L.-Pratt",
                        "structuredName": {
                            "firstName": "Lorien",
                            "lastName": "Pratt",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Pratt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 117
                            }
                        ],
                        "text": "In early work, network pruning proved to be a promising approach to reducing the network complexity and over-fitting [34]\u2013[36]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9344018,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4ea5a6ff3ffcd11ec2e6ed7828a7d41279fb3ad",
            "isKey": false,
            "numCitedBy": 518,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Rumelhart (1987), has proposed a method for choosing minimal or \"simple\" representations during learning in Back-propagation networks. This approach can be used to (a) dynamically select the number of hidden units, (b) construct a representation that is appropriate for the problem and (c) thus improve the generalization ability of Back-propagation networks. The method Rumelhart suggests involves adding penalty terms to the usual error function. In this paper we introduce Rumelhart's minimal networks idea and compare two possible biases on the weight search space. These biases are compared in both simple counting problems and a speech recognition problem. In general, the constrained search does seem to minimize the number of hidden units required with an expected increase in local minima."
            },
            "slug": "Comparing-Biases-for-Minimal-Network-Construction-Hanson-Pratt",
            "title": {
                "fragments": [],
                "text": "Comparing Biases for Minimal Network Construction with Back-Propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper introduces Rumelhart's minimal networks idea and compares two possible biases on the weight search space that are compared in both simple counting problems and a speech recognition problem."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2188620"
                        ],
                        "name": "Yaniv Taigman",
                        "slug": "Yaniv-Taigman",
                        "structuredName": {
                            "firstName": "Yaniv",
                            "lastName": "Taigman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yaniv Taigman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41216159"
                        ],
                        "name": "Ming Yang",
                        "slug": "Ming-Yang",
                        "structuredName": {
                            "firstName": "Ming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706809"
                        ],
                        "name": "Marc'Aurelio Ranzato",
                        "slug": "Marc'Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Marc'Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc'Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145128145"
                        ],
                        "name": "Lior Wolf",
                        "slug": "Lior-Wolf",
                        "structuredName": {
                            "firstName": "Lior",
                            "lastName": "Wolf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lior Wolf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 98
                            }
                        ],
                        "text": "In object detection algorithms, an FC layer is required to run multiple times on all proposal regions, taking up to 38% computation time [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2814088,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f2efadf66817f1b38f58b3f50c7c8f34c69d89a",
            "isKey": false,
            "numCitedBy": 5077,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "In modern face recognition, the conventional pipeline consists of four stages: detect => align => represent => classify. We revisit both the alignment step and the representation step by employing explicit 3D face modeling in order to apply a piecewise affine transformation, and derive a face representation from a nine-layer deep neural network. This deep network involves more than 120 million parameters using several locally connected layers without weight sharing, rather than the standard convolutional layers. Thus we trained it on the largest facial dataset to-date, an identity labeled dataset of four million facial images belonging to more than 4, 000 identities. The learned representations coupling the accurate model-based alignment with the large facial database generalize remarkably well to faces in unconstrained environments, even with a simple classifier. Our method reaches an accuracy of 97.35% on the Labeled Faces in the Wild (LFW) dataset, reducing the error of the current state of the art by more than 27%, closely approaching human-level performance."
            },
            "slug": "DeepFace:-Closing-the-Gap-to-Human-Level-in-Face-Taigman-Yang",
            "title": {
                "fragments": [],
                "text": "DeepFace: Closing the Gap to Human-Level Performance in Face Verification"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This work revisits both the alignment step and the representation step by employing explicit 3D face modeling in order to apply a piecewise affine transformation, and derive a face representation from a nine-layer deep neural network."
            },
            "venue": {
                "fragments": [],
                "text": "2014 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1856462,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2f83f6e1afadf0963153974968af6b8342775d82",
            "isKey": false,
            "numCitedBy": 3324,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Framewise-phoneme-classification-with-bidirectional-Graves-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Framewise phoneme classification with bidirectional LSTM and other neural network architectures"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153302678"
                        ],
                        "name": "Jia Deng",
                        "slug": "Jia-Deng",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144847596"
                        ],
                        "name": "Wei Dong",
                        "slug": "Wei-Dong",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Dong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Dong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2040091191"
                        ],
                        "name": "Li-Jia Li",
                        "slug": "Li-Jia-Li",
                        "structuredName": {
                            "firstName": "Li-Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "94451829"
                        ],
                        "name": "K. Li",
                        "slug": "K.-Li",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "The accuracy is measured on ImageNet dataset [29] with AlexNet [1], and the energy is obtained from synthesized RTL under 45nm process."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 29
                            }
                        ],
                        "text": "We use the Image-Net dataset [29] and the Caffe [28] deep learning framework as golden model to verify the correctness of the hardware design."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 57246310,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2c733e34d48784a37d717fe43d9e93277a8c53e",
            "isKey": false,
            "numCitedBy": 28266,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called \u201cImageNet\u201d, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond."
            },
            "slug": "ImageNet:-A-large-scale-hierarchical-image-database-Deng-Dong",
            "title": {
                "fragments": [],
                "text": "ImageNet: A large-scale hierarchical image database"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new database called \u201cImageNet\u201d is introduced, a large-scale ontology of images built upon the backbone of the WordNet structure, much larger in scale and diversity and much more accurate than the current image datasets."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073603971"
                        ],
                        "name": "Vinod Nair",
                        "slug": "Vinod-Nair",
                        "structuredName": {
                            "firstName": "Vinod",
                            "lastName": "Nair",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vinod Nair"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 190
                            }
                        ],
                        "text": "Where a is the input activation vector, b is the output activation vector, v is the bias, W is the weight matrix, and f is the non-linear function, typically the Rectified Linear Unit(ReLU) [22] in CNN and some RNN."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15539264,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a538b05ebb01a40323997629e171c91aa28b8e2f",
            "isKey": false,
            "numCitedBy": 12985,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Restricted Boltzmann machines were developed using binary stochastic hidden units. These can be generalized by replacing each binary unit by an infinite number of copies that all have the same weights but have progressively more negative biases. The learning and inference rules for these \"Stepped Sigmoid Units\" are unchanged. They can be approximated efficiently by noisy, rectified linear units. Compared with binary units, these units learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset. Unlike binary units, rectified linear units preserve information about relative intensities as information travels through multiple layers of feature detectors."
            },
            "slug": "Rectified-Linear-Units-Improve-Restricted-Boltzmann-Nair-Hinton",
            "title": {
                "fragments": [],
                "text": "Rectified Linear Units Improve Restricted Boltzmann Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "Restricted Boltzmann machines were developed using binary stochastic hidden units that learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759839"
                        ],
                        "name": "S. Solla",
                        "slug": "S.-Solla",
                        "structuredName": {
                            "firstName": "Sara",
                            "lastName": "Solla",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Solla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7785881,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e7297db245c3feb1897720b173a59fe7e36babb7",
            "isKey": false,
            "numCitedBy": 3518,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We have used information-theoretic ideas to derive a class of practical and nearly optimal schemes for adapting the size of a neural network. By removing unimportant weights from a network, several improvements can be expected: better generalization, fewer training examples required, and improved speed of learning and/or classification. The basic idea is to use second-derivative information to make a tradeoff between network complexity and training set error. Experiments confirm the usefulness of the methods on a real-world application."
            },
            "slug": "Optimal-Brain-Damage-LeCun-Denker",
            "title": {
                "fragments": [],
                "text": "Optimal Brain Damage"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A class of practical and nearly optimal schemes for adapting the size of a neural network by using second-derivative information to make a tradeoff between network complexity and training set error is derived."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739274"
                        ],
                        "name": "V. Eijkhout",
                        "slug": "V.-Eijkhout",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Eijkhout",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Eijkhout"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 103
                            }
                        ],
                        "text": "This solution is more scalable for distributed systems where communication latency cost is significant [32]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58713083,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "355589166b0fc85dcd1e68ec5b62ad4098ef7193",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Distributed data structures for matrices and vectors representing sparse data, both structured and unstructured, are described. For unstructured data it is described how processors can derive communication information from the data structure."
            },
            "slug": "LAPACK-Working-Note-50:-Distributed-Sparse-Data-for-Eijkhout",
            "title": {
                "fragments": [],
                "text": "LAPACK Working Note 50: Distributed Sparse Data Structures for Linear Algebra Operations"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "Distributed data structures for matrices and vectors representing sparse data, both structured and unstructured, are described to show how processors can derive communication information from the data structure."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "65739159"
                        ],
                        "name": "A. Chrz\u0229szczyk",
                        "slug": "A.-Chrz\u0229szczyk",
                        "structuredName": {
                            "firstName": "Andrzej",
                            "lastName": "Chrz\u0229szczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Chrz\u0229szczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1920259"
                        ],
                        "name": "J. Kochanowski",
                        "slug": "J.-Kochanowski",
                        "structuredName": {
                            "firstName": "Janusz",
                            "lastName": "Kochanowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kochanowski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 291377,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "444d70e3331b5083b40ef32e49390ef683a65e67",
            "isKey": false,
            "numCitedBy": 8504,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Matrix-Computations-Chrz\u0229szczyk-Kochanowski",
            "title": {
                "fragments": [],
                "text": "Matrix Computations"
            },
            "venue": {
                "fragments": [],
                "text": "Encyclopedia of Parallel Computing"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14471419,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eabf117aae614d6b65cc33a3a4bbb22b9a5014d9",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "GPU-Based-Deep-Learning-Inference:-A-Performance",
            "title": {
                "fragments": [],
                "text": "GPU-Based Deep Learning Inference: A Performance and Power Analysis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Energy table for 45nm process, Stanford VLSI wiki. [Online]. Available: https://sites.google.com/site/seecproject/ energy-table"
            },
            "venue": {
                "fragments": [],
                "text": "Energy table for 45nm process, Stanford VLSI wiki. [Online]. Available: https://sites.google.com/site/seecproject/ energy-table"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "SVD is frequently used to reduce model size [37] [38]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 39
                            }
                        ],
                        "text": "The Singular Value Decomposition (SVD) [14] is frequently used to reduce memory footprint."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Matrix computations. 1996"
            },
            "venue": {
                "fragments": [],
                "text": "Johns Hopkins University, Press, Baltimore, MD, USA, pp. 374\u2013426, 1996."
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 91
                            }
                        ],
                        "text": "During M\u00d7V, the memory access is usually the bottleneck [14] especially when the matrix is larger than the cache capacity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Energy table for 45nm process, Stanford VLSI wiki"
            },
            "venue": {
                "fragments": [],
                "text": "Energy table for 45nm process, Stanford VLSI wiki"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Technical brief: NVIDIA jetson TK1 development kit bringing GPU-accelerated computing to embedded systems"
            },
            "venue": {
                "fragments": [],
                "text": "Technical brief: NVIDIA jetson TK1 development kit bringing GPU-accelerated computing to embedded systems"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Available: https://sites.google.com/site"
            },
            "venue": {
                "fragments": [],
                "text": "Available: https://sites.google.com/site"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 16,
            "methodology": 17
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 52,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/EIE:-Efficient-Inference-Engine-on-Compressed-Deep-Han-Liu/2e2b189f668cf2c06ebc44dc9b166648256cf457?sort=total-citations"
}