{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7148093"
                        ],
                        "name": "Sunpyo Hong",
                        "slug": "Sunpyo-Hong",
                        "structuredName": {
                            "firstName": "Sunpyo",
                            "lastName": "Hong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sunpyo Hong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8187053"
                        ],
                        "name": "Hyesoon Kim",
                        "slug": "Hyesoon-Kim",
                        "structuredName": {
                            "firstName": "Hyesoon",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hyesoon Kim"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 701,
                                "start": 45
                            }
                        ],
                        "text": "[2012] model is a further development of the Hong and Kim model discussed before. An important improvement is inclusion of arithmetic latencies into consideration. The resulting model suffers from the same limitation as Zhang and Owens model: it is fairly accurate at limits \u03b1 = 0 and \u03b1 = \u221e, but not at intermediate arithmetic intensities. We evaluate this model on the GTX480 GPU, which is similar to the Tesla C2050 GPU used in the original work. Both of them have the Fermi architecture and similar multiprocessors of compute capability 2.0. The differences include: C2050 has one fewer multiprocessor, a lower processor clock rate, and a lower memory bandwidth. Figure 7.5: Zhang and Owens [2011] and our model compared with experiment on the GT200 GPU, \u03b1 = 16."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 130
                            }
                        ],
                        "text": "assume no dual-issue) and are better consistent with prior work, such as with the latencies reported in Volkov and Demmel [2008], Hong and Kim [2009] and Wong et al. [2010]. These parameters and the resulting estimates are also listed in Table 4."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 55
                            }
                        ],
                        "text": "This concept is covered in more detail in the original Hong and Kim [2009] paper \u2013 see, for example, Figures 9 and 10 there."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 536,
                                "start": 270
                            }
                        ],
                        "text": "If we also ignore arithmetic latency and assume that each instruction is executed in instruction time equal 1 / alu_thru, we get R = (\u03b1 + 1) \uf0d7 instruction time, which produces the same result for the needed number of physical threads as in the programming guide and the Hong and Kim model. If we do include arithmetic latency, such as by putting R = \u03b1 \uf0d7 alu_lat, the result is smaller and therefore is even less accurate. Similar solutions were also suggested for prefetching, such as by Klaiber and Levy [1991] and Mowry et al. [1992]. Prefetching is another technique for latency hiding that hides memory but not arithmetic latency."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 30
                            }
                        ],
                        "text": "CWP is the same concept as in Hong and Kim [2009] but enhanced to include arithmetic latencies."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "Hong and Kim [2009] is one of the better known GPU performance models."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 130
                            }
                        ],
                        "text": "assume no dual-issue) and are better consistent with prior work, such as with the latencies reported in Volkov and Demmel [2008], Hong and Kim [2009] and Wong et al."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 127
                            }
                        ],
                        "text": "The number of warps needed to fully overlap memory stalls with execution is denoted in this\nmodel as CWP_full and is found as [Hong and Kim 2009, Eq."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 3
                            }
                        ],
                        "text": "1: Hong and Kim [2009] and our model compared with experiment on the GT200 GPU, \u03b1 = 32."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 4
                            }
                        ],
                        "text": "7.1 Hong and Kim 2009 model Hong and Kim [2009] model is one of the better known performance models for GPUs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Hong and Kim 2009 model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 2
                            }
                        ],
                        "text": "1 Hong and Kim 2009 model Hong and Kim [2009] model is one of the better known performance models for GPUs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 512,
                                "start": 270
                            }
                        ],
                        "text": "If we also ignore arithmetic latency and assume that each instruction is executed in instruction time equal 1 / alu_thru, we get R = (\u03b1 + 1) \uf0d7 instruction time, which produces the same result for the needed number of physical threads as in the programming guide and the Hong and Kim model. If we do include arithmetic latency, such as by putting R = \u03b1 \uf0d7 alu_lat, the result is smaller and therefore is even less accurate. Similar solutions were also suggested for prefetching, such as by Klaiber and Levy [1991] and Mowry et al."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 207173155,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47d526abe02451421ca2ce3688d6e8b0e6967cb0",
            "isKey": true,
            "numCitedBy": 663,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "GPU architectures are increasingly important in the multi-core era due to their high number of parallel processors. Programming thousands of massively parallel threads is a big challenge for software engineers, but understanding the performance bottlenecks of those parallel programs on GPU architectures to improve application performance is even more difficult. Current approaches rely on programmers to tune their applications by exploiting the design space exhaustively without fully understanding the performance characteristics of their applications.\n To provide insights into the performance bottlenecks of parallel applications on GPU architectures, we propose a simple analytical model that estimates the execution time of massively parallel programs. The key component of our model is estimating the number of parallel memory requests (we call this the memory warp parallelism) by considering the number of running threads and memory bandwidth. Based on the degree of memory warp parallelism, the model estimates the cost of memory requests, thereby estimating the overall execution time of a program. Comparisons between the outcome of the model and the actual execution time in several GPUs show that the geometric mean of absolute error of our model on micro-benchmarks is 5.4% and on GPU computing applications is 13.3%. All the applications are written in the CUDA programming language."
            },
            "slug": "An-analytical-model-for-a-GPU-architecture-with-and-Hong-Kim",
            "title": {
                "fragments": [],
                "text": "An analytical model for a GPU architecture with memory-level and thread-level parallelism awareness"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A simple analytical model is proposed that estimates the execution time of massively parallel programs by considering the number of running threads and memory bandwidth and estimates the cost of memory requests, thereby estimating the overall executionTime of a program."
            },
            "venue": {
                "fragments": [],
                "text": "ISCA '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145753386"
                        ],
                        "name": "C. Nugteren",
                        "slug": "C.-Nugteren",
                        "structuredName": {
                            "firstName": "Cedric",
                            "lastName": "Nugteren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Nugteren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3030396"
                        ],
                        "name": "Gert-Jan van den Braak",
                        "slug": "Gert-Jan-van-den-Braak",
                        "structuredName": {
                            "firstName": "Gert-Jan",
                            "lastName": "Braak",
                            "middleNames": [
                                "van",
                                "den"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gert-Jan van den Braak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684335"
                        ],
                        "name": "H. Corporaal",
                        "slug": "H.-Corporaal",
                        "structuredName": {
                            "firstName": "Henk",
                            "lastName": "Corporaal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Corporaal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144680288"
                        ],
                        "name": "H. Bal",
                        "slug": "H.-Bal",
                        "structuredName": {
                            "firstName": "Henri",
                            "lastName": "Bal",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1517021,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "00dc45d5a9b977ffa033b809e8a0e6c93bfca7dc",
            "isKey": false,
            "numCitedBy": 106,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "As modern GPUs rely partly on their on-chip memories to counter the imminent off-chip memory wall, the efficient use of their caches has become important for performance and energy. However, optimising cache locality system-atically requires insight into and prediction of cache behaviour. On sequential processors, stack distance or reuse distance theory is a well-known means to model cache behaviour. However, it is not straightforward to apply this theory to GPUs, mainly because of the parallel execution model and fine-grained multi-threading. This work extends reuse distance to GPUs by modelling: (1) the GPU's hierarchy of threads, warps, threadblocks, and sets of active threads, (2) conditional and non-uniform latencies, (3) cache associativity, (4) miss-status holding-registers, and (5) warp divergence. We implement the model in C++ and extend the Ocelot GPU emulator to extract lists of memory addresses. We compare our model with measured cache miss rates for the Parboil and PolyBench/GPU benchmark suites, showing a mean absolute error of 6% and 8% for two cache configurations. We show that our model is faster and even more accurate compared to the GPGPU-Sim simulator."
            },
            "slug": "A-detailed-GPU-cache-model-based-on-reuse-distance-Nugteren-Braak",
            "title": {
                "fragments": [],
                "text": "A detailed GPU cache model based on reuse distance theory"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work extends reuse distance to GPUs by modelling the GPU's hierarchy of threads, warps, threadblocks, and sets of active threads, including conditional and non-uniform latencies, cache associativity, miss-status holding-registers, and warp divergence."
            },
            "venue": {
                "fragments": [],
                "text": "2014 IEEE 20th International Symposium on High Performance Computer Architecture (HPCA)"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2030803"
                        ],
                        "name": "Xinxin Mei",
                        "slug": "Xinxin-Mei",
                        "structuredName": {
                            "firstName": "Xinxin",
                            "lastName": "Mei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinxin Mei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680596"
                        ],
                        "name": "Xiaowen Chu",
                        "slug": "Xiaowen-Chu",
                        "structuredName": {
                            "firstName": "Xiaowen",
                            "lastName": "Chu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaowen Chu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 0
                            }
                        ],
                        "text": "Mei and Chu [2016] report attaining only up to 156 GB/s on a similar Maxwell GPU."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12993723,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a170a2e07d02b1ee0281f8f657aef820cb303d4c",
            "isKey": false,
            "numCitedBy": 163,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Memory access efficiency is a key factor in fully utilizing the computational power of graphics processing units (GPUs). However, many details of the GPU memory hierarchy are not released by GPU vendors. In this paper, we propose a novel fine-grained microbenchmarking approach and apply it to three generations of NVIDIA GPUs, namely Fermi, Kepler, and Maxwell, to expose the previously unknown characteristics of their memory hierarchies. Specifically, we investigate the structures of different GPU cache systems, such as the data cache, the texture cache and the translation look-aside buffer (TLB). We also investigate the throughput and access latency of GPU global memory and shared memory. Our microbenchmark results offer a better understanding of the mysterious GPU memory hierarchy, which will facilitate the software optimization and modelling of GPU architectures. To the best of our knowledge, this is the first study to reveal the cache properties of Kepler and Maxwell GPUs, and the superiority of Maxwell in shared memory performance under bank conflict."
            },
            "slug": "Dissecting-GPU-Memory-Hierarchy-Through-Mei-Chu",
            "title": {
                "fragments": [],
                "text": "Dissecting GPU Memory Hierarchy Through Microbenchmarking"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "This is the first study to reveal the cache properties of Kepler and Maxwell GPUs, and the superiority of Maxwell in shared memory performance under bank conflict."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Parallel and Distributed Systems"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115502914"
                        ],
                        "name": "Lin Ma",
                        "slug": "Lin-Ma",
                        "structuredName": {
                            "firstName": "Lin",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lin Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366935"
                        ],
                        "name": "Kunal Agrawal",
                        "slug": "Kunal-Agrawal",
                        "structuredName": {
                            "firstName": "Kunal",
                            "lastName": "Agrawal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kunal Agrawal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35099612"
                        ],
                        "name": "R. Chamberlain",
                        "slug": "R.-Chamberlain",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Chamberlain",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Chamberlain"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6191015,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c925c79b0d5300796c562e08878af86c591d0222",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Memory-Access-Model-for-Highly-threaded-Many-core-Ma-Agrawal",
            "title": {
                "fragments": [],
                "text": "A Memory Access Model for Highly-threaded Many-core Architectures"
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE 18th International Conference on Parallel and Distributed Systems"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757079"
                        ],
                        "name": "Zvika Guz",
                        "slug": "Zvika-Guz",
                        "structuredName": {
                            "firstName": "Zvika",
                            "lastName": "Guz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zvika Guz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3291427"
                        ],
                        "name": "O. Itzhak",
                        "slug": "O.-Itzhak",
                        "structuredName": {
                            "firstName": "Oved",
                            "lastName": "Itzhak",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Itzhak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777373"
                        ],
                        "name": "I. Keidar",
                        "slug": "I.-Keidar",
                        "structuredName": {
                            "firstName": "Idit",
                            "lastName": "Keidar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Keidar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2385801"
                        ],
                        "name": "A. Kolodny",
                        "slug": "A.-Kolodny",
                        "structuredName": {
                            "firstName": "Avinoam",
                            "lastName": "Kolodny",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kolodny"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144188849"
                        ],
                        "name": "A. Mendelson",
                        "slug": "A.-Mendelson",
                        "structuredName": {
                            "firstName": "Avi",
                            "lastName": "Mendelson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mendelson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1948330"
                        ],
                        "name": "U. Weiser",
                        "slug": "U.-Weiser",
                        "structuredName": {
                            "firstName": "Uri",
                            "lastName": "Weiser",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Weiser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9757931,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "489d7d3da46db50f5e8e3e83fd8cffe685bc4e81",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "A new generation of high-performance engines now combine graphics-oriented parallel processors with a cache architecture. In order to meet this new trend, new highly-parallel workloads are being developed. However, it is often difficult to predict how a given application would perform on a given architecture. This paper provides a new model capturing the behavior of such parallel workloads on different multi-core architectures. Specifically, we provide a simple analytical model, which, for a given application, describes its performance and power as a function of the number of threads it runs in parallel, on a range of architectures. We use our model (backed by simulations) to study both synthetic workloads and real ones from the PARSEC suite. Our findings recognize distinctly different behavior patterns for different application families and architectures."
            },
            "slug": "Threads-vs.-caches:-Modeling-the-behavior-of-Guz-Itzhak",
            "title": {
                "fragments": [],
                "text": "Threads vs. caches: Modeling the behavior of parallel workloads"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new model capturing the behavior of such parallel workloads on different multi-core architectures is provided, which describes its performance and power as a function of the number of threads it runs in parallel, on a range of architectures."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE International Conference on Computer Design"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144859824"
                        ],
                        "name": "D. Burger",
                        "slug": "D.-Burger",
                        "structuredName": {
                            "firstName": "Doug",
                            "lastName": "Burger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Burger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144839843"
                        ],
                        "name": "J. Goodman",
                        "slug": "J.-Goodman",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Goodman",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Goodman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3234875"
                        ],
                        "name": "A. K\u00e4gi",
                        "slug": "A.-K\u00e4gi",
                        "structuredName": {
                            "firstName": "Alain",
                            "lastName": "K\u00e4gi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. K\u00e4gi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 17
                            }
                        ],
                        "text": "6 performance by Chen and Aamodt [2009]. Similarly, memory bandwidth is not considered in a number of GPU performance models, such as in Kothapalli et al. [2009], in many important cases in Huang et al. [2014], and in the brief review of latency hiding in the widely distributed vendor\u2019s programming guide [NVIDIA 2015, Ch."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 41
                            }
                        ],
                        "text": "A similar classification is suggested in Burger et al. [1996], except in application to memory stalls only."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 17
                            }
                        ],
                        "text": "6 performance by Chen and Aamodt [2009]. Similarly, memory bandwidth is not considered in a number of GPU performance models, such as in Kothapalli et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 110
                            }
                        ],
                        "text": "It was long understood that memory bandwidth is an important factor in processor performance, see for example Burger et al. [1996]. Yet, many"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 75
                            }
                        ],
                        "text": "This trend is a part of what is known as \u201cmemory wall\u201d \u2013 see, for example, Burger et al. [1996] and McKee [2004]. The trend is not exclusive to GPUs but is observed on GPUs as well."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 75
                            }
                        ],
                        "text": "This trend is a part of what is known as \u201cmemory wall\u201d \u2013 see, for example, Burger et al. [1996] and McKee [2004]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 17
                            }
                        ],
                        "text": "6 performance by Chen and Aamodt [2009]. Similarly, memory bandwidth is not considered in a number of GPU performance models, such as in Kothapalli et al. [2009], in many important cases in Huang et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2047029,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d413979868946143313f4119bac440eb2f6e6fb",
            "isKey": true,
            "numCitedBy": 354,
            "numCiting": 116,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper makes the case that pin bandwidth will be a critical consideration for future microprocessors. We show that many of the techniques used to tolerate growing memory latencies do so at the expense of increased bandwidth requirements. Using a decomposition of execution time, we show that for modern processors that employ aggressive memory latency tolerance techniques, wasted cycles due to insufficient bandwidth generally exceed those due to raw memory latencies. Given the importance of maximizing memory bandwidth, we calculate effective pin bandwidth, then estimate optimal effective pin bandwidth. We measure these quantities by determining the amount by which both caches and minimal-traffic caches filter accesses to the lower levels of the memory hierarchy. We see that there is a gap that can exceed two orders of magnitude between the total memory traffic generated by caches and the minimal-traffic caches---implying that the potential exists to increase effective pin bandwidth substantially. We decompose this traffic gap into four factors, and show they contribute quite differently to traffic reduction for different benchmarks. We conclude that, in the short term, pin bandwidth limitations will make more complex on-chip caches cost-effective. For example, flexible caches may allow individual applications to choose from a range of caching policies. In the long term, we predict that off-chip accesses will be so expensive that all system memory will reside on one or more processor chips."
            },
            "slug": "Memory-Bandwidth-Limitations-of-Future-Burger-Goodman",
            "title": {
                "fragments": [],
                "text": "Memory Bandwidth Limitations of Future Microprocessors"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is predicted that off-chip accesses will be so expensive that all system memory will reside on one or more processor chips, and pin bandwidth limitations will make more complex on-chip caches cost-effective."
            },
            "venue": {
                "fragments": [],
                "text": "23rd Annual International Symposium on Computer Architecture (ISCA'96)"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1798309"
                        ],
                        "name": "Shuaiwen Song",
                        "slug": "Shuaiwen-Song",
                        "structuredName": {
                            "firstName": "Shuaiwen",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuaiwen Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9187296"
                        ],
                        "name": "Chun-Yi Su",
                        "slug": "Chun-Yi-Su",
                        "structuredName": {
                            "firstName": "Chun-Yi",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chun-Yi Su"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145015445"
                        ],
                        "name": "B. Rountree",
                        "slug": "B.-Rountree",
                        "structuredName": {
                            "firstName": "Barry",
                            "lastName": "Rountree",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Rountree"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717511"
                        ],
                        "name": "K. Cameron",
                        "slug": "K.-Cameron",
                        "structuredName": {
                            "firstName": "Kirk",
                            "lastName": "Cameron",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Cameron"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 104
                            }
                        ],
                        "text": "assume no dual-issue) and are better consistent with prior work, such as with the latencies reported in Volkov and Demmel [2008], Hong and Kim [2009] and Wong et al."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 10649083,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "daed770cbb163e0c9362a838a7c235d11c153f1c",
            "isKey": false,
            "numCitedBy": 133,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Emergent heterogeneous systems must be optimized for both power and performance at exascale. Massive parallelism combined with complex memory hierarchies form a barrier to efficient application and architecture design. These challenges are exacerbated with GPUs as parallelism increases orders of magnitude and power consumption can easily double. Models have been proposed to isolate power and performance bottlenecks and identify their root causes. However, no current models combine simplicity, accuracy, and support for emergent GPU architectures (e.g. NVIDIA Fermi). We combine hardware performance counter data with machine learning and advanced analytics to model power-performance efficiency for modern GPU-based systems. Our performance counter based approach is simpler than previous approaches and does not require detailed understanding of the underlying architecture. The resulting model is accurate for predicting power (within 2.1%) and performance (within 6.7%) for application kernels on modern GPUs. Our model can identify power-performance bottlenecks and their root causes for various complex computation and memory access patterns (e.g. global, shared, texture). We measure the accuracy of our power and performance models on a NVIDIA Fermi C2075 GPU for more than a dozen CUDA applications. We show our power model is more accurate and robust than the best available GPU power models - multiple linear regression models MLR and MLR+. We demonstrate how to use our models to identify power-performance bottlenecks and suggest optimization strategies for high-performance codes such as GEM, a biomolecular electrostatic analysis application. We verify our power-performance model is accurate on clusters of NVIDIA Fermi M2090s and useful for suggesting optimal runtime configurations on the Keeneland supercomputer at Georgia Tech."
            },
            "slug": "A-Simplified-and-Accurate-Model-of-Efficiency-on-Song-Su",
            "title": {
                "fragments": [],
                "text": "A Simplified and Accurate Model of Power-Performance Efficiency on Emergent GPU Architectures"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The performance counter based power model is simpler than previous approaches and does not require detailed understanding of the underlying architecture, and is more accurate and robust than the best available GPU power models - multiple linear regression models MLR and MLR+."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE 27th International Symposium on Parallel and Distributed Processing"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2292813"
                        ],
                        "name": "Sara S. Baghsorkhi",
                        "slug": "Sara-S.-Baghsorkhi",
                        "structuredName": {
                            "firstName": "Sara",
                            "lastName": "Baghsorkhi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sara S. Baghsorkhi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1979330"
                        ],
                        "name": "Matthieu Delahaye",
                        "slug": "Matthieu-Delahaye",
                        "structuredName": {
                            "firstName": "Matthieu",
                            "lastName": "Delahaye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthieu Delahaye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32794191"
                        ],
                        "name": "Sanjay J. Patel",
                        "slug": "Sanjay-J.-Patel",
                        "structuredName": {
                            "firstName": "Sanjay",
                            "lastName": "Patel",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sanjay J. Patel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703559"
                        ],
                        "name": "W. Gropp",
                        "slug": "W.-Gropp",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Gropp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gropp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143668320"
                        ],
                        "name": "W. Hwu",
                        "slug": "W.-Hwu",
                        "structuredName": {
                            "firstName": "Wen-mei",
                            "lastName": "Hwu",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hwu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 0
                            }
                        ],
                        "text": "Baghsorkhi et al. 2010 model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95 \u00a7 7.3."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 4
                            }
                        ],
                        "text": "7.2 Baghsorkhi et al. 2010 model The model by Baghsorkhi et al. [2010] is the first performance model for GPUs to include both arithmetic and memory latencies."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 32
                            }
                        ],
                        "text": "[2012], Zhang and Owens [2011], Baghsorkhi et al. [2010] and Hong and Kim [2009], and in the CUDA C Programming Guide [NVIDIA 2015]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 743,
                                "start": 32
                            }
                        ],
                        "text": "[2012], Zhang and Owens [2011], Baghsorkhi et al. [2010] and Hong and Kim [2009], and in the CUDA C Programming Guide [NVIDIA 2015]. An example corresponding to the Sim et al. model is shown in Figure 1.2, a, left. A similar example for the CUDA C Programming Guide is shown in Figure 1.2, a, right. In the latter case the estimate is shown as a vertical bar because the respective analysis is limited to estimating the needed occupancy only. Another repeating pattern is poor accuracy on memory-intensive codes, i.e. at small arithmetic intensities. In this case the performance model by Baghsorkhi et al. [2010] is found to severely underestimate throughput, as shown in Figure 1.2, b, left, and the performance model by Huang et al. [2014], in contrast, is found to substantially overestimate throughput, as shown in Figure 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 112
                            }
                        ],
                        "text": "This prior work includes CUDA C programming guide [NVIDIA 2015], and performance models by Hong and Kim [2009], Baghsorkhi et al. [2010], Sim et al. [2012] and Song et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 6
                            }
                        ],
                        "text": "3], \uf0b7 Baghsorkhi et al. [2010], Pseudo-code Assembly code a = memory[a] LD R1, [R1] a = a + b FADD R1, R1, R2 a = a + b FADD R1, R1, R2 a = a + b FADD R1, R1, R2 a = memory[a] LD R1, [R1] a = a + b FADD R1, R1, R2 ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 29
                            }
                        ],
                        "text": "The GPU performance model by Baghsorkhi et al. [2010] does take memory bandwidth into account but does not integrate it well with a model for latency hiding."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1194,
                                "start": 32
                            }
                        ],
                        "text": "[2012], Zhang and Owens [2011], Baghsorkhi et al. [2010] and Hong and Kim [2009], and in the CUDA C Programming Guide [NVIDIA 2015]. An example corresponding to the Sim et al. model is shown in Figure 1.2, a, left. A similar example for the CUDA C Programming Guide is shown in Figure 1.2, a, right. In the latter case the estimate is shown as a vertical bar because the respective analysis is limited to estimating the needed occupancy only. Another repeating pattern is poor accuracy on memory-intensive codes, i.e. at small arithmetic intensities. In this case the performance model by Baghsorkhi et al. [2010] is found to severely underestimate throughput, as shown in Figure 1.2, b, left, and the performance model by Huang et al. [2014], in contrast, is found to substantially overestimate throughput, as shown in Figure 1.2, b, right. Some performance models are found to have unique limitations. The performance model by Huang et al. [2014] is found to produce, in some cases, negative execution times. Also, one of its versions is found to substantially overestimate throughput in both memory-intensive and arithmetic-intensive codes. The performance model by Baghsorkhi et al. [2010], as shown in Figure 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 949,
                                "start": 32
                            }
                        ],
                        "text": "[2012], Zhang and Owens [2011], Baghsorkhi et al. [2010] and Hong and Kim [2009], and in the CUDA C Programming Guide [NVIDIA 2015]. An example corresponding to the Sim et al. model is shown in Figure 1.2, a, left. A similar example for the CUDA C Programming Guide is shown in Figure 1.2, a, right. In the latter case the estimate is shown as a vertical bar because the respective analysis is limited to estimating the needed occupancy only. Another repeating pattern is poor accuracy on memory-intensive codes, i.e. at small arithmetic intensities. In this case the performance model by Baghsorkhi et al. [2010] is found to severely underestimate throughput, as shown in Figure 1.2, b, left, and the performance model by Huang et al. [2014], in contrast, is found to substantially overestimate throughput, as shown in Figure 1.2, b, right. Some performance models are found to have unique limitations. The performance model by Huang et al. [2014] is found to produce, in some cases, negative execution times."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 614,
                                "start": 32
                            }
                        ],
                        "text": "[2012], Zhang and Owens [2011], Baghsorkhi et al. [2010] and Hong and Kim [2009], and in the CUDA C Programming Guide [NVIDIA 2015]. An example corresponding to the Sim et al. model is shown in Figure 1.2, a, left. A similar example for the CUDA C Programming Guide is shown in Figure 1.2, a, right. In the latter case the estimate is shown as a vertical bar because the respective analysis is limited to estimating the needed occupancy only. Another repeating pattern is poor accuracy on memory-intensive codes, i.e. at small arithmetic intensities. In this case the performance model by Baghsorkhi et al. [2010] is found to severely underestimate throughput, as shown in Figure 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 112
                            }
                        ],
                        "text": "This prior work includes CUDA C programming guide [NVIDIA 2015], and performance models by Hong and Kim [2009], Baghsorkhi et al. [2010], Sim et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16984758,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "55220bc99ffe36591a4b31a2ee9e40620381e0ca",
            "isKey": true,
            "numCitedBy": 298,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an analytical model to predict the performance of\n general-purpose applications on a GPU architecture. The model is designed to provide performance information to an auto-tuning compiler and assist it in narrowing down the search to the more promising implementations. It can also be incorporated into a tool to help programmers better assess the performance bottlenecks in their code. We analyze each GPU kernel and identify how the kernel exercises major GPU microarchitecture features. To identify the performance bottlenecks accurately, we introduce an abstract interpretation of a GPU kernel, work flow graph, based on which we estimate the execution time of a GPU kernel. We validated our performance model on the NVIDIA GPUs using CUDA (Compute Unified Device Architecture). For this purpose, we used data parallel benchmarks that stress different GPU microarchitecture events such as uncoalesced memory accesses, scratch-pad memory bank conflicts, and control flow divergence, which must be accurately modeled but represent challenges to the analytical performance models. The proposed model captures full system complexity and shows high accuracy in predicting the performance trends of different optimized kernel implementations. We also describe our approach to extracting the performance model automatically from a kernel code."
            },
            "slug": "An-adaptive-performance-modeling-tool-for-GPU-Baghsorkhi-Delahaye",
            "title": {
                "fragments": [],
                "text": "An adaptive performance modeling tool for GPU architectures"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "An analytical model to predict the performance of general-purpose applications on a GPU architecture that captures full system complexity and shows high accuracy in predicting the performance trends of different optimized kernel implementations is presented."
            },
            "venue": {
                "fragments": [],
                "text": "PPoPP '10"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144052393"
                        ],
                        "name": "Henry Wong",
                        "slug": "Henry-Wong",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Wong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Henry Wong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057582754"
                        ],
                        "name": "Misel-Myrto Papadopoulou",
                        "slug": "Misel-Myrto-Papadopoulou",
                        "structuredName": {
                            "firstName": "Misel-Myrto",
                            "lastName": "Papadopoulou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Misel-Myrto Papadopoulou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1405605090"
                        ],
                        "name": "Maryam Sadooghi-Alvandi",
                        "slug": "Maryam-Sadooghi-Alvandi",
                        "structuredName": {
                            "firstName": "Maryam",
                            "lastName": "Sadooghi-Alvandi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maryam Sadooghi-Alvandi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150023334"
                        ],
                        "name": "A. Moshovos",
                        "slug": "A.-Moshovos",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Moshovos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Moshovos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 117
                            }
                        ],
                        "text": "and this is what we do below, or we may use the throughputs sustained in respective microbenchmarks, as suggested in Zhang and Owens [2011]. Here, both arithmetic time (n) and memory time (n) are reciprocal throughputs in cycles per instruction at each SM, and n is occupancy in warps per SM."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 44
                            }
                        ],
                        "text": "This approach, with refinements, appears in Zhang and Owens [2011] and Sim et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 2
                            }
                        ],
                        "text": "3 Zhang and Owens 2011 model The GPU performance model by Zhang and Owens [2011] is the first to be accurate in both \u03b1 = 0 and \u03b1 = \u221e limits."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 122
                            }
                        ],
                        "text": "This is likely due to the hierarchy of TLBs, which implements address translation, and is consistent with the analysis in Wong et al. [2010]. This analysis suggests that GTX280 GPUs have two-level TLB with the second level covering 32 MB of address space."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 11208400,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "026ae09252067dfba5d577a4aaaadb20b85d1145",
            "isKey": true,
            "numCitedBy": 434,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Graphics processors (GPU) offer the promise of more than an order of magnitude speedup over conventional processors for certain non-graphics computations. Because the GPU is often presented as a C-like abstraction (e.g., Nvidia's CUDA), little is known about the characteristics of the GPU's architecture beyond what the manufacturer has documented. This work develops a microbechmark suite and measures the CUDA-visible architectural characteristics of the Nvidia GT200 (GTX280) GPU. Various undisclosed characteristics of the processing elements and the memory hierarchies are measured. This analysis exposes undocumented features that impact program performance and correctness. These measurements can be useful for improving performance optimization, analysis, and modeling on this architecture and offer additional insight on the decisions made in developing this GPU."
            },
            "slug": "Demystifying-GPU-microarchitecture-through-Wong-Papadopoulou",
            "title": {
                "fragments": [],
                "text": "Demystifying GPU microarchitecture through microbenchmarking"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This work develops a microbechmark suite and measures the CUDA-visible architectural characteristics of the Nvidia GT200 (GTX280) GPU, exposing undocumented features that impact program performance and correctness."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE International Symposium on Performance Analysis of Systems & Software (ISPASS)"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39806454"
                        ],
                        "name": "Thanh Tuan Dao",
                        "slug": "Thanh-Tuan-Dao",
                        "structuredName": {
                            "firstName": "Thanh",
                            "lastName": "Dao",
                            "middleNames": [
                                "Tuan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thanh Tuan Dao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157119718"
                        ],
                        "name": "Jungwon Kim",
                        "slug": "Jungwon-Kim",
                        "structuredName": {
                            "firstName": "Jungwon",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jungwon Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145910810"
                        ],
                        "name": "Sangmin Seo",
                        "slug": "Sangmin-Seo",
                        "structuredName": {
                            "firstName": "Sangmin",
                            "lastName": "Seo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sangmin Seo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34460642"
                        ],
                        "name": "Bernhard Egger",
                        "slug": "Bernhard-Egger",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Egger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bernhard Egger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108395388"
                        ],
                        "name": "Jaejin Lee",
                        "slug": "Jaejin-Lee",
                        "structuredName": {
                            "firstName": "Jaejin",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jaejin Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14449717,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cb4e66aff240df656bbc53aa493664544ec1f87",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "To exploit the abundant computational power of the world's fastest supercomputers, an even workload distribution to the typically heterogeneous compute devices is necessary. While relatively accurate performance models exist for conventional CPUs, accurate performance estimation models for modern GPUs do not exist. This paper presents two accurate models for modern GPUs: a sampling-based linear model, and a model based on machine-learning (ML) techniques which improves the accuracy of the linear model and is applicable to modern GPUs with and without caches. We first construct the sampling-based linear model to predict the runtime of an arbitrary OpenCL kernel. Based on an analysis of NVIDIA GPUs' scheduling policies we determine the earliest sampling points that allow an accurate estimation. The linear model cannot capture well the significant effects that memory coalescing or caching as implemented in modern GPUs have on performance. We therefore propose a model based on ML techniques that takes several compiler-generated statistics about the kernel as well as the GPU's hardware performance counters as additional inputs to obtain a more accurate runtime performance estimation for modern GPUs. We demonstrate the effectiveness and broad applicability of the model by applying it to three different NVIDIA GPU architectures and one AMD GPU architecture. On an extensive set of OpenCL benchmarks, on average, the proposed model estimates the runtime performance with less than 7 percent error for a second-generation GTX 280 with no on-chip caches and less than 5 percent for the Fermi-based GTX 580 with hardware caches. On the Kepler-based GTX 680, the linear model has an error of less than 10 percent. On an AMD GPU architecture, Radeon HD 6970, the model estimates with 8 percent of error rates. The proposed technique outperforms existing models by a factor of 5 to 6 in terms of accuracy."
            },
            "slug": "A-Performance-Model-for-GPUs-with-Caches-Dao-Kim",
            "title": {
                "fragments": [],
                "text": "A Performance Model for GPUs with Caches"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Two accurate models for modern GPUs are presented: a sampling-based linear model, and a model based on machine-learning (ML) techniques which improves the accuracy of the linear model and is applicable to modern GPUs with and without caches."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Parallel and Distributed Systems"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49309175"
                        ],
                        "name": "Mark Gebhart",
                        "slug": "Mark-Gebhart",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Gebhart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Gebhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "26864738"
                        ],
                        "name": "Daniel R. Johnson",
                        "slug": "Daniel-R.-Johnson",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Johnson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel R. Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2924393"
                        ],
                        "name": "D. Tarjan",
                        "slug": "D.-Tarjan",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Tarjan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tarjan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715863"
                        ],
                        "name": "S. Keckler",
                        "slug": "S.-Keckler",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Keckler",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Keckler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80724002"
                        ],
                        "name": "W. Dally",
                        "slug": "W.-Dally",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dally",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dally"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2516040"
                        ],
                        "name": "Erik Lindholm",
                        "slug": "Erik-Lindholm",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Lindholm",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Erik Lindholm"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735065"
                        ],
                        "name": "K. Skadron",
                        "slug": "K.-Skadron",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Skadron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Skadron"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 54
                            }
                        ],
                        "text": "Some performance models are more complicated, such as Hong and Kim [2009], Sim et al. [2012] and Huang et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 54
                            }
                        ],
                        "text": "Some performance models are more complicated, such as Hong and Kim [2009], Sim et al. [2012] and Huang et al. [2014], which include over 20 equations each."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 54
                            }
                        ],
                        "text": "Some performance models are more complicated, such as Hong and Kim [2009], Sim et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 64
                            }
                        ],
                        "text": "Even publications that do recognize arithmetic latency, such as Gebhart et al. [2011], tend to downplay it as requiring \u201ca much smaller pool of warps\u201d."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 54
                            }
                        ],
                        "text": "Some performance models are more complicated, such as Hong and Kim [2009], Sim et al. [2012] and Huang et al. [2014], which include over 20 equations each. Many feature unique approaches; for example, Zhang and Owens [2011] suggest using extensive experimental data instead of microarchitectural parameters, and Baghsorkhi et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11867941,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e679f628891a2f055ce9bfae528d419b6d075426",
            "isKey": true,
            "numCitedBy": 255,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Modern graphics processing units (GPUs) use a large number of hardware threads to hide both function unit and memory access latency. Extreme multithreading requires a complicated thread scheduler as well as a large register file, which is expensive to access both in terms of energy and latency. We present two complementary techniques for reducing energy on massively-threaded processors such as GPUs. First, we examine register file caching to replace accesses to the large main register file with accesses to a smaller structure containing the immediate register working set of active threads. Second, we investigate a two-level thread scheduler that maintains a small set of active threads to hide ALU and local memory access latency and a larger set of pending threads to hide main memory latency. Combined with register file caching, a two-level thread scheduler provides a further reduction in energy by limiting the allocation of temporary register cache resources to only the currently active subset of threads. We show that on average, across a variety of real world graphics and compute workloads, a 6-entry per-thread register file cache reduces the number of reads and writes to the main register file by 50% and 59% respectively. We further show that the active thread count can be reduced by a factor of 4 with minimal impact on performance, resulting in a 36% reduction of register file energy."
            },
            "slug": "Energy-efficient-mechanisms-for-managing-thread-in-Gebhart-Johnson",
            "title": {
                "fragments": [],
                "text": "Energy-efficient mechanisms for managing thread context in throughput processors"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Two complementary techniques for reducing energy on massively-threaded processors such as GPUs are presented and it is shown that on average, across a variety of real world graphics and compute workloads, a 6-entry per-thread register file cache reduces the number of reads and writes to the main register file by 50% and 59% respectively."
            },
            "venue": {
                "fragments": [],
                "text": "2011 38th Annual International Symposium on Computer Architecture (ISCA)"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40583265"
                        ],
                        "name": "Junjie Lai",
                        "slug": "Junjie-Lai",
                        "structuredName": {
                            "firstName": "Junjie",
                            "lastName": "Lai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junjie Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743857"
                        ],
                        "name": "Andr\u00e9 Seznec",
                        "slug": "Andr\u00e9-Seznec",
                        "structuredName": {
                            "firstName": "Andr\u00e9",
                            "lastName": "Seznec",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andr\u00e9 Seznec"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15528887,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a12fca1053e945356b8a3332320db81f6f5f35e",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Because modern GPGPU can provide significant computing power and has very high memory bandwidth, and also, developer-friendly programming interfaces such as CUDA have been introduced, GPGPU becomes more and more accepted in the HPC research area. Much research has been done to help developers to better optimize GPU applications. But to fully understand GPU performance behavior remains a hot research topic.\n We developed an analytical tool called TEG (Timing Estimation tool for GPU) to estimate GPU performance. Previous work shows that TEG has good approximation and can help us to quantify bottlenecks' performance effects. We have made some improvement to the tool and in this paper, we use TEG to analyze the GPU performance scaling behavior. TEG takes the dis-assembly output of CUDA kernel binary code and instruction trace as input. It does not execute the codes, but try to model the execution of CUDA codes with timing information. Because TEG takes the native GPU assembly code as input, it can estimate the execution time with a small error and it allows us to get more insight into GPU performance result."
            },
            "slug": "Break-down-GPU-execution-time-with-an-analytical-Lai-Seznec",
            "title": {
                "fragments": [],
                "text": "Break down GPU execution time with an analytical method"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "An analytical tool called TEG (Timing Estimation tool for GPU) is developed to estimate GPU performance and it can estimate the execution time with a small error and it allows for more insight into GPU performance result."
            },
            "venue": {
                "fragments": [],
                "text": "RAPIDO '12"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2615488"
                        ],
                        "name": "Mario Alberto Chapa Martell",
                        "slug": "Mario-Alberto-Chapa-Martell",
                        "structuredName": {
                            "firstName": "Mario",
                            "lastName": "Martell",
                            "middleNames": [
                                "Alberto",
                                "Chapa"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mario Alberto Chapa Martell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145506499"
                        ],
                        "name": "Hiroyuki Sato",
                        "slug": "Hiroyuki-Sato",
                        "structuredName": {
                            "firstName": "Hiroyuki",
                            "lastName": "Sato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hiroyuki Sato"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 346,
                                "start": 156
                            }
                        ],
                        "text": "Many feature unique approaches; for example, Zhang and Owens [2011] suggest using extensive experimental data instead of microarchitectural parameters, and Baghsorkhi et al. [2010] formulate their model as operations on a graph, such as weight assignments and reductions. The list of other performance models for GPUs includes Song et al. [2013], Kothapalli et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 424,
                                "start": 156
                            }
                        ],
                        "text": "Many feature unique approaches; for example, Zhang and Owens [2011] suggest using extensive experimental data instead of microarchitectural parameters, and Baghsorkhi et al. [2010] formulate their model as operations on a graph, such as weight assignments and reductions. The list of other performance models for GPUs includes Song et al. [2013], Kothapalli et al. [2009], Guz et al. [2010], Resios [2011], Ma et al. [2014], Alberto and Hiroyuki [2015], and Dao et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 156
                            }
                        ],
                        "text": "Many feature unique approaches; for example, Zhang and Owens [2011] suggest using extensive experimental data instead of microarchitectural parameters, and Baghsorkhi et al. [2010] formulate their model as operations on a graph, such as weight assignments and reductions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 8
                            }
                        ],
                        "text": "[2014], Alberto and Hiroyuki [2015], and Dao et al. [2015]. The suggested approaches share little in common, despite considering fundamentally similar GPUs, mostly from NVIDIA."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 372,
                                "start": 156
                            }
                        ],
                        "text": "Many feature unique approaches; for example, Zhang and Owens [2011] suggest using extensive experimental data instead of microarchitectural parameters, and Baghsorkhi et al. [2010] formulate their model as operations on a graph, such as weight assignments and reductions. The list of other performance models for GPUs includes Song et al. [2013], Kothapalli et al. [2009], Guz et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 391,
                                "start": 156
                            }
                        ],
                        "text": "Many feature unique approaches; for example, Zhang and Owens [2011] suggest using extensive experimental data instead of microarchitectural parameters, and Baghsorkhi et al. [2010] formulate their model as operations on a graph, such as weight assignments and reductions. The list of other performance models for GPUs includes Song et al. [2013], Kothapalli et al. [2009], Guz et al. [2010], Resios [2011], Ma et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 33081519,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d89addbd0d0e723f3c1d9df9c1506f7a7cd0da8",
            "isKey": true,
            "numCitedBy": 3,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe our performance-breakdown model for GPU programs. GPUs are a popular choice as accelerator hardware due to their high performance, high availability and relatively low price. However, writing programs that are highly efficient represents a difficult and time consuming task for programmers because of the complexities of GPU architecture and the inherent difficulty of parallel programming. That is the reason why we propose the Linear Performance-Breakdown Model Framework as a tool to assist in the optimization process. We show that the model closely matches the behavior of the GPU by comparing the execution time obtained from experiments in two different types of GPU, an Accelerated Processing Unit (APU) and a GTX660, a discrete board. We also show performance-breakdown results obtained from applying the modeling strategy and how they indicate the time spent during the computation in each of the three Mayor Performance Factors that we define as processing time, global memory transfer time and shared memory transfer time.\u00c2"
            },
            "slug": "Linear-Performance-Breakdown-Model:-A-Framework-for-Martell-Sato",
            "title": {
                "fragments": [],
                "text": "Linear Performance-Breakdown Model: A Framework for GPU kernel programs performance analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The Linear Performance-Breakdown Model Framework is proposed as a tool to assist in the optimization process of GPU programs and it is shown that the model closely matches the behavior of the GPU by comparing the execution time obtained from experiments in two different types of GPU."
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Netw. Comput."
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761585"
                        ],
                        "name": "T. Mowry",
                        "slug": "T.-Mowry",
                        "structuredName": {
                            "firstName": "Todd",
                            "lastName": "Mowry",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Mowry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682108"
                        ],
                        "name": "M. Lam",
                        "slug": "M.-Lam",
                        "structuredName": {
                            "firstName": "Monica",
                            "lastName": "Lam",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110759834"
                        ],
                        "name": "Anoop Gupta",
                        "slug": "Anoop-Gupta",
                        "structuredName": {
                            "firstName": "Anoop",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anoop Gupta"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 75
                            }
                        ],
                        "text": "It is written in CUDA; for a quick but sufficient introduction to CUDA see Nickolls et al. [2008]. CUDA code resembles C code but includes a few additional features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 11
                            }
                        ],
                        "text": "[1990] and Mowry et al. [1992]. This is in line with understanding latency hiding as keeping processor busy, not as saturating one or another bottleneck."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 205
                            }
                        ],
                        "text": "If memory latency is l cycles, each instruction executes in instruction time = 1 cycle, and s instructions are executed in each loop iteration, then the number of iterations to prefetch ahead is found as [Mowry et al. 1992]:\nprefetch distance (Mowry et al.)"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 204
                            }
                        ],
                        "text": "If memory latency is l cycles, each instruction executes in instruction time = 1 cycle, and s instructions are executed in each loop iteration, then the number of iterations to prefetch ahead is found as [Mowry et al. 1992]:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1298475,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a600817135a76810f15a15925e790de0d843e259",
            "isKey": true,
            "numCitedBy": 815,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Software-controlled data prefetching is a promising technique for improving the performance of the memory subsystem to match today\u2019s high-performance processors. While prefctching is useful in hiding the latency, issuing prefetches incurs an instruction overhead and can increase the load on the memory subsystem. As a resu 1~ care must be taken to ensure that such overheads do not exceed the benefits. This paper proposes a compiler algorithm to insert prefetch instructions into code that operates on dense matrices. Our algorithm identiEes those references that are likely to be cache misses, and issues prefetches only for them. We have implemented our algorithm in the SUfF (Stanford University Intermediate Form) optimizing compiler. By generating fully functional code, we have been able to measure not only the improvements in cache miss rates, but also the oversdl performance of a simulated system. We show that our algorithm significantly improves the execution speed of our benchmark programs-some of the programs improve by as much as a factor of two. When compared to an algorithm that indiscriminately prefetches alf array accesses, our algorithm can eliminate many of the unnecessary prefetches without any significant decrease in the coverage of the cache misses."
            },
            "slug": "Design-and-evaluation-of-a-compiler-algorithm-for-Mowry-Lam",
            "title": {
                "fragments": [],
                "text": "Design and evaluation of a compiler algorithm for prefetching"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper proposes a compiler algorithm to insert prefetch instructions into code that operates on dense matrices, and shows that this algorithm significantly improves the execution speed of the benchmark programs-some of the programs improve by as much as a factor of two."
            },
            "venue": {
                "fragments": [],
                "text": "ASPLOS V"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47182925"
                        ],
                        "name": "D. Merrill",
                        "slug": "D.-Merrill",
                        "structuredName": {
                            "firstName": "Duane",
                            "lastName": "Merrill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Merrill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144098284"
                        ],
                        "name": "A. Grimshaw",
                        "slug": "A.-Grimshaw",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Grimshaw",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Grimshaw"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 196
                            }
                        ],
                        "text": "Similar long sequences of independent instructions are common in highly optimized kernels such as matrix multiply [Volkov and Demmel 2008; Gray 2014], FFT [Volkov and Kazian 2008] and radix sort [Merrill and Grimshaw 2010]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14902096,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "790ab5f286336dc6826df483d3adc96043f6834d",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "This poster presents efficient strategies for sorting large sequences of fixed-length keys (and values) using GPGPU stream processors. Compared to the state-of-the-art, our radix sorting methods exhibit speedup of at least 2x for all generations of NVIDIA GPGPUs, and up to 3.7x for current GT200-based models. Our implementations demonstrate sorting rates of 482 million key-value pairs per second, and 550 million keys per second (32-bit). For this domain of sorting problems, we believe our sorting primitive to be the fastest available for any fully-programmable microarchitecture. These results motivate a different breed of parallel primitives for GPGPU stream architectures that can better exploit the memory and computational resources while maintaining the flexibility of a reusable component. Our sorting performance is derived from a parallel scan stream primitive that has been generalized in two ways: (1) with local interfaces for producer/consumer operations (visiting logic), and (2) with interfaces for performing multiple related, concurrent prefix scans (multi-scan)."
            },
            "slug": "Revisiting-sorting-for-GPGPU-stream-architectures-Merrill-Grimshaw",
            "title": {
                "fragments": [],
                "text": "Revisiting sorting for GPGPU stream architectures"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This poster presents efficient strategies for sorting large sequences of fixed-length keys (and values) using GPGPU stream processors using a parallel scan stream primitive that has been generalized in two ways: with local interfaces for producer/consumer operations (visiting logic), and with interfaces for performing multiple related, concurrent prefix scans (multi-scan)."
            },
            "venue": {
                "fragments": [],
                "text": "2010 19th International Conference on Parallel Architectures and Compilation Techniques (PACT)"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3235932"
                        ],
                        "name": "K. Kothapalli",
                        "slug": "K.-Kothapalli",
                        "structuredName": {
                            "firstName": "Kishore",
                            "lastName": "Kothapalli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kothapalli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3210730"
                        ],
                        "name": "Rishabh Mukherjee",
                        "slug": "Rishabh-Mukherjee",
                        "structuredName": {
                            "firstName": "Rishabh",
                            "lastName": "Mukherjee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rishabh Mukherjee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39751409"
                        ],
                        "name": "M. S. Rehman",
                        "slug": "M.-S.-Rehman",
                        "structuredName": {
                            "firstName": "Mohammed",
                            "lastName": "Rehman",
                            "middleNames": [
                                "Suhail"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. S. Rehman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2499797"
                        ],
                        "name": "Suryakant Patidar",
                        "slug": "Suryakant-Patidar",
                        "structuredName": {
                            "firstName": "Suryakant",
                            "lastName": "Patidar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Suryakant Patidar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144422343"
                        ],
                        "name": "P. Narayanan",
                        "slug": "P.-Narayanan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Narayanan",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Narayanan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3052515"
                        ],
                        "name": "K. Srinathan",
                        "slug": "K.-Srinathan",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Srinathan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Srinathan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 77
                            }
                        ],
                        "text": "Similar bounds are discussed in classical work on concurrent systems such as Lazowska et al. [1984], Chapter 5."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 115
                            }
                        ],
                        "text": "one with adding memory and arithmetic times and another with taking the maximum of them, were earlier discussed by Kothapalli et al. [2009]. However, their discussion was more simplistic, as they don\u2019t consider how these times depend on occupancy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5184714,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0aab1ca3a641aaee97567c8def5ec9016245dfe",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "The significant growth in computational power of modern Graphics Processing Units (GPUs) coupled with the advent of general purpose programming environments like NVIDIA's CUDA, has seen GPUs emerging as a very popular parallel computing platform. Till recently, there has not been a performance model for GPGPUs. The absence of such a model makes it difficult to definitively assess the suitability of the GPU for solving a particular problem and is a significant impediment to the mainstream adoption of GPUs as a massively parallel (super)computing platform. In this paper we present a performance prediction model for the CUDA GPGPU platform. This model encompasses the various facets of the GPU architecture like scheduling, memory hierarchy, and pipelining among others. We also perform experiments that demonstrate the effects of various memory access strategies. The proposed model can be used to analyze pseudo code for a CUDA kernel to obtain a performance estimate, in a way that is similar to performing asymptotic analysis. We illustrate the usage of our model and its accuracy with three case studies: matrix multiplication, list ranking, and histogram generation."
            },
            "slug": "A-performance-prediction-model-for-the-CUDA-GPGPU-Kothapalli-Mukherjee",
            "title": {
                "fragments": [],
                "text": "A performance prediction model for the CUDA GPGPU platform"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents a performance prediction model for the CUDA GPGPU platform that encompasses the various facets of the GPU architecture like scheduling, memory hierarchy, and pipelining among others and can be used to analyze pseudo code for a CUDA kernel to obtain a performance estimate."
            },
            "venue": {
                "fragments": [],
                "text": "2009 International Conference on High Performance Computing (HiPC)"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40429127"
                        ],
                        "name": "Jen-Cheng Huang",
                        "slug": "Jen-Cheng-Huang",
                        "structuredName": {
                            "firstName": "Jen-Cheng",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jen-Cheng Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108358520"
                        ],
                        "name": "Joo Hwan Lee",
                        "slug": "Joo-Hwan-Lee",
                        "structuredName": {
                            "firstName": "Joo",
                            "lastName": "Lee",
                            "middleNames": [
                                "Hwan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joo Hwan Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8187053"
                        ],
                        "name": "Hyesoon Kim",
                        "slug": "Hyesoon-Kim",
                        "structuredName": {
                            "firstName": "Hyesoon",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hyesoon Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36012806"
                        ],
                        "name": "H. Lee",
                        "slug": "H.-Lee",
                        "structuredName": {
                            "firstName": "Hsien-Hsin",
                            "lastName": "Lee",
                            "middleNames": [
                                "Sean"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 4
                            }
                        ],
                        "text": "7.5 Huang et al. 2014 model: round-robin policy The performance model by Huang et al. [2014] is the most recent model that we evaluate in this text."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 3
                            }
                        ],
                        "text": "8: Huang et al. [2014] model and our model, both scheduling policies."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "Huang et al. [2014] similarly suggest using queuing theory to estimate delays in the GPU memory system."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 2
                            }
                        ],
                        "text": "6 Huang et al. model: greedy-then-oldest policy The second solution suggested by Huang et al. [2014] corresponds to the greedy-then-oldest warp scheduling policy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 0
                            }
                        ],
                        "text": "Huang et al. 2014 model: round-robin policy . . . . . . . . . . . . . . . . . . . . ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 2
                            }
                        ],
                        "text": "7 Huang et al. model with bandwidth term The major limitation of Huang et al. [2014] model is that it ignores limits on memory throughput when memory accesses are coalesced."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 2
                            }
                        ],
                        "text": "5 Huang et al. 2014 model: round-robin policy The performance model by Huang et al. [2014] is the most recent model that we evaluate in this text."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15282249,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "702ad24deb683795e03ff1a79e96afb73cb4d988",
            "isKey": true,
            "numCitedBy": 36,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "GPU has become a first-order computing plat-form. Nonetheless, not many performance modeling techniques have been developed for architecture studies. Several GPU analytical performance models have been proposed, but they mostly target application optimizations rather than the study of different architecture design options. Interval analysis is a relatively accurate performance modeling technique, which traverses the instruction trace and uses functional simulators, e.g., Cache simulator, to track the stall events that cause performance loss. It shows hundred times of speedup compared to detailed timing simulations and better accuracy compared to pure analytical models. However, previous techniques are limited to CPUs and not applicable to multithreaded architectures. In this work, we propose GPU Mech, an interval analysis-based performance modeling technique for GPU architectures. GPU Mech models multithreading and resource contentions caused by memory divergence. We compare GPU Mech with a detailed timing simulator and show that on average, GPU Mechhas 13.2% error for modeling the round-robin scheduling policy and 14.0% error for modeling the greedy-then-oldest policy while achieving a 97x faster simulation speed. In addition, GPU Mech generates CPI stacks, which help hardware/software developers to visualize performance bottlenecks of a kernel."
            },
            "slug": "GPUMech:-GPU-Performance-Modeling-Technique-Based-Huang-Lee",
            "title": {
                "fragments": [],
                "text": "GPUMech: GPU Performance Modeling Technique Based on Interval Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work proposes GPU Mech, an interval analysis-based performance modeling technique for GPU architectures that models multithreading and resource contentions caused by memory divergence, and generates CPI stacks, which help hardware/software developers to visualize performance bottlenecks of a kernel."
            },
            "venue": {
                "fragments": [],
                "text": "2014 47th Annual IEEE/ACM International Symposium on Microarchitecture"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46772960"
                        ],
                        "name": "Xi E. Chen",
                        "slug": "Xi-E.-Chen",
                        "structuredName": {
                            "firstName": "Xi",
                            "lastName": "Chen",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xi E. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742561"
                        ],
                        "name": "Tor M. Aamodt",
                        "slug": "Tor-M.-Aamodt",
                        "structuredName": {
                            "firstName": "Tor",
                            "lastName": "Aamodt",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tor M. Aamodt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 8
                            }
                        ],
                        "text": "[1990], Chen and Aamodt [2009], and Huang et al. [2014] model the gradual saturation effect but not some of the other factors that are important on GPUs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 94
                            }
                        ],
                        "text": "13 Models with no memory bandwidth limits Some of the previously published models, such as by Chen and Aamodt [2009] and Huang et al. [2014], also include a component similar to our latency bound."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 94
                            }
                        ],
                        "text": "13 Models with no memory bandwidth limits Some of the previously published models, such as by Chen and Aamodt [2009] and Huang et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1231,
                                "start": 94
                            }
                        ],
                        "text": "13 Models with no memory bandwidth limits Some of the previously published models, such as by Chen and Aamodt [2009] and Huang et al. [2014], also include a component similar to our latency bound. Yet, they don\u2019t include similar throughput bounds, in particular the bound due to the limited memory throughput. Chen and Aamodt [2009] suggest four models for processors such as Sun\u2019s Niagara, which are not GPUs, but are also fine-grained multithreaded. None of these models consider memory bandwidth. Suppose that all executed threads are similar, as in our kernel, and \uf06c is the throughput when executing one thread at a time. Then, their first three models can be summarized as \uf06c1(n) = \uf06c, \uf06c2(n) = n\uf06c, \uf06c3(n) = 1 \u2013 (1 \u2013 \uf06c), where \uf06c1(n), \uf06c2(n), and \uf06c3(n) are the estimated throughputs when executing n threads at a time. The first model ignores any effect of multithreading. The second model is similar to our latency bound but with no throughput bounds. The third model includes one throughput bound: 1 IPC for instruction issue. Also, it features a model for the gradual saturation effect. Their fourth model is more complex, suggests no simple closed-form solutions, and still doesn\u2019t include memory bandwidth. Huang et al. [2014] propose a GPU performance model where limits on memory bandwidth are not considered if all memory accesses are coalesced."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 333,
                                "start": 94
                            }
                        ],
                        "text": "13 Models with no memory bandwidth limits Some of the previously published models, such as by Chen and Aamodt [2009] and Huang et al. [2014], also include a component similar to our latency bound. Yet, they don\u2019t include similar throughput bounds, in particular the bound due to the limited memory throughput. Chen and Aamodt [2009] suggest four models for processors such as Sun\u2019s Niagara, which are not GPUs, but are also fine-grained multithreaded."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15868982,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9d48b6dc8d9086d66f3ce3a12b33b3a9025d35f3",
            "isKey": true,
            "numCitedBy": 93,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Analytical modeling is an alternative to detailed performance simulation with the potential to shorten the development cycle and provide additional insights. This paper proposes analytical models for predicting the cache contention and throughput of heavily multithreaded architectures such as Sun Microsystems' Niagara. First, it proposes a novel probabilistic model to accurately predict the number of extra cache misses due to cache contention for significantly larger numbers of threads than possible with prior analytical cache contention models. Then it presents a Markov chain model for analytically estimating the throughput of multicore, fine-grained multithreaded architectures. The Markov model uses the number of stalled threads as the states and calculates transition probabilities based upon the rates and latencies of events stalling a thread. By modeling the overlapping of the stalls among threads and taking account of cache contention our models accurately predict system throughput obtained from a cycle-accurate performance simulator with an average error of 7.9%. We also demonstrate the application of our model to a design problem\u2014optimizing the design of fine-grained multithreaded chip multiprocessors for application-specific workloads\u2014yielding the same result as detailed simulations 65 times faster. Moreover, this paper shows that our models accurately predict cache contention and throughput trends across varying workloads on real hardware\u2014a Sun Fire T1000 server."
            },
            "slug": "A-first-order-fine-grained-multithreaded-throughput-Chen-Aamodt",
            "title": {
                "fragments": [],
                "text": "A first-order fine-grained multithreaded throughput model"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A novel probabilistic model is proposed to accurately predict the number of extra cache misses due to cache contention for significantly larger numbers of threads than possible with prior analytical cache contention models."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE 15th International Symposium on High Performance Computer Architecture"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2080795"
                        ],
                        "name": "A. Klaiber",
                        "slug": "A.-Klaiber",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Klaiber",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Klaiber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36105267"
                        ],
                        "name": "H. Levy",
                        "slug": "H.-Levy",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Levy",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Levy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 52
                            }
                        ],
                        "text": "Similar latency on a GT200 GPU was earlier noted by Lai and Seznec [2012]. Global memory access instructions may incur a larger ILP latency."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 0
                            }
                        ],
                        "text": "Lai and Seznec [2013] and Gray [2014] reverse engineered how registers are mapped to register banks on Kepler and Maxwell GPUs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1079,
                                "start": 52
                            }
                        ],
                        "text": "Similar latency on a GT200 GPU was earlier noted by Lai and Seznec [2012]. Global memory access instructions may incur a larger ILP latency. For example, store instructions on the Fermi GPU, according to our study, cannot be issued more often than once in 34 cycles, as shown in Listing 3.2, center. This is if one warp is executed at a time, and all accesses are fully coalesced. ILP latencies for load instructions may even be larger and have a complicated structure, as shown in the same listing, right. The first five instructions in the example are issued 6 cycles after one another, except that the fourth instruction is issued 26 cycles after the third. What is more notable, is that the sixth instruction is issued 482 cycles after the fifth. This delay is about as long as memory latency itself, which equals approximately 513 cycles on this GPU (as we find in Chapter 6, Table 6.2). The delay may be due to a limitation on the number of concurrently processed memory loads allowed for each individual warp. This limitation was studied earlier by Nugteren et al. [2014]. Similar long sequences of independent instructions are common in highly optimized kernels such as matrix multiply [Volkov and Demmel 2008; Gray 2014], FFT [Volkov and Kazian 2008] and radix sort [Merrill and Grimshaw 2010]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1899747,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6de7f47715cd27b8305c80ecfac7a2a36f8ecbc9",
            "isKey": true,
            "numCitedBy": 151,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an architecture and related compiler support for software-controlled daia prefetching, a technique to hide memory latency in high-performance processors. At compile-time, FETCB instructions are inserted into the instruction-stream by the compiler, based on anticipated data references and detailed information about the memory system. At run time, a separate functional unit in the CPU, the fe tch uni t , interprets these instructions and initiates appropriate memory reads. Prefetched data is kept in a small, fullyassociative cache, called the fetchbuffer, to reduce contention with the conventional direct-mapped cache. We also introduce a prewrileback technique that can reduce the impact.of stalls due to replacement writebacks in the cache. A detailed hardware model is presented and the required compiler support is developed. Simulations based on a MIPS processor model show that this technique can dramatically reduce on-chip cache miss ratios and average observed memory latency for scientific loops at only slight cost in total memory traffic."
            },
            "slug": "An-architecture-for-software-controlled-data-Klaiber-Levy",
            "title": {
                "fragments": [],
                "text": "An architecture for software-controlled data prefetching"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Simulations based on a MIPS processor model show that this technique can dramatically reduce on-chip cache miss ratios and average observed memory latency for scientific loops at only slight cost in total memory traffic."
            },
            "venue": {
                "fragments": [],
                "text": "[1991] Proceedings. The 18th Annual International Symposium on Computer Architecture"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40619503"
                        ],
                        "name": "R. Saavedra",
                        "slug": "R.-Saavedra",
                        "structuredName": {
                            "firstName": "Rafael",
                            "lastName": "Saavedra",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Saavedra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706858"
                        ],
                        "name": "D. Culler",
                        "slug": "D.-Culler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Culler",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Culler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1934623"
                        ],
                        "name": "T. V. Eicken",
                        "slug": "T.-V.-Eicken",
                        "structuredName": {
                            "firstName": "Thorsten",
                            "lastName": "Eicken",
                            "middleNames": [
                                "von"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. V. Eicken"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 48
                            }
                        ],
                        "text": "In this case, we solve (n \u2013 1)  (R + C) \u2265 L and get [Saavedra-Barrera et al. 1990, Eq."
                    },
                    "intents": []
                }
            ],
            "corpusId": 12224240,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "144e5294c5481bf83986308ddd4682d1e685647a",
            "isKey": false,
            "numCitedBy": 156,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Multithreading has been proposed as an architectural strategy for tolerating latency on multiprocessors and, through limited empirical studies shows to offer promise. This paper develops an analytical models of multi threaded processor behavior based on a small set of architectural and program parameters. The model gives rise to a large Markov chain, which is solved to obtain a formula for processor in terms of the number of threads). transition, and saturation efficiency depends only on the remorse reference rate and switch case. Formulas for regime boundaries are derived. The model is embellished to reflect cache degradation due to multithreading, using an analytical model of cache behavior, demonstrating that returns diminish as the number threads becomes large. Predictions from the embellished model correlate will with published empirical measurements. Prescriptive use of the model under various scenarios indicates that multithreading is effective But the number of useful threads per processor is fairly small."
            },
            "slug": "Analysis-of-multithreaded-architectures-for-Saavedra-Culler",
            "title": {
                "fragments": [],
                "text": "Analysis of multithreaded architectures for parallel computing"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Prescriptive use of the model under various scenarios indicates that multithreading is effective, and an analytical models of multi threaded processor behavior based on a small set of architectural and program parameters are developed."
            },
            "venue": {
                "fragments": [],
                "text": "SPAA '90"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118389666"
                        ],
                        "name": "Yao Zhang",
                        "slug": "Yao-Zhang",
                        "structuredName": {
                            "firstName": "Yao",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yao Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758404"
                        ],
                        "name": "John Douglas Owens",
                        "slug": "John-Douglas-Owens",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Owens",
                            "middleNames": [
                                "Douglas"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Douglas Owens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 4
                            }
                        ],
                        "text": "7.3 Zhang and Owens 2011 model The GPU performance model by Zhang and Owens [2011] is the first to be accurate in both \u03b1 = 0 and \u03b1 = \u221e limits."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "Zhang and Owens 2011 model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98 \u00a7 7.4."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 3
                            }
                        ],
                        "text": "6: Zhang and Owens [2011] model and our model on the newer GPUs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10246721,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e4827160affa489adc4d80a2ffa3bfa7ac2a00a8",
            "isKey": true,
            "numCitedBy": 275,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a microbenchmark-based performance model for NVIDIA GeForce 200-series GPUs. Our model identifies GPU program bottlenecks and quantitatively analyzes performance, and thus allows programmers and architects to predict the benefits of potential program optimizations and architectural improvements. In particular, we use a microbenchmark-based approach to develop a throughput model for three major components of GPU execution time: the instruction pipeline, shared memory access, and global memory access. Because our model is based on the GPU's native instruction set, we can predict performance with a 5\u201315% error. To demonstrate the usefulness of the model, we analyze three representative real-world and already highly-optimized programs: dense matrix multiply, tridiagonal systems solver, and sparse matrix vector multiply. The model provides us detailed quantitative analysis on performance, allowing us to understand the configuration of the fastest dense matrix multiply implementation and to optimize the tridiagonal solver and sparse matrix vector multiply by 60% and 18% respectively. Furthermore, our model applied to analysis on these codes allows us to suggest architectural improvements on hardware resource allocation, avoiding bank conflicts, block scheduling, and memory transaction granularity."
            },
            "slug": "A-quantitative-performance-analysis-model-for-GPU-Zhang-Owens",
            "title": {
                "fragments": [],
                "text": "A quantitative performance analysis model for GPU architectures"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A microbenchmark-based performance model is developed for NVIDIA GeForce 200-series GPUs that identifies GPU program bottlenecks and quantitatively analyzes performance, and thus allows programmers and architects to predict the benefits of potential program optimizations and architectural improvements."
            },
            "venue": {
                "fragments": [],
                "text": "2011 IEEE 17th International Symposium on High Performance Computer Architecture"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144647854"
                        ],
                        "name": "A. Agarwal",
                        "slug": "A.-Agarwal",
                        "structuredName": {
                            "firstName": "Anant",
                            "lastName": "Agarwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Agarwal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 832,
                                "start": 11
                            }
                        ],
                        "text": "[1990] and Agarwal [1989]. These processors switch to a different thread only on long latency events, such as stalls on memory accesses; arithmetic latencies, thus, are not hidden by multithreading. In this respect, these models are similar to Hong and Kim model, which also implies that warps are switched only on memory accesses. The models are derived as follows. Suppose each context switch takes C cycles, which is typically a non-zero number for coarse-grained multithreading, memory latency is L cycles, and each thread is executed for R cycles until stalling on a memory access. If n threads are executed at the same time, then each stall can be overlapped with execution of n \u2013 1 threads and n context switches. Therefore, latency is hidden if (n \u2013 1) \uf0d7 R + n \uf0d7 C \u2265 L. Solving this for n gives (Section 2 in Agarwal [1989], here in a different notation):"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 11
                            }
                        ],
                        "text": "[1990] and Agarwal [1989]. These processors switch to a different thread only on long latency events, such as stalls on memory accesses; arithmetic latencies, thus, are not hidden by multithreading."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 26470455,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ae0a1d4a0566727d7f265232e6fcf2144b3beddb",
            "isKey": false,
            "numCitedBy": 201,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "An analytical performance model for multithreaded processors that includes cache interference, network contention, context-switching overhead, and data-sharing effects is presented. The model is validated through the author's simulations and by comparison with previously published simulation results. The results indicate that processors can substantially benefit from multithreading, even in systems with small caches, provided sufficient network bandwidth exists. Caches that are much larger than the working-set sizes of individual processes yield close to full processor utilization with as few as two to four contexts. Smaller caches require more contexts to keep the processor busy, while caches that are comparable in size to the working-sets of individual processes cannot achieve a high utilization regardless of the number of contexts. Increased network contention due to multithreading has a major effect on performance. The available network bandwidth and the context-switching overhead limits the best possible utilization. >"
            },
            "slug": "Performance-Tradeoffs-in-Multithreaded-Processors-Agarwal",
            "title": {
                "fragments": [],
                "text": "Performance Tradeoffs in Multithreaded Processors"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "An analytical performance model for multithreaded processors that includes cache interference, network contention, context-switching overhead, and data-sharing effects is presented and indicates that processors can substantially benefit from multithreading, even in systems with small caches, provided sufficient network bandwidth exists."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Parallel Distributed Syst."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41170272"
                        ],
                        "name": "Jaewoong Sim",
                        "slug": "Jaewoong-Sim",
                        "structuredName": {
                            "firstName": "Jaewoong",
                            "lastName": "Sim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jaewoong Sim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1860287"
                        ],
                        "name": "A. Dasgupta",
                        "slug": "A.-Dasgupta",
                        "structuredName": {
                            "firstName": "Aniruddha",
                            "lastName": "Dasgupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dasgupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8187053"
                        ],
                        "name": "Hyesoon Kim",
                        "slug": "Hyesoon-Kim",
                        "structuredName": {
                            "firstName": "Hyesoon",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hyesoon Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771649"
                        ],
                        "name": "R. Vuduc",
                        "slug": "R.-Vuduc",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Vuduc",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Vuduc"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 134
                            }
                        ],
                        "text": "The total processing time in CUDA cores in our example, per the repeating group of \u03b1+1 instructions, is found as (Equations 2 to 6 in Sim et al. [2012]):"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 0
                            }
                        ],
                        "text": "Sim et al. 2012 model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100 \u00a7 7.5."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 71
                            }
                        ],
                        "text": "This approach, with refinements, appears in Zhang and Owens [2011] and Sim et al. [2012]. It suffers from a similar difficulty: throughputs found when considering different instruction types in isolation don\u2019t apply in general."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 4
                            }
                        ],
                        "text": "7.4 Sim et al. 2012 model The Sim et al. [2012] model is a further development of the Hong and Kim model discussed before."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 3
                            }
                        ],
                        "text": "7: Sim et al. [2012] model and our model compared to the experiment."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 1
                            }
                        ],
                        "text": "(Sim et al. [2012] suggest a slightly more complicated merging procedure."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6817445,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a5eb8900450908f3e245c3740420af4cb2348ef8",
            "isKey": true,
            "numCitedBy": 197,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Tuning code for GPGPU and other emerging many-core platforms is a challenge because few models or tools can precisely pinpoint the root cause of performance bottlenecks. In this paper, we present a performance analysis framework that can help shed light on such bottlenecks for GPGPU applications. Although a handful of GPGPU profiling tools exist, most of the traditional tools, unfortunately, simply provide programmers with a variety of measurements and metrics obtained by running applications, and it is often difficult to map these metrics to understand the root causes of slowdowns, much less decide what next optimization step to take to alleviate the bottleneck. In our approach, we first develop an analytical performance model that can precisely predict performance and aims to provide programmer-interpretable metrics. Then, we apply static and dynamic profiling to instantiate our performance model for a particular input code and show how the model can predict the potential performance benefits. We demonstrate our framework on a suite of micro-benchmarks as well as a variety of computations extracted from real codes."
            },
            "slug": "A-performance-analysis-framework-for-identifying-in-Sim-Dasgupta",
            "title": {
                "fragments": [],
                "text": "A performance analysis framework for identifying potential benefits in GPGPU applications"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper develops an analytical performance model that can precisely predict performance and aims to provide programmer-interpretable metrics and demonstrates how the model can predict the potential performance benefits of GPGPU applications."
            },
            "venue": {
                "fragments": [],
                "text": "PPoPP '12"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145687683"
                        ],
                        "name": "V. Volkov",
                        "slug": "V.-Volkov",
                        "structuredName": {
                            "firstName": "Vasily",
                            "lastName": "Volkov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Volkov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700326"
                        ],
                        "name": "J. Demmel",
                        "slug": "J.-Demmel",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Demmel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Demmel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 115
                            }
                        ],
                        "text": "Similar long sequences of independent instructions are common in highly optimized kernels such as matrix multiply [Volkov and Demmel 2008; Gray 2014], FFT [Volkov and Kazian 2008] and radix sort [Merrill and Grimshaw 2010]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 426657,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ec98ae3e4f5724af4d7b052dd37f7b5b48310d98",
            "isKey": false,
            "numCitedBy": 900,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We present performance results for dense linear algebra using recent NVIDIA GPUs. Our matrix-matrix multiply routine (GEMM) runs up to 60% faster than the vendor's implementation and approaches the peak of hardware capabilities. Our LU, QR and Cholesky factorizations achieve up to 80-90% of the peak GEMM rate. Our parallel LU running on two GPUs achieves up to ~540 Gflop/s. These results are accomplished by challenging the accepted view of the GPU architecture and programming guidelines. We argue that modern GPUs should be viewed as multithreaded multicore vector units. We exploit blocking similarly to vector computers and heterogeneity of the system by computing both on GPU and CPU. This study includes detailed benchmarking of the GPU memory system that reveals sizes and latencies of caches and TLB. We present a couple of algorithmic optimizations aimed at increasing parallelism and regularity in the problem that provide us with slightly higher performance."
            },
            "slug": "Benchmarking-GPUs-to-tune-dense-linear-algebra-Volkov-Demmel",
            "title": {
                "fragments": [],
                "text": "Benchmarking GPUs to tune dense linear algebra"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "It is argued that modern GPUs should be viewed as multithreaded multicore vector units and exploit blocking similarly to vector computers and heterogeneity of the system by computing both on GPU and CPU."
            },
            "venue": {
                "fragments": [],
                "text": "2008 SC - International Conference for High Performance Computing, Networking, Storage and Analysis"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40583265"
                        ],
                        "name": "Junjie Lai",
                        "slug": "Junjie-Lai",
                        "structuredName": {
                            "firstName": "Junjie",
                            "lastName": "Lai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junjie Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743857"
                        ],
                        "name": "Andr\u00e9 Seznec",
                        "slug": "Andr\u00e9-Seznec",
                        "structuredName": {
                            "firstName": "Andr\u00e9",
                            "lastName": "Seznec",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andr\u00e9 Seznec"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 121
                            }
                        ],
                        "text": "The two modes are similar to asymptotic bounds on performance of concurrent systems discussed in classical work, such as Lazowska et al. [1984] and Jain [1991]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3242763,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9eaa5628b3458a2bdfb6d7423b5e76c768d9e710",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present an approach to estimate GPU applications' performance upper bound based on algorithm analysis and assembly code level benchmarking. As an example, we analyze the potential peak performance of SGEMM (Single-precision General Matrix Multiply) on Fermi (GF110) and Kepler (GK104) GPUs. We try to answer the question of how much optimization space is left for SGEMM and why. According to our analysis, the nature of Fermi (Kepler) instruction set and the limited issue throughput of the schedulers are the main limitation factors for SGEMM to approach the theoretical peak performance. The estimated upper-bound peak performance of SGEMM is around 82.5% of the theoretical peak performance on GTX580 Fermi GPU and 57.6% on GTX680 Kepler GPU. Guided by this analysis and using the native assembly language, on average, our SGEMM implementations achieve about 5% better performance than CUBLAS in CUDA 4.1 SDK for large matrices on GTX580. The achieved performance is around 90% of the estimated upper-bound performance of SGEMM on GTX580. On GTX680, the best performance we achieve is around 77.3% of the estimated performance upper bound. We also describe how to use native assembly language directly in the CUDA runtime source code."
            },
            "slug": "Performance-upper-bound-analysis-and-optimization-Lai-Seznec",
            "title": {
                "fragments": [],
                "text": "Performance upper bound analysis and optimization of SGEMM on Fermi and Kepler GPUs"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "An approach to estimate GPU applications' performance upper bound based on algorithm analysis and assembly code level benchmarking and how to use native assembly language directly in the CUDA runtime source code is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2013 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761103"
                        ],
                        "name": "Timo Aila",
                        "slug": "Timo-Aila",
                        "structuredName": {
                            "firstName": "Timo",
                            "lastName": "Aila",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timo Aila"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36436218"
                        ],
                        "name": "S. Laine",
                        "slug": "S.-Laine",
                        "structuredName": {
                            "firstName": "Samuli",
                            "lastName": "Laine",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Laine"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 47
                            }
                        ],
                        "text": "Another practice is to use persistent threads [Aila and Laine 2009]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15392840,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49a92d7b09bae22cbd7aaad9c99d90dc9c0bcb41",
            "isKey": false,
            "numCitedBy": 456,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We discuss the mapping of elementary ray tracing operations---acceleration structure traversal and primitive intersection---onto wide SIMD/SIMT machines. Our focus is on NVIDIA GPUs, but some of the observations should be valid for other wide machines as well. While several fast GPU tracing methods have been published, very little is actually understood about their performance. Nobody knows whether the methods are anywhere near the theoretically obtainable limits, and if not, what might be causing the discrepancy. We study this question by comparing the measurements against a simulator that tells the upper bound of performance for a given kernel. We observe that previously known methods are a factor of 1.5--2.5X off from theoretical optimum, and most of the gap is not explained by memory bandwidth, but rather by previously unidentified inefficiencies in hardware work distribution. We then propose a simple solution that significantly narrows the gap between simulation and measurement. This results in the fastest GPU ray tracer to date. We provide results for primary, ambient occlusion and diffuse interreflection rays."
            },
            "slug": "Understanding-the-efficiency-of-ray-traversal-on-Aila-Laine",
            "title": {
                "fragments": [],
                "text": "Understanding the efficiency of ray traversal on GPUs"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A simple solution is proposed that significantly narrows the gap between simulation and measurement, and results in the fastest GPU ray tracer to date."
            },
            "venue": {
                "fragments": [],
                "text": "High Performance Graphics"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1773596"
                        ],
                        "name": "J. Stratton",
                        "slug": "J.-Stratton",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Stratton",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Stratton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2012705"
                        ],
                        "name": "C. Rodrigues",
                        "slug": "C.-Rodrigues",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Rodrigues",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rodrigues"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38699517"
                        ],
                        "name": "I-Jui Sung",
                        "slug": "I-Jui-Sung",
                        "structuredName": {
                            "firstName": "I-Jui",
                            "lastName": "Sung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I-Jui Sung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2409502"
                        ],
                        "name": "N. Obeid",
                        "slug": "N.-Obeid",
                        "structuredName": {
                            "firstName": "Nady",
                            "lastName": "Obeid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Obeid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48319011"
                        ],
                        "name": "Li-Wen Chang",
                        "slug": "Li-Wen-Chang",
                        "structuredName": {
                            "firstName": "Li-Wen",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-Wen Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48798569"
                        ],
                        "name": "N. Anssari",
                        "slug": "N.-Anssari",
                        "structuredName": {
                            "firstName": "Nasser",
                            "lastName": "Anssari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Anssari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109614818"
                        ],
                        "name": "Geng Liu",
                        "slug": "Geng-Liu",
                        "structuredName": {
                            "firstName": "Geng",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geng Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143668320"
                        ],
                        "name": "W. Hwu",
                        "slug": "W.-Hwu",
                        "structuredName": {
                            "firstName": "Wen-mei",
                            "lastName": "Hwu",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hwu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 497928,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f3cce1bc739ebfc03e003010d3438bb318efc14",
            "isKey": false,
            "numCitedBy": 667,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The Parboil benchmarks are a set of throughput computing applications useful for studying the performance of throughput computing architecture and compilers. The name comes from the culinary term for a partial cooking process, which represents our belief that useful throughput computing benchmarks must be \u201ccooked\u201d, or preselected to implement a scalable algorithm with fine-grained paralle l tasks. But useful benchmarks for this field cannot be \u201cfully cooked\u201d, because the architectures and programming models and supporting tools are evolving rapidly enough that static benchmark codes will lose relevance very quickly. We have collected benchmarks from throughput computing application researchers in many different scientific and commercial fields including image processing, biomolec ular simulation, fluid dynamics, and astronomy. Each benchmark includes several implementations. Some implementations we provide as readable base implementations from which new optimization efforts can begin, and others as examples of the current state-of-the-art targeting specific CPU and GPU architectures. As we continue to optimiz e these benchmarks for new and existing architectures ourselves, we will also gladly accept new implementations and benchmark contributions from developers to recognize those at the frontier of performance optimization on each architecture. Finally, by including versions of varying levels of optimization of the same fundamental algorithm, the benchmarks present opportunities to demonstrate tools and architectures that help programmers get the most out of their parallel hardware. Less optimized versions are presented as challenges to the compiler and architecture research communities: to develop the technology that automatically raises the performance of simpler implementations to the performance level of sophisticated programmer-optimized implementations, or demonstrate any other performance or programmability improvements. We hope that these benchmarks will facilitate effective demonstrations of such technology."
            },
            "slug": "Parboil:-A-Revised-Benchmark-Suite-for-Scientific-Stratton-Rodrigues",
            "title": {
                "fragments": [],
                "text": "Parboil: A Revised Benchmark Suite for Scientific and Commercial Throughput Computing"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "By including versions of varying levels of optimization of the same fundamental algorithm, the Parboil benchmarks present opportunities to demonstrate tools and architectures that help programmers get the most out of their parallel hardware."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66842373"
                        ],
                        "name": "G. Ruetsch",
                        "slug": "G.-Ruetsch",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Ruetsch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Ruetsch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2543296"
                        ],
                        "name": "M. Fatica",
                        "slug": "M.-Fatica",
                        "structuredName": {
                            "firstName": "Massimiliano",
                            "lastName": "Fatica",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fatica"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 40
                            }
                        ],
                        "text": "104 Indeed, if we use the data given in Sim et al. [2012] for the C2050 GPU, we find that MWPpeak_bw = 30."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 99
                            }
                        ],
                        "text": "Memory bandwidth is also not considered in some of the early models for latency hiding, such as by Saavedra-Barrera et al. [1990] and Mowry et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58847080,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "acb889a012e78e1ed2a8e0ed48186e792f3d3168",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "CUDA Fortran for Scientists and Engineers shows how high-performance application developers can leverage the power of GPUs using Fortran, the familiar language of scientific computing and supercomputer performance benchmarking. The authors presume no prior parallel computing experience, and cover the basics along with best practices for efficient GPU computing using CUDA Fortran. To help you add CUDA Fortran to existing Fortran codes, the book explains how to understand the target GPU architecture, identify computationally intensive parts of the code, and modify the code to manage the data and parallelism and optimize performance. All of this is done in Fortran, without having to rewrite in another language. Each concept is illustrated with actual examples so you can immediately evaluate the performance of your code in comparison.Leverage the power of GPU computing with PGI's CUDA Fortran compilerGain insights from members of the CUDA Fortran language development teamIncludes multi-GPU programming in CUDA Fortran, covering both peer-to-peer and message passing interface (MPI) approachesIncludes full source code for all the examples and several case studies Download source code and slides from the book's companion website"
            },
            "slug": "CUDA-Fortran-for-Scientists-and-Engineers:-Best-for-Ruetsch-Fatica",
            "title": {
                "fragments": [],
                "text": "CUDA Fortran for Scientists and Engineers: Best Practices for Efficient CUDA Fortran Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This book explains how to understand the target GPU architecture, identify computationally intensive parts of the code, and modify the code to manage the data and parallelism and optimize performance, all of this is done in Fortran."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2782714"
                        ],
                        "name": "J. Nickolls",
                        "slug": "J.-Nickolls",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Nickolls",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Nickolls"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144437216"
                        ],
                        "name": "I. Buck",
                        "slug": "I.-Buck",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Buck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Buck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144764367"
                        ],
                        "name": "M. Garland",
                        "slug": "M.-Garland",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Garland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Garland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735065"
                        ],
                        "name": "K. Skadron",
                        "slug": "K.-Skadron",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Skadron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Skadron"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7344254,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a234864ad768c43a8dd4c2f8efd95051209da851",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The advent of multicore CPUs and manycore GPUs means that mainstream processor chips are now parallel systems. Furthermore, their parallelism continues to scale with Moore's law. The challenge is to develop mainstream application software that transparently scales its parallelism to leverage the increasing number of processor cores, much as 3D graphics applications transparently scale their parallelism to manycore GPUs with widely varying numbers of cores."
            },
            "slug": "Scalable-parallel-programming-Nickolls-Buck",
            "title": {
                "fragments": [],
                "text": "Scalable parallel programming"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The challenge is to develop mainstream application software that transparently scales its parallelism to leverage the increasing number of processor cores, much as 3D graphics applications transparently scale their Parallelism to manycore GPUs with widely varying numbers of cores."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Hot Chips 20 Symposium (HCS)"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143937132"
                        ],
                        "name": "Mark J. Harris",
                        "slug": "Mark-J.-Harris",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Harris",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark J. Harris"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 59
                            }
                        ],
                        "text": "The only degrees of freedom kept are arithmetic intensity [Harris 2005; Williams et al. 2009] and occupancy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8212423,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc74b356b6d8c7ae793d4355301f64fde3c89a1d",
            "isKey": false,
            "numCitedBy": 222,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, graphics processors have emerged as a powerful computational platform. A variety of encouraging results, mostly from researchers using GPUs to accelerate scientific computing and visualization applications, have shown that significant speedups can be achieved by applying GPUs to data-parallel computational problems. However, attaining these speedups requires knowledge of GPU programming and architecture.The preceding chapters have described the architecture of modern GPUs and the trends that govern their performance and design. Continuing from the concepts introduced in those chapters, in this chapter we present intuitive mappings of standard computational concepts onto the special-purpose features of GPUs. After presenting the basics, we introduce a simple GPU programming framework and demonstrate the use of the framework in a short sample program."
            },
            "slug": "Mapping-computational-concepts-to-GPUs-Harris",
            "title": {
                "fragments": [],
                "text": "Mapping computational concepts to GPUs"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This chapter presents intuitive mappings of standard computational concepts onto the special-purpose features of GPUs and introduces a simple GPU programming framework and demonstrates the use of the framework in a short sample program."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH Courses"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1572502788"
                        ],
                        "name": "AngryCalc",
                        "slug": "AngryCalc",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "AngryCalc",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "AngryCalc"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 895,
                                "start": 168
                            }
                        ],
                        "text": "The specifications suggest that this throughput must be 8 ops/cycle per SM as there are 16 banks per SM and each bank is capable of fetching a new word every 2 cycles [NVIDIA 2010a]. In practice, we find that this throughput never exceeds 6 ops/cycle. A similar finding is reported in Volkov and Demmel [2008]. Another number that requires a commentary is the throughput of floating-point adds on the Kepler GPU. This GPU has 48 CUDA cores per scheduler, but the best recorded throughput is only 32 ops/cycle per scheduler. This is the expected number when no instruction-level parallelism (ILP) is present in the executed code: dual-issue in this case is not possible, and throughput is bound by warp schedulers, not CUDA cores. Our best sustained throughputs approach theoretical peak numbers better than similar numbers reported in some of the prior work. For example, Zhang and Owens [2011] report sustaining only 84% of theoretical peak in executing CUDA core instructions on a GT200 GPU (Figure 2 in their paper), and Sim et al."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 116
                            }
                        ],
                        "text": "Another source of similar results is the performance models for coarse-grained multithreaded processors, such as by Saavedra-Barrera et al. [1990] and Agarwal [1989]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 51
                            }
                        ],
                        "text": "This effect is recognized in performance models by Sim et al. [2012] and Baghsorkhi et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 1042,
                                "start": 168
                            }
                        ],
                        "text": "The specifications suggest that this throughput must be 8 ops/cycle per SM as there are 16 banks per SM and each bank is capable of fetching a new word every 2 cycles [NVIDIA 2010a]. In practice, we find that this throughput never exceeds 6 ops/cycle. A similar finding is reported in Volkov and Demmel [2008]. Another number that requires a commentary is the throughput of floating-point adds on the Kepler GPU. This GPU has 48 CUDA cores per scheduler, but the best recorded throughput is only 32 ops/cycle per scheduler. This is the expected number when no instruction-level parallelism (ILP) is present in the executed code: dual-issue in this case is not possible, and throughput is bound by warp schedulers, not CUDA cores. Our best sustained throughputs approach theoretical peak numbers better than similar numbers reported in some of the prior work. For example, Zhang and Owens [2011] report sustaining only 84% of theoretical peak in executing CUDA core instructions on a GT200 GPU (Figure 2 in their paper), and Sim et al. [2012] report sustaining only 93% of peak throughput in executing CUDA core instructions on a Fermi GPU when not using ILP (Figure 6 in their paper)."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 310,
                                "start": 168
                            }
                        ],
                        "text": "The specifications suggest that this throughput must be 8 ops/cycle per SM as there are 16 banks per SM and each bank is capable of fetching a new word every 2 cycles [NVIDIA 2010a]. In practice, we find that this throughput never exceeds 6 ops/cycle. A similar finding is reported in Volkov and Demmel [2008]. Another number that requires a commentary is the throughput of floating-point adds on the Kepler GPU."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 216687915,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10a14811f5157b7a9ae19000885e817a674f441f",
            "isKey": true,
            "numCitedBy": 15,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The GTX 1050 Ti 4GB is Nvidia\u2019s latest Pascal based GPU. The 1050 Ti has a TDP of 75 Watts and is based on a new 14nm GP107 processing core which has approximately 66% of the key resources (CUDA cores, texture units, memory bandwidth and transistor count etc.) found on the 3GB GTX 1060. Comparing userbenchmarks for the 1050 Ti and 3GB 1060 shows that the 1050 Ti is falling a little short of our expectations but we only have one benchmark for the 1050 Ti so the average score will probably improve as we gather more samples. The list price for the 1050 Ti is $139 which is between AMDs $185 RX 470 and $100 RX 460. Comparing performance between the RX 470 vs GTX 1050 Ti and RX 460 vs GTX 1050 Ti shows that the 1050 Ti sits roughly in the middle for both price and performance.\u00a0[Oct '16\u00a0GPUPro]"
            },
            "slug": "NVIDIA-GeForce-GTX-1050-Ti-AngryCalc",
            "title": {
                "fragments": [],
                "text": "NVIDIA GeForce GTX 1050 Ti"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "The GTX 1050 Ti 4GB is Nvidia\u2019s latest Pascal based GPU and is based on a new 14nm GP107 processing core which has approximately 66% of the key resources found on the 3GB GTX 1060."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145687683"
                        ],
                        "name": "V. Volkov",
                        "slug": "V.-Volkov",
                        "structuredName": {
                            "firstName": "Vasily",
                            "lastName": "Volkov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Volkov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104624497"
                        ],
                        "name": "Brian Kazian",
                        "slug": "Brian-Kazian",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Kazian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian Kazian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 8
                            }
                        ],
                        "text": "Fitting FFT onto the G80 architecture."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 156
                            }
                        ],
                        "text": "Similar long sequences of independent instructions are common in highly optimized kernels such as matrix multiply [Volkov and Demmel 2008; Gray 2014], FFT [Volkov and Kazian 2008] and radix sort [Merrill and Grimshaw 2010]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18371335,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb3a82ddfc4e73de18a4004ecb9c1109730ae3eb",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we present a novel implementation of FFT on GeForce 8800GTX that achieves 144 Gflop/s that is nearly 3x faster than best rate achieved in the current vendor\u2019s numerical libraries. This performance is achieved by exploiting the Cooley-Tukey framework to make use of the hardware capabilities, such as the massive vector register files and small on-chip local storage. We also consider performance of the FFT on few other platforms."
            },
            "slug": "Fitting-FFT-onto-the-G-80-Architecture-Volkov-Kazian",
            "title": {
                "fragments": [],
                "text": "Fitting FFT onto the G 80 Architecture"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A novel implementation of FFT on GeForce 8800GTX that achieves 144 Gflop/s that is nearly 3x faster than best rate achieved in the current vendor\u2019s numerical libraries is presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772133"
                        ],
                        "name": "J. Hennessy",
                        "slug": "J.-Hennessy",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hennessy",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hennessy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701130"
                        ],
                        "name": "D. Patterson",
                        "slug": "D.-Patterson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Patterson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Patterson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 387,
                                "start": 0
                            }
                        ],
                        "text": "Hong and Kim [2009] also separately consider what we call latency-bound and throughput-bound modes, but disregard arithmetic latency. This latency is important as we show later in Chapter 4. Sim et al. [2012] improves Hong and Kim model to include arithmetic latency and other factors, but the improved model has other limitations and is not similar to our approach. Huang et al. [2014] suggest a model that includes a similar latency-bound solution, but doesn\u2019t include similar throughput bounds."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 64
                            }
                        ],
                        "text": "Our reference point is the AMAT model for cached memory access [Hennessy and Patterson 2011]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 248,
                                "start": 87
                            }
                        ],
                        "text": "Memory bandwidth is not taken into account in the well-known AMAT model cited earlier [Hennessy and Patterson 2011]. It is not taken into account in some of the early performance models for latency hiding, such as by Saavedra-Barrera et al. [1990] and Mowry et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 0
                            }
                        ],
                        "text": "Hong and Kim [2009] also separately consider what we call latency-bound and throughput-bound modes, but disregard arithmetic latency. This latency is important as we show later in Chapter 4. Sim et al. [2012] improves Hong and Kim model to include arithmetic latency and other factors, but the improved model has other limitations and is not similar to our approach."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 91
                            }
                        ],
                        "text": "This prior work includes CUDA C programming guide [NVIDIA 2015], and performance models by Hong and Kim [2009], Baghsorkhi et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 0
                            }
                        ],
                        "text": "Hong and Kim [2009] also separately consider what we call latency-bound and throughput-bound modes, but disregard arithmetic latency."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 2
                            }
                        ],
                        "text": "\uf0b7 Hong and Kim [2009], \uf0b7 CUDA C Programming Guide [NVIDIA 2015, Ch."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 87
                            }
                        ],
                        "text": "Memory bandwidth is not taken into account in the well-known AMAT model cited earlier [Hennessy and Patterson 2011]. It is not taken into account in some of the early performance models for latency hiding, such as by Saavedra-Barrera et al. [1990] and Mowry et al. [1992]. It is not considered in a recent work on multithreaded (a) Many prior performance models tend to underestimate the occupancy needed to attain a maximum throughput."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 529,
                                "start": 0
                            }
                        ],
                        "text": "Hong and Kim [2009] also separately consider what we call latency-bound and throughput-bound modes, but disregard arithmetic latency. This latency is important as we show later in Chapter 4. Sim et al. [2012] improves Hong and Kim model to include arithmetic latency and other factors, but the improved model has other limitations and is not similar to our approach. Huang et al. [2014] suggest a model that includes a similar latency-bound solution, but doesn\u2019t include similar throughput bounds. Saavedra-Barrera et al. [1990], Chen and Aamodt [2009], and Huang et al."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 87
                            }
                        ],
                        "text": "Memory bandwidth is not taken into account in the well-known AMAT model cited earlier [Hennessy and Patterson 2011]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60915581,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b4324589c4f19d543db286d4c087068a356955d7",
            "isKey": true,
            "numCitedBy": 942,
            "numCiting": 411,
            "paperAbstract": {
                "fragments": [],
                "text": "The computing world today is in the middle of a revolution: mobile clients and cloud computing have emerged as the dominant paradigms driving programming and hardware innovation today. The Fifth Edition of Computer Architecture focuses on this dramatic shift, exploring the ways in which software and technology in the \"cloud\" are accessed by cell phones, tablets, laptops, and other mobile computing devices. Each chapter includes two real-world examples, one mobile and one datacenter, to illustrate this revolutionary change. Updated to cover the mobile computing revolutionEmphasizes the two most important topics in architecture today: memory hierarchy and parallelism in all its forms.Develops common themes throughout each chapter: power, performance, cost, dependability, protection, programming models, and emerging trends (\"What's Next\")Includes three review appendices in the printed text. Additional reference appendices are available online.Includes updated Case Studies and completely new exercises."
            },
            "slug": "Computer-Architecture,-Fifth-Edition:-A-Approach-Hennessy-Patterson",
            "title": {
                "fragments": [],
                "text": "Computer Architecture, Fifth Edition: A Quantitative Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The Fifth Edition of Computer Architecture focuses on this dramatic shift in the ways in which software and technology in the \"cloud\" are accessed by cell phones, tablets, laptops, and other mobile computing devices."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789983"
                        ],
                        "name": "C. Wittenbrink",
                        "slug": "C.-Wittenbrink",
                        "structuredName": {
                            "firstName": "Craig",
                            "lastName": "Wittenbrink",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wittenbrink"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2120741"
                        ],
                        "name": "Emmett Kilgariff",
                        "slug": "Emmett-Kilgariff",
                        "structuredName": {
                            "firstName": "Emmett",
                            "lastName": "Kilgariff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Emmett Kilgariff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40207754"
                        ],
                        "name": "A. Prabhu",
                        "slug": "A.-Prabhu",
                        "structuredName": {
                            "firstName": "Arjun",
                            "lastName": "Prabhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Prabhu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 4
                            }
                        ],
                        "text": "4 \uf0b7 Zhang and Owens [2011] (slightly simplified), \uf0b7 Sim et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2997624,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92fd40952fb7561127e325cfb66398fc70c22ff7",
            "isKey": false,
            "numCitedBy": 180,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "The Fermi GF100 is a GPU architecture that provides several new capabilities beyond the Nvidia GT200 or Tesla architecture. The Fermi architecture offers up to 512 CUDA cores and special features for gaming and high-performance computing. This article describes the GPU's new capabilities for tessellation, physics processing, and computational graphics."
            },
            "slug": "Fermi-GF100-GPU-Architecture-Wittenbrink-Kilgariff",
            "title": {
                "fragments": [],
                "text": "Fermi GF100 GPU Architecture"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "The Fermi GF100 is a GPU architecture that provides several new capabilities beyond the Nvidia GT200 or Tesla architecture, including tessellation, physics processing, and computational graphics."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Micro"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2782714"
                        ],
                        "name": "J. Nickolls",
                        "slug": "J.-Nickolls",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Nickolls",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Nickolls"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80724002"
                        ],
                        "name": "W. Dally",
                        "slug": "W.-Dally",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dally",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dally"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1867180,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "039ad1ad259a9bd98e24b0738ba048282188d184",
            "isKey": false,
            "numCitedBy": 938,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "GPU computing is at a tipping point, becoming more widely used in demanding consumer applications and high-performance computing. This article describes the rapid evolution of GPU architectures-from graphics processors to massively parallel many-core multiprocessors, recent developments in GPU computing architectures, and how the enthusiastic adoption of CPU+GPU coprocessing is accelerating parallel applications."
            },
            "slug": "The-GPU-Computing-Era-Nickolls-Dally",
            "title": {
                "fragments": [],
                "text": "The GPU Computing Era"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The rapid evolution of GPU architectures-from graphics processors to massively parallel many-core multiprocessors, recent developments in GPU computing architectures, and how the enthusiastic adoption of CPU+GPU coprocessing is accelerating parallel applications are described."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Micro"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145889709"
                        ],
                        "name": "R. Jain",
                        "slug": "R.-Jain",
                        "structuredName": {
                            "firstName": "Raj",
                            "lastName": "Jain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Jain"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 11
                            }
                        ],
                        "text": "[1984] and Jain [1991]. In the latencybound case we take into account various processor latencies."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 53236245,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e2c16a6e1b9d2c125451fb601acaec61f7caaec8",
            "isKey": false,
            "numCitedBy": 2523,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Partial table of contents: AN OVERVIEW OF PERFORMANCE EVALUATION. Common Mistakes and How to Avoid Them. Selection of Techniques and Metrics. MEASUREMENT TECHNIQUES AND TOOLS. Types of Workloads. Workload Characterization Techniques. Monitors. Ratio Games. PROBABILITY THEORY AND STATISTICS. Summarizing Measured Data. Simple Linear Regression Models. Other Regression Models. EXPERIMENTAL DESIGN AND ANALYSIS. One-Factor Experiments. Two-Factor Full Factorial Design without Replications. Two-Factor Full Factorial Design with Replications. SIMULATION. Analysis of Simulation Results. Testing Random-Number Generators. Commonly Used Distributions. QUEUEING MODELS. Analysis of a Single Queue. Operational Laws. Convolution Algorithm. Appendix. Solutions to Selected Exercises. References. Author Index. Subject Index."
            },
            "slug": "The-art-of-computer-systems-performance-analysis-Jain",
            "title": {
                "fragments": [],
                "text": "The art of computer systems performance analysis - techniques for experimental design, measurement, simulation, and modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This paper presents an overview of performance evaluation in the context of two-Factor Full Factorial Design and Convolution Algorithm, as well as some of the techniques used in designing and analyzing these models."
            },
            "venue": {
                "fragments": [],
                "text": "Wiley professional computing"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701130"
                        ],
                        "name": "D. Patterson",
                        "slug": "D.-Patterson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Patterson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Patterson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772133"
                        ],
                        "name": "J. Hennessy",
                        "slug": "J.-Hennessy",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hennessy",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hennessy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 60693966,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "890469e625fe728adfa690a3945ebca4c11a8998",
            "isKey": false,
            "numCitedBy": 11540,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This best-selling title, considered for over a decade to be essential reading for every serious student and practitioner of computer design, has been updated throughout to address the most important trends facing computer designers today. In this edition, the authors bring their trademark method of quantitative analysis not only to high-performance desktop machine design, but also to the design of embedded and server systems. They have illustrated their principles with designs from all three of these domains, including examples from consumer electronics, multimedia and Web technologies, and high-performance computing."
            },
            "slug": "Computer-Architecture:-A-Quantitative-Approach-Patterson-Hennessy",
            "title": {
                "fragments": [],
                "text": "Computer Architecture: A Quantitative Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This best-selling title, considered for over a decade to be essential reading for every serious student and practitioner of computer design, has been updated throughout to address the most important trends facing computer designers today."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2516040"
                        ],
                        "name": "Erik Lindholm",
                        "slug": "Erik-Lindholm",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Lindholm",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Erik Lindholm"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2782714"
                        ],
                        "name": "J. Nickolls",
                        "slug": "J.-Nickolls",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Nickolls",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Nickolls"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3210618"
                        ],
                        "name": "S. Oberman",
                        "slug": "S.-Oberman",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Oberman",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Oberman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1892041"
                        ],
                        "name": "John Montrym",
                        "slug": "John-Montrym",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Montrym",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Montrym"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 125
                            }
                        ],
                        "text": "81 difference is important on G80 and GT200 GPUs, where each instruction is executed as two sets of 16 threads (half-warps) [Lindholm et al. 2008]. Mei and Chu [2016] report a larger, 28 cycle latency for shared memory accesses on a similar Maxwell GPU, GTX980."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 131
                            }
                        ],
                        "text": "GPU Year Generation Related publications and whitepapers by vendor 8800GTX 2006 G80 NVIDIA [2006] GTX280 2008 GT200 NVIDIA [2008], Lindholm et al. [2008] GTX480 2010 Fermi NVIDIA [2009], NVIDIA [2010b], Wittenbrink et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 191,
                                "start": 171
                            }
                        ],
                        "text": "However, this limit is effective only for CUDA core instructions, as bound by 8 CUDA cores per scheduler and SIMD width 32; the schedulers per se can issue twice as fast [Lindholm et al. 2008, p.45]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 130
                            }
                        ],
                        "text": "This\n81\ndifference is important on G80 and GT200 GPUs, where each instruction is executed as two sets of 16 threads (half-warps) [Lindholm et al. 2008]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 131
                            }
                        ],
                        "text": "GPU Year Generation Related publications and whitepapers by vendor 8800GTX 2006 G80 NVIDIA [2006] GTX280 2008 GT200 NVIDIA [2008], Lindholm et al. [2008] GTX480 2010 Fermi NVIDIA [2009], NVIDIA [2010b], Wittenbrink et al. [2011] GTX680 2012 Kepler NVIDIA [2012a], NVIDIA [2012b] GTX980 2014 Maxwell NVIDIA [2014a], NVIDIA [2014b]"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 122
                            }
                        ],
                        "text": "Note that on a realistic GPU such context switches happen every issue cycle, not only at memory and barrier instructions [Lindholm et al. 2008]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 124
                            }
                        ],
                        "text": "81 difference is important on G80 and GT200 GPUs, where each instruction is executed as two sets of 16 threads (half-warps) [Lindholm et al. 2008]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2793450,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "356869aa0ae8d598e956c7f2ae884bbf5009c98c",
            "isKey": true,
            "numCitedBy": 1414,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "To enable flexible, programmable graphics and high-performance computing, NVIDIA has developed the Tesla scalable unified graphics and parallel computing architecture. Its scalable parallel array of processors is massively multithreaded and programmable in C or via graphics APIs."
            },
            "slug": "NVIDIA-Tesla:-A-Unified-Graphics-and-Computing-Lindholm-Nickolls",
            "title": {
                "fragments": [],
                "text": "NVIDIA Tesla: A Unified Graphics and Computing Architecture"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "To enable flexible, programmable graphics and high-performance computing, NVIDIA has developed the Tesla scalable unified graphics and parallel computing architecture, which is massively multithreaded and programmable in C or via graphics APIs."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Micro"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80724002"
                        ],
                        "name": "W. Dally",
                        "slug": "W.-Dally",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dally",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dally"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762455"
                        ],
                        "name": "B. Towles",
                        "slug": "B.-Towles",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Towles",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Towles"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 85
                            }
                        ],
                        "text": "Similar behavior is known in interconnection networks, as discussed, for example, in Dally and Towles [2003]. The GPU memory system includes a similar interconnection network, which may, at least partially, explain the latency increase."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58820603,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "850225c7c13b4cffa2ee101798f488dfa289ee3e",
            "isKey": false,
            "numCitedBy": 3290,
            "numCiting": 157,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the greatest challenges faced by designers of digital systems is optimizing the communication and interconnection between system components. Interconnection networks offer an attractive and economical solution to this communication crisis and are fast becoming pervasive in digital systems. Current trends suggest that this communication bottleneck will be even more problematic when designing future generations of machines. Consequently, the anatomy of an interconnection network router and science of interconnection network design will only grow in importance in the coming years. \n \nThis book offers a detailed and comprehensive presentation of the basic principles of interconnection network design, clearly illustrating them with numerous examples, chapter exercises, and case studies. It incorporates hardware-level descriptions of concepts, allowing a designer to see all the steps of the process from abstract design to concrete implementation. \n \n\u00b7Case studies throughout the book draw on extensive author experience in designing interconnection networks over a period of more than twenty years, providing real world examples of what works, and what doesn't. \n \n\u00b7Tightly couples concepts with implementation costs to facilitate a deeper understanding of the tradeoffs in the design of a practical network. \n \n\u00b7A set of examples and exercises in every chapter help the reader to fully understand all the implications of every design decision. \n \nTable of Contents \n \n \nChapter 1 Introduction to Interconnection Networks \n1.1 Three Questions About Interconnection Networks \n1.2 Uses of Interconnection Networks \n1.3 Network Basics \n1.4 History \n1.5 Organization of this Book \n \nChapter 2 A Simple Interconnection Network \n2.1 Network Specifications and Constraints \n2.2 Topology \n2.3 Routing \n2.4 Flow Control \n2.5 Router Design \n2.6 Performance Analysis \n2.7 Exercises \n \nChapter 3 Topology Basics \n3.1 Nomenclature \n3.2 Traffic Patterns \n3.3 Performance \n3.4 Packaging Cost \n3.5 Case Study: The SGI Origin 2000 \n3.6 Bibliographic Notes \n3.7 Exercises \n \nChapter 4 Butterfly Networks \n4.1 The Structure of Butterfly Networks \n4.2 Isomorphic Butterflies \n4.3 Performance and Packaging Cost \n4.4 Path Diversity and Extra Stages \n4.5 Case Study: The BBN Butterfly \n4.6 Bibliographic Notes \n4.7 Exercises \n \nChapter 5 Torus Networks \n5.1 The Structure of Torus Networks \n5.2 Performance \n5.3 Building Mesh and Torus Networks \n5.4 Express Cubes \n5.5 Case Study: The MIT J-Machine \n5.6 Bibliographic Notes \n5.7 Exercises \nChapter 6 Non-Blocking Networks \n6.1 Non-Blocking vs. Non-Interfering Networks \n6.2 Crossbar Networks \n6.3 Clos Networks \n6.4 Benes Networks \n6.5 Sorting Networks \n6.6 Case Study: The Velio VC2002 (Zeus) Grooming Switch \n6.7 Bibliographic Notes \n6.8 Exercises \n \nChapter 7 Slicing and Dicing \n7.1 Concentrators and Distributors \n7.2 Slicing and Dicing \n7.3 Slicing Multistage Networks \n7.4 Case Study: Bit Slicing in the Tiny Tera \n7.5 Bibliographic Notes \n7.6 Exercises \n \nChapter 8 Routing Basics \n8.1 A Routing Example \n8.2 Taxonomy of Routing Algorithms \n8.3 The Routing Relation \n8.4 Deterministic Routing \n8.5 Case Study: Dimension-Order Routing in the Cray T3D \n8.6 Bibliographic Notes \n8.7 Exercises \n \nChapter 9 Oblivious Routing \n9.1 Valiant's Randomized Routing Algorithm \n9.2 Minimal Oblivious Routing \n9.3 Load-Balanced Oblivious Routing \n9.4 Analysis of Oblivious Routing \n9.5 Case Study: Oblivious Routing in the \nAvici Terabit Switch Router(TSR) \n9.6 Bibliographic Notes \n9.7 Exercises \n \nChapter 10 Adaptive Routing \n10.1 Adaptive Routing Basics \n10.2 Minimal Adaptive Routing \n10.3 Fully Adaptive Routing \n10.4 Load-Balanced Adaptive Routing \n10.5 Search-Based Routing \n10.6 Case Study: Adaptive Routing in the \nThinking Machines CM-5 \n10.7 Bibliographic Notes \n10.8 Exercises \n \nChapter 11 Routing Mechanics \n11.1 Table-Based Routing \n11.2 Algorithmic Routing \n11.3 Case Study: Oblivious Source Routing in the \nIBM Vulcan Network \n11.4 Bibliographic Notes \n11.5 Exercises \n \nChapter 12 Flow Control Basics \n12.1 Resources and Allocation Units \n12.2 Bufferless Flow Control \n12.3 Circuit Switching \n12.4 Bibliographic Notes \n12.5 Exercises \n \nChapter 13 Buffered Flow Control \n13.1 Packet-Buffer Flow Control \n13.2 Flit-Buffer Flow Control \n13.3 Buffer Management and Backpressure \n13.4 Flit-Reservation Flow Control \n13.5 Bibliographic Notes \n13.6 Exercises \n \nChapter 14 Deadlock and Livelock \n14.1 Deadlock \n14.2 Deadlock Avoidance \n14.3 Adaptive Routing \n14.4 Deadlock Recovery \n14.5 Livelock \n14.6 Case Study: Deadlock Avoidance in the Cray T3E \n14.7 Bibliographic Notes \n14.8 Exercises \n \nChapter 15 Quality of Service \n15.1 Service Classes and Service Contracts \n15.2 Burstiness and Network Delays \n15.3 Implementation of Guaranteed Services \n15.4 Implementation of Best-Effort Services \n15.5 Separation of Resources \n15.6 Case Study: ATM Service Classes \n15.7 Case Study: Virtual Networks in the Avici TSR \n15.8 Bibliographic Notes \n15.9 Exercises \n \nChapter 16 Router Architecture \n16.1 Basic Router Architecture \n16.2 Stalls \n16.3 Closing the Loop with Credits \n16.4 Reallocating a Channel \n16.5 Speculation and Lookahead \n16.6 Flit and Credit Encoding \n16.7 Case Study: The Alpha 21364 Router \n16.8 Bibliographic Notes \n16.9 Exercises \n \nChapter 17 Router Datapath Components \n17.1 Input Buffer Organization \n17.2 Switches \n17.3 Output Organization \n17.4 Case Study: The Datapath of the IBM Colony \nRouter \n17.5 Bibliographic Notes \n17.6 Exercises \n \nChapter 18 Arbitration \n18.1 Arbitration Timing \n18.2 Fairness \n18.3 Fixed Priority Arbiter \n18.4 Variable Priority Iterative Arbiters \n18.5 Matrix Arbiter \n18.6 Queuing Arbiter \n18.7 Exercises \n \nChapter 19 Allocation \n19.1 Representations \n19.2 Exact Algorithms \n19.3 Separable Allocators \n19.4 Wavefront Allocator \n19.5 Incremental vs. Batch Allocation \n19.6 Multistage Allocation \n19.7 Performance of Allocators \n19.8 Case Study: The Tiny Tera Allocator \n19.9 Bibliographic Notes \n19.10 Exercises \n \nChapter 20 Network Interfaces \n20.1 Processor-Network Interface \n20.2 Shared-Memory Interface \n20.3 Line-Fabric Interface \n20.4 Case Study: The MIT M-Machine Network Interface \n20.5 Bibliographic Notes \n20.6 Exercises \n \nChapter 21 Error Control 411 \n21.1 Know Thy Enemy: Failure Modes and Fault Models \n21.2 The Error Control Process: Detection, Containment, \nand Recovery \n21.3 Link Level Error Control \n21.4 Router Error Control \n21.5 Network-Level Error Control \n21.6 End-to-end Error Control \n21.7 Bibliographic Notes \n21.8 Exercises \n \nChapter 22 Buses \n22.1 Bus Basics \n22.2 Bus Arbitration \n22.3 High Performance Bus Protocol \n22.4 From Buses to Networks \n22.5 Case Study: The PCI Bus \n22.6 Bibliographic Notes \n22.7 Exercises \n \nChapter 23 Performance Analysis \n23.1 Measures of Interconnection Network Performance \n23.2 Analysis \n23.3 Validation \n23.4 Case Study: Efficiency and Loss in the \nBBN Monarch Network \n23.5 Bibliographic Notes \n23.6 Exercises \n \nChapter 24 Simulation \n24.1 Levels of Detail \n24.2 Network Workloads \n24.3 Simulation Measurements \n24.4 Simulator Design \n24.5 Bibliographic Notes \n24.6 Exercises \n \nChapter 25 Simulation Examples 495 \n25.1 Routing \n25.2 Flow Control Performance \n25.3 Fault Tolerance \n \nAppendix A Nomenclature \nAppendix B Glossary \nAppendix C Network Simulator"
            },
            "slug": "Principles-and-Practices-of-Interconnection-Dally-Towles",
            "title": {
                "fragments": [],
                "text": "Principles and Practices of Interconnection Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This book offers a detailed and comprehensive presentation of the basic principles of interconnection network design, clearly illustrating them with numerous examples, chapter exercises, and case studies, allowing a designer to see all the steps of the process from abstract design to concrete implementation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2782714"
                        ],
                        "name": "J. Nickolls",
                        "slug": "J.-Nickolls",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Nickolls",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Nickolls"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144437216"
                        ],
                        "name": "I. Buck",
                        "slug": "I.-Buck",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Buck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Buck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144764367"
                        ],
                        "name": "M. Garland",
                        "slug": "M.-Garland",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Garland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Garland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735065"
                        ],
                        "name": "K. Skadron",
                        "slug": "K.-Skadron",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Skadron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Skadron"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7917593,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3bf06754c03c58f5a2599d816caf0bab0250ea42",
            "isKey": false,
            "numCitedBy": 2177,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Presents a collection of slides covering the following topics: CUDA parallel programming model; CUDA toolkit and libraries; performance optimization; and application development."
            },
            "slug": "Scalable-parallel-programming-with-CUDA-Nickolls-Buck",
            "title": {
                "fragments": [],
                "text": "Scalable parallel programming with CUDA"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Presents a collection of slides covering the following topics: CUDA parallel programming model; CUDA toolkit and libraries; performance optimization; and application development."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Hot Chips 20 Symposium (HCS)"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711154"
                        ],
                        "name": "S. Mckee",
                        "slug": "S.-Mckee",
                        "structuredName": {
                            "firstName": "Sally",
                            "lastName": "Mckee",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mckee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 57
                            }
                        ],
                        "text": "Similar results for 2-way bank conflicts are reported in Mei and Chu [2016]. They find 37 cycle, 35 cycle and 2 cycle latency increments on Fermi, Kepler and Maxwell GPUs respectively."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 5302205,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6b3ea152aa5d35056c677000085333621c54962",
            "isKey": false,
            "numCitedBy": 349,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper looks at the evolution of the \"Memory Wall\" problem over the past decade. It begins by reviewing the short Computer Architecture News note that coined the phrase, including the motivation behind the note, the context in which it was written, and the controversy it sparked. What has changed over the years? Are we hitting the Memory Wall? And if so, for what types of applications?"
            },
            "slug": "Reflections-on-the-memory-wall-Mckee",
            "title": {
                "fragments": [],
                "text": "Reflections on the memory wall"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The short Computer Architecture News note that coined the phrase \"Memory Wall\" is reviewed, including the motivation behind the note, the context in which it was written, and the controversy it sparked."
            },
            "venue": {
                "fragments": [],
                "text": "CF '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082481941"
                        ],
                        "name": "D. Bailey",
                        "slug": "D.-Bailey",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Bailey",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bailey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 57
                            }
                        ],
                        "text": "A similar estimate can be also used for memory accesses [Bailey 1997]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 51
                            }
                        ],
                        "text": "The case of hiding memory latency is considered in Bailey [1997], and the result can be recognized as MWP_peak_BW in Hong and Kim [2009] and Sim et al. [2012]. A minor difference in our approach is that we treat arithmetic and memory instructions in a similar manner."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 51
                            }
                        ],
                        "text": "The case of hiding memory latency is considered in Bailey [1997], and the result can be recognized as MWP_peak_BW in Hong and Kim [2009] and Sim et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18826197,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e6ef9ee1a2183e1801ef2fcb75898bc73714333e",
            "isKey": true,
            "numCitedBy": 19,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "This note discuses Little\u2019s law and relates the form cited in queuing theory with a form often cited in the field of high performance computing. A rigorous mathematical proof of Little\u2019s law is included. Author\u2019s address: NAS Applications and Tools Group, NASA Ames Research Center, Moffett Field, CA 94035-1000; dbailey@nas.nasa.gov"
            },
            "slug": "Little-\u2019-s-Law-and-High-Performance-Computing-Bailey",
            "title": {
                "fragments": [],
                "text": "Little \u2019 s Law and High Performance Computing"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This note discuses Little\u2019s law and relates the form cited in queuing theory with a form often cited in the field of high performance computing."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683210"
                        ],
                        "name": "E. Lazowska",
                        "slug": "E.-Lazowska",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Lazowska",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Lazowska"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700666"
                        ],
                        "name": "J. Zahorjan",
                        "slug": "J.-Zahorjan",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Zahorjan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Zahorjan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145596540"
                        ],
                        "name": "G. S. Graham",
                        "slug": "G.-S.-Graham",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Graham",
                            "middleNames": [
                                "Scott"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. S. Graham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737874"
                        ],
                        "name": "K. Sevcik",
                        "slug": "K.-Sevcik",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Sevcik",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sevcik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 101
                            }
                        ],
                        "text": "This is how GPU\u2019s massive multithreading was originally introduced in vendor\u2019s publications, such as Lindholm et al. [2008], Nickolls et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 101
                            }
                        ],
                        "text": "This is how GPU\u2019s massive multithreading was originally introduced in vendor\u2019s publications, such as Lindholm et al. [2008], Nickolls et al. [2008], and Nickolls and Dally [2010]; this view is still dominant today."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1619603,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "02544882276ff1a35f4b6f1a8504a972b8df4087",
            "isKey": false,
            "numCitedBy": 1220,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Reading a book is also kind of better solution when you have no enough money or time to get your own adventure. This is one of the reasons we show the quantitative system performance computer system analysis using queuing network models as your friend in spending the time. For more representative collections, this book not only offers it's strategically book resource. It can be a good friend, really good friend with much knowledge."
            },
            "slug": "Quantitative-system-performance-computer-system-Lazowska-Zahorjan",
            "title": {
                "fragments": [],
                "text": "Quantitative system performance - computer system analysis using queueing network models"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This book shows the quantitative system performance computer system analysis using queuing network models as your friend in spending the time."
            },
            "venue": {
                "fragments": [],
                "text": "Int. CMG Conference"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1397221034"
                        ],
                        "name": "D. Simchi-Levi",
                        "slug": "D.-Simchi-Levi",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Simchi-Levi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Simchi-Levi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1834417"
                        ],
                        "name": "M. Trick",
                        "slug": "M.-Trick",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Trick",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Trick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 44469752,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c520f802119841152d81594741da72afe8ae42cf",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "In 1961, Operations Research published a short, fivepage article by John D. C. Little, then of Case Institute of Technology (now Case Western Reserve University), entitled a \u201cA Proof for the Queuing Formula: L= \u008bW \u201d Little (1961). This paper has become one of the five most cited papers ever published in the journal. And its influence goes far beyond the professional literature. In the paper, Little proves that under very general conditions, the average length of a queue, in steady state, will be equal to the arrival rate into the queue times the average wait in the queue. Remarkably, this relationship is not influenced by the arrival process distribution, the service distribution, the service order, or practically anything else. Nor does it depend on the structure of the queueing system: \u201cLittle\u2019s Law\u201d holds not just at the individual queue level but also at the system level. Complicated systems can be analyzed simply by looking at the queue length and waiting time relative to the system. For such a simple relationship, Little\u2019s Law has had a tremendous impact in practically every field of endeavor. Whether you are trying to access a Web page of a heavily utilized server or standing in line at an amusement park attraction, Little\u2019s Law governs the length of the wait for service. Little\u2019s Law has been used to calculate the spread of genes in a population and in analyzing complex project management systems. Given the generality of the conditions that are needed for Little\u2019s Law to apply, it acts as a quick heuristic analysis for systems of all kinds. Fifty years after publication, John Little has put together a paper (Little 2011) summarizing the influence of his original paper. In the new paper, he outlines both the theoretical advances and the practical applications of the Law. For a five-page paper with a forbidding title, the 1961 paper has had a tremendous impact on the profession and beyond. We are pleased to have this retrospective on this important anniversary. To celebrate this occasion, the OR Forum area of the journal has asked a number of luminaries to provide comments on the impact that the paper has had both on practice and on theory. These authors include Ron Wolff, Ed Kaplan, Tim Lowe, and Sridhar Tayur. Their comments are published in an online companion at http://orforum.blog.informs.org. This is also the place for readers of the journal and the community at large to share their experiences and comment on this beautiful piece of work published exactly 50 years ago!"
            },
            "slug": "Introduction-to-\"Little's-Law-as-Viewed-on-Its-50th-Simchi-Levi-Trick",
            "title": {
                "fragments": [],
                "text": "Introduction to \"Little's Law as Viewed on Its 50th Anniversary\""
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Fifty years after publication, John Little has put together a paper summarizing the influence of his original paper, which proved that under very general conditions, the average length of a queue will be equal to the arrival rate into the queue times the average wait in the queue."
            },
            "venue": {
                "fragments": [],
                "text": "Oper. Res."
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34753526"
                        ],
                        "name": "J. Little",
                        "slug": "J.-Little",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Little",
                            "middleNames": [
                                "D.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Little"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 913,
                                "start": 46
                            }
                        ],
                        "text": "041 IPC/SM \u2013 whereas memory latency is only a little larger: 376 cycles. As a result, the required occupancy is 2x lower: 20 warps per SM for 90% of the peak. If the accesses are random, i.e. unstructured and fully divergent, latency increases less than 2x compared to the base level \u2013 to 534 cycles \u2013 whereas throughput drops by more than an order of magnitude, down to 0.0029 IPC/SM. As a result, only 3 warps per SM are needed to attain 90% of the peak. This case is shown in Figure 4.3, right. Also shown in the figure, in a thick grey line, is our model plotted using the quoted metrics. In \u00a76.7 we find that in the case of unstructured accesses the same pattern also applies to other GPUs in the study \u2013 see Table 6.3. These findings suggest that arithmetic latency must not be considered a second-class citizen in GPU performance modeling; yet, some of relatively recent models, such as Song et al. [2013], entirely omit it."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 45
                            }
                        ],
                        "text": "This is due to what is known as Little\u2019s law [Little 1961], which is a simple relation that states that latency multiplied by throughput equals concurrency."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 123314524,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0953122463fe09928d0850d9e6d387db97b9d218",
            "isKey": true,
            "numCitedBy": 2301,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "In a queuing process, let 1/\u03bb be the mean time between the arrivals of two consecutive units, L be the mean number of units in the system, and W be the mean time spent by a unit in the system. It is shown that, if the three means are finite and the corresponding stochastic processes strictly stationary, and, if the arrival process is metrically transitive with nonzero mean, then L = \u03bbW."
            },
            "slug": "A-Proof-for-the-Queuing-Formula:-L-=-\u03bbW-Little",
            "title": {
                "fragments": [],
                "text": "A Proof for the Queuing Formula: L = \u03bbW"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1961
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111143430"
                        ],
                        "name": "Samuel Williams",
                        "slug": "Samuel-Williams",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Williams",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuel Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145492285"
                        ],
                        "name": "Andrew Waterman",
                        "slug": "Andrew-Waterman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Waterman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Waterman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052996765"
                        ],
                        "name": "David A. Patterson",
                        "slug": "David-A.-Patterson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Patterson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. Patterson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 28
                            }
                        ],
                        "text": "The popular Roofline model [Williams et al. 2009] does take memory bandwidth into account, but doesn\u2019t explain how to take into account latencies."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 45
                            }
                        ],
                        "text": "The kernel is inspired by the Roofline model [Williams et al. 2009] and a discussion in the CUDA C programming guide, Ch."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 72
                            }
                        ],
                        "text": "The only degrees of freedom kept are arithmetic intensity [Harris 2005; Williams et al. 2009] and occupancy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 102
                            }
                        ],
                        "text": "The found latencies are in a minor disagreement with the latencies reported in prior work, such as in Wong et al. [2010] and Volkov and Demmel [2008]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 13
                            }
                        ],
                        "text": "For example, Wong et al. [2010] cite a similar 440 cycle latency on a similar GT200 GPU (GTX280)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 20
                            }
                        ],
                        "text": "The Roofline model [Williams et al. 2009] includes a number of throughput bounds but doesn\u2019t provide a specific solution for the latency-bound case."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 46
                            }
                        ],
                        "text": "The kernel is inspired by the Roofline model [Williams et al. 2009] and a discussion in the\nCUDA C programming guide, Ch. 5.2.3 [NVIDIA 2015]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5703612,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "092217c2267f6e0673590aa151d811e579ff7760",
            "isKey": true,
            "numCitedBy": 1897,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "The Roofline model offers insight on how to improve the performance of software and hardware."
            },
            "slug": "Roofline:-an-insightful-visual-performance-model-Williams-Waterman",
            "title": {
                "fragments": [],
                "text": "Roofline: an insightful visual performance model for multicore architectures"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "The Roofline model offers insight on how to improve the performance of software and hardware in the rapidly changing world of connected devices."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 8
                            }
                        ],
                        "text": "Khronos\nOpenCL Working Group."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 130
                            }
                        ],
                        "text": "We use CUDA throughout this work, but the conclusions likely apply to kernels implemented using other frameworks, such as OpenCL [Howes 2015], as long as a similar hardware is used."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 4
                            }
                        ],
                        "text": "The OpenCL Specification Version: 2.1 Document Revision: 23."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 4
                            }
                        ],
                        "text": "AMD OpenCL optimization guide (rev 1.0), August 2015."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The OpenCL Specification Version: 2.1 Document Revision: 23"
            },
            "venue": {
                "fragments": [],
                "text": "Khronos OpenCL Working Group"
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 2
                            }
                        ],
                        "text": ", Volkov and Demmel [2008] and Wong et al. [2010]), but includes a few substantially new features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 11
                            }
                        ],
                        "text": "[2010] and Volkov and Demmel [2008]. Specifically, the latencies found on the G80 and GT200 GPUs are larger than the previously reported numbers by 6 cycles in the case of SFU instructions and by 2 cycles in the case of shared memory instructions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 0
                            }
                        ],
                        "text": "Volkov and Demmel [2008] cite 470 cycle latency on a similar G80 GPU (8800GTX), which includes 20 or 24 cycle latency of pointer arithmetic."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 25
                            }
                        ],
                        "text": "1 Data for SGEMM is from Volkov and Demmel [2008], Section 4."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 0
                            }
                        ],
                        "text": "Volkov and Demmel [2008] cite 470 cycle latency on a similar G80 GPU (8800GTX), which includes 20 or 24 cycle latency of pointer arithmetic. Chu and Mei [2016] report 383 cycle memory latency on a similar Maxwell GPU (GTX980), which also includes the latency of pointer arithmetic \u2013 likely, 6 cycles."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Better performance at lower occupancy"
            },
            "venue": {
                "fragments": [],
                "text": "GPU Technology Conference (GTC '10)."
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 55
                            }
                        ],
                        "text": "Further details can be found in NVIDIA patents such as Coon et al. [2008], Coon et al. [2009], Coon et al. [2010], and Coon et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 55
                            }
                        ],
                        "text": "Further details can be found in NVIDIA patents such as Coon et al. [2008], Coon et al. [2009], Coon et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 55
                            }
                        ],
                        "text": "Further details can be found in NVIDIA patents such as Coon et al. [2008], Coon et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 55
                            }
                        ],
                        "text": "Further details can be found in NVIDIA patents such as Coon et al. [2008], Coon et al. [2009], Coon et al. [2010], and Coon et al. [2011]. Instructions Threads Warp 0 1 2 3 Order Mask SSY ENDIF @!P0 BRA ELSE IF: IADD R1, R1, 1 IADD R2, R2, 2 IADD."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Processing an indirect branch instruction in a SIMD architecture"
            },
            "venue": {
                "fragments": [],
                "text": "US Patent 7,761,697."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1484553207"
                        ],
                        "name": "J. Little",
                        "slug": "J.-Little",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Little",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Little"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777955"
                        ],
                        "name": "S. Graves",
                        "slug": "S.-Graves",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Graves",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Graves"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59821081,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "9b57440804084abb467a359aebce5e50fff084ab",
            "isKey": false,
            "numCitedBy": 133,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Little's-Law-Little-Graves",
            "title": {
                "fragments": [],
                "text": "Little's Law"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2401723"
                        ],
                        "name": "Andreas Resios",
                        "slug": "Andreas-Resios",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Resios",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Resios"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 38251947,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9353c2bbb5d2590a15faad7a0d0642a8feec0a99",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "GPU-performance-prediction-using-parametrized-Resios",
            "title": {
                "fragments": [],
                "text": "GPU performance prediction using parametrized models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 48
                            }
                        ],
                        "text": "In this case, we solve (n \u2013 1)  (R + C) \u2265 L and get [Saavedra-Barrera et al. 1990, Eq."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 2
                            }
                        ],
                        "text": "4 Sim et al. 2012 model The Sim et al. [2012] model is a further development of the Hong and Kim model discussed before."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 52
                            }
                        ],
                        "text": "4 \uf0b7 Zhang and Owens [2011] (slightly simplified), \uf0b7 Sim et al. [2012], and \uf0b7 Huang et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Efficient CUDA Fortran Programming (1 ed.)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "System and method for managing divergent threads using synchronization tokens and program instructions that include set-synchronization bits"
            },
            "venue": {
                "fragments": [],
                "text": "US Patent 7,543,136."
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 72
                            }
                        ],
                        "text": "Similar bounds were previously discussed by Shebanow as \u201cspace limiters\u201d [Shebanow 2008; Shebanow 2010]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 16
                            }
                        ],
                        "text": "Limiter theory [Shebanow 2008] considers similar throughput bounds, but does not consider latency bounds, at least not explicitly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Parallel Programming (PPoPP"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 26
                            }
                        ],
                        "text": "Lai and Seznec [2013] and Gray [2014] reverse engineered how registers are mapped to register banks on Kepler and Maxwell GPUs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 139
                            }
                        ],
                        "text": "Similar long sequences of independent instructions are common in highly optimized kernels such as matrix multiply [Volkov and Demmel 2008; Gray 2014], FFT [Volkov and Kazian 2008] and radix sort [Merrill and Grimshaw 2010]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A full walk through of the SGEMM implementation, https://github.com/NervanaSystems/maxas/wiki/SGEMM"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 111
                            }
                        ],
                        "text": "This work is in also line with prior work on understanding GPU performance by using microbenchmarking, such as Buck et al. [2004], Volkov and Demmel [2008], and Wong et al. [2010]. The simplistic workload we suggested may, too, be classified as a microbenchmark."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 111
                            }
                        ],
                        "text": "This work is in also line with prior work on understanding GPU performance by using microbenchmarking, such as Buck et al. [2004], Volkov and Demmel [2008], and Wong et al."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "GPUBench: Evaluating GPU performance for numerical and scientific applications, GP2"
            },
            "venue": {
                "fragments": [],
                "text": "Workshop on General Purpose Computing on Graphics Processors,"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Threads vs"
            },
            "venue": {
                "fragments": [],
                "text": "caches: Modeling the behavior of parallel workloads. International Conference on Computer Design (ICCD), 274\u2013281."
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 44
                            }
                        ],
                        "text": "We find it in such performance models as by Sim et al. [2012], Zhang and Owens [2011], Baghsorkhi et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 84
                            }
                        ],
                        "text": "GPU Year Generation Related publications and whitepapers by vendor 8800GTX 2006 G80 NVIDIA [2006] GTX280 2008 GT200 NVIDIA [2008], Lindholm et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dynamic Parallelism in CUDA"
            },
            "venue": {
                "fragments": [],
                "text": "NVIDIA. 2012b. NVIDIA GeForce GTX 680. Whitepaper. V1.0"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Structured programming control flow in a SIMD architecture"
            },
            "venue": {
                "fragments": [],
                "text": "US Patent 7,877,585."
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "System and method for managing divergent threads in a SIMD architecture"
            },
            "venue": {
                "fragments": [],
                "text": "US Patent 7,353,369."
            },
            "year": 2008
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 35,
            "methodology": 21,
            "result": 11
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 60,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Understanding-Latency-Hiding-on-GPUs-Volkov/ac425b104c5884f0fa7b98d764d4785a7ee3d822?sort=total-citations"
}