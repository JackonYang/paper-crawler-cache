{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31558848"
                        ],
                        "name": "A. Rahimi",
                        "slug": "A.-Rahimi",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Rahimi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rahimi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9229182"
                        ],
                        "name": "B. Recht",
                        "slug": "B.-Recht",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Recht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Recht"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 877929,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a59fde27461a3ef4a21a249cc403d0d96e4a0d7",
            "isKey": false,
            "numCitedBy": 2969,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "To accelerate the training of kernel machines, we propose to map the input data to a randomized low-dimensional feature space and then apply existing fast linear methods. The features are designed so that the inner products of the transformed data are approximately equal to those in the feature space of a user specified shift-invariant kernel. We explore two sets of random features, provide convergence bounds on their ability to approximate various radial basis kernels, and show that in large-scale classification and regression tasks linear machine learning algorithms applied to these features outperform state-of-the-art large-scale kernel machines."
            },
            "slug": "Random-Features-for-Large-Scale-Kernel-Machines-Rahimi-Recht",
            "title": {
                "fragments": [],
                "text": "Random Features for Large-Scale Kernel Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Two sets of random features are explored, provided convergence bounds on their ability to approximate various radial basis kernels, and it is shown that in large-scale classification and regression tasks linear machine learning algorithms applied to these features outperform state-of-the-art large- scale kernel machines."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144785135"
                        ],
                        "name": "Ping Li",
                        "slug": "Ping-Li",
                        "structuredName": {
                            "firstName": "Ping",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ping Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244184"
                        ],
                        "name": "Kenneth Ward Church",
                        "slug": "Kenneth-Ward-Church",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Church",
                            "middleNames": [
                                "Ward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Ward Church"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784682"
                        ],
                        "name": "T. Hastie",
                        "slug": "T.-Hastie",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Hastie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hastie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17021559,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2ca59d9e88682a56b6f8fc748d3186d089749bf2",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop Conditional Random Sampling (CRS), a technique particularly suitable for sparse data. In large-scale applications, the data are often highly sparse. CRS combines sketching and sampling in that it converts sketches of the data into conditional random samples online in the estimation stage, with the sample size determined retrospectively. This paper focuses on approximating pairwise l2 and l1 distances and comparing CRS with random projections. For boolean (0/1) data, CRS is provably better than random projections. We show using real-world data that CRS often outperforms random projections. This technique can be applied in learning, data mining, information retrieval, and database query optimizations."
            },
            "slug": "Conditional-Random-Sampling:-A-Sketch-based-for-Li-Church",
            "title": {
                "fragments": [],
                "text": "Conditional Random Sampling: A Sketch-based Sampling Technique for Sparse Data"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper focuses on approximating pairwise l2 and l1 distances and comparing CRS with random projections, showing using real-world data that CRS often outperforms random projections."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144422385"
                        ],
                        "name": "Kuzman Ganchev",
                        "slug": "Kuzman-Ganchev",
                        "structuredName": {
                            "firstName": "Kuzman",
                            "lastName": "Ganchev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kuzman Ganchev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782853"
                        ],
                        "name": "Mark Dredze",
                        "slug": "Mark-Dredze",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Dredze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Dredze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11307434,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3fb1c64b763d27fba2a18c923637c5ea0e048e3b",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "The application of statistical NLP systems to resource constrained devices is limited by the need to maintain parameters for a large number of features and an alphabet mapping features to parameters. We introduce random feature mixing to eliminate alphabet storage and reduce the number of parameters without severely impacting model performance."
            },
            "slug": "Small-Statistical-Models-by-Random-Feature-Mixing-Ganchev-Dredze",
            "title": {
                "fragments": [],
                "text": "Small Statistical Models by Random Feature Mixing"
            },
            "venue": {
                "fragments": [],
                "text": "ACL 2008"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30654921"
                        ],
                        "name": "Anirban Dasgupta",
                        "slug": "Anirban-Dasgupta",
                        "structuredName": {
                            "firstName": "Anirban",
                            "lastName": "Dasgupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anirban Dasgupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683442"
                        ],
                        "name": "Ravi Kumar",
                        "slug": "Ravi-Kumar",
                        "structuredName": {
                            "firstName": "Ravi",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ravi Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2227764"
                        ],
                        "name": "Tam\u00e1s Sarl\u00f3s",
                        "slug": "Tam\u00e1s-Sarl\u00f3s",
                        "structuredName": {
                            "firstName": "Tam\u00e1s",
                            "lastName": "Sarl\u00f3s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tam\u00e1s Sarl\u00f3s"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13492200,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4ba0079fbfaf8a49f36f4e400f44c17b7f4552d4",
            "isKey": false,
            "numCitedBy": 194,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Dimension reduction is a key algorithmic tool with many applications including nearest-neighbor search, compressed sensing and linear algebra in the streaming model. In this work we obtain a sparse version of the fundamental tool in dimension reduction -- the Johnson-Lindenstrauss transform. Using hashing and local densification, we construct a sparse projection matrix with just ~O(1/\u03b5) non-zero entries per column. We also show a matching lower bound on the sparsity for a large class of projection matrices. Our bounds are somewhat surprising, given the known lower bounds of \u03a9(1/\u03b52) both on the number of rows of any projection matrix and on the sparsity of projection matrices generated by natural constructions. Using this, we achieve an ~O(1/\u03b5) update time per non-zero element for a (1 \u03b5)-approximate projection, thereby substantially outperforming the ~O(1/\u03b52) update time required by prior approaches. A variant of our method offers the same guarantees for sparse vectors, yet its ~O(d) worst case running time matches the best approach of Ailon and Liberty."
            },
            "slug": "A-sparse-Johnson:-Lindenstrauss-transform-Dasgupta-Kumar",
            "title": {
                "fragments": [],
                "text": "A sparse Johnson: Lindenstrauss transform"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A sparse version of the fundamental tool in dimension reduction -- the Johnson-Lindenstrauss transform is obtained, using hashing and local densification to construct a sparse projection matrix with just ~O(1/\u03b5) non-zero entries per column, and a matching lower bound on the sparsity for a large class of projection matrices is shown."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '10"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113543585"
                        ],
                        "name": "J. Bennett",
                        "slug": "J.-Bennett",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bennett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bennett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47511653"
                        ],
                        "name": "S. Lanning",
                        "slug": "S.-Lanning",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Lanning",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lanning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9528522,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31af4b8793e93fd35e89569ccd663ae8777f0072",
            "isKey": false,
            "numCitedBy": 2030,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Netflix released a dataset containing 100 million anonymous movie ratings and challenged the data mining, machine learning and computer science communities to develop systems that could beat the accuracy of its recommendation system, Cinematch. We briefly describe the challenge itself, review related work and efforts, and summarize visible progress to date. Other potential uses of the data are outlined, including its application to the KDD Cup 2007."
            },
            "slug": "The-Netflix-Prize-Bennett-Lanning",
            "title": {
                "fragments": [],
                "text": "The Netflix Prize"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Netflix released a dataset containing 100 million anonymous movie ratings and challenged the data mining, machine learning and computer science communities to develop systems that could beat the accuracy of its recommendation system, Cinematch."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2941680"
                        ],
                        "name": "Edo Liberty",
                        "slug": "Edo-Liberty",
                        "structuredName": {
                            "firstName": "Edo",
                            "lastName": "Liberty",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edo Liberty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2048494"
                        ],
                        "name": "Nir Ailon",
                        "slug": "Nir-Ailon",
                        "structuredName": {
                            "firstName": "Nir",
                            "lastName": "Ailon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nir Ailon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805915"
                        ],
                        "name": "A. Singer",
                        "slug": "A.-Singer",
                        "structuredName": {
                            "firstName": "Amit",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 58
                            }
                        ],
                        "text": "Some of our theoretical bounds are derivable from that of (Liberty et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 104
                            }
                        ],
                        "text": "This, together with an indirect application of Talagrand\u2019s convex distance inequality via the result of (Liberty et al., 2008), enables us to construct exponential tail bounds."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 38650247,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f09dc96aad6370caf9fb47ee422ac1e673b58bd1",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Random projection methods give distributions over k\u00d7dmatrices such that if a matrix i\u00be?(chosen according to the distribution) is applied to a vector the norm of the resulting vector, , is up to distortion i\u00be?equal to the norm of xw.p. at least 1 i\u00be? i\u00be?. The Johnson Lindenstrauss lemma shows that such distributions exist over densematrices for k(the target dimension) in . Ailon and Chazelle and later Matousek showed that there exist entry-wise i.i.d. distributions over sparsematrices i\u00be?which give the same guaranties for vectors whose i\u00be? i\u00be? is bounded away from their i\u00be? 2 norm. This allows to accelerate the mapping xi\u00be?i\u00be?x. We claim that setting i\u00be?as any column normalized deterministic densematrix composed with random \u00b11 diagonal matrix also exhibits this property for vectors whose i\u00be? p (for any p> 2) is bounded away from their i\u00be? 2 norm. We also describe a specific tensor product matrix which we term lean Walsh. It is applicable to any vector in in O(d) operations and requires a weaker i\u00be? i\u00be? bound on xthen the best current result, under comparable running times, using sparse matrices due to Matousek."
            },
            "slug": "Dense-Fast-Random-Projections-and-Lean-Walsh-Liberty-Ailon",
            "title": {
                "fragments": [],
                "text": "Dense Fast Random Projections and Lean Walsh Transforms"
            },
            "venue": {
                "fragments": [],
                "text": "APPROX-RANDOM"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705268"
                        ],
                        "name": "D. Achlioptas",
                        "slug": "D.-Achlioptas",
                        "structuredName": {
                            "firstName": "Dimitris",
                            "lastName": "Achlioptas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Achlioptas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18931062,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "594d2e123ecb8ec0bc781aec467007d65ab5464d",
            "isKey": false,
            "numCitedBy": 1244,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Database-friendly-random-projections:-with-binary-Achlioptas",
            "title": {
                "fragments": [],
                "text": "Database-friendly random projections: Johnson-Lindenstrauss with binary coins"
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Syst. Sci."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709589"
                        ],
                        "name": "Graham Cormode",
                        "slug": "Graham-Cormode",
                        "structuredName": {
                            "firstName": "Graham",
                            "lastName": "Cormode",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Graham Cormode"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144963537"
                        ],
                        "name": "S. Muthukrishnan",
                        "slug": "S.-Muthukrishnan",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Muthukrishnan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Muthukrishnan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 999108,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd873347660c2af6a70d623a9fb265893e64c98d",
            "isKey": false,
            "numCitedBy": 1918,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new sublinear space data structure\u2014the Count-Min Sketch\u2014 for summarizing data streams. Our sketch allows fundamental queries in data stream summarization such as point, range, and inner product queries to be approximately answered very quickly; in addition, it can be applied to solve several important problems in data streams such as finding quantiles, frequent items, etc. The time and space bounds we show for using the CM sketch to solve these problems significantly improve those previously known \u2014 typically from 1/e 2 to 1/e in factor."
            },
            "slug": "An-improved-data-stream-summary:-the-count-min-and-Cormode-Muthukrishnan",
            "title": {
                "fragments": [],
                "text": "An improved data stream summary: the count-min sketch and its applications"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The Count-Min Sketch allows fundamental queries in data stream summarization such as point, range, and inner product queries to be approximately answered very quickly and can be applied to solve several important problems in data streams such as finding quantiles, frequent items, etc."
            },
            "venue": {
                "fragments": [],
                "text": "J. Algorithms"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2048494"
                        ],
                        "name": "Nir Ailon",
                        "slug": "Nir-Ailon",
                        "structuredName": {
                            "firstName": "Nir",
                            "lastName": "Ailon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nir Ailon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730838"
                        ],
                        "name": "B. Chazelle",
                        "slug": "B.-Chazelle",
                        "structuredName": {
                            "firstName": "Bernard",
                            "lastName": "Chazelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Chazelle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 490517,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b4d6a34f9d25b7a7ca665087ad7cb82f58d89d51",
            "isKey": false,
            "numCitedBy": 486,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new low-distortion embedding of l<sub>2</sub><sup>d</sup> into l<sub>p</sub><sup>O(log n)</sup> (p=1,2), called the <i>Fast-Johnson-Linden-strauss-Transform</i>. The FJLT is faster than standard random projections and just as easy to implement. It is based upon the preconditioning of a sparse projection matrix with a randomized Fourier transform. Sparse random projections are unsuitable for low-distortion embeddings. We overcome this handicap by exploiting the \"Heisenberg principle\" of the Fourier transform, ie, its local-global duality. The FJLT can be used to speed up search algorithms based on low-distortion embeddings in l<sub>1</sub> and l<sub>2</sub>. We consider the case of approximate nearest neighbors in l<sub>2</sub><sup>d</sup>. We provide a faster algorithm using classical projections, which we then further speed up by plugging in the FJLT. We also give a faster algorithm for searching over the hypercube."
            },
            "slug": "Approximate-nearest-neighbors-and-the-fast-Ailon-Chazelle",
            "title": {
                "fragments": [],
                "text": "Approximate nearest neighbors and the fast Johnson-Lindenstrauss transform"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A new low-distortion embedding of l<sub>2</sub><sup>d</sup> into l p (p=1,2) is introduced, called the Fast-Johnson-Linden-strauss-Transform (FJLT), based upon the preconditioning of a sparse projection matrix with a randomized Fourier transform."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '06"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722360"
                        ],
                        "name": "Hal Daum\u00e9",
                        "slug": "Hal-Daum\u00e9",
                        "structuredName": {
                            "firstName": "Hal",
                            "lastName": "Daum\u00e9",
                            "middleNames": [],
                            "suffix": "III"
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hal Daum\u00e9"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5360764,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f62067945d991cd78a62cf647de17f01d1b54d3",
            "isKey": false,
            "numCitedBy": 1636,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe an approach to domain adaptation that is appropriate exactly in the case when one has enough \u201ctarget\u201d data to do slightly better than just using only \u201csource\u201d data. Our approach is incredibly simple, easy to implement as a preprocessing step (10 lines of Perl!) and outperforms stateof-the-art approaches on a range of datasets. Moreover, it is trivially extended to a multidomain adaptation problem, where one has data from a variety of different domains."
            },
            "slug": "Frustratingly-Easy-Domain-Adaptation-Daum\u00e9",
            "title": {
                "fragments": [],
                "text": "Frustratingly Easy Domain Adaptation"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "This work describes an approach to domain adaptation that is appropriate exactly in the case when one has enough \u201ctarget\u201d data to do slightly better than just using only \u201csource\u2019 data."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144378473"
                        ],
                        "name": "J. Matousek",
                        "slug": "J.-Matousek",
                        "structuredName": {
                            "firstName": "Jir\u00ed",
                            "lastName": "Matousek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Matousek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15786275,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "0a65097bcb2dd400a27a65d42608658dc9f6898d",
            "isKey": false,
            "numCitedBy": 239,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "The Johnson\u2013Lindenstrauss lemma asserts that an n\u2010point set in any Euclidean space can be mapped to a Euclidean space of dimension k = O(\u03b5\u20102 log n) so that all distances are preserved up to a multiplicative factor between 1 \u2212 \u03b5 and 1 + \u03b5. Known proofs obtain such a mapping as a linear map Rn \u2192 Rk with a suitable random matrix. We give a simple and self\u2010contained proof of a version of the Johnson\u2013Lindenstrauss lemma that subsumes a basic versions by Indyk and Motwani and a version more suitable for efficient computations due to Achlioptas. (Another proof of this result, slightly different but in a similar spirit, was given independently by Indyk and Naor.) An even more general result was established by Klartag and Mendelson using considerably heavier machinery."
            },
            "slug": "On-variants-of-the-Johnson\u2013Lindenstrauss-lemma-Matousek",
            "title": {
                "fragments": [],
                "text": "On variants of the Johnson\u2013Lindenstrauss lemma"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A simple and self\u2010contained proof of a version of the Johnson\u2013Lindenstrauss lemma that subsumes a basic versions by Indyk and Motwani and a version more suitable for efficient computations due to Achlioptas is given."
            },
            "venue": {
                "fragments": [],
                "text": "Random Struct. Algorithms"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2048494"
                        ],
                        "name": "Nir Ailon",
                        "slug": "Nir-Ailon",
                        "structuredName": {
                            "firstName": "Nir",
                            "lastName": "Ailon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nir Ailon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2941680"
                        ],
                        "name": "Edo Liberty",
                        "slug": "Edo-Liberty",
                        "structuredName": {
                            "firstName": "Edo",
                            "lastName": "Liberty",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edo Liberty"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 313102,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "723f76a1a0ddeb522e4ad3cb004a5baa2a721f10",
            "isKey": false,
            "numCitedBy": 237,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "The Fast Johnson\u2013Lindenstrauss Transform (FJLT) was recently discovered by Ailon and Chazelle as a novel technique for performing fast dimension reduction with small distortion from \u21132d to \u21132k in time O(max\u2009{dlog\u2009d,k3}). For k in [\u03a9(log\u2009d),O(d1/2)], this beats time O(dk) achieved by naive multiplication by random dense matrices, an approach followed by several authors as a variant of the seminal result by Johnson and Lindenstrauss (JL) from the mid 1980s. In this work we show how to significantly improve the running time to O(dlog\u2009k) for k=O(d1/2\u2212\u03b4), for any arbitrary small fixed \u03b4. This beats the better of FJLT and JL. Our analysis uses a powerful measure concentration bound due to Talagrand applied to Rademacher series in Banach spaces (sums of vectors in Banach spaces with random signs). The set of vectors used is a real embedding of dual BCH code vectors over GF(2). We also discuss the number of random bits used and reduction to \u21131 space.The connection between geometry and discrete coding theory discussed here is interesting in its own right and may be useful in other algorithmic applications as well."
            },
            "slug": "Fast-Dimension-Reduction-Using-Rademacher-Series-Ailon-Liberty",
            "title": {
                "fragments": [],
                "text": "Fast Dimension Reduction Using Rademacher Series on\u00a0Dual BCH Codes"
            },
            "tldr": {
                "abstractSimilarityScore": 34,
                "text": "This work shows how to significantly improve the running time to O(dlog\u2009k) for k=O(d1/2\u2212\u03b4), for any arbitrary small fixed \u03b4, which beats the better of FJLT and JL."
            },
            "venue": {
                "fragments": [],
                "text": "SODA '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734327"
                        ],
                        "name": "N. Alon",
                        "slug": "N.-Alon",
                        "structuredName": {
                            "firstName": "Noga",
                            "lastName": "Alon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Alon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 23110576,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2dca86a626ef078b41920d502a3160e0999a693a",
            "isKey": false,
            "numCitedBy": 244,
            "numCiting": 84,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Problems-and-results-in-extremal-combinatorics--I-Alon",
            "title": {
                "fragments": [],
                "text": "Problems and results in extremal combinatorics--I"
            },
            "venue": {
                "fragments": [],
                "text": "Discret. Math."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734327"
                        ],
                        "name": "N. Alon",
                        "slug": "N.-Alon",
                        "structuredName": {
                            "firstName": "Noga",
                            "lastName": "Alon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Alon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8431738,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "cf3a5ab7e04df5252e1f3417a4332a499b11dd89",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Extremal Combinatorics is an area in Discrete Mathematics that has developed spectacularly during the last decades. This paper contains a collection of problems and results in the area, including solutions or partial solutions to open problems suggested by various researchers in Extremal Graph Theory, Extremal Finite Set Theory and Combinatorial Geometry. This is not meant to be a comprehensive survey of the area, it is merely a collection of various extremal problems, which are hopefully interesting. The choice of the problems is inevitably somewhat biased, and as the title of the paper suggests I hope to write a related paper in the future. Each section of this paper is essentially self contained, and can be read separately."
            },
            "slug": "Problems-and-results-in-Extremal-Combinatorics-,-Alon",
            "title": {
                "fragments": [],
                "text": "Problems and results in Extremal Combinatorics , Part"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14725378"
                        ],
                        "name": "M. Ledoux",
                        "slug": "M.-Ledoux",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Ledoux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ledoux"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 117088211,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "381667eec4fb626d3a5352d33aa7ee756b7cd08c",
            "isKey": false,
            "numCitedBy": 1998,
            "numCiting": 124,
            "paperAbstract": {
                "fragments": [],
                "text": "Concentration functions and inequalities Isoperimetric and functional examples Concentration and geometry Concentration in product spaces Entropy and concentration Transportation cost inequalities Sharp bounds of Gaussian and empirical processes Selected applications References Index."
            },
            "slug": "The-concentration-of-measure-phenomenon-Ledoux",
            "title": {
                "fragments": [],
                "text": "The concentration of measure phenomenon"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 321,
                                "start": 280
                            }
                        ],
                        "text": "For this common scenario several authors have recently proposed an alternative, but highly complimentary variation of the kernel-trick, which we refer to as the hashing-trick: one hashes the high dimensional input vectors x into a lower dimensional feature space R with \u03c6 : X \u2192 R (Langford et al., 2007; Shi et al., 2009)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 14
                            }
                        ],
                        "text": "In addition, (Langford et al., \n2007) released the Vowpal Wabbit fast online learn\u00ading software which uses a hash representation similar \nto that discussed here."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 13
                            }
                        ],
                        "text": "In addition, (Langford et al., 2007) released the Vowpal Wabbit fast online learning software which uses a hash representation similar to that discussed here."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 4
                            }
                        ],
                        "text": "Rm (Langford et al., 2007; Shi et al., 2009)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vowpal wabbit online learning project (Technical Report)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69439715"
                        ],
                        "name": "P. B. Kleidman",
                        "slug": "P.-B.-Kleidman",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Kleidman",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. B. Kleidman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1965526"
                        ],
                        "name": "M. Liebeck",
                        "slug": "M.-Liebeck",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Liebeck",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Liebeck"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123821450,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ad8e98a6fb9d1f0d09635dc395e73df0f01c5bfb",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Subgroup-Structure-of-the-Finite-Classical-The-Kleidman-Liebeck",
            "title": {
                "fragments": [],
                "text": "The Subgroup Structure of the Finite Classical Groups: The Statement of the Main Theorem"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799860"
                        ],
                        "name": "T. Griffiths",
                        "slug": "T.-Griffiths",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Griffiths",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Griffiths"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31872195"
                        ],
                        "name": "Christopher G. Lucas",
                        "slug": "Christopher-G.-Lucas",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Lucas",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher G. Lucas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1580222881"
                        ],
                        "name": "J. Williams",
                        "slug": "J.-Williams",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Williams",
                            "middleNames": [
                                "Jay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2147951"
                        ],
                        "name": "M. Kalish",
                        "slug": "M.-Kalish",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Kalish",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kalish"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 63401287,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "827ea2516f389aad105de1c3aa234382bd6ba70d",
            "isKey": false,
            "numCitedBy": 114,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Advances-in-Neural-Information-Processing-Systems-Griffiths-Lucas",
            "title": {
                "fragments": [],
                "text": "Advances in Neural Information Processing Systems 21"
            },
            "venue": {
                "fragments": [],
                "text": "NIPS 2009"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "115715700"
                        ],
                        "name": "A. E. Bostwick",
                        "slug": "A.-E.-Bostwick",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Bostwick",
                            "middleNames": [
                                "Elmore"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. E. Bostwick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 148
                            }
                        ],
                        "text": "\u2026the value of the inner product w, \nfu(x) is bounded by 2/2 - m-1 w 22 x 22+ w 8 x 8/3 Pr {| w, fu(x) | >E}= 2e Proof We use Bernstein s \ninequality (Bernstein, 1946), which states that for independent random variables Xj, with E [Xj ]=0,if \nC> 0 is such that |Xj|= C, then .. n t2/2 .. Pr Xj >t\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5224243,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6a45bc7826bf2928850c61844b53f1dc5b9bb739",
            "isKey": false,
            "numCitedBy": 273,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "THE-THEORY-OF-PROBABILITIES.-Bostwick",
            "title": {
                "fragments": [],
                "text": "THE THEORY OF PROBABILITIES."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 1896
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682878"
                        ],
                        "name": "A. Gionis",
                        "slug": "A.-Gionis",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Gionis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gionis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688317"
                        ],
                        "name": "P. Indyk",
                        "slug": "P.-Indyk",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Indyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Indyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "84095744"
                        ],
                        "name": "R. Motwani",
                        "slug": "R.-Motwani",
                        "structuredName": {
                            "firstName": "Rajeev",
                            "lastName": "Motwani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Motwani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1578969,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e74388f55f2cc704c4de410578887a53a9433b0",
            "isKey": false,
            "numCitedBy": 3517,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "The nearestor near-neighbor query problems arise in a large variety of database applications, usually in the context of similarity searching. Of late, there has been increasing interest in building search/index structures for performing similarity search over high-dimensional data, e.g., image databases, document collections, time-series databases, and genome databases. Unfortunately, all known techniques for solving this problem fall prey to the \\curse of dimensionality.\" That is, the data structures scale poorly with data dimensionality; in fact, if the number of dimensions exceeds 10 to 20, searching in k-d trees and related structures involves the inspection of a large fraction of the database, thereby doing no better than brute-force linear search. It has been suggested that since the selection of features and the choice of a distance metric in typical applications is rather heuristic, determining an approximate nearest neighbor should su ce for most practical purposes. In this paper, we examine a novel scheme for approximate similarity search based on hashing. The basic idea is to hash the points Supported by NAVY N00014-96-1-1221 grant and NSF Grant IIS-9811904. Supported by Stanford Graduate Fellowship and NSF NYI Award CCR-9357849. Supported by ARO MURI Grant DAAH04-96-1-0007, NSF Grant IIS-9811904, and NSF Young Investigator Award CCR9357849, with matching funds from IBM, Mitsubishi, Schlumberger Foundation, Shell Foundation, and Xerox Corporation. Permission to copy without fee all or part of this material is granted provided that the copies are not made or distributed for direct commercial advantage, the VLDB copyright notice and the title of the publication and its date appear, and notice is given that copying is by permission of the Very Large Data Base Endowment. To copy otherwise, or to republish, requires a fee and/or special permission from the Endowment. Proceedings of the 25th VLDB Conference, Edinburgh, Scotland, 1999. from the database so as to ensure that the probability of collision is much higher for objects that are close to each other than for those that are far apart. We provide experimental evidence that our method gives signi cant improvement in running time over other methods for searching in highdimensional spaces based on hierarchical tree decomposition. Experimental results also indicate that our scheme scales well even for a relatively large number of dimensions (more than 50)."
            },
            "slug": "Similarity-Search-in-High-Dimensions-via-Hashing-Gionis-Indyk",
            "title": {
                "fragments": [],
                "text": "Similarity Search in High Dimensions via Hashing"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Experimental results indicate that the novel scheme for approximate similarity search based on hashing scales well even for a relatively large number of dimensions, and provides experimental evidence that the method gives improvement in running time over other methods for searching in highdimensional spaces based on hierarchical tree decomposition."
            },
            "venue": {
                "fragments": [],
                "text": "VLDB"
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Netflix Prize. Proceedings of KDD Cup and Workshop"
            },
            "venue": {
                "fragments": [],
                "text": "The Netflix Prize. Proceedings of KDD Cup and Workshop"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vowpal wabbit online learning project"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Netflix Prize. Proceedings of KDD Cup and Workshop"
            },
            "venue": {
                "fragments": [],
                "text": "The Netflix Prize. Proceedings of KDD Cup and Workshop"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 148
                            }
                        ],
                        "text": "\u2026the value of the inner product w, \nfu(x) is bounded by 2/2 - m-1 w 22 x 22+ w 8 x 8/3 Pr {| w, fu(x) | >E}= 2e Proof We use Bernstein s \ninequality (Bernstein, 1946), which states that for independent random variables Xj, with E [Xj ]=0,if \nC> 0 is such that |Xj|= C, then .. n t2/2 .. Pr Xj >t\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 36
                            }
                        ],
                        "text": "Proof We use Bernstein\u2019s inequality (Bernstein, 1946), which states that for independent random variables Xj , with E [Xj ] = 0, if C > 0 is such that |Xj | \u2264 C, then"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The theory of probabilities. Moscow: Gastehizdat Publishing House"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1946
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Random features for largescale kernel machines Advances in neural information processing systems 20"
            },
            "venue": {
                "fragments": [],
                "text": "Random features for largescale kernel machines Advances in neural information processing systems 20"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hash kernels. Proc. Intl. Workshop on Artificial Intelligence and Statistics 12"
            },
            "venue": {
                "fragments": [],
                "text": "Hash kernels. Proc. Intl. Workshop on Artificial Intelligence and Statistics 12"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The details of this contradiction are best presented through (Weinberger et al., 2009, Corollary 5) as follows. Set m = 128 and \u03b4 = 1/2 and consider the vertices of then-simplex inRn+1"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Feature hashing for large scale multitask learning"
            },
            "venue": {
                "fragments": [],
                "text": "26th International Conference on Machine Learning"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 17
                            }
                        ],
                        "text": "Personalization (Daume, 2007) introduced a very sim\u00adple but strikingly \neffective method for multitask learning."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 16
                            }
                        ],
                        "text": "Personalization (Daume, 2007) introduced a very simple but strikingly effective method for multitask learning."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Frustratingly easy domain adaptation. Annual Meeting of the Association for Computational Linguistics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "For a given vector x, define the diagonal matrix Dx as (Dx)jj = xj . For any matrix A \u2208 Rm\u00d7d, define \u2225x\u2225A \u2261 \u2225ADx\u22252\u21922"
            },
            "venue": {
                "fragments": [],
                "text": "Lemma 2 (Liberty et al.,"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "2007).Vowpal wabbit online learning project (Technical Report)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 1
                            }
                        ],
                        "text": "(Rahimi &#38; Recht, 2009) extend this to sparse approximation of weighted combinations of ba\u00adsis functions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Randomized kitchen sinks"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in neural information processing systems 21"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 1
                            }
                        ],
                        "text": "(Rahimi &#38; Recht, 2008) \nuse Bochner s theorem and sam\u00adpling to obtain approximate inner products for Radial Ba\u00adsis Function kernels."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Random features for largescale kernel machines"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in neural information processing systems 20"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vowpal wabbit online learning project"
            },
            "venue": {
                "fragments": [],
                "text": "Vowpal wabbit online learning project"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 14
                            }
                        ],
                        "text": "In addition, (Langford et al., \n2007) released the Vowpal Wabbit fast online learn\u00ading software which uses a hash representation similar \nto that discussed here."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 4
                            }
                        ],
                        "text": "Rm (Langford et al., 2007; Shi et al., 2009)."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vow - pal wabbit online learning project ( Technical Report )"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 69
                            }
                        ],
                        "text": "Pioneered by (Ailon & Chazelle, 2006), there has been a line of work (Ailon & Liberty, 2008; Matousek, 2008) on improving the complexity of random projection by using various code-matrices in order to preprocess the input vectors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On variants of the Johnson"
            },
            "venue": {
                "fragments": [],
                "text": "Lindenstrauss lemma. Random Structures and Algorithms,"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Frustratingly easy domain adaptation. . ACL"
            },
            "venue": {
                "fragments": [],
                "text": "Frustratingly easy domain adaptation. . ACL"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Frustratingly easy domain adaptation. Annual Meeting-Associa for Computation Linguistics"
            },
            "venue": {
                "fragments": [],
                "text": "Frustratingly easy domain adaptation. Annual Meeting-Associa for Computation Linguistics"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Problems and results in extremal combinatorics , Part I. Discrete Math"
            },
            "venue": {
                "fragments": [],
                "text": "Problems and results in extremal combinatorics , Part I. Discrete Math"
            },
            "year": 2003
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 4,
            "methodology": 6
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 39,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Feature-hashing-for-large-scale-multitask-learning-Weinberger-Dasgupta/00bbfde6af97ce5efcf86b3401d265d42a95603d?sort=total-citations"
}