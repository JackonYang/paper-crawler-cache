{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1859405"
                        ],
                        "name": "David E. Moriarty",
                        "slug": "David-E.-Moriarty",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Moriarty",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David E. Moriarty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686788"
                        ],
                        "name": "R. Miikkulainen",
                        "slug": "R.-Miikkulainen",
                        "structuredName": {
                            "firstName": "Risto",
                            "lastName": "Miikkulainen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Miikkulainen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 30
                            }
                        ],
                        "text": "The second two systems, SANE (Moriarty and Miikkulainen, 1996) and ESP (Gomez and Miikkulainen, 1999), evolved populations of neurons and a population of network blueprints that specifies how to build networks from the neurons that are assembled into fixed-topology networks for evaluation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 50
                            }
                        ],
                        "text": "Earlier comparisons were done with a single pole (Moriarty and Miikkulainen, 1996), but this version of the task has become too easy for modern methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 191
                            }
                        ],
                        "text": "Past studies have shown NE to be faster and more efficient than reinforcement learning methods such as Adaptive Heuristic Critic and Q-Learning on single pole balancing and robot arm control (Moriarty 1997; Moriarty and Miikkulainen 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "ESP improves over SANE by maintaining a separate population for each hidden neuron position in the complete network."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 192
                            }
                        ],
                        "text": "Past studies have shown NE to be faster and more efficient than reinforcement learning methods such as Adaptive Heuristic Critic and Q-Learning on single pole balancing and robot arm control (Moriarty and Miikkulainen, 1996; Moriarty, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 29
                            }
                        ],
                        "text": "The second two systems, SANE (Moriarty and Miikkulainen 1996) and ESP (Gomez and Miikkulainen 1999), evolved populations of neurons and a population of network blueprints that specifies how to build networks from the neurons that are assembled into fixedtopology networks for evaluation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "SANE maintains a single population of neurons."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 49
                            }
                        ],
                        "text": "Earlier comparisons were done with a single pole (Moriarty and Miikkulainen 1996), but this version of the task has become too easy for modern methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 267
                            }
                        ],
                        "text": "\u20262 113\nNE methods for two reasons: (1) The focus is on developing and demonstrating better performance on evolving neural networks and (2) NE methods in this comparison have outperformed reinforcement learning methods in prior comparisons on the pole balancing task (Moriarty and Miikkulainen, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 314,
                                "start": 282
                            }
                        ],
                        "text": "However, we limit the comparisons in this paper to NE methods for two reasons: (1) The focus is on developing and demonstrating better performance on evolving neural networks and (2) NE methods in this comparison have been shown superior to reinforcement learning methods elsewhere (Moriarty and Miikkulainen 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 608769,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb01aa49fdd9b59127b8651b36fa187095097799",
            "isKey": false,
            "numCitedBy": 197,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "This article presents a new reinforcement learning method called SANE (Symbiotic, Adaptive Neuro-Evolution), which evolves a population of neurons through genetic algorithms to form a neural network capable of performing a task. Symbiotic evolution promotes both cooperation and specialization, which results in a fast, efficient genetic search and discourages convergence to suboptimal solutions. In the inverted pendulum problem, SANE formed effective networks 9 to 16 times faster than the Adaptive Heuristic Critic and 2 times faster thanQ-learning and the GENITOR neuro-evolution approach without loss of generalization. Such efficient learning, combined with few domain assumptions, make SANE a promising approach to a broad range of reinforcement learning problems, including many real-world applications."
            },
            "slug": "Efficient-reinforcement-learning-through-symbiotic-Moriarty-Miikkulainen",
            "title": {
                "fragments": [],
                "text": "Efficient reinforcement learning through symbiotic evolution"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A new reinforcement learning method called SANE (Symbiotic, Adaptive Neuro-Evolution), which evolves a population of neurons through genetic algorithms to form a neural network capable of performing a task, is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145842938"
                        ],
                        "name": "Faustino J. Gomez",
                        "slug": "Faustino-J.-Gomez",
                        "structuredName": {
                            "firstName": "Faustino",
                            "lastName": "Gomez",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Faustino J. Gomez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686788"
                        ],
                        "name": "R. Miikkulainen",
                        "slug": "R.-Miikkulainen",
                        "structuredName": {
                            "firstName": "Risto",
                            "lastName": "Miikkulainen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Miikkulainen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 82
                            }
                        ],
                        "text": "The second two systems, SANE (Moriarty and Miikkulainen, 1996) and ESP (Gomez and Miikkulainen, 1999), evolved populations of neurons and a population of network blueprints that specifies how to build networks from the neurons that are assembled into fixed-topology networks for evaluation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 86
                            }
                        ],
                        "text": "We set up the pole balancing experiments as described by Wieland (1991) and Gomez and Miikkulainen (1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 144
                            }
                        ],
                        "text": "\u2026is easily represented through recurrent connections in neural networks, making NE a natural choice for learning non-Markovian tasks (Gomez and Miikkulainen, 1999, 2002).\nc\u00a92002 by the Massachusetts Institute of Technology Evolutionary Computation 10(2): 99-127\nIn traditional NE approaches, a\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 72
                            }
                        ],
                        "text": "A fixed-topology method called Enforced Subpopulations (ESP) (Gomez and Miikkulainen, 1999) was able to solve the same problem 5 times faster simply by restarting with a random number of hidden neurons whenever it became stuck ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 166
                            }
                        ],
                        "text": "Neuroevolution (NE), the artificial evolution of neural networks using genetic algorithms, has shown great promise in complex reinforcement learning tasks (Gomez and Miikkulainen, 1999; Gruau et al., 1996; Moriarty and Miikkulainen, 1997; Potter et al., 1995; Whitley et al., 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1554231,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e1d8c5d31ba295dcac4ec93ffdee31682c00c4b8",
            "isKey": false,
            "numCitedBy": 278,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "The success of evolutionary methods on standard control learning tasks has created a need for new benchmarks. The classic pole balancing problem is no longer difficult enough to serve as a viable yardstick for measuring the learning efficiency of these systems. The double pole case, where two poles connected to the cart must be balanced simultaneously is much more difficult, especially when velocity information is not available. In this article, we demonstrate a neuroevolution system, Enforced Sub-populations (ESP), that is used to evolve a controller for the standard double pole task and a much harder, non-Markovian version. In both cases, our results show that ESP is faster than other neuroevolution methods. In addition, we introduce an incremental method that evolves on a sequence of tasks, and utilizes a local search technique (Delta-Coding) to sustain diversity. This method enables the system to solve even more difficult versions of the task where direct evolution cannot."
            },
            "slug": "Solving-Non-Markovian-Control-Tasks-with-Gomez-Miikkulainen",
            "title": {
                "fragments": [],
                "text": "Solving Non-Markovian Control Tasks with Neuro-Evolution"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This article demonstrates a neuroevolution system, Enforced Sub-populations (ESP), that is used to evolve a controller for the standard double pole task and a much harder, non-Markovian version, and introduces an incremental method that evolves on a sequence of tasks, and utilizes a local search technique (Delta-Coding) to sustain diversity."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718584"
                        ],
                        "name": "P. Angeline",
                        "slug": "P.-Angeline",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Angeline",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Angeline"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33047146"
                        ],
                        "name": "G. M. Saunders",
                        "slug": "G.-M.-Saunders",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Saunders",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. M. Saunders"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145539951"
                        ],
                        "name": "J. Pollack",
                        "slug": "J.-Pollack",
                        "structuredName": {
                            "firstName": "Jordan",
                            "lastName": "Pollack",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pollack"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 0
                            }
                        ],
                        "text": "Angeline et al. (1993) implemented a system called GeNeralized Acquisition of Recurrent Links (GNARL), commenting that \u201cthe prospect of evolving connectionist networks with crossover appears limited in general.\u201d"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 91
                            }
                        ],
                        "text": "4 Initial Random Ablation TWEANNs other than NEAT typically start with a random population (Angeline et al., 1993; Gruau et al., 1996; Yao, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 110
                            }
                        ],
                        "text": "Many systems have been developed over the last decade that evolve both neural network topologies and weights (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Gruau et al., 1996; Krishnan and Ciesielski, 1994; Lee and Kim, 1996;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 13
                            }
                        ],
                        "text": "For example, Angeline et al. (1993) claimed that crossover in TWEANNs does more harm than good."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 403,
                                "start": 133
                            }
                        ],
                        "text": "Direct encoding schemes, employed by most TWEANNs, specify in the genome every connection and node that will appear in the phenotype (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and M\u00fchlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 417,
                                "start": 109
                            }
                        ],
                        "text": "Many systems have been developed over the last decade that evolve both neural network topologies and weights (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Gruau et al., 1996; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Mandischer, 1993; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and M\u00fchlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 134
                            }
                        ],
                        "text": "Direct encoding schemes, employed by most TWEANNs, specify in the genome every connection and node that will appear in the phenotype (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Krishnan and Ciesielski, 1994; Lee and Kim, 1996;\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 117
                            }
                        ],
                        "text": "There has also been a great deal of interest in evolving network topologies as well as weights over the last decade (Angeline et al., 1993; Branke, 1995; Gruau et al., 1996; Yao, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 44767,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fba6007d482db5fbe8cd6c3af90fe0922453e1d2",
            "isKey": true,
            "numCitedBy": 1072,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "Standard methods for simultaneously inducing the structure and weights of recurrent neural networks limit every task to an assumed class of architectures. Such a simplification is necessary since the interactions between network structure and function are not well understood. Evolutionary computations, which include genetic algorithms and evolutionary programming, are population-based search methods that have shown promise in many similarly complex tasks. This paper argues that genetic algorithms are inappropriate for network acquisition and describes an evolutionary program, called GNARL, that simultaneously acquires both the structure and weights for recurrent networks. GNARL's empirical acquisition method allows for the emergence of complex behaviors and topologies that are potentially excluded by the artificial architectural constraints imposed in standard network induction methods."
            },
            "slug": "An-evolutionary-algorithm-that-constructs-recurrent-Angeline-Saunders",
            "title": {
                "fragments": [],
                "text": "An evolutionary algorithm that constructs recurrent neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is argued that genetic algorithms are inappropriate for network acquisition and an evolutionary program is described, called GNARL, that simultaneously acquires both the structure and weights for recurrent networks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1859405"
                        ],
                        "name": "David E. Moriarty",
                        "slug": "David-E.-Moriarty",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Moriarty",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David E. Moriarty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686788"
                        ],
                        "name": "R. Miikkulainen",
                        "slug": "R.-Miikkulainen",
                        "structuredName": {
                            "firstName": "Risto",
                            "lastName": "Miikkulainen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Miikkulainen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 276,
                                "start": 155
                            }
                        ],
                        "text": "Neuroevolution (NE), the artificial evolution of neural networks using genetic algorithms, has shown great promise in complex reinforcement learning tasks (Gomez and Miikkulainen 1999; Gruau et al. 1996; Moriarty and Miikkulainen 1997; Potter et al. 1995; Whitley et al. 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 206
                            }
                        ],
                        "text": "Neuroevolution (NE), the artificial evolution of neural networks using genetic algorithms, has shown great promise in complex reinforcement learning tasks (Gomez and Miikkulainen, 1999; Gruau et al., 1996; Moriarty and Miikkulainen, 1997; Potter et al., 1995; Whitley et al., 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7885480,
            "fieldsOfStudy": [
                "Biology",
                "Psychology"
            ],
            "id": "3564c49d34c1642cf52606665440b8d2754510d8",
            "isKey": false,
            "numCitedBy": 341,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "This article demonstrates the advantages of a cooperative, coevolutionary search in difficult control problems. The symbiotic adaptive neuroevolution (SANE) system coevolves a population of neurons that cooperate to form a functioning neural network. In this process, neurons assume different but overlapping roles, resulting in a robust encoding of control behavior. SANE is shown to be more efficient and more adaptive and to maintain higher levels of diversity than the more common network-based population approaches. Further empirical studies illustrate the emergent neuron specializations and the different roles the neurons assume in the population."
            },
            "slug": "Forming-Neural-Networks-Through-Efficient-and-Moriarty-Miikkulainen",
            "title": {
                "fragments": [],
                "text": "Forming Neural Networks Through Efficient and Adaptive Coevolution"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "The symbiotic adaptive neuroevolution system coevolves a population of neurons that cooperate to form a functioning neural network to be more efficient and more adaptive and to maintain higher levels of diversity than the more common network-based population approaches."
            },
            "venue": {
                "fragments": [],
                "text": "Evolutionary Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692756"
                        ],
                        "name": "Byoung-Tak Zhang",
                        "slug": "Byoung-Tak-Zhang",
                        "structuredName": {
                            "firstName": "Byoung-Tak",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Byoung-Tak Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680145"
                        ],
                        "name": "H. M\u00fchlenbein",
                        "slug": "H.-M\u00fchlenbein",
                        "structuredName": {
                            "firstName": "Heinz",
                            "lastName": "M\u00fchlenbein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. M\u00fchlenbein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords Genetic algorithms, neural networks, neuroevolution, network topologies, speciation, competing conventions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15411602,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "386dbcb3fb713410d5a6a1b4bf4ecf35d18e8d28",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 95,
            "paperAbstract": {
                "fragments": [],
                "text": "Genetic algorithms have had two primary applications for neural networks: optimization of network architecture, and training weights of a fixed architecture. While most previous work focuses on one or the other of these options, this paper investigates an alternative evolutionary approach-breeder genetic programming (BGP)-in which the architecture and the weights are optimized simultaneously. In this method, the genotype of each network is represented as a tree whose depth and width are dynamically adapted to the particular application by specifically defined genetic operators. The weights are trained by a next-ascent hillclimbing search . A new fitness function is proposed that quantifies the principle of Occam's razor ; it makes an optimal trade-off between the error fitting ability and the parsimony of the network. Simulation results on two benchmark problems of differing complexity suggest that the method finds minimal networks on clean data. The experiments on noisy data show that using Occam's razor not only improves the generalization performance, it also accelerates convergence."
            },
            "slug": "Evolving-Optimal-Neural-Networks-Using-Genetic-with-Zhang-M\u00fchlenbein",
            "title": {
                "fragments": [],
                "text": "Evolving Optimal Neural Networks Using Genetic Algorithms with Occam's Razor"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper investigates an alternative evolutionary approach-breeder genetic programming (BGP)-in which the architecture and the weights are optimized simultaneously, in which the genotype of each network is represented as a tree whose depth and width are dynamically adapted to the particular application by specifically defined genetic operators."
            },
            "venue": {
                "fragments": [],
                "text": "Complex Syst."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701352"
                        ],
                        "name": "P. Darwen",
                        "slug": "P.-Darwen",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Darwen",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Darwen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 165
                            }
                        ],
                        "text": "However, evolution tends to find the simplest solutions that can win, meaning that strategies oscillate between different idiosyncratic yet uninteresting variations (Darwen, 1996; Rosin and Belew, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61017974,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a9dee0c1ec3d479c7684eeef3b7022625436d3f6",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 199,
            "paperAbstract": {
                "fragments": [],
                "text": "This thesis discovers and describes some problems in both co-evolutionary learning and genetic algorithm (GA) speciation, and uses this understanding to improve co-evolutionary learning. Ever since Art Samuel's early checkers program, a seductive idea for creating expertise arti cially is to have a collection of individuals compete against each other. This can cause an escalating \\arms race\" of innovation and increasing sophistication. Co-evolutionary genetic algorithms are a recent version of this concept. Co-evolutionary learning is suitable for a range of management and control problems, such as controlling a stock portfolio, and numerous military tasks. We study the most intuitive of such problems, learning to play a simple game of con ict, but our results are relevant to many important real-world problems. We demonstrate why co-evolution can sometimes fail (and fail spectacularly) to cause the desired escalation of expertise. In most games, and in related problems of management and control, there is more than one good strategy. Genetic drift causes a GA to nd only one high-quality strategy. In a co-evolutionary environment, it then over-specialises to that one strategy, creating expertise that is na\u007f vely vulnerable to other strategies. This can cause mass extinctions, when a random mutation is novel enough to exploit its overspecialised opponents. With this explanation in mind, we then show that some plausible modi cations to the co-evolutionary GA do not greatly improve this poor generalisation ability. To induce a smoothly escalating level of expertise, more radical modi cation is needed. Speciation o ers a way to improve the generalisation ability of co-evolutionary learning: a speciated co-evolving GA can automatically nd all the high-quality strategies for a game of con ict, preventing convergence to only one strategy and the over-specialisation that causes. We scrutinise a pair of sharing-based GA speciation methods, and discover some hitherto unknown problems which can cause poor results. Knowing these aws, we implement and validate some improvements. Some previous researchers have studied speciated co-evolutionary systems, but failed to utilise the diverse expertise embodied in the various species. Instead, they have used only the best individual, and discarded the rest of the population. This is a waste of learning: for tasks (such as learning a game) where generalisation to a wide range of possible opponents is desirable, a diverse ensemble of specialised strategies is usually more versatile than a single individual. We extend co-evolutionary learning beyond that level. Many real-world problems are too di cult to solve with a monolithic solution. The standard solution is a modular approach, where di erent sub-solutions deal with di erent aspects of the problem. For a game of con ict (and numerous management and control problems), Australian Defence Force Academy Page v di erent contingency strategies must be separately re ned and specialised to suit di erent possible opponents or situations. A committee of human experts usually decides how to manually modularise the system into sub-solutions. Their choice can be less than optimal, and does not always re ect the underlying structure of the problem. Manual modularisation relies on a priori knowledge of the problem. However, such knowledge is often di cult and costly to obtain for real-world problems. Speciation can divide responsibilities automatically. In the example problem of learning a game, a speciated co-evolutionary genetic algorithm can produce a repertoire of complementary high-quality strategies, where each species is a good opponent for another species. We describe a simple gating algorithm for combining these di erent strategies into a single high-level strategy. This gating algorithm uses majority voting. This approach generalises better than the best individual in the nal generation of the GA, with or without speciation and co-evolution. This validates our modular approach over the earlier method of simply using the best individual. It also demonstrates that speciation as automatic modularisation is a promising method of realising the potential of co-evolutionary learning. Page vi University College, The University of New South Wales Australian Defence Force Academy Page vii Acknowledgements First and foremost, many thanks are due to my supervisor, Dr. Xin Yao. His advice, support, and encouragement have been absolutely rst-class, and he has been the best supervisor any student could possibly have wanted. Dr. Bob McKay has been an excellent co-supervisor, especially in nding ambiguities and loopholes in my writing. Thanks are also due to those who answered my unsolicited questions over the years, including Samir Mahfoud, Simon Ronald, Rik Belew, Risto Miikulainen, David Moriarty, Greg Werner, Liane Gabora, David Fogel, Zbigniew Michalewicz, Steve Hubbard, Paul Donnelly, Robert Smith, Steven Salzberg, Robert Congleton, Peter Angeline, Stephen Hood, Mark Nelson, Alan Meyrowitz, Mitchell Potter, and last but not least my namesakes Hugh Darwen and Jamie Darwen. I would also like to thank the many people at ADFA's School of Computer Science who have helped me over the years. The group of people working on evolutionary computation at ADFA have provided many productive discussions and exchanges, including Peter Whigham, Yong Liu, Guangmin Lin, and Jason Bobbin. The postgraduate conveners during my time here, rst Dr. Bob McKay and lately Mrs. Miriam Fergusson, have provided excellent support mechanisms to encourage postgraduate research. I would also like to thank our secretariat, Eileen Trott, Helen Foot, Pam Giannakakis (n ee Trianta llopoulos), Maxine Kelly, and Alison McMaster. I would also like to thank our head of department, Professor Charles Newton, who has encouraged postgraduate research by nding the funds to let us present papers at conferences whenever possible. I also thank ATERB for funding to travel to a conference Several excellent public-domain genetic algorithm packages are available. This thesis has used and modi ed John Grefenstette's excellent GENESIS 5.0 package. Australian Defence Force Academy Page ix"
            },
            "slug": "Co-Evolutionary-Learning-by-Automatic-with-Darwen",
            "title": {
                "fragments": [],
                "text": "Co-Evolutionary Learning by Automatic Modularisation with Speciation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is demonstrated why co-evolution can sometimes fail (and fail spectacularly) to cause the desired escalation of expertise, and why a simple gating algorithm for combining these di erent strategies into a single high-level strategy is a way to improve the generalisation ability of co- Evolutionary learning."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145842938"
                        ],
                        "name": "Faustino J. Gomez",
                        "slug": "Faustino-J.-Gomez",
                        "structuredName": {
                            "firstName": "Faustino",
                            "lastName": "Gomez",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Faustino J. Gomez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686788"
                        ],
                        "name": "R. Miikkulainen",
                        "slug": "R.-Miikkulainen",
                        "structuredName": {
                            "firstName": "Risto",
                            "lastName": "Miikkulainen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Miikkulainen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 86
                            }
                        ],
                        "text": "A parallel can be drawn between structure evolution in NEAT and incremental evolution (Gomez and Miikkulainen, 1997; Wieland, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2209222,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8939e9298eedb90aa4f040ab8e9f16872089a495",
            "isKey": false,
            "numCitedBy": 505,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Several researchers have demonstrated how complex action sequences can be learned through neuroevolution (i.e., evolving neural networks with genetic algorithms). However, complex general behavior such as evading predators or avoiding obstacles, which is not tied to specific environments, turns out to be very difficult to evolve. Often the system discovers mechanical strategies, such as moving back and forth, that help the agent cope but are not very effective, do not appear believable, and do not generalize to new environments. The problem is that a general strategy is too difficult for the evolution system to discover directly. This article proposes an approach wherein such complex general behavior is learned incrementally, by starting with simpler behavior and gradually making the task more challenging and general. The task transitions are implemented through successive stages of Delta coding (i.e., evolving modifications), which allows even converged populations to adapt to the new task. The method is tested in the stochastic, dynamic task of prey capture and is compared with direct evolution. The incremental approach evolves more effective and more general behavior and should also scale up to harder tasks."
            },
            "slug": "Incremental-Evolution-of-Complex-General-Behavior-Gomez-Miikkulainen",
            "title": {
                "fragments": [],
                "text": "Incremental Evolution of Complex General Behavior"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This article proposes an approach wherein complex general behavior is learned incrementally, by starting with simpler behavior and gradually making the task more challenging and general, which evolves more effective and more general behavior."
            },
            "venue": {
                "fragments": [],
                "text": "Adapt. Behav."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752379"
                        ],
                        "name": "D. Opitz",
                        "slug": "D.-Opitz",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Opitz",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Opitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734317"
                        ],
                        "name": "J. Shavlik",
                        "slug": "J.-Shavlik",
                        "structuredName": {
                            "firstName": "Jude",
                            "lastName": "Shavlik",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shavlik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 417,
                                "start": 109
                            }
                        ],
                        "text": "Many systems have been developed over the last decade that evolve both neural network topologies and weights (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Gruau et al., 1996; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Mandischer, 1993; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and M\u00fchlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 203
                            }
                        ],
                        "text": "\u2026al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Gruau et al., 1996; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Mandischer, 1993; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and Mu\u0308hlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 403,
                                "start": 133
                            }
                        ],
                        "text": "Direct encoding schemes, employed by most TWEANNs, specify in the genome every connection and node that will appear in the phenotype (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and M\u00fchlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 225,
                                "start": 202
                            }
                        ],
                        "text": "\u2026appear in the phenotype (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and Mu\u0308hlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1645467,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d49a9c7d9659dadf389e22d56547cc7abf025d86",
            "isKey": true,
            "numCitedBy": 82,
            "numCiting": 146,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm that learns from a set of examples should ideally be able to exploit the available resources of (a) abundant computing power and (b) domain-specific knowledge to improve its ability to generalize. Connectionist theory-refinement systems, which use background knowledge to select a neural network's topology and initial weights, have proven to be effective at exploiting domain-specific knowledge; however, most do not exploit available computing power. This weakness occurs because they lack the ability to refine the topology of the neural networks they produce, thereby limiting generalization, especially when given impoverished domain theories. We present the Regent algorithm which uses (a) domain-specific knowledge to help create an initial population of knowledge-based neural networks and (b) genetic operators of crossover and mutation (specifically designed for knowledge-based networks) to continually search for better network topologies. Experiments on three real-world domains indicate that our new algorithm is able to significantly increase generalization compared to a standard connectionist theory-refinement system, as well as our previous algorithm for growing knowledge-based networks."
            },
            "slug": "Connectionist-Theory-Refinement:-Genetically-the-of-Opitz-Shavlik",
            "title": {
                "fragments": [],
                "text": "Connectionist Theory Refinement: Genetically Searching the Space of Network Topologies"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The Regent algorithm is presented, which uses domain-specific knowledge to help create an initial population of knowledge-based neural networks and genetic operators of crossover and mutation to continually search for better network topologies."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145842938"
                        ],
                        "name": "Faustino J. Gomez",
                        "slug": "Faustino-J.-Gomez",
                        "structuredName": {
                            "firstName": "Faustino",
                            "lastName": "Gomez",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Faustino J. Gomez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686788"
                        ],
                        "name": "R. Miikkulainen",
                        "slug": "R.-Miikkulainen",
                        "structuredName": {
                            "firstName": "Risto",
                            "lastName": "Miikkulainen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Miikkulainen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62752350,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "9cdb78c0c6d237122d714885e1248080589a869f",
            "isKey": false,
            "numCitedBy": 181,
            "numCiting": 167,
            "paperAbstract": {
                "fragments": [],
                "text": "Many complex control problems require sophisticated solutions that are not amenable to traditional controller design. Not only is it difficult to model real world systems, but often it is unclear what kind of behavior is required to solve the task. Reinforcement learning approaches have made progress in such problems, but have so far not scaled well. Neuroevolution, has improved upon conventional reinforcement learning, but has still not been successful in full-scale, non-linear control problems. This dissertation develops a methodology for solving real world control tasks consisting of three components: (1)\u00a0an efficient neuroevolution algorithm that solves difficult non-linear control tasks by coevolving neurons, (2)\u00a0an incremental evolution method to scale the algorithm to the most challenging tasks, and (3)\u00a0a technique for making controllers robust so that they can transfer from simulation to the real world. The method is faster than other approaches on a set of difficult learning benchmarks, and is used in two full-scale control tasks demonstrating its applicability to real world problems."
            },
            "slug": "Robust-non-linear-control-through-neuroevolution-Gomez-Miikkulainen",
            "title": {
                "fragments": [],
                "text": "Robust non-linear control through neuroevolution"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This dissertation develops a methodology for solving real world control tasks consisting of an efficient neuroevolution algorithm that solves difficult non-linear control tasks by coevolving neurons, an incremental evolution method to scale the algorithm to the most challenging tasks, and a technique for making controllers robust so that they can transfer from simulation to the real world."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760426"
                        ],
                        "name": "V. Maniezzo",
                        "slug": "V.-Maniezzo",
                        "structuredName": {
                            "firstName": "Vittorio",
                            "lastName": "Maniezzo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Maniezzo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 20561554,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e589508e3095f96c034072b859561f31bcd6378b",
            "isKey": false,
            "numCitedBy": 483,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a system based on a parallel genetic algorithm with enhanced encoding and operational abilities. The system, used to evolve feedforward artificial neural networks, has been applied to two widely different problem areas: Boolean function learning and robot control. It is shown that the good results obtained in both cases are due to two factors: first, the enhanced exploration abilities provided by the search-space reducing evolution of both coding granularity and network topology, and, second, the enhanced exploitational abilities due to a recently proposed cooperative local optimizing genetic operator."
            },
            "slug": "Genetic-evolution-of-the-topology-and-weight-of-Maniezzo",
            "title": {
                "fragments": [],
                "text": "Genetic evolution of the topology and weight distribution of neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This paper proposes a system based on a parallel genetic algorithm with enhanced encoding and operational abilities that has been applied to two widely different problem areas: Boolean function learning and robot control."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2388305"
                        ],
                        "name": "D. Thierens",
                        "slug": "D.-Thierens",
                        "structuredName": {
                            "firstName": "Dirk",
                            "lastName": "Thierens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Thierens"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 243,
                                "start": 229
                            }
                        ],
                        "text": "Because TWEANNs do not satisfy strict constraints on the kinds of topologies they produce, proposed solutions to the competing conventions problem for fixed or constrained topology networks such as nonredundant genetic encoding (Thierens, 1996) do not apply."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15159460,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fde9a5e98958ed8126377780a07f756cd57682f5",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Feedforward neural networks have a number of functionally equivalent symmetries that make them difficult to optimise with genetic recombination operators. Although this problem has received considerable attention in the past, the proposed solutions all have a heuristic nature. We discuss a neural network genotype representation that completely eliminates the functional redundancies by transforming each neural network into its canonical form. This transformation is computationally extremely simple, since it only requires flipping the sign of some of the weights, followed by sorting the hidden neurons according to their bias. We have compared the redundant and non-redundant representations on the basis of their crossover correlation coefficient. As expected, the redundancy elimination results in a much higher crossover correlation coefficient, which shows that more information is now transmitted from the parents to the children. Finally, experimental results are given for the two-spirals classification problem."
            },
            "slug": "Non-redundant-genetic-coding-of-neural-networks-Thierens",
            "title": {
                "fragments": [],
                "text": "Non-redundant genetic coding of neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A neural network genotype representation that completely eliminates the functional redundancies by transforming each neural network into its canonical form is discussed, which is computationally extremely simple."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Evolutionary Computation"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710856"
                        ],
                        "name": "D. Dasgupta",
                        "slug": "D.-Dasgupta",
                        "structuredName": {
                            "firstName": "Dipankar",
                            "lastName": "Dasgupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Dasgupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145624039"
                        ],
                        "name": "D. McGregor",
                        "slug": "D.-McGregor",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "McGregor",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. McGregor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 147
                            }
                        ],
                        "text": "\u2026have been developed over the last decade that evolve both neural network topologies and weights (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Gruau et al., 1996; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Mandischer, 1993;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 150
                            }
                        ],
                        "text": "\u2026by most TWEANNs, specify in the genome every connection and node that will appear in the phenotype (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Maniezzo, 1994; Opitz and Shavlik,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 188
                            }
                        ],
                        "text": "Unfortunately, quantitative performance comparisons are dif-\n112 Evolutionary Computation Volume 10, Number 2\nficult in this domain because the methodologies vary widely across experiments (Dasgupta and McGregor, 1992; Pujol and Poli, 1998; Yao and Shi, 1995; Zhang and Mu\u0308hlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 79
                            }
                        ],
                        "text": "ficult in this domain because the methodologies vary widely across experiments (Dasgupta and McGregor, 1992; Pujol and Poli, 1998; Yao and Shi, 1995; Zhang and M\u00fchlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 403,
                                "start": 133
                            }
                        ],
                        "text": "Direct encoding schemes, employed by most TWEANNs, specify in the genome every connection and node that will appear in the phenotype (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and M\u00fchlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 13
                            }
                        ],
                        "text": "For example, Dasgupta and McGregor (1992) use such an encoding in their method, called Structured Genetic Algorithm (sGA), where a bit string represents the connection matrix of a network. sGA is notable for its simplicity, allowing it to operate almost like a standard GA."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 417,
                                "start": 109
                            }
                        ],
                        "text": "Many systems have been developed over the last decade that evolve both neural network topologies and weights (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Gruau et al., 1996; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Mandischer, 1993; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and M\u00fchlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14049704,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b9e17dab48963519bd0abab630d9343a8ac9b57c",
            "isKey": true,
            "numCitedBy": 163,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Presents a different type of genetic algorithm called the structured genetic algorithm (SGA) for the design of application-specific neural networks. The novelty of this new genetic approach is that it can determine the network structures and their weights solely by an evolutionary process. This is made possible for the SGA primarily due to its redundant genetic material and a gene activation mechanism which in combination provide a multi-layered structure to the chromosome. The authors focus on the use of this learning algorithm for automatic generation of a complete application specific neural network. With this approach, no a priori assumptions about topology are needed and the only information required is the input and output characteristics of the task. The empirical studies show that the SGA can efficiently determine the network size and topology along with the optimal set of connection weights appropriate for desired tasks, without using backpropagation or any other learning algorithm.<<ETX>>"
            },
            "slug": "Designing-application-specific-neural-networks-the-Dasgupta-McGregor",
            "title": {
                "fragments": [],
                "text": "Designing application-specific neural networks using the structured genetic algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The empirical studies show that the SGA can efficiently determine the network size and topology along with the optimal set of connection weights appropriate for desired tasks, without using backpropagation or any other learning algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] COGANN-92: International Workshop on Combinations of Genetic Algorithms and Neural Networks"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143901532"
                        ],
                        "name": "X. Yao",
                        "slug": "X.-Yao",
                        "structuredName": {
                            "firstName": "Xin",
                            "lastName": "Yao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Yao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 91
                            }
                        ],
                        "text": "4 Initial Random Ablation TWEANNs other than NEAT typically start with a random population (Angeline et al., 1993; Gruau et al., 1996; Yao, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 174
                            }
                        ],
                        "text": "There has also been a great deal of interest in evolving network topologies as well as weights over the last decade (Angeline et al., 1993; Branke, 1995; Gruau et al., 1996; Yao, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13958007,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ac303258fd7f522fd3e4f172b97bb17eb888598",
            "isKey": false,
            "numCitedBy": 1175,
            "numCiting": 363,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning and evolution are two fundamental forms of adaptation. There has been a great interest in combining learning and evolution with artificial neural networks (ANN\u2019s) in recent years. This paper: 1) reviews different combinations between ANN\u2019s and evolutionary algorithms (EA\u2019s), including using EA\u2019s to evolve ANN connection weights, architectures, learning rules, and input features; 2) discusses different search operators which have been used in various EA\u2019s; and 3) points out possible future research directions. It is shown, through a considerably large literature review, that combinations between ANN\u2019s and EA\u2019s can lead to significantly better intelligent systems than relying on ANN\u2019s or EA\u2019s alone."
            },
            "slug": "Evolving-Artificial-Neural-Networks-Yao",
            "title": {
                "fragments": [],
                "text": "Evolving Artificial Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown, through a considerably large literature review, that combinations between ANN\u2019s and EA\u2019\u2019 can lead to significantly better intelligent systems than relying on ANNs or EA\u201ds alone."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1392172819"
                        ],
                        "name": "J. Urgen Branke",
                        "slug": "J.-Urgen-Branke",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "Urgen Branke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Urgen Branke"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 140
                            }
                        ],
                        "text": "There has also been a great deal of interest in evolving network topologies as well as weights over the last decade (Angeline et al., 1993; Branke, 1995; Gruau et al., 1996; Yao, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7879428,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af9612b51f0bcab7013b239c333d17cf398d20b8",
            "isKey": false,
            "numCitedBy": 114,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural networks and genetic algorithms are two relatively young research areas that were subject to a steadily growing interest during the past years. Both models are inspired by nature, but whereas neural networks are concerned with learning of an individual (phenotypic learning), evolutionary algorithms deal with a population's adaptation to a changing environment (genotypic learning). This paper focuses on the intersection of neural networks and evolutionary computation , namely on how evolutionary algorithms can be used to assist neural network design and training. The purpose of the paper is to set forth the general considerations that have to be made when designing an algorithm in this area and to give an overview on how researchers addressed these issues in the past."
            },
            "slug": "Evolutionary-Algorithms-for-Neural-Network-Design-Branke",
            "title": {
                "fragments": [],
                "text": "Evolutionary Algorithms for Neural Network Design and Training"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The purpose of the paper is to set forth the general considerations that have to be made when designing an algorithm in this area and to give an overview on how researchers addressed these issues in the past."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713460"
                        ],
                        "name": "H. Abbass",
                        "slug": "H.-Abbass",
                        "structuredName": {
                            "firstName": "Hussein",
                            "lastName": "Abbass",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Abbass"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15010780,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7167ffc286bc18191b6ab8fd6b661ab049eeeaa2",
            "isKey": false,
            "numCitedBy": 153,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of backpropagation for training artificial neural networks (ANNs) is usually associated with a long training process. The user needs to experiment with a number of network architectures; with larger networks, more computational cost in terms of training time is required. The objective of this letter is to present an optimization algorithm, comprising a multiobjective evolutionary algorithm and a gradient-based local search. In the rest of the letter, this is referred to as the memetic Pareto artificial neural network algorithm for training ANNs. The evolutionary approach is used to train the network and simultaneously optimize its architecture. The result is a set of networks, with each network in the set attempting to optimize both the training error and the architecture. We also present a self-adaptive version with lower computational cost. We show empirically that the proposed method is capable of reducing the training time compared to gradientbased techniques."
            },
            "slug": "Speeding-Up-Backpropagation-Using-Multiobjective-Abbass",
            "title": {
                "fragments": [],
                "text": "Speeding Up Backpropagation Using Multiobjective Evolutionary Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The objective of this letter is to present an optimization algorithm, comprising a multiobjective evolutionary algorithm and a gradient-based local search, referred to as the memetic Pareto artificial neural network algorithm for training ANNs."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723475"
                        ],
                        "name": "D. Montana",
                        "slug": "D.-Montana",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Montana",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Montana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144286518"
                        ],
                        "name": "L. Davis",
                        "slug": "L.-Davis",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Davis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Davis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 239,
                                "start": 225
                            }
                        ],
                        "text": "Past studies have shown NE to be faster and more efficient than reinforcement learning methods such as Adaptive Heuristic Critic and Q-Learning on single pole balancing and robot arm control (Moriarty and Miikkulainen, 1996; Moriarty, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6336712,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "09920800fa7841c84a551d70c6101d9510e6fcc8",
            "isKey": false,
            "numCitedBy": 1119,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayered feedforward neural networks possess a number of properties which make them particularly suited to complex pattern classification problems. However, their application to some realworld problems has been hampered by the lack of a training algonthm which reliably finds a nearly globally optimal set of weights in a relatively short time. Genetic algorithms are a class of optimization procedures which are good at exploring a large and complex space in an intelligent way to find values close to the global optimum. Hence, they are well suited to the problem of training feedforward networks. In this paper, we describe a set of experiments performed on data from a sonar image classification problem. These experiments both 1) illustrate the improvements gained by using a genetic algorithm rather than backpropagation and 2) chronicle the evolution of the performance of the genetic algorithm as we added more and more domain-specific knowledge into it."
            },
            "slug": "Training-Feedforward-Neural-Networks-Using-Genetic-Montana-Davis",
            "title": {
                "fragments": [],
                "text": "Training Feedforward Neural Networks Using Genetic Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A set of experiments performed on data from a sonar image classification problem are described to illustrate the improvements gained by using a genetic algorithm rather than backpropagation and chronicle the evolution of the performance of the genetic algorithm as it added more and more domain-specific knowledge into it."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2158193072"
                        ],
                        "name": "Dong Chen",
                        "slug": "Dong-Chen",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145200131"
                        ],
                        "name": "C. L. Giles",
                        "slug": "C.-L.-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. L. Giles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148800040"
                        ],
                        "name": "G. Sun",
                        "slug": "G.-Sun",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Sun",
                            "middleNames": [
                                "Z."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769857"
                        ],
                        "name": "H. H. Chen",
                        "slug": "H.-H.-Chen",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Chen",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. H. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145040825"
                        ],
                        "name": "Y. C. Lee",
                        "slug": "Y.-C.-Lee",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Lee",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. C. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788202"
                        ],
                        "name": "M. Goudreau",
                        "slug": "M.-Goudreau",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Goudreau",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Goudreau"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords Genetic algorithms, neural networks, neuroevolution, network topologies, speciation, competing conventions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62618832,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f8c249709b436fdad1bf7efc61919dca6f494e3f",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "It is difficult to determine the minimal neural network structure for a particular automaton. A large recurrent network in practice is very difficult to train. Constructive or destructive recurrent methods might offer a solution to this problem. It is proved that one current method, recurrent cascade correlation, has fundamental limitations in representation and thus in its learning capabilities. A preliminary approach to circumventing these limitations by devising a simple constructive training method that adds neurons during training while still preserving the powerful fully recurrent structure is given. Through simulations it is shown that such a method can learn many types of regular grammars which the recurrent cascade correlation method is unable to learn.<<ETX>>"
            },
            "slug": "Constructive-learning-of-recurrent-neural-networks-Chen-Giles",
            "title": {
                "fragments": [],
                "text": "Constructive learning of recurrent neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is proved that one current method, recurrent cascade correlation, has fundamental limitations in representation and thus in its learning capabilities, and a preliminary approach to circumventing these limitations by devising a simple constructive training method."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE International Conference on Neural Networks"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777920"
                        ],
                        "name": "M. A. Potter",
                        "slug": "M.-A.-Potter",
                        "structuredName": {
                            "firstName": "Mitchell",
                            "lastName": "Potter",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. A. Potter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145502027"
                        ],
                        "name": "K. D. Jong",
                        "slug": "K.-D.-Jong",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Jong",
                            "middleNames": [
                                "A.",
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. D. Jong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1869443"
                        ],
                        "name": "J. Grefenstette",
                        "slug": "J.-Grefenstette",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Grefenstette",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Grefenstette"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 258,
                                "start": 239
                            }
                        ],
                        "text": "Neuroevolution (NE), the artificial evolution of neural networks using genetic algorithms, has shown great promise in complex reinforcement learning tasks (Gomez and Miikkulainen, 1999; Gruau et al., 1996; Moriarty and Miikkulainen, 1997; Potter et al., 1995; Whitley et al., 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14262564,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "id": "0b4d4c39c4e532699735c3077920ca3fe5b2a61c",
            "isKey": false,
            "numCitedBy": 181,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a coevolutionary approach to learning sequential decision rules which appears to have a number of advantages over non-coevolutionary approaches. The coevolutionary approach encourages the formation of stable niches representing simpler subbehaviors. The evolutionary direction of each subbehavior can be controlled independently, providing an alternative to evolving complex behavior using intermediate training steps. Results are presented showing a significant learning rate speedup over a noncoevolutionary approach in a simulated robot domain. In addition, the results suggest the coevolutionary approach may lead to emergent problem decompositions."
            },
            "slug": "A-Coevolutionary-Approach-to-Learning-Sequential-Potter-Jong",
            "title": {
                "fragments": [],
                "text": "A Coevolutionary Approach to Learning Sequential Decision Rules"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A coevolutionary approach to learning sequential decision rules which appears to have a number of advantages over non-coevolutionARY approaches and which may lead to emergent problem decompositions is presented."
            },
            "venue": {
                "fragments": [],
                "text": "ICGA"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701352"
                        ],
                        "name": "P. Darwen",
                        "slug": "P.-Darwen",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Darwen",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Darwen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115584711"
                        ],
                        "name": "X. Yao",
                        "slug": "X.-Yao",
                        "structuredName": {
                            "firstName": "Xin",
                            "lastName": "Yao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Yao"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 106
                            }
                        ],
                        "text": "Speciation has also been applied in the cooperative coevolution of modular systems of multiple solutions (Darwen and Yao, 1996; Potter and De Jong, 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9732683,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d058f31f00fc8f381a81f5673e6eae32e5d2be04",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Real-world problems are often too difficult to solve by a single monolithic system. There are many examples of natural and artificial systems which show that a modular approach can reduce the total complexity of the system while solving a difficult problem satisfactorily. The success of modular artificial neural networks in speech and image processing is a typical example. However, designing a modular system is a difficult task. It relies heavily on human experts and prior knowledge about the problem. There is no systematic and automatic way to form a modular system for a problem. This paper proposes a novel evolutionary learning approach to designing a modular system automatically, without human intervention. Our starting point is speciation, using a technique based on fitness sharing. While speciation in genetic algorithms is not new, no effort has been made towards using a speciated population as a complete modular system. We harness the specialized expertise in the species of an entire population, rather than a single individual, by introducing a gating algorithm. We demonstrate our approach to automatic modularization by improving co-evolutionary game learning, learning to play the iterated prisoner's dilemma. We review some problems of earlier co-evolutionary learning methods, and explain their poor generalization ability and sudden mass extinctions. The generalization ability of our approach is significantly better than past efforts. Using the specialized expertise of the entire speciated population though a gating algorithm, instead of the best individual, is the main contributor to this improvement."
            },
            "slug": "Automatic-modularization-by-speciation-Darwen-Yao",
            "title": {
                "fragments": [],
                "text": "Automatic modularization by speciation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper proposes a novel evolutionary learning approach to designing a modular system automatically, without human intervention, and demonstrates the approach to automatic modularization by improving co-evolutionary game learning, learning to play the iterated prisoner's dilemma."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Evolutionary Computation"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143901532"
                        ],
                        "name": "X. Yao",
                        "slug": "X.-Yao",
                        "structuredName": {
                            "firstName": "Xin",
                            "lastName": "Yao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Yao"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 256,
                                "start": 247
                            }
                        ],
                        "text": "Unfortunately, quantitative performance comparisons are dif-\n112 Evolutionary Computation Volume 10, Number 2\nficult in this domain because the methodologies vary widely across experiments (Dasgupta and McGregor, 1992; Pujol and Poli, 1998; Yao and Shi, 1995; Zhang and Mu\u0308hlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15392806,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f62478f2d594e66b0dbb7943fe158d49ff0a29f2",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "The design of optimal artiicial neural networks (ANNs) is a key issue in the study of ANNs from the point of view of both theory and applications. There are strong biological and engineering evidences to support that the information processing capability of an ANN is determined by its architecture. However, no systematic method for designing ANNs exists although there are many attempts in attacking this problem. This paper adopts an evolutionary approach to ANN design. The indirect encoding scheme of ANN ar-chitectures is used. That is, a genetic algorithm is used to evolve a set of grammar rules which generate an ANN architecture. A novel method of co-evolving a set of rules is proposed in this paper. In our co-evolutionary system, each individual in a population represents a rule. The whole population is the complete set of grammar rules which are used to generate an architecture. Preliminary experiments have been carried out to evolve ANN architectures for the parity problem with various sizes."
            },
            "slug": "A-Preliminary-Study-on-Designing-Artiicial-Neural-Yao",
            "title": {
                "fragments": [],
                "text": "A Preliminary Study on Designing Artiicial Neural Networks Using Co-evolution"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel method of co-evolving a set of rules is proposed in this paper, which adopts an evolutionary approach to ANN design and uses the indirect encoding scheme of ANN ar-chitectures."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143901532"
                        ],
                        "name": "X. Yao",
                        "slug": "X.-Yao",
                        "structuredName": {
                            "firstName": "Xin",
                            "lastName": "Yao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Yao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1679704"
                        ],
                        "name": "Y. Liu",
                        "slug": "Y.-Liu",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Liu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 258
                            }
                        ],
                        "text": "\u2026al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Gruau et al., 1996; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Mandischer, 1993; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and Mu\u0308hlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 266,
                                "start": 257
                            }
                        ],
                        "text": "\u2026appear in the phenotype (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and Mu\u0308hlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 211
                            }
                        ],
                        "text": "Because crossover of networks with different topologies can frequently lead to a loss of functionality, some researchers have given up on crossover altogether in what is called Evolutionary Programming (Yao and Liu, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15460875,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "255a0b5b14f82b24107668e0a3806c5eafa6d888",
            "isKey": false,
            "numCitedBy": 170,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Towards-designing-artificial-neural-networks-by-Yao-Liu",
            "title": {
                "fragments": [],
                "text": "Towards designing artificial neural networks by evolution"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144404817"
                        ],
                        "name": "J. Holland",
                        "slug": "J.-Holland",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Holland",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Holland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 63
                            }
                        ],
                        "text": "The original implicit version of fitness sharing introduced by Holland (1975) grouped individuals by performance similarity rather than genetic similarity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 109380360,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "f366e7b30c507c9c3acdd19173fa9db7368f1831",
            "isKey": false,
            "numCitedBy": 11617,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nGenetic algorithms are playing an increasingly important role in studies of complex adaptive systems, ranging from adaptive agents in economic theory to the use of machine learning techniques in the design of complex devices such as aircraft turbines and integrated circuits. Adaptation in Natural and Artificial Systems is the book that initiated this field of study, presenting the theoretical foundations and exploring applications. \nIn its most familiar form, adaptation is a biological process, whereby organisms evolve by rearranging genetic material to survive in environments confronting them. In this now classic work, Holland presents a mathematical model that allows for the nonlinearity of such complex interactions. He demonstrates the model's universality by applying it to economics, physiological psychology, game theory, and artificial intelligence and then outlines the way in which this approach modifies the traditional views of mathematical genetics. \nInitially applying his concepts to simply defined artificial systems with limited numbers of parameters, Holland goes on to explore their use in the study of a wide range of complex, naturally occuring processes, concentrating on systems having multiple factors that interact in nonlinear ways. Along the way he accounts for major effects of coadaptation and coevolution: the emergence of building blocks, or schemata, that are recombined and passed on to succeeding generations to provide, innovations and improvements. \nJohn H. Holland is Professor of Psychology and Professor of Electrical Engineering and Computer Science at the University of Michigan. He is also Maxwell Professor at the Santa Fe Institute and isDirector of the University of Michigan/Santa Fe Institute Advanced Research Program."
            },
            "slug": "Adaptation-in-Natural-and-Artificial-Systems:-An-to-Holland",
            "title": {
                "fragments": [],
                "text": "Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, Control, and Artificial Intelligence"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Initially applying his concepts to simply defined artificial systems with limited numbers of parameters, Holland goes on to explore their use in the study of a wide range of complex, naturally occuring processes, concentrating on systems having multiple factors that interact in nonlinear ways."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46291010"
                        ],
                        "name": "C. Rosin",
                        "slug": "C.-Rosin",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Rosin",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rosin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682655"
                        ],
                        "name": "R. Belew",
                        "slug": "R.-Belew",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Belew",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Belew"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 202,
                                "start": 165
                            }
                        ],
                        "text": "However, evolution tends to find the simplest solutions that can win, meaning that strategies oscillate between different idiosyncratic yet uninteresting variations (Darwen, 1996; Rosin and Belew, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18217524,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "e276d83398222f2e55f7267e48d58e5cbf40341a",
            "isKey": false,
            "numCitedBy": 624,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider competitive coevolution, in which fitness is based on direct competition among individuals selected from two independently evolving populations of hosts and parasites. Competitive coevolution can lead to an arms race, in which the two populations reciprocally drive one another to increasing levels of performance and complexity. We use the games of Nim and 3-D Tic-Tac-Toe as test problems to explore three new techniques in competitive coevolution. Competitive fitness sharing changes the way fitness is measured; shared sampling provides a method for selecting a strong, diverse set of parasites; and the hall of fame encourages arms races by saving good individuals from prior generations. We provide several different motivations for these methods and mathematical insights into their use. Experimental comparisons are done, and a detailed analysis of these experiments is presented in terms of testing issues, diversity, extinction, arms race progress measurements, and drift."
            },
            "slug": "New-Methods-for-Competitive-Coevolution-Rosin-Belew",
            "title": {
                "fragments": [],
                "text": "New Methods for Competitive Coevolution"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work uses the games of Nim and 3-D Tic-Tac-Toe as test problems to explore three new techniques in competitive coevolution, which changes the way fitness is measured, shared sampling provides a method for selecting a strong, diverse set of parasites and the hall of fame encourages arms races by saving good individuals from prior generations."
            },
            "venue": {
                "fragments": [],
                "text": "Evolutionary Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1846883"
                        ],
                        "name": "Kenneth O. Stanley",
                        "slug": "Kenneth-O.-Stanley",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Stanley",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth O. Stanley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686788"
                        ],
                        "name": "R. Miikkulainen",
                        "slug": "R.-Miikkulainen",
                        "structuredName": {
                            "firstName": "Risto",
                            "lastName": "Miikkulainen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Miikkulainen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2124332,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "3f953f3413de91804cc333601da835f2dd37eac2",
            "isKey": false,
            "numCitedBy": 489,
            "numCiting": 140,
            "paperAbstract": {
                "fragments": [],
                "text": "A major challenge for evolutionary computation is to evolve phenotypes such as neural networks, sensory systems, or motor controllers at the same level of complexity as found in biological organisms. In order to meet this challenge, many researchers are proposing indirect encodings, that is, evolutionary mechanisms where the same genes are used multiple times in the process of building a phenotype. Such gene reuse allows compact representations of very complex phenotypes. Development is a natural choice for implementing indirect encodings, if only because nature itself uses this very process. Motivated by the development of embryos in nature, we define artificial embryogeny (AE) as the subdiscipline of evolutionary computation (EC) in which phenotypes undergo a developmental phase. An increasing number of AE systems are currently being developed, and a need has arisen for a principled approach to comparing and contrasting, and ultimately building, such systems. Thus, in this paper, we develop a principled taxonomy for AE. This taxonomy provides a unified context for long-term research in AE, so that implementation decisions can be compared and contrasted along known dimensions in the design space of embryogenic systems. It also allows predicting how the settings of various AE parameters affect the capacity to efficiently evolve complex phenotypes."
            },
            "slug": "A-Taxonomy-for-Artificial-Embryogeny-Stanley-Miikkulainen",
            "title": {
                "fragments": [],
                "text": "A Taxonomy for Artificial Embryogeny"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This taxonomy provides a unified context for long-term research in AE, so that implementation decisions can be compared and contrasted along known dimensions in the design space of embryogenic systems, and allows predicting how the settings of various AE parameters affect the capacity to efficiently evolve complex phenotypes."
            },
            "venue": {
                "fragments": [],
                "text": "Artificial Life"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1859405"
                        ],
                        "name": "David E. Moriarty",
                        "slug": "David-E.-Moriarty",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Moriarty",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David E. Moriarty"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 239,
                                "start": 225
                            }
                        ],
                        "text": "Past studies have shown NE to be faster and more efficient than reinforcement learning methods such as Adaptive Heuristic Critic and Q-Learning on single pole balancing and robot arm control (Moriarty and Miikkulainen, 1996; Moriarty, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 191
                            }
                        ],
                        "text": "Past studies have shown NE to be faster and more efficient than reinforcement learning methods such as Adaptive Heuristic Critic and Q-Learning on single pole balancing and robot arm control (Moriarty 1997; Moriarty and Miikkulainen 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2943620,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6dbbc1c6a819978fb72a9baae157d7d2a19b5361",
            "isKey": false,
            "numCitedBy": 168,
            "numCiting": 199,
            "paperAbstract": {
                "fragments": [],
                "text": "Sequential decision tasks appear in many practical situations ranging from robot navigation to stock market trading. Because of the complexity of such tasks, it is often difficult to perceive the direct consequences of individual decisions and even harder to generate examples of correct behavior. Consequently, difficult decision problems such as routing traffic, autonomous control, and resource allocation are often unautomated or are only semi-automated using \"rule-of-thumb\" strategies or simple heuristics. This dissertation proposes a general methodology for automating these tasks using techniques from machine learning. Specifically, this research studies the combination of evolutionary algorithms and artificial neural networks to learn and perform difficult decision tasks. Evolutionary algorithms provide an efficient search engine for building decision strategies and require only minimal reinforcement or direction from the environment. Neural networks provide an efficient storage mechanism for the decision policy and can generalize experiences from one situation to another. The learning system developed in this dissertation called SANE contains an evolutionary algorithm specifically tailored to sequential decision learning. Populations evolve faster than previous methods and rarely converge on suboptimal solutions. SANE is extensively evaluated and compared to existing decision learning systems and other evolutionary algorithms. SANE is shown to be significantly faster, more robust, and more adaptive in almost every situation. Moreover, SANE's efficient searches return more profitable decision strategies. The flexibility and scope of SANE is demonstrated in two real-world applications. First, SANE significantly improves the play of a world champion Othello program. Second, SANE successfully forms neural networks that guide a robot arm to target objects while avoiding randomly placed obstacles. The contributions of this research are twofold: a novel integration of evolutionary algorithms and neural networks and an efficient system for learning decision strategies in complex problems."
            },
            "slug": "Symbiotic-Evolution-of-Neural-Networks-in-Decision-Moriarty",
            "title": {
                "fragments": [],
                "text": "Symbiotic Evolution of Neural Networks in Sequential Decision Tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This research studies the combination of evolutionary algorithms and artificial neural networks to learn and perform difficult decision tasks and develops an efficient system for learning decision strategies in complex problems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "117289777"
                        ],
                        "name": "Brad Fullmer and Risto Miikkulainen",
                        "slug": "Brad-Fullmer-and-Risto-Miikkulainen",
                        "structuredName": {
                            "firstName": "Brad",
                            "lastName": "Miikkulainen",
                            "middleNames": [
                                "Fullmer",
                                "and",
                                "Risto"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brad Fullmer and Risto Miikkulainen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 68
                            }
                        ],
                        "text": "These methods encompass a range of ideas about how Topology and Weight Evolving Artificial Neural Networks (TWEANNs) should be implemented."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 185
                            }
                        ],
                        "text": "Neuroevolution (NE), the artificial evolution of neural networks using genetic algorithms, has shown great promise in complex reinforcement learning tasks (Gomez and Miikkulainen, 1999; Gruau et al., 1996; Moriarty and Miikkulainen, 1997; Potter et al., 1995; Whitley et al., 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 147
                            }
                        ],
                        "text": "\u2026genome every connection and node that will appear in the phenotype (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 147
                            }
                        ],
                        "text": "\u2026last decade that evolve both neural network topologies and weights (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Gruau et al., 1996; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Mandischer, 1993; Maniezzo, 1994; Opitz and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8809224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8a030483afa171bbe9df0d6bb402808b13944708",
            "isKey": true,
            "numCitedBy": 71,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A new mechanism for genetic encoding of neural networks is proposed, which is loosely based on the marker structure of biological DNA. The mechanism allows all aspects of the network structure, including the number of nodes and their connectivity, to be evolved through genetic algorithms. The e ectiveness of the encoding scheme is demonstrated in an object recognition task that requires arti cial creatures (whose behaviour is driven by a neural network) to develop high-level nite-state exploration and discrimination strategies. The task requires solving the sensory-motor grounding problem, i.e. developing a functional understanding of the e ects that a creature's movement has on its sensory input."
            },
            "slug": "Using-Marker-Based-Genetic-Encoding-Of-Neural-To-Miikkulainen",
            "title": {
                "fragments": [],
                "text": "Using Marker-Based Genetic Encoding Of Neural Networks To Evolve Finite-State Behaviour"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A new mechanism for genetic encoding of neural networks is proposed, which is loosely based on the marker structure of biological DNA, which allows all aspects of the network structure, including the number of nodes and their connectivity, to be evolved through genetic algorithms."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694724"
                        ],
                        "name": "F. Gruau",
                        "slug": "F.-Gruau",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Gruau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Gruau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145285040"
                        ],
                        "name": "L. D. Whitley",
                        "slug": "L.-D.-Whitley",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Whitley",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. D. Whitley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2800737"
                        ],
                        "name": "Larry D. Pyeatt",
                        "slug": "Larry-D.-Pyeatt",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Pyeatt",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Larry D. Pyeatt"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60742600,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "20c8c77d469575a077d6a15f70b7b0ee590e5bd3",
            "isKey": false,
            "numCitedBy": 331,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper compares the efficiency of two encoding schemes for Artificial Neural Networks optimized by evolutionary algorithms. Direct Encoding encodes the weights for an a priori fixed neural network architecture. Cellular Encoding encodes both weights and the architecture of the neural network. In previous studies, Direct Encoding and Cellular Encoding have been used to create neural networks for balancing 1 and 2 poles attached to a cart on a fixed track. The poles are balanced by a controller that pushes the cart to the left or the right. In some cases velocity information about the pole and cart is provided as an input; in other cases the network must learn to balance a single pole without velocity information. A careful study of the behavior of these systems suggests that it is possible to balance a single pole with velocity information as an input and without learning to compute the velocity. A new fitness function is introduced that forces the neural network to compute the velocity. By using this new fitness function and tuning the syntactic constraints used with cellular encoding, we achieve a tenfold speedup over our previous study and solve a more difficult problem: balancing two poles when no information about the velocity is provided as input."
            },
            "slug": "A-comparison-between-cellular-encoding-and-direct-Gruau-Whitley",
            "title": {
                "fragments": [],
                "text": "A comparison between cellular encoding and direct encoding for genetic neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This paper compares the efficiency of two encoding schemes for Artificial Neural Networks optimized by evolutionary algorithms and solves a more difficult problem: balancing two poles when no information about the velocity is provided as input."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145285040"
                        ],
                        "name": "L. D. Whitley",
                        "slug": "L.-D.-Whitley",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Whitley",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. D. Whitley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3310039"
                        ],
                        "name": "Stephen Dominic",
                        "slug": "Stephen-Dominic",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Dominic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen Dominic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143863023"
                        ],
                        "name": "R. Das",
                        "slug": "R.-Das",
                        "structuredName": {
                            "firstName": "Rajarshi",
                            "lastName": "Das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Das"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144826602"
                        ],
                        "name": "C. Anderson",
                        "slug": "C.-Anderson",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Anderson",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Anderson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9828797,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1fe7e65d0682e5a54b92c0ff61f461fd93381f37",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Empirical tests indicate that at least one class of genetic algorithms yields good performance for neural network weight optimization in terms of learning rates and scalability. The successful application of these genetic algorithms to supervised learning problems sets the stage for the use of genetic algorithms in reinforcement learning problems. On a simulated inverted-pendulum control problem, \u201cgenetic reinforcement learning\u201d produces competitive results with AHC, another well-known reinforcement learning paradigm for neural networks that employs the temporal difference method. These algorithms are compared in terms of learning rates, performance-based generalization, and control behavior over time."
            },
            "slug": "Genetic-Reinforcement-Learning-for-Neurocontrol-Whitley-Dominic",
            "title": {
                "fragments": [],
                "text": "Genetic Reinforcement Learning for Neurocontrol Problems"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "On a simulated inverted-pendulum control problem, \u201cgenetic reinforcement learning\u201d produces competitive results with AHC, another well-known reinforcement learning paradigm for neural networks that employs the temporal difference method."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144990917"
                        ],
                        "name": "R. Krishnan",
                        "slug": "R.-Krishnan",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Krishnan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Krishnan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116125442"
                        ],
                        "name": "Fujitsu Australia",
                        "slug": "Fujitsu-Australia",
                        "structuredName": {
                            "firstName": "Fujitsu",
                            "lastName": "Australia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fujitsu Australia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707279"
                        ],
                        "name": "V. Ciesielski",
                        "slug": "V.-Ciesielski",
                        "structuredName": {
                            "firstName": "V.",
                            "lastName": "Ciesielski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Ciesielski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9333066,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c14c13fcbbde954b5e9c964c04df6c12cfbde292",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a method of using Genetic Algorithms for training multi-layer perceptron neworks in which the chromosomes encode \\rules\" for changing the network weights rather than the weights themselves. The genetic operators of crossover, selection and mutation are used to generate new rules which are then applied to the weight matrix. The approach is signican tly better than other approaches to training networks using genetic algorithms and successfully solves a number of benchmark problems which are known to be dicult for backward error propagation."
            },
            "slug": "2DELTA-GANN:-A-NEW-APPROACH-TO-TRAINING-NEURAL-Krishnan-Australia",
            "title": {
                "fragments": [],
                "text": "2DELTA-GANN: A NEW APPROACH TO TRAINING NEURAL NETWORKS USING GENETIC ALGORITHMS"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This work describes a method of using Genetic Algorithms for training multi-layer perceptron neworks in which the chromosomes encode \"rules\" for changing the network weights rather than the weights themselves."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730590"
                        ],
                        "name": "A. Barto",
                        "slug": "A.-Barto",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Barto",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barto"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 93
                            }
                        ],
                        "text": "Standard reinforcement learning methods have also been applied to this task (Anderson, 1989; Pendrith, 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 77
                            }
                        ],
                        "text": "Standard reinforcement learning methods have also been app lied to this task (Anderson 1989; Pendrith 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6191323,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7cb01758de95579f5fddded4fbf8ef7d4eb26172",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Reinforcement-learning-control-Barto",
            "title": {
                "fragments": [],
                "text": "Reinforcement learning control"
            },
            "venue": {
                "fragments": [],
                "text": "Current Opinion in Neurobiology"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2876033"
                        ],
                        "name": "A. Wieland",
                        "slug": "A.-Wieland",
                        "structuredName": {
                            "firstName": "Alexis",
                            "lastName": "Wieland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Wieland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 57
                            }
                        ],
                        "text": "We set up the pole balancing experiments as described by Wieland (1991) and Gomez and Miikkulainen (1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 91
                            }
                        ],
                        "text": "NE systems where structures are fixed start with a fully connected hidden layer of neurons (Wieland, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 86
                            }
                        ],
                        "text": "A parallel can be drawn between structure evolution in NEAT and incremental evolution (Gomez and Miikkulainen, 1997; Wieland, 1991)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 121
                            }
                        ],
                        "text": "Saravanan and Fogel (1995) used Evolutionary Programming, which relies entirely on mutation of connection weights, while Wieland (1991) used both mating and mutation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 58
                            }
                        ],
                        "text": "hidden units like the fixed topology methods in this task (Saravanan and Fogel, 1995; Wieland, 1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62662319,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8f67d2fbeab8b97b264fde1ee6e70c8cfd04052a",
            "isKey": true,
            "numCitedBy": 220,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The author describes how genetic algorithms (GAs) were used to create recurrent neural networks to control a series of unstable systems. The systems considered are variations of the pole balancing problem: network controllers with two, one, and zero inputs, variable length pole, multiple poles on one cart, and a jointed pole. GAs were able to quickly evolve networks for the one- and two-input pole balancing problems. Networks with zero inputs were only able to valance poles for a few seconds of simulated time due to the network's inability to maintain accurate estimates of their position and pole angle. Also, work in progress on a two-legged walker is briefly described.<<ETX>>"
            },
            "slug": "Evolving-neural-network-controllers-for-unstable-Wieland",
            "title": {
                "fragments": [],
                "text": "Evolving neural network controllers for unstable systems"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "The author describes how genetic algorithms were used to create recurrent neural networks to control a series of unstable systems, including network controllers with two, one, and zero inputs, and variations of the pole balancing problem."
            },
            "venue": {
                "fragments": [],
                "text": "IJCNN-91-Seattle International Joint Conference on Neural Networks"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109465183"
                        ],
                        "name": "Chi-Ho Lee",
                        "slug": "Chi-Ho-Lee",
                        "structuredName": {
                            "firstName": "Chi-Ho",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chi-Ho Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699362"
                        ],
                        "name": "Jong-Hwan Kim",
                        "slug": "Jong-Hwan-Kim",
                        "structuredName": {
                            "firstName": "Jong-Hwan",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jong-Hwan Kim"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 129
                            }
                        ],
                        "text": "These methods encompass a range of ideas about how Topology and Weight Evolving Artificial Neural Networks (TWEANNs) should be implemented."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 33704755,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f81b11f36095fc80d1260de0b3abbcef67b79ceb",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper proposes an evolutionary design of a neural network architecture, with a one dimensional linked list encoding scheme. In this scheme, neurons are arranged in one dimensional array, and the order information of neurons play important roles in genetic operation. Due to one dimensional structure, encoding from neural network architecture to genotype becomes easy, and genetic operation can be easily applied. To avoid the permutation problem, we choose evolutionary programming (EP) rather than genetic algorithm (GA), i.e., we apply mutation operators only in order to generate offspring. The proposed scheme is applied to XOR and 3 parity problems, and optimal neural network architecture can be found with this encoding scheme."
            },
            "slug": "Evolutionary-ordered-neural-network-with-a-encoding-Lee-Kim",
            "title": {
                "fragments": [],
                "text": "Evolutionary ordered neural network with a linked-list encoding scheme"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "The paper proposes an evolutionary design of a neural network architecture, with a one dimensional linked list encoding scheme, which chooses evolutionary programming (EP) rather than genetic algorithm (GA), and applies mutation operators only in order to generate offspring."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE International Conference on Evolutionary Computation"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3040233"
                        ],
                        "name": "Samir W. Mahfoud",
                        "slug": "Samir-W.-Mahfoud",
                        "structuredName": {
                            "firstName": "Samir",
                            "lastName": "Mahfoud",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samir W. Mahfoud"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 73
                            }
                        ],
                        "text": "Speciation is most commonly applied to multimodal function optimization (Mahfoud, 1995), where a function has multiple optima, and a GA with several species is used to find those optima."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58205211,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c9ff6e4db26d537d9d82ea4915fbe42ce069e3d",
            "isKey": false,
            "numCitedBy": 1015,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Niching methods extend genetic algorithms to domains that require the location and maintenance of multiple solutions. Such domains include classification and machine learning, multimodal function optimization, multiobjective function optimization, and simulation of complex and adaptive systems. \nThis study presents a comprehensive treatment of niching methods and the related topic of population diversity. Its purpose is to analyze existing niching methods and to design improved niching methods. To achieve this purpose, it first develops a general framework for the modelling of niching methods, and then applies this framework to construct models of individual niching methods, specifically crowding and sharing methods. \nUsing a constructed model of crowding, this study determines why crowding methods over the last two decades have not made effective niching methods. A series of tests and design modifications results in the development of a highly effective form of crowding, called deterministic crowding. Further analysis of deterministic crowding focuses upon the distribution of population elements among niches, that arises from the combination of crossover and replacement selection. Interactions among niches are isolated and explained. The concept of crossover hillclimbing is introduced. \nUsing constructed models of fitness sharing, this study derives lower bounds on the population size required to maintain, with probability $\\gamma$, a fixed number of desired niches. It also derives expressions for the expected time to disappearance of a desired niche, and relates disappearance time to population size. Models are presented of sharing under selection, and sharing under both selection and crossover. Some models assume that all niches are equivalent with respect to fitness. Others allow niches to differ with respect to fitness. \nFocusing on the differences between parallel and sequential niching methods, this study compares and further examines four niching methods--crowding, sharing, sequential niching, and parallel hillclimbing. The four niching methods undergo rigorous testing on optimization and classification problems of increasing difficulty; a new niching-based technique is introduced that extends genetic algorithms to classification problems."
            },
            "slug": "Niching-methods-for-genetic-algorithms-Mahfoud",
            "title": {
                "fragments": [],
                "text": "Niching methods for genetic algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Why crowding methods over the last two decades have not made effective niching methods is determined and a series of tests and design modifications results in the development of a highly effective form of crowding, called deterministic crowding."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145738991"
                        ],
                        "name": "J. D. Schaffer",
                        "slug": "J.-D.-Schaffer",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Schaffer",
                            "middleNames": [
                                "David"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. D. Schaffer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145285040"
                        ],
                        "name": "L. D. Whitley",
                        "slug": "L.-D.-Whitley",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Whitley",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. D. Whitley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3035326"
                        ],
                        "name": "L. Eshelman",
                        "slug": "L.-Eshelman",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Eshelman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Eshelman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 95
                            }
                        ],
                        "text": "One of the main problems for NE is the Competing Conventions Problem (Montana and Davis, 1989; Schaffer et al., 1992), also known as the Permutations Problem (Radcliffe, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60670877,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "afdf48aaf69a520ed6d5b4a50189facc0ebf4e37",
            "isKey": false,
            "numCitedBy": 621,
            "numCiting": 150,
            "paperAbstract": {
                "fragments": [],
                "text": "Various schemes for combining genetic algorithms and neural networks have been proposed and tested in recent years, but the literature is scattered among a variety of journals, proceedings and technical reports. Activity in this area is clearly increasing. The authors provide an overview of this body of literature drawing out common themes and providing, where possible, the emerging wisdom about what seems to work and what does not.<<ETX>>"
            },
            "slug": "Combinations-of-genetic-algorithms-and-neural-a-of-Schaffer-Whitley",
            "title": {
                "fragments": [],
                "text": "Combinations of genetic algorithms and neural networks: a survey of the state of the art"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An overview of this body of literature drawing out common themes and providing, where possible, the emerging wisdom about what seems to work and what does not is provided."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] COGANN-92: International Workshop on Combinations of Genetic Algorithms and Neural Networks"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709512"
                        ],
                        "name": "L. Kaelbling",
                        "slug": "L.-Kaelbling",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Kaelbling",
                            "middleNames": [
                                "Pack"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Kaelbling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144885169"
                        ],
                        "name": "M. Littman",
                        "slug": "M.-Littman",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Littman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Littman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760402"
                        ],
                        "name": "A. Moore",
                        "slug": "A.-Moore",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Moore",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Moore"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 196
                            }
                        ],
                        "text": "This approach to solving complex control problems represents an alternative to statistical techniques that attempt to estimate the utility of particular actions in particular states of the world (Kaelbling et al., 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1708582,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "12d1d070a53d4084d88a77b8b143bad51c40c38f",
            "isKey": false,
            "numCitedBy": 7412,
            "numCiting": 229,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper surveys the field of reinforcement learning from a computer-science perspective. It is written to be accessible to researchers familiar with machine learning. Both the historical basis of the field and a broad selection of current work are summarized. Reinforcement learning is the problem faced by an agent that learns behavior through trial-and-error interactions with a dynamic environment. The work described here has a resemblance to work in psychology, but differs considerably in the details and in the use of the word \"reinforcement.\" The paper discusses central issues of reinforcement learning, including trading off exploration and exploitation, establishing the foundations of the field via Markov decision theory, learning from delayed reinforcement, constructing empirical models to accelerate learning, making use of generalization and hierarchy, and coping with hidden state. It concludes with a survey of some implemented systems and an assessment of the practical utility of current methods for reinforcement learning."
            },
            "slug": "Reinforcement-Learning:-A-Survey-Kaelbling-Littman",
            "title": {
                "fragments": [],
                "text": "Reinforcement Learning: A Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Central issues of reinforcement learning are discussed, including trading off exploration and exploitation, establishing the foundations of the field via Markov decision theory, learning from delayed reinforcement, constructing empirical models to accelerate learning, making use of generalization and hierarchy, and coping with hidden state."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1862271"
                        ],
                        "name": "Mark D. Pendrith",
                        "slug": "Mark-D.-Pendrith",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Pendrith",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark D. Pendrith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 93
                            }
                        ],
                        "text": "Standard reinforcement learning methods have also been applied to this task (Anderson, 1989; Pendrith, 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15277970,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7115ac32935d2c4983d3bcd0f510b512bfde3404",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "If reinforcement learning RL techniques are to be used for real world dynamic system control the problems of noise and plant disturbance will have to be addressed This study investigates the e ects of noise disturbance on ve di erent RL algorithms Watkins Q Learning QL Barto Sutton and Ander son s Adaptive Heuristic Critic AHC Sammut and Law s modern variant of Michie and Chamber s BOXES algorithm and two new algorithms developed during the course of this study Both these new algorithms are conceptually re lated to QL both algorithms called P Trace and Q Trace respectively provide for substantially faster learning than straight QL overall and for dramatically faster learning by up to a factor of in the special case of learning in a noisy environment for the dynamic system studied here a pole and cart simulation As well as speeding learning both the P Trace and Q Trace algorithms have been designed to preserve the convergence with probability formal properties of standard QL i e that they be provably correct algorithms for Markovian domains for the same conditions that QL is guaranteed to be correct We present both arguments and experimental evidence that trace methods may prove to be both faster and more powerful in general than TD Temporal Di erence methods The potential performance improvements using trace over pure TD methods may turn out to be particularly important when learning is to occur in noisy or stochastic environments and in the case where the domain is not well modelled by Markovian processes A surprising result to emerge from this study is evidence for hitherto un suspected chaotic behaviour with respect to learning rates exhibited by the well studied AHC algorithm The e ect becomes more pronounced as noise increases"
            },
            "slug": "On-Reinforcement-Learning-of-Control-Actions-in-and-Pendrith",
            "title": {
                "fragments": [],
                "text": "On Reinforcement Learning of Control Actions in Noisy and Non-Markovian Domains"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This study investigates the effects of noise disturbance on RL algorithms using the AHC algorithm, a modern variant of Michie and Chamber s BOXES algorithm, and two new algorithms developed during the course of this study that provide for substantially faster learning than straight QL overall and dramatically faster learning in a noisy environment."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1643923853"
                        ],
                        "name": "PujolJo\u00e3o Carlos Figueira",
                        "slug": "PujolJo\u00e3o-Carlos-Figueira",
                        "structuredName": {
                            "firstName": "PujolJo\u00e3o",
                            "lastName": "Figueira",
                            "middleNames": [
                                "Carlos"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "PujolJo\u00e3o Carlos Figueira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1643834361"
                        ],
                        "name": "PoliRiccardo",
                        "slug": "PoliRiccardo",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "PoliRiccardo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "PoliRiccardo"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 217
                            }
                        ],
                        "text": "Unfortunately, quantitative performance comparisons are dif-\n112 Evolutionary Computation Volume 10, Number 2\nficult in this domain because the methodologies vary widely across experiments (Dasgupta and McGregor, 1992; Pujol and Poli, 1998; Yao and Shi, 1995; Zhang and Mu\u0308hlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 79
                            }
                        ],
                        "text": "ficult in this domain because the methodologies vary widely across experiments (Dasgupta and McGregor, 1992; Pujol and Poli, 1998; Yao and Shi, 1995; Zhang and M\u00fchlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 403,
                                "start": 133
                            }
                        ],
                        "text": "Direct encoding schemes, employed by most TWEANNs, specify in the genome every connection and node that will appear in the phenotype (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and M\u00fchlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 417,
                                "start": 109
                            }
                        ],
                        "text": "Many systems have been developed over the last decade that evolve both neural network topologies and weights (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Gruau et al., 1996; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Mandischer, 1993; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and M\u00fchlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 227
                            }
                        ],
                        "text": "\u2026appear in the phenotype (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and Mu\u0308hlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 248,
                                "start": 228
                            }
                        ],
                        "text": "\u2026al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Gruau et al., 1996; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Mandischer, 1993; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and Mu\u0308hlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6461198,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "08ffc45da941e384658ef1cf2b9badb950b5c2df",
            "isKey": true,
            "numCitedBy": 37,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Evolutionary computation is a class of global search techniques based on the learning process of a population of potential solutions to a given problem, that has been successfully applied to a vari..."
            },
            "slug": "Evolving-the-Topology-and-the-Weights-of-Neural-a-Figueira-PoliRiccardo",
            "title": {
                "fragments": [],
                "text": "Evolving the Topology and the Weights of Neural Networks Using a Dual Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "Evolutionary computation is a class of global search techniques based on the learning process of a population of potential solutions to a given problem, that has been successfully applied to a variate of problems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2761298"
                        ],
                        "name": "M. Mandischer",
                        "slug": "M.-Mandischer",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Mandischer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mandischer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 417,
                                "start": 109
                            }
                        ],
                        "text": "Many systems have been developed over the last decade that evolve both neural network topologies and weights (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Gruau et al., 1996; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Mandischer, 1993; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and M\u00fchlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 169
                            }
                        ],
                        "text": "\u2026al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Gruau et al., 1996; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Mandischer, 1993; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and Mu\u0308hlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 102
                            }
                        ],
                        "text": "In contrast, indirect encodings usually only specify rules for constructing a phenotype (Gruau, 1993; Mandischer, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16541864,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b2b632375e86149ac30c53cb470b19c7ae0d681b",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "An evolutionary approach for developing improved neural network architectures is presented. It is shown that it is possible to use genetic algorithms for the construction of backpropagation networks for real world tasks. Therefore a network representation is developed with certain properties. Results with various application are presented."
            },
            "slug": "Representation-and-Evolution-of-Neural-Networks-Mandischer",
            "title": {
                "fragments": [],
                "text": "Representation and Evolution of Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "An evolutionary approach for developing improved neural network architectures is presented and it is shown that it is possible to use genetic algorithms for the construction of backpropagation networks for real world tasks."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144826602"
                        ],
                        "name": "C. Anderson",
                        "slug": "C.-Anderson",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Anderson",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Anderson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 77
                            }
                        ],
                        "text": "Standard reinforcement learning methods have also been applied to this task (Anderson, 1989; Pendrith, 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7089976,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "8302c2a57c98c08d634aa2212a87cd9009ecc2fe",
            "isKey": false,
            "numCitedBy": 561,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "An inverted pendulum is simulated as a control task with the goal of learning to balance the pendulum with no a priori knowledge of the dynamics. In contrast to other applications of neural networks to the inverted pendulum task, performance feedback is assumed to be unavailable on each step, appearing only as a failure signal when the pendulum falls or reaches the bounds of a horizontal track. To solve this task, the controller must deal with issues of delayed performance evaluation, learning under uncertainty, and the learning of nonlinear functions. Reinforcement and temporal-difference learning methods are presented that deal with these issues to avoid unstable conditions and balance the pendulum.<<ETX>>"
            },
            "slug": "Learning-to-control-an-inverted-pendulum-using-Anderson",
            "title": {
                "fragments": [],
                "text": "Learning to control an inverted pendulum using neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Control Systems Magazine"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715339"
                        ],
                        "name": "D. Goldberg",
                        "slug": "D.-Goldberg",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Goldberg",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Goldberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 184
                            }
                        ],
                        "text": "Such problems may be deceptive, meaning local optima have large basins of attraction compared to global optima, and the global optima are significantly different from the local optima (Goldberg, 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 38613589,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e62d1345b340d5fda3b092c460264b9543bc4b5",
            "isKey": false,
            "numCitedBy": 58251,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThis book brings together - in an informal and tutorial fashion - the computer techniques, mathematical tools, and research results that will enable both students and practitioners to apply genetic algorithms to problems in many fields. \n \nMajor concepts are illustrated with running examples, and major algorithms are illustrated by Pascal computer programs. No prior knowledge of GAs or genetics is assumed, and only a minimum of computer programming and mathematics background is required."
            },
            "slug": "Genetic-Algorithms-in-Search-Optimization-and-Goldberg",
            "title": {
                "fragments": [],
                "text": "Genetic Algorithms in Search Optimization and Machine Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This book brings together the computer techniques, mathematical tools, and research results that will enable both students and practitioners to apply genetic algorithms to problems in many fields."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2416462"
                        ],
                        "name": "G. Cybenko",
                        "slug": "G.-Cybenko",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Cybenko",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cybenko"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 80
                            }
                        ],
                        "text": "A fully connected network can in principle approximate any continuous function (Cybenko, 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 239,
                                "start": 224
                            }
                        ],
                        "text": "The basic question, however, remains: Can evolving topologies along with weights provide an advantage over evolving weights on a fixed-topology? A fully connected network can in principle approximate any continuous function (Cybenko, 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3958369,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8da1dda34ecc96263102181448c94ec7d645d085",
            "isKey": false,
            "numCitedBy": 6455,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we demonstrate that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube; only mild conditions are imposed on the univariate function. Our results settle an open question about representability in the class of single hidden layer neural networks. In particular, we show that arbitrary decision regions can be arbitrarily well approximated by continuous feedforward neural networks with only a single internal, hidden layer and any continuous sigmoidal nonlinearity. The paper discusses approximation properties of other possible types of nonlinearities that might be implemented by artificial neural networks."
            },
            "slug": "Approximation-by-superpositions-of-a-sigmoidal-Cybenko",
            "title": {
                "fragments": [],
                "text": "Approximation by superpositions of a sigmoidal function"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "It is demonstrated that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Control. Signals Syst."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144826602"
                        ],
                        "name": "C. Anderson",
                        "slug": "C.-Anderson",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Anderson",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Anderson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 77
                            }
                        ],
                        "text": "Standard reinforcement learning methods have also been applied to this task (Anderson, 1989; Pendrith, 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 77
                            }
                        ],
                        "text": "Standard reinforcement learning methods have also been app lied to this task (Anderson 1989; Pendrith 1994)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 22423929,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "298bfddea7583c78a167e852836f88902326ddcd",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "An inverted pendulum is simulated and cast as a control task with the goal of learning to avoid a subset of states with no a priori knowledge of the pendulum's dynamics. To solve this task a controller must deal with the issues of delayed performance evaluation, learning under uncertainty, and the learning of nonlinear functions. These issues are addressed by connectionist learing procedures that learn to balance the pendulum."
            },
            "slug": "Learning-to-Control-an-Inverted-Pendulum-with-Anderson",
            "title": {
                "fragments": [],
                "text": "Learning to Control an Inverted Pendulum with Connectionist Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "An inverted pendulum is simulated and cast as a control task with the goal of learning to avoid a subset of states with no a priori knowledge of the pendulum's dynamics."
            },
            "venue": {
                "fragments": [],
                "text": "1988 American Control Conference"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4205535"
                        ],
                        "name": "N. Sigal",
                        "slug": "N.-Sigal",
                        "structuredName": {
                            "firstName": "Nolan",
                            "lastName": "Sigal",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sigal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34748544"
                        ],
                        "name": "B. Alberts",
                        "slug": "B.-Alberts",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Alberts",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Alberts"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 188
                            }
                        ],
                        "text": "For example, in E. coli, in a process called synapsis, a special protein called RecA goes through and lines up homologous genes between two genomes before crossover occurs (Radding, 1982; Sigal and Alberts, 1972)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 153
                            }
                        ],
                        "text": "coli, in a process called synapsis, a special protein called RecA goes through and lines up homologous genes between two genomes before crossover occurs (Radding, 1982; Sigal and Alberts, 1972)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 26713492,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "564550f372cbc1e3a954095263eb87a987bae7a3",
            "isKey": false,
            "numCitedBy": 57,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Genetic-recombination:-the-nature-of-a-crossed-two-Sigal-Alberts",
            "title": {
                "fragments": [],
                "text": "Genetic recombination: the nature of a crossed strand-exchange between two homologous DNA molecules."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of molecular biology"
            },
            "year": 1972
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144567818"
                        ],
                        "name": "N. Saravanan",
                        "slug": "N.-Saravanan",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Saravanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Saravanan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144330013"
                        ],
                        "name": "D. Fogel",
                        "slug": "D.-Fogel",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Fogel",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Fogel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 58
                            }
                        ],
                        "text": "hidden units like the fixed topology methods in this task (Saravanan and Fogel, 1995; Wieland, 1991)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 0
                            }
                        ],
                        "text": "Saravanan and Fogel (1995) used Evolutionary Programming, which relies entirely on mutation of connection weights, while Wieland (1991) used both mating and mutation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 31293164,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "37d6a212344e5d098f4c3abe9291dfd2d1b31ab9",
            "isKey": false,
            "numCitedBy": 129,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Controlling unstable nonlinear systems with neural networks can be problematic. Two examples show that evolutionary programming provides a feasible method for addressing such control problems. >"
            },
            "slug": "Evolving-Neural-Control-Systems-Saravanan-Fogel",
            "title": {
                "fragments": [],
                "text": "Evolving Neural Control Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "Two examples show that evolutionary programming provides a feasible method for addressing such control problems as controlling unstable nonlinear systems with neural networks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Expert"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145472053"
                        ],
                        "name": "I. Harvey",
                        "slug": "I.-Harvey",
                        "structuredName": {
                            "firstName": "Inman",
                            "lastName": "Harvey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Harvey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 97
                            }
                        ],
                        "text": "Although GAs have been proposed where bit string chromosomes can increase in length indefinitely (Harvey, 1993), NEAT goes beyond a gradual uniform growth in genome size."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 32956645,
            "fieldsOfStudy": [
                "Psychology",
                "Engineering"
            ],
            "id": "5ddd5eee1b8269b68e3bcfa8da3a915379cde514",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "An electrically heated suit system is modular to enable selective wearing of different portions of the suit, without impairment of the heating function of the worn sections."
            },
            "slug": "The-artificial-evolution-of-adaptive-behaviour-Harvey",
            "title": {
                "fragments": [],
                "text": "The artificial evolution of adaptive behaviour"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "An electrically heated suit system is modular to enable selective wearing of different portions of the suit, without impairment of the heating function of the worn sections."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143708601"
                        ],
                        "name": "J. Darnell",
                        "slug": "J.-Darnell",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Darnell",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Darnell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2638706"
                        ],
                        "name": "W. Doolittle",
                        "slug": "W.-Doolittle",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Doolittle",
                            "middleNames": [
                                "Ford"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Doolittle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 151
                            }
                        ],
                        "text": "Somewhere along the evolution from single cells to more complex organisms, new genes were added to the genomes in a process called gene amplification (Darnell and Doolittle, 1986; Watson et al., 1987)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2060902,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "d717a4e9d40ad4718610cb921e82b0f9896702a8",
            "isKey": false,
            "numCitedBy": 241,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The proposal that RNA preceded DNA in evolution is more than 15 years old. In light of recent studies on RNA processing (including protein-free reactions), present knowledge about eukaryotic gene structure, and studies comparing ribosomal RNA sequences, we propose a train of events for precellular and early cellular evolution."
            },
            "slug": "Speculations-on-the-early-course-of-evolution.-Darnell-Doolittle",
            "title": {
                "fragments": [],
                "text": "Speculations on the early course of evolution."
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work proposes a train of events for precellular and early cellular evolution and presents knowledge about eukaryotic gene structure and studies comparing ribosomal RNA sequences."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the National Academy of Sciences of the United States of America"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 72
                            }
                        ],
                        "text": "The second two systems, SANE (Moriarty and Miikkulainen, 1996) and ESP (Gomez and Miikkulainen, 1999), evolved populations of neurons and a population of network blueprints that specifies how to build networks from the neurons that are assembled into fixed-topology networks for evaluation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 32
                            }
                        ],
                        "text": "Why is NEAT so much faster than ESP on the more difficult task when there was not much difference in the easier task?"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 71
                            }
                        ],
                        "text": "The result is important because it shows that NEAT performs as well as ESP while finding more minimal solutions."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 76
                            }
                        ],
                        "text": "We set up the pole balancing experiments as described by Wieland (1991) and Gomez and Miikkulainen (1999)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 141
                            }
                        ],
                        "text": "\u2026memory is easily represented through recurrent connections in neural networks, making NE a natural choice for learning non-Markovian tasks (Gomez and Miikkulainen, 1999, 2002).\nc\u00a92002 by the Massachusetts Institute of Technology Evolutionary Computation 10(2): 99-127\nIn traditional NE\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 9
                            }
                        ],
                        "text": "However, ESP, a fixed-topology NE system, was able to complete the task five times faster simply by restarting with a random number of hidden nodes whenever it got stuck."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "ESP improves over SANE by maintaining a separate population for each hidden neuron position in the complete network."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 20
                            }
                        ],
                        "text": "Because both CE and ESP were evaluated using this special fitness function, NEAT uses it on this task as well."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 71
                            }
                        ],
                        "text": "The seco nd two systems, SANE (Moriarty and Miikkulainen 1996) and ESP (Gomez and Miikkulainen 1999), evolv ed populations of neurons and a population of network blueprints that specifies how to build networks fr om the neurons that are assembled into fixedtopology networks for evaluation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 51
                            }
                        ],
                        "text": "The reason is that in the task without velocities, ESP needed to restart an average of 4.06 times per solution while NEAT never needed to restart."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 132
                            }
                        ],
                        "text": "The method is validated on pole balancing tasks, where NEAT performs 25 times faster than Cellular Encoding and 5 times faster than ESP."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 62
                            }
                        ],
                        "text": "A fixed-topology method called Enforced Subpopulations (ESP) (Gomez and Miikkulainen, 1999) was able to solve the same problem 5 times faster simply by restarting with a random number of hidden neurons whenever it became stuck ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 33
                            }
                        ],
                        "text": "To our knowledge, the results of ESP are the best achieved so far in this task."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 162
                            }
                        ],
                        "text": "On the double pole balancing without velocity problem (DPNV), NEAT is compared to the only two systems that have been demonstrated able to solve the task: CE and ESP."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 156
                            }
                        ],
                        "text": "Neuroevolution (NE), the artificial evolution of neural networks using genetic algorithms, has shown great promise in complex reinforcement learning tasks (Gomez and Miikkulainen, 1999; Gruau et al., 1996; Moriarty and Miikkulainen, 1997; Potter et al., 1995; Whitley et al., 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 33
                            }
                        ],
                        "text": "NEAT is also 5 times faster than ESP, showing that structure evolution can indeed perform better than evolution of fixed topologies."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 277,
                                "start": 156
                            }
                        ],
                        "text": "Neuroevolution (NE), the artificial evolution of neural net works using genetic algorithms, has shown great promise in complex reinforcement learning tasks (Gomez and Miikkulainen 1999; Gruau et al. 1996; Moriarty and Miikkulainen 1997; Potter et al. 1995; Whitley et al. 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 117
                            }
                        ],
                        "text": "Table 1 shows that NEAT takes the fewest evaluations to complete this task, although the difference between NEAT and ESP is not statistically significant."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Solving non-Markov"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "As in sGA, PDGP has a finite limit on the number of nodes in the network, corresponding to the number of nodes in the two-dimensional grid that represents the graph version of the genome."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 37
                            }
                        ],
                        "text": "\u201d Although some TWEANNs such as PDGP (Pujol and Poli 1998) have attempted to a dress the problem by assuming that subnetworks represent functional units that can be recombi ned, different topologies may not be based on the same subnetworks at all, in which case no meaningful combina tion of substructures exists."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 408,
                                "start": 110
                            }
                        ],
                        "text": "Many systems have been developed over the last decade that ev olve both neural network topologies and weights (Angeline et al. 1993; Braun and Weisbrod 1993; Dasg upta and McGregor 1992; Fullmer and Miikkulainen 1992; Gruau et al. 1996; Krishnan and Ciesiels ki 1994; Lee and Kim 1996; Mandischer 1993; Maniezzo 1994; Opitz and Shavlik 1997; Pujol and Poli 1998; Y ao and Liu 1996; Zhang and Muhlenbein 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "PDGP uses graph encoding so that subgraphs can be swapped in crossover."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 217
                            }
                        ],
                        "text": "Unfortunately, quantitative performance comparisons are dif-\n112 Evolutionary Computation Volume 10, Number 2\nficult in this domain because the methodologies vary widely across experiments (Dasgupta and McGregor, 1992; Pujol and Poli, 1998; Yao and Shi, 1995; Zhang and Mu\u0308hlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 78
                            }
                        ],
                        "text": "However, we cannot be sure whether the particular subgraphs being combined in PDGP are the right ones to create a functional offspring."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 393,
                                "start": 133
                            }
                        ],
                        "text": "Direct encoding schemes, employed by most TWEANNs, specify in the genome every connection and node that will appear in the phenotype (Angeline et al. 1993; Brau n nd Weisbrod 1993; Dasgupta and McGregor 1992; Fullmer and Miikkulainen 1992; Krishnan and Ciesiels ki 1994; Lee and Kim 1996; Maniezzo 1994; Opitz and Shavlik 1997; Pujol and Poli 1998; Yao and Liu 1996; Zhang and Muhlenbein 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "Although some TWEANNs such as PDGP have attempted to address the problem by assuming that subnetworks represent functional units that can be recombined, different topologies may not be based on the same subnetworks at all, in which case no meaningful combination of substructures exists."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 227
                            }
                        ],
                        "text": "\u2026appear in the phenotype (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and Mu\u0308hlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 248,
                                "start": 228
                            }
                        ],
                        "text": "\u2026al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Gruau et al., 1996; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Mandischer, 1993; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and Mu\u0308hlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 81
                            }
                        ],
                        "text": "additional generations pruning networks after a solution h as already been found (Pujol and Poli 1998)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 144
                            }
                        ],
                        "text": "Pujol and Poli (1997) use a dual representation scheme to allow different kinds of crossover in their Parallel Distributed Genetic Programming (PDGP) system."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "Although GNARL uses a graph encoding, it is fundamentally different from PDGP in that it sidesteps the issue of crossover entirely."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evolving the topology"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 30
                            }
                        ],
                        "text": "The second two systems, SANE (Moriarty and Miikkulainen, 1996) and ESP (Gomez and Miikkulainen, 1999), evolved populations of neurons and a population of network blueprints that specifies how to build networks from the neurons that are assembled into fixed-topology networks for evaluation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 49
                            }
                        ],
                        "text": "Earlier comparisons were done with a single pole (Moriarty and Miikkulainen 1996), but this version of the task has become t oo easy for modern methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 50
                            }
                        ],
                        "text": "Earlier comparisons were done with a single pole (Moriarty and Miikkulainen, 1996), but this version of the task has become too easy for modern methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "ESP improves over SANE by maintaining a separate population for each hidden neuron position in the complete network."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 30
                            }
                        ],
                        "text": "The seco nd two systems, SANE (Moriarty and Miikkulainen 1996) and ESP (Gomez and Miikkulainen 1999), evolv ed populations of neurons and a population of network blueprints that specifies how to build networks fr om the neurons that are assembled into fixedtopology networks for evaluation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 192
                            }
                        ],
                        "text": "Past studies have shown NE to be faster and more efficient than reinforcement learning methods such as Adaptive Heuristic Critic and Q-Learning on single pole balancing and robot arm control (Moriarty and Miikkulainen, 1996; Moriarty, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "SANE maintains a single population of neurons."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 317,
                                "start": 285
                            }
                        ],
                        "text": "However, we limit the comparisons in this paper to NE m ethods for two reasons: (1) The focus is on developing and demonstrating better performance on evolvi ng neural networks and (2) NE methods in this comparison have been shown superior to reinforcement learn ing methods elsewhere (Moriarty and Miikkulainen 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 267
                            }
                        ],
                        "text": "\u20262 113\nNE methods for two reasons: (1) The focus is on developing and demonstrating better performance on evolving neural networks and (2) NE methods in this comparison have outperformed reinforcement learning methods in prior comparisons on the pole balancing task (Moriarty and Miikkulainen, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 239,
                                "start": 191
                            }
                        ],
                        "text": "Past studies have shown NE to be faster and more efficient than reinforcement learning methods such as Adaptive Heuristic Critic and Q-Learning on single pole balancing and robot arm control (Moriarty 199 7; Moriarty and Miikkulainen 1996)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Efficient rein"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 203
                            }
                        ],
                        "text": "Because crossover of networks with different topologies can frequently lead to a loss of functionality, some researchers have given up on crossover altogether in what is called Evolutionary Programming (Yao and Liu, 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 393,
                                "start": 133
                            }
                        ],
                        "text": "Direct encoding schemes, employed by most TWEANNs, specify in the genome every connection and node that will appear in the phenotype (Angeline et al. 1993; Brau n nd Weisbrod 1993; Dasgupta and McGregor 1992; Fullmer and Miikkulainen 1992; Krishnan and Ciesiels ki 1994; Lee and Kim 1996; Maniezzo 1994; Opitz and Shavlik 1997; Pujol and Poli 1998; Yao and Liu 1996; Zhang and Muhlenbein 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 32
                            }
                        ],
                        "text": "Saravanan and Fogel (1995) used Evolutionary Programming, which relies entirely on mutation of connection weights, while Wieland (1991) used both mating and mutation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 266,
                                "start": 249
                            }
                        ],
                        "text": "\u2026appear in the phenotype (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and Mu\u0308hlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 203
                            }
                        ],
                        "text": "Because crossover of networks with different topologies ca n frequently lead to a loss of functionality, some researchers have given up on crossover altogether in what is c lled Evolutionary Programming (Yao and Liu 1996)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 267,
                                "start": 250
                            }
                        ],
                        "text": "\u2026al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Gruau et al., 1996; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Mandischer, 1993; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and Mu\u0308hlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Towards designing artificial neu"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 124
                            }
                        ],
                        "text": "Although CE demonstrates that it is possible to evolve developmental systems, we chose direct encoding for NEAT because, as Braun and Weisbrod (1993) argue, indirect encoding requires \u201cmore detailed knowledge of genetic and neural mechanisms.\u201d"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 142
                            }
                        ],
                        "text": "\u2026schemes, employed by most TWEANNs, specify in the genome every connection and node that will appear in the phenotype (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Maniezzo,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 133
                            }
                        ],
                        "text": "Many systems have been developed over the last decade that evolve both neural network topologies and weights (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Gruau et al., 1996; Krishnan and Ciesielski, 1994; Lee and Kim, 1996;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 403,
                                "start": 133
                            }
                        ],
                        "text": "Direct encoding schemes, employed by most TWEANNs, specify in the genome every connection and node that will appear in the phenotype (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and M\u00fchlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 417,
                                "start": 109
                            }
                        ],
                        "text": "Many systems have been developed over the last decade that evolve both neural network topologies and weights (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Gruau et al., 1996; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Mandischer, 1993; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and M\u00fchlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evolving feedforward neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of ANNGA93, International Conference on Artificial Neural Networks and Genetic Algorithms,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 408,
                                "start": 110
                            }
                        ],
                        "text": "Many systems have been developed over the last decade that ev olve both neural network topologies and weights (Angeline et al. 1993; Braun and Weisbrod 1993; Dasg upta and McGregor 1992; Fullmer and Miikkulainen 1992; Gruau et al. 1996; Krishnan and Ciesiels ki 1994; Lee and Kim 1996; Mandischer 1993; Maniezzo 1994; Opitz and Shavlik 1997; Pujol and Poli 1998; Y ao and Liu 1996; Zhang and Muhlenbein 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 133
                            }
                        ],
                        "text": "Many systems have been developed over the last decade that evolve both neural network topologies and weights (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Gruau et al., 1996; Krishnan and Ciesielski, 1994; Lee and Kim, 1996;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 142
                            }
                        ],
                        "text": "\u2026schemes, employed by most TWEANNs, specify in the genome every connection and node that will appear in the phenotype (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Maniezzo,\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 124
                            }
                        ],
                        "text": "Although CE demonstrates that it is possible to evolve developmental systems, we chose direct encoding for NEAT because, as Braun and Weisbrod (1993) argue, indirect encoding requires \u201cmore detailed knowledge of genetic and neural mechanisms.\u201d"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evolving feedforward ne"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 408,
                                "start": 110
                            }
                        ],
                        "text": "Many systems have been developed over the last decade that ev olve both neural network topologies and weights (Angeline et al. 1993; Braun and Weisbrod 1993; Dasg upta and McGregor 1992; Fullmer and Miikkulainen 1992; Gruau et al. 1996; Krishnan and Ciesiels ki 1994; Lee and Kim 1996; Mandischer 1993; Maniezzo 1994; Opitz and Shavlik 1997; Pujol and Poli 1998; Y ao and Liu 1996; Zhang and Muhlenbein 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 169
                            }
                        ],
                        "text": "\u2026al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Gruau et al., 1996; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Mandischer, 1993; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and Mu\u0308hlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 89
                            }
                        ],
                        "text": "In contrast, indirect encodings usually only specify rules for construc ting a phenotype (Gruau 1993; Mandischer 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 102
                            }
                        ],
                        "text": "In contrast, indirect encodings usually only specify rules for constructing a phenotype (Gruau, 1993; Mandischer, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Representation and evolution of neu"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 144
                            }
                        ],
                        "text": "\u2026and weights (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Gruau et al., 1996; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Mandischer, 1993; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 417,
                                "start": 109
                            }
                        ],
                        "text": "Many systems have been developed over the last decade that evolve both neural network topologies and weights (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Gruau et al., 1996; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Mandischer, 1993; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and M\u00fchlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 146
                            }
                        ],
                        "text": "\u2026that will appear in the phenotype (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 403,
                                "start": 133
                            }
                        ],
                        "text": "Direct encoding schemes, employed by most TWEANNs, specify in the genome every connection and node that will appear in the phenotype (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and M\u00fchlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Delta-gann: A new approach to training neural networks using genetic algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the Australian Conference on Neural Networks,"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 147
                            }
                        ],
                        "text": "\u2026have been developed over the last decade that evolve both neural network topologies and weights (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Gruau et al., 1996; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Mandischer, 1993;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 150
                            }
                        ],
                        "text": "\u2026by most TWEANNs, specify in the genome every connection and node that will appear in the phenotype (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Maniezzo, 1994; Opitz and Shavlik,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 188
                            }
                        ],
                        "text": "Unfortunately, quantitative performance comparisons are dif-\n112 Evolutionary Computation Volume 10, Number 2\nficult in this domain because the methodologies vary widely across experiments (Dasgupta and McGregor, 1992; Pujol and Poli, 1998; Yao and Shi, 1995; Zhang and Mu\u0308hlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 13
                            }
                        ],
                        "text": "For example, Dasgupta and McGregor (1992) use such an encoding in their method, called Structured Genetic Algorithm (sGA), where a bit string represents the connection matrix of a network. sGA is notable for its simplicity, allowing it to operate almost like a standard GA."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 393,
                                "start": 133
                            }
                        ],
                        "text": "Direct encoding schemes, employed by most TWEANNs, specify in the genome every connection and node that will appear in the phenotype (Angeline et al. 1993; Brau n nd Weisbrod 1993; Dasgupta and McGregor 1992; Fullmer and Miikkulainen 1992; Krishnan and Ciesiels ki 1994; Lee and Kim 1996; Maniezzo 1994; Opitz and Shavlik 1997; Pujol and Poli 1998; Yao and Liu 1996; Zhang and Muhlenbein 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 182
                            }
                        ],
                        "text": "sGA, like NEAT, evolves both topologies and weights and does not p os - rune; however, the reported results do not include the average number of generations necessary for a s lution (Dasgupta and McGregor 1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Designing applicati"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34822682"
                        ],
                        "name": "E. Spanier",
                        "slug": "E.-Spanier",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Spanier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Spanier"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 150
                            }
                        ],
                        "text": "Somewhere along the evolution from single cells to more complex organisms, new genes were added to the genomes in a process called gene amplification (Darnell and Doolittle 1986; Watson et al. 1987)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 97764505,
            "fieldsOfStudy": [
                "Chemistry"
            ],
            "id": "9e6be032874581ee26a0b4afed6e49327eeebb87",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Molecular-biology-of-the-gene(fourth-edition).-Vol.-Spanier",
            "title": {
                "fragments": [],
                "text": "Molecular biology of the gene(fourth edition). Vol. I. General principles. Menlo Park/California; Reading, Massachusetts; Don Mills, Ontario; Wokingham, U.K.; Amsterdam; Sydney; Singapore; Tokyo; Madrid; Bogota; Santiago; San Juan: The Benjamin/Cummings Publishing Company, Inc., 1987. 765 pp., DM 12"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152881341"
                        ],
                        "name": "J. Holland",
                        "slug": "J.-Holland",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "Holland",
                            "middleNames": [
                                "W"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Holland"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 63
                            }
                        ],
                        "text": "The original implicit version of fitness sharing introduced by Holland (1975) grouped individuals by performance similarity rather than genetic similarity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61023588,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "id": "658f27f99f0cf4d69c178d5925aa2b6289be20cc",
            "isKey": false,
            "numCitedBy": 999,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Adaptation-in-Natural-and-Artificial-Sys-tems:-An-Holland",
            "title": {
                "fragments": [],
                "text": "Adaptation in Natural and Artificial Sys-tems: An Introductory Analysis with Applications to Biology"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2634015"
                        ],
                        "name": "C. Radding",
                        "slug": "C.-Radding",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Radding",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Radding"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 173
                            }
                        ],
                        "text": "For example, in E. coli, in a process called synapsis, a special protein called RecA goes through and lines up homologous genes between two genomes before crossover occurs (Radding, 1982; Sigal and Alberts, 1972)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 153
                            }
                        ],
                        "text": "coli, in a process called synapsis, a special protein called RecA goes through and lines up homologous genes between two genomes before crossover occurs (Radding, 1982; Sigal and Alberts, 1972)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 33646572,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "8748025c3f1c4514a68bd0b4e44a49d94d6f50b6",
            "isKey": false,
            "numCitedBy": 341,
            "numCiting": 71,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Homologous-pairing-and-strand-exchange-in-genetic-Radding",
            "title": {
                "fragments": [],
                "text": "Homologous pairing and strand exchange in genetic recombination."
            },
            "venue": {
                "fragments": [],
                "text": "Annual review of genetics"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694724"
                        ],
                        "name": "F. Gruau",
                        "slug": "F.-Gruau",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Gruau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Gruau"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 33
                            }
                        ],
                        "text": "Gruau\u2019s Cellular Encoding method (CE; Gruau 1993) is an exam ple of a system that utilizes indirect encoding of network structures."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 89
                            }
                        ],
                        "text": "In contrast, indirect encodings usually only specify rules for construc ting a phenotype (Gruau 1993; Mandischer 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 89
                            }
                        ],
                        "text": "In contrast, indirect encodings usually only specify rules for constructing a phenotype (Gruau, 1993; Mandischer, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60749742,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ff33f09e9e211e1f1f4344beb9af1753c60cab4b",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Genetic-Synthesis-of-Modular-Neural-Networks-Gruau",
            "title": {
                "fragments": [],
                "text": "Genetic Synthesis of Modular Neural Networks"
            },
            "venue": {
                "fragments": [],
                "text": "ICGA"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715339"
                        ],
                        "name": "D. Goldberg",
                        "slug": "D.-Goldberg",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Goldberg",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Goldberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40169405"
                        ],
                        "name": "J. Richardson",
                        "slug": "J.-Richardson",
                        "structuredName": {
                            "firstName": "Jon",
                            "lastName": "Richardson",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Richardson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 110
                            }
                        ],
                        "text": "We use explicit fitness sharing, which forces individuals with similar genomes to share their fitness payoff (Goldberg and Richardson, 1987)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 73
                            }
                        ],
                        "text": "As the reproduction mechanism for NEAT, we use explicit fitness sharing (Goldberg and Richardson, 1987), where organisms in the same species must share the fitness of their niche."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 45428766,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1aee8a4cc00ff85606487c769b3595158026153e",
            "isKey": false,
            "numCitedBy": 2203,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Genetic-Algorithms-with-Sharing-for-Optimization-Goldberg-Richardson",
            "title": {
                "fragments": [],
                "text": "Genetic Algorithms with Sharing for Multimodalfunction Optimization"
            },
            "venue": {
                "fragments": [],
                "text": "ICGA"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145285040"
                        ],
                        "name": "L. D. Whitley",
                        "slug": "L.-D.-Whitley",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Whitley",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. D. Whitley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 280,
                                "start": 260
                            }
                        ],
                        "text": "Neuroevolution (NE), the artificial evolution of neural networks using genetic algorithms, has shown great promise in complex reinforcement learning tasks (Gomez and Miikkulainen, 1999; Gruau et al., 1996; Moriarty and Miikkulainen, 1997; Potter et al., 1995; Whitley et al., 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Keywords Genetic algorithms, neural networks, neuroevolution, network topologies, speciation, competing conventions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60440589,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13193f151ecabb2e950b18dc402eca77642465e6",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Empirical tests indicate that at least one class of genetic algorithms yields good performance for neural network weight optimization in terms of learning rates and scalability. The successful application of these genetic algorithms to supervised learning problems sets the stage for the use of genetic algorithms in reinforcement learning problems. On a simulated inverted-pendulum control problem, \u201cgenetic reinforcement learning\u201d produces competitive results with AHC, another well-known reinforcement learning paradigm for neural networks that employs the temporal difference method. These algorithms are compared in terms of learning rates, performance-based generalization, and control behavior over time."
            },
            "slug": "Genetic-reinforcement-learning-for-neurocontrol-Whitley",
            "title": {
                "fragments": [],
                "text": "Genetic reinforcement learning for neurocontrol problems"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "On a simulated inverted-pendulum control problem, \u201cgenetic reinforcement learning\u201d produces competitive results with AHC, another well-known reinforcement learning paradigm for neural networks that employs the temporal difference method."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 206
                            }
                        ],
                        "text": "Neuroevolution (NE), the artificial evolution of neural networks using genetic algorithms, has shown great promise in complex reinforcement learning tasks (Gomez and Miikkulainen, 1999; Gruau et al., 1996; Moriarty and Miikkulainen, 1997; Potter et al., 1995; Whitley et al., 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Forming neural networks through efficient and adaptive co-evolution Evolutionary Computation"
            },
            "venue": {
                "fragments": [],
                "text": "Forming neural networks through efficient and adaptive co-evolution Evolutionary Computation"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 148
                            }
                        ],
                        "text": "In a process called synapsis, a special protein called RecA g oes through and lines up homologous genes between two genomes before crossover occurs (Radding 1982; Sigal and Alberts 1972)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 188
                            }
                        ],
                        "text": "For example, in E. coli, in a process called synapsis, a special protein called RecA goes through and lines up homologous genes between two genomes before crossover occurs (Radding, 1982; Sigal and Alberts, 1972)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Genetic recombination: T"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 256,
                                "start": 239
                            }
                        ],
                        "text": "Unfortunately, quantitative performance comparisons are dif-\n112 Evolutionary Computation Volume 10, Number 2\nficult in this domain because the methodologies vary widely across experiments (Dasgupta and McGregor, 1992; Pujol and Poli, 1998; Yao and Shi, 1995; Zhang and Mu\u0308hlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A preliminary study on designing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 241,
                                "start": 227
                            }
                        ],
                        "text": "The basic que stion, however, remains: Can evolving topologies along with weights provide an advantage over evo lving weights on a fixed-topology? A fully connected network can in principle approximate any continu ous function (Cybenko 1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Approximation by superpositions of a si"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 120
                            }
                        ],
                        "text": "The sharing function sh is set to 0 when distance \u03b4(i, j) is above the threshold \u03b4t; otherwise, sh(\u03b4(i, j)) is set to 1 (Spears, 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 122
                            }
                        ],
                        "text": "(2)\nThe sharing function sh is set to 0 when distance \u03b4(i, j) is above the threshold \u03b4t; otherwise, sh(\u03b4(i, j)) is set to 1 (Spears, 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Speciation using tag bits. In Handbook of Evolutionary Computation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 149
                            }
                        ],
                        "text": "\u2026appear in the phenotype (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and Mu\u0308hlenbein, 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 145
                            }
                        ],
                        "text": "\u2026(Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Gruau et al., 1996; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Mandischer, 1993; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Delta - gann : A new approach to training neural networks using genetic algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "Procee dings of the Australian Conference on Neural Networks"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 73
                            }
                        ],
                        "text": "Speciation is most commonly applied to multimodal function optimization (Mahfoud, 1995), where a function has multiple optima, and a GA with several species is used to find those optima."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Niching Methods for Genetic Algorithms Ph.D. thesis, Department of General Engineering"
            },
            "venue": {
                "fragments": [],
                "text": "Niching Methods for Genetic Algorithms Ph.D. thesis, Department of General Engineering"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 98
                            }
                        ],
                        "text": "Although GAs have been proposed where bit string chromosomes can increase in length in definitely (Harvey 1993), NEAT goes beyond a gradual uniform growth in genome size."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Artificial Evolution of Adaptive Behavior"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 63
                            }
                        ],
                        "text": "The original implicit version of fitness sharing introduced by Holland (1975) grouped individuals by performance similarity rather than genetic similarity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1975).Adaptation in Natural and Artificial Systems: An Introducto"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evolutionary ordered neu"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Biology of the Gene Fourth Edition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 144
                            }
                        ],
                        "text": "\u2026and weights (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Gruau et al., 1996; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Mandischer, 1993; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996;\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 146
                            }
                        ],
                        "text": "\u2026that will appear in the phenotype (Angeline et al., 1993; Braun and Weisbrod, 1993; Dasgupta and McGregor, 1992; Fullmer and Miikkulainen, 1992; Krishnan and Ciesielski, 1994; Lee and Kim, 1996; Maniezzo, 1994; Opitz and Shavlik, 1997; Pujol and Poli, 1998; Yao and Liu, 1996; Zhang and\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Delta-gann: A ne"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evolving optimal n"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 0
                            }
                        ],
                        "text": "Saravanan and Fogel (1995) used Evolutionary Programming, which relies entirely on mutation of connection weights, while Wieland (1991) used both mating and mutation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evolving neural cont"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 141
                            }
                        ],
                        "text": "\u2026memory is easily represented through recurrent connections in neural networks, making NE a natural choice for learning non-Markovian tasks (Gomez and Miikkulainen, 1999, 2002).\nc\u00a92002 by the Massachusetts Institute of Technology Evolutionary Computation 10(2): 99-127\nIn traditional NE\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning robust nonlinear control with neuroevolution"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report AI02-292,"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 239,
                                "start": 225
                            }
                        ],
                        "text": "Past studies have shown NE to be faster and more efficient than reinforcement learning methods such as Adaptive Heuristic Critic and Q-Learning on single pole balancing and robot arm control (Moriarty and Miikkulainen, 1996; Moriarty, 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evolution of Neural Networks in Sequential Decis"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 73
                            }
                        ],
                        "text": "Speciation is most commonly applied to multimodal fun ction optimization (Mahfoud 1995), where a function has multiple optima, and a GA with several species i s used to find those optima."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 73
                            }
                        ],
                        "text": "Speciation is most commonly applied to multimodal function optimization (Mahfoud, 1995), where a function has multiple optima, and a GA with several species is used to find those optima."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "1995).Niching Methods for Genetic Algorithms"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Miikkulainen"
            },
            "venue": {
                "fragments": [],
                "text": "Miikkulainen"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Genetic algorit"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evolving feedforward neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of ANNGA 93 , International Conference on Artificial Neural Networks and Genetic Algorithms"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Incremental evolut"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evolving neural netw"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 105
                            }
                        ],
                        "text": "Speciation has also been applied in the cooperative coevolution of modular systems of multiple solutions (Darwen and Yao 1996; Potter and De Jong 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 106
                            }
                        ],
                        "text": "Speciation has also been applied in the cooperative coevolution of modular systems of multiple solutions (Darwen and Yao, 1996; Potter and De Jong, 1995)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic modularization"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 206
                            }
                        ],
                        "text": "Neuroevolution (NE), the artificial evolution of neural networks using genetic algorithms, has shown great promise in complex reinforcement learning tasks (Gomez and Miikkulainen, 1999; Gruau et al., 1996; Moriarty and Miikkulainen, 1997; Potter et al., 1995; Whitley et al., 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Forming neural networks through efficient and adaptive co-evolution Evolutionary Computation, 5(4):373\u2013399"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 166
                            }
                        ],
                        "text": "However, evolution tends to find the s implest solutions that can win, meaning that strategies oscillate between different idiosyncratic yet uninteresting variations (Darwen 1996; Rosin and Belew 1997)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "New methods for competi"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Artificial Evolution of Adaptive Behavior Ph"
            },
            "venue": {
                "fragments": [],
                "text": "The Artificial Evolution of Adaptive Behavior Ph"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 206
                            }
                        ],
                        "text": "Neuroevolution (NE), the artificial evolution of neural networks using genetic algorithms, has shown great promise in complex reinforcement learning tasks (Gomez and Miikkulainen, 1999; Gruau et al., 1996; Moriarty and Miikkulainen, 1997; Potter et al., 1995; Whitley et al., 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 277,
                                "start": 156
                            }
                        ],
                        "text": "Neuroevolution (NE), the artificial evolution of neural net works using genetic algorithms, has shown great promise in complex reinforcement learning tasks (Gomez and Miikkulainen 1999; Gruau et al. 1996; Moriarty and Miikkulainen 1997; Potter et al. 1995; Whitley et al. 1993)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Forming neura"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evolving NN's through Augmenting Topologies"
            },
            "venue": {
                "fragments": [],
                "text": "Evolving NN's through Augmenting Topologies"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 140
                            }
                        ],
                        "text": "There has also been a great deal of interest in evolving network topologies as well as weights over the last decade (Angeline et al., 1993; Branke, 1995; Gruau et al., 1996; Yao, 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 122
                            }
                        ],
                        "text": "Ther e has been a great deal of interest in the evolution of both topologies and connecti on weights over the last decade (Angeline et al. 1993; Branke 1995; Gruau et al. 1996; Yao 1999)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evolutionary algorithms for neural netw"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 63,
            "methodology": 27
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 90,
        "totalPages": 9
    },
    "page_url": "https://www.semanticscholar.org/paper/Evolving-Neural-Networks-through-Augmenting-Stanley-Miikkulainen/d03c916d49268d48fde3b76a68e64af7761835e7?sort=total-citations"
}