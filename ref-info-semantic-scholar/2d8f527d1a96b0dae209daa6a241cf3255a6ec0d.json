{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2370815"
                        ],
                        "name": "Boris Sofman",
                        "slug": "Boris-Sofman",
                        "structuredName": {
                            "firstName": "Boris",
                            "lastName": "Sofman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Boris Sofman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7298797"
                        ],
                        "name": "E. Lin",
                        "slug": "E.-Lin",
                        "structuredName": {
                            "firstName": "Ellie",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756566"
                        ],
                        "name": "J. Bagnell",
                        "slug": "J.-Bagnell",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Bagnell",
                            "middleNames": [
                                "Andrew"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bagnell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069465277"
                        ],
                        "name": "John Cole",
                        "slug": "John-Cole",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Cole",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Cole"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1874217"
                        ],
                        "name": "N. Vandapel",
                        "slug": "N.-Vandapel",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Vandapel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vandapel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722938"
                        ],
                        "name": "A. Stentz",
                        "slug": "A.-Stentz",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Stentz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stentz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 128
                            }
                        ],
                        "text": "A self-supervised classifier was trained on satellite imagery and ladar sensor data for the Spinner vehicle\u2019s navigation system (Sofman et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 49
                            }
                        ],
                        "text": "The performance of such stereo-based methods is limited, because stereo-based distance estimation is unreliable above 10 or 12 meters (for typical camera configurations and resolutions)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16168467,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd9d564c46069251afe65f46070fdf9607e3cf20",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In mobile robotics, there are often features that, while potentially powerful for improving navigation, prove difficult to profit from as they generalize poorly to novel situations. Overhead imagery data, for instance, have the potential to greatly enhance autonomous robot navigation in complex outdoor environments. In practice, reliable and effective automated interpretation of imagery from diverse terrain, environmental conditions, and sensor varieties proves challenging. Similarly, fixed techniques that successfully interpret on\u2010board sensor data across many environments begin to fail past short ranges as the density and accuracy necessary for such computation quickly degrade and features that are able to be computed from distant data are very domain specific. We introduce an online, probabilistic model to effectively learn to use these scope\u2010limited features by leveraging other features that, while perhaps otherwise more limited, generalize reliably. We apply our approach to provide an efficient, self\u2010supervised learning method that accurately predicts traversal costs over large areas from overhead data. We present results from field testing on\u2010board a robot operating over large distances in various off\u2010road environments. Additionally, we show how our algorithm can be used offline with overhead data to produce a priori traversal cost maps and detect misalignments between overhead data and estimated vehicle positions. This approach can significantly improve the versatility of many unmanned ground vehicles by allowing them to traverse highly varied terrains with increased performance. \u00a9 2007 Wiley Periodicals, Inc."
            },
            "slug": "Improving-robot-navigation-through-self\u2010supervised-Sofman-Lin",
            "title": {
                "fragments": [],
                "text": "Improving robot navigation through self\u2010supervised online learning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An online, probabilistic model is introduced to provide an efficient, self\u2010supervised learning method that accurately predicts traversal costs over large areas from overhead data and can significantly improve the versatility of many unmanned ground vehicles by allowing them to traverse highly varied terrains with increased performance."
            },
            "venue": {
                "fragments": [],
                "text": "J. Field Robotics"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779200"
                        ],
                        "name": "Hendrik Dahlkamp",
                        "slug": "Hendrik-Dahlkamp",
                        "structuredName": {
                            "firstName": "Hendrik",
                            "lastName": "Dahlkamp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hendrik Dahlkamp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34576226"
                        ],
                        "name": "A. Kaehler",
                        "slug": "A.-Kaehler",
                        "structuredName": {
                            "firstName": "Adrian",
                            "lastName": "Kaehler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kaehler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768464"
                        ],
                        "name": "David Stavens",
                        "slug": "David-Stavens",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Stavens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Stavens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144867807"
                        ],
                        "name": "S. Thrun",
                        "slug": "S.-Thrun",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Thrun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thrun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720184"
                        ],
                        "name": "G. Bradski",
                        "slug": "G.-Bradski",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Bradski",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Bradski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 85
                            }
                        ],
                        "text": "Current robotics research has recently begun to develop vision-based systems that can navigate through offroad environments; however, existing approaches generally rely on stereo algorithms, which produce short-range, sparse, and noisy costmaps that are inadequate for long-range strategic\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 54
                            }
                        ],
                        "text": "This is especially useful for roadfollowing vehicles (Dahlkamp et al., 2006; Leib et al., 2005; Hong et al., 2002); the ground immediately in front of the vehicle is assumed to be traversable, and the rest of the image is then filtered to find similarly colored or textured pixels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2260178,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "acda4460f0ad088023369c2e7e32f2512dcd75e7",
            "isKey": false,
            "numCitedBy": 381,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for identifying drivable surfaces in difficult unpaved and offroad terrain conditions as encountered in the DARPA Grand Challenge robot race. Instead of relying on a static, pre-computed road appearance model, this method adjusts its model to changing environments. It achieves robustness by combining sensor information from a laser range finder, a pose estimation system and a color camera. Using the first two modalities, the system first identifies a nearby patch of drivable surface. Computer Vision then takes this patch and uses it to construct appearance models to find drivable surface outward into the far range. This information is put into a drivability map for the vehicle path planner. In addition to evaluating the method\u2019s performance using a scoring framework run on real-world data, the system was entered, and won, the 2005 DARPA Grand Challenge. Post-race log-file analysis proved that without the Computer Vision algorithm, the vehicle would not have driven fast enough to win."
            },
            "slug": "Self-supervised-Monocular-Road-Detection-in-Desert-Dahlkamp-Kaehler",
            "title": {
                "fragments": [],
                "text": "Self-supervised Monocular Road Detection in Desert Terrain"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This method for identifying drivable surfaces in difficult unpaved and offroad terrain conditions as encountered in the DARPA Grand Challenge robot race achieves robustness by combining sensor information from a laser range finder, a pose estimation system and a color camera."
            },
            "venue": {
                "fragments": [],
                "text": "Robotics: Science and Systems"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3142556"
                        ],
                        "name": "Pierre Sermanet",
                        "slug": "Pierre-Sermanet",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Sermanet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierre Sermanet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2315504"
                        ],
                        "name": "R. Hadsell",
                        "slug": "R.-Hadsell",
                        "structuredName": {
                            "firstName": "Raia",
                            "lastName": "Hadsell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hadsell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085624"
                        ],
                        "name": "Marco Scoffier",
                        "slug": "Marco-Scoffier",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Scoffier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Scoffier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145636949"
                        ],
                        "name": "Urs Muller",
                        "slug": "Urs-Muller",
                        "structuredName": {
                            "firstName": "Urs",
                            "lastName": "Muller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Urs Muller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 51
                            }
                        ],
                        "text": "The outputs from the classifier populate a hyperbolic polar coordinate costmap, and planning algorithms are run on the map to decide trajectories and wheel commands at each step."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 52
                            }
                        ],
                        "text": "Details of the full navigation system are given in (Sermanet et al., 2008b; Sermanet et al., 2008a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 128
                            }
                        ],
                        "text": "Details of the full system, including architecture, short-range perception and planning, and long-range planning, are given in (Sermanet et al., 2008a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 58
                            }
                        ],
                        "text": "This multi-resolution architecture is fully described in (Sermanet et al., 2008b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 117
                            }
                        ],
                        "text": "Figures 18, 19, 20, 21, 22, and 23 show examples of long-range mapping with a hyperbolic polar map, as described in (Sermanet et al., 2008a; Sermanet et al., 2008b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10168732,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1331f67dd0c39845a7b129817a0697d798ffc548",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent advances in self-supervised learning have enabled very long-range visual detection of obstacles and pathways (to 100 meters or more). Unfortunately, the category and range of regions at such large distances come with a considerable amount of uncertainty. We present a mapping and planning system that accurately represents range and category uncertainties, and accumulates the evidence from multiple frames in a principled way. The system relies on a hyperbolicpolar map centered on the robot with a 200 m radius. Map cells are histograms that accumulate evidence obtained from a self-supervised object classifier operating on image windows. The performance of the system is demonstrated on the LAGR off-road robot platform."
            },
            "slug": "Mapping-and-planning-under-uncertainty-in-mobile-Sermanet-Hadsell",
            "title": {
                "fragments": [],
                "text": "Mapping and planning under uncertainty in mobile robots with long-range perception"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work presents a mapping and planning system that accurately represents range and category uncertainties, and accumulates the evidence from multiple frames in a principled way, and is demonstrated on the LAGR off-road robot platform."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE/RSJ International Conference on Intelligent Robots and Systems"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3142556"
                        ],
                        "name": "Pierre Sermanet",
                        "slug": "Pierre-Sermanet",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Sermanet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierre Sermanet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2315504"
                        ],
                        "name": "R. Hadsell",
                        "slug": "R.-Hadsell",
                        "structuredName": {
                            "firstName": "Raia",
                            "lastName": "Hadsell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hadsell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085624"
                        ],
                        "name": "Marco Scoffier",
                        "slug": "Marco-Scoffier",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Scoffier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Scoffier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2167293"
                        ],
                        "name": "M. Grimes",
                        "slug": "M.-Grimes",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Grimes",
                            "middleNames": [
                                "Koichi"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Grimes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144050629"
                        ],
                        "name": "J. Ben",
                        "slug": "J.-Ben",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Ben",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ben"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767093"
                        ],
                        "name": "A. Erkan",
                        "slug": "A.-Erkan",
                        "structuredName": {
                            "firstName": "Ayse",
                            "lastName": "Erkan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Erkan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2661990"
                        ],
                        "name": "Chris Crudele",
                        "slug": "Chris-Crudele",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Crudele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris Crudele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2092013891"
                        ],
                        "name": "Urs Miller",
                        "slug": "Urs-Miller",
                        "structuredName": {
                            "firstName": "Urs",
                            "lastName": "Miller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Urs Miller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 127
                            }
                        ],
                        "text": "Details of the full system, including architecture, short-range perception and planning, and long-range planning, are given in Sermanet et al. (2009). We present experimental results obtained by running the robot on two courses with the long-range vision turned on and turned off."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 95
                            }
                        ],
                        "text": "Figures 18\u201323 show examples of long-range mapping with a hyperbolic polar map, as described in Sermanet et al. (2009) and Sermanet et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 95
                            }
                        ],
                        "text": "Figures 18\u201323 show examples of long-range mapping with a hyperbolic polar map, as described in Sermanet et al. (2009) and Sermanet et al. (2008). Each example shows the left and right input frames, the output map with short-range (10 m) stereo vision, and the output map with long-range classifier outputs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 51
                            }
                        ],
                        "text": "Details of the full navigation system are given in Sermanet et al. (2009) and Sermanet, Hadsell, Scoffier, Muller, and LeCun (2008). The long-range classifier has been thoroughly tested."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 56
                            }
                        ],
                        "text": "This multiresolution architecture is fully described in Sermanet et al. (2008). The contribution of this paper is a full description and analysis of the long-range vision system."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 51
                            }
                        ],
                        "text": "Details of the full navigation system are given in Sermanet et al. (2009) and Sermanet, Hadsell, Scoffier, Muller, and LeCun (2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14535347,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "b48d78ed73144d69f6239696e55ba9596fe7813b",
            "isKey": false,
            "numCitedBy": 34,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a multilayered mapping, planning, and command execution system developed and tested on the LAGR mobile robot. Key to robust performance under uncertainty is the combination of a short\u2010range perception system operating at high frame rate and low resolution and a long\u2010range, adaptive vision system operating at lower frame rate and higher resolution. The short\u2010range module performs local planning and obstacle avoidance with fast reaction times, whereas the long\u2010range module performs strategic visual planning. Probabilistic traversability labels provided by the perception modules are combined and accumulated into a robot\u2010centered hyperbolic\u2010polar map with a 200\u2010m effective range. Instead of using a dynamical model of the robot for short\u2010range planning, the system uses a large lookup table of physically possible trajectory segments recorded on the robot in a wide variety of driving conditions. Localization is performed using a combination of global positioning system, wheel odometry, inertial measurement unit, and a high\u2010speed, low\u2010complexity rotational visual odometry module. The end\u2010to\u2010end system was developed and tested on the LAGR mobile robot and was verified in independent government tests. \u00a9 2008 Wiley Periodicals, Inc."
            },
            "slug": "A-multirange-architecture-for-collision\u2010free-robot-Sermanet-Hadsell",
            "title": {
                "fragments": [],
                "text": "A multirange architecture for collision\u2010free off\u2010road robot navigation"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A multi-layered mapping, planning, and command execution system developed and tested on the LAGR mobile robot that uses a large lookup table of physically-possible trajectory segments recorded on the robot in a wide variety of driving conditions to provide robust performance under uncertainty."
            },
            "venue": {
                "fragments": [],
                "text": "J. Field Robotics"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145426908"
                        ],
                        "name": "A. Angelova",
                        "slug": "A.-Angelova",
                        "structuredName": {
                            "firstName": "Anelia",
                            "lastName": "Angelova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Angelova"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782162"
                        ],
                        "name": "L. Matthies",
                        "slug": "L.-Matthies",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Matthies",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Matthies"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2658100"
                        ],
                        "name": "D. Helmick",
                        "slug": "D.-Helmick",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Helmick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Helmick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 67
                            }
                        ],
                        "text": "The visual representation is a 15 bin histogram of \u201ctexton\u201d matches (Angelova et al., 2007)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 459,
                                "start": 0
                            }
                        ],
                        "text": "Angelova et al. use selfsupervised learning to train a feature extractor and classifier to discriminate terrain types such as gravel, asphalt, and soil. The visual representation is a 15-bin histogram of \u201ctexton\u201d matches (Angelova, Matthies, Helmick, & Perona, 2007). The SRI LAGR system used fast stereo and color-based online learning (Konolige et al., 2008). Staying within the realm of simple color-based, near-to-far learning, Grudic and Mulligan (2006) explore the use of distance metrics for clustering traversable pixels."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17125548,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "55c48812b928376e7bfef4a367aeb4df2a1bb943",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper considers the problem of learning to recognize \ndifferent terrains from color imagery in a fully automatic \nfashion, using the robot\u2019s mechanical sensors as supervision. We present a probabilistic framework in which the visual information and the mechanical supervision interact to learn the available terrain types. Within this framework, a novel supervised dimensionality \nreduction method is proposed, in which the automatic \nsupervision provided by the robot helps select better lower \ndimensional representations, more suitable for the discrimination task at hand. Incorporating supervision into the dimensionality reduction process is important, as some terrains might be visually similar but induce very different robot mobility. Therefore, choosing a lower dimensional visual representation adequately \nis expected to improve the vision-based terrain learning and \nthe final classification performance. This is the first work that proposes automatically supervised dimensionality reduction in a probabilistic framework using the supervision coming from the robot\u2019s sensors. The proposed method stands in between methods \nfor reasoning under uncertainty using probabilistic models and methods for learning the underlying structure of the data. \n \nThe proposed approach has been tested on field test data \ncollected by an autonomous robot while driving on soil, gravel and asphalt. Although the supervision might be ambiguous \nor noisy, our experiments show that it helps build a more \nappropriate lower dimensional visual representation and achieves improved terrain recognition performance compared to unsupervised learning methods."
            },
            "slug": "Dimensionality-Reduction-Using-Automatic-for-Angelova-Matthies",
            "title": {
                "fragments": [],
                "text": "Dimensionality Reduction Using Automatic Supervision for Vision-Based Terrain Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A novel supervised dimensionality reduction method is proposed, in which the automatic supervision provided by the robot helps select better lower dimensional representations, more suitable for the discrimination task at hand, and achieves improved terrain recognition performance compared to unsupervised learning methods."
            },
            "venue": {
                "fragments": [],
                "text": "Robotics: Science and Systems"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768464"
                        ],
                        "name": "David Stavens",
                        "slug": "David-Stavens",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Stavens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Stavens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144867807"
                        ],
                        "name": "S. Thrun",
                        "slug": "S.-Thrun",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Thrun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thrun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 92
                            }
                        ],
                        "text": "Stavens and Thrun used self-supervision to train a classifier to predict surface roughness (Stavens and Thrun, 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 63
                            }
                        ],
                        "text": "Maps from multiple frames are assembled in a global map in which path finding algorithms are run (Kelly and Stentz, 1998; Kriegman et al., 1989; Goldberg et al., 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1099861,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a636df8c19dd12cf1f5dc40ffc6c7518af89499",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a machine learning approach for estimating the second derivative of a drivable surface, its roughness. Robot perception generally focuses on the first derivative, obstacle detection. However, the second derivative is also important due to its direct relation (with speed) to the shock the vehicle experiences. Knowing the second derivative allows a vehicle to slow down in advance of rough terrain. Estimating the second derivative is challenging due to uncertainty. For example, at range, laser readings may be so sparse that significant information about the surface is missing. Also, a high degree of precision is required in projecting laser readings. This precision may be unavailable due to latency or error in the pose estimation. We model these sources of error as a multivariate polynomial. Its coefficients are learned using the shock data as ground truth -- the accelerometers are used to train the lasers. The resulting classifier operates on individual laser readings from a road surface described by a 3D point cloud. The classifier identifies sections of road where the second derivative is likely to be large. Thus, the vehicle can slow down in advance, reducing the shock it experiences. The algorithm is an evolution of one we used in the 2005 DARPA Grand Challenge. We analyze it using data from that route."
            },
            "slug": "A-Self-Supervised-Terrain-Roughness-Estimator-for-Stavens-Thrun",
            "title": {
                "fragments": [],
                "text": "A Self-Supervised Terrain Roughness Estimator for Off-Road Autonomous Driving"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A machine learning approach for estimating the second derivative of a drivable surface, its roughness, an evolution of one used in the 2005 DARPA Grand Challenge and analyzed using data from that route."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144302166"
                        ],
                        "name": "David Lieb",
                        "slug": "David-Lieb",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lieb",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Lieb"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2229768"
                        ],
                        "name": "Andrew Lookingbill",
                        "slug": "Andrew-Lookingbill",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Lookingbill",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Lookingbill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144867807"
                        ],
                        "name": "S. Thrun",
                        "slug": "S.-Thrun",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Thrun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thrun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 108
                            }
                        ],
                        "text": "Current robotics research has recently begun to develop vision-based systems that can navigate through offroad environments; however, existing approaches generally rely on stereo algorithms, which produce short-range, sparse, and noisy costmaps that are inadequate for long-range strategic\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 77
                            }
                        ],
                        "text": "This is especially useful for roadfollowing vehicles (Dahlkamp et al., 2006; Leib et al., 2005; Hong et al., 2002); the ground immediately in front of the vehicle is assumed to be traversable, and the rest of the image is then filtered to find similarly colored or textured pixels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 404529,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f60812c47ffd7e63a22469dc3a0577f86033136",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The majority of current image-based road following algorithms operate, at least in part, by assuming the presence of structural or visual cues unique to the roadway. As a result, these algorithms are poorly suited to the task of tracking unstructured roads typical in desert environments. In this paper, we propose a road following algorithm that operates in a selfsupervised learning regime, allowing it to adapt to changing road conditions while making no assumptions about the general structure or appearance of the road surface. An application of optical flow techniques, paired with one-dimensional template matching, allows identification of regions in the current camera image that closely resemble the learned appearance of the road in the recent past. The algorithm assumes the vehicle lies on the road in order to form templates of the road\u2019s appearance. A dynamic programming variant is then applied to optimize the 1-D template match results while enforcing a constraint on the maximum road curvature expected. Algorithm output images, as well as quantitative results, are presented for three distinct road types encountered in actual driving video acquired in the California Mojave Desert."
            },
            "slug": "Adaptive-Road-Following-using-Self-Supervised-and-Lieb-Lookingbill",
            "title": {
                "fragments": [],
                "text": "Adaptive Road Following using Self-Supervised Learning and Reverse Optical Flow"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A road following algorithm that operates in a selfsupervised learning regime, allowing it to adapt to changing road conditions while making no assumptions about the general structure or appearance of the road surface is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Robotics: Science and Systems"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35595732"
                        ],
                        "name": "L. Jackel",
                        "slug": "L.-Jackel",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Jackel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jackel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737088"
                        ],
                        "name": "E. Krotkov",
                        "slug": "E.-Krotkov",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Krotkov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Krotkov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2749773"
                        ],
                        "name": "M. Perschbacher",
                        "slug": "M.-Perschbacher",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Perschbacher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Perschbacher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1957016"
                        ],
                        "name": "James Pippine",
                        "slug": "James-Pippine",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Pippine",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Pippine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33345540"
                        ],
                        "name": "Chad Sullivan",
                        "slug": "Chad-Sullivan",
                        "structuredName": {
                            "firstName": "Chad",
                            "lastName": "Sullivan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chad Sullivan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 101
                            }
                        ],
                        "text": "The platform and the program have been thoroughly documented in previous publications (Jackel, 2005; Jackel et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 29011527,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f46592898b485ba0174c421bd8145e797f0129a0",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "The DARPA Learning Applied to Ground Vehicles (LAGR) program is accelerating progress in autonomous, perception\u2010based, off\u2010road navigation in unmanned ground vehicles (UGVs) by incorporating learned behaviors. In addition, the program is using passive optical systems to accomplish long\u2010range scene analysis. By combining long\u2010range perception with learned behavior, LAGR expects to make a qualitative break with the myopic, brittle behavior that characterizes most UGV autonomous navigation in unstructured environments. The very nature of testing navigation in unstructured, off\u2010road environments makes accurate, objective measurement of progress a challenging task. While no absolute measure of performance has been defined by LAGR, the Government Team managing the program has created a relative measure: the Government Team tests navigation software by comparing its effectiveness to that of fixed, but state\u2010of\u2010the\u2010art, navigation software running on a standardized vehicle on a series of varied test courses. Starting in March 2005, eight performers have been submitting navigation code for Government testing on such a standardized Government vehicle. As this text is being written, several teams have already demonstrated leaps in performance. In this paper we report observations on the state of the art in autonomous, off\u2010road UGV navigation, we explain how LAGR intends to change current methods, we discuss the challenges we face in implementing technical aspects of the program, we describe early results, and we suggest where major opportunities for breakthroughs exist as LAGR progresses. \u00a9 2007 Wiley Periodicals, Inc."
            },
            "slug": "The-DARPA-LAGR-program:-Goals,-challenges,-and-I-Jackel-Krotkov",
            "title": {
                "fragments": [],
                "text": "The DARPA LAGR program: Goals, challenges, methodology, and phase I results"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Observations on the state of the art in autonomous, off\u2010road UGV navigation are reported, how LAGR intends to change current methods is explained, the challenges the program faces in implementing technical aspects of the program are discussed, early results are described, and where major opportunities for breakthroughs exist are suggested."
            },
            "venue": {
                "fragments": [],
                "text": "J. Field Robotics"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111414926"
                        ],
                        "name": "Dongshin Kim",
                        "slug": "Dongshin-Kim",
                        "structuredName": {
                            "firstName": "Dongshin",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dongshin Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46968797"
                        ],
                        "name": "Jie Sun",
                        "slug": "Jie-Sun",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2457612"
                        ],
                        "name": "Sangmin Oh",
                        "slug": "Sangmin-Oh",
                        "structuredName": {
                            "firstName": "Sangmin",
                            "lastName": "Oh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sangmin Oh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144177248"
                        ],
                        "name": "James M. Rehg",
                        "slug": "James-M.-Rehg",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Rehg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James M. Rehg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688328"
                        ],
                        "name": "A. Bobick",
                        "slug": "A.-Bobick",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Bobick",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bobick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 200
                            }
                        ],
                        "text": "The Georgia Tech LAGR team built a self-supervised terrain classifier that uses traversability cues from close-range sensors (IMU, bumper switch) to train a classifier on stereo point cloud features (Kim et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 120
                            }
                        ],
                        "text": "The first challenge is the choice of a feature representation that is robust to irrelevant transformations of the input, such as lighting and viewpoint."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13236716,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "64833a5f6434e8260c94fb22e703dac160859141",
            "isKey": false,
            "numCitedBy": 194,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Estimating the traversability of terrain in an unstructured outdoor environment is a core functionality for autonomous robot navigation. While general-purpose sensing can be used to identify the existence of terrain features such as vegetation and sloping ground, the traversability of these regions is a complex function of the terrain characteristics and vehicle capabilities, which makes it extremely difficult to characterize a priori. Moreover, it is difficult to find general rules which work for a wide variety of terrain types such as trees, rocks, tall grass, logs, and bushes. As a result, methods which provide traversability estimates based on predefined terrain properties such as height or shape will be unlikely to work reliably in unknown outdoor environments. Our approach is based on the observation that traversability in the most general sense is an affordance which is jointly determined by the vehicle and its environment. We describe a novel on-line learning method which can make accurate predictions of the traversability properties of complex terrain. Our method is based on autonomous training data collection which exploits the robot's experience in navigating its environment to train classifiers without human intervention. This is in contrast to other learning methods in which training data is collected manually. We have implemented and tested our traversability learning method on an unmanned ground vehicle (UGV) and evaluated its performance in several realistic outdoor environments. The experiments quantify the benefit of our on-line traversability learning approach"
            },
            "slug": "Traversability-classification-using-unsupervised-Kim-Sun",
            "title": {
                "fragments": [],
                "text": "Traversability classification using unsupervised on-line visual learning for outdoor robot navigation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A novel on-line learning method which can make accurate predictions of the traversability properties of complex terrain based on autonomous training data collection which exploits the robot's experience in navigating its environment to train classifiers without human intervention."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2006 IEEE International Conference on Robotics and Automation, 2006. ICRA 2006."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2348519"
                        ],
                        "name": "Michael Happold",
                        "slug": "Michael-Happold",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Happold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Happold"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2071427"
                        ],
                        "name": "Mark Ollis",
                        "slug": "Mark-Ollis",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Ollis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Ollis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1886412"
                        ],
                        "name": "N. Johnson",
                        "slug": "N.-Johnson",
                        "structuredName": {
                            "firstName": "Nikolas",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 213,
                                "start": 193
                            }
                        ],
                        "text": "Thus their obstacle detection algorithm is in two phases: first color information is extracted and stereo geometry is predicted, then the predicted geometry is mapped to a traversability cost (Happold et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 107
                            }
                        ],
                        "text": "Training with large image patches allows for high-level recognition of obstacles, paths, groundtypes, and other natural features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17392971,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b3fd601fec6452120ee8d275e1b7ec5eae65b23c",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a method for classifying the traversability of terrain by combining unsupervised learning of color models that predict scene geometry with supervised learning of the relationship between geometric features and traversability. A neural network is trained offline on hand-labeled geometric features computed from stereo data. An online process learns the association between color and geometry, enabling the robot to assess the traversability of regions for which there is little range information by estimating the geometry from the color of the scene and passing this to the neural network. This online process is continuous and extremely rapid, which allows for quick adaptations to different lighting conditions and terrain changes. The sensitivity of the traversability judgment is further adjusted online by feedback from the robot\u2019s bumper. Terrain assessments from the color classifier are merged with pure geometric classifications in an occupancy grid by computing the intersection of the ray associated with a pixel with a ground plane computed from the stereo range data. We present results from DARPA-conducted tests that demonstrate its effectiveness in a variety of outdoor environments."
            },
            "slug": "Enhancing-Supervised-Terrain-Classification-with-Happold-Ollis",
            "title": {
                "fragments": [],
                "text": "Enhancing Supervised Terrain Classification with Predictive Unsupervised Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "This paper describes a method for classifying the traversability of terrain by combining unsupervised learning of color models that predict scene geometry with supervised learning of the relationship between geometric features and traversability, and presents results from DARPA-conducted tests that demonstrate its effectiveness in a variety of outdoor environments."
            },
            "venue": {
                "fragments": [],
                "text": "Robotics: Science and Systems"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076828"
                        ],
                        "name": "G. Grudic",
                        "slug": "G.-Grudic",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Grudic",
                            "middleNames": [
                                "Z."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Grudic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2646255"
                        ],
                        "name": "J. Mulligan",
                        "slug": "J.-Mulligan",
                        "structuredName": {
                            "firstName": "Jane",
                            "lastName": "Mulligan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mulligan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 132
                            }
                        ],
                        "text": "The primary contribution of this work is a long-range vision system that uses self-supervised learning to train a classifier in realtime."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 163
                            }
                        ],
                        "text": "Staying within the realm\nof simple color-based near-to-far learning, Grudic and Mulligan explore the use of distance metrics for clustering traversable pixels in (Grudic and Mulligan, 2006)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12304391,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e615e4de0382153fe2238619086c437631a95055",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Autonomous robot navigation in outdoor environments remains a challenging and unsolved problem. A key issue is our ability to identify safe or navigable paths far enough ahead of the robot to allow smooth trajectories at acceptable speeds. Colour or texture-based labeling of safe path regions in image sequences is one way to achieve this far field prediction. A challenge for classifiers identifying path and nonpath regions is to make meaningful comparisons of feature vectors at pixels or over a window. Most simple distance metrics cannot use all the information available and therefore the resulting labeling does not tightly capture the visible path. We introduce a new Polynomial Mahalanobis Distance and demonstrate its ability to capture the properties of an initial positive path sample and produce accurate path segmentation with few outliers. Experiments show the method\u2019s effectiveness for path segmentation in natural scenes using both colour and texture feature vectors. The new metric is compared with classifications based on Euclidean and standard Mahalanobis distance and produces superior results."
            },
            "slug": "Outdoor-Path-Labeling-Using-Polynomial-Mahalanobis-Grudic-Mulligan",
            "title": {
                "fragments": [],
                "text": "Outdoor Path Labeling Using Polynomial Mahalanobis Distance"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new Polynomial Mahalanobis Distance is introduced and its ability to capture the properties of an initial positive path sample and produce accurate path segmentation with few outliers is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "Robotics: Science and Systems"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781188"
                        ],
                        "name": "K. Konolige",
                        "slug": "K.-Konolige",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Konolige",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Konolige"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36153647"
                        ],
                        "name": "M. Agrawal",
                        "slug": "M.-Agrawal",
                        "structuredName": {
                            "firstName": "Motilal",
                            "lastName": "Agrawal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Agrawal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764443"
                        ],
                        "name": "R. Bolles",
                        "slug": "R.-Bolles",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bolles",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bolles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1946779"
                        ],
                        "name": "C. Cowan",
                        "slug": "C.-Cowan",
                        "structuredName": {
                            "firstName": "Cregg",
                            "lastName": "Cowan",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Cowan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2465976"
                        ],
                        "name": "M. Fischler",
                        "slug": "M.-Fischler",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Fischler",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Fischler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3087910"
                        ],
                        "name": "Brian P. Gerkey",
                        "slug": "Brian-P.-Gerkey",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Gerkey",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian P. Gerkey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 70
                            }
                        ],
                        "text": "The SRI LAGR system used fast stereo and color-based online learning (Konolige et al., 2008)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1889386,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e06a99bbaa918c1af7808995d68a9935ed829c6",
            "isKey": false,
            "numCitedBy": 222,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of autonomous navigation in an unstructured outdoor environment. The goal is for a small outdoor robot to come into a new area, learn about and map its environment, and move to a given goal at modest speeds (1 m/s). This problem is especially difficult in outdoor, off-road environments, where tall grass, shadows, deadfall, and other obstacles predominate. Not surprisingly, the biggest challenge is acquiring and using a reliable map of the new area. Although work in outdoor navigation has preferentially used laser rangefinders [14,2,6], we use stereo vision as the main sensor. Vision sensors allow us to use more distant objects as landmarks for navigation, and to learn and use color and texture models of the environment, in looking further ahead than is possible with range sensors alone."
            },
            "slug": "Outdoor-Mapping-and-Navigation-Using-Stereo-Vision-Konolige-Agrawal",
            "title": {
                "fragments": [],
                "text": "Outdoor Mapping and Navigation Using Stereo Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "This work considers the problem of autonomous navigation in an unstructured outdoor environment, and uses stereo vision as the main sensor to use more distant objects as landmarks for navigation, and to learn and use color and texture models of the environment."
            },
            "venue": {
                "fragments": [],
                "text": "ISER"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40908101"
                        ],
                        "name": "T. Hong",
                        "slug": "T.-Hong",
                        "structuredName": {
                            "firstName": "Tsai",
                            "lastName": "Hong",
                            "middleNames": [],
                            "suffix": ""
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46887763"
                        ],
                        "name": "C. Rasmussen",
                        "slug": "C.-Rasmussen",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Rasmussen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rasmussen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2134442775"
                        ],
                        "name": "Tommy Chang",
                        "slug": "Tommy-Chang",
                        "structuredName": {
                            "firstName": "Tommy",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tommy Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064843"
                        ],
                        "name": "M. Shneier",
                        "slug": "M.-Shneier",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Shneier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Shneier"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 127
                            }
                        ],
                        "text": "Current robotics research has recently begun to develop vision-based systems that can navigate through offroad environments; however, existing approaches generally rely on stereo algorithms, which produce short-range, sparse, and noisy costmaps that are inadequate for long-range strategic\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 96
                            }
                        ],
                        "text": "This is especially useful for roadfollowing vehicles (Dahlkamp et al., 2006; Leib et al., 2005; Hong et al., 2002); the ground immediately in front of the vehicle is assumed to be traversable, and the rest of the image is then filtered to find similarly colored or textured pixels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13293810,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "02e40693b2ba031edaeac3235a6146e66e227402",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "As part of the Army's Demo III project, a sensor-based system has been developed to identify roads and to enable a mobile robot to drive along them. A ladar sensor, which produces range images, and a color camera are used in conjunction to locate the road surface and its boundaries. Sensing is used to constantly update an internal world model of the road surface. The world model is used to predict the future position of the road and to focus the attention of the sensors on the relevant regions in their respective images. The world model also determines the most suitable algorithm for locating and tracking road features in the images based on the current task and sensing information. The planner uses information from the world model to determine the best path for the vehicle along the road. Several different algorithms have been developed and tested on a diverse set of road sequences. The road types include some paved roads with lanes, but most of the sequences are of unpaved roads, including dirt and gravel roads. The algorithms compute various features of the road images including smoothness in the world model map and in the range domain, and color features and texture in the color domain. Performance in road detection and tracking are described and examples are shown of the system in action."
            },
            "slug": "Road-detection-and-tracking-for-autonomous-mobile-Hong-Rasmussen",
            "title": {
                "fragments": [],
                "text": "Road detection and tracking for autonomous mobile robots"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A sensor-based system has been developed to identify roads and to enable a mobile robot to drive along them and performance in road detection and tracking are described and examples are shown of the system in action."
            },
            "venue": {
                "fragments": [],
                "text": "SPIE Defense + Commercial Sensing"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145976879"
                        ],
                        "name": "S. Goldberg",
                        "slug": "S.-Goldberg",
                        "structuredName": {
                            "firstName": "Steven.",
                            "lastName": "Goldberg",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Goldberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781507"
                        ],
                        "name": "M. Maimone",
                        "slug": "M.-Maimone",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Maimone",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maimone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782162"
                        ],
                        "name": "L. Matthies",
                        "slug": "L.-Matthies",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Matthies",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Matthies"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 129
                            }
                        ],
                        "text": "Humans navigate effortlessly through most outdoor environments, detecting and planning around distant obstacles even in new, never-seen terrain."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 145
                            }
                        ],
                        "text": "Maps from multiple frames are assembled in a global map in which path finding algorithms are run (Kelly and Stentz, 1998; Kriegman et al., 1989; Goldberg et al., 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 129
                            }
                        ],
                        "text": "Many methods for vision-based navigation rely on stereo-based obstacle detection (Kelly and Stentz, 1998; Kriegman et al., 1989; Goldberg et al., 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 109873447,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a1b69be3d2dae9ebd388e81927f2b086431dc7b",
            "isKey": false,
            "numCitedBy": 424,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "NASA's Mars Exploration Rover (MER) missions will land twin rovers on the surface of Mars in 2004. These rovers will have the ability to navigate safely through unknown and potentially hazardous terrain, using autonomous passive stereo vision to detect potential terrain hazards before driving into them. Unfortunately, the computational power of currently available radiation hardened processors limits the amount of distance (and therefore science) that can be safely achieved by any rover in a given time frame. We present overviews of our current rover vision and navigation systems, to provide context for the types of computation that are required to navigate safely. We also present baseline timing results that represent a lower bound in achievable performance (useful for systems engineering studies of future missions), and describe ways to improve that performance using commercial grade (as opposed to radiation hardened) processors. In particular, we document speedups to our stereo vision system that were achieved using the vectorized operations provided by Pentium MMX technology. Timing data were derived from implementations on several platforms: a prototype Mars rover with flight-like electronics (the Athena Software Development Model (SDM) rover), a RAD6000 computing platform (as will be used in the 2003 MER missions), and research platforms with commercial Pentium III and Sparc processors. Finally, we summarize the radiation effects analysis that suggests that commercial grade processors are likely to be adequate for Mars surface missions, and discuss the level of speedup that may accrue from using these instead of radiation hardened parts."
            },
            "slug": "Stereo-vision-and-rover-navigation-software-for-Goldberg-Maimone",
            "title": {
                "fragments": [],
                "text": "Stereo vision and rover navigation software for planetary exploration"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The radiation effects analysis is summarized that suggests that commercial grade processors are likely to be adequate for Mars surface missions, and the level of speedup that may accrue from using these instead of radiation hardened parts is discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings, IEEE Aerospace Conference"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145135843"
                        ],
                        "name": "A. Kelly",
                        "slug": "A.-Kelly",
                        "structuredName": {
                            "firstName": "Alonzo",
                            "lastName": "Kelly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kelly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722938"
                        ],
                        "name": "A. Stentz",
                        "slug": "A.-Stentz",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Stentz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stentz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 82
                            }
                        ],
                        "text": "Humans navigate effortlessly through most outdoor environments, detecting and planning around distant obstacles even in new, never-seen terrain."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 98
                            }
                        ],
                        "text": "Maps from multiple frames are assembled in a global map in which path finding algorithms are run (Kelly and Stentz, 1998; Kriegman et al., 1989; Goldberg et al., 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 82
                            }
                        ],
                        "text": "Many methods for vision-based navigation rely on stereo-based obstacle detection (Kelly and Stentz, 1998; Kriegman et al., 1989; Goldberg et al., 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9967809,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9d07c7ec369099a7f52f6add27e057380b1cfd2b",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The contemporary implementation of software systems for offroad navigation on conventional computing involves a continuous struggle to develop more computationally efficient algorithms. A basic trade-off exists between system performance and reliability for any given level of efficiency of the software. Hence, the only way to improve both performance and reliability is to improve the computational efficiency of the underlying algorithms. Dense stereo vision algorithms can easily exhaust almost all available computer cycles and are therefore prime candidates for the development of more efficient approaches. This paper presents some techniques that can be used to improve the efficiency and/or reliability of dense stereo for off road autonomous vehicles."
            },
            "slug": "Stereo-Vision-Enhancements-for-Low-Cost-Outdoor-Kelly-Stentz",
            "title": {
                "fragments": [],
                "text": "Stereo Vision Enhancements for Low-Cost Outdoor Autonomous Vehicles"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper presents some techniques that can be used to improve the efficiency and/or reliability of dense stereo for off road autonomous vehicles."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765887"
                        ],
                        "name": "D. Kriegman",
                        "slug": "D.-Kriegman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kriegman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kriegman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2437345"
                        ],
                        "name": "E. Triendl",
                        "slug": "E.-Triendl",
                        "structuredName": {
                            "firstName": "Ernst",
                            "lastName": "Triendl",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Triendl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738591"
                        ],
                        "name": "T. Binford",
                        "slug": "T.-Binford",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Binford",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Binford"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 81
                            }
                        ],
                        "text": "Many methods for vision-based navigation rely on stereo-based obstacle detection (Goldberg et al., 2002; Kelly & Stentz, 1998; Kriegman et al., 1989)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 122
                            }
                        ],
                        "text": "Maps from multiple frames are assembled in a global map in which path finding algorithms are run (Kelly and Stentz, 1998; Kriegman et al., 1989; Goldberg et al., 2002)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 106
                            }
                        ],
                        "text": "Many methods for vision-based navigation rely on stereo-based obstacle detection (Kelly and Stentz, 1998; Kriegman et al., 1989; Goldberg et al., 2002)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 140578,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a27332b0e4d02e3d379bd1cc62aa9388f437087",
            "isKey": false,
            "numCitedBy": 317,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "A mobile robot that autonomously functions in a complex and previously unknown indoor environment has been developed. The omnidirectional mobile robot uses stereo vision, odometry, and contact bumpers to instantiate a symbolic world model. Finding stereo correspondences across a single epipolar line is adequate for instantiating the model. Uncertainty in sensor data is represented by a multivariate normal distribution, and uncertainty models for motion and stereo are presented. Uncertainty is reduced by extended Kalman filtering. To execute a high-level command such as 'Enter the second door on the left', a model is instantiated from sensing and motions are planned and executed. Experimental results from the fast, running system are presented. >"
            },
            "slug": "Stereo-vision-and-navigation-in-buildings-for-Kriegman-Triendl",
            "title": {
                "fragments": [],
                "text": "Stereo vision and navigation in buildings for mobile robots"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A mobile robot that autonomously functions in a complex and previously unknown indoor environment has been developed that uses stereo vision, odometry, and contact bumpers to instantiate a symbolic world model."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Robotics Autom."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36328565"
                        ],
                        "name": "Carl K. Wellington",
                        "slug": "Carl-K.-Wellington",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Wellington",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carl K. Wellington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722938"
                        ],
                        "name": "A. Stentz",
                        "slug": "A.-Stentz",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Stentz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Stentz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 32
                            }
                        ],
                        "text": "This may cause the system to drive as if in a self-imposed \u201cfog\u201d, driving into dead-ends and taking time to discover distant pathways that are obvious to a human observer (see Fig."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 148
                            }
                        ],
                        "text": "An online self-supervised classifier for a ladarbased navigation system was trained to predict load-bearing surfaces in the presence of vegetation (Wellington and Stentz, 2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2000564,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "211e8d9b2830bb2c4b977371786eed3e68687c40",
            "isKey": false,
            "numCitedBy": 87,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Autonomous navigation in vegetation is challenging because the vegetation often hides the load-bearing surface, which is used for evaluating the safety of potential actions. It is difficult to design rules for finding the true ground height in vegetation from forward looking sensor data, so we use an online adaptive method to automatically learn this mapping through experience with the world. This approach has been implemented on an autonomous tractor and has been tested in a farm setting. We describe the system and provide examples of finding obstacles and improving roll predictions in the presence of vegetation. We also show that the system can adapt to new vegetation conditions."
            },
            "slug": "Online-adaptive-rough-terrain-navigation-vegetation-Wellington-Stentz",
            "title": {
                "fragments": [],
                "text": "Online adaptive rough-terrain navigation vegetation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An online adaptive method is used to automatically learn rules for finding the true ground height in vegetation from forward looking sensor data, which has been implemented on an autonomous tractor and has been tested in a farm setting."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE International Conference on Robotics and Automation, 2004. Proceedings. ICRA '04. 2004"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706809"
                        ],
                        "name": "Marc'Aurelio Ranzato",
                        "slug": "Marc'Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Marc'Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc'Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13919023"
                        ],
                        "name": "F. Huang",
                        "slug": "F.-Huang",
                        "structuredName": {
                            "firstName": "Fu",
                            "lastName": "Huang",
                            "middleNames": [
                                "Jie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "90841478"
                        ],
                        "name": "Y-Lan Boureau",
                        "slug": "Y-Lan-Boureau",
                        "structuredName": {
                            "firstName": "Y-Lan",
                            "lastName": "Boureau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y-Lan Boureau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 119
                            }
                        ],
                        "text": "The next feature extraction approach uses some of the principles of deep belief network training (Hinton et al., 2006; Ranzato et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11398758,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ccd52aff02b0f902f4ce7247c4fee7273014c41c",
            "isKey": false,
            "numCitedBy": 1093,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an unsupervised method for learning a hierarchy of sparse feature detectors that are invariant to small shifts and distortions. The resulting feature extractor consists of multiple convolution filters, followed by a feature-pooling layer that computes the max of each filter output within adjacent windows, and a point-wise sigmoid non-linearity. A second level of larger and more invariant features is obtained by training the same algorithm on patches of features from the first level. Training a supervised classifier on these features yields 0.64% error on MNIST, and 54% average recognition rate on Caltech 101 with 30 training samples per category. While the resulting architecture is similar to convolutional networks, the layer-wise unsupervised training procedure alleviates the over-parameterization problems that plague purely supervised learning procedures, and yields good performance with very few labeled training samples."
            },
            "slug": "Unsupervised-Learning-of-Invariant-Feature-with-to-Ranzato-Huang",
            "title": {
                "fragments": [],
                "text": "Unsupervised Learning of Invariant Feature Hierarchies with Applications to Object Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "An unsupervised method for learning a hierarchy of sparse feature detectors that are invariant to small shifts and distortions that alleviates the over-parameterization problems that plague purely supervised learning procedures, and yields good performance with very few labeled training samples."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2217144"
                        ],
                        "name": "Simon Osindero",
                        "slug": "Simon-Osindero",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Osindero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Simon Osindero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725303"
                        ],
                        "name": "Y. Teh",
                        "slug": "Y.-Teh",
                        "structuredName": {
                            "firstName": "Yee",
                            "lastName": "Teh",
                            "middleNames": [
                                "Whye"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Teh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 98
                            }
                        ],
                        "text": "The next feature extraction approach uses some of the principles of deep belief network training (Hinton et al., 2006; Ranzato et al., 2007)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2309950,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8978cf7574ceb35f4c3096be768c7547b28a35d0",
            "isKey": false,
            "numCitedBy": 13502,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We show how to use complementary priors to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind."
            },
            "slug": "A-Fast-Learning-Algorithm-for-Deep-Belief-Nets-Hinton-Osindero",
            "title": {
                "fragments": [],
                "text": "A Fast Learning Algorithm for Deep Belief Nets"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A fast, greedy algorithm is derived that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144867807"
                        ],
                        "name": "S. Thrun",
                        "slug": "S.-Thrun",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Thrun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thrun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 69
                            }
                        ],
                        "text": "Although this approach helped to win the 2005 DARPA Grand Challenge (Thrun et al., 2006), its utility was limited by the inherent fragility of color-based methods, and the online visual classifier was only used to slightly modulate the speed of the autonomous car, rather than used for planning of\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 80
                            }
                        ],
                        "text": "The method of choice for vision-based driving in offroad mobile robots is to construct a traversability map of the environment using stereo vision."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 46
                            }
                        ],
                        "text": "Although this approach helped to win the 2005 DARPA Grand Challenge (Thrun et al., 2006), its utility was limited by the inherent fragility of color-based methods, and the online visual classifier was only used to slightly modulate the speed of the autonomous car, rather than used for planning of any sort."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1438204,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e938cf8a74c2e7415bfd10d66a9ea4b1c3e0e15",
            "isKey": true,
            "numCitedBy": 2105,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "This article describes the robot Stanley, which won the 2005 DARPA Grand Challenge. Stanley was developed for high\u2010speed desert driving without manual intervention. The robot's software system relied predominately on state\u2010of\u2010the\u2010art artificial intelligence technologies, such as machine learning and probabilistic reasoning. This paper describes the major components of this architecture, and discusses the results of the Grand Challenge race. \u00a9 2006 Wiley Periodicals, Inc."
            },
            "slug": "Stanley:-The-robot-that-won-the-DARPA-Grand-Thrun",
            "title": {
                "fragments": [],
                "text": "Stanley: The robot that won the DARPA Grand Challenge"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "The robot Stanley, which won the 2005 DARPA Grand Challenge, was developed for high\u2010speed desert driving without manual intervention and relied predominately on state\u2010of\u2010the\u2010art artificial intelligence technologies, such as machine learning and probabilistic reasoning."
            },
            "venue": {
                "fragments": [],
                "text": "J. Field Robotics"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2035627651"
                        ],
                        "name": "SermanetPierre",
                        "slug": "SermanetPierre",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "SermanetPierre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "SermanetPierre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2035627068"
                        ],
                        "name": "HadsellRaia",
                        "slug": "HadsellRaia",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "HadsellRaia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "HadsellRaia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2035620895"
                        ],
                        "name": "ScoffierMarco",
                        "slug": "ScoffierMarco",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "ScoffierMarco",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "ScoffierMarco"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2131708675"
                        ],
                        "name": "GrimesMatt",
                        "slug": "GrimesMatt",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "GrimesMatt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "GrimesMatt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2035627271"
                        ],
                        "name": "BenJan",
                        "slug": "BenJan",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "BenJan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "BenJan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2035626069"
                        ],
                        "name": "ErkanAyse",
                        "slug": "ErkanAyse",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "ErkanAyse",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "ErkanAyse"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2131761740"
                        ],
                        "name": "CrudeleChris",
                        "slug": "CrudeleChris",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "CrudeleChris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "CrudeleChris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2131736922"
                        ],
                        "name": "MillerUrs",
                        "slug": "MillerUrs",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "MillerUrs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "MillerUrs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644009625"
                        ],
                        "name": "LecunYann",
                        "slug": "LecunYann",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "LecunYann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "LecunYann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 52
                            }
                        ],
                        "text": "Details of the full navigation system are given in (Sermanet et al., 2008b; Sermanet et al., 2008a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 128
                            }
                        ],
                        "text": "Details of the full system, including architecture, short-range perception and planning, and long-range planning, are given in (Sermanet et al., 2008a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 58
                            }
                        ],
                        "text": "This multi-resolution architecture is fully described in (Sermanet et al., 2008b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 117
                            }
                        ],
                        "text": "Figures 18, 19, 20, 21, 22, and 23 show examples of long-range mapping with a hyperbolic polar map, as described in (Sermanet et al., 2008a; Sermanet et al., 2008b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 238541657,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1835e01f774934cc59062dab203dae5a2f9a163e",
            "isKey": true,
            "numCitedBy": 3,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a multilayered mapping, planning, and command execution system developed and tested on the LAGR mobile robot. Key to robust performance under uncertainty is the combination of a short-ra..."
            },
            "slug": "A-multirange-architecture-for-collision-free-robot-SermanetPierre-HadsellRaia",
            "title": {
                "fragments": [],
                "text": "A multirange architecture for collision-free off-road robot navigation"
            },
            "tldr": {
                "abstractSimilarityScore": 85,
                "text": "This work presents a multilayered mapping, planning, and command execution system developed and tested on the LAGR mobile robot, which demonstrates robust performance under uncertainty."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35106875"
                        ],
                        "name": "R. Duda",
                        "slug": "R.-Duda",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Duda",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Duda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3108177"
                        ],
                        "name": "P. Hart",
                        "slug": "P.-Hart",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Hart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 19
                            }
                        ],
                        "text": "A Hough transform (Duda and Hart, 1972) is a voting procedure that is used to select a shape from within a parameterized class of shapes (in this case, the class of planes)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1105637,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "2415fd60305739543105118739f7118493257af3",
            "isKey": false,
            "numCitedBy": 6455,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "Hough has proposed an interesting and computationally efficient procedure for detecting lines in pictures. This paper points out that the use of angle-radius rather than slope-intercept parameters simplifies the computation further. It also shows how the method can be used for more general curve fitting, and gives alternative interpretations that explain the source of its efficiency."
            },
            "slug": "Use-of-the-Hough-transformation-to-detect-lines-and-Duda-Hart",
            "title": {
                "fragments": [],
                "text": "Use of the Hough transformation to detect lines and curves in pictures"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is pointed out that the use of angle-radius rather than slope-intercept parameters simplifies the computation further, and how the method can be used for more general curve fitting."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1972
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 52
                            }
                        ],
                        "text": "Details of the full navigation system are given in (Sermanet et al., 2008b; Sermanet et al., 2008a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 128
                            }
                        ],
                        "text": "Details of the full system, including architecture, short-range perception and planning, and long-range planning, are given in (Sermanet et al., 2008a)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 58
                            }
                        ],
                        "text": "This multi-resolution architecture is fully described in (Sermanet et al., 2008b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 117
                            }
                        ],
                        "text": "Figures 18, 19, 20, 21, 22, and 23 show examples of long-range mapping with a hyperbolic polar map, as described in (Sermanet et al., 2008a; Sermanet et al., 2008b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A multi-range architecture for collision-free off-road robot"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 25
                            }
                        ],
                        "text": "A convolutional network (LeCun and Bengio, 1995) contains local receptive fields that are trained to extract local features and patterns."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6916627,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "563e821bb5ea825efb56b77484f5287f08cf3753",
            "isKey": false,
            "numCitedBy": 4130,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Convolutional-networks-for-images,-speech,-and-time-LeCun-Bengio",
            "title": {
                "fragments": [],
                "text": "Convolutional networks for images, speech, and time series"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 148
                            }
                        ],
                        "text": "An online self-supervised classifier for a ladarbased navigation system was trained to predict load-bearing surfaces in the presence of vegetation (Wellington and Stentz, 2004)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Online adaptive roughterrain navigation in vegetation"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of International Conference on Robotics and Automation (ICRA), New Orleans, LA (pp. 96\u2013101). IEEE. Journal of Field Robotics DOI 10.1002/rob"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 119
                            }
                        ],
                        "text": "The Triclops SDK, from Point Grey Research, provides image rectification and stereo processing on each pair of cameras (Inc., 2003)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Triclops Stereo Vision Software Development Kit User\u2019s guide and command reference"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 87
                            }
                        ],
                        "text": "The platform and the program have been thoroughly documented in previous publications (Jackel, 2005; Jackel et al., 2006)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning applied to ground robots (LAGR)"
            },
            "venue": {
                "fragments": [],
                "text": "Learning applied to ground robots (LAGR)"
            },
            "year": 2005
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 17,
            "methodology": 19
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 27,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Learning-long\u2010range-vision-for-autonomous-off\u2010road-Hadsell-Sermanet/2d8f527d1a96b0dae209daa6a241cf3255a6ec0d?sort=total-citations"
}