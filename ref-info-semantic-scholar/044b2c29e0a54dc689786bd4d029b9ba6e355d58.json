{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145547836"
                        ],
                        "name": "A. S. Younger",
                        "slug": "A.-S.-Younger",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Younger",
                            "middleNames": [
                                "Steven"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. S. Younger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2927101"
                        ],
                        "name": "P. R. Conwell",
                        "slug": "P.-R.-Conwell",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Conwell",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. R. Conwell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2264754"
                        ],
                        "name": "N. E. Cotter",
                        "slug": "N.-E.-Cotter",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Cotter",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. E. Cotter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 115
                            }
                        ],
                        "text": "learning systems based on neural networks and used genetic algorithms to adjust the subordinate learning algorithm [2,10,19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 102
                            }
                        ],
                        "text": "The capability of recurrent networks to execute the subordinate system was proved and demonstrated in [3,19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11354159,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f67e7dd2495500f3975f39e541fa38073d49a2ee",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Conventional artificial neural networks perform functional mappings from their input space to their output space. The synaptic weights encode information about the mapping in a manner analogous to long-term memory in biological systems. This paper presents a method of designing neural networks where recurrent signal loops store this knowledge in a manner analogous to short-term memory. The synaptic weights of these networks encode a learning algorithm. This gives these networks the ability to dynamically learn any functional mapping from a (possibly very large) set, without changing any synaptic weights. These networks are adaptive dynamic systems. Learning is online continually taking place as part of the network's overall behavior instead of a separate, externally driven process. We present four higher order fixed-weight learning networks. Two of these networks have standard backpropagation embedded in their synaptic weights. The other two utilize a more efficient gradient-descent-based learning rule. This new learning scheme was discovered by examining variations in fixed-weight topology. We present empirical tests showing that all these networks were able to successfully learn functions from both discrete (Boolean) and continuous function sets. Largely, the networks were robust with respect to perturbations in the synaptic weights. The exception was the recurrent connections used to store information. These required a tight tolerance of 0.5%. We found that the cost of these networks scaled approximately in proportion to the total number of synapses. We consider evolving fixed weight networks tailored to a specific problem class by analyzing the meta-learning cost surface of the networks presented."
            },
            "slug": "Fixed-weight-on-line-learning-Younger-Conwell",
            "title": {
                "fragments": [],
                "text": "Fixed-weight on-line learning"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A method of designing neural networks where recurrent signal loops store this knowledge in a manner analogous to short-term memory, which gives these networks the ability to dynamically learn any functional mapping from a (possibly very large) set, without changing any synaptic weights."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690247"
                        ],
                        "name": "T. Runarsson",
                        "slug": "T.-Runarsson",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Runarsson",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Runarsson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47398115"
                        ],
                        "name": "M. Jonsson",
                        "slug": "M.-Jonsson",
                        "structuredName": {
                            "firstName": "Magnus",
                            "lastName": "Jonsson",
                            "middleNames": [
                                "Thor"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Jonsson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 115
                            }
                        ],
                        "text": "learning systems based on neural networks and used genetic algorithms to adjust the subordinate learning algorithm [2,10,19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60641576,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ad9b6c56748ff12fb10536d0c189fb6835b2e43",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper describes the application of neural networks as learning rules for the training of neural networks. The learning rule is part of the neural network architecture. As a result the learning rule is non-local and globally distributed within the network. The learning rules are evolved using an evolution strategy. The survival of a learning rule is based on its performance in training neural networks on a set of tasks. Training algorithms will be evolved for single layer artificial neural networks. Experimental results show that a learning rule of this type is very capable of generating an efficient training algorithm."
            },
            "slug": "Evolution-and-design-of-distributed-learning-rules-Runarsson-Jonsson",
            "title": {
                "fragments": [],
                "text": "Evolution and design of distributed learning rules"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Experimental results show that a learning rule of this type is very capable of generating an efficient training algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "2000 IEEE Symposium on Combinations of Evolutionary Computation and Neural Networks. Proceedings of the First IEEE Symposium on Combinations of Evolutionary Computation and Neural Networks (Cat. No.00"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072252"
                        ],
                        "name": "D. Chalmers",
                        "slug": "D.-Chalmers",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Chalmers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Chalmers"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 115
                            }
                        ],
                        "text": "learning systems based on neural networks and used genetic algorithms to adjust the subordinate learning algorithm [2,10,19]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10538501,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "id": "74fd7e2750614b8b405a9e45d639331c3ed9d811",
            "isKey": false,
            "numCitedBy": 239,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Evolution-of-Learning:-An-Experiment-in-Genetic-Chalmers",
            "title": {
                "fragments": [],
                "text": "The Evolution of Learning: An Experiment in Genetic Connectionism"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47055692"
                        ],
                        "name": "P. Werbos",
                        "slug": "P.-Werbos",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Werbos",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Werbos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 105
                            }
                        ],
                        "text": "(B) Recurrent network with fully recurrent hidden layer trained with Back Propagation Through Time (BPTT [18,16]) truncated after 2 time steps and with Real Time Recurrent Learning (RTRL [9,17])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 62
                            }
                        ],
                        "text": "One may choose for example backpropagation through time (BPTT [18,16]) or real-time recurrent learning (RTRL [9,17]) as attendant learning algorithms."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 205118721,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "266e07d0dd9a75b61e3632e9469993dbaf063f1c",
            "isKey": false,
            "numCitedBy": 882,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Generalization-of-backpropagation-with-application-Werbos",
            "title": {
                "fragments": [],
                "text": "Generalization of backpropagation with application to a recurrent gas market model"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308557"
                        ],
                        "name": "S. Hochreiter",
                        "slug": "S.-Hochreiter",
                        "structuredName": {
                            "firstName": "Sepp",
                            "lastName": "Hochreiter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hochreiter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 733161,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f91154c0d159a3f2dd3638915db32c5914544273",
            "isKey": false,
            "numCitedBy": 534,
            "numCiting": 76,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new algorithm for finding low-complexity neural networks with high generalization capability. The algorithm searches for a flat minimum of the error function. A flat minimum is a large connected region in weight space where the error remains approximately constant. An MDL-based, Bayesian argument suggests that flat minima correspond to simple networks and low expected overfitting. The argument is based on a Gibbs algorithm variant and a novel way of splitting generalization error into underfitting and overfitting error. Unlike many previous approaches, ours does not require gaussian assumptions and does not depend on a good weight prior. Instead we have a prior over input output functions, thus taking into account net architecture and training set. Although our algorithm requires the computation of second-order derivatives, it has backpropagation's order of complexity. Automatically, it effectively prunes units, weights, and input lines. Various experiments with feedforward and recurrent nets are described. In an application to stock market prediction, flat minimum search outperforms conventional backprop, weight decay, and optimal brain surgeon/optimal brain damage."
            },
            "slug": "Flat-Minima-Hochreiter-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Flat Minima"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A new algorithm for finding low-complexity neural networks with high generalization capability that outperforms conventional backprop, weight decay, and optimal brain surgeon/optimal brain damage and requires the computation of second-order derivatives, but has backpropagation's order of complexity."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2264754"
                        ],
                        "name": "N. E. Cotter",
                        "slug": "N.-E.-Cotter",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Cotter",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. E. Cotter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2927101"
                        ],
                        "name": "P. R. Conwell",
                        "slug": "P.-R.-Conwell",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Conwell",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. R. Conwell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 102
                            }
                        ],
                        "text": "The capability of recurrent networks to execute the subordinate system was proved and demonstrated in [3,19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 32951368,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8001b80755bb8b189f3e1a51db8d108303b9fe7b",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A theorem describing how fixed-weight recurrent neural networks can approximate adaptive-weight learning algorithms is proved. The theorem applies to most networks and learning algorithms currently in use. It is concluded from the theorem that a system which exhibits learning behavior may exhibit no synaptic weight modifications. This idea is demonstrated by transforming a backward error propagation network into a fixed-weight system"
            },
            "slug": "Fixed-weight-networks-can-learn-Cotter-Conwell",
            "title": {
                "fragments": [],
                "text": "Fixed-weight networks can learn"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is concluded from the theorem that a system which exhibits learning behavior may exhibit no synaptic weight modifications, and it is demonstrated by transforming a backward error propagation network into a fixed-weight system."
            },
            "venue": {
                "fragments": [],
                "text": "1990 IJCNN International Joint Conference on Neural Networks"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145727186"
                        ],
                        "name": "R. Caruana",
                        "slug": "R.-Caruana",
                        "structuredName": {
                            "firstName": "Rich",
                            "lastName": "Caruana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Caruana"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 97
                            }
                        ],
                        "text": "The use of previous learning experiences in inductive reasoning is known as \u201cknowledge transfer\u201d [4,1,14] or \u201cinductive bias shifts\u201d [15,6,12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9667898,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "210da45e57f86a50c04bdd7b37d498c8ecc288da",
            "isKey": false,
            "numCitedBy": 255,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Hinton [6] proposed that generalization in artificial neural nets should improve if nets learn to represent the domain's underlying regularities. Abu-Mustafa's hints work [1] shows that the outputs of a backprop net can be used as inputs through which domain-specific information can be given to the net. We extend these ideas by showing that a backprop net learning many related tasks at the same time can use these tasks as inductive bias for each other and thus learn better. We identify five mechanisms by which multitask backprop improves generalization and give empirical evidence that multitask backprop generalizes better in real domains."
            },
            "slug": "Learning-Many-Related-Tasks-at-the-Same-Time-with-Caruana",
            "title": {
                "fragments": [],
                "text": "Learning Many Related Tasks at the Same Time with Backpropagation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work shows that a backprop net learning many related tasks at the same time can use these tasks as inductive bias for each other and thus learn better and give empirical evidence that multitask backprop generalizes better in real domains."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308557"
                        ],
                        "name": "S. Hochreiter",
                        "slug": "S.-Hochreiter",
                        "structuredName": {
                            "firstName": "Sepp",
                            "lastName": "Hochreiter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hochreiter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 65
                            }
                        ],
                        "text": "In the same section, the use of the Long Short-Term Memory (LSTM [8]) architecture is suggested to achieve better results."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 76
                            }
                        ],
                        "text": "An architecture fulfilling this requirement is Long Short-Term Memory (LSTM [8])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 33
                            }
                        ],
                        "text": "(C) Long Short-Term Memory (LSTM [8]) with its corresponding learning procedure."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1915014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44d2abe2175df8153f465f6c39b68b76a0d40ab9",
            "isKey": false,
            "numCitedBy": 52390,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms."
            },
            "slug": "Long-Short-Term-Memory-Hochreiter-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Long Short-Term Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel, efficient, gradient based method called long short-term memory (LSTM) is introduced, which can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055652031"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "Juergen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110117732"
                        ],
                        "name": "Jieyu Zhao",
                        "slug": "Jieyu-Zhao",
                        "structuredName": {
                            "firstName": "Jieyu",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jieyu Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32239759"
                        ],
                        "name": "M. Wiering",
                        "slug": "M.-Wiering",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Wiering",
                            "middleNames": [
                                "A"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wiering"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 63
                            }
                        ],
                        "text": "Meta-learning is known in the reinforcement learning framework [11,12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 131
                            }
                        ],
                        "text": "In the research field of \u201cknowledge transfer\u201d we focus on one of the most appealing topics: \u201cmeta-learning\u201d or \u201clearning to learn\u201d [4,14,13,11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14099817,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7986fc1c9026180468023f3dcc1d7c5f6379b8f",
            "isKey": false,
            "numCitedBy": 79,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of metalearning is to generate useful shifts of inductive bias by adapting the current learning strategy in a ``useful'''' way. Our learner leads a single life during which actions are continually executed according to the system''s internal state and current {\\em policy} (a modifiable, probabilistic algorithm mapping environmental inputs and internal states to outputs and new internal states). An action is considered a learning algorithm if it can modify the policy. Effects of learning processes on later learning processes are measured using reward/time ratios. Occasional backtracking enforces success histories of still valid policy modifications corresponding to histories of lifelong reward accelerations. The principle allows for plugging in a wide variety of learning algorithms. In particular, it allows for embedding the learner''s policy modification strategy within the policy itself (self-reference). To demonstrate the principle''s feasibility in cases where conventional reinforcement learning fails, we test it in complex, non-Markovian, changing environments (``POMDPs''''). One of the tasks involves more than $10^{13}$ states, two learners that both cooperate and compete, and strongly delayed reinforcement signals (initially separated by more than 300,000 time steps)."
            },
            "slug": "Simple-Principles-of-Metalearning-Schmidhuber-Zhao",
            "title": {
                "fragments": [],
                "text": "Simple Principles of Metalearning"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The metalearning principle allows for embedding the learner''s policy modification strategy within the policy itself (self-reference) and is tested in complex, non-Markovian, changing environments (``POMDPs'')."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144867807"
                        ],
                        "name": "S. Thrun",
                        "slug": "S.-Thrun",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Thrun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Thrun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144442133"
                        ],
                        "name": "L. Pratt",
                        "slug": "L.-Pratt",
                        "structuredName": {
                            "firstName": "Lorien",
                            "lastName": "Pratt",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Pratt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 29136678,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ec5540f6da71eb79a18bbcacb48b8ea847cad120",
            "isKey": false,
            "numCitedBy": 794,
            "numCiting": 259,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface. Part I: Overview Articles. 1. Learning to Learn: Introduction and Overview S. Thrun, L. Pratt. 2. A Survey of Connectionist Network Reuse Through Transfer L. Pratt, B. Jennings. 3. Transfer in Cognition A. Robins. Part II: Prediction. 4. Theoretical Models of Learning to Learn J. Baxter. 5. Multitask Learning R. Caruana. 6. Making a Low-Dimensional Representation Suitable for Diverse Tasks N. Intrator, S. Edelman. 7. The Canonical Distortion Measure for Vector Quantization and Function Approximation J. Baxter. 8. Lifelong Learning Algorithms S. Thrun. Part III: Relatedness. 9. The Parallel Transfer of Task Knowledge Using Dynamic Learning Rates Based on a Measure of Relatedness D.L. Silver, R.E. Mercer. 10. Clustering Learning Tasks and the Selective Cross-Task Transfer of Knowledge S. Thrun, J. O'Sullivan. Part IV: Control. 11. CHILD: A First Step Towards Continual Learning M.B. Ring. 12. Reinforcement Learning with Self-Modifying Policies J. Schmidhuber, et al. 13. Creating Advice-Taking Reinforcement Learners R. Maclin, J.W. Shavlik. Contributing Authors. Index."
            },
            "slug": "Learning-to-Learn-Thrun-Pratt",
            "title": {
                "fragments": [],
                "text": "Learning to Learn"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This chapter discusses Reinforcement Learning with Self-Modifying Policies J. Schmidhuber, et al., and theoretical Models of Learning to Learn J. Baxter, a first step towards Continual Learning."
            },
            "venue": {
                "fragments": [],
                "text": "Springer US"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733689"
                        ],
                        "name": "D. Haussler",
                        "slug": "D.-Haussler",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Haussler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Haussler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 133
                            }
                        ],
                        "text": "The use of previous learning experiences in inductive reasoning is known as \u201cknowledge transfer\u201d [4,1,14] or \u201cinductive bias shifts\u201d [15,6,12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 27204621,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3b814ad3055d6bfd7828effdbfbf1372646b7c22",
            "isKey": false,
            "numCitedBy": 551,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Quantifying-Inductive-Bias:-AI-Learning-Algorithms-Haussler",
            "title": {
                "fragments": [],
                "text": "Quantifying Inductive Bias: AI Learning Algorithms and Valiant's Learning Framework"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2884373"
                        ],
                        "name": "J. Elman",
                        "slug": "J.-Elman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Elman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Elman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 65
                            }
                        ],
                        "text": "B14 Experiments We compared following methods: (A) Elman network [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2763403,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "668087f0ae7ce1de6e0bd0965dbb480c08103260",
            "isKey": false,
            "numCitedBy": 9891,
            "numCiting": 111,
            "paperAbstract": {
                "fragments": [],
                "text": "Time underlies many interesting human behaviors. Thus, the question of how to represent time in connectionist models is very important. One approach is to represent time implicitly by its effects on processing rather than explicitly (as in a spatial representation). The current report develops a proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory. In this approach, hidden unit patterns are fed back to themselves; the internal representations which develop thus reflect task demands in the context of prior internal states. A set of simulations is reported which range from relatively simple problems (temporal version of XOR) to discovering syntactic/semantic features for words. The networks are able to learn interesting internal representations which incorporate task demands with memory demands; indeed, in this approach the notion of memory is inextricably bound up with task processing. These representations reveal a rich structure, which allows them to be highly context-dependent while also expressing generalizations across classes of items. These representations suggest a method for representing lexical categories and the type/token distinction."
            },
            "slug": "Finding-Structure-in-Time-Elman",
            "title": {
                "fragments": [],
                "text": "Finding Structure in Time"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory and suggests a method for representing lexical categories and the type/token distinction is developed."
            },
            "venue": {
                "fragments": [],
                "text": "Cogn. Sci."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2195972"
                        ],
                        "name": "P. Utgoff",
                        "slug": "P.-Utgoff",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Utgoff",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Utgoff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 133
                            }
                        ],
                        "text": "The use of previous learning experiences in inductive reasoning is known as \u201cknowledge transfer\u201d [4,1,14] or \u201cinductive bias shifts\u201d [15,6,12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61047266,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "f5157391985e1b8b451461f3350e9f91e697b76f",
            "isKey": false,
            "numCitedBy": 377,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We identify and examine the fundamental role that bias plays in inductive concept learning. Bias is the set of all influences, procedural or declarative, that causes a concept learner to prefer one hypothesis to another. Much of the success of concept learning programs to date results from the program's author having provided the learning program with appropriate bias. To date there has been no good mechanical method for shifting from one bias to another that is better. Instead, the author of a learning program has himself had to search for a better bias. The program author manually generates a bias, from scratch or by revising a previous bias, and then tests it in his program. If the author is not satisfied with the induced concepts, then he repeats the manual-generate and program-test cycle. If the author is satisfied, then he deems his program successful. Too often, he does not recognize his own role in the learning process. \nOur thesis is that search for appropriate bias is itself a major part of the learning task, and that we can create mechanical procedures for conducting a well-directed search for an appropriate bias. We would like to understand better how a program author goes about doing his search for appropriate bias. What insights does he have? What does he learn when he observes that a particular bias produces poor performance? What domain knowledge does he apply? \nWe explore the problem of mechanizing the search for appropriate bias. To that end, we develop a framework for a procedure that shifts bias. We then build two instantiations of the procedure in a program called STABB, which we then incorporate in the LEX learning program. One, called \"least disjunction\", uses simple syntactic manipulation, and the other, called \"constraint back propagation\" uses analytic deduction. We report experiments with the implementations that both demonstrate the usefulness of the framework, and uncover important issues for this kind of learning."
            },
            "slug": "Shift-of-bias-for-inductive-concept-learning-Utgoff",
            "title": {
                "fragments": [],
                "text": "Shift of bias for inductive concept learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that search for appropriate bias is itself a major part of the learning task, and that mechanical procedures for conducting a well-directed search for an appropriate bias can be created."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32309850"
                        ],
                        "name": "G. Salomon",
                        "slug": "G.-Salomon",
                        "structuredName": {
                            "firstName": "Gavriel",
                            "lastName": "Salomon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Salomon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 97
                            }
                        ],
                        "text": "The use of previous learning experiences in inductive reasoning is known as \u201cknowledge transfer\u201d [4,1,14] or \u201cinductive bias shifts\u201d [15,6,12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 131
                            }
                        ],
                        "text": "In the research field of \u201cknowledge transfer\u201d we focus on one of the most appealing topics: \u201cmeta-learning\u201d or \u201clearning to learn\u201d [4,14,13,11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18201927,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "fb86245e6623502017940c796c01ed508c3d8208",
            "isKey": false,
            "numCitedBy": 1814,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Transfer of learning occurs when learning in one context enhances (positive transfer) or undermines (negative transfer) a related performance in another context. Transfer includes near transfer (to closely related contexts and performances) and far transfer (to rather different contexts and performances). Transfer is crucial to education, which generally aspires to impact on contexts quite different from the context of learning. Research on transfer argues that very often transfer does not occur, especially ``far'' transfer. However, sometimes far transfer does occur. Findings from various sources suggest that transfer happens by way of two rather different mechanisms. Reflexive or low road transfer involves the triggering of well-practiced routines by stimulus conditions similar to those in the learning context. Mindful or high road transfer involves deliberate effortful abstraction and a search for connections. Conventional educational practices often fail to establish the conditions either for reflexive or mindful transfer. However, education can be designed to honor these conditions and achieve transfer."
            },
            "slug": "Transfer-of-Learning-Salomon",
            "title": {
                "fragments": [],
                "text": "Transfer of Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Findings from various sources suggest that transfer happens by way of two rather different mechanisms, and conventional educational practices often fail to establish the conditions either for reflexive or mindful transfer."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 97
                            }
                        ],
                        "text": "The use of previous learning experiences in inductive reasoning is known as \u201cknowledge transfer\u201d [4,1,14] or \u201cinductive bias shifts\u201d [15,6,12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 131
                            }
                        ],
                        "text": "In the research field of \u201cknowledge transfer\u201d we focus on one of the most appealing topics: \u201cmeta-learning\u201d or \u201clearning to learn\u201d [4,14,13,11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 208784962,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ff65ac698013cdd9d61326cab49a1d75404e001",
            "isKey": false,
            "numCitedBy": 18494,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Editors",
            "title": {
                "fragments": [],
                "text": "Editors"
            },
            "venue": {
                "fragments": [],
                "text": "Brain Research Bulletin"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895771"
                        ],
                        "name": "D. Zipser",
                        "slug": "D.-Zipser",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Zipser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zipser"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 105
                            }
                        ],
                        "text": "(B) Recurrent network with fully recurrent hidden layer trained with Back Propagation Through Time (BPTT [18,16]) truncated after 2 time steps and with Real Time Recurrent Learning (RTRL [9,17])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 62
                            }
                        ],
                        "text": "One may choose for example backpropagation through time (BPTT [18,16]) or real-time recurrent learning (RTRL [9,17]) as attendant learning algorithms."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14792754,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10dae7fca6b65b61d155a622f0c6ca2bc3922251",
            "isKey": false,
            "numCitedBy": 570,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Gradient-based-learning-algorithms-for-recurrent-Williams-Zipser",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning algorithms for recurrent networks and their computational complexity"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 131
                            }
                        ],
                        "text": "In the research field of \u201cknowledge transfer\u201d we focus on one of the most appealing topics: \u201cmeta-learning\u201d or \u201clearning to learn\u201d [4,14,13,11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evolutionary principles in self-referential learning, or on learning how to learn: The meta-meta-."
            },
            "venue": {
                "fragments": [],
                "text": "hook. Inst. fu\u0308r Inf., Tech. Univ. Mu\u0308nchen,"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 187
                            }
                        ],
                        "text": "(B) Recurrent network with fully recurrent hidden layer trained with Back Propagation Through Time (BPTT [18,16]) truncated after 2 time steps and with Real Time Recurrent Learning (RTRL [9,17])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 109
                            }
                        ],
                        "text": "One may choose for example backpropagation through time (BPTT [18,16]) or real-time recurrent learning (RTRL [9,17]) as attendant learning algorithms."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The utility driven dynamic error propagation network"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report CUED/F-INFENG/TR.1, Camb. Uni. Eng. Dep.,"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 187
                            }
                        ],
                        "text": "(B) Recurrent network with fully recurrent hidden layer trained with Back Propagation Through Time (BPTT [18,16]) truncated after 2 time steps and with Real Time Recurrent Learning (RTRL [9,17])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 109
                            }
                        ],
                        "text": "One may choose for example backpropagation through time (BPTT [18,16]) or real-time recurrent learning (RTRL [9,17]) as attendant learning algorithms."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A learning algorithm for continually running fully recurrent networks"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report ICS 8805, Univ. of Cal., La Jolla,"
            },
            "year": 1988
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 14,
            "methodology": 9
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 19,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Learning-to-Learn-Using-Gradient-Descent-Hochreiter-Younger/044b2c29e0a54dc689786bd4d029b9ba6e355d58?sort=total-citations"
}