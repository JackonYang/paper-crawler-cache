{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47800062"
                        ],
                        "name": "M. Baskaran",
                        "slug": "M.-Baskaran",
                        "structuredName": {
                            "firstName": "Muthu",
                            "lastName": "Baskaran",
                            "middleNames": [
                                "Manikandan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Baskaran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145981817"
                        ],
                        "name": "J. Ramanujam",
                        "slug": "J.-Ramanujam",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Ramanujam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ramanujam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145293384"
                        ],
                        "name": "P. Sadayappan",
                        "slug": "P.-Sadayappan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Sadayappan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sadayappan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 21
                            }
                        ],
                        "text": "We focus on C-toCUDA [Baskaran et al. 2010] and Par4All [HPC Project 2012] because of the availability of their source code."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 21
                            }
                        ],
                        "text": "Baskaran\u2019s C-to-CUDA [Baskaran et al. 2010] is the first end-to-end, automatic source-to-source polyhedral compiler for GPU targets."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 23
                            }
                        ],
                        "text": "We focus \non C-to-CUDA [Baskaran et al. 2010] and Par4All [HPC Project 2012] because of the availability of their \nsource code."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 22
                            }
                        ],
                        "text": "Baskaran s C-to-CUDA [Baskaran et al. 2010] is the .rst end-to-end, automatic source-to-source \npolyhedral compiler for GPU targets."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18075016,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbe0f0b3e2d60c4f96d9d84f97dc8a9be4f72802",
            "isKey": true,
            "numCitedBy": 238,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Graphics Processing Units (GPUs) offer tremendous computational power. CUDA (Compute Unified Device Architecture) provides a multi-threaded parallel programming model, facilitating high performance implementations of general-purpose computations. However, the explicitly managed memory hierarchy and multi-level parallel view make manual development of high-performance CUDA code rather complicated. Hence the automatic transformation of sequential input programs into efficient parallel CUDA programs is of considerable interest. \n \nThis paper describes an automatic code transformation system that generates parallel CUDA code from input sequential C code, for regular (affine) programs. Using and adapting publicly available tools that have made polyhedral compiler optimization practically effective, we develop a C-to-CUDA transformation system that generates two-level parallel CUDA code that is optimized for efficient data access. The performance of automatically generated code is compared with manually optimized CUDA code for a number of benchmarks. The performance of the automatically generated CUDA code is quite close to hand-optimized CUDA code and considerably better than the benchmarks' performance on a multicore CPU."
            },
            "slug": "Automatic-C-to-CUDA-Code-Generation-for-Affine-Baskaran-Ramanujam",
            "title": {
                "fragments": [],
                "text": "Automatic C-to-CUDA Code Generation for Affine Programs"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An automatic code transformation system that generates parallel CUDA code from input sequential C code, for regular (affine) programs, that is quite close to hand-optimizedCUDA code and considerably better than the benchmarks' performance on a multicore CPU."
            },
            "venue": {
                "fragments": [],
                "text": "CC"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9426225"
                        ],
                        "name": "M. Amini",
                        "slug": "M.-Amini",
                        "structuredName": {
                            "firstName": "Mehdi",
                            "lastName": "Amini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Amini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51030319"
                        ],
                        "name": "F. Coelho",
                        "slug": "F.-Coelho",
                        "structuredName": {
                            "firstName": "Fabien",
                            "lastName": "Coelho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Coelho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2912411"
                        ],
                        "name": "F. Irigoin",
                        "slug": "F.-Irigoin",
                        "structuredName": {
                            "firstName": "Fran\u00e7ois",
                            "lastName": "Irigoin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Irigoin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2621820"
                        ],
                        "name": "Ronan Keryell",
                        "slug": "Ronan-Keryell",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Keryell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Keryell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 27
                            }
                        ],
                        "text": "Par4All [HPC Project \n2012; Amini et al. 2011] is an open-source initiative developed by the HPC Project to unify efforts concerning \ncompilers for parallel architectures."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 8
                            }
                        ],
                        "text": "Par4All [HPC Project 2012; Amini et al. 2011] is an open-source initiative developed by the HPC Project to unify efforts concerning compilers for parallel architectures."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18008164,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a2a24d5c824e48a42b4b06b0958a09474bca3d32",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an automatic, static program transformation that schedules and generates efficient memory transfers between a computer host and its hardware accelerator, addressing a well-known performance bottleneck. Our automatic approach uses two simple heuristics: to perform transfers to the accelerator as early as possible and to delay transfers back from the accelerator as late as possible. We implemented this transformation as a middle-end compilation pass in the pips /Par4All compiler. In the generated code, redundant communications due to data reuse between kernel executions are avoided. Instructions that initiate transfers are scheduled effectively at compile-time. We present experimental results obtained with the Polybench 2.0, some Rodinia benchmarks, and with a real numerical simulation. We obtain an average speedup of 4 to 5 when compared to a naive parallelization using a modern gpu with Par4All , hmpp , and pgi , and 3.5 when compared to an OpenMP version using a 12-core multiprocessor."
            },
            "slug": "Static-Compilation-Analysis-for-Host-Accelerator-Amini-Coelho",
            "title": {
                "fragments": [],
                "text": "Static Compilation Analysis for Host-Accelerator Communication Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "An automatic, static program transformation that schedules and generates efficient memory transfers between a computer host and its hardware accelerator, addressing a well-known performance bottleneck is presented."
            },
            "venue": {
                "fragments": [],
                "text": "LCPC"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751936"
                        ],
                        "name": "Uday Bondhugula",
                        "slug": "Uday-Bondhugula",
                        "structuredName": {
                            "firstName": "Uday",
                            "lastName": "Bondhugula",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Uday Bondhugula"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763408"
                        ],
                        "name": "Albert Hartono",
                        "slug": "Albert-Hartono",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Hartono",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Albert Hartono"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145981817"
                        ],
                        "name": "J. Ramanujam",
                        "slug": "J.-Ramanujam",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Ramanujam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ramanujam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145293384"
                        ],
                        "name": "P. Sadayappan",
                        "slug": "P.-Sadayappan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Sadayappan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sadayappan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", for computing the affine functions Si, we refer to [Bondhugula et al. 2008a]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 103
                            }
                        ],
                        "text": "Many efforts have been invested to develop source-to-source \ncompilers such as PoCC [PoCC 2012], Pluto [Bondhugula et al. 2008b], and CHiLL [Chen et al. 2008], which \nuse a polyhedral framework to perform loop transformations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The polyhedral model has been the basis for major advances in automatic optimization and parallelization of programs [Boulet et al. 1998; Feautrier 1992a; Feautrier 1992b; Lim 2001; Bondhugula et al. 2008a]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 103
                            }
                        ],
                        "text": "The generation of the schedule in both C-to-CUDA and PPCG is based \non the algorithm proposed in Pluto [Bondhugula et al. 2008b; Bondhugula 2012], although they currently \nevolve independently."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 195
                            }
                        ],
                        "text": "Polyhedral Compilation The polyhedral model has been the basis \nfor major advances in automatic optimization and parallelization of programs [Boulet et al. 1998; Feautrier \n1992a, 1992b; Lim 2001; Bondhugula et al. 2008a]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7086982,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f0f4757aa2f923a349e8357e73850a78e9b80fee",
            "isKey": true,
            "numCitedBy": 860,
            "numCiting": 71,
            "paperAbstract": {
                "fragments": [],
                "text": "We present the design and implementation of an automatic polyhedral source-to-source transformation framework that can optimize regular programs (sequences of possibly imperfectly nested loops) for parallelism and locality simultaneously. Through this work, we show the practicality of analytical model-driven automatic transformation in the polyhedral model -- far beyond what is possible by current production compilers. Unlike previous works, our approach is an end-to-end fully automatic one driven by an integer linear optimization framework that takes an explicit view of finding good ways of tiling for parallelism and locality using affine transformations. The framework has been implemented into a tool to automatically generate OpenMP parallel code from C program sections. Experimental results from the tool show very high speedups for local and parallel execution on multi-cores over state-of-the-art compiler frameworks from the research community as well as the best native production compilers. The system also enables the easy use of powerful empirical/iterative optimization for general arbitrarily nested loop sequences."
            },
            "slug": "A-practical-automatic-polyhedral-parallelizer-and-Bondhugula-Hartono",
            "title": {
                "fragments": [],
                "text": "A practical automatic polyhedral parallelizer and locality optimizer"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "An automatic polyhedral source-to-source transformation framework that can optimize regular programs for parallelism and locality simultaneously simultaneously and is implemented into a tool to automatically generate OpenMP parallel code from C program sections."
            },
            "venue": {
                "fragments": [],
                "text": "PLDI '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744256"
                        ],
                        "name": "Pierre Boulet",
                        "slug": "Pierre-Boulet",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Boulet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierre Boulet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733001"
                        ],
                        "name": "A. Darte",
                        "slug": "A.-Darte",
                        "structuredName": {
                            "firstName": "Alain",
                            "lastName": "Darte",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Darte"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2192711"
                        ],
                        "name": "Georges-Andr\u00e9 Silber",
                        "slug": "Georges-Andr\u00e9-Silber",
                        "structuredName": {
                            "firstName": "Georges-Andr\u00e9",
                            "lastName": "Silber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Georges-Andr\u00e9 Silber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41070781"
                        ],
                        "name": "F. Vivien",
                        "slug": "F.-Vivien",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Vivien",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Vivien"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7804781,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f1206999e216f9622dcc42ab548434361c3cef73",
            "isKey": false,
            "numCitedBy": 97,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Loop-Parallelization-Algorithms:-From-Parallelism-Boulet-Darte",
            "title": {
                "fragments": [],
                "text": "Loop Parallelization Algorithms: From Parallelism Extraction to Code Generation"
            },
            "venue": {
                "fragments": [],
                "text": "Parallel Comput."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144417793"
                        ],
                        "name": "Allen Leung",
                        "slug": "Allen-Leung",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Leung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Allen Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800919"
                        ],
                        "name": "Nicolas Vasilache",
                        "slug": "Nicolas-Vasilache",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Vasilache",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Vasilache"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35104370"
                        ],
                        "name": "Beno\u00eet Meister",
                        "slug": "Beno\u00eet-Meister",
                        "structuredName": {
                            "firstName": "Beno\u00eet",
                            "lastName": "Meister",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Beno\u00eet Meister"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47800062"
                        ],
                        "name": "M. Baskaran",
                        "slug": "M.-Baskaran",
                        "structuredName": {
                            "firstName": "Muthu",
                            "lastName": "Baskaran",
                            "middleNames": [
                                "Manikandan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Baskaran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2375921"
                        ],
                        "name": "David Wohlford",
                        "slug": "David-Wohlford",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Wohlford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Wohlford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769333"
                        ],
                        "name": "C. Bastoul",
                        "slug": "C.-Bastoul",
                        "structuredName": {
                            "firstName": "C\u00e9dric",
                            "lastName": "Bastoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bastoul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802881"
                        ],
                        "name": "R. Lethin",
                        "slug": "R.-Lethin",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Lethin",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lethin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1750218,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8a953487418417586bd256bbe298979b828d267",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Programmers for GPGPU face rapidly changing substrate of programming abstractions, execution models, and hardware implementations. It has been established, through numerous demonstrations for particular conjunctions of application kernel, programming languages, and GPU hardware instance, that it is possible to achieve significant improvements in the price/performance and energy/performance over general purpose processors. But these demonstrations are each the result of significant dedicated programmer labor, which is likely to be duplicated for each new GPU hardware architecture to achieve performance portability.\n This paper discusses the implementation, in the R-Stream compiler, of a source to source mapping pathway from a high-level, textbook-style algorithm expression method in ANSI C, to multi-GPGPU accelerated computers. The compiler performs hierarchical decomposition and parallelization of the algorithm between and across host, multiple GPGPUs, and within-GPU. The semantic transformations are expressed within the polyhedral model, including optimization of integrated parallelization, locality, and contiguity tradeoffs. Hierarchical tiling is performed. Communication and synchronizations operations at multiple levels are generated automatically. The resulting mapping is currently emitted in the CUDA programming language.\n The GPU backend adds to the range of hardware and accelerator targets for R-Stream and indicates the potential for performance portability of single sources across multiple hardware targets."
            },
            "slug": "A-mapping-path-for-multi-GPGPU-accelerated-from-a-Leung-Vasilache",
            "title": {
                "fragments": [],
                "text": "A mapping path for multi-GPGPU accelerated computers from a portable high level programming abstraction"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper discusses the implementation, in the R-Stream compiler, of a source to source mapping pathway from a high-level, textbook-style algorithm expression method in ANSI C, to multi-GPGPU accelerated computers."
            },
            "venue": {
                "fragments": [],
                "text": "GPGPU-3"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108701347"
                        ],
                        "name": "Seyong Lee",
                        "slug": "Seyong-Lee",
                        "structuredName": {
                            "firstName": "Seyong",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Seyong Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3025470"
                        ],
                        "name": "Seung-Jai Min",
                        "slug": "Seung-Jai-Min",
                        "structuredName": {
                            "firstName": "Seung-Jai",
                            "lastName": "Min",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Seung-Jai Min"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727592"
                        ],
                        "name": "R. Eigenmann",
                        "slug": "R.-Eigenmann",
                        "structuredName": {
                            "firstName": "Rudolf",
                            "lastName": "Eigenmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Eigenmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 103
                            }
                        ],
                        "text": "In parallel, in the OpenMPC project, the Cetus compiler framework was used to translate OpenMP to CUDA [Lee et al. 2009]; unlike current polyhedral compilers, it can handle dynamic, data-dependent control flow."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 104
                            }
                        ],
                        "text": "In parallel, in \nthe OpenMPC project, the Cetus compiler framework was used to translate OpenMP to CUDA [Lee et al. 2009]; \nunlike current polyhedral compilers, it can handle dynamic, data-dependent control .ow."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14985688,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "271be72b0c57686a3e77d0f794ef08db1b39a28f",
            "isKey": false,
            "numCitedBy": 490,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "GPGPUs have recently emerged as powerful vehicles for general-purpose high-performance computing. Although a new Compute Unified Device Architecture (CUDA) programming model from NVIDIA offers improved programmability for general computing, programming GPGPUs is still complex and error-prone. This paper presents a compiler framework for automatic source-to-source translation of standard OpenMP applications into CUDA-based GPGPU applications. The goal of this translation is to further improve programmability and make existing OpenMP applications amenable to execution on GPGPUs. In this paper, we have identified several key transformation techniques, which enable efficient GPU global memory access, to achieve high performance. Experimental results from two important kernels (JACOBI and SPMUL) and two NAS OpenMP Parallel Benchmarks (EP and CG) show that the described translator and compile-time optimizations work well on both regular and irregular applications, leading to performance improvements of up to 50X over the unoptimized translation (up to 328X over serial)."
            },
            "slug": "OpenMP-to-GPGPU:-a-compiler-framework-for-automatic-Lee-Min",
            "title": {
                "fragments": [],
                "text": "OpenMP to GPGPU: a compiler framework for automatic translation and optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper presents a compiler framework for automatic source-to-source translation of standard OpenMP applications into CUDA-based GPGPU applications, and identifies several key transformation techniques, which enable efficient GPU global memory access, to achieve high performance."
            },
            "venue": {
                "fragments": [],
                "text": "PPoPP '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682108"
                        ],
                        "name": "M. Lam",
                        "slug": "M.-Lam",
                        "structuredName": {
                            "firstName": "Monica",
                            "lastName": "Lam",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "28513548"
                        ],
                        "name": "Amy W. Lim",
                        "slug": "Amy-W.-Lim",
                        "structuredName": {
                            "firstName": "Amy",
                            "lastName": "Lim",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amy W. Lim"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58729313,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "255849a9cee9ff81c0ece58f4038c06e959c8cb5",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "To effectively harness the power of modern parallel machines, it is important to find parallelism that does not incur high synchronization cost between the processors. Effective utilization of the memory hierarchy is another crucial factor in getting high performance. In the past, a large number of compiler algorithms have been proposed in the areas of finding loop-level parallelism and improving data locality. Many of these algorithms rely on ad hoc techniques to select a series of transformations. Others attempt to place a number of transformations in a single framework to avoid ad hoc selections. Unfortunately, frameworks proposed so far are either limited to perfectly nested loops or they lack algorithms to select the best possible transformations in the frameworks. \nThis dissertation proposes a new transformation framework for the program domain of arbitrary loop structures with affine array accesses and loop bounds. This framework unifies a large class of transformations, including loop interchange, reversal, skewing, fusion, fission, reindexing, scaling, and statement reordering. In this framework, each statement is given its own affine mapping describing the partition of its dynamic instances to different processors or to different sequential steps. Two algorithms, one for parallelization and one for locality optimization, were developed under this framework and can be easily combined. \nThe parallelization algorithm derives from data dependence constraints the affine mappings that maximize the degree of parallelism with the least amount of synchronization. The degree of parallelism found by the algorithm is optimal with respect to all the unified transformations. The algorithm also minimizes communication by trading off excess degrees of parallelism and by choosing pipeline parallelism over doall parallelism if it can significantly reduce communication cost. Optimizing memory performance in a single processor, the locality algorithm performs aggressive affine transformations to separate the independent threads in a program and if possible, place statements with data reuse into perfectly nested loops. These transformations also have the benefits of enabling blocking and array contraction to be applied across arbitrarily nested loops."
            },
            "slug": "Improving-parallelism-and-data-locality-with-affine-Lam-Lim",
            "title": {
                "fragments": [],
                "text": "Improving parallelism and data locality with affine partitioning"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This dissertation proposes a new transformation framework for the program domain of arbitrary loop structures with affine array accesses and loop bounds that unifies a large class of transformations, including loop interchange, reversal, skewing, fusion, fission, reindexing, scaling, and statement reordering."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38769180"
                        ],
                        "name": "Sain-Zee Ueng",
                        "slug": "Sain-Zee-Ueng",
                        "structuredName": {
                            "firstName": "Sain-Zee",
                            "lastName": "Ueng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sain-Zee Ueng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2273003"
                        ],
                        "name": "Melvin Lathara",
                        "slug": "Melvin-Lathara",
                        "structuredName": {
                            "firstName": "Melvin",
                            "lastName": "Lathara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Melvin Lathara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2292813"
                        ],
                        "name": "Sara S. Baghsorkhi",
                        "slug": "Sara-S.-Baghsorkhi",
                        "structuredName": {
                            "firstName": "Sara",
                            "lastName": "Baghsorkhi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sara S. Baghsorkhi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143668320"
                        ],
                        "name": "W. Hwu",
                        "slug": "W.-Hwu",
                        "structuredName": {
                            "firstName": "Wen-mei",
                            "lastName": "Hwu",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hwu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "CUDA-lite [Ueng et al. 2008] started a trend to achieve better performance portability on CUDA programs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 30
                            }
                        ],
                        "text": "Programming Models CUDA-lite [Ueng et al. \n2008] started a trend to achieve better performance portability on CUDA programs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15331404,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "27d82ffffb15ad376009c5769e8c974c24607f3a",
            "isKey": false,
            "numCitedBy": 256,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "The computer industry has transitioned into multi-core and many-core parallel systems. The CUDA programming environment from NVIDIA is an attempt to make programming many-core GPUs more accessible to programmers. However, there are still many burdens placed upon the programmer to maximize performance when using CUDA. One such burden is dealing with the complex memory hierarchy. Efficient and correct usage of the various memories is essential, making a difference of 2-17x in performance. Currently, the task of determining the appropriate memory to use and the coding of data transfer between memories is still left to the programmer. We believe that this task can be better performed by automated tools. We present CUDA-lite, an enhancement to CUDA, as one such tool. We leverage programmer knowledge via annotations to perform transformations and show preliminary results that indicate auto-generated code can have performance comparable to hand coding."
            },
            "slug": "CUDA-Lite:-Reducing-GPU-Programming-Complexity-Ueng-Lathara",
            "title": {
                "fragments": [],
                "text": "CUDA-Lite: Reducing GPU Programming Complexity"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The present CUDA-lite, an enhancement to CUDA, is presented and preliminary results that indicate auto-generated code can have performance comparable to hand coding are shown."
            },
            "venue": {
                "fragments": [],
                "text": "LCPC"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2810599"
                        ],
                        "name": "Shane Ryoo",
                        "slug": "Shane-Ryoo",
                        "structuredName": {
                            "firstName": "Shane",
                            "lastName": "Ryoo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shane Ryoo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2012705"
                        ],
                        "name": "C. Rodrigues",
                        "slug": "C.-Rodrigues",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Rodrigues",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rodrigues"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40113841"
                        ],
                        "name": "S. S. Stone",
                        "slug": "S.-S.-Stone",
                        "structuredName": {
                            "firstName": "Sam",
                            "lastName": "Stone",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. S. Stone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2292813"
                        ],
                        "name": "Sara S. Baghsorkhi",
                        "slug": "Sara-S.-Baghsorkhi",
                        "structuredName": {
                            "firstName": "Sara",
                            "lastName": "Baghsorkhi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sara S. Baghsorkhi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38769180"
                        ],
                        "name": "Sain-Zee Ueng",
                        "slug": "Sain-Zee-Ueng",
                        "structuredName": {
                            "firstName": "Sain-Zee",
                            "lastName": "Ueng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sain-Zee Ueng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1773596"
                        ],
                        "name": "J. Stratton",
                        "slug": "J.-Stratton",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Stratton",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Stratton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143668320"
                        ],
                        "name": "W. Hwu",
                        "slug": "W.-Hwu",
                        "structuredName": {
                            "firstName": "Wen-mei",
                            "lastName": "Hwu",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hwu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 185
                            }
                        ],
                        "text": "have shown that the optimization space for CUDA programs can be highly non-linear, and highly challenging for model-based heuristics, performance modeling, or feedback-directed methods [Ryoo et al. 2008b; Ryoo et al. 2008a]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 197
                            }
                        ],
                        "text": "Ryoo et al. \nhave shown that the optimization space for CUDA programs can be highly nonlinear, and highly challenging \nfor model-based heuristics, performance mod\u00adeling, or feedback-directed methods [Ryoo et al. 2008a, 2008b]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12382528,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41bff2e236e73c5c9b21f8660856f58bba46aaf5",
            "isKey": false,
            "numCitedBy": 300,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Program optimization for highly-parallel systems has historically been considered an art, with experts doing much of the performance tuning by hand. With the introduction of inexpensive, single-chip, massively parallel platforms, more developers will be creating highly-parallel applications for these platforms, who lack the substantial experience and knowledge needed to maximize their performance. This creates a need for more structured optimization methods with means to estimate their performance effects. Furthermore these methods need to be understandable by most programmers. This paper shows the complexity involved in optimizing applications for one such system and one relatively simple methodology for reducing the workload involved in the optimization process.\n This work is based on one such highly-parallel system, the GeForce 8800 GTX using CUDA. Its flexible allocation of resources to threads allows it to extract performance from a range of applications with varying resource requirements, but places new demands on developers who seek to maximize an application's performance. We show how optimizations interact with the architecture in complex ways, initially prompting an inspection of the entire configuration space to find the optimal configuration. Even for a seemingly simple application such as matrix multiplication, the optimal configuration can be unexpected. We then present metrics derived from static code that capture the first-order factors of performance. We demonstrate how these metrics can be used to prune many optimization configurations, down to those that lie on a Pareto-optimal curve. This reduces the optimization space by as much as 98% and still finds the optimal configuration for each of the studied applications."
            },
            "slug": "Program-optimization-space-pruning-for-a-gpu-Ryoo-Rodrigues",
            "title": {
                "fragments": [],
                "text": "Program optimization space pruning for a multithreaded gpu"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The complexity involved in optimizing applications for one highly-parallel system and one relatively simple methodology for reducing the workload involved in the optimization process are shown."
            },
            "venue": {
                "fragments": [],
                "text": "CGO '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108701347"
                        ],
                        "name": "Seyong Lee",
                        "slug": "Seyong-Lee",
                        "structuredName": {
                            "firstName": "Seyong",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Seyong Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727592"
                        ],
                        "name": "R. Eigenmann",
                        "slug": "R.-Eigenmann",
                        "structuredName": {
                            "firstName": "Rudolf",
                            "lastName": "Eigenmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Eigenmann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18512872,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15f67796899118508cc3021df0f88faf2298bd45",
            "isKey": false,
            "numCitedBy": 238,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "General-Purpose Graphics Processing Units (GPGPUs) are promising parallel platforms for high performance computing. The CUDA (Compute Unified Device Architecture) programming model provides improved programmability for general computing on GPGPUs. However, its unique execution model and memory model still pose significant challenges for developers of efficient GPGPU code. This paper proposes a new programming interface, called OpenMPC, which builds on OpenMP to provide an abstraction of the complex CUDA programming model and offers high-level controls of the involved parameters and optimizations. We have developed a fully automatic compilation and user-assisted tuning system supporting OpenMPC. In addition to a range of compiler transformations and optimizations, the system includes tuning capabilities for generating, pruning, and navigating the search space of compilation variants. Our results demonstrate that OpenMPC offers both programmability and tunability. Our system achieves 88% of the performance of the hand-coded CUDA programs."
            },
            "slug": "OpenMPC:-Extended-OpenMP-Programming-and-Tuning-for-Lee-Eigenmann",
            "title": {
                "fragments": [],
                "text": "OpenMPC: Extended OpenMP Programming and Tuning for GPUs"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper has developed a fully automatic compilation and user-assisted tuning system supporting OpenMPC, which builds on OpenMP to provide an abstraction of the complex CUDA programming model and offers high-level controls of the involved parameters and optimizations."
            },
            "venue": {
                "fragments": [],
                "text": "2010 ACM/IEEE International Conference for High Performance Computing, Networking, Storage and Analysis"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056153534"
                        ],
                        "name": "Soufiane Baghdadi",
                        "slug": "Soufiane-Baghdadi",
                        "structuredName": {
                            "firstName": "Soufiane",
                            "lastName": "Baghdadi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Soufiane Baghdadi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "115089566"
                        ],
                        "name": "Armin Grosslinger",
                        "slug": "Armin-Grosslinger",
                        "structuredName": {
                            "firstName": "Armin",
                            "lastName": "Grosslinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Armin Grosslinger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145509576"
                        ],
                        "name": "Albert Cohen",
                        "slug": "Albert-Cohen",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Albert Cohen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11667417,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f363f702eb613ca4d3df010e3e5cca5cafbfe32",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Universita\u00a8t Passau, Fakulta\u00a8t fu\u00a8r Informatik und Mathem atikarmin.groesslinger@uni-passau.deAbstract. Automatic parallelization is becoming more important as pa rallelismbecomes ubiquitous. The rst step for achieving automation is to develop a the-oretical foundation, for example, the polyhedron model. Th e second step is toimplement the algorithms studied in the theoretical framew ork and getting themto work in a compiler that can be used to parallelize real code s.The polyhedral model is a well-established theoretical fou ndation for paralleliz-ing codes with static control. In this paper, we present, fro m a practical pointof view, the challenges to solve for getting polyhedral comp ilation for GPUs towork. We choose the Polyhedral Compiler Collection (PoCC)a s compiler infras-tructure and target CUDA as the target platform; we plan to su pport OpenCL inthe future."
            },
            "slug": "Putting-Automatic-Polyhedral-Compilation-for-GPGPU-Baghdadi-Grosslinger",
            "title": {
                "fragments": [],
                "text": "Putting Automatic Polyhedral Compilation for GPGPU to Work"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The challenges to solve for getting polyhedral comp ilation for GPUs to work in a compiler that can be used to parallelize real code s and the Polyhedral Compiler Collection (PoCC) is chosen."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109525543"
                        ],
                        "name": "Chun Chen",
                        "slug": "Chun-Chen",
                        "structuredName": {
                            "firstName": "Chun",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chun Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772362"
                        ],
                        "name": "Jacqueline Chame",
                        "slug": "Jacqueline-Chame",
                        "structuredName": {
                            "firstName": "Jacqueline",
                            "lastName": "Chame",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jacqueline Chame"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143896454"
                        ],
                        "name": "Mary W. Hall",
                        "slug": "Mary-W.-Hall",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Hall",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mary W. Hall"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 115
                            }
                        ],
                        "text": "Progress towards fully automatic performance tuning has been achieved by the Crest [Unkule et al. 2012] \nand CHiLL [Chen et al. 2008] projects."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 124
                            }
                        ],
                        "text": "Unfortunately we were unable to obtain a copy of Reservoir Labs R-Stream [Leung \net al. 2010; Vasilache et al. 2012] or CUDA-CHiLL [Rudy et al. 2011] to provide a deeper assessment of \nthese tools capabilities."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 140
                            }
                        ],
                        "text": "Many efforts have been invested to develop source-to-source \ncompilers such as PoCC [PoCC 2012], Pluto [Bondhugula et al. 2008b], and CHiLL [Chen et al. 2008], which \nuse a polyhedral framework to perform loop transformations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 4
                            }
                        ],
                        "text": "The CHiLL developers also extended their compiler to generate GPU code; \nthey introduced CUDA-CHiLL [Rudy et al. 2011], which does not perform an automatic parallelization and \nmapping to CUDA but instead offers high-level constructs that allow a user or search engine to perform \nsuch a transformation."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 18
                            }
                        ],
                        "text": "2008b], and CHiLL [Chen et al. 2008], which use a polyhedral framework to perform loop transformations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15619135,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a4620589f63f3385707d2d590f7b7dc8ee4d74f",
            "isKey": true,
            "numCitedBy": 198,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a general and robust loop transformation framework that enables compilers to generate efficient code on complex loop nests. Despite two decades of prior research on loop optimization, performance of compiler-generated code often falls short of manually optimized versions, even for some well-studied BLAS kernels. There are two primary reasons for this. First, today\u2019s compilers employ fixed transformation strategies, making it difficult to adapt to different optimization requirements for different application codes. Second, code transformations are treated in isolation, not taking into account the interactions between different transformations. This paper addresses such limitations in a unified framework that supports a broad collection of transformations, (permutation, tiling, unroll-and-jam, data copying, iteration space splitting, fusion, distribution and others), which go beyond existing polyhedral transformation models. This framework is a key element of a compiler we are developing which performs empirical optimization to evaluate a collection of alternative optimized variants of a code segment. A script interface to code generation and empirical search permits transformation parameters to be adjusted independently and tested; alternative scripts are used to represent different code variants. By applying this framework to example codes, we show performance results on automaticallygenerated code for the Pentium M and MIPS R10000 that are comparable to the best hand-tuned codes, and significantly better (up to a 14x speedup) than the native compilers."
            },
            "slug": "CHiLL-:-A-Framework-for-Composing-High-Level-Loop-Chen-Chame",
            "title": {
                "fragments": [],
                "text": "CHiLL : A Framework for Composing High-Level Loop Transformations"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A general and robust loop transformation framework that enables compilers to generate efficient code on complex loop nests and shows performance results on automaticallygenerated code for the Pentium M and MIPS R10000 that are comparable to the best hand-tuned codes, and significantly better than the native compilers."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751936"
                        ],
                        "name": "Uday Bondhugula",
                        "slug": "Uday-Bondhugula",
                        "structuredName": {
                            "firstName": "Uday",
                            "lastName": "Bondhugula",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Uday Bondhugula"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145981817"
                        ],
                        "name": "J. Ramanujam",
                        "slug": "J.-Ramanujam",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Ramanujam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ramanujam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145293384"
                        ],
                        "name": "P. Sadayappan",
                        "slug": "P.-Sadayappan",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Sadayappan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sadayappan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 394227,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ec11e8ce6cb4d5e699de7992f6566fcc1f9ebad1",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 88,
            "paperAbstract": {
                "fragments": [],
                "text": "We present the design and implementation of a fully automatic polyhedral source-to-source transformation framework that can optimize regular programs (sequences of possibly imperfectly nested loops) for parallelism and locality simultaneously. Through this work, we show the practicality of analytical model-driven automatic transformation in the polyhedral model \u2010 far beyond what is possible by current production compilers. Unlike previous works, our approach is an end-to-end fully automatic one driven by an integer linear optimization framework that takes an explicit view of finding good ways of tiling for parallelism and locality using affine transformations. We also address generation of tiled code for multiple statement domains of arbitrary dimensionalities under (statement-wise) affine transformations \u2010 an issue that has not been addressed previously. Experimental results from the implemented system show very high speedups for local and parallel execution on multi-cores over state-of-the-art compiler frameworks from the research community as well as the best native compilers. The system also enables the easy use of powerful empirical/iterative optimization for general arbitrarily nested loop sequences. 1. Introduction and Motivation"
            },
            "slug": "PLuTo:-A-Practical-and-Fully-Automatic-Polyhedral-Bondhugula-Ramanujam",
            "title": {
                "fragments": [],
                "text": "PLuTo: A Practical and Fully Automatic Polyhedral Program Optimization System"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A fully automatic polyhedral source-to-source transformation framework that can optimize regular programs for parallelism and locality simultaneously simultaneously and addresses generation of tiled code for multiple statement domains of arbitrary dimensionalities under (statement-wise) affine transformations."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756389"
                        ],
                        "name": "T. Grosser",
                        "slug": "T.-Grosser",
                        "structuredName": {
                            "firstName": "Tobias",
                            "lastName": "Grosser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Grosser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3281029"
                        ],
                        "name": "Hongbin Zheng",
                        "slug": "Hongbin-Zheng",
                        "structuredName": {
                            "firstName": "Hongbin",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hongbin Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2216401"
                        ],
                        "name": "Raghesh Aloor",
                        "slug": "Raghesh-Aloor",
                        "structuredName": {
                            "firstName": "Raghesh",
                            "lastName": "Aloor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raghesh Aloor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2260870"
                        ],
                        "name": "Andreas Simburger",
                        "slug": "Andreas-Simburger",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Simburger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Simburger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "115089566"
                        ],
                        "name": "Armin Grosslinger",
                        "slug": "Armin-Grosslinger",
                        "structuredName": {
                            "firstName": "Armin",
                            "lastName": "Grosslinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Armin Grosslinger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793611"
                        ],
                        "name": "L. Pouchet",
                        "slug": "L.-Pouchet",
                        "structuredName": {
                            "firstName": "Louis-No\u00ebl",
                            "lastName": "Pouchet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Pouchet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10258844,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "58ef44a34ef69b880964b0e3527374e8fa8b10c4",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Various powerful polyhedral techniques exist to optimize computation intensive programs effectively. Applying these techniques on any non-trivial program is still surprisingly difficult and often not as effective as expected. Most polyhedral tools are limited to a specific programming language. Even for this language, relevant code needs to match specific syntax that rarely appears in existing code. It is therefore hard or even impossible to process existing programs automatically. In addition, most tools target C or OpenCL code, which prevents effective communication with compiler internal optimizers. As a result target architecture specific optimizations are either little effective or not approached at all. In this paper we present Polly, a project to enable polyhedral optimizations in LLVM. Polly automatically detects and transforms relevant program parts in a language-independent and syntactically transparent way. Therefore, it supports programs written in most common programming languages and constructs like C++ iterators, goto based loops and pointer arithmetic. Internally it provides a state-of-the-art polyhedral library with full support for Z-polyhedra, advanced data dependency analysis and support for external optimizers. Polly includes integrated SIMD and OpenMP code generation. Through LLVM, machine code for CPUs and GPU accelerators, C source code and even hardware descriptions can be targeted."
            },
            "slug": "Polly-\u2013-Polyhedral-optimization-in-LLVM-Grosser-Zheng",
            "title": {
                "fragments": [],
                "text": "Polly \u2013 Polyhedral optimization in LLVM"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Polly is presented, a project to enable polyhedral optimizations in LLVM that automatically detects and transforms relevant program parts in a language-independent and syntactically transparent way and supports programs written in most common programming languages and constructs."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2810599"
                        ],
                        "name": "Shane Ryoo",
                        "slug": "Shane-Ryoo",
                        "structuredName": {
                            "firstName": "Shane",
                            "lastName": "Ryoo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shane Ryoo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2012705"
                        ],
                        "name": "C. Rodrigues",
                        "slug": "C.-Rodrigues",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Rodrigues",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rodrigues"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2292813"
                        ],
                        "name": "Sara S. Baghsorkhi",
                        "slug": "Sara-S.-Baghsorkhi",
                        "structuredName": {
                            "firstName": "Sara",
                            "lastName": "Baghsorkhi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sara S. Baghsorkhi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40113841"
                        ],
                        "name": "S. S. Stone",
                        "slug": "S.-S.-Stone",
                        "structuredName": {
                            "firstName": "Sam",
                            "lastName": "Stone",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. S. Stone"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2491805"
                        ],
                        "name": "D. Kirk",
                        "slug": "D.-Kirk",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Kirk",
                            "middleNames": [
                                "Blair"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kirk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143668320"
                        ],
                        "name": "W. Hwu",
                        "slug": "W.-Hwu",
                        "structuredName": {
                            "firstName": "Wen-mei",
                            "lastName": "Hwu",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hwu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 185
                            }
                        ],
                        "text": "have shown that the optimization space for CUDA programs can be highly non-linear, and highly challenging for model-based heuristics, performance modeling, or feedback-directed methods [Ryoo et al. 2008b; Ryoo et al. 2008a]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 197
                            }
                        ],
                        "text": "Ryoo et al. \nhave shown that the optimization space for CUDA programs can be highly nonlinear, and highly challenging \nfor model-based heuristics, performance mod\u00adeling, or feedback-directed methods [Ryoo et al. 2008a, 2008b]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15383162,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3bd2467087d06c4b5fc258c30ca5fae90c8bf7d8",
            "isKey": false,
            "numCitedBy": 978,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "GPUs have recently attracted the attention of many application developers as commodity data-parallel coprocessors. The newest generations of GPU architecture provide easier programmability and increased generality while maintaining the tremendous memory bandwidth and computational power of traditional GPUs. This opportunity should redirect efforts in GPGPU research from ad hoc porting of applications to establishing principles and strategies that allow efficient mapping of computation to graphics hardware. In this work we discuss the GeForce 8800 GTX processor's organization, features, and generalized optimization strategies. Key to performance on this platform is using massive multithreading to utilize the large number of cores and hide global memory latency. To achieve this, developers face the challenge of striking the right balance between each thread's resource usage and the number of simultaneously active threads. The resources to manage include the number of registers and the amount of on-chip memory used per thread, number of threads per multiprocessor, and global memory bandwidth. We also obtain increased performance by reordering accesses to off-chip memory to combine requests to the same or contiguous memory locations and apply classical optimizations to reduce the number of executed operations. We apply these strategies across a variety of applications and domains and achieve between a 10.5X to 457X speedup in kernel codes and between 1.16X to 431X total application speedup."
            },
            "slug": "Optimization-principles-and-application-performance-Ryoo-Rodrigues",
            "title": {
                "fragments": [],
                "text": "Optimization principles and application performance evaluation of a multithreaded GPU using CUDA"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work discusses the GeForce 8800 GTX processor's organization, features, and generalized optimization strategies, and achieves increased performance by reordering accesses to off-chip memory to combine requests to the same or contiguous memory locations and apply classical optimizations to reduce the number of executed operations."
            },
            "venue": {
                "fragments": [],
                "text": "PPOPP"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2639817"
                        ],
                        "name": "Swapneela Unkule",
                        "slug": "Swapneela-Unkule",
                        "structuredName": {
                            "firstName": "Swapneela",
                            "lastName": "Unkule",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Swapneela Unkule"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2770601"
                        ],
                        "name": "Christopher Shaltz",
                        "slug": "Christopher-Shaltz",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Shaltz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Shaltz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721526"
                        ],
                        "name": "A. Qasem",
                        "slug": "A.-Qasem",
                        "structuredName": {
                            "firstName": "Apan",
                            "lastName": "Qasem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Qasem"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Progress towards fully automatic performance tuning have been achieved by the Crest [Unkule et al. 2012] and CHiLL [Chen et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 84
                            }
                        ],
                        "text": "Progress towards fully automatic performance tuning has been achieved by the Crest [Unkule et al. 2012] \nand CHiLL [Chen et al. 2008] projects."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18930291,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6b4197133776010760e0882c401ab39f203d3dbf",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Hundreds of cores per chip and support for fine-grain multithreading have made GPUs a central player in today's HPC world. For many applications, however, achieving a high fraction of peak on current GPUs, still requires significant programmer effort. A key consideration for optimizing GPU code is determining a suitable amount of work to be performed by each thread. Thread granularity not only has a direct impact on occupancy but can also influence data locality at the register and shared-memory levels. This paper describes a software framework to analyze dependencies in parallel GPU threads and perform source-level restructuring to obtain GPU kernels with varying thread granularity. The framework supports specification of coarsening factors through source-code annotation and also implements a heuristic based on estimated register pressure that automatically recommends coarsening factors for improved memory performance. We present preliminary experimental results on a select set of CUDA kernels. The results show that the proposed strategy is generally able to select profitable coarsening factors. More importantly, the results demonstrate a clear need for automatic control of thread granularity at the software level for achieving higher performance."
            },
            "slug": "Automatic-Restructuring-of-GPU-Kernels-for-Data-Unkule-Shaltz",
            "title": {
                "fragments": [],
                "text": "Automatic Restructuring of GPU Kernels for Exploiting Inter-thread Data Locality"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A software framework to analyze dependencies in parallel GPU threads and perform source-level restructuring to obtain GPU kernels with varying thread granularity is described and a heuristic based on estimated register pressure that automatically recommends coarsening factors for improved memory performance is implemented."
            },
            "venue": {
                "fragments": [],
                "text": "CC"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1838186"
                        ],
                        "name": "P. Feautrier",
                        "slug": "P.-Feautrier",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Feautrier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Feautrier"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The dependence relation can be obtained using standard techniques [Feautrier 1991] and in the example of Section 4, we obtain"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 67
                            }
                        ],
                        "text": "The dependence \nrelation can be obtained using standard techniques [Feautrier 1991] and in the example of Section 4, \nwe obtain {S1(i, j) ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5738544,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7cd685371e267a499ded869a934a4cffed591aec",
            "isKey": false,
            "numCitedBy": 454,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a program written in a simple imperative language (assignment statements,for loops, affine indices and loop limits), this paper presents an algorithm for analyzing the patterns along which values flow as the execution proceeds. For each array or scalar reference, the result is the name and iteration vector of the source statement as a function of the iteration vector of the referencing statement. The paper discusses several applications of the method: conversion of a program to a set of recurrence equations, array and scalar expansion, program verification and parallel program construction."
            },
            "slug": "Dataflow-analysis-of-array-and-scalar-references-Feautrier",
            "title": {
                "fragments": [],
                "text": "Dataflow analysis of array and scalar references"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This paper presents an algorithm for analyzing the patterns along which values flow as the execution proceeds, and discusses several applications of the method: conversion of a program to a set of recurrence equations, array and scalar expansion, program verification and parallel program construction."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Parallel Programming"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111108147"
                        ],
                        "name": "Jaewook Shin",
                        "slug": "Jaewook-Shin",
                        "structuredName": {
                            "firstName": "Jaewook",
                            "lastName": "Shin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jaewook Shin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772362"
                        ],
                        "name": "Jacqueline Chame",
                        "slug": "Jacqueline-Chame",
                        "structuredName": {
                            "firstName": "Jacqueline",
                            "lastName": "Chame",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jacqueline Chame"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143896454"
                        ],
                        "name": "Mary W. Hall",
                        "slug": "Mary-W.-Hall",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Hall",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mary W. Hall"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 72
                            }
                        ],
                        "text": "Realignment and data-reuse were considered together with loop-unrolling [Shin et al. 2002] in the context of straight-line code vectorization."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 73
                            }
                        ],
                        "text": "Realignment and data reuse were considered together with loop-unrolling \n[Shin et al. 2002] in the context of straight-line code vectorization."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10725600,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "91d2ed195e16a782e9f78862679143ee96798804",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe an algorithm and implementation of locality optimizations for architectures with instruction sets such as Intel's SSE and Motorola's AltiVec that support operations on superwords, i.e., aggregate objects consisting of several machine words. We treat the large superword register file as a compiler-controlled cache, thus avoiding unnecessary memory accesses by exploiting reuse in superword registers. This research is distinguished from previous work on exploiting reuse in scalar registers because it considers not only temporal but also spatial reuse. As compared to optimizations to exploit reuse in cache, the compiler must also manage replacement, and thus, explicitly name registers in the generated code. We describe an implementation of our approach integrated with a compiler that exploits superword-level parallelism (SLP). We present a set of results derived automatically on 4 multimedia kernels and 2 scientific benchmarks. Our results show speedups ranging from 1.3 to 2.8X on the 6 programs as compared to using SLP alone, and we eliminate the majority of memory accesses."
            },
            "slug": "Compiler-controlled-caching-in-superword-register-Shin-Chame",
            "title": {
                "fragments": [],
                "text": "Compiler-controlled caching in superword register files for multimedia extension architectures"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "An algorithm and implementation of locality optimizations for architectures with instruction sets that support operations on superwords, i.e., aggregate objects consisting of several machine words that treats the large superword register file as a compiler-controlled cache, thus avoiding unnecessary memory accesses by exploiting reuse in superword registers."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings.International Conference on Parallel Architectures and Compilation Techniques"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144616193"
                        ],
                        "name": "R. Allen",
                        "slug": "R.-Allen",
                        "structuredName": {
                            "firstName": "Randy",
                            "lastName": "Allen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Allen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70455556"
                        ],
                        "name": "K. Kennedy",
                        "slug": "K.-Kennedy",
                        "structuredName": {
                            "firstName": "Ken",
                            "lastName": "Kennedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kennedy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 43779902,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9dc9f86fb3116acf723f4404dcdf279fe322f01f",
            "isKey": false,
            "numCitedBy": 1104,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Modern computer architectures designed with high-performance microprocessors offer tremendous potential gains in performance over previous designs. Yet their very complexity makes it increasingly difficult to produce efficient code and to realize their full potential. This landmark text from two leaders in the field focuses on the pivotal role that compilers can play in addressing this critical issue. The basis for all the methods presented in this book is data dependence, a fundamental compiler analysis tool for optimizing programs on high-performance microprocessors and parallel architectures. It enables compiler designers to write compilers that automatically transform simple, sequential programs into forms that can exploit special features of these modern architectures. The text provides a broad introduction to data dependence, to the many transformation strategies it supports, and to its applications to important optimization problems such as parallelization, compiler memory hierarchy management, and instruction scheduling. The authors demonstrate the importance and wide applicability of dependence-based compiler optimizations and give the compiler writer the basics needed to understand and implement them. They also offer cookbook explanations for transforming applications by hand to computational scientists and engineers who are driven to obtain the best possible performance of their complex applications."
            },
            "slug": "Optimizing-Compilers-for-Modern-Architectures:-A-Allen-Kennedy",
            "title": {
                "fragments": [],
                "text": "Optimizing Compilers for Modern Architectures: A Dependence-based Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A broad introduction to data dependence, to the many transformation strategies it supports, and to its applications to important optimization problems such as parallelization, compiler memory hierarchy management, and instruction scheduling are provided."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800919"
                        ],
                        "name": "Nicolas Vasilache",
                        "slug": "Nicolas-Vasilache",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Vasilache",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Vasilache"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35104370"
                        ],
                        "name": "Beno\u00eet Meister",
                        "slug": "Beno\u00eet-Meister",
                        "structuredName": {
                            "firstName": "Beno\u00eet",
                            "lastName": "Meister",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Beno\u00eet Meister"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47800062"
                        ],
                        "name": "M. Baskaran",
                        "slug": "M.-Baskaran",
                        "structuredName": {
                            "firstName": "Muthu",
                            "lastName": "Baskaran",
                            "middleNames": [
                                "Manikandan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Baskaran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802881"
                        ],
                        "name": "R. Lethin",
                        "slug": "R.-Lethin",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Lethin",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lethin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13384652,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c76671c478130ee4cd1600ff0f51807ed6e8d4b9",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a novel loop nest scheduling strategy implemented in the R-Stream compiler 1 : the first scheduling formulation to jointly optimize a trade-off between parallelism, locality, contiguity of array accesses and data layout permutations in a single complete formulation. Our search space contains the maximal amount of vectorization in the program and automatically finds opportunities for automatic multi-level vectorization and simd-ization. Using our model of memory layout, we demonstrate that the amount of contiguous accesses, vectorization and simd-ization can be increased modulo data layout permutations automatically exposed by our technique. This additional degree of freedom opens new opportunities for the scheduler that were previously out of reach. But perhaps the most significant aspect of this work is to encompass an ever increasing number of traditional optimization phases into a single pass. Our approach offers a good solution to the fundamental problem of phase ordering of high-level loop transformations."
            },
            "slug": "Joint-Scheduling-and-Layout-Optimization-to-Enable-Vasilache-Meister",
            "title": {
                "fragments": [],
                "text": "Joint Scheduling and Layout Optimization to Enable Multi-Level Vectorization"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This work describes a novel loop nest scheduling strategy implemented in the R-Stream compiler, the first scheduling formulation to jointly optimize a trade-off between parallelism, locality, contiguity of array accesses and data layout permutations in a single complete formulation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755190"
                        ],
                        "name": "Dorit Nuzman",
                        "slug": "Dorit-Nuzman",
                        "structuredName": {
                            "firstName": "Dorit",
                            "lastName": "Nuzman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dorit Nuzman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153090846"
                        ],
                        "name": "Ira Rosen",
                        "slug": "Ira-Rosen",
                        "structuredName": {
                            "firstName": "Ira",
                            "lastName": "Rosen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ira Rosen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38737579"
                        ],
                        "name": "A. Zaks",
                        "slug": "A.-Zaks",
                        "structuredName": {
                            "firstName": "Ayal",
                            "lastName": "Zaks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zaks"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 81
                            }
                        ],
                        "text": "A cost model for vectorization of accesses with non-unit strides was proposed in [Nuzman et al. 2006], but it does not consider other overheads or loop transformations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 94
                            }
                        ],
                        "text": "All of these works had a successful impact on \nproduction compilers [Wu et al. 2005; Bik 2004; Nuzman et al. 2006; Nuzman and Zaks 2008]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 67
                            }
                        ],
                        "text": "All of these works had a successful impact on production compilers [Wu et al. 2005; Bik 2004; Nuzman et al. 2006; Nuzman and Zaks 2008]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12024793,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be8a25f7e7bf82415f86f26babbe3283349f8d74",
            "isKey": false,
            "numCitedBy": 186,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "Most implementations of the Single Instruction Multiple Data (SIMD) model available today require that data elements be packed in vector registers. Operations on disjoint vector elements are not supported directly and require explicit data reorganization manipulations. Computations on non-contiguous and especially interleaved data appear in important applications, which can greatly benefit from SIMD instructions once the data is reorganized properly. Vectorizing such computations efficiently is therefore an ambitious challenge for both programmers and vectorizing compilers. We demonstrate an automatic compilation scheme that supports effective vectorization in the presence of interleaved data with constant strides that are powers of 2, facilitating data reorganization. We demonstrate how our vectorization scheme applies to dominant SIMD architectures, and present experimental results on a wide range of key kernels, showing speedups in execution time up to 3.7 for interleaving levels (stride) as high as 8."
            },
            "slug": "Auto-vectorization-of-interleaved-data-for-SIMD-Nuzman-Rosen",
            "title": {
                "fragments": [],
                "text": "Auto-vectorization of interleaved data for SIMD"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work demonstrates an automatic compilation scheme that supports effective vectorization in the presence of interleaved data with constant strides that are powers of 2, facilitating data reorganization."
            },
            "venue": {
                "fragments": [],
                "text": "PLDI '06"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056756233"
                        ],
                        "name": "Pete Cooper",
                        "slug": "Pete-Cooper",
                        "structuredName": {
                            "firstName": "Pete",
                            "lastName": "Cooper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pete Cooper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3096365"
                        ],
                        "name": "Uwe Dolinsky",
                        "slug": "Uwe-Dolinsky",
                        "structuredName": {
                            "firstName": "Uwe",
                            "lastName": "Dolinsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Uwe Dolinsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734519"
                        ],
                        "name": "A. Donaldson",
                        "slug": "A.-Donaldson",
                        "structuredName": {
                            "firstName": "Alastair",
                            "lastName": "Donaldson",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Donaldson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144292174"
                        ],
                        "name": "Andrew Richards",
                        "slug": "Andrew-Richards",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Richards",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Richards"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053231625"
                        ],
                        "name": "C. Riley",
                        "slug": "C.-Riley",
                        "structuredName": {
                            "firstName": "Colin",
                            "lastName": "Riley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Riley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054310494"
                        ],
                        "name": "G. Russell",
                        "slug": "G.-Russell",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Russell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Russell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Offload [Cooper et al. 2010] is a set of high-level C++ extensions, a compiler and a runtime system to accelerate kernels on the Cell BE."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 8
                            }
                        ],
                        "text": "Of.oad [Cooper et al. \n2010] is a set of high-level C++ extensions, a compiler and a runtime system to accelerate kernels on \nthe Cell BE."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12293292,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fb194862d9ec12cee7f881eaa3ba9e21de564412",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "We present Offload, a programming model for offloading parts of a C++ application to run on accelerator cores in a heterogeneous multicore system. Code to be offloaded is enclosed in an offload scope; all functions called indirectly from an offload scope are compiled for the accelerator cores. Data defined inside/outside an offload scope resides in accelerator/host memory respectively, and code to move data between memory spaces is generated automatically by the compiler. This is achieved by distinguishing between host and accelerator pointers at the type level, and compiling multiple versions of functions based on pointer parameter configurations using automatic call-graph duplication. We discuss solutions to several challenging issues related to call-graph duplication, and present an implementation of Offload for the Cell BE processor, evaluated using a number of benchmarks."
            },
            "slug": "Offload-Automating-Code-Migration-to-Heterogeneous-Cooper-Dolinsky",
            "title": {
                "fragments": [],
                "text": "Offload - Automating Code Migration to Heterogeneous Multicore Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "Offload, a programming model for offloading parts of a C++ application to run on accelerator cores in a heterogeneous multicore system, is presented and solutions to several challenging issues related to call-graph duplication are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "HiPEAC"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145167085"
                        ],
                        "name": "R. Ferrer",
                        "slug": "R.-Ferrer",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Ferrer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ferrer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782004402"
                        ],
                        "name": "Vicencc Beltran",
                        "slug": "Vicencc-Beltran",
                        "structuredName": {
                            "firstName": "Vicencc",
                            "lastName": "Beltran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vicencc Beltran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11149867"
                        ],
                        "name": "Marc Gonz\u00e1lez",
                        "slug": "Marc-Gonz\u00e1lez",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Gonz\u00e1lez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc Gonz\u00e1lez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767107"
                        ],
                        "name": "X. Martorell",
                        "slug": "X.-Martorell",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Martorell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Martorell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744495"
                        ],
                        "name": "E. Ayguad\u00e9",
                        "slug": "E.-Ayguad\u00e9",
                        "structuredName": {
                            "firstName": "Eduard",
                            "lastName": "Ayguad\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Ayguad\u00e9"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18860046,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4cc4e09922ba53ba48503dedc2b4e05dc59030f",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "As an answer to the forthcoming heterogeneous multicore and accelerator\u2013based architectures, we have proposed some syntactic extensions to C in the form of C pragmas, based on OpenMP, that make easier for programmers to offload parts of their applications to the auxiliary processors. Offloaded tasks can be made more profitable using a simple blocking strategy. And the runtime system is used to better support computation and communication overlap, while moving data to and from accelerators. \n \nIn order to prove the feasibility and usefulness of our proposal, we have considered the IBM Cell architecture. The performance of the whole system has been evaluated using HPCC STREAM Triad and several NAS benchmarks. We present their evaluation and a detailed performance breakdown at the level of parallel regions. We also classify the parallel regions according to their suitability to be exploited in accelerators. Overall, our performance is better compared to the results obtained from the IBM compiler for the Cell processor."
            },
            "slug": "Analysis-of-Task-Offloading-for-Accelerators-Ferrer-Beltran",
            "title": {
                "fragments": [],
                "text": "Analysis of Task Offloading for Accelerators"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "Some syntactic extensions to C in the form of C pragmas, based on OpenMP, that make easier for programmers to offload parts of their applications to the auxiliary processors that are better compared to the results obtained from the IBM compiler for the Cell processor are proposed."
            },
            "venue": {
                "fragments": [],
                "text": "HiPEAC"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48648812"
                        ],
                        "name": "Mohamed-Walid Benabderrahmane",
                        "slug": "Mohamed-Walid-Benabderrahmane",
                        "structuredName": {
                            "firstName": "Mohamed-Walid",
                            "lastName": "Benabderrahmane",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohamed-Walid Benabderrahmane"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793611"
                        ],
                        "name": "L. Pouchet",
                        "slug": "L.-Pouchet",
                        "structuredName": {
                            "firstName": "Louis-No\u00ebl",
                            "lastName": "Pouchet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Pouchet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145509576"
                        ],
                        "name": "Albert Cohen",
                        "slug": "Albert-Cohen",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Albert Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769333"
                        ],
                        "name": "C. Bastoul",
                        "slug": "C.-Bastoul",
                        "structuredName": {
                            "firstName": "C\u00e9dric",
                            "lastName": "Bastoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bastoul"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8032464,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a4672941d77499591c31ac8bd64d6039dfb8b0e1",
            "isKey": false,
            "numCitedBy": 217,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The polyhedral model is a powerful framework for automatic optimization and parallelization. It is based on an algebraic representation of programs, allowing to construct and search for complex sequences of optimizations. This model is now mature and reaches production compilers. The main limitation of the polyhedral model is known to be its restriction to statically predictable, loop-based program parts. This paper removes this limitation, allowing to operate on general data-dependent control-flow. We embed control and exit predicates as first-class citizens of the algebraic representation, from program analysis to code generation. Complementing previous (partial) attempts in this direction, our work concentrates on extending the code generation step and does not compromise the expressiveness of the model. We present experimental evidence that our extension is relevant for program optimization and parallelization, showing performance improvements on benchmarks that were thought to be out of reach of the polyhedral model."
            },
            "slug": "The-Polyhedral-Model-Is-More-Widely-Applicable-Than-Benabderrahmane-Pouchet",
            "title": {
                "fragments": [],
                "text": "The Polyhedral Model Is More Widely Applicable Than You Think"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work concentrates on extending the code generation step and does not compromise the expressiveness of the model, presenting experimental evidence that the extension is relevant for program optimization and parallelization, showing performance improvements on benchmarks that were thought to be out of reach of the polyhedral model."
            },
            "venue": {
                "fragments": [],
                "text": "CC"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708011"
                        ],
                        "name": "Armin Gr\u00f6\u00dflinger",
                        "slug": "Armin-Gr\u00f6\u00dflinger",
                        "structuredName": {
                            "firstName": "Armin",
                            "lastName": "Gr\u00f6\u00dflinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Armin Gr\u00f6\u00dflinger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16409022,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "907f552d1e2423cc5dcf20ab93dd6d361d3e594e",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Unlike desktop and server CPUs, special-purpose processors found in embedded systems and on graphics cards often do not have a cache memory which is managed automatically by hardware logic. Instead, they offer a so-called scratchpad memory which is fast like a cache but, unlike a cache, has to be managed explicitly, i.e., the burden of its efficient use is imposed on the software. We present a method for computing precisely which memory cells are reused due to temporal locality of a certain class of codes, namely codes which can be modelled in the well-known polyhedron model. We present some examples demonstrating the effectiveness of our method for scientific codes."
            },
            "slug": "Precise-Management-of-Scratchpad-Memories-for-Array-Gr\u00f6\u00dflinger",
            "title": {
                "fragments": [],
                "text": "Precise Management of Scratchpad Memories for Localising Array Accesses in Scientific Codes"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A method for computing precisely which memory cells are reused due to temporal locality of a certain class of codes, namely codes which can be modelled in the well-known polyhedron model is presented."
            },
            "venue": {
                "fragments": [],
                "text": "CC"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2341687"
                        ],
                        "name": "Lakshminarayanan Renganarayanan",
                        "slug": "Lakshminarayanan-Renganarayanan",
                        "structuredName": {
                            "firstName": "Lakshminarayanan",
                            "lastName": "Renganarayanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lakshminarayanan Renganarayanan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2209910"
                        ],
                        "name": "DaeGon Kim",
                        "slug": "DaeGon-Kim",
                        "structuredName": {
                            "firstName": "DaeGon",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "DaeGon Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747659"
                        ],
                        "name": "S. Rajopadhye",
                        "slug": "S.-Rajopadhye",
                        "structuredName": {
                            "firstName": "Sanjay",
                            "lastName": "Rajopadhye",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Rajopadhye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709408"
                        ],
                        "name": "M. Strout",
                        "slug": "M.-Strout",
                        "structuredName": {
                            "firstName": "Michelle",
                            "lastName": "Strout",
                            "middleNames": [
                                "Mills"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Strout"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We expect this overhead can be eliminated with the implementation of full-tile/partial-tile separation on the code generator [Renganarayanan et al. 2007]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 513727,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e52672b9c05cd7870fef0a87512b7c388ebe40c5",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Parameterized tiled loops-where the tile sizes are not fixed at compile time, but remain symbolic parameters until later--are quite useful for iterative compilers and \"auto-tuners\" that produce highly optimized libraries and codes. Tile size parameterization could also enable optimizations such as register tiling to become dynamic optimizations. Although it is easy to generate such loops for (hyper) rectangular iteration spaces tiled with (hyper) rectangular tiles, many important computations do not fall into this restricted domain. Parameterized tile code generation for the general case of convex iteration spaces being tiled by (hyper) rectangular tiles has in the past been solved with bounding box approaches or symbolic Fourier Motzkin approaches. However, both approaches have less than ideal code generation efficiency and resulting code quality. We present the theoretical foundations, implementation, and experimental validation of a simple, unified technique for generating parameterized tiled code. Our code generation efficiency is comparable to all existing code generation techniques including those for fixed tile sizes, and the resulting code is as efficient as, if not more than, all previous techniques. Thus the technique provides parameterized tiled loops for free! Our \"one-size-fits-all\" solution, which is available as open source software can be adapted for use in production compilers."
            },
            "slug": "Parameterized-tiled-loops-for-free-Renganarayanan-Kim",
            "title": {
                "fragments": [],
                "text": "Parameterized tiled loops for free"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The theoretical foundations, implementation, and experimental validation of a simple, unified technique for generating parameterized tiled code that is comparable to all existing code generation techniques including those for fixed tile sizes are presented and the resulting code is as efficient as, if not more than, all previous techniques."
            },
            "venue": {
                "fragments": [],
                "text": "PLDI '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772079"
                        ],
                        "name": "Sven Verdoolaege",
                        "slug": "Sven-Verdoolaege",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Verdoolaege",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sven Verdoolaege"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 67
                            }
                        ],
                        "text": "In PPCG, we \nuse a variation of this algorithm, implemented in isl [Verdoolaege 2010]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In PPCG, we use a variation of this algorithm, implemented in isl [Verdoolaege 2010]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 36
                            }
                        ],
                        "text": "The .nal code, \ngenerated using isl [Verdoolaege 2010], is shown in Figure 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The final code, generated using isl [Verdoolaege 2010], is shown in Figure 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9220965,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "1c5b15587e4034c97610b2017697ad1ea663a8fa",
            "isKey": false,
            "numCitedBy": 351,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "In compiler research, polytopes and related mathematical objects have been successfully used for several decades to represent and manipulate computer programs in an approach that has become known as the polyhedral model. The key insight is that the kernels of many compute-intensive applications are composed of loops with bounds that are affine combinations of symbolic constants and outer loop iterators. The iterations of a loop nest can then be represented as the integer points in a (parametric) polytope and manipulated as a whole, rather than as individual iterations. A similar reasoning holds for the elements of an array and for mappings between loop iterations and array elements."
            },
            "slug": "isl:-An-Integer-Set-Library-for-the-Polyhedral-Verdoolaege",
            "title": {
                "fragments": [],
                "text": "isl: An Integer Set Library for the Polyhedral Model"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "In compiler research, polytopes and related mathematical objects have been successfully used for several decades to represent and manipulate computer programs in an approach that has become known as the polyhedral model."
            },
            "venue": {
                "fragments": [],
                "text": "ICMS"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769333"
                        ],
                        "name": "C. Bastoul",
                        "slug": "C.-Bastoul",
                        "structuredName": {
                            "firstName": "C\u00e9dric",
                            "lastName": "Bastoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bastoul"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For the purpose of the present paper, our code generator is similar to CLooG [Bastoul 2004], except that it has support for nested code generations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 15
                            }
                        ],
                        "text": "In particular, CLooG was designed \nto take a complete schedule and generate a single piece of code."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 80
                            }
                        ],
                        "text": "For the purpose of the present article, our code generator is similar to CLooG \n[Bastoul 2004], except that it has support for nested code generations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7971227,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2f48fb9fd31390c56609f00510accf5c56f9f9b",
            "isKey": true,
            "numCitedBy": 518,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Many advances in automatic parallelization and optimization have been achieved through the polyhedral model. It has been extensively shown that this computational model provides convenient abstractions to reason about and apply program transformations. Nevertheless, the complexity of code generation has long been a deterrent for using polyhedral representation in optimizing compilers. First, code generators have a hard time coping with generated code size and control overhead that may spoil theoretical benefits achieved by the transformations. Second, this step is usually time consuming, hampering the integration of the polyhedral framework in production compilers or feedback-directed, iterative optimization schemes. Moreover, current code generation algorithms only cover a restrictive set of possible transformation functions. This paper discusses a general transformation framework able to deal with nonunimodular, noninvertible, nonintegral or even nonuniform functions. It presents several improvements to a state-of-the-art code generation algorithm. Two directions are explored: generated code size and code generator efficiency. Experimental evidence proves the ability of the improved method to handle real-life problems."
            },
            "slug": "Code-generation-in-the-polyhedral-model-is-easier-Bastoul",
            "title": {
                "fragments": [],
                "text": "Code generation in the polyhedral model is easier than you think"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A general transformation framework able to deal with nonunimodular, noninvertible, nonintegral or even nonuniform functions is discussed and several improvements to a state-of-the-art code generation algorithm are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 13th International Conference on Parallel Architecture and Compilation Techniques, 2004. PACT 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2759686"
                        ],
                        "name": "K. Trifunovic",
                        "slug": "K.-Trifunovic",
                        "structuredName": {
                            "firstName": "Konrad",
                            "lastName": "Trifunovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Trifunovic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755190"
                        ],
                        "name": "Dorit Nuzman",
                        "slug": "Dorit-Nuzman",
                        "structuredName": {
                            "firstName": "Dorit",
                            "lastName": "Nuzman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dorit Nuzman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145509576"
                        ],
                        "name": "Albert Cohen",
                        "slug": "Albert-Cohen",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Albert Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38737579"
                        ],
                        "name": "A. Zaks",
                        "slug": "A.-Zaks",
                        "structuredName": {
                            "firstName": "Ayal",
                            "lastName": "Zaks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zaks"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153090846"
                        ],
                        "name": "Ira Rosen",
                        "slug": "Ira-Rosen",
                        "structuredName": {
                            "firstName": "Ira",
                            "lastName": "Rosen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ira Rosen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 564675,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "db9f78176b27de866704536f44824f1d3af13402",
            "isKey": false,
            "numCitedBy": 115,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Optimizing compilers strive to construct efficient executables by applying sequences of transformations. Additional transformations are constantly being devised, with various mutual interactions among them, thereby exacerbating the notoriously difficult phase-ordering problem --- that of deciding which transformations to apply and in which order. Fortunately, new infrastructures such as the polyhedral compilation framework host a variety of transformations, facilitating the efficient exploration and configuration of multiple transformation sequences. Many powerful optimizations, however, remain external to the polyhedral framework, with potential mutual interactions that need to be considered. In this paper we examine the interactions between loop transformations of the polyhedral compilation framework and subsequent vectorization optimizations targeting fine-grain SIMD data-level parallelism. Automatic vectorization involves many low-level, target-specific considerations and transformations, which currently exclude it from being part of the polyhedral framework. In order to consider potential interactions among polyhedral loop transformations and vectorization, we first model the performance impact of the different loop transformations and vectorization strategies, and then show how this cost model can be integrated seamlessly into the polyhedral representation. This predictive modelling then facilitates efficient exploration and educated decision making on how to best apply various polyhedral loop transformations while considering the subsequent effects of different vectorization schemes. Our work demonstrates the feasibility and benefit of tuning the polyhedral model in the context of vectorization. Experimental results confirm that our model has accurate predictions, providing speedups of over 2 on average over traditional innermost-loop vectorization on PowerPC970 and Cell-SPU SIMD platforms."
            },
            "slug": "Polyhedral-Model-Guided-Loop-Nest-Trifunovic-Nuzman",
            "title": {
                "fragments": [],
                "text": "Polyhedral-Model Guided Loop-Nest Auto-Vectorization"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper examines the interactions between loop transformations of the polyhedral compilation framework and subsequent vectorization optimizations targeting fine-grain SIMD data-level parallelism, and demonstrates the feasibility and benefit of tuning thepolyhedral model in the context of vectorization."
            },
            "venue": {
                "fragments": [],
                "text": "2009 18th International Conference on Parallel Architectures and Compilation Techniques"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47910057"
                        ],
                        "name": "Yixun Liu",
                        "slug": "Yixun-Liu",
                        "structuredName": {
                            "firstName": "Yixun",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yixun Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31790133"
                        ],
                        "name": "E. Zhang",
                        "slug": "E.-Zhang",
                        "structuredName": {
                            "firstName": "Eddy",
                            "lastName": "Zhang",
                            "middleNames": [
                                "Z."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37914192"
                        ],
                        "name": "Xipeng Shen",
                        "slug": "Xipeng-Shen",
                        "structuredName": {
                            "firstName": "Xipeng",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xipeng Shen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 122
                            }
                        ],
                        "text": "G-ADAPT is a compiler framework to search and predict the best con.guration for different input sizes \nfor GPGPU programs [Liu et al. 2009]; it starts from already optimized code and aims to adapt the code \nto different input sizes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "GADAPT is a compiler framework to search and predict the best configuration for different input sizes for GPGPU programs [Liu et al. 2009]; it starts from already optimized code and aims to adapt the code to different input sizes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1030373,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9c961cbafd082da139cb6700ae29d841529fd2ba",
            "isKey": false,
            "numCitedBy": 142,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent years have seen a trend in using graphic processing units (GPU) as accelerators for general-purpose computing. The inexpensive, single-chip, massively parallel architecture of GPU has evidentially brought factors of speedup to many numerical applications. However, the development of a high-quality GPU application is challenging, due to the large optimization space and complex unpredictable effects of optimizations on GPU program performance. Recently, several studies have attempted to use empirical search to help the optimization. Although those studies have shown promising results, one important factor\u2014program inputs\u2014in the optimization has remained unexplored. In this work, we initiate the exploration in this new dimension. By conducting a series of measurement, we find that the ability to adapt to program inputs is important for some applications to achieve their best performance on GPU. In light of the findings, we develop an input-adaptive optimization framework, namely G-ADAPT, to address the influence by constructing cross-input predictive models for automatically predicting the (near-)optimal configurations for an arbitrary input to a GPU program. The results demonstrate the promise of the framework in serving as a tool to alleviate the productivity bottleneck in GPU programming."
            },
            "slug": "A-cross-input-adaptive-framework-for-GPU-program-Liu-Zhang",
            "title": {
                "fragments": [],
                "text": "A cross-input adaptive framework for GPU program optimizations"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An input-adaptive optimization framework, namely G-ADAPT, is developed to address the influence of program inputs by constructing cross-input predictive models for automatically predicting the (near-)optimal configurations for an arbitrary input to a GPU program."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE International Symposium on Parallel & Distributed Processing"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074562273"
                        ],
                        "name": "Allen",
                        "slug": "Allen",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Allen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Allen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Classical techniques of loop distribution and loop interchange [Wolfe 1996; Allen and Kennedy 2001; Trifunovi\u0107 et al. 2009] can dramatically impact the profitability of vectorization."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Strip-mining divides the dimension into bands, or strips of iterations [Allen and Kennedy 2001]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Combined loop-nest auto-vectorization and loop-interchange has been addressed in the context of vector supercomputers [Allen and Kennedy 1987; Wolfe 1996; Allen and Kennedy 2001]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60598493,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aafae29ae58c03d0d50de766d4cdf1349c85a53d",
            "isKey": false,
            "numCitedBy": 485,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Description: Modern computer architectures designed with high-performance microprocessors offer tremendous potential gains in performance over previous designs. Yet their very complexity makes it increasingly difficult to produce efficient code and to realize their full potential. This landmark text from two leaders in the field focuses on the pivotal role that compilers can play in addressing this critical issue."
            },
            "slug": "Optimizing-Compilers-for-Modern-Architectures-Allen",
            "title": {
                "fragments": [],
                "text": "Optimizing Compilers for Modern Architectures"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This landmark text from two leaders in the field focuses on the pivotal role that compilers can play in addressing this critical issue of increasing complexity of microprocessors."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2458826"
                        ],
                        "name": "N. Ravi",
                        "slug": "N.-Ravi",
                        "structuredName": {
                            "firstName": "Nishkam",
                            "lastName": "Ravi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ravi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2143686020"
                        ],
                        "name": "Yi Yang",
                        "slug": "Yi-Yang",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50555211"
                        ],
                        "name": "Tao Bao",
                        "slug": "Tao-Bao",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Bao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Bao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752242"
                        ],
                        "name": "S. Chakradhar",
                        "slug": "S.-Chakradhar",
                        "structuredName": {
                            "firstName": "Srimat",
                            "lastName": "Chakradhar",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chakradhar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 81
                            }
                        ],
                        "text": "Rather than targeting a low-level programming model like OpenCL or CUDA, Apricot [Ravi et al. 2012] focuses on the automatic insertion of offload constructs, targeting LEO."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 82
                            }
                        ],
                        "text": "Rather than targeting a low-level programming model like OpenCL \nor CUDA, Apri\u00adcot [Ravi et al. 2012] focuses on the automatic insertion of of.oad constructs, targeting \nLEO."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15388333,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a91da02b2074893ce1b0ecf650ba5c3bec56e6d",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Intel MIC (Many Integrated Core) is the first x86-based coprocessor architecture aimed at accelerating multi-core HPC applications. In the most common usage model, parallel code sections are offloaded to the MIC coprocessor using LEO (Language Extensions for Offload). The developer is responsible for identifying and specifying offloadable code regions, managing data transfers between the CPU and MIC and optimizing the application for performance, which requires some amount of effort and experimentation. In this paper, we present Apricot, an optimizing compiler and productivity tool for x86-compatible many-core coprocessors (such as Intel MIC) that minimizes developer effort by (i) automatically inserting LEO clauses for parallelizable code regions, (ii) selectively offloading some of the code regions to the coprocessor at runtime based on a cost model that we have developed, (iii) applying a set ofoptimizations for minimizing the data communication overhead and improving overall performance. Apricot is intended to assist programmers in porting existing multi-core applications and writing new ones to take advantage of the many-core coprocessor, while maximizing overall performance. Experiments with SpecOMP and NAS Parallel benchmarks show that Apricot can successfully transform OpenMP applications to run on the MIC coprocessor with good performance gains."
            },
            "slug": "Apricot:-an-optimizing-compiler-and-productivity-Ravi-Yang",
            "title": {
                "fragments": [],
                "text": "Apricot: an optimizing compiler and productivity tool for x86-compatible many-core coprocessors"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "Apricot is an optimizing compiler and productivity tool for x86-compatible many-core coprocessors (such as Intel MIC) that minimizes developer effort by automatically inserting LEO clauses for parallelizable code regions and selectively offloading some of the code regions to the coprocessionor at runtime."
            },
            "venue": {
                "fragments": [],
                "text": "ICS '12"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40335288"
                        ],
                        "name": "Gabe Rudy",
                        "slug": "Gabe-Rudy",
                        "structuredName": {
                            "firstName": "Gabe",
                            "lastName": "Rudy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gabe Rudy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31568526"
                        ],
                        "name": "M. Khan",
                        "slug": "M.-Khan",
                        "structuredName": {
                            "firstName": "Malik",
                            "lastName": "Khan",
                            "middleNames": [
                                "Murtaza"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Khan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143896454"
                        ],
                        "name": "Mary W. Hall",
                        "slug": "Mary-W.-Hall",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Hall",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mary W. Hall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109525543"
                        ],
                        "name": "Chun Chen",
                        "slug": "Chun-Chen",
                        "structuredName": {
                            "firstName": "Chun",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chun Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772362"
                        ],
                        "name": "Jacqueline Chame",
                        "slug": "Jacqueline-Chame",
                        "structuredName": {
                            "firstName": "Jacqueline",
                            "lastName": "Chame",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jacqueline Chame"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The CHiLL developers also extended their compiler to generate GPU code \u2014 they introduced CUDA-CHiLL [Rudy et al. 2011], which does not perform an automatic parallelization and mapping to CUDA but instead offers high-level constructs that allow a user or search engine to perform such a transformation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "2012] or CUDA-CHiLL [Rudy et al. 2011] to provide a deeper assessment of these tools\u2019 capabilities."
                    },
                    "intents": []
                }
            ],
            "corpusId": 19501057,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc2906b3a18ee0e4d0ef4ba324c01d5b60d77315",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a programming language interface, a complete scripting language, to describe composable compiler transformations. These transformation programs can be written, shared and reused by non-expert application and library developers. From a compiler writer's perspective, a scripting language interface permits rapid prototyping of compiler algorithms that can mix levels and compose different sequences of transformations, producing readable code as output. From a library or application developer's perspective, the use of transformation programs permits expression of clean high-level code, and a separate description of how to map that code to architectural features, easing maintenance and porting to new architectures. \n \nWe illustrate this interface in the context of CUDA-CHiLL, a source-to-source compiler transformation and code generation framework that transforms sequential loop nests to high-performance GPU code. We show how this high-level transformation and code generation language can be used to express: (1) complex transformation sequences, exemplified by a single loop restructuring construct used to generate a series of tiling and permute commands; and, (2) complex code generation sequences to produce CUDA code from a high-level specification. We demonstrate that the automatically-generated code either performs closely or outperforms two hand-tuned GPU library kernels from Nvidia's CUBLAS 2.2 and 3.2 libraries."
            },
            "slug": "A-Programming-Language-Interface-to-Describe-and-Rudy-Khan",
            "title": {
                "fragments": [],
                "text": "A Programming Language Interface to Describe Transformations and Code Generation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is demonstrated that the automatically-generated code either performs closely or outperforms two hand-tuned GPU library kernels from Nvidia's CUBLAS 2.2 and 3.2 libraries."
            },
            "venue": {
                "fragments": [],
                "text": "LCPC"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111108147"
                        ],
                        "name": "Jaewook Shin",
                        "slug": "Jaewook-Shin",
                        "structuredName": {
                            "firstName": "Jaewook",
                            "lastName": "Shin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jaewook Shin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143896454"
                        ],
                        "name": "Mary W. Hall",
                        "slug": "Mary-W.-Hall",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Hall",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mary W. Hall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772362"
                        ],
                        "name": "Jacqueline Chame",
                        "slug": "Jacqueline-Chame",
                        "structuredName": {
                            "firstName": "Jacqueline",
                            "lastName": "Chame",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jacqueline Chame"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 122
                            }
                        ],
                        "text": "Automatic vectorization was also extended to handle more sophisticated \ncontrol-.ow restructuring including if-conversion [Shin et al. 2005] and outer-loop vec\u00adtorization [Nuzman \nand Zaks 2008]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 122
                            }
                        ],
                        "text": "Automatic vectorization was also extended to handle more sophisticated control-flow restructuring including if-conversion [Shin et al. 2005] and outer-loop vectorization [Nuzman and Zaks 2008]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2811822,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ad8e1308849167d96355b9b1906994eb92283a3",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we describe how to extend the concept of superword-level parallelization (SLP), used for multimedia extension architectures, so that it can be applied in the presence of control flow constructs. Superword-level parallelization involves identifying scalar instructions in a large basic block that perform the same operation, and, if dependences do not prevent it, combining them into a superword operation on a multi-word object. A key insight is that we can use techniques related to optimizations for architectures supporting predicated execution, even for multimedia ISAs that do not provide hardware predication. We derive large basic blocks with predicated instructions to which SLP can be applied. We describe how to minimize overheads for superword predicates and re-introduce control flow for scalar operations. We discuss other extensions to SLP to address common features of real multimedia codes. We present automatically-generated performance results on 8 multimedia codes to demonstrate the power of this approach. We observe speedups ranging from 1.97X to 15.07X as compared to both sequential execution and SLP alone."
            },
            "slug": "Superword-level-parallelism-in-the-presence-of-flow-Shin-Hall",
            "title": {
                "fragments": [],
                "text": "Superword-level parallelism in the presence of control flow"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This paper describes how to minimize overheads for superword predicates and re-introduce control flow for scalar operations in the presence of control flow constructs, and presents automatically-generated performance results on 8 multimedia codes to demonstrate the power of this approach."
            },
            "venue": {
                "fragments": [],
                "text": "International Symposium on Code Generation and Optimization"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772079"
                        ],
                        "name": "Sven Verdoolaege",
                        "slug": "Sven-Verdoolaege",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Verdoolaege",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sven Verdoolaege"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756389"
                        ],
                        "name": "T. Grosser",
                        "slug": "T.-Grosser",
                        "structuredName": {
                            "firstName": "Tobias",
                            "lastName": "Grosser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Grosser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Our first step is to extract a polyhedral model using pet [Verdoolaege and Grosser 2012]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 58
                            }
                        ],
                        "text": "Our .rst step is to extract \na polyhedral model using pet [Verdoolaege and Grosser 2012]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13921165,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d79ead5a5c9e932ba3ab5bb41a7a2ac19d551346",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new library for extracting a polyhedral model from C source. The library is based on clang, the LLVM C frontend, and isl, a library for manipulating quasi-ane sets and relations. The use of clang for parsing the C code brings advanced diagnostics and full support for C99. The use of isl allows for an easy construction and a powerful and compact representation of the polyhedral model. Besides allowing arbitrary piecewise quasi-ane index expressions and conditions, the library also supports some data dependent constructs and has special treatment for unsigned integers. The library has been successfully used to obtain polyhedral models for use in an equivalence checker, a tool for constructing polyhedral process networks, a parallelizer targeting GPUs and an interactive polyhedral environment."
            },
            "slug": "Polyhedral-Extraction-Tool-Verdoolaege-Grosser",
            "title": {
                "fragments": [],
                "text": "Polyhedral Extraction Tool"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A new library for extracting a polyhedral model from C source based on clang, the LLVM C frontend, and isl, a library for manipulating quasi-ane sets and relations, which allows for an easy construction and a powerful and compact representation of thepolyhedral model."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755190"
                        ],
                        "name": "Dorit Nuzman",
                        "slug": "Dorit-Nuzman",
                        "structuredName": {
                            "firstName": "Dorit",
                            "lastName": "Nuzman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dorit Nuzman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38737579"
                        ],
                        "name": "A. Zaks",
                        "slug": "A.-Zaks",
                        "structuredName": {
                            "firstName": "Ayal",
                            "lastName": "Zaks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zaks"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 170
                            }
                        ],
                        "text": "Automatic vectorization was also extended to handle more sophisticated \ncontrol-.ow restructuring including if-conversion [Shin et al. 2005] and outer-loop vec\u00adtorization [Nuzman \nand Zaks 2008]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 114
                            }
                        ],
                        "text": "All of these works had a successful impact on \nproduction compilers [Wu et al. 2005; Bik 2004; Nuzman et al. 2006; Nuzman and Zaks 2008]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 35
                            }
                        ],
                        "text": "2005] and outer-loop vectorization [Nuzman and Zaks 2008]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 67
                            }
                        ],
                        "text": "All of these works had a successful impact on production compilers [Wu et al. 2005; Bik 2004; Nuzman et al. 2006; Nuzman and Zaks 2008]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9118288,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e47758869097cda0e6d8cf80fe37c811ffc72901",
            "isKey": true,
            "numCitedBy": 150,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Vectorization has been an important method of using data-level parallelism to accelerate scientific workloads on vector machines such as Cray for the past three decades. In the last decade it has also proven useful for accelerating multimedia and embedded applications on short SIMD architectures such as MMX, SSE and AltiVec. Most of the focus has been directed at innermost loops, effectively executing their iterations concurrently as much as possible. Outer loop vectorization refers to vectorizing a level of a loop nest other than the innermost, which can be beneficial if the outer loop exhibits greater data-level parallelism and locality than the innermost loop. Outer loop vectorization has traditionally been performed by interchanging an outer-loop with the innermost loop, followed by vectorizing it at the innermost position. A more direct unroll-and-jam approach can be used to vectorize an outer-loop without involving loop interchange, which can be especially suitable for short SIMD architectures. In this paper we revisit the method of outer loop vectorization, paying special attention to properties of modern short SIMD architectures. We show that even though current optimizing compilers for such targets do not apply outer-loop vectorization in general, it can provide significant performance improvements over innermost loop vectorization. Our implementation of direct outer-loop vectorization, available in GCC 4.3, achieves speedup factors of 3.13 and 2.77 on average across a set of benchmarks, compared to 1.53 and 1.39 achieved by innermost loop vectorization, when running on a Cell BE SPU and PowerPC970 processors respectively. Moreover, outer-loop vectorization provides new reuse opportunities that can be vital for such short SIMD architectures, including efficient handling of alignment. We present an optimization tapping such opportunities, capable of further boosting the performance obtained by outer-loop vectorization to achieve average speedup factors of 5.26 and 3.64."
            },
            "slug": "Outer-loop-vectorization-revisited-for-short-SIMD-Nuzman-Zaks",
            "title": {
                "fragments": [],
                "text": "Outer-loop vectorization - revisited for short SIMD architectures"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper revisit the method of outer loop vectorization, paying special attention to properties of modern short SIMD architectures, and presents an optimization tapping such opportunities, capable of further boosting the performance obtained by outer-loop vectorization to achieve average speedup factors of 5.26 and 3.64."
            },
            "venue": {
                "fragments": [],
                "text": "2008 International Conference on Parallel Architectures and Compilation Techniques (PACT)"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50073003"
                        ],
                        "name": "M. Wolfe",
                        "slug": "M.-Wolfe",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Wolfe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wolfe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 64
                            }
                        ],
                        "text": "Classical techniques of loop distribution and loop interchange [Wolfe 1996; Allen and \nKennedy 2001; Trifunovi \u00b4 c et al. 2009] can dramat\u00adically impact the pro.tability of vectorization."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 63
                            }
                        ],
                        "text": "Classical techniques of loop distribution and loop interchange [Wolfe 1996; Allen and Kennedy 2001; Trifunovi\u0107 et al. 2009] can dramatically impact the profitability of vectorization."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 118
                            }
                        ],
                        "text": "Combined loop-nest auto-vectorization and loop-interchange has been addressed in the context of vector supercomputers [Allen and Kennedy 1987; Wolfe 1996; Allen and Kennedy 2001]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 143
                            }
                        ],
                        "text": "Combined loop-nest auto-vectorization and loop-interchange has been addressed \nin the context of vector supercomputers [Allen and Kennedy 1987; Wolfe 1996; Allen and Kennedy 2001]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 36080832,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7c7fbce6a693ba54e63bc8742afd25f20f4f2d0",
            "isKey": true,
            "numCitedBy": 1445,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. High Performance Systems. An Example Program: Matrix Multiplication. Structure of a Compiler. 2. Programming Language Features. Languages for High Performance. Sequential and Parallel Loops. Roundoff Error. 3. Basic Graph Concepts. Sets, Tuples, Logic. Graphs. Control Dependence. 4. Review of Linear Algebra. Real Vectors and Matrices. Integer Matrices and Lattices. Linear System of Equations. System of Integer Equations. Systems of Linear Inequalities. Systems of Integer Linear Inequalities. Extreme Values of Affine Functions. 5. Data Dependence. Data Dependence in Loops. Data Dependence in Conditionals. Data Dependence in Parallel Loops. Program Dependence Graph. 6. Scalar Analysis with Factored Use-Def Chains. Constructing Factored Use-Def Chains. FUD Chains for Arrays. Finding All Reaching Definitions. Implicit References in FUD Chains. InductionVariables Using FUD Chains. Constant Propagation with FUD Chains. Data Dependence for Scalars. 7. Data Dependence Analysis for Arrays. Building the Dependence System. Dependence System Solvers. General Solver. Summary of Solvers. Complications. Run-time Dependence Testing. 8. Other Dependence Problems. Array Region Analysis. Pointer Analysis. I/O Dependence. Procedure Calls. Interprocedural Analysis. 9. Loop Restructuring. Simpile Transformations. Loop Fusion. Loop Fission. Loop Reversal. Loop Interchanging. Loop Skewing. Linear Loop Transformations. Strip-Mining. Loop Tiling. Other Loop Transformations. Interprocedural Transformations. 10. Optimizing for Locality. Single Reference to Each Array. Multiple References. General Tiling. Fission and Fusion for Locality. 11. Concurrency Analysis. Code for Concurrent Loops. Concurrency from Sequential Loops. Concurrency from Parallel Loops. Nested Loops. Roundoff Error. Exceptions and Debuggers. 12. Vector Analysis. Vector Code. Vector Code from Sequential Loops. Vector Code from Forall Loops. Nested Loops. Roundoff Error, Exceptions, and Debuggers. Multivector Computers. 13. Message-Passing Machines. SIMD Machines. MIMD Machines. Data Layout. Parallel Code for Array Assignment. Remote Data Access. Automatic Data Layout. Multiple Array Assignments. Other Topics. 14. Scalable Shared-Memory Machines. Global Cache Coherence. Local Cache Coherence. Latency Tolerant Machines. Glossary. References. Author Index. Index. 0805327304T04062001"
            },
            "slug": "High-performance-compilers-for-parallel-computing-Wolfe",
            "title": {
                "fragments": [],
                "text": "High performance compilers for parallel computing"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This book discusses Programming Language Features, Data Dependence, Dependence System Solvers, and Run-time Dependence Testing for High Performance Systems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143856977"
                        ],
                        "name": "Peng Wu",
                        "slug": "Peng-Wu",
                        "structuredName": {
                            "firstName": "Peng",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peng Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1985764"
                        ],
                        "name": "A. Eichenberger",
                        "slug": "A.-Eichenberger",
                        "structuredName": {
                            "firstName": "Alexandre",
                            "lastName": "Eichenberger",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Eichenberger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145130549"
                        ],
                        "name": "A. Wang",
                        "slug": "A.-Wang",
                        "structuredName": {
                            "firstName": "Amy",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1384721292"
                        ],
                        "name": "Peng Zhao",
                        "slug": "Peng-Zhao",
                        "structuredName": {
                            "firstName": "Peng",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peng Zhao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 146
                            }
                        ],
                        "text": "Leading optimizing compilers recognize the importance of devising a cost model for vectorization, but have so far provided only partial solutions [Wu et al. 2005; Bik 2004]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 67
                            }
                        ],
                        "text": "All of these works had a successful impact on production compilers [Wu et al. 2005; Bik 2004; Nuzman et al. 2006; Nuzman and Zaks 2008]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10355850,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af054f4f6c36901781925936292bfbcde33e8cb5",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic simdization for multimedia extensions faces several new challenges that are not present in traditional vectorization. Some of the new issues are due to the more restrictive SIMD architectures designed for multimedia extensions. Among them are alignment constraints, lack of memory gather and scatter support, and the short and fixed-length nature of SIMD vectors. Since these constraints affect some very basic components of a program, a compiler must not only provide solid solutions to individual issues, but also take an integrated approach to address these constraints in combination.In this paper, we propose a simdization framework that addresses several orthogonal aspects of simdization, such as alignment handling, simdization of loops with mixed data lengths, and SIMD parallelism extraction from different program scopes (from basic blocks to inner loops). The novelty of this framework is its ability to facilitate interactions between different techniques based on the simple intermediate representation of virtual vectors. Measurements on a PPC970 with a VMX SIMD unit indicate speedup factors of up to 8.11 for numerical/video/communication kernels and speedup factors of up to 2.16 for benchmarks, when automatic simdization is turned on."
            },
            "slug": "An-integrated-simdization-framework-using-virtual-Wu-Eichenberger",
            "title": {
                "fragments": [],
                "text": "An integrated simdization framework using virtual vectors"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes aSimdization framework that addresses several orthogonal aspects of simdization, such as alignment handling, simdized of loops with mixed data lengths, and SIMD parallelism extraction from different program scopes (from basic blocks to inner loops)."
            },
            "venue": {
                "fragments": [],
                "text": "ICS '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1838186"
                        ],
                        "name": "P. Feautrier",
                        "slug": "P.-Feautrier",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Feautrier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Feautrier"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 12851421,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16de6f9e2bf6ee1068dbca8c9e5446295c904315",
            "isKey": false,
            "numCitedBy": 459,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Programs and systems of recurrence equations may be represented as sets of actions which are to be executed subject to precedence constraints. In may cases, actions may be labelled by integral vectors in some iterations domains, and precedence constraints may be described by affine relations. A schedule for such a program is a function which assigns an execution data to each action. Knowledge of such a schedule allows one to estimate the intrinsic degree of parallelism of the program and to compile a parallel version for multiprocessor architectures or systolic arrays. This paper deals with the problem of finding closed form schedules as affine or piecewise affine functions of the iteration vector. An algorithm is presented which reduces the scheduling problem to a parametric linear program of small size, which can be readily solved by an efficient algorithm."
            },
            "slug": "Some-efficient-solutions-to-the-affine-scheduling-Feautrier",
            "title": {
                "fragments": [],
                "text": "Some efficient solutions to the affine scheduling problem. I. One-dimensional time"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper deals with the problem of finding closed form schedules as affine or piecewise affine functions of the iteration vector and presents an algorithm which reduces the scheduling problem to a parametric linear program of small size, which can be readily solved by an efficient algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Parallel Programming"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144616193"
                        ],
                        "name": "R. Allen",
                        "slug": "R.-Allen",
                        "structuredName": {
                            "firstName": "Randy",
                            "lastName": "Allen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Allen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70455556"
                        ],
                        "name": "K. Kennedy",
                        "slug": "K.-Kennedy",
                        "structuredName": {
                            "firstName": "Ken",
                            "lastName": "Kennedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kennedy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Combined loop-nest auto-vectorization and loop-interchange has been addressed in the context of vector supercomputers [Allen and Kennedy 1987; Wolfe 1996; Allen and Kennedy 2001]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 119
                            }
                        ],
                        "text": "Combined loop-nest auto-vectorization and loop-interchange has been addressed \nin the context of vector supercomputers [Allen and Kennedy 1987; Wolfe 1996; Allen and Kennedy 2001]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13978052,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e8ddfb7574926d50b75937424ff907b53d264ca6",
            "isKey": false,
            "numCitedBy": 824,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "The recent success of vector computers such as the Cray-1 and array processors such as those manufactured by Floating Point Systems has increased interest in making vector operations available to the FORTRAN programmer. The FORTRAN standards committee is currently considering a successor to FORTRAN 77, usually called FORTRAN 8x, that will permit the programmer to explicitly specify vector and array operations.\nAlthough FORTRAN 8x will make it convenient to specify explicit vector operations in new programs, it does little for existing code. In order to benefit from the power of vector hardware, existing programs will need to be rewritten in some language (presumably FORTRAN 8x) that permits the explicit specification of vector operations. One way to avoid a massive manual recoding effort is to provide a translator that discovers the parallelism implicit in a FORTRAN program and automatically rewrites that program in FORTRAN 8x.\nSuch a translation from FORTRAN to FORTRAN 8x is not straightforward because FORTRAN DO loops are not always semantically equivalent to the corresponding FORTRAN 8x parallel operation. The semantic difference between these two constructs is precisely captured by the concept of dependence. A translation from FORTRAN to FORTRAN 8x preserves the semantics of the original program if it preserves the dependences in that program.\nThe theoretical background is developed here for employing data dependence to convert FORTRAN programs to parallel form. Dependence is defined and characterized in terms of the conditions that give rise to it; accurate tests to determine dependence are presented; and transformations that use dependence to uncover additional parallelism are discussed."
            },
            "slug": "Automatic-translation-of-FORTRAN-programs-to-vector-Allen-Kennedy",
            "title": {
                "fragments": [],
                "text": "Automatic translation of FORTRAN programs to vector form"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The theoretical background is developed here for employing data dependence to convert FORTRAN programs to parallel form and transformations that use dependence to uncover additional parallelism are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "TOPL"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144301481"
                        ],
                        "name": "R. C. Whaley",
                        "slug": "R.-C.-Whaley",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Whaley",
                            "middleNames": [
                                "Clinton"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. C. Whaley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719457"
                        ],
                        "name": "A. Petitet",
                        "slug": "A.-Petitet",
                        "structuredName": {
                            "firstName": "Antoine",
                            "lastName": "Petitet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Petitet"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 34574568,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f45055dbddd5e80bc08e3586bce13aa67fd990f",
            "isKey": false,
            "numCitedBy": 195,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "The Basic Linear Algebra Subprograms (BLAS) define one of the most heavily used performance\u2010critical APIs in scientific computing today. It has long been understood that the most important of these routines, the dense Level 3 BLAS, may be written efficiently given a highly optimized general matrix multiply routine. In this paper, however, we show that an even larger set of operations can be efficiently maintained using a much simpler matrix multiply kernel. Indeed, this is how our own project, ATLAS (which provides one of the most widely used BLAS implementations in use today), supports a large variety of performance\u2010critical routines. Copyright \u00a9 2004 John Wiley & Sons, Ltd."
            },
            "slug": "Minimizing-development-and-maintenance-costs-in-Whaley-Petitet",
            "title": {
                "fragments": [],
                "text": "Minimizing development and maintenance costs in supporting persistently optimized BLAS"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is shown that an even larger set of operations can be efficiently maintained using a much simpler matrix multiply kernel, which supports a large variety of performance\u2010critical routines."
            },
            "venue": {
                "fragments": [],
                "text": "Softw. Pract. Exp."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1838186"
                        ],
                        "name": "P. Feautrier",
                        "slug": "P.-Feautrier",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Feautrier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Feautrier"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 23417662,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "486986fb365f072146cb9648ab408b0c567ae019",
            "isKey": false,
            "numCitedBy": 384,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper extends the algorithms which were developed in Part I to cases in which there is no affine schedule, i.e. to problems whose parallel complexity is polynomial but not linear. The natural generalization is to multidimensional schedules with lexicographic ordering as temporal succession. Multidimensional affine schedules, are, in a sense, equivalent to polynomial schedules, and are much easier to handle automatically. Furthermore, there is a strong connection between multidimensional schedules and loop nests, which allows one to prove that a static control program always has a multidimensional schedule. Roughly, a larger dimension indicates less parallelism. In the algorithm which is presented here, this dimension is computed dynamically, and is just sufficient for scheduling the source program. The algorithm lends itself to a \u201cdivide and conquer\u201d strategy. The paper gives some experimental evidence for the applicability, performances and limitations of the algorithm."
            },
            "slug": "Some-efficient-solutions-to-the-affine-scheduling-Feautrier",
            "title": {
                "fragments": [],
                "text": "Some efficient solutions to the affine scheduling problem. Part II. Multidimensional time"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "This paper extends the algorithms which were developed in Part I to cases in which there is no affine schedule, i.e. to problems whose parallel complexity is polynomial but not linear, and gives some experimental evidence for the applicability, performances and limitations of the algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Parallel Programming"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144211012"
                        ],
                        "name": "A. Bik",
                        "slug": "A.-Bik",
                        "structuredName": {
                            "firstName": "Aart",
                            "lastName": "Bik",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 59914977,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39dd44107ee2051bba8c6b7a75d044dfbc0653b1",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-software-vectorization-handbook-Bik",
            "title": {
                "fragments": [],
                "text": "The software vectorization handbook"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "OpenACC: Directives for accelerators. http://www.openacc-standard.org \nPoCC 2012."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 116
                            }
                        ],
                        "text": "On the other hand, PPCG showed \nthe best performance in all cases compared to the full-automatic strategies (Pluto + OpenACC or OpenMPC)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 332,
                                "start": 326
                            }
                        ],
                        "text": "On the other hand, PPCG performs better than Par4All in 7 cases \nwhere the hardware cache is not performing as well as the software-controlled shared memory exploited \nby PPCG. Finally, and for the sake of completeness, we compare PPCG with two of the most representative \nsemi-automatic tools: the PGI compiler with support for OpenACC [OpenACC 2011] and OpenMPC [Lee and Eigenmann \n2010]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 39
                            }
                        ],
                        "text": "The aim for this is clear, it provides OpenACC \nand OpenMPC of an automatic parallel extraction stage and allows for a fair comparison with PPCG. Figure \n7 shows the results."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 72
                            }
                        ],
                        "text": "the OpenACC language has recently been proposed as a unifying direction [OpenACC 2011]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 58
                            }
                        ],
                        "text": "For OpenMPC manual placement was always better, while for OpenACC Pluto generally \ngenerates a slightly better input code, with one distinct exception, bicg, for which the manually annotated \ncode was signi.cantly better."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 74
                            }
                        ],
                        "text": "Performance comparison between PPCG and two semi-automatic mapping tools: OpenACC and OpenMPC. \nheavily rely on the effectiveness of a previous pragma placement stage."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 131
                            }
                        ],
                        "text": "In.uenced by all these trends, 54:4 S. \nVerdoolaege et al. the OpenACC language has recently been proposed as a unifying direction [OpenACC 2011]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 255,
                                "start": 243
                            }
                        ],
                        "text": "\u2026not performing as well as the software-controlled shared memory exploited \nby PPCG. Finally, and for the sake of completeness, we compare PPCG with two of the most representative \nsemi-automatic tools: the PGI compiler with support for OpenACC [OpenACC 2011] and OpenMPC [Lee and Eigenmann \n2010]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 0
                            }
                        ],
                        "text": "OpenACC 2011."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 0
                            }
                        ],
                        "text": "OpenACC is now supported by PGI and CAPS in their commercial compilers."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 159
                            }
                        ],
                        "text": "Finally, and for the sake of completeness, we compare PPCG with two of the most representative semi-automatic tools: the PGI compiler with support for OpenACC [OpenACC 2011] and OpenMPC [Lee and Eigenmann 2010]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "OpenACC: Directives for accelerators"
            },
            "venue": {
                "fragments": [],
                "text": "http://www.openacc-standard.org"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "AMP 2011."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 49
                            }
                        ],
                        "text": "Microsoft s AMP is also based on the same ideas \n[AMP 2011]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 48
                            }
                        ],
                        "text": "Microsoft\u2019s AMP is also based on the same ideas [AMP 2011]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "C++ accelerated massive parallelism"
            },
            "venue": {
                "fragments": [],
                "text": "http://msdn.microsoft.com/en-us/library/hh265137"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 172
                            }
                        ],
                        "text": "As a complementary approach, CAPS has been pushing for a more explicit programming model called HMPP, emphasizing the need for expert programmers to guide the optimization [HMPP 2010]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 0
                            }
                        ],
                        "text": "HMPP 2010."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 173
                            }
                        ],
                        "text": "As a complementary \napproach, CAPS has been pushing for a more explicit programming model called HMPP, emphasizing the need \nfor expert programmers to guide the optimization [HMPP 2010]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "HMPP workbench: directive-based multi-language and multi-target hybrid programming model"
            },
            "venue": {
                "fragments": [],
                "text": "http://www.caps-entreprise.com/hmpp.html"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144211012"
                        ],
                        "name": "A. Bik",
                        "slug": "A.-Bik",
                        "structuredName": {
                            "firstName": "Aart",
                            "lastName": "Bik",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bik"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 163
                            }
                        ],
                        "text": "Leading optimizing compilers recognize the importance of devising a cost model for vectorization, but \nhave so far provided only partial solutions [Wu et al. 2005; Bik 2004]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 84
                            }
                        ],
                        "text": "All of these works had a successful impact on \nproduction compilers [Wu et al. 2005; Bik 2004; Nuzman et al. 2006; Nuzman and Zaks 2008]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 57338838,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b2aff687f08bf2b20be478827eef3918e576fdc",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Software-Vectorization-Handbook,-The:-Applying-for-Bik",
            "title": {
                "fragments": [],
                "text": "Software Vectorization Handbook, The: Applying Intel Multimedia Extensions for Maximum Performance"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ACM-TRANSACTION December"
            },
            "venue": {
                "fragments": [],
                "text": "ACM-TRANSACTION December"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "HMPP workbench: a directive-based multi-language and multi-target hybrid programming model http"
            },
            "venue": {
                "fragments": [],
                "text": "HMPP 2010"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "PLuTo: An automatic parallelizer and locality optimizer for multicores, version 0.7. http://pluto-compiler.sourceforge.net"
            },
            "venue": {
                "fragments": [],
                "text": "PLuTo: An automatic parallelizer and locality optimizer for multicores, version 0.7. http://pluto-compiler.sourceforge.net"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Portland Group 2010. PGI Accelerator Programming Model for Fortran & C v1.3 Ed. The Portland Group"
            },
            "venue": {
                "fragments": [],
                "text": "The Portland Group 2010. PGI Accelerator Programming Model for Fortran & C v1.3 Ed. The Portland Group"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 128
                            }
                        ],
                        "text": "The generation of the schedule in both C-to-CUDA and PPCG is based \non the algorithm proposed in Pluto [Bondhugula et al. 2008b; Bondhugula 2012], although they currently \nevolve independently."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "PLuTo: An automatic parallelizer and locality optimizer for multicores, version 0.7. http://pluto-compiler.sourceforge.net"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Article 54, Publication date: January 2013. Polyhedral Parallel Code Generation for CUDA"
            },
            "venue": {
                "fragments": [],
                "text": "ACM Transactions on Architecture and Code Optimization"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Software Vectorization Handbook. Applying Multimedia Extensions for Maximum Performance"
            },
            "venue": {
                "fragments": [],
                "text": "The Software Vectorization Handbook. Applying Multimedia Extensions for Maximum Performance"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ACM Transactions on Architecture and Code Optimization"
            },
            "venue": {
                "fragments": [],
                "text": "ACM Transactions on Architecture and Code Optimization"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ACM Transactions on Architecture and Code Optimization"
            },
            "venue": {
                "fragments": [],
                "text": "ACM Transactions on Architecture and Code Optimization"
            },
            "year": 2013
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "OpenACC: Directives for accelerators. http://www.openacc-standard.org PoCC 2012. PoCC: the polyhedral compiler collection version 1.1"
            },
            "venue": {
                "fragments": [],
                "text": "OpenACC"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "PoCC: the polyhedral compiler collection version"
            },
            "venue": {
                "fragments": [],
                "text": "PoCC"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "NVIDIA Corporation"
            },
            "venue": {
                "fragments": [],
                "text": "NVIDIA Corporation"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "PGI Accelerator Programming Model for Fortran & C v1.3 ed. The Portland Group"
            },
            "venue": {
                "fragments": [],
                "text": "PGI Accelerator Programming Model for Fortran & C v1.3 ed. The Portland Group"
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Par4All automatic parallelization version 1.3"
            },
            "venue": {
                "fragments": [],
                "text": "Par4All automatic parallelization version 1.3"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "PoCC: the polyhedral compiler collection version 1.1"
            },
            "venue": {
                "fragments": [],
                "text": "PoCC"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 128
                            }
                        ],
                        "text": "The generation of the schedule in both C-to-CUDA and PPCG is based \non the algorithm proposed in Pluto [Bondhugula et al. 2008b; Bondhugula 2012], although they currently \nevolve independently."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "PLuTo: An automatic parallelizer and locality optimizer for multicores, version 0.7"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "OpenACC: Directives for accelerators"
            },
            "venue": {
                "fragments": [],
                "text": "OpenACC"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Polyhedral Parallel Code Generation for CUDA"
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans . Architec . Code Optim ."
            },
            "year": 2012
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 14,
            "methodology": 25
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 65,
        "totalPages": 7
    },
    "page_url": "https://www.semanticscholar.org/paper/Polyhedral-parallel-code-generation-for-CUDA-Verdoolaege-Juega/963a1e639971e7e3a4e6c871cf9c0b410e5532d0?sort=total-citations"
}