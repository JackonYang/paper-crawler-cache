{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2425143"
                        ],
                        "name": "I. Pil\u00e1szy",
                        "slug": "I.-Pil\u00e1szy",
                        "structuredName": {
                            "firstName": "Istv\u00e1n",
                            "lastName": "Pil\u00e1szy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Pil\u00e1szy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2871013"
                        ],
                        "name": "D\u00e1vid Zibriczky",
                        "slug": "D\u00e1vid-Zibriczky",
                        "structuredName": {
                            "firstName": "D\u00e1vid",
                            "lastName": "Zibriczky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D\u00e1vid Zibriczky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754164"
                        ],
                        "name": "D. Tikk",
                        "slug": "D.-Tikk",
                        "structuredName": {
                            "firstName": "Domonkos",
                            "lastName": "Tikk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tikk"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "K makes it unsuitable to run on large-scale data [23], where a large number of factors needs to be considered to gain improved performance [31]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "[25]) O(|R|K) IALS1 (Pil\u00e1szy et al.[23]) O(K(3) + (M +N)K(2) + |R|K) ii-SVD (Volkovs et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "To resolve this, [23] describes an approximate solution to ALS."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 28
                            }
                        ],
                        "text": "To this end, existing works [4, 12, 23, 30, 31] have applied a simple uniform weight on missing entries, which are, however, suboptimal and non-extendable for real applications."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 145
                            }
                        ],
                        "text": "In particular, we assign the weight of missing data based on the popularity of items, which is arguably more effective than the previous methods [4, 12, 23, 30, 31] that are limited by the uniformity assumption."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "This analytical solution is also known as the ridge regression [23]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 178
                            }
                        ],
                        "text": "ALS can be seen as an instantiation of CD and has been widely used to solve the whole-based MF [12, 20, 21, 30]; however, its inefficiency is the main obstacle for practical use [23, 31]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 38
                            }
                        ],
                        "text": "For existing whole-data based methods [4, 12, 23, 30, 31], one major limitation is in the uniform weighting on missing entries, which favors algorithm\u2019s efficiency but limits model\u2019s flexibility and extensibility."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1816937,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ccd14d553d547384d7a848a6a532e65f1fd6746",
            "isKey": true,
            "numCitedBy": 169,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Alternating least squares (ALS) is a powerful matrix factorization (MF) algorithm for both explicit and implicit feedback based recommender systems. As shown in many articles, increasing the number of latent factors (denoted by K) boosts the prediction accuracy of MF based recommender systems, including ALS as well. The price of the better accuracy is paid by the increased running time: the running time of the original version of ALS is proportional to K3. Yet, the running time of model building can be important in recommendation systems; if the model cannot keep up with the changing item portfolio and/or user profile, the prediction accuracy can be degraded.\n In this paper we present novel and fast ALS variants both for the implicit and explicit feedback datasets, which offers better trade-off between running time and accuracy. Due to the significantly lower computational complexity of the algorithm - linear in terms of K - the model being generated under the same amount of time is more accurate, since the faster training enables to build model with more latent factors. We demonstrate the efficiency of our ALS variants on two datasets using two performance measures, RMSE and average relative position (ARP), and show that either a significantly more accurate model can be generated under the same amount of time or a model with similar prediction accuracy can be created faster; for explicit feedback the speed-up factor can be even 5-10."
            },
            "slug": "Fast-als-based-matrix-factorization-for-explicit-Pil\u00e1szy-Zibriczky",
            "title": {
                "fragments": [],
                "text": "Fast als-based matrix factorization for explicit and implicit feedback datasets"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "Novel and fast ALS variants both for the implicit and explicit feedback datasets, which offers better trade-off between running time and accuracy and either a significantly more accurate model can be generated under the same amount of time or a model with similar prediction accuracy can be created faster."
            },
            "venue": {
                "fragments": [],
                "text": "RecSys '10"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1765951"
                        ],
                        "name": "M. Volkovs",
                        "slug": "M.-Volkovs",
                        "structuredName": {
                            "firstName": "Maksims",
                            "lastName": "Volkovs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Volkovs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3847750"
                        ],
                        "name": "Guangwei Yu",
                        "slug": "Guangwei-Yu",
                        "structuredName": {
                            "firstName": "Guangwei",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guangwei Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 139
                            }
                        ],
                        "text": "K makes it unsuitable to run on large-scale data [23], where a large number of factors needs to be considered to gain improved performance [31]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 28
                            }
                        ],
                        "text": "To this end, existing works [4, 12, 23, 30, 31] have applied a simple uniform weight on missing entries, which are, however, suboptimal and non-extendable for real applications."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 145
                            }
                        ],
                        "text": "In particular, we assign the weight of missing data based on the popularity of items, which is arguably more effective than the previous methods [4, 12, 23, 30, 31] that are limited by the uniformity assumption."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 99
                            }
                        ],
                        "text": "In addition, our proposed eALS has the same time complexity with RCD [4], being faster than ii-SVD [31], another recent solution."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 178
                            }
                        ],
                        "text": "ALS can be seen as an instantiation of CD and has been widely used to solve the whole-based MF [12, 20, 21, 30]; however, its inefficiency is the main obstacle for practical use [23, 31]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 38
                            }
                        ],
                        "text": "For existing whole-data based methods [4, 12, 23, 30, 31], one major limitation is in the uniform weighting on missing entries, which favors algorithm\u2019s efficiency but limits model\u2019s flexibility and extensibility."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "Similarly, [31] enriches the implicit feedback matrix with neighbor-based similarly, followed by applying unweighted SVD."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": "[23]) O(K(3) + (M +N)K(2) + |R|K) ii-SVD (Volkovs et al.[31]) O((M +N)K(2) +MN logK) RCD (Devooght et al."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1571771,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d4d90b5a2623a8d8284b130461b08d7546763a2",
            "isKey": true,
            "numCitedBy": 61,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "In many collaborative filtering (CF) applications, latent approaches are the preferred model choice due to their ability to generate real-time recommendations efficiently. However, the majority of existing latent models are not designed for implicit binary feedback (views, clicks, plays etc.) and perform poorly on data of this type. Developing accurate models from implicit feedback is becoming increasingly important in CF since implicit feedback can often be collected at lower cost and in much larger quantities than explicit preferences. The need for accurate latent models for implicit data was further emphasized by the recently conducted Million Song Dataset Challenge organized by Kaggle. In this challenge, the results for the best latent model were orders of magnitude worse than neighbor-based approaches, and all the top performing teams exclusively used neighbor-based models. We address this problem and propose a new latent approach for binary feedback in CF. In our model, neighborhood similarity information is used to guide latent factorization and derive accurate latent representations. We show that even with simple factorization methods like SVD, our approach outperforms existing models and produces state-of-the-art results."
            },
            "slug": "Effective-Latent-Models-for-Binary-Feedback-in-Volkovs-Yu",
            "title": {
                "fragments": [],
                "text": "Effective Latent Models for Binary Feedback in Recommender Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes a new latent approach for binary feedback in CF and shows that even with simple factorization methods like SVD, this approach outperforms existing models and produces state-of-the-art results."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066007146"
                        ],
                        "name": "Rong Pan",
                        "slug": "Rong-Pan",
                        "structuredName": {
                            "firstName": "Rong",
                            "lastName": "Pan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rong Pan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144362899"
                        ],
                        "name": "Martin Scholz",
                        "slug": "Martin-Scholz",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Scholz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin Scholz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 95
                            }
                        ],
                        "text": "ALS can be seen as an instantiation of CD and has been widely used to solve the whole-based MF [12, 20, 21, 30]; however, its inefficiency is the main obstacle for practical use [23, 31]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "[20, 21]; however their cubic time complexity w."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14575731,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de2a0b7ec920e94fcbdeb9ae1f6c7e92cd1e7470",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "One-Class Collaborative Filtering (OCCF) is a task that naturally emerges in recommender system settings. Typical characteristics include: Only positive examples can be observed, classes are highly imbalanced, and the vast majority of data points are missing. The idea of introducing weights for missing parts of a matrix has recently been shown to help in OCCF. While existing weighting approaches mitigate the first two problems above, a sparsity preserving solution that would allow to efficiently utilize data sets with e.g., hundred thousands of users and items has not yet been reported. In this paper, we study three different collaborative filtering frameworks: Low-rank matrix approximation, probabilistic latent semantic analysis, and maximum-margin matrix factorization. We propose two novel algorithms for large-scale OCCF that allow to weight the unknowns. Our experimental results demonstrate their effectiveness and efficiency on different problems, including the Netflix Prize data."
            },
            "slug": "Mind-the-gaps:-weighting-the-unknown-in-large-scale-Pan-Scholz",
            "title": {
                "fragments": [],
                "text": "Mind the gaps: weighting the unknown in large-scale one-class collaborative filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper proposes two novel algorithms for large-scale OCCF that allow to weight the unknowns: Low-rank matrix approximation, probabilistic latent semantic analysis, and maximum-margin matrix factorization."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2843982"
                        ],
                        "name": "Steffen Rendle",
                        "slug": "Steffen-Rendle",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Rendle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steffen Rendle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1825333"
                        ],
                        "name": "C. Freudenthaler",
                        "slug": "C.-Freudenthaler",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Freudenthaler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Freudenthaler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": "Our proposed popularity-aware weighting strategy has the same intuition with Rendle\u2019s popularity-based oversampling [24] for learning BPR, which basically samples popular items as negative feedback with a higher probability."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "However, [24] empirically shows the oversampling method underperforms the basic uniform sampler."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8750954,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "25ad8ad3d1549888a4609659bd55ad825c5df82e",
            "isKey": false,
            "numCitedBy": 287,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Pairwise algorithms are popular for learning recommender systems from implicit feedback. For each user, or more generally context, they try to discriminate between a small set of selected items and the large set of remaining (irrelevant) items. Learning is typically based on stochastic gradient descent (SGD) with uniformly drawn pairs. In this work, we show that convergence of such SGD learning algorithms slows down considerably if the item popularity has a tailed distribution. We propose a non-uniform item sampler to overcome this problem. The proposed sampler is context-dependent and oversamples informative pairs to speed up convergence. An efficient implementation with constant amortized runtime costs is developed. Furthermore, it is shown how the proposed learning algorithm can be applied to a large class of recommender models. The properties of the new learning algorithm are studied empirically on two real-world recommender system problems. The experiments indicate that the proposed adaptive sampler improves the state-of-the art learning algorithm largely in convergence without negative effects on prediction quality or iteration runtime."
            },
            "slug": "Improving-pairwise-learning-for-item-recommendation-Rendle-Freudenthaler",
            "title": {
                "fragments": [],
                "text": "Improving pairwise learning for item recommendation from implicit feedback"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The experiments indicate that the proposed adaptive sampler improves the state-of-the art learning algorithm largely in convergence without negative effects on prediction quality or iteration runtime."
            },
            "venue": {
                "fragments": [],
                "text": "WSDM"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2778969"
                        ],
                        "name": "Robin Devooght",
                        "slug": "Robin-Devooght",
                        "structuredName": {
                            "firstName": "Robin",
                            "lastName": "Devooght",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robin Devooght"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1946641"
                        ],
                        "name": "N. Kourtellis",
                        "slug": "N.-Kourtellis",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Kourtellis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Kourtellis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3105979"
                        ],
                        "name": "Amin Mantrach",
                        "slug": "Amin-Mantrach",
                        "structuredName": {
                            "firstName": "Amin",
                            "lastName": "Mantrach",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amin Mantrach"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 120
                            }
                        ],
                        "text": "It has been shown that modeling only the observed, positive feedback results in biased representations in user profiles [4, 12]; e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 183
                            }
                        ],
                        "text": "As it is prohibitive to retrain the full model online, various works have developed incremental learning strategies for neighbor-based [13], graph-based [9], probabilistic [3] and MF [4, 5, 17, 27] methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 149
                            }
                        ],
                        "text": "Another key advantage of eALS is that it works without learning rate, bypassing the wellknown difficulty for tuning gradient descent methods such as [4] and Stochastic Gradient Descent (SGD) [25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 10
                            }
                        ],
                        "text": "Recently, [4] employs the Randomized block Coordinate Descent (RCD) learner [28], reducing the complexity and applying it to a dynamic scenario."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 105
                            }
                        ],
                        "text": "To optimize MF, various learners have been investigated, including SGD [14, 25], Coordinate Descent (CD) [4, 32], and Markov Chain Monto Carlo (MCMC) [26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[4] has proposed an efficient implicit MF method for learning with dynamic data."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 145
                            }
                        ],
                        "text": "In particular, we assign the weight of missing data based on the popularity of items, which is arguably more effective than the previous methods [4, 12, 23, 30, 31] that are limited by the uniformity assumption."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 38
                            }
                        ],
                        "text": "For existing whole-data based methods [4, 12, 23, 30, 31], one major limitation is in the uniform weighting on missing entries, which favors algorithm\u2019s efficiency but limits model\u2019s flexibility and extensibility."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 41
                            }
                        ],
                        "text": "However, we argue that Devooght\u2019s method [4] models missing data in an unrealistic, suboptimal way."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 206
                            }
                        ],
                        "text": "Our eALS algorithm is fast in accounting for missing data \u2014 analytically K times faster than ALS [12] where K denotes number of latent factors \u2014 the same time complexity with the recent dynamic MF solution [4]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11421123,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a3cdd6ff02f5b67fc68df25b363cf2f7be92d5dd",
            "isKey": true,
            "numCitedBy": 85,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Advanced and effective collaborative filtering methods based on explicit feedback assume that unknown ratings do not follow the same model as the observed ones not missing at random). In this work, we build on this assumption, and introduce a novel dynamic matrix factorization framework that allows to set an explicit prior on unknown values. When new ratings, users, or items enter the system, we can update the factorization in time independent of the size of data (number of users, items and ratings). Hence, we can quickly recommend items even to very recent users. We test our methods on three large datasets, including two very sparse ones, in static and dynamic conditions. In each case, we outrank state-of-the-art matrix factorization methods that do not use a prior on unknown ratings."
            },
            "slug": "Dynamic-Matrix-Factorization-with-Priors-on-Unknown-Devooght-Kourtellis",
            "title": {
                "fragments": [],
                "text": "Dynamic Matrix Factorization with Priors on Unknown Values"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A novel dynamic matrix factorization framework that allows to set an explicit prior on unknown values is introduced, and it is shown that when new ratings, users, or items enter the system, it can update the factorization in time independent of the size of data."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065174415"
                        ],
                        "name": "Guang Ling",
                        "slug": "Guang-Ling",
                        "structuredName": {
                            "firstName": "Guang",
                            "lastName": "Ling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guang Ling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702456"
                        ],
                        "name": "Haiqin Yang",
                        "slug": "Haiqin-Yang",
                        "structuredName": {
                            "firstName": "Haiqin",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haiqin Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145310663"
                        ],
                        "name": "Irwin King",
                        "slug": "Irwin-King",
                        "structuredName": {
                            "firstName": "Irwin",
                            "lastName": "King",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Irwin King"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785083"
                        ],
                        "name": "Michael R. Lyu",
                        "slug": "Michael-R.-Lyu",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Lyu",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael R. Lyu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 115
                            }
                        ],
                        "text": "For MF, different learners have been studied for online updating, including SGD [5, 27], RCD [4] and dualaveraging [17]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 183
                            }
                        ],
                        "text": "As it is prohibitive to retrain the full model online, various works have developed incremental learning strategies for neighbor-based [13], graph-based [9], probabilistic [3] and MF [4, 5, 17, 27] methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8384702,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "38485c7b4e991a67cda20c38062626a7637955b9",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Collaborative filtering (CF), aiming at predicting users' unknown preferences based on observational preferences from some users, has become one of the most successful methods to building recommender systems. Various approaches to CF have been proposed in this area, but seldom do they consider the dynamic scenarios: 1) new items arriving in the system, 2) new users joining the system; or 3) new rating updating the system are all dynamically obtained with respect to time. To capture these changes, in this paper, we develop an online learning framework for collaborative filtering. Specifically, we construct this framework consisting of two state-of-the-art matrix factorization based CF methods: the probabilistic matrix factorization and the top-one probability based ranking matrix factorization. Moreover, we demonstrate that the proposed online algorithms bring several attractive advantages: 1) they scale linearly with the number of observed ratings and the size of latent features; 2) they obviate the need to load all ratings in memory; 3) they can adapt to new ratings easily. Finally, we conduct a series of detailed experiments on real-world datasets to demonstrate the merits of the proposed online learning algorithms under various settings."
            },
            "slug": "Online-learning-for-collaborative-filtering-Ling-Yang",
            "title": {
                "fragments": [],
                "text": "Online learning for collaborative filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper develops an online learning framework for collaborative filtering consisting of two state-of-the-art matrix factorization based CF methods: the probabilistic matrix factorsization and the top-one probability based ranking matrix factorizations."
            },
            "venue": {
                "fragments": [],
                "text": "The 2012 International Joint Conference on Neural Networks (IJCNN)"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2843982"
                        ],
                        "name": "Steffen Rendle",
                        "slug": "Steffen-Rendle",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Rendle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steffen Rendle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1825333"
                        ],
                        "name": "C. Freudenthaler",
                        "slug": "C.-Freudenthaler",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Freudenthaler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Freudenthaler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2382247"
                        ],
                        "name": "Zeno Gantner",
                        "slug": "Zeno-Gantner",
                        "structuredName": {
                            "firstName": "Zeno",
                            "lastName": "Gantner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zeno Gantner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388781075"
                        ],
                        "name": "L. Schmidt-Thieme",
                        "slug": "L.-Schmidt-Thieme",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Schmidt-Thieme",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Schmidt-Thieme"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 67
                            }
                        ],
                        "text": "Although it is a widely used evaluation protocol in the literature [9, 25], we point out that it is an artificial split that does not correspond to the real recommendation scenario."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "In addition, the O(|R|K(2)) part is still much higher than in SGD [25], which only requires O(|R|K) time."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 149
                            }
                        ],
                        "text": "The second term accounts for the missing data, which acts as the role of negative instances and is crucial for recommendation from implicit feedback [12, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 191
                            }
                        ],
                        "text": "Another key advantage of eALS is that it works without learning rate, bypassing the wellknown difficulty for tuning gradient descent methods such as [4] and Stochastic Gradient Descent (SGD) [25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "In addition, the O(|R|K2) part is still much higher than in SGD [25], which only requires O(|R|K) time."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 55
                            }
                        ],
                        "text": "The most efficient algorithm is BPR, which applies the SGD learner on sampled, partial missing data only."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 104
                            }
                        ],
                        "text": "As the focus of this paper is on whole-data based implicit MF, we do not further explore the details of SGD."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 71
                            }
                        ],
                        "text": "To optimize MF, various learners have been investigated, including SGD [14, 25], Coordinate Descent (CD) [4, 32], and Markov Chain Monto Carlo (MCMC) [26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 44
                            }
                        ],
                        "text": "This is an advantage over the commonly-used SGD learner, which is a stochastic method that updates model parameters given a training instance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "SGD is the most popular one owing to the ease of derivation, however,\nit is unsuitable for whole-data based MF [12] due to the large amount of training instances (the full user\u2013item interaction matrix is considered)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In SGD, different gradient steps can influence with each other and there is no exact way to separate the updates for workers."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 71
                            }
                        ],
                        "text": "To this end, two strategies have been proposed \u2014 sample based learning [21, 25] that samples negative instances from missing data, or whole-data based learning [12, 30] that treats all missing data as negative."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 71
                            }
                        ],
                        "text": ", over half users have only one review), we follow the common practice [25] to filter out"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 37
                            }
                        ],
                        "text": "We suspect the reason comes from the SGD learner, which will result in more gradient steps on popular items, due to oversampling."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 103
                            }
                        ],
                        "text": "For the weight of observed interactions, we set it uniformly as 1, a default setting by previous works [4, 25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 76
                            }
                        ],
                        "text": "For MF, different learners have been studied for online updating, including SGD [5, 27], RCD [4] and dualaveraging [17]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "BPR (Rendle et al.[25]) O(|R|K) IALS1 (Pil\u00e1szy et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 13
                            }
                        ],
                        "text": "It learns by SGD, which can be adjusted to online incremental learning by [27]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10795036,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "db16e908246f32b60a6e0a8e27093aa145fbb1ed",
            "isKey": true,
            "numCitedBy": 3865,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Item recommendation is the task of predicting a personalized ranking on a set of items (e.g. websites, movies, products). In this paper, we investigate the most common scenario with implicit feedback (e.g. clicks, purchases). There are many methods for item recommendation from implicit feedback like matrix factorization (MF) or adaptive k-nearest-neighbor (kNN). Even though these methods are designed for the item prediction task of personalized ranking, none of them is directly optimized for ranking. In this paper we present a generic optimization criterion BPR-Opt for personalized ranking that is the maximum posterior estimator derived from a Bayesian analysis of the problem. We also provide a generic learning algorithm for optimizing models with respect to BPR-Opt. The learning method is based on stochastic gradient descent with bootstrap sampling. We show how to apply our method to two state-of-the-art recommender models: matrix factorization and adaptive kNN. Our experiments indicate that for the task of personalized ranking our optimization method outperforms the standard learning techniques for MF and kNN. The results show the importance of optimizing models for the right criterion."
            },
            "slug": "BPR:-Bayesian-Personalized-Ranking-from-Implicit-Rendle-Freudenthaler",
            "title": {
                "fragments": [],
                "text": "BPR: Bayesian Personalized Ranking from Implicit Feedback"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper presents a generic optimization criterion BPR-Opt for personalized ranking that is the maximum posterior estimator derived from a Bayesian analysis of the problem and provides a generic learning algorithm for optimizing models with respect to B PR-Opt."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2843982"
                        ],
                        "name": "Steffen Rendle",
                        "slug": "Steffen-Rendle",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Rendle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steffen Rendle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388781075"
                        ],
                        "name": "L. Schmidt-Thieme",
                        "slug": "L.-Schmidt-Thieme",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Schmidt-Thieme",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Schmidt-Thieme"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 145
                            }
                        ],
                        "text": "It is clear that the first term denotes the prediction error of the observed entries, which has been widely adopted in modeling explicit ratings [15, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 183
                            }
                        ],
                        "text": "As it is prohibitive to retrain the full model online, various works have developed incremental learning strategies for neighbor-based [13], graph-based [9], probabilistic [3] and MF [4, 5, 17, 27] methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 186
                            }
                        ],
                        "text": "Another key advantage of eALS is that it works without learning rate, bypassing the wellknown difficulty for tuning gradient descent methods such as [4] and Stochastic Gradient Descent (SGD) [25]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "In addition, the O(|R|K2) part is still much higher than in SGD [25], which only requires O(|R|K) time."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 55
                            }
                        ],
                        "text": "The most efficient algorithm is BPR, which applies the SGD learner on sampled, partial missing data only."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 104
                            }
                        ],
                        "text": "As the focus of this paper is on whole-data based implicit MF, we do not further explore the details of SGD."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "To optimize MF, various learners have been investigated, including SGD [14, 25], Coordinate Descent (CD) [4, 32], and Markov Chain Monto Carlo (MCMC) [26]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 44
                            }
                        ],
                        "text": "This is an advantage over the commonly-used SGD learner, which is a stochastic method that updates model parameters given a training instance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 47
                            }
                        ],
                        "text": "Early work on MF algorithms for recommendation [14, 27] have largely focused on explicit feedback, where users\u2019 ratings that directly reflect their preference on items are provided."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "SGD is the most popular one owing to the ease of derivation, however,\nit is unsuitable for whole-data based MF [12] due to the large amount of training instances (the full user\u2013item interaction matrix is considered)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In SGD, different gradient steps can influence with each other and there is no exact way to separate the updates for workers."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 37
                            }
                        ],
                        "text": "We suspect the reason comes from the SGD learner, which will result in more gradient steps on popular items, due to oversampling."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 80
                            }
                        ],
                        "text": "For MF, different learners have been studied for online updating, including SGD [5, 27], RCD [4] and dualaveraging [17]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": "It learns by SGD, which can be adjusted to online incremental learning by [27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5443538,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc431f385822efc00541b896cc83a0972e478e01",
            "isKey": true,
            "numCitedBy": 240,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Regularized matrix factorization models are known to generate high quality rating predictions for recommender systems. One of the major drawbacks of matrix factorization is that once computed, the model is static. For real-world applications dynamic updating a model is one of the most important tasks. Especially when ratings on new users or new items come in, updating the feature matrices is crucial.\n In this paper, we generalize regularized matrix factorization (RMF) to regularized kernel matrix factorization (RKMF). Kernels provide a flexible method for deriving new matrix factorization methods. Furthermore with kernels nonlinear interactions between feature vectors are possible. We propose a generic method for learning RKMF models. From this method we derive an online-update algorithm for RKMF models that allows to solve the new-user/new-item problem. Our evaluation indicates that our proposed online-update methods are accurate in approximating a full retrain of a RKMF model while the runtime of online-updating is in the range of milliseconds even for huge datasets like Netflix."
            },
            "slug": "Online-updating-regularized-kernel-matrix-models-Rendle-Schmidt-Thieme",
            "title": {
                "fragments": [],
                "text": "Online-updating regularized kernel matrix factorization models for large-scale recommender systems"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The evaluation indicates that the proposed online-update methods are accurate in approximating a full retrain of a RKMF model while the runtime of online-updating is in the range of milliseconds even for huge datasets like Netflix."
            },
            "venue": {
                "fragments": [],
                "text": "RecSys '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50819900"
                        ],
                        "name": "Yifan Hu",
                        "slug": "Yifan-Hu",
                        "structuredName": {
                            "firstName": "Yifan",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yifan Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701121"
                        ],
                        "name": "Y. Koren",
                        "slug": "Y.-Koren",
                        "structuredName": {
                            "firstName": "Yehuda",
                            "lastName": "Koren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Koren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3146362"
                        ],
                        "name": "C. Volinsky",
                        "slug": "C.-Volinsky",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Volinsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Volinsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 120
                            }
                        ],
                        "text": "It has been shown that modeling only the observed, positive feedback results in biased representations in user profiles [4, 12]; e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 167
                            }
                        ],
                        "text": "To solve the problem of lacking negative feedback (also known as the one-class problem [21]), a popular solution is to model all the missing data as negative feedback [12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 152
                            }
                        ],
                        "text": "We first introduce the whole-data based MF method for learning from implicit data, highlighting the inefficiency issue of the conventional ALS solution [12, 21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 145
                            }
                        ],
                        "text": "In particular, we assign the weight of missing data based on the popularity of items, which is arguably more effective than the previous methods [4, 12, 23, 30, 31] that are limited by the uniformity assumption."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": ", missing data) are assumed to be extraneous for modeling user preference [12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 95
                            }
                        ],
                        "text": "ALS can be seen as an instantiation of CD and has been widely used to solve the whole-based MF [12, 20, 21, 30]; however, its inefficiency is the main obstacle for practical use [23, 31]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 38
                            }
                        ],
                        "text": "For existing whole-data based methods [4, 12, 23, 30, 31], one major limitation is in the uniform weighting on missing entries, which favors algorithm\u2019s efficiency but limits model\u2019s flexibility and extensibility."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 160
                            }
                        ],
                        "text": "To this end, two strategies have been proposed \u2014 sample based learning [21, 25] that samples negative instances from missing data, or whole-data based learning [12, 30] that treats all missing data as negative."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "Our eALS algorithm is fast in accounting for missing data \u2014 analytically K times faster than ALS [12] where K denotes number of latent factors \u2014 the same time complexity with the recent dynamic MF solution [4]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 111
                            }
                        ],
                        "text": "SGD is the most popular one owing to the ease of derivation, however, it is unsuitable for whole-data based MF [12] due to the large amount of training instances (the full user\u2013item interaction matrix is considered)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10537313,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "184b7281a87ee16228b24716ca02b29519d52eb5",
            "isKey": true,
            "numCitedBy": 2749,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "A common task of recommender systems is to improve customer experience through personalized recommendations based on prior implicit feedback. These systems passively track different sorts of user behavior, such as purchase history, watching habits and browsing activity, in order to model user preferences. Unlike the much more extensively researched explicit feedback, we do not have any direct input from the users regarding their preferences. In particular, we lack substantial evidence on which products consumer dislike. In this work we identify unique properties of implicit feedback datasets. We propose treating the data as indication of positive and negative preference associated with vastly varying confidence levels. This leads to a factor model which is especially tailored for implicit feedback recommenders. We also suggest a scalable optimization procedure, which scales linearly with the data size. The algorithm is used successfully within a recommender system for television shows. It compares favorably with well tuned implementations of other known methods. In addition, we offer a novel way to give explanations to recommendations given by this factor model."
            },
            "slug": "Collaborative-Filtering-for-Implicit-Feedback-Hu-Koren",
            "title": {
                "fragments": [],
                "text": "Collaborative Filtering for Implicit Feedback Datasets"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work identifies unique properties of implicit feedback datasets and proposes treating the data as indication of positive and negative preference associated with vastly varying confidence levels, which leads to a factor model which is especially tailored for implicit feedback recommenders."
            },
            "venue": {
                "fragments": [],
                "text": "2008 Eighth IEEE International Conference on Data Mining"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2843982"
                        ],
                        "name": "Steffen Rendle",
                        "slug": "Steffen-Rendle",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Rendle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steffen Rendle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2382247"
                        ],
                        "name": "Zeno Gantner",
                        "slug": "Zeno-Gantner",
                        "structuredName": {
                            "firstName": "Zeno",
                            "lastName": "Gantner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zeno Gantner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1825333"
                        ],
                        "name": "C. Freudenthaler",
                        "slug": "C.-Freudenthaler",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Freudenthaler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Freudenthaler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388781075"
                        ],
                        "name": "L. Schmidt-Thieme",
                        "slug": "L.-Schmidt-Thieme",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Schmidt-Thieme",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Schmidt-Thieme"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 254,
                                "start": 250
                            }
                        ],
                        "text": "To make our method more applicable to real-world settings, we plan to encode side information such as user social contexts [8] and reviews [9] by extending eALS to more generic models, such as collective factorization [11] and Factorization machines [26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 150
                            }
                        ],
                        "text": "To optimize MF, various learners have been investigated, including SGD [14, 25], Coordinate Descent (CD) [4, 32], and Markov Chain Monto Carlo (MCMC) [26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 199
                            }
                        ],
                        "text": "Then, we develop a fast eALS algorithm to optimize the objective function that significantly reduces learning complexity comparing with the conventional ALS [12] and generic element-wise ALS learner [26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "Then we describe eALS, an element-wise ALS learner [26] that can reduce the time complexity to linearity w."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 149
                            }
                        ],
                        "text": "As such, it is natural to optimize parameters at the element level \u2014 optimizing each coordinate of the latent vector, while leaving the others fixed [26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "Moreover, by pre-computing r\u0302ui [26], we can calculate r\u0302 ui in O(1) time rather than O(K)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207189080,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1683ffc189d16b616131c300f45af87602d211f7",
            "isKey": true,
            "numCitedBy": 517,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The situation in which a choice is made is an important information for recommender systems. Context-aware recommenders take this information into account to make predictions. So far, the best performing method for context-aware rating prediction in terms of predictive accuracy is Multiverse Recommendation based on the Tucker tensor factorization model. However this method has two drawbacks: (1) its model complexity is exponential in the number of context variables and polynomial in the size of the factorization and (2) it only works for categorical context variables. On the other hand there is a large variety of fast but specialized recommender methods which lack the generality of context-aware methods. We propose to apply Factorization Machines (FMs) to model contextual information and to provide context-aware rating predictions. This approach results in fast context-aware recommendations because the model equation of FMs can be computed in linear time both in the number of context variables and the factorization size. For learning FMs, we develop an iterative optimization method that analytically finds the least-square solution for one parameter given the other ones. Finally, we show empirically that our approach outperforms Multiverse Recommendation in prediction quality and runtime."
            },
            "slug": "Fast-context-aware-recommendations-with-machines-Rendle-Gantner",
            "title": {
                "fragments": [],
                "text": "Fast context-aware recommendations with factorization machines"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This work proposes to apply Factorization Machines (FMs) to model contextual information and to provide context-aware rating predictions and shows empirically that this approach outperforms Multiverse Recommendation in prediction quality and runtime."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075336856"
                        ],
                        "name": "Xue Geng",
                        "slug": "Xue-Geng",
                        "structuredName": {
                            "firstName": "Xue",
                            "lastName": "Geng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xue Geng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5462268"
                        ],
                        "name": "Hanwang Zhang",
                        "slug": "Hanwang-Zhang",
                        "structuredName": {
                            "firstName": "Hanwang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanwang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35141826"
                        ],
                        "name": "Jingwen Bian",
                        "slug": "Jingwen-Bian",
                        "structuredName": {
                            "firstName": "Jingwen",
                            "lastName": "Bian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jingwen Bian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144078686"
                        ],
                        "name": "Tat-Seng Chua",
                        "slug": "Tat-Seng-Chua",
                        "structuredName": {
                            "firstName": "Tat-Seng",
                            "lastName": "Chua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tat-Seng Chua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 123
                            }
                        ],
                        "text": "To make our method more applicable to real-world settings, we plan to encode side information such as user social contexts [8] and reviews [9] by extending eALS to more generic models, such as collective factorization [11] and Factorization machines [26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1975342,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "15f5721502c2905c555a4eb0a110d6fc211c1fb2",
            "isKey": false,
            "numCitedBy": 141,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Good representations of data do help in many machine learning tasks such as recommendation. It is often a great challenge for traditional recommender systems to learn representative features of both users and images in large social networks, in particular, social curation networks, which are characterized as the extremely sparse links between users and images, and the extremely diverse visual contents of images. To address the challenges, we propose a novel deep model which learns the unified feature representations for both users and images. This is done by transforming the heterogeneous user-image networks into homogeneous low-dimensional representations, which facilitate a recommender to trivially recommend images to users by feature similarity. We also develop a fast online algorithm that can be easily scaled up to large networks in an asynchronously parallel way. We conduct extensive experiments on a representative subset of Pinterest, containing 1,456,540 images and 1,000,000 users. Results of image recommendation experiments demonstrate that our feature learning approach significantly outperforms other state-of-the-art recommendation methods."
            },
            "slug": "Learning-Image-and-User-Features-for-Recommendation-Geng-Zhang",
            "title": {
                "fragments": [],
                "text": "Learning Image and User Features for Recommendation in Social Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A novel deep model is proposed which learns the unified feature representations for both users and images by transforming the heterogeneous user-image networks into homogeneous low-dimensional representations, which facilitate a recommender to trivially recommend images to users by feature similarity."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE International Conference on Computer Vision (ICCV)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399601671"
                        ],
                        "name": "Ernesto Diaz-Aviles",
                        "slug": "Ernesto-Diaz-Aviles",
                        "structuredName": {
                            "firstName": "Ernesto",
                            "lastName": "Diaz-Aviles",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ernesto Diaz-Aviles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2282727"
                        ],
                        "name": "Lucas Drumond",
                        "slug": "Lucas-Drumond",
                        "structuredName": {
                            "firstName": "Lucas",
                            "lastName": "Drumond",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lucas Drumond"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388781075"
                        ],
                        "name": "L. Schmidt-Thieme",
                        "slug": "L.-Schmidt-Thieme",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Schmidt-Thieme",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Schmidt-Thieme"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744808"
                        ],
                        "name": "W. Nejdl",
                        "slug": "W.-Nejdl",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Nejdl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Nejdl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 183
                            }
                        ],
                        "text": "As it is prohibitive to retrain the full model online, various works have developed incremental learning strategies for neighbor-based [13], graph-based [9], probabilistic [3] and MF [4, 5, 17, 27] methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 186
                            }
                        ],
                        "text": "Another key advantage of eALS is that it works without learning rate, bypassing the wellknown difficulty for tuning gradient descent methods such as [4] and Stochastic Gradient Descent (SGD) [25]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "In addition, the O(|R|K2) part is still much higher than in SGD [25], which only requires O(|R|K) time."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 55
                            }
                        ],
                        "text": "The most efficient algorithm is BPR, which applies the SGD learner on sampled, partial missing data only."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 104
                            }
                        ],
                        "text": "As the focus of this paper is on whole-data based implicit MF, we do not further explore the details of SGD."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "To optimize MF, various learners have been investigated, including SGD [14, 25], Coordinate Descent (CD) [4, 32], and Markov Chain Monto Carlo (MCMC) [26]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 44
                            }
                        ],
                        "text": "This is an advantage over the commonly-used SGD learner, which is a stochastic method that updates model parameters given a training instance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "SGD is the most popular one owing to the ease of derivation, however,\nit is unsuitable for whole-data based MF [12] due to the large amount of training instances (the full user\u2013item interaction matrix is considered)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In SGD, different gradient steps can influence with each other and there is no exact way to separate the updates for workers."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 37
                            }
                        ],
                        "text": "We suspect the reason comes from the SGD learner, which will result in more gradient steps on popular items, due to oversampling."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 80
                            }
                        ],
                        "text": "For MF, different learners have been studied for online updating, including SGD [5, 27], RCD [4] and dualaveraging [17]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 13
                            }
                        ],
                        "text": "It learns by SGD, which can be adjusted to online incremental learning by [27]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14730257,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f1fc7a3e14003e196d2e4261035b299e448fa87",
            "isKey": true,
            "numCitedBy": 148,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "The Social Web is successfully established, and steadily growing in terms of users, content and services. People generate and consume data in real-time within social networking services, such as Twitter, and increasingly rely upon continuous streams of messages for real-time access to fresh knowledge about current affairs. In this paper, we focus on analyzing social streams in real-time for personalized topic recommendation and discovery. We consider collaborative filtering as an online ranking problem and present Stream Ranking Matrix Factorization - RMFX -, which uses a pairwise approach to matrix factorization in order to optimize the personalized ranking of topics. Our novel approach follows a selective sampling strategy to perform online model updates based on active learning principles, that closely simulates the task of identifying relevant items from a pool of mostly uninteresting ones. RMFX is particularly suitable for large scale applications and experiments on the \"476 million Twitter tweets\" dataset show that our online approach largely outperforms recommendations based on Twitter's global trend, and it is also able to deliver highly competitive Top-N recommendations faster while using less space than Weighted Regularized Matrix Factorization (WRMF), a state-of-the-art matrix factorization technique for Collaborative Filtering, demonstrating the efficacy of our approach."
            },
            "slug": "Real-time-top-n-recommendation-in-social-streams-Diaz-Aviles-Drumond",
            "title": {
                "fragments": [],
                "text": "Real-time top-n recommendation in social streams"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper focuses on analyzing social streams in real-time for personalized topic recommendation and discovery and presents Stream Ranking Matrix Factorization - RMFX, which uses a pairwise approach to matrix factorization in order to optimize the personalized ranking of topics."
            },
            "venue": {
                "fragments": [],
                "text": "RecSys '12"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701121"
                        ],
                        "name": "Y. Koren",
                        "slug": "Y.-Koren",
                        "structuredName": {
                            "firstName": "Yehuda",
                            "lastName": "Koren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Koren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113591957"
                        ],
                        "name": "Robert M. Bell",
                        "slug": "Robert-M.-Bell",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Bell",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert M. Bell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 161
                            }
                        ],
                        "text": "Among its various methods, matrix factorization (MF) is the most popular and effective technique that characterizes users and items by vectors of latent factors [15, 32]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 145
                            }
                        ],
                        "text": "It is clear that the first term denotes the prediction error of the observed entries, which has been widely adopted in modeling explicit ratings [15, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 108
                            }
                        ],
                        "text": "This greatly reduces the modeling workload, and many sophisticated methods have been devised, such as SVD++ [15] and timeSVD [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14698210,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "480ca76957e066eb6b24cd28df998d30310b4ced",
            "isKey": false,
            "numCitedBy": 1092,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "The collaborative filtering (CF) approach to recommenders has recently enjoyed much interest and progress. The fact that it played a central role within the recently completed Netflix competition has contributed to its popularity. This chapter surveys the recent progress in the field. Matrix factorization techniques, which became a first choice for implementing CF, are described together with recent innovations. We also describe several extensions that bring competitive accuracy into neighborhood methods, which used to dominate the field. The chapter demonstrates how to utilize temporal models and implicit feedback to extend models accuracy. In passing, we include detailed descriptions of some the central methods developed for tackling the challenge of the Netflix Prize competition."
            },
            "slug": "Advances-in-Collaborative-Filtering-Koren-Bell",
            "title": {
                "fragments": [],
                "text": "Advances in Collaborative Filtering"
            },
            "venue": {
                "fragments": [],
                "text": "Recommender Systems Handbook"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7792071"
                        ],
                        "name": "Xiangnan He",
                        "slug": "Xiangnan-He",
                        "structuredName": {
                            "firstName": "Xiangnan",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangnan He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144799987"
                        ],
                        "name": "Tao Chen",
                        "slug": "Tao-Chen",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37596605"
                        ],
                        "name": "Min-Yen Kan",
                        "slug": "Min-Yen-Kan",
                        "structuredName": {
                            "firstName": "Min-Yen",
                            "lastName": "Kan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Min-Yen Kan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145228898"
                        ],
                        "name": "Xiao Chen",
                        "slug": "Xiao-Chen",
                        "structuredName": {
                            "firstName": "Xiao",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiao Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 117
                            }
                        ],
                        "text": "HR measures whether the ground truth item is present on the ranked list, while NDCG accounts for the position of hit [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 67
                            }
                        ],
                        "text": "Although it is a widely used evaluation protocol in the literature [9, 25], we point out that it is an artificial split that does not correspond to the real recommendation scenario."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 139
                            }
                        ],
                        "text": "To make our method more applicable to real-world settings, we plan to encode side information such as user social contexts [8] and reviews [9] by extending eALS to more generic models, such as collective factorization [11] and Factorization machines [26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 153
                            }
                        ],
                        "text": "As it is prohibitive to retrain the full model online, various works have developed incremental learning strategies for neighbor-based [13], graph-based [9], probabilistic [3] and MF [4, 5, 17, 27] methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2023519,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "676c4dfdc8782c2cc5157f5bd5e1c1e39dd732a3",
            "isKey": false,
            "numCitedBy": 363,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Most existing collaborative filtering techniques have focused on modeling the binary relation of users to items by extracting from user ratings. Aside from users' ratings, their affiliated reviews often provide the rationale for their ratings and identify what aspects of the item they cared most about. We explore the rich evidence source of aspects in user reviews to improve top-N recommendation. By extracting aspects (i.e., the specific properties of items) from textual reviews, we enrich the user--item binary relation to a user--item--aspect ternary relation. We model the ternary relation as a heterogeneous tripartite graph, casting the recommendation task as one of vertex ranking. We devise a generic algorithm for ranking on tripartite graphs -- TriRank -- and specialize it for personalized recommendation. Experiments on two public review datasets show that it consistently outperforms state-of-the-art methods. Most importantly, TriRank endows the recommender system with a higher degree of explainability and transparency by modeling aspects in reviews. It allows users to interact with the system through their aspect preferences, assisting users in making informed decisions."
            },
            "slug": "TriRank:-Review-aware-Explainable-Recommendation-by-He-Chen",
            "title": {
                "fragments": [],
                "text": "TriRank: Review-aware Explainable Recommendation by Modeling Aspects"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "TriRank endows the recommender system with a higher degree of explainability and transparency by modeling aspects in reviews, and allows users to interact with the system through their aspect preferences, assisting users in making informed decisions."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777107"
                        ],
                        "name": "Rainer Gemulla",
                        "slug": "Rainer-Gemulla",
                        "structuredName": {
                            "firstName": "Rainer",
                            "lastName": "Gemulla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rainer Gemulla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2043490"
                        ],
                        "name": "Erik Nijkamp",
                        "slug": "Erik-Nijkamp",
                        "structuredName": {
                            "firstName": "Erik",
                            "lastName": "Nijkamp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Erik Nijkamp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37810307"
                        ],
                        "name": "P. Haas",
                        "slug": "P.-Haas",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Haas",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2037842"
                        ],
                        "name": "Yannis Sismanis",
                        "slug": "Yannis-Sismanis",
                        "structuredName": {
                            "firstName": "Yannis",
                            "lastName": "Sismanis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yannis Sismanis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 105
                            }
                        ],
                        "text": "Thus, sophisticated strategies are required to control the possible losses introduced by parallelization [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207189532,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e8d8f8e7cad53725aa0eb255e28124aab6b4d64b",
            "isKey": false,
            "numCitedBy": 671,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "We provide a novel algorithm to approximately factor large matrices with millions of rows, millions of columns, and billions of nonzero elements. Our approach rests on stochastic gradient descent (SGD), an iterative stochastic optimization algorithm. We first develop a novel \"stratified\" SGD variant (SSGD) that applies to general loss-minimization problems in which the loss function can be expressed as a weighted sum of \"stratum losses.\" We establish sufficient conditions for convergence of SSGD using results from stochastic approximation theory and regenerative process theory. We then specialize SSGD to obtain a new matrix-factorization algorithm, called DSGD, that can be fully distributed and run on web-scale datasets using, e.g., MapReduce. DSGD can handle a wide variety of matrix factorizations. We describe the practical techniques used to optimize performance in our DSGD implementation. Experiments suggest that DSGD converges significantly faster and has better scalability properties than alternative algorithms."
            },
            "slug": "Large-scale-matrix-factorization-with-distributed-Gemulla-Nijkamp",
            "title": {
                "fragments": [],
                "text": "Large-scale matrix factorization with distributed stochastic gradient descent"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A novel algorithm to approximately factor large matrices with millions of rows, millions of columns, and billions of nonzero elements, called DSGD, that can be fully distributed and run on web-scale datasets using, e.g., MapReduce."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5462268"
                        ],
                        "name": "Hanwang Zhang",
                        "slug": "Hanwang-Zhang",
                        "structuredName": {
                            "firstName": "Hanwang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanwang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144618699"
                        ],
                        "name": "Fumin Shen",
                        "slug": "Fumin-Shen",
                        "structuredName": {
                            "firstName": "Fumin",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fumin Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46641573"
                        ],
                        "name": "W. Liu",
                        "slug": "W.-Liu",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7792071"
                        ],
                        "name": "Xiangnan He",
                        "slug": "Xiangnan-He",
                        "structuredName": {
                            "firstName": "Xiangnan",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangnan He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3371599"
                        ],
                        "name": "Huanbo Luan",
                        "slug": "Huanbo-Luan",
                        "structuredName": {
                            "firstName": "Huanbo",
                            "lastName": "Luan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huanbo Luan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144078686"
                        ],
                        "name": "Tat-Seng Chua",
                        "slug": "Tat-Seng-Chua",
                        "structuredName": {
                            "firstName": "Tat-Seng",
                            "lastName": "Chua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tat-Seng Chua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 161
                            }
                        ],
                        "text": "Among its various methods, matrix factorization (MF) is the most popular and effective technique that characterizes users and items by vectors of latent factors [15, 32]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 105
                            }
                        ],
                        "text": "To optimize MF, various learners have been investigated, including SGD [14, 25], Coordinate Descent (CD) [4, 32], and Markov Chain Monto Carlo (MCMC) [26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "In addition, we will study binary coding for MF on implicit data, since a recent advance [32] has shown that discrete latent factors are beneficial to collaborative filtering for explicit ratings."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13124023,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b526b9b39046d3661160256153a5b602166f316a",
            "isKey": false,
            "numCitedBy": 217,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the efficiency problem of Collaborative Filtering (CF) by hashing users and items as latent vectors in the form of binary codes, so that user-item affinity can be efficiently calculated in a Hamming space. However, existing hashing methods for CF employ binary code learning procedures that most suffer from the challenging discrete constraints. Hence, those methods generally adopt a two-stage learning scheme composed of relaxed optimization via discarding the discrete constraints, followed by binary quantization. We argue that such a scheme will result in a large quantization loss, which especially compromises the performance of large-scale CF that resorts to longer binary codes. In this paper, we propose a principled CF hashing framework called Discrete Collaborative Filtering (DCF), which directly tackles the challenging discrete optimization that should have been treated adequately in hashing. The formulation of DCF has two advantages: 1) the Hamming similarity induced loss that preserves the intrinsic user-item similarity, and 2) the balanced and uncorrelated code constraints that yield compact yet informative binary codes. We devise a computationally efficient algorithm with a rigorous convergence proof of DCF. Through extensive experiments on several real-world benchmarks, we show that DCF consistently outperforms state-of-the-art CF hashing techniques, e.g, though using only 8 bits, DCF is even significantly better than other methods using 128 bits."
            },
            "slug": "Discrete-Collaborative-Filtering-Zhang-Shen",
            "title": {
                "fragments": [],
                "text": "Discrete Collaborative Filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes a principled CF hashing framework called Discrete Collaborative Filtering (DCF), which directly tackles the challenging discrete optimization that should have been treated adequately in hashing, and devise a computationally efficient algorithm with a rigorous convergence proof of DCF."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7792071"
                        ],
                        "name": "Xiangnan He",
                        "slug": "Xiangnan-He",
                        "structuredName": {
                            "firstName": "Xiangnan",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangnan He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46572901"
                        ],
                        "name": "Ming Gao",
                        "slug": "Ming-Gao",
                        "structuredName": {
                            "firstName": "Ming",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37596605"
                        ],
                        "name": "Min-Yen Kan",
                        "slug": "Min-Yen-Kan",
                        "structuredName": {
                            "firstName": "Min-Yen",
                            "lastName": "Kan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Min-Yen Kan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783406"
                        ],
                        "name": "Yiqun Liu",
                        "slug": "Yiqun-Liu",
                        "structuredName": {
                            "firstName": "Yiqun",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiqun Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3060386"
                        ],
                        "name": "Kazunari Sugiyama",
                        "slug": "Kazunari-Sugiyama",
                        "structuredName": {
                            "firstName": "Kazunari",
                            "lastName": "Sugiyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kazunari Sugiyama"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 893103,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b1d4273d1c967c10680aca02deebb125243b713",
            "isKey": false,
            "numCitedBy": 97,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "In the current Web 2.0 era, the popularity of Web resources fluctuates ephemerally, based on trends and social interest. As a result, content-based relevance signals are insufficient to meet users' constantly evolving information needs in searching for Web 2.0 items. Incorporating future popularity into ranking is one way to counter this. However, predicting popularity as a third party (as in the case of general search engines) is difficult in practice, due to their limited access to item view histories. To enable popularity prediction externally without excessive crawling, we propose an alternative solution by leveraging user comments, which are more accessible than view counts. Due to the sparsity of comments, traditional solutions that are solely based on view histories do not perform well. To deal with this sparsity, we mine comments to recover additional signal, such as social influence. By modeling comments as a time-aware bipartite graph, we propose a regularization-based ranking algorithm that accounts for temporal, social influence and current popularity factors to predict the future popularity of items. Experimental results on three real-world datasets --- crawled from YouTube, Flickr and Last.fm --- show that our method consistently outperforms competitive baselines in several evaluation tasks."
            },
            "slug": "Predicting-the-popularity-of-web-2.0-items-based-on-He-Gao",
            "title": {
                "fragments": [],
                "text": "Predicting the popularity of web 2.0 items based on user comments"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "By modeling comments as a time-aware bipartite graph, this work proposes a regularization-based ranking algorithm that accounts for temporal, social influence and current popularity factors to predict the future popularity of items."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2454529"
                        ],
                        "name": "H. Steck",
                        "slug": "H.-Steck",
                        "structuredName": {
                            "firstName": "Harald",
                            "lastName": "Steck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Steck"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 28
                            }
                        ],
                        "text": "To this end, existing works [4, 12, 23, 30, 31] have applied a simple uniform weight on missing entries, which are, however, suboptimal and non-extendable for real applications."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 145
                            }
                        ],
                        "text": "In particular, we assign the weight of missing data based on the popularity of items, which is arguably more effective than the previous methods [4, 12, 23, 30, 31] that are limited by the uniformity assumption."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 95
                            }
                        ],
                        "text": "ALS can be seen as an instantiation of CD and has been widely used to solve the whole-based MF [12, 20, 21, 30]; however, its inefficiency is the main obstacle for practical use [23, 31]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 38
                            }
                        ],
                        "text": "For existing whole-data based methods [4, 12, 23, 30, 31], one major limitation is in the uniform weighting on missing entries, which favors algorithm\u2019s efficiency but limits model\u2019s flexibility and extensibility."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 160
                            }
                        ],
                        "text": "To this end, two strategies have been proposed \u2014 sample based learning [21, 25] that samples negative instances from missing data, or whole-data based learning [12, 30] that treats all missing data as negative."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3355517,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f0636bad1e8d3c1a19894d1995b03b26bf6033f1",
            "isKey": true,
            "numCitedBy": 299,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Users typically rate only a small fraction of all available items. We show that the absence of ratings carries useful information for improving the top-k hit rate concerning all items, a natural accuracy measure for recommendations. As to test recommender systems, we present two performance measures that can be estimated, under mild assumptions, without bias from data even when ratings are missing not at random (MNAR). As to achieve optimal test results, we present appropriate surrogate objective functions for efficient training on MNAR data. Their main property is to account for all ratings - whether observed or missing in the data. Concerning the top-k hit rate on test data, our experiments indicate dramatic improvements over even sophisticated methods that are optimized on observed ratings only."
            },
            "slug": "Training-and-testing-of-recommender-systems-on-data-Steck",
            "title": {
                "fragments": [],
                "text": "Training and testing of recommender systems on data missing not at random"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "It is shown that the absence of ratings carries useful information for improving the top-k hit rate concerning all items, a natural accuracy measure for recommendations, and two performance measures can be estimated, under mild assumptions, without bias from data even when ratings are missing not at random (MNAR)."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709519"
                        ],
                        "name": "P. Cremonesi",
                        "slug": "P.-Cremonesi",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Cremonesi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cremonesi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701121"
                        ],
                        "name": "Y. Koren",
                        "slug": "Y.-Koren",
                        "structuredName": {
                            "firstName": "Yehuda",
                            "lastName": "Koren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Koren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2541923"
                        ],
                        "name": "R. Turrin",
                        "slug": "R.-Turrin",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Turrin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Turrin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 24
                            }
                        ],
                        "text": "This is consistent with [2]\u2019s finding in evaluating top-K recommendation."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 68
                            }
                        ],
                        "text": "Based on this observation, we believe the traditional SVD technique [2] that treats all entries equally weighted will be suboptimal here."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17638609,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5fdc3c0b2049a025091179a73e0e4174105fcd4",
            "isKey": false,
            "numCitedBy": 1297,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In many commercial systems, the 'best bet' recommendations are shown, but the predicted rating values are not. This is usually referred to as a top-N recommendation task, where the goal of the recommender system is to find a few specific items which are supposed to be most appealing to the user. Common methodologies based on error metrics (such as RMSE) are not a natural fit for evaluating the top-N recommendation task. Rather, top-N performance can be directly measured by alternative methodologies based on accuracy metrics (such as precision/recall).\n An extensive evaluation of several state-of-the art recommender algorithms suggests that algorithms optimized for minimizing RMSE do not necessarily perform as expected in terms of top-N recommendation task. Results show that improvements in RMSE often do not translate into accuracy improvements. In particular, a naive non-personalized algorithm can outperform some common recommendation approaches and almost match the accuracy of sophisticated algorithms. Another finding is that the very few top popular items can skew the top-N performance. The analysis points out that when evaluating a recommender algorithm on the top-N recommendation task, the test set should be chosen carefully in order to not bias accuracy metrics towards non-personalized solutions. Finally, we offer practitioners new variants of two collaborative filtering algorithms that, regardless of their RMSE, significantly outperform other recommender algorithms in pursuing the top-N recommendation task, with offering additional practical advantages. This comes at surprise given the simplicity of these two methods."
            },
            "slug": "Performance-of-recommender-algorithms-on-top-n-Cremonesi-Koren",
            "title": {
                "fragments": [],
                "text": "Performance of recommender algorithms on top-n recommendation tasks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "An extensive evaluation of several state-of-the art recommender algorithms suggests that algorithms optimized for minimizing RMSE do not necessarily perform as expected in terms of top-N recommendation task, and new variants of two collaborative filtering algorithms are offered."
            },
            "venue": {
                "fragments": [],
                "text": "RecSys '10"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066007146"
                        ],
                        "name": "Rong Pan",
                        "slug": "Rong-Pan",
                        "structuredName": {
                            "firstName": "Rong",
                            "lastName": "Pan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rong Pan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118116274"
                        ],
                        "name": "Yunhong Zhou",
                        "slug": "Yunhong-Zhou",
                        "structuredName": {
                            "firstName": "Yunhong",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yunhong Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144948990"
                        ],
                        "name": "Bin Cao",
                        "slug": "Bin-Cao",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "Cao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bin Cao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768416"
                        ],
                        "name": "N. Liu",
                        "slug": "N.-Liu",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Liu",
                            "middleNames": [
                                "Nan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777845"
                        ],
                        "name": "R. Lukose",
                        "slug": "R.-Lukose",
                        "structuredName": {
                            "firstName": "Rajan",
                            "lastName": "Lukose",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lukose"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144362899"
                        ],
                        "name": "Martin Scholz",
                        "slug": "Martin-Scholz",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Scholz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin Scholz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 87
                            }
                        ],
                        "text": "To solve the problem of lacking negative feedback (also known as the one-class problem [21]), a popular solution is to model all the missing data as negative feedback [12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "[20, 21]; however their cubic time complexity w."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 152
                            }
                        ],
                        "text": "We first introduce the whole-data based MF method for learning from implicit data, highlighting the inefficiency issue of the conventional ALS solution [12, 21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 35
                            }
                        ],
                        "text": "Comparing with the vector-wise ALS [12, 21], our elementwise ALS learner is K times faster."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 95
                            }
                        ],
                        "text": "ALS can be seen as an instantiation of CD and has been widely used to solve the whole-based MF [12, 20, 21, 30]; however, its inefficiency is the main obstacle for practical use [23, 31]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 71
                            }
                        ],
                        "text": "To this end, two strategies have been proposed \u2014 sample based learning [21, 25] that samples negative instances from missing data, or whole-data based learning [12, 30] that treats all missing data as negative."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7369746,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "109de4531e279681919f7330f01b532a7201e4b9",
            "isKey": true,
            "numCitedBy": 935,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Many applications of collaborative filtering (CF), such as news item recommendation and bookmark recommendation, are most naturally thought of as one-class collaborative filtering (OCCF) problems. In these problems, the training data usually consist simply of binary data reflecting a user's action or inaction, such as page visitation in the case of news item recommendation or webpage bookmarking in the bookmarking scenario. Usually this kind of data are extremely sparse (a small fraction are positive examples), therefore ambiguity arises in the interpretation of the non-positive examples. Negative examples and unlabeled positive examples are mixed together and we are typically unable to distinguish them. For example, we cannot really attribute a user not bookmarking a page to a lack of interest or lack of awareness of the page. Previous research addressing this one-class problem only considered it as a classification task. In this paper, we consider the one-class problem under the CF setting. We propose two frameworks to tackle OCCF. One is based on weighted low rank approximation; the other is based on negative example sampling. The experimental results show that our approaches significantly outperform the baselines."
            },
            "slug": "One-Class-Collaborative-Filtering-Pan-Zhou",
            "title": {
                "fragments": [],
                "text": "One-Class Collaborative Filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper considers the one-class problem under the CF setting, and proposes two frameworks to tackle OCCF, one based on weighted low rank approximation; the other based on negative example sampling."
            },
            "venue": {
                "fragments": [],
                "text": "2008 Eighth IEEE International Conference on Data Mining"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805742"
                        ],
                        "name": "Benjamin M Marlin",
                        "slug": "Benjamin-M-Marlin",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Marlin",
                            "middleNames": [
                                "M"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin M Marlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804104"
                        ],
                        "name": "R. Zemel",
                        "slug": "R.-Zemel",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zemel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zemel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9330607"
                        ],
                        "name": "S. Roweis",
                        "slug": "S.-Roweis",
                        "structuredName": {
                            "firstName": "Sam",
                            "lastName": "Roweis",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roweis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145290352"
                        ],
                        "name": "M. Slaney",
                        "slug": "M.-Slaney",
                        "structuredName": {
                            "firstName": "Malcolm",
                            "lastName": "Slaney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Slaney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[18] finds that users listen to music they expect to like and avoid the genres they dislike, leading to a severe bias in the observed data."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9024470,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fee5bc9a391816be11c52b8559d62ea397bff90f",
            "isKey": false,
            "numCitedBy": 261,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Rating prediction is an important application, and a popular research topic in collaborative filtering. However, both the validity of learning algorithms, and the validity of standard testing procedures rest on the assumption that missing ratings are missing at random (MAR). In this paper we present the results of a user study in which we collect a random sample of ratings from current users of an online radio service. An analysis of the rating data collected in the study shows that the sample of random ratings has markedly different properties than ratings of user-selected songs. When asked to report on their own rating behaviour, a large number of users indicate they believe their opinion of a song does affect whether they choose to rate that song, a violation of the MAR condition. Finally, we present experimental results showing that incorporating an explicit model of the missing data mechanism can lead to significant improvements in prediction performance on the random sample of ratings."
            },
            "slug": "Collaborative-Filtering-and-the-Missing-at-Random-Marlin-Zemel",
            "title": {
                "fragments": [],
                "text": "Collaborative Filtering and the Missing at Random Assumption"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Experimental results are presented showing that incorporating an explicit model of the missing data mechanism can lead to significant improvements in prediction performance on the random sample of ratings."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7792071"
                        ],
                        "name": "Xiangnan He",
                        "slug": "Xiangnan-He",
                        "structuredName": {
                            "firstName": "Xiangnan",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangnan He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37596605"
                        ],
                        "name": "Min-Yen Kan",
                        "slug": "Min-Yen-Kan",
                        "structuredName": {
                            "firstName": "Min-Yen",
                            "lastName": "Kan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Min-Yen Kan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2586395"
                        ],
                        "name": "Peichu Xie",
                        "slug": "Peichu-Xie",
                        "structuredName": {
                            "firstName": "Peichu",
                            "lastName": "Xie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peichu Xie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145228898"
                        ],
                        "name": "Xiao Chen",
                        "slug": "Xiao-Chen",
                        "structuredName": {
                            "firstName": "Xiao",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiao Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 222,
                                "start": 218
                            }
                        ],
                        "text": "To make our method more applicable to real-world settings, we plan to encode side information such as user social contexts [8] and reviews [9] by extending eALS to more generic models, such as collective factorization [11] and Factorization machines [26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2989432,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7296b5b22b839836d8c226f049131eef1dc0d95",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Clustering Web 2.0 items (i.e., web resources like videos, images) into semantic groups benefits many applications, such as organizing items, generating meaningful tags and improving web search. In this paper, we systematically investigate how user-generated comments can be used to improve the clustering of Web 2.0 items. In our preliminary study of Last.fm, we find that the two data sources extracted from user comments -- the textual comments and the commenting users -- provide complementary evidence to the items' intrinsic features. These sources have varying levels of quality, but we importantly we find that incorporating all three sources improves clustering. To accommodate such quality imbalance, we invoke multi-view clustering, in which each data source represents a view, aiming to best leverage the utility of different views. To combine multiple views under a principled framework, we propose CoNMF (Co-regularized Non-negative Matrix Factorization), which extends NMF for multi-view clustering by jointly factorizing the multiple matrices through co-regularization. Under our CoNMF framework, we devise two paradigms -- pair-wise CoNMF and cluster-wise CoNMF -- and propose iterative algorithms for their joint factorization. Experimental results on Last.fm and Yelp datasets demonstrate the effectiveness of our solution. In Last.fm, CoNMF betters k-means with a statistically significant F1 increase of 14%, while achieving comparable performance with the state-of-the-art multi-view clustering method CoSC (Co-regularized Spectral Clustering). On a Yelp dataset, CoNMF outperforms the best baseline CoSC with a statistically significant performance gain of 7%."
            },
            "slug": "Comment-based-multi-view-clustering-of-web-2.0-He-Kan",
            "title": {
                "fragments": [],
                "text": "Comment-based multi-view clustering of web 2.0 items"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper systematically investigates how user-generated comments can be used to improve the clustering of Web 2.0 items and proposes CoNMF (Co-regularized Non-negative Matrix Factorization), which extends NMF for multi-view clustering by jointly factorizing the multiple matrices through co-regularization."
            },
            "venue": {
                "fragments": [],
                "text": "WWW"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5462268"
                        ],
                        "name": "Hanwang Zhang",
                        "slug": "Hanwang-Zhang",
                        "structuredName": {
                            "firstName": "Hanwang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanwang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143962510"
                        ],
                        "name": "Zhengjun Zha",
                        "slug": "Zhengjun-Zha",
                        "structuredName": {
                            "firstName": "Zhengjun",
                            "lastName": "Zha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhengjun Zha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143653681"
                        ],
                        "name": "Shuicheng Yan",
                        "slug": "Shuicheng-Yan",
                        "structuredName": {
                            "firstName": "Shuicheng",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuicheng Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146058320"
                        ],
                        "name": "Meng Wang",
                        "slug": "Meng-Wang",
                        "structuredName": {
                            "firstName": "Meng",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Meng Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144078686"
                        ],
                        "name": "Tat-Seng Chua",
                        "slug": "Tat-Seng-Chua",
                        "structuredName": {
                            "firstName": "Tat-Seng",
                            "lastName": "Chua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tat-Seng Chua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11474314,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "81c6c5470b16a876c75d00d2743dda16cadc5fb9",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Non-negative data factorization has been widely used recently. However, existing techniques, such as Non-negative Graph Embedding (NGE), often suffer from noisy data, unreliable graphs, and noisy labels, which are commonly encountered in real-world applications. To address these issues, in this paper, we propose a Robust Non-negative Graph Embedding (RNGE) framework. The joint sparsity in both graph embedding and reconstruction endues the robustness of RNGE. We develop an elegant multiplicative updating solution that can solve RNGE efficiently and prove the convergence rigourously. RNGE is robust to unreliable graphs, as well as both sample and label noises in training data. Moreover, RNGE provides a general formulation such that all the algorithms unified with the graph embedding framework can be easily extended to obtain their robust non-negative solutions. We conduct extensive experiments on four real-world datasets and compared the proposed RNGE to NGE and other representative non-negative data factorization and subspace learning methods. The experimental results demonstrate the effectiveness and robustness of RNGE."
            },
            "slug": "Robust-Non-negative-Graph-Embedding:-Towards-noisy-Zhang-Zha",
            "title": {
                "fragments": [],
                "text": "Robust Non-negative Graph Embedding: Towards noisy data, unreliable graphs, and noisy labels"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper develops an elegant multiplicative updating solution that can solve RNGE efficiently and prove the convergence rigourously and provides a general formulation such that all the algorithms unified with the graph embedding framework can be easily extended to obtain their robust non-negative solutions."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734693"
                        ],
                        "name": "John C. Duchi",
                        "slug": "John-C.-Duchi",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Duchi",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Duchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34840427"
                        ],
                        "name": "Elad Hazan",
                        "slug": "Elad-Hazan",
                        "structuredName": {
                            "firstName": "Elad",
                            "lastName": "Hazan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elad Hazan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 102
                            }
                        ],
                        "text": "To resolve this, tricks like subsampling frequent items [19] and adaptive learning rates like Adagrad [6] have been adopted in other domains."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 538820,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "413c1142de9d91804d6d11c67ff3fed59c9fc279",
            "isKey": false,
            "numCitedBy": 8368,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to find needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efficient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms."
            },
            "slug": "Adaptive-Subgradient-Methods-for-Online-Learning-Duchi-Hazan",
            "title": {
                "fragments": [],
                "text": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work describes and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies setting a learning rate and results in regret guarantees that are provably as good as the best proximal functions that can be chosen in hindsight."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2892654"
                        ],
                        "name": "Abhinandan Das",
                        "slug": "Abhinandan-Das",
                        "structuredName": {
                            "firstName": "Abhinandan",
                            "lastName": "Das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abhinandan Das"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145112445"
                        ],
                        "name": "Mayur Datar",
                        "slug": "Mayur-Datar",
                        "structuredName": {
                            "firstName": "Mayur",
                            "lastName": "Datar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mayur Datar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729828"
                        ],
                        "name": "A. Garg",
                        "slug": "A.-Garg",
                        "structuredName": {
                            "firstName": "Ashutosh",
                            "lastName": "Garg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Garg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153085314"
                        ],
                        "name": "S. Rajaram",
                        "slug": "S.-Rajaram",
                        "structuredName": {
                            "firstName": "Shyamsundar",
                            "lastName": "Rajaram",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Rajaram"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 172
                            }
                        ],
                        "text": "As it is prohibitive to retrain the full model online, various works have developed incremental learning strategies for neighbor-based [13], graph-based [9], probabilistic [3] and MF [4, 5, 17, 27] methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207163129,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e104b1968b9ec09af0f6b480a46fc1ce884c3bc",
            "isKey": false,
            "numCitedBy": 1649,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Several approaches to collaborative filtering have been studied but seldom have studies been reported for large (several millionusers and items) and dynamic (the underlying item set is continually changing) settings. In this paper we describe our approach to collaborative filtering for generating personalized recommendations for users of Google News. We generate recommendations using three approaches: collaborative filtering using MinHash clustering, Probabilistic Latent Semantic Indexing (PLSI), and covisitation counts. We combine recommendations from different algorithms using a linear model. Our approach is content agnostic and consequently domain independent, making it easily adaptable for other applications and languages with minimal effort. This paper will describe our algorithms and system setup in detail, and report results of running the recommendations engine on Google News."
            },
            "slug": "Google-news-personalization:-scalable-online-Das-Datar",
            "title": {
                "fragments": [],
                "text": "Google news personalization: scalable online collaborative filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper describes the approach to collaborative filtering for generating personalized recommendations for users of Google News using MinHash clustering, Probabilistic Latent Semantic Indexing, and covisitation counts, and combines recommendations from different algorithms using a linear model."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701121"
                        ],
                        "name": "Y. Koren",
                        "slug": "Y.-Koren",
                        "structuredName": {
                            "firstName": "Yehuda",
                            "lastName": "Koren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Koren"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 186
                            }
                        ],
                        "text": "Another key advantage of eALS is that it works without learning rate, bypassing the wellknown difficulty for tuning gradient descent methods such as [4] and Stochastic Gradient Descent (SGD) [25]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "In addition, the O(|R|K2) part is still much higher than in SGD [25], which only requires O(|R|K) time."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 55
                            }
                        ],
                        "text": "The most efficient algorithm is BPR, which applies the SGD learner on sampled, partial missing data only."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 104
                            }
                        ],
                        "text": "As the focus of this paper is on whole-data based implicit MF, we do not further explore the details of SGD."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 71
                            }
                        ],
                        "text": "To optimize MF, various learners have been investigated, including SGD [14, 25], Coordinate Descent (CD) [4, 32], and Markov Chain Monto Carlo (MCMC) [26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 44
                            }
                        ],
                        "text": "This is an advantage over the commonly-used SGD learner, which is a stochastic method that updates model parameters given a training instance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 47
                            }
                        ],
                        "text": "Early work on MF algorithms for recommendation [14, 27] have largely focused on explicit feedback, where users\u2019 ratings that directly reflect their preference on items are provided."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "SGD is the most popular one owing to the ease of derivation, however,\nit is unsuitable for whole-data based MF [12] due to the large amount of training instances (the full user\u2013item interaction matrix is considered)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In SGD, different gradient steps can influence with each other and there is no exact way to separate the updates for workers."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 125
                            }
                        ],
                        "text": "This greatly reduces the modeling workload, and many sophisticated methods have been devised, such as SVD++ [15] and timeSVD [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 37
                            }
                        ],
                        "text": "We suspect the reason comes from the SGD learner, which will result in more gradient steps on popular items, due to oversampling."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 50
                            }
                        ],
                        "text": "Note that this basic model subsumes the biased MF [14], commonly used in modeling explicit ratings:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 76
                            }
                        ],
                        "text": "For MF, different learners have been studied for online updating, including SGD [5, 27], RCD [4] and dualaveraging [17]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 13
                            }
                        ],
                        "text": "It learns by SGD, which can be adjusted to online incremental learning by [27]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 3022077,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c1aa28159e768b75d0f4637a71d20da02efe1ef2",
            "isKey": true,
            "numCitedBy": 1668,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Customer preferences for products are drifting over time. Product perception and popularity are constantly changing as new selection emerges. Similarly, customer inclinations are evolving, leading them to ever redefine their taste. Thus, modeling temporal dynamics should be a key when designing recommender systems or general customer preference models. However, this raises unique challenges. Within the eco-system intersecting multiple products and customers, many different characteristics are shifting simultaneously, while many of them influence each other and often those shifts are delicate and associated with a few data instances. This distinguishes the problem from concept drift explorations, where mostly a single concept is tracked. Classical time-window or instance-decay approaches cannot work, as they lose too much signal when discarding data instances. A more sensitive approach is required, which can make better distinctions between transient effects and long term patterns. The paradigm we offer is creating a model tracking the time changing behavior throughout the life span of the data. This allows us to exploit the relevant components of all data instances, while discarding only what is modeled as being irrelevant. Accordingly, we revamp two leading collaborative filtering recommendation approaches. Evaluation is made on a large movie rating dataset by Netflix. Results are encouraging and better than those previously reported on this dataset."
            },
            "slug": "Collaborative-filtering-with-temporal-dynamics-Koren",
            "title": {
                "fragments": [],
                "text": "Collaborative filtering with temporal dynamics"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Two leading collaborative filtering recommendation approaches are revamp and a more sensitive approach is required, which can make better distinctions between transient effects and long term patterns."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145432804"
                        ],
                        "name": "Yanxiang Huang",
                        "slug": "Yanxiang-Huang",
                        "structuredName": {
                            "firstName": "Yanxiang",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yanxiang Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144585959"
                        ],
                        "name": "B. Cui",
                        "slug": "B.-Cui",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "Cui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Cui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108348160"
                        ],
                        "name": "Wenyu Zhang",
                        "slug": "Wenyu-Zhang",
                        "structuredName": {
                            "firstName": "Wenyu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenyu Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107911966"
                        ],
                        "name": "Jie Jiang",
                        "slug": "Jie-Jiang",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145206237"
                        ],
                        "name": "Ying Xu",
                        "slug": "Ying-Xu",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ying Xu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 135
                            }
                        ],
                        "text": "As it is prohibitive to retrain the full model online, various works have developed incremental learning strategies for neighbor-based [13], graph-based [9], probabilistic [3] and MF [4, 5, 17, 27] methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 997171,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0cc9fec29996cdc2a288883f8aba4423ab2f90fa",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "With the arrival of the big data era, opportunities as well as challenges arise in both industry and academia. As an important service in most web applications, accurate real-time recommendation in the context of big data is of high demand. Traditional recommender systems that analyze data and update models at regular time intervals cannot satisfy the requirements of modern web applications, calling for real-time recommender systems. In this paper, we tackle the ``big\", ``real-time\" and ``accurate\" challenges in real-time recommendation, and propose a general real-time stream recommender system built on Storm named TencentRec from three aspects, i.e., ``system\", ``algorithm\", and ``data\". We analyze the large amount of data streams from a wide range of applications leveraging the considerable computation ability of Storm, together with a data access component and a data storage component developed by us. To deal with various application specific demands, we have implemented several classic practical recommendation algorithms in TencentRec, including the item-based collaborative filtering, the content based, and the demographic based algorithms. Specially, we present a practical scalable item-based CF algorithm in detail, with the super characteristics such as robust to the implicit feedback problem, incremental update and real-time pruning. With the enhancement of real-time data collection and processing, we can capture the recommendation changes in real-time. We deploy the TencentRec in a series of production applications, and observe the superiority of TencentRec in providing accurate real-time recommendations for 10 billion user requests everyday."
            },
            "slug": "TencentRec:-Real-time-Stream-Recommendation-in-Huang-Cui",
            "title": {
                "fragments": [],
                "text": "TencentRec: Real-time Stream Recommendation in Practice"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper proposes a general real-time stream recommender system built on Storm named TencentRec, and presents a practical scalable item-based CF algorithm in detail, with the super characteristics such as robust to the implicit feedback problem, incremental update and real- time pruning."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD Conference"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143845796"
                        ],
                        "name": "Jeffrey Pennington",
                        "slug": "Jeffrey-Pennington",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Pennington",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeffrey Pennington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144783904"
                        ],
                        "name": "Christopher D. Manning",
                        "slug": "Christopher-D.-Manning",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Manning",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher D. Manning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 157
                            }
                        ],
                        "text": "This bridge nicely motivates several proposals to use MF to learn word embeddings; however, when it comes to handling missing data, they have either ignored [22] or equally weighted the missing entries, similar to traditional SVD [16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1957433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f37e1b62a767a307c046404ca96bc140b3e68cb5",
            "isKey": false,
            "numCitedBy": 23879,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent methods for learning vector space representations of words have succeeded in capturing fine-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model efficiently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition."
            },
            "slug": "GloVe:-Global-Vectors-for-Word-Representation-Pennington-Socher",
            "title": {
                "fragments": [],
                "text": "GloVe: Global Vectors for Word Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods and produces a vector space with meaningful substructure."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2662221"
                        ],
                        "name": "Peter Richt\u00e1rik",
                        "slug": "Peter-Richt\u00e1rik",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Richt\u00e1rik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter Richt\u00e1rik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144696183"
                        ],
                        "name": "Martin Tak\u00e1c",
                        "slug": "Martin-Tak\u00e1c",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Tak\u00e1c",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin Tak\u00e1c"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "Recently, [4] employs the Randomized block Coordinate Descent (RCD) learner [28], reducing the complexity and applying it to a dynamic scenario."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16816638,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "a8048db26cb78e785e82f06645da3f79d729528e",
            "isKey": false,
            "numCitedBy": 681,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we develop a randomized block-coordinate descent method for minimizing the sum of a smooth and a simple nonsmooth block-separable convex function and prove that it obtains an $$\\varepsilon $$-accurate solution with probability at least $$1-\\rho $$ in at most $$O((n/\\varepsilon ) \\log (1/\\rho ))$$ iterations, where $$n$$ is the number of blocks. This extends recent results of Nesterov (SIAM J Optim 22(2): 341\u2013362, 2012), which cover the smooth case, to composite minimization, while at the same time improving the complexity by the factor of 4 and removing $$\\varepsilon $$ from the logarithmic term. More importantly, in contrast with the aforementioned work in which the author achieves the results by applying the method to a regularized version of the objective function with an unknown scaling factor, we show that this is not necessary, thus achieving first true iteration complexity bounds. For strongly convex functions the method converges linearly. In the smooth case we also allow for arbitrary probability vectors and non-Euclidean norms. Finally, we demonstrate numerically that the algorithm is able to solve huge-scale $$\\ell _1$$-regularized least squares problems with a billion variables."
            },
            "slug": "Iteration-complexity-of-randomized-block-coordinate-Richt\u00e1rik-Tak\u00e1c",
            "title": {
                "fragments": [],
                "text": "Iteration complexity of randomized block-coordinate descent methods for minimizing a composite function"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A randomized block-coordinate descent method for minimizing the sum of a smooth and a simple nonsmooth block-separable convex function is developed and it is proved that it obtains an accurate solution with probability at least 1-\\rho in at most O(n/\\varepsilon) iterations, thus achieving first true iteration complexity bounds."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Program."
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5462268"
                        ],
                        "name": "Hanwang Zhang",
                        "slug": "Hanwang-Zhang",
                        "structuredName": {
                            "firstName": "Hanwang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanwang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6897666"
                        ],
                        "name": "Yang Yang",
                        "slug": "Yang-Yang",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3371599"
                        ],
                        "name": "Huanbo Luan",
                        "slug": "Huanbo-Luan",
                        "structuredName": {
                            "firstName": "Huanbo",
                            "lastName": "Luan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huanbo Luan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143653681"
                        ],
                        "name": "Shuicheng Yan",
                        "slug": "Shuicheng-Yan",
                        "structuredName": {
                            "firstName": "Shuicheng",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuicheng Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144078686"
                        ],
                        "name": "Tat-Seng Chua",
                        "slug": "Tat-Seng-Chua",
                        "structuredName": {
                            "firstName": "Tat-Seng",
                            "lastName": "Chua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tat-Seng Chua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10615988,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d511bc8d630248e9befb6deb6fe6e5e719f1e414",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Higher-level semantics such as visual attributes are crucial for fundamental multimedia applications. We present a novel attribute discovery approach that can automatically identify, model and name attributes from an arbitrary set of image and text pairs that can be easily gathered on the Web. Different from conventional attribute discovery methods, our approach does not rely on any pre-defined vocabularies and human labeling. Therefore, we are able to build a large visual knowledge base without any human efforts. The discovery is based on a novel deep architecture, named Independent Component Multimodal Autoencoder (ICMAE), that can continually learn shared higher-level representations across the visual and textual modalities. With the help of the resultant representations encoding strong visual and semantic evidences, we propose to (a) identify attributes and their corresponding high-quality training images, (b) iteratively model them with maximum compactness and comprehensiveness, and (c) name the attribute models with human understandable words. To date, the proposed system has discovered 1,898 attributes over 1.3 million pairs of image and text. Extensive experiments on various real-world multimedia datasets demonstrate the quality and effectiveness of the discovered attributes, facilitating multimedia applications such as image annotation and retrieval as compared to the state-of-the-art approaches."
            },
            "slug": "Start-from-Scratch:-Towards-Automatically-Modeling,-Zhang-Yang",
            "title": {
                "fragments": [],
                "text": "Start from Scratch: Towards Automatically Identifying, Modeling, and Naming Visual Attributes"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "A novel attribute discovery approach that can automatically identify, model and name attributes from an arbitrary set of image and text pairs that can be easily gathered on the Web, and is able to build a large visual knowledge base without any human efforts."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Multimedia"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2047446108"
                        ],
                        "name": "Tomas Mikolov",
                        "slug": "Tomas-Mikolov",
                        "structuredName": {
                            "firstName": "Tomas",
                            "lastName": "Mikolov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tomas Mikolov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118440152"
                        ],
                        "name": "Kai Chen",
                        "slug": "Kai-Chen",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32131713"
                        ],
                        "name": "G. Corrado",
                        "slug": "G.-Corrado",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Corrado",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Corrado"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": "To resolve this, tricks like subsampling frequent items [19] and adaptive learning rates like Adagrad [6] have been adopted in other domains."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16447573,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87f40e6f3022adbc1f1905e3e506abad05a9964f",
            "isKey": false,
            "numCitedBy": 27216,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling. \n \nAn inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of \"Canada\" and \"Air\" cannot be easily combined to obtain \"Air Canada\". Motivated by this example, we present a simple method for finding phrases in text, and show that learning good vector representations for millions of phrases is possible."
            },
            "slug": "Distributed-Representations-of-Words-and-Phrases-Mikolov-Sutskever",
            "title": {
                "fragments": [],
                "text": "Distributed Representations of Words and Phrases and their Compositionality"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper presents a simple method for finding phrases in text, and shows that learning good vector representations for millions of phrases is possible and describes a simple alternative to the hierarchical softmax called negative sampling."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5462268"
                        ],
                        "name": "Hanwang Zhang",
                        "slug": "Hanwang-Zhang",
                        "structuredName": {
                            "firstName": "Hanwang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanwang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143962510"
                        ],
                        "name": "Zhengjun Zha",
                        "slug": "Zhengjun-Zha",
                        "structuredName": {
                            "firstName": "Zhengjun",
                            "lastName": "Zha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhengjun Zha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6897666"
                        ],
                        "name": "Yang Yang",
                        "slug": "Yang-Yang",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143653681"
                        ],
                        "name": "Shuicheng Yan",
                        "slug": "Shuicheng-Yan",
                        "structuredName": {
                            "firstName": "Shuicheng",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuicheng Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109218951"
                        ],
                        "name": "Yue Gao",
                        "slug": "Yue-Gao",
                        "structuredName": {
                            "firstName": "Yue",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yue Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144078686"
                        ],
                        "name": "Tat-Seng Chua",
                        "slug": "Tat-Seng-Chua",
                        "structuredName": {
                            "firstName": "Tat-Seng",
                            "lastName": "Chua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tat-Seng Chua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 126658,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a35338cb4686cff66710b7f8102e5eabfc38adb8",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "This article presents a novel attribute-augmented semantic hierarchy (A2SH) and demonstrates its effectiveness in bridging both the semantic and intention gaps in content-based image retrieval (CBIR). A2SH organizes semantic concepts into multiple semantic levels and augments each concept with a set of related attributes. The attributes are used to describe the multiple facets of the concept and act as the intermediate bridge connecting the concept and low-level visual content. An hierarchical semantic similarity function is learned to characterize the semantic similarities among images for retrieval. To better capture user search intent, a hybrid feedback mechanism is developed, which collects hybrid feedback on attributes and images. This feedback is then used to refine the search results based on A2SH. We use A2SH as a basis to develop a unified content-based image retrieval system. We conduct extensive experiments on a large-scale dataset of over one million Web images. Experimental results show that the proposed A2SH can characterize the semantic affinities among images accurately and can shape user search intent quickly, leading to more accurate search results as compared to state-of-the-art CBIR solutions."
            },
            "slug": "Attribute-Augmented-Semantic-Hierarchy:-Towards-a-Zhang-Zha",
            "title": {
                "fragments": [],
                "text": "Attribute-Augmented Semantic Hierarchy: Towards a Unified Framework for Content-Based Image Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Experimental results show that the proposed A2SH can characterize the semantic affinities among images accurately and can shape user search intent quickly, leading to more accurate search results as compared to state-of-the-art CBIR solutions."
            },
            "venue": {
                "fragments": [],
                "text": "TOMM"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35141826"
                        ],
                        "name": "Jingwen Bian",
                        "slug": "Jingwen-Bian",
                        "structuredName": {
                            "firstName": "Jingwen",
                            "lastName": "Bian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jingwen Bian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6897666"
                        ],
                        "name": "Yang Yang",
                        "slug": "Yang-Yang",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5462268"
                        ],
                        "name": "Hanwang Zhang",
                        "slug": "Hanwang-Zhang",
                        "structuredName": {
                            "firstName": "Hanwang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanwang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144078686"
                        ],
                        "name": "Tat-Seng Chua",
                        "slug": "Tat-Seng-Chua",
                        "structuredName": {
                            "firstName": "Tat-Seng",
                            "lastName": "Chua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tat-Seng Chua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14398952,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3844c7d5fa7ded98dca892a935e2c0e92140323f",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Microblogging services have revolutionized the way people exchange information. Confronted with the ever-increasing numbers of social events and the corresponding microblogs with multimedia contents, it is desirable to provide visualized summaries to help users to quickly grasp the essence of these social events for better understanding. While existing approaches mostly focus only on text-based summary, microblog summarization with multiple media types (e.g., text, image, and video) is scarcely explored. In this paper, we propose a multimedia social event summarization framework to automatically generate visualized summaries from the microblog stream of multiple media types. Specifically, the proposed framework comprises three stages, as follows. 1) A noise removal approach is first devised to eliminate potentially noisy images. An effective spectral filtering model is exploited to estimate the probability that an image is relevant to a given event. 2) A novel cross-media probabilistic model, termed Cross-Media-LDA (CMLDA), is proposed to jointly discover subevents from microblogs of multiple media types. The intrinsic correlations among these different media types are well explored and exploited for reinforcing the cross-media subevent discovery process. 3) Finally, based on the cross-media knowledge of all the discovered subevents, a multimedia microblog summary generation process is designed to jointly identify both representative textual and visual samples, which are further aggregated to form a holistic visualized summary. We conduct extensive experiments on two real-world microblog datasets to demonstrate the superiority of the proposed framework as compared to the state-of-the-art approaches."
            },
            "slug": "Multimedia-Summarization-for-Social-Events-in-Bian-Yang",
            "title": {
                "fragments": [],
                "text": "Multimedia Summarization for Social Events in Microblog Stream"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper proposes a multimedia social event summarization framework to automatically generate visualized summaries from the microblog stream of multiple media types and conducts extensive experiments on two real-world microblog datasets to demonstrate the superiority of the proposed framework as compared to the state-of-the-art approaches."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Multimedia"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763785"
                        ],
                        "name": "Luming Zhang",
                        "slug": "Luming-Zhang",
                        "structuredName": {
                            "firstName": "Luming",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luming Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109218951"
                        ],
                        "name": "Yue Gao",
                        "slug": "Yue-Gao",
                        "structuredName": {
                            "firstName": "Yue",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yue Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152735427"
                        ],
                        "name": "Chao Zhang",
                        "slug": "Chao-Zhang",
                        "structuredName": {
                            "firstName": "Chao",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chao Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5462268"
                        ],
                        "name": "Hanwang Zhang",
                        "slug": "Hanwang-Zhang",
                        "structuredName": {
                            "firstName": "Hanwang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanwang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144876831"
                        ],
                        "name": "Q. Tian",
                        "slug": "Q.-Tian",
                        "structuredName": {
                            "firstName": "Qi",
                            "lastName": "Tian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Q. Tian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144809527"
                        ],
                        "name": "Roger Zimmermann",
                        "slug": "Roger-Zimmermann",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Zimmermann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roger Zimmermann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12302403,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9a79e11b4261aa601d7f77f4ba5aed22ca1f6ad6",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Photo aesthetic quality evaluation is a challenging task in multimedia and computer vision fields. Conventional approaches suffer from the following three drawbacks: 1) the deemphasized role of semantic content that is many times more important than low-level visual features in photo aesthetics; 2) the difficulty to optimally fuse low-level and high-level visual cues in photo aesthetics evaluation; and 3) the absence of a sequential viewing path in the existing models, as humans perceive visually salient regions sequentially when viewing a photo. To solve these problems, we propose a new aesthetic descriptor that mimics humans sequentially perceiving visually/semantically salient regions in a photo. In particular, a weakly supervised learning paradigm is developed to project the local aesthetic descriptors (graphlets in this work) into a low-dimensional semantic space. Thereafter, each graphlet can be described by multiple types of visual features, both at low-level and in high-level. Since humans usually perceive only a few salient regions in a photo, a sparsity-constrained graphlet ranking algorithm is proposed that seamlessly integrates both the low-level and the high-level visual cues. Top-ranked graphlets are those visually/semantically prominent graphlets in a photo. They are sequentially linked into a path that simulates the process of humans actively viewing. Finally, we learn a probabilistic aesthetic measure based on such actively viewing paths (AVPs) from the training photos that are marked as aesthetically pleasing by multiple users. Experimental results show that: 1) the AVPs are 87.65% consistent with real human gaze shifting paths, as verified by the eye-tracking data; and 2) our photo aesthetic measure outperforms many of its competitors."
            },
            "slug": "Perception-Guided-Multimodal-Feature-Fusion-for-Zhang-Gao",
            "title": {
                "fragments": [],
                "text": "Perception-Guided Multimodal Feature Fusion for Photo Aesthetics Assessment"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A weakly supervised learning paradigm is developed to project the local aesthetic descriptors (graphlets in this work) into a low-dimensional semantic space, and a sparsity-constrained graphlet ranking algorithm is proposed that seamlessly integrates both the low-level and the high-level visual cues."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Multimedia"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "22066021"
                        ],
                        "name": "Xishan Zhang",
                        "slug": "Xishan-Zhang",
                        "structuredName": {
                            "firstName": "Xishan",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xishan Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6897666"
                        ],
                        "name": "Yang Yang",
                        "slug": "Yang-Yang",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699819"
                        ],
                        "name": "Yongdong Zhang",
                        "slug": "Yongdong-Zhang",
                        "structuredName": {
                            "firstName": "Yongdong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yongdong Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3371599"
                        ],
                        "name": "Huanbo Luan",
                        "slug": "Huanbo-Luan",
                        "structuredName": {
                            "firstName": "Huanbo",
                            "lastName": "Luan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huanbo Luan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30821609"
                        ],
                        "name": "Jintao Li",
                        "slug": "Jintao-Li",
                        "structuredName": {
                            "firstName": "Jintao",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jintao Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5462268"
                        ],
                        "name": "Hanwang Zhang",
                        "slug": "Hanwang-Zhang",
                        "structuredName": {
                            "firstName": "Hanwang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanwang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144078686"
                        ],
                        "name": "Tat-Seng Chua",
                        "slug": "Tat-Seng-Chua",
                        "structuredName": {
                            "firstName": "Tat-Seng",
                            "lastName": "Chua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tat-Seng Chua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11962705,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72d856a91821e6e3418e916b1b732ea9637742e1",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "The task of recognizing events from video has attracted a lot of attention in recent years. However, due to the complex nature of user-defined events, the use of purely audio- visual content analysis without domain knowledge has been found to be grossly inadequate. In this paper, we propose to construct a semantic-visual knowledge base to encode the rich event-centric concepts and their relationships from the well- established lexical databases, including FrameNet, as well as the concept-specific visual knowledge from ImageNet. Based on this semantic-visual knowledge bases, we design an effective system for video event recognition. Specifically, in order to narrow the semantic gap between the high-level complex events and low-level visual representations, we utilize the event-centric semantic concepts encoded in the knowledge base as the intermediate-level event representation, which offers both human-perceivable and machine-interpretable semantic clues for event recognition. In addition, in order to leverage the abundant ImageNet images, we propose a robust transfer learning model to learn the noise- resistant concept classifiers for videos. Extensive experiments on various real-world video datasets demonstrate the superiority of our proposed system as compared to the state-of-the-art approaches."
            },
            "slug": "Enhancing-Video-Event-Recognition-Using-Constructed-Zhang-Yang",
            "title": {
                "fragments": [],
                "text": "Enhancing Video Event Recognition Using Automatically Constructed Semantic-Visual Knowledge Base"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper proposes to construct a semantic-visual knowledge base to encode the rich event-centric concepts and their relationships from the well- established lexical databases, including FrameNet, as well as the concept-specific visual knowledge from ImageNet, and designs an effective system for video event recognition."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Multimedia"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733143"
                        ],
                        "name": "D. Sculley",
                        "slug": "D.-Sculley",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Sculley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Sculley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144510728"
                        ],
                        "name": "Gary Holt",
                        "slug": "Gary-Holt",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Holt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gary Holt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145973657"
                        ],
                        "name": "D. Golovin",
                        "slug": "D.-Golovin",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Golovin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Golovin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143698521"
                        ],
                        "name": "Eugene Davydov",
                        "slug": "Eugene-Davydov",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Davydov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Davydov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054375101"
                        ],
                        "name": "Todd Phillips",
                        "slug": "Todd-Phillips",
                        "structuredName": {
                            "firstName": "Todd",
                            "lastName": "Phillips",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Todd Phillips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49236095"
                        ],
                        "name": "D. Ebner",
                        "slug": "D.-Ebner",
                        "structuredName": {
                            "firstName": "Dietmar",
                            "lastName": "Ebner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ebner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055477158"
                        ],
                        "name": "Vinay Chaudhary",
                        "slug": "Vinay-Chaudhary",
                        "structuredName": {
                            "firstName": "Vinay",
                            "lastName": "Chaudhary",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vinay Chaudhary"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114084357"
                        ],
                        "name": "Michael Young",
                        "slug": "Michael-Young",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Young",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Young"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 102
                            }
                        ],
                        "text": "More importantly, the low efficiency makes it even more difficult to deploy implicit MF method online [29]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 167
                            }
                        ],
                        "text": "This localized complexity make the online learning algorithm suitable to deployment in industrial use, as the complex software stack that deals with data dependencies [29] can be avoided."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15225610,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "51891710e30da33c4ced4ae7daee1593e0cb5cc4",
            "isKey": false,
            "numCitedBy": 256,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Machine learning offers a fantastically powerful toolkit for building complex systems quickly. This paper argues that it is dangerous to think of these quick wins as coming for free. Using the framework of technical debt, we note that it is remarkably easy to incur massive ongoing maintenance costs at the system level when applying machine learning. The goal of this paper is highlight several machine learning specific risk factors and design patterns to be avoided or refactored where possible. These include boundary erosion, entanglement, hidden feedback loops, undeclared consumers, data dependencies, changes in the external world, and a variety of system-level anti-patterns. 1 Machine Learning and Complex Systems Real world software engineers are often faced with the challenge of moving quickly to ship new products or services, which can lead to a dilemma between speed of execution and quality of engineering. The concept of technical debt was first introduced by Ward Cunningham in 1992 as a way to help quantify the cost of such decisions. Like incurring fiscal debt, there are often sound strategic reasons to take on technical debt. Not all debt is necessarily bad, but technical debt does tend to compound. Deferring the work to pay it off results in increasing costs, system brittleness, and reduced rates of innovation. Traditional methods of paying off technical debt include refactoring, increasing coverage of unit tests, deleting dead code, reducing dependencies, tightening APIs, and improving documentation [4]. The goal of these activities is not to add new functionality, but to make it easier to add future improvements, be cheaper to maintain, and reduce the likelihood of bugs. One of the basic arguments in this paper is that machine learning packages have all the basic code complexity issues as normal code, but also have a larger system-level complexity that can create hidden debt. Thus, refactoring these libraries, adding better unit tests, and associated activity is time well spent but does not necessarily address debt at a systems level. In this paper, we focus on the system-level interaction between machine learning code and larger systems as an area where hidden technical debt may rapidly accumulate. At a system-level, a machine learning model may subtly erode abstraction boundaries. It may be tempting to re-use input signals in ways that create unintended tight coupling of otherwise disjoint systems. Machine learning packages may often be treated as black boxes, resulting in large masses of \u201cglue code\u201d or calibration layers that can lock in assumptions. Changes in the external world may make models or input signals change behavior in unintended ways, ratcheting up maintenance cost and the burden of any debt. Even monitoring that the system as a whole is operating as intended may be difficult without careful design."
            },
            "slug": "Machine-Learning:-The-High-Interest-Credit-Card-of-Sculley-Holt",
            "title": {
                "fragments": [],
                "text": "Machine Learning: The High Interest Credit Card of Technical Debt"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The goal of this paper is highlight several machine learning specific risk factors and design patterns to be avoided or refactored where possible, including boundary erosion, entanglement, hidden feedback loops, undeclared consumers, data dependencies, changes in the external world, and a variety of system-level anti-patterns."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716227"
                        ],
                        "name": "D. Coppersmith",
                        "slug": "D.-Coppersmith",
                        "structuredName": {
                            "firstName": "Don",
                            "lastName": "Coppersmith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Coppersmith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690630"
                        ],
                        "name": "S. Winograd",
                        "slug": "S.-Winograd",
                        "structuredName": {
                            "firstName": "Shmuel",
                            "lastName": "Winograd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Winograd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 159
                            }
                        ],
                        "text": "Although eALS does not empirically show K times faster than ALS due to the more efficient matrix inversion implementation (we used the fastest known algorithm [1] with time complexity around O(K)), the speed-up is already very significant."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11155203,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "1992fee8d33e66e32a213ecf047f9022adbff92e",
            "isKey": false,
            "numCitedBy": 2830,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new method for accelerating matrix multiplication asymptotically. This work builds on recent ideas of Volker Strassen, by using a basic trilinear form which is not a matrix product. We make novel use of the Salem-Spencer Theorem, which gives a fairly dense set of integers with no three-term arithmetic progression. Our resulting matrix exponent is 2.376."
            },
            "slug": "Matrix-multiplication-via-arithmetic-progressions-Coppersmith-Winograd",
            "title": {
                "fragments": [],
                "text": "Matrix multiplication via arithmetic progressions"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "A new method for accelerating matrix multiplication asymptotically is presented, by using a basic trilinear form which is not a matrix product, and making novel use of the Salem-Spencer Theorem."
            },
            "venue": {
                "fragments": [],
                "text": "STOC"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2375038"
                        ],
                        "name": "S. R\u00fcger",
                        "slug": "S.-R\u00fcger",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "R\u00fcger",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. R\u00fcger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50686770"
                        ],
                        "name": "J. Jose",
                        "slug": "J.-Jose",
                        "structuredName": {
                            "firstName": "Joemon",
                            "lastName": "Jose",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Jose"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 26591487,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "17cb9922a8f8ee54ff0d7714aa65a69dcd2dee52",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This article provides a recap of the 4th ACM International Conference on Multimedia Retrieval, which took place in Glasgow, Scotland, from 1-4 April 2014."
            },
            "slug": "ACM-International-Conference-on-Multimedia-(ICMR-R\u00fcger-Jose",
            "title": {
                "fragments": [],
                "text": "ACM International Conference on Multimedia Retrieval (ICMR 2014)"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This article provides a recap of the 4th ACM International Conference on Multimedia Retrieval, which took place in Glasgow, Scotland, from 1-4 April 2014."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Multim."
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39455775"
                        ],
                        "name": "Omer Levy",
                        "slug": "Omer-Levy",
                        "structuredName": {
                            "firstName": "Omer",
                            "lastName": "Levy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Omer Levy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2089067"
                        ],
                        "name": "Yoav Goldberg",
                        "slug": "Yoav-Goldberg",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Goldberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoav Goldberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 95
                            }
                        ],
                        "text": "In addition, our proposed eALS has the same time complexity with RCD [4],\nbeing faster than ii-SVD [31], another recent solution."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "For example, recent advances in natural language processing [16] have shown the connection between neural word embeddings and MF on the word\u2013context matrix."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 54
                            }
                        ],
                        "text": "Based on this observation, we believe the traditional SVD technique [2] that treats all entries equally weighted will be suboptimal here."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 230
                            }
                        ],
                        "text": "This bridge nicely motivates several proposals to use MF to learn word embeddings; however, when it comes to handling missing data, they have either ignored [22] or equally weighted the missing entries, similar to traditional SVD [16]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 102
                            }
                        ],
                        "text": "This greatly reduces the modeling workload, and many sophisticated methods have been devised, such as SVD++ [15] and timeSVD [14]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 117
                            }
                        ],
                        "text": "Similarly, [31] enriches the implicit feedback matrix with neighbor-based similarly, followed by applying unweighted SVD. Distinct from previous works, we propose an efficient element-wise ALS solution for the whole-data based MF with non-uniform missing data, which has never been studied before."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1190093,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4c018bcc8ea707b83247866bdc8ccb87cd9f5da",
            "isKey": true,
            "numCitedBy": 1632,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We analyze skip-gram with negative-sampling (SGNS), a word embedding method introduced by Mikolov et al., and show that it is implicitly factorizing a word-context matrix, whose cells are the pointwise mutual information (PMI) of the respective word and context pairs, shifted by a global constant. We find that another embedding method, NCE, is implicitly factorizing a similar matrix, where each cell is the (shifted) log conditional probability of a word given its context. We show that using a sparse Shifted Positive PMI word-context matrix to represent words improves results on two word similarity tasks and one of two analogy tasks. When dense low-dimensional vectors are preferred, exact factorization with SVD can achieve solutions that are at least as good as SGNS's solutions for word similarity tasks. On analogy questions SGNS remains superior to SVD. We conjecture that this stems from the weighted nature of SGNS's factorization."
            },
            "slug": "Neural-Word-Embedding-as-Implicit-Matrix-Levy-Goldberg",
            "title": {
                "fragments": [],
                "text": "Neural Word Embedding as Implicit Matrix Factorization"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that using a sparse Shifted Positive PMI word-context matrix to represent words improves results on two word similarity tasks and one of two analogy tasks, and conjecture that this stems from the weighted nature of SGNS's factorization."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "User Profiling by Social Curation (oral) Xue Geng, Hanwang Zhang"
            },
            "venue": {
                "fragments": [],
                "text": "Tat-Seng Chua. ACM International Conference on Multimedia. MM 2014"
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Image Tagging with Social Assistance (oral) Yang Yang"
            },
            "venue": {
                "fragments": [],
                "text": "Image Tagging with Social Assistance (oral) Yang Yang"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Attribute Feedback (oral, Best Demo Runner-up)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Attribute-augmented Semantic Hierarchy (oral, Best Student Paper)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Attribute Feedback (oral, Best Demo Runner-up) Hanwang Zhang, Zheng-Jun Zha"
            },
            "venue": {
                "fragments": [],
                "text": "Attribute Feedback (oral, Best Demo Runner-up) Hanwang Zhang, Zheng-Jun Zha"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Attribute-augmented Semantic Hierarchy (oral, Best Student Paper) Hanwang Zhang, Zheng-Jun Zha"
            },
            "venue": {
                "fragments": [],
                "text": "Tat-Seng Chua. ACM International Conference on Multimedia. MM 2013"
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ACM International Conference on Multimedia. MM 2012"
            },
            "venue": {
                "fragments": [],
                "text": "ACM International Conference on Multimedia. MM 2012"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Robust (Semi-) Nonnegative Graph Embedding Hanwang Zhang, Zheng-Jun Zha, Yang Yang, Shuicheng Yan, Tat-Seng Chua"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Image Processing. TIP"
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ACM International Conference on Multimedia. MM 2014"
            },
            "venue": {
                "fragments": [],
                "text": "ACM International Conference on Multimedia. MM 2014"
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "IEEE International Conference on Computer Vision and Pattern Recognition. CVPR 2012"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE International Conference on Computer Vision and Pattern Recognition. CVPR 2012"
            },
            "year": 2012
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 17,
            "methodology": 27,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 49,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Fast-Matrix-Factorization-for-Online-Recommendation-He-Zhang/ab443bd7e732374caabb5785b8d37bbfc724c845?sort=total-citations"
}