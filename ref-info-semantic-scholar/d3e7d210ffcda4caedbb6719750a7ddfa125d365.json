{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152895903"
                        ],
                        "name": "Lin Xu",
                        "slug": "Lin-Xu",
                        "structuredName": {
                            "firstName": "Lin",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lin Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388404060"
                        ],
                        "name": "Kevin Leyton-Brown",
                        "slug": "Kevin-Leyton-Brown",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Leyton-Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Leyton-Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In this invited extended abstract of our AI Journal paper [Hutter et al., 2014b], we summarized existing and new techniques for predicting algorithm runtime and evaluated their performance in a comprehensive empirical analysis."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "work on runtime prediction from many separate communities, our AI Journal article [Hutter et al., 2014b] makes four new contributions:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2217This paper is an invited extended abstract of our 2014 AI Journal article [Hutter et al., 2014b] basis [Rice, 1976; Smith-Miles, 2009; Kotthoff, 2014] has been successfully addressed by using EPMs to predict the performance of all candidate algorithms and selecting the one predicted to perform best [Brewer, 1995; Lobjois and Lema\u0131\u0302tre, 1998; Fink, 1998; Howe et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2472445,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14e1f20764d6733499e0a07062de42433522bddf",
            "isKey": false,
            "numCitedBy": 342,
            "numCiting": 165,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Algorithm-runtime-prediction:-Methods-&-evaluation-Hutter-Xu",
            "title": {
                "fragments": [],
                "text": "Algorithm runtime prediction: Methods & evaluation"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728524"
                        ],
                        "name": "Y. Hamadi",
                        "slug": "Y.-Hamadi",
                        "structuredName": {
                            "firstName": "Youssef",
                            "lastName": "Hamadi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Hamadi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388404060"
                        ],
                        "name": "Kevin Leyton-Brown",
                        "slug": "Kevin-Leyton-Brown",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Leyton-Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Leyton-Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Second, EPMs can model algorithm performance dependent on both problem instance features and algorithm parameter settings; such models can then be used to select parameter settings with good predicted performance on a per-instance basis [Hutter et al., 2006]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1471952,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "56019659c24fcec61e80dfcf4f472f50091ac11b",
            "isKey": false,
            "numCitedBy": 197,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Machine learning can be used to build models that predict the run-time of search algorithms for hard combinatorial problems. Such empirical hardness models have previously been studied for complete, deterministic search algorithms. In this work, we demonstrate that such models can also make surprisingly accurate predictions of the run-time distributions of incomplete and randomized search methods, such as stochastic local search algorithms. We also show for the first time how information about an algorithm's parameter settings can be incorporated into a model, and how such models can be used to automatically adjust the algorithm's parameters on a per-instance basis in order to optimize its performance. Empirical results for Novelty+ and SAPS on structured and unstructured SAT instances show very good predictive performance and significant speedups of our automatically determined parameter settings when compared to the default and best fixed distribution-specific parameter settings."
            },
            "slug": "Performance-Prediction-and-Automated-Tuning-of-and-Hutter-Hamadi",
            "title": {
                "fragments": [],
                "text": "Performance Prediction and Automated Tuning of Randomized and Parametric Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is demonstrated for the first time how information about an algorithm's parameter settings can be incorporated into a model, and how such models can be used to automatically adjust the algorithm's parameters on a per-instance basis in order to optimize its performance."
            },
            "venue": {
                "fragments": [],
                "text": "CP"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388404060"
                        ],
                        "name": "Kevin Leyton-Brown",
                        "slug": "Kevin-Leyton-Brown",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Leyton-Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Leyton-Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For other models, generic feature selection methods, such as forward selection, can be used to identify a small number of key model inputs (often fewer than five) that explain algorithm performance almost as well as the whole set of inputs [Leyton-Brown et al., 2009; Hutter et al., 2013]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1130380,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "205172102afca365014b0ee9f470c94a00aff8c6",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Most state-of-the-art algorithms for large-scale optimization problems expose free parameters, giving rise to combinatorial spaces of possible configurations. Typically, these spaces are hard for humans to understand. In this work, we study a model-based approach for identifying a small set of both algorithm parameters and instance features that suffices for predicting empirical algorithm performance well. Our empirical analyses on a wide variety of hard combinatorial problem benchmarks spanning SAT, MIP, and TSP show that--for parameter configurations sampled uniformly at random--very good performance predictions can typically be obtained based on just two key parameters, and that similarly, few instance features and algorithm parameters suffice to predict the most salient algorithm performance characteristics in the combined configuration/feature space. We also use these models to identify settings of these key parameters that are predicted to achieve the best overall performance, both on average across instances and in an instance-specific way. This serves as a further way of evaluating model quality and also provides a tool for further understanding the parameter space. We provide software for carrying out this analysis on arbitrary problem domains and hope that it will help algorithm developers gain insights into the key parameters of their algorithms, the key features of their instances, and their interactions."
            },
            "slug": "Identifying-Key-Algorithm-Parameters-and-Instance-Hutter-Hoos",
            "title": {
                "fragments": [],
                "text": "Identifying Key Algorithm Parameters and Instance Features Using Forward Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work study's empirical analyses show that--for parameter configurations sampled uniformly at random--very good performance predictions can typically be obtained based on just two key parameters, and that similarly, few instance features and algorithm parameters suffice to predict the most salient algorithm performance characteristics in the combined configuration/feature space."
            },
            "venue": {
                "fragments": [],
                "text": "LION"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388404060"
                        ],
                        "name": "Kevin Leyton-Brown",
                        "slug": "Kevin-Leyton-Brown",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Leyton-Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Leyton-Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48942559"
                        ],
                        "name": "E. Nudelman",
                        "slug": "E.-Nudelman",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Nudelman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Nudelman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701353"
                        ],
                        "name": "Y. Shoham",
                        "slug": "Y.-Shoham",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Shoham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Shoham"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "An EPM for one or more algorithms can be used to set the parameters of existing benchmark generators in order to create instances that are hard for the algorithms in question [Leyton-Brown et al., 2009]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "For other models, generic feature selection methods, such as forward selection, can be used to identify a small number of key model inputs (often fewer than five) that explain algorithm performance almost as well as the whole set of inputs [Leyton-Brown et al., 2009; Hutter et al., 2013]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2022 RR: ridge regression with quadratic basis function expansion and forward selection as in early versions of SATzilla [Leyton-Brown et al., 2009; Xu et al., 2008]);"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9223857,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2609f23364b0611e75d69ac5d311ebe6fcd75f44",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 113,
            "paperAbstract": {
                "fragments": [],
                "text": "Is it possible to predict how long an algorithm will take to solve a previously-unseen instance of an NP-complete problem? If so, what uses can be found for models that make such predictions? This article provides answers to these questions and evaluates the answers experimentally.\n We propose the use of supervised machine learning to build models that predict an algorithm's runtime given a problem instance. We discuss the construction of these models and describe techniques for interpreting them to gain understanding of the characteristics that cause instances to be hard or easy. We also present two applications of our models: building algorithm portfolios that outperform their constituent algorithms, and generating test distributions that emphasize hard problems.\n We demonstrate the effectiveness of our techniques in a case study of the combinatorial auction winner determination problem. Our experimental results show that we can build very accurate models of an algorithm's running time, interpret our models, build an algorithm portfolio that strongly outperforms the best single algorithm, and tune a standard benchmark suite to generate much harder problem instances."
            },
            "slug": "Empirical-hardness-models:-Methodology-and-a-case-Leyton-Brown-Nudelman",
            "title": {
                "fragments": [],
                "text": "Empirical hardness models: Methodology and a case study on combinatorial auctions"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The use of supervised machine learning is proposed to build models that predict an algorithm's runtime given a problem instance and techniques for interpreting them are described to gain understanding of the characteristics that cause instances to be hard or easy."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388404060"
                        ],
                        "name": "Kevin Leyton-Brown",
                        "slug": "Kevin-Leyton-Brown",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Leyton-Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Leyton-Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "First, they can model the performance of a parameterized algorithm dependent on the settings of its parameters; in a sequential model-based optimization process, one alternates between learning an EPM and using it to identify promising settings to evaluate next [Jones et al., 1998; Bartz-Beielstein et al., 2005; Hutter et al., 2011]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6944647,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "728744423ff0fb7e327664ed4e6352a95bb6c893",
            "isKey": false,
            "numCitedBy": 2055,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "State-of-the-art algorithms for hard computational problems often expose many parameters that can be modified to improve empirical performance. However, manually exploring the resulting combinatorial space of parameter settings is tedious and tends to lead to unsatisfactory outcomes. Recently, automated approaches for solving this algorithm configuration problem have led to substantial improvements in the state of the art for solving various problems. One promising approach constructs explicit regression models to describe the dependence of target algorithm performance on parameter settings; however, this approach has so far been limited to the optimization of few numerical algorithm parameters on single instances. In this paper, we extend this paradigm for the first time to general algorithm configuration problems, allowing many categorical parameters and optimization for sets of instances. We experimentally validate our new algorithm configuration procedure by optimizing a local search and a tree search solver for the propositional satisfiability problem (SAT), as well as the commercial mixed integer programming (MIP) solver CPLEX. In these experiments, our procedure yielded state-of-the-art performance, and in many cases outperformed the previous best configuration approach."
            },
            "slug": "Sequential-Model-Based-Optimization-for-General-Hutter-Hoos",
            "title": {
                "fragments": [],
                "text": "Sequential Model-Based Optimization for General Algorithm Configuration"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper extends the explicit regression models paradigm for the first time to general algorithm configuration problems, allowing many categorical parameters and optimization for sets of instances, and yields state-of-the-art performance."
            },
            "venue": {
                "fragments": [],
                "text": "LION"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388404060"
                        ],
                        "name": "Kevin Leyton-Brown",
                        "slug": "Kevin-Leyton-Brown",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Leyton-Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Leyton-Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9569110,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cabd6bbdd2be9996dd7473185c9eaf104980fe21",
            "isKey": false,
            "numCitedBy": 282,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "The performance of many machine learning methods depends critically on hyperparameter settings. Sophisticated Bayesian optimization methods have recently achieved considerable successes in optimizing these hyperparameters, in several cases surpassing the performance of human experts. However, blind reliance on such methods can leave end users without insight into the relative importance of different hyperparameters and their interactions. This paper describes efficient methods that can be used to gain such insight, leveraging random forest models fit on the data already gathered by Bayesian optimization. We first introduce a novel, linear-time algorithm for computing marginals of random forest predictions and then show how to leverage these predictions within a functional ANOVA framework, to quantify the importance of both single hyperparameters and of interactions between hyperparameters. We conducted experiments with prominent machine learning frameworks and state-of-the-art solvers for combinatorial problems. We show that our methods provide insight into the relationship between hyperparameter settings and performance, and demonstrate that--even in very highdimensional cases--most performance variation is attributable to just a few hyperparameters."
            },
            "slug": "An-Efficient-Approach-for-Assessing-Hyperparameter-Hutter-Hoos",
            "title": {
                "fragments": [],
                "text": "An Efficient Approach for Assessing Hyperparameter Importance"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper describes efficient methods that can be used to gain insight into the relationship between hyperparameter settings and performance, and demonstrates that--even in very highdimensional cases--most performance variation is attributable to just a few hyperparameters."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2278779"
                        ],
                        "name": "L. Lobjois",
                        "slug": "L.-Lobjois",
                        "structuredName": {
                            "firstName": "Lionel",
                            "lastName": "Lobjois",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Lobjois"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144971682"
                        ],
                        "name": "M. Lema\u00eetre",
                        "slug": "M.-Lema\u00eetre",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Lema\u00eetre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lema\u00eetre"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9004409,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "069b93285c4c3d504b9788826b342566c29460e1",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a method called Selection by Performance Prediction (SPP) which allows one, when faced with a particular problem instance, to select a Branch and Bound algorithm from among several promising ones. This method is based on Knuth's sampling method which estimates the efficiency of a backtrack program on a particular instance by iteratively generating random paths in the search tree. We present a simple adaptation of this estimator in the field of combinatorial optimization problems, more precisely for an extension of the maximal constraint satisfaction framework. Experiments both on random and strongly structured instances show that, in most cases, the proposed method is able to select, from a candidate list, the best algorithm for solving a given instance."
            },
            "slug": "Branch-and-Bound-Algorithm-Selection-by-Performance-Lobjois-Lema\u00eetre",
            "title": {
                "fragments": [],
                "text": "Branch and Bound Algorithm Selection by Performance Prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "A method called Selection by Performance Prediction (SPP) which allows one, when faced with a particular problem instance, to select a Branch and Bound algorithm from among several promising ones, based on Knuth's sampling method."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50055322"
                        ],
                        "name": "Ling Huang",
                        "slug": "Ling-Huang",
                        "structuredName": {
                            "firstName": "Ling",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ling Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2542974"
                        ],
                        "name": "Jinzhu Jia",
                        "slug": "Jinzhu-Jia",
                        "structuredName": {
                            "firstName": "Jinzhu",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jinzhu Jia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144923779"
                        ],
                        "name": "Bin Yu",
                        "slug": "Bin-Yu",
                        "structuredName": {
                            "firstName": "Bin",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bin Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704157"
                        ],
                        "name": "Byung-Gon Chun",
                        "slug": "Byung-Gon-Chun",
                        "structuredName": {
                            "firstName": "Byung-Gon",
                            "lastName": "Chun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Byung-Gon Chun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2286904"
                        ],
                        "name": "Petros Maniatis",
                        "slug": "Petros-Maniatis",
                        "structuredName": {
                            "firstName": "Petros",
                            "lastName": "Maniatis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Petros Maniatis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145835621"
                        ],
                        "name": "M. Naik",
                        "slug": "M.-Naik",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Naik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Naik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15546879,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4dd36e37d417825d4c850fb3789224e63269daac",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Predicting the execution time of computer programs is an important but challenging problem in the community of computer systems. Existing methods require experts to perform detailed analysis of program code in order to construct predictors or select important features. We recently developed a new system to automatically extract a large number of features from program execution on sample inputs, on which prediction models can be constructed without expert knowledge. In this paper we study the construction of predictive models for this problem. We propose the SPORE (Sparse POlynomial REgression) methodology to build accurate prediction models of program performance using feature data collected from program execution on sample inputs. Our two SPORE algorithms are able to build relationships between responses (e.g., the execution time of a computer program) and features, and select a few from hundreds of the retrieved features to construct an explicitly sparse and non-linear model to predict the response variable. The compact and explicitly polynomial form of the estimated model could reveal important insights into the computer program (e.g., features and their non-linear combinations that dominate the execution time), enabling a better understanding of the program's behavior. Our evaluation on three widely used computer programs shows that SPORE methods can give accurate prediction with relative error less than 7% by using a moderate number of training data samples. In addition, we compare SPORE algorithms to state-of-the-art sparse regression algorithms, and show that SPORE methods, motivated by real applications, outperform the other methods in terms of both interpretability and prediction accuracy."
            },
            "slug": "Predicting-Execution-Time-of-Computer-Programs-Huang-Jia",
            "title": {
                "fragments": [],
                "text": "Predicting Execution Time of Computer Programs Using Sparse Polynomial Regression"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes the SPORE (Sparse POlynomial REgression) methodology to build accurate prediction models of program performance using feature data collected from program execution on sample inputs and shows that SPORE methods can give accurate prediction with relative error less than 7% by using a moderate number of training data samples."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722782"
                        ],
                        "name": "Lars Kotthoff",
                        "slug": "Lars-Kotthoff",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Kotthoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lars Kotthoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726451"
                        ],
                        "name": "Ian P. Gent",
                        "slug": "Ian-P.-Gent",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Gent",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian P. Gent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711462"
                        ],
                        "name": "I. Miguel",
                        "slug": "I.-Miguel",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Miguel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Miguel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", 2014b] basis [Rice, 1976; Smith-Miles, 2009; Kotthoff, 2014] has been successfully addressed by using EPMs to predict the performance of all candidate algorithms and selecting the one predicted to perform best [Brewer, 1995; Lobjois and Lema\u0131\u0302tre, 1998; Fink, 1998; Howe et al., 2000; Nudelman et al., 2003; Roberts and Howe, 2007; Xu et al., 2008; Kotthoff et al., 2012]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11943892,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30e61aff0fcdf86f94f23bed26cbc0985d108a26",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Machine learning is an established method of selecting algorithms to solve hard search problems. Despite this, to date no systematic comparison and evaluation of the different techniques has been performed and the performance of existing systems has not been critically compared with other approaches. We compare the performance of a large number of different machine learning techniques from different machine learning methodologies on five data sets of hard algorithm selection problems from the literature. In addition to well-established approaches, for the first time we also apply statistical relational learning to this problem. We demonstrate that there is significant scope for improvement both compared with existing systems and in general. To guide practitioners, we close by giving clear recommendations as to which machine learning techniques are likely to achieve good performance in the context of algorithm selection problems. In particular, we show that linear regression and alternating decision trees have a very high probability of achieving better performance than always selecting the single best algorithm."
            },
            "slug": "An-evaluation-of-machine-learning-in-algorithm-for-Kotthoff-Gent",
            "title": {
                "fragments": [],
                "text": "An evaluation of machine learning in algorithm selection for search problems"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that linear regression and alternating decision trees have a very high probability of achieving better performance than always selecting the single best algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "AI Commun."
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398371449"
                        ],
                        "name": "K. Smith\u2010Miles",
                        "slug": "K.-Smith\u2010Miles",
                        "structuredName": {
                            "firstName": "Kate",
                            "lastName": "Smith\u2010Miles",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Smith\u2010Miles"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", 2014b] basis [Rice, 1976; Smith-Miles, 2009; Kotthoff, 2014] has been successfully addressed by using EPMs to predict the performance of all candidate algorithms and selecting the one predicted to perform best [Brewer, 1995; Lobjois and Lema\u0131\u0302tre, 1998; Fink, 1998; Howe et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17063820,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "590fbc7b3b06416b72e23ef02e96ba5831977a3c",
            "isKey": false,
            "numCitedBy": 496,
            "numCiting": 120,
            "paperAbstract": {
                "fragments": [],
                "text": "The algorithm selection problem [Rice 1976] seeks to answer the question: Which algorithm is likely to perform best for my problem? Recognizing the problem as a learning task in the early 1990's, the machine learning community has developed the field of meta-learning, focused on learning about learning algorithm performance on classification problems. But there has been only limited generalization of these ideas beyond classification, and many related attempts have been made in other disciplines (such as AI and operations research) to tackle the algorithm selection problem in different ways, introducing different terminology, and overlooking the similarities of approaches. In this sense, there is much to be gained from a greater awareness of developments in meta-learning, and how these ideas can be generalized to learn about the behaviors of other (nonlearning) algorithms. In this article we present a unified framework for considering the algorithm selection problem as a learning problem, and use this framework to tie together the crossdisciplinary developments in tackling the algorithm selection problem. We discuss the generalization of meta-learning concepts to algorithms focused on tasks including sorting, forecasting, constraint satisfaction, and optimization, and the extension of these ideas to bioinformatics, cryptography, and other fields."
            },
            "slug": "Cross-disciplinary-perspectives-on-meta-learning-Smith\u2010Miles",
            "title": {
                "fragments": [],
                "text": "Cross-disciplinary perspectives on meta-learning for algorithm selection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The generalization of meta-learning concepts to algorithms focused on tasks including sorting, forecasting, constraint satisfaction, and optimization, and the extension of these ideas to bioinformatics, cryptography, and other fields are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "CSUR"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152895903"
                        ],
                        "name": "Lin Xu",
                        "slug": "Lin-Xu",
                        "structuredName": {
                            "firstName": "Lin",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lin Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388404060"
                        ],
                        "name": "Kevin Leyton-Brown",
                        "slug": "Kevin-Leyton-Brown",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Leyton-Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Leyton-Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", 2014b] basis [Rice, 1976; Smith-Miles, 2009; Kotthoff, 2014] has been successfully addressed by using EPMs to predict the performance of all candidate algorithms and selecting the one predicted to perform best [Brewer, 1995; Lobjois and Lema\u0131\u0302tre, 1998; Fink, 1998; Howe et al., 2000; Nudelman et al., 2003; Roberts and Howe, 2007; Xu et al., 2008; Kotthoff et al., 2012]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2022 RR: ridge regression with quadratic basis function expansion and forward selection as in early versions of SATzilla [Leyton-Brown et al., 2009; Xu et al., 2008]);"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "While the models were certainly not perfect, note that even the relatively poor predictions of ridge regression tended to be accurate within about an order of magnitude, which was sufficient to enable the portfolio-based algorithm selector SATzilla [Xu et al., 2008] to win five medals in each of the 2007 and 2009 SAT competitions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10987043,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72489f377f08ac720cd31d9eed20706abfed58bb",
            "isKey": false,
            "numCitedBy": 876,
            "numCiting": 99,
            "paperAbstract": {
                "fragments": [],
                "text": "It has been widely observed that there is no single \"dominant\" SAT solver; instead, different solvers perform best on different instances. Rather than following the traditional approach of choosing the best solver for a given class of instances, we advocate making this decision online on a per-instance basis. Building on previous work, we describe SATzilla, an automated approach for constructing per-instance algorithm portfolios for SAT that use so-called empirical hardness models to choose among their constituent solvers. This approach takes as input a distribution of problem instances and a set of component solvers, and constructs a portfolio optimizing a given objective function (such as mean runtime, percent of instances solved, or score in a competition). The excellent performance of SATzilla was independently verified in the 2007 SAT Competition, where our SATzilla07 solvers won three gold, one silver and one bronze medal. In this article, we go well beyond SATzilla07 by making the portfolio construction scalable and completely automated, and improving it by integrating local search solvers as candidate solvers, by predicting performance score instead of runtime, and by using hierarchical hardness models that take into account different types of SAT instances. We demonstrate the effectiveness of these new techniques in extensive experimental results on data sets including instances from the most recent SAT competition."
            },
            "slug": "SATzilla:-Portfolio-based-Algorithm-Selection-for-Xu-Hutter",
            "title": {
                "fragments": [],
                "text": "SATzilla: Portfolio-based Algorithm Selection for SAT"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "SATzilla is described, an automated approach for constructing per-instance algorithm portfolios for SAT that use so-called empirical hardness models to choose among their constituent solvers and is improved by integrating local search solvers as candidate solvers, by predicting performance score instead of runtime, and by using hierarchical hardness models that take into account different types of SAT instances."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759010"
                        ],
                        "name": "E. Brewer",
                        "slug": "E.-Brewer",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brewer",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brewer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", 2014b] basis [Rice, 1976; Smith-Miles, 2009; Kotthoff, 2014] has been successfully addressed by using EPMs to predict the performance of all candidate algorithms and selecting the one predicted to perform best [Brewer, 1995; Lobjois and Lema\u0131\u0302tre, 1998; Fink, 1998; Howe et al., 2000; Nudelman et al., 2003; Roberts and Howe, 2007; Xu et al., 2008; Kotthoff et al., 2012]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4522735,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "daab3fcf0e7300bfba1ea588f0681f451020311f",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop the use of statistical modeling for portable high-level optimizations such as data layout and algorithm selection. We build the models automatically from profiling information, which ensures robust and accurate models that reflect all aspects of the target platform.\nWe use the models to select among several data layouts for an iterative PDE solver and to select among several sorting algorithms. The selection is correct more than 99% of the time on each of four platforms. In the few cases it selects suboptimally, the selected implementation performs nearly as well; that is, it always makes at least a very good choice. Correct selection is platform and workload dependent and can improve performance by nearly a factor of three.\nWe also use the models to optimize parameters of these applications automatically. In all cases, the models predicted the optimal parameter setting, resulting in improvements ranging up to a factor of three.\nFinally, we use the models to construct portable high-level libraries, which contain multiple implementations and support for automatic selection and parameter optimization of the fastest implementation for the target platform and workload."
            },
            "slug": "High-level-optimization-via-automated-statistical-Brewer",
            "title": {
                "fragments": [],
                "text": "High-level optimization via automated statistical modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "This work develops the use of statistical modeling for portable high-level optimizations such as data layout and algorithm selection and builds the models automatically from profiling information, which ensures robust and accurate models that reflect all aspects of the target platform."
            },
            "venue": {
                "fragments": [],
                "text": "PPOPP '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144659218"
                        ],
                        "name": "C. Gomes",
                        "slug": "C.-Gomes",
                        "structuredName": {
                            "firstName": "Carla",
                            "lastName": "Gomes",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Gomes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744679"
                        ],
                        "name": "B. Selman",
                        "slug": "B.-Selman",
                        "structuredName": {
                            "firstName": "Bart",
                            "lastName": "Selman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Selman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701843"
                        ],
                        "name": "N. Crato",
                        "slug": "N.-Crato",
                        "structuredName": {
                            "firstName": "Nuno",
                            "lastName": "Crato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Crato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690271"
                        ],
                        "name": "Henry A. Kautz",
                        "slug": "Henry-A.-Kautz",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Kautz",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Henry A. Kautz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Less luckily, state-of-the-art algorithms often exhibit extreme runtime variation across instances from realistic distributions, even when problem size is held constant, and conversely the same instance can take dramatically different amounts of time to solve depending on the algorithm used [Gomes et al., 2000]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1748869,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6eb44d3238bcab0b0b7ad634288a49787b84abde",
            "isKey": false,
            "numCitedBy": 425,
            "numCiting": 97,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the runtime distributions of backtrack procedures for propositional satisfiability and constraint satisfaction. Such procedures often exhibit a large variability in performance. Our study reveals some intriguing properties of such distributions: They are often characterized by very long tails or \u201cheavy tails\u201d. We will show that these distributions are best characterized by a general class of distributions that can have infinite moments (i.e., an infinite mean, variance, etc.). Such nonstandard distributions have recently been observed in areas as diverse as economics, statistical physics, and geophysics. They are closely related to fractal phenomena, whose study was introduced by Mandelbrot. We also show how random restarts can effectively eliminate heavy-tailed behavior. Furthermore, for harder problem instances, we observe long tails on the left-hand side of the distribution, which is indicative of a non-negligible fraction of relatively short, successful runs. A rapid restart strategy eliminates heavy-tailed behavior and takes advantage of short runs, significantly reducing expected solution time. We demonstrate speedups of up to two orders of magnitude on SAT and CSP encodings of hard problems in planning, scheduling, and circuit synthesis."
            },
            "slug": "Heavy-Tailed-Phenomena-in-Satisfiability-and-Gomes-Selman",
            "title": {
                "fragments": [],
                "text": "Heavy-Tailed Phenomena in Satisfiability and Constraint Satisfaction Problems"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "It is shown that these runtime distributions of backtrack procedures for propositional satisfiability and constraint satisfaction are best characterized by a general class of distributions that can have infinite moments (i.e., an infinite mean, variance, etc.)."
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Automated Reasoning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398371449"
                        ],
                        "name": "K. Smith\u2010Miles",
                        "slug": "K.-Smith\u2010Miles",
                        "structuredName": {
                            "firstName": "Kate",
                            "lastName": "Smith\u2010Miles",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Smith\u2010Miles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4369431"
                        ],
                        "name": "Jano van Hemert",
                        "slug": "Jano-van-Hemert",
                        "structuredName": {
                            "firstName": "Jano",
                            "lastName": "van Hemert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jano van Hemert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 21512740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f5897218707c653a31d4d5c179bd7af0201bfc4d",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "The suitability of an optimisation algorithm selected from within an algorithm portfolio depends upon the features of the particular instance to be solved. Understanding the relative strengths and weaknesses of different algorithms in the portfolio is crucial for effective performance prediction, automated algorithm selection, and to generate knowledge about the ideal conditions for each algorithm to influence better algorithm design. Relying on well-studied benchmark instances, or randomly generated instances, limits our ability to truly challenge each of the algorithms in a portfolio and determine these ideal conditions. Instead we use an evolutionary algorithm to evolve instances that are uniquely easy or hard for each algorithm, thus providing a more direct method for studying the relative strengths and weaknesses of each algorithm. The proposed methodology ensures that the meta-data is sufficient to be able to learn the features of the instances that uniquely characterise the ideal conditions for each algorithm. A case study is presented based on a comprehensive study of the performance of two heuristics on the Travelling Salesman Problem. The results show that prediction of search effort as well as the best performing algorithm for a given instance can be achieved with high accuracy."
            },
            "slug": "Discovering-the-suitability-of-optimisation-by-from-Smith\u2010Miles-Hemert",
            "title": {
                "fragments": [],
                "text": "Discovering the suitability of optimisation algorithms by learning from evolved instances"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This work uses an evolutionary algorithm to evolve instances that are uniquely easy or hard for each algorithm, thus providing a more direct method for studying the relative strengths and weaknesses of each algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "Annals of Mathematics and Artificial Intelligence"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1393588417"
                        ],
                        "name": "T. Bartz-Beielstein",
                        "slug": "T.-Bartz-Beielstein",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Bartz-Beielstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Bartz-Beielstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2565835"
                        ],
                        "name": "S. Markon",
                        "slug": "S.-Markon",
                        "structuredName": {
                            "firstName": "Sandor",
                            "lastName": "Markon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Markon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7041566,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9cee220298e83d4d04cce622067eac93b5552bff",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The optimization of complex real-world problems might benefit from well tuned algorithm's parameters. We propose a methodology that performs this tuning in an effective and efficient algorithmical manner. This approach combines methods from statistical design of experiments, regression analysis, design and analysis of computer experiments methods, and tree-based regression. It can also be applied to analyze the influence of different operators or to compare the performance of different algorithms. An evolution strategy and a simulated annealing algorithm that optimize an elevator supervisory group controller system are used to demonstrate the applicability of our approach to real-world optimization problems."
            },
            "slug": "Tuning-search-algorithms-for-real-world-a-tree-Bartz-Beielstein-Markon",
            "title": {
                "fragments": [],
                "text": "Tuning search algorithms for real-world applications: a regression tree based approach"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This approach combines methods from statistical design of experiments, regression analysis, design and analysis of computer experiments methods, and tree-based regression to perform algorithmical tuning of parameters of well tuned algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 Congress on Evolutionary Computation (IEEE Cat. No.04TH8753)"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3370368"
                        ],
                        "name": "Eugene Fink",
                        "slug": "Eugene-Fink",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Fink",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eugene Fink"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", 2014b] basis [Rice, 1976; Smith-Miles, 2009; Kotthoff, 2014] has been successfully addressed by using EPMs to predict the performance of all candidate algorithms and selecting the one predicted to perform best [Brewer, 1995; Lobjois and Lema\u0131\u0302tre, 1998; Fink, 1998; Howe et al., 2000; Nudelman et al., 2003; Roberts and Howe, 2007; Xu et al., 2008; Kotthoff et al., 2012]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5740393,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4af5fe9226bdd90610be463c0caaeb5a6b385fe",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "The choice of an appropriate problem-solving method, from available methods, is a crucial skill for experts in many areas. We describe a technique for the automatic selection among methods, which is based on a statistical analysis of their past performances. \n \nWe formalize the statistical problem involved in selecting an efficient problem-solving method, derive a solution to this problem, and describe a method-selection algorithm. The algorithm not only chooses among available methods, but also decides when to abandon the chosen method, if it proves to take too much time. We give empirical results on the use of this technique in selecting among search engines in the PRODIGY planning system."
            },
            "slug": "How-to-Solve-It-Automatically:-Selection-Among-Fink",
            "title": {
                "fragments": [],
                "text": "How to Solve It Automatically: Selection Among Problem Solving Methods"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A technique for the automatic selection among methods, which is based on a statistical analysis of their past performances is described, and a method-selection algorithm is described that not only chooses among available methods, but also decides when to abandon the chosen method, if it proves to take too much time."
            },
            "venue": {
                "fragments": [],
                "text": "AIPS"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3319413"
                        ],
                        "name": "Olaf Mersmann",
                        "slug": "Olaf-Mersmann",
                        "structuredName": {
                            "firstName": "Olaf",
                            "lastName": "Mersmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Olaf Mersmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686924"
                        ],
                        "name": "B. Bischl",
                        "slug": "B.-Bischl",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Bischl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Bischl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2981824"
                        ],
                        "name": "H. Trautmann",
                        "slug": "H.-Trautmann",
                        "structuredName": {
                            "firstName": "Heike",
                            "lastName": "Trautmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Trautmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145412358"
                        ],
                        "name": "Markus Wagner",
                        "slug": "Markus-Wagner",
                        "structuredName": {
                            "firstName": "Markus",
                            "lastName": "Wagner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markus Wagner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3011711"
                        ],
                        "name": "Jakob Bossek",
                        "slug": "Jakob-Bossek",
                        "structuredName": {
                            "firstName": "Jakob",
                            "lastName": "Bossek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jakob Bossek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144130135"
                        ],
                        "name": "F. Neumann",
                        "slug": "F.-Neumann",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Neumann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Neumann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Some models support such assessments directly [Ridge and Kudenko, 2007; Mersmann et al., 2013; Hutter et al., 2014a]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4972060,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47f9313055aa411ebf7780b8d1f79524bf5dd883",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "Meta-heuristics are frequently used to tackle NP-hard combinatorial optimization problems. With this paper we contribute to the understanding of the success of 2-opt based local search algorithms for solving the traveling salesperson problem (TSP). Although 2-opt is widely used in practice, it is hard to understand its success from a theoretical perspective. We take a statistical approach and examine the features of TSP instances that make the problem either hard or easy to solve. As a measure of problem difficulty for 2-opt we use the approximation ratio that it achieves on a given instance. Our investigations point out important features that make TSP instances hard or easy to be approximated by 2-opt."
            },
            "slug": "A-novel-feature-based-approach-to-characterize-for-Mersmann-Bischl",
            "title": {
                "fragments": [],
                "text": "A novel feature-based approach to characterize algorithm performance for the traveling salesperson problem"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This paper contributes to the understanding of the success of 2-opt based local search algorithms for solving the traveling salesperson problem with a statistical approach and examines the features of TSP instances that make the problem either hard or easy to solve."
            },
            "venue": {
                "fragments": [],
                "text": "Annals of Mathematics and Artificial Intelligence"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143746090"
                        ],
                        "name": "J. Rice",
                        "slug": "J.-Rice",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Rice",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rice"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", 2014b] basis [Rice, 1976; Smith-Miles, 2009; Kotthoff, 2014] has been successfully addressed by using EPMs to predict the performance of all candidate algorithms and selecting the one predicted to perform best [Brewer, 1995; Lobjois and Lema\u0131\u0302tre, 1998; Fink, 1998; Howe et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7554653,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "d8ae81043e96f0583501f7021abaa17db1a4be99",
            "isKey": false,
            "numCitedBy": 632,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Algorithm-Selection-Problem-Rice",
            "title": {
                "fragments": [],
                "text": "The Algorithm Selection Problem"
            },
            "venue": {
                "fragments": [],
                "text": "Adv. Comput."
            },
            "year": 1976
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1393588417"
                        ],
                        "name": "T. Bartz-Beielstein",
                        "slug": "T.-Bartz-Beielstein",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Bartz-Beielstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Bartz-Beielstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2278193"
                        ],
                        "name": "C. Lasarczyk",
                        "slug": "C.-Lasarczyk",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Lasarczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lasarczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1950379"
                        ],
                        "name": "M. Preuss",
                        "slug": "M.-Preuss",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Preuss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Preuss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "First, they can model the performance of a parameterized algorithm dependent on the settings of its parameters; in a sequential model-based optimization process, one alternates between learning an EPM and using it to identify promising settings to evaluate next [Jones et al., 1998; Bartz-Beielstein et al., 2005; Hutter et al., 2011]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6815175,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a99e54554731bda87e72024bb58da8c902d9800",
            "isKey": false,
            "numCitedBy": 325,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "Sequential parameter optimization is a heuristic that combines classical and modern statistical techniques to improve the performance of search algorithms. To demonstrate its flexibility, three scenarios are discussed: (1) no experience how to choose the parameter setting of an algorithm is available, (2) a comparison with other algorithms is needed, and (3) an optimization algorithm has to be applied effectively and efficiently to a complex real-world optimization problem. Although sequential parameter optimization relies on enhanced statistical techniques such as design and analysis of computer experiments, it can be performed algorithmically and requires basically the specification of the relevant algorithm's parameters"
            },
            "slug": "Sequential-parameter-optimization-Bartz-Beielstein-Lasarczyk",
            "title": {
                "fragments": [],
                "text": "Sequential parameter optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "Although sequential parameter optimization relies on enhanced statistical techniques such as design and analysis of computer experiments, it can be performed algorithmically and requires basically the specification of the relevant algorithm's parameters."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Congress on Evolutionary Computation"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3472959"
                        ],
                        "name": "C. Rasmussen",
                        "slug": "C.-Rasmussen",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Rasmussen",
                            "middleNames": [
                                "Edward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rasmussen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2022 GP: approximate Gaussian processes [Rasmussen and Williams, 2006], equipped with a new kernel for categorical parameters; and"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1430472,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82266f6103bade9005ec555ed06ba20b5210ff22",
            "isKey": false,
            "numCitedBy": 18076,
            "numCiting": 231,
            "paperAbstract": {
                "fragments": [],
                "text": "Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received growing attention in the machine learning community over the past decade. The book provides a long-needed, systematic and unified treatment of theoretical and practical aspects of GPs in machine learning. The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics. The book deals with the supervised learning problem for both regression and classification, and includes detailed algorithms. A wide variety of covariance (kernel) functions are presented and their properties discussed. Model selection is discussed both from a Bayesian and classical perspective. Many connections to other well-known techniques from machine learning and statistics are discussed, including support vector machines, neural networks, splines, regularization networks, relevance vector machines and others. Theoretical issues including learning curves and the PAC-Bayesian framework are treated, and several approximation methods for learning with large datasets are discussed. The book contains illustrative examples and exercises. Code and datasets can be obtained on the web. Appendices provide mathematical background and a discussion of Gaussian Markov processes."
            },
            "slug": "Gaussian-Processes-for-Machine-Learning-Rasmussen-Williams",
            "title": {
                "fragments": [],
                "text": "Gaussian Processes for Machine Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics, and deals with the supervised learning problem for both regression and classification."
            },
            "venue": {
                "fragments": [],
                "text": "Adaptive computation and machine learning"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722782"
                        ],
                        "name": "Lars Kotthoff",
                        "slug": "Lars-Kotthoff",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Kotthoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lars Kotthoff"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", 2014b] basis [Rice, 1976; Smith-Miles, 2009; Kotthoff, 2014] has been successfully addressed by using EPMs to predict the performance of all candidate algorithms and selecting the one predicted to perform best [Brewer, 1995; Lobjois and Lema\u0131\u0302tre, 1998; Fink, 1998; Howe et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14659766,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "9579a0ba622f4d4a7e158d76eaaf7bb2014419e6",
            "isKey": false,
            "numCitedBy": 296,
            "numCiting": 193,
            "paperAbstract": {
                "fragments": [],
                "text": "The Algorithm Selection Problem is concerned with selecting the best algorithm to solve a given problem on a case-by-case basis. It has become especially relevant in the last decade, as researchers are increasingly investigating how to identify the most suitable existing algorithm for solving a problem instead of developing new algorithms. This survey presents an overview of this work focusing on the contributions made in the area of combinatorial search problems, where Algorithm Selection techniques have achieved significant performance improvements. We unify and organise the vast literature according to criteria that determine Algorithm Selection systems in practice. The comprehensive classification of approaches identifies and analyses the different directions from which Algorithm Selection has been approached. This chapter contrasts and compares different methods for solving the problem as well as ways of using these solutions."
            },
            "slug": "Algorithm-Selection-for-Combinatorial-Search-A-Kotthoff",
            "title": {
                "fragments": [],
                "text": "Algorithm Selection for Combinatorial Search Problems: A Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This chapter contrasts and compares different methods for solving the problem as well as ways of using these solutions, and unify and organise the vast literature according to criteria that determine Algorithm Selection systems in practice."
            },
            "venue": {
                "fragments": [],
                "text": "AI Mag."
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2136919"
                        ],
                        "name": "A. Howe",
                        "slug": "A.-Howe",
                        "structuredName": {
                            "firstName": "Adele",
                            "lastName": "Howe",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Howe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30797446"
                        ],
                        "name": "E. Dahlman",
                        "slug": "E.-Dahlman",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Dahlman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Dahlman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052329189"
                        ],
                        "name": "Christoper Hansen",
                        "slug": "Christoper-Hansen",
                        "structuredName": {
                            "firstName": "Christoper",
                            "lastName": "Hansen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christoper Hansen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35568738"
                        ],
                        "name": "M. Scheetz",
                        "slug": "M.-Scheetz",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Scheetz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Scheetz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1712567"
                        ],
                        "name": "A. Andrews",
                        "slug": "A.-Andrews",
                        "structuredName": {
                            "firstName": "Anneliese",
                            "lastName": "Andrews",
                            "middleNames": [
                                "Amschler"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Andrews"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 15168606,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "333213da0d3277d3a0de143bef65fed5ae832a26",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "To date, no one planner has demonstrated clearly superior performance. Although researchers have hypothesized that this should be the case, no one has performed a large study to test its limits. In this research, we tested performance of a set of planners to determine which is best on what types of problems. The study included six planners and over 200 problems. We found that performance, as measured by number of problems solved and computation time, varied with no one planner solving all the problems or being consistently fastest. Analysis of the data also showed that most planners either fail or succeed quickly and that performance depends at least in part on some easily observable problem/domain features. Based on these results, we implemented a meta-planner that interleaves execution of six planners on a problem until one of them solves it. The control strategy for ordering the planners and allocating time is derived from the performance study data. We found that our meta-planner is able to solve more problems than any single planner, but at the expense of computation time."
            },
            "slug": "Exploiting-Competitive-Planner-Performance-Howe-Dahlman",
            "title": {
                "fragments": [],
                "text": "Exploiting Competitive Planner Performance"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This research tested performance of a set of planners to determine which is best on what types of problems and implemented a meta-planner that interleaves execution of six planners on a problem until one of them solves it."
            },
            "venue": {
                "fragments": [],
                "text": "ECP"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423230"
                        ],
                        "name": "L. Breiman",
                        "slug": "L.-Breiman",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Breiman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Breiman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2022 RF: random forests [Breiman, 2001], adapted with a new method to quantify predictive uncertainties and a new method for choosing split points to yield linear interpolations (and uncertainty estimates that grow with distance to observed data points) in the limit of an infinite number of trees."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 89141,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13d4c2f76a7c1a4d0a71204e1d5d263a3f5a7986",
            "isKey": false,
            "numCitedBy": 65885,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund & R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148\u2013156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression."
            },
            "slug": "Random-Forests-Breiman",
            "title": {
                "fragments": [],
                "text": "Random Forests"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the forest, and are also applicable to regression."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118096690"
                        ],
                        "name": "Donald R. Jones",
                        "slug": "Donald-R.-Jones",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Jones",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donald R. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815604"
                        ],
                        "name": "M. Schonlau",
                        "slug": "M.-Schonlau",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Schonlau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schonlau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145228938"
                        ],
                        "name": "W. Welch",
                        "slug": "W.-Welch",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Welch",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Welch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "First, they can model the performance of a parameterized algorithm dependent on the settings of its parameters; in a sequential model-based optimization process, one alternates between learning an EPM and using it to identify promising settings to evaluate next [Jones et al., 1998; Bartz-Beielstein et al., 2005; Hutter et al., 2011]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13068209,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "daa63f57c3fbe994c4356f8d986a22e696e776d2",
            "isKey": false,
            "numCitedBy": 5764,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "In many engineering optimization problems, the number of function evaluations is severely limited by time or cost. These problems pose a special challenge to the field of global optimization, since existing methods often require more function evaluations than can be comfortably afforded. One way to address this challenge is to fit response surfaces to data collected by evaluating the objective and constraint functions at a few points. These surfaces can then be used for visualization, tradeoff analysis, and optimization. In this paper, we introduce the reader to a response surface methodology that is especially good at modeling the nonlinear, multimodal functions that often occur in engineering. We then show how these approximating functions can be used to construct an efficient global optimization algorithm with a credible stopping rule. The key to using response surfaces for global optimization lies in balancing the need to exploit the approximating surface (by sampling where it is minimized) with the need to improve the approximation (by sampling where prediction error may be high). Striking this balance requires solving certain auxiliary problems which have previously been considered intractable, but we show how these computational obstacles can be overcome."
            },
            "slug": "Efficient-Global-Optimization-of-Expensive-Jones-Schonlau",
            "title": {
                "fragments": [],
                "text": "Efficient Global Optimization of Expensive Black-Box Functions"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper introduces the reader to a response surface methodology that is especially good at modeling the nonlinear, multimodal functions that often occur in engineering and shows how these approximating functions can be used to construct an efficient global optimization algorithm with a credible stopping rule."
            },
            "venue": {
                "fragments": [],
                "text": "J. Glob. Optim."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2835134"
                        ],
                        "name": "Enda Ridge",
                        "slug": "Enda-Ridge",
                        "structuredName": {
                            "firstName": "Enda",
                            "lastName": "Ridge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Enda Ridge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2380005"
                        ],
                        "name": "D. Kudenko",
                        "slug": "D.-Kudenko",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Kudenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kudenko"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Some models support such assessments directly [Ridge and Kudenko, 2007; Mersmann et al., 2013; Hutter et al., 2014a]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15664433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30e26fa656a3a36f59b18c3e307b0b2300bf771d",
            "isKey": false,
            "numCitedBy": 56,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an in-depth Design of Experiments (DOE) methodology for the performance analysis of a stochastic heuristic. The heuristic under investigation is Max-Min Ant System (MMAS). for the Travelling Salesperson Problem (TSP). Specifically, the Response Surface Methodology is used to model and tune MMAS performance with regard to 10 tuning parameters, 2 problem characteristics and 2 performance metrics--solution quality and solution time. The accuracy of these predictions is methodically verified in a separate series of confirmation experiments. The two conflicting responses are simultaneously optimised using desirability functions. Recommendations on optimal parameter settings are made. The optimal parameters are methodically verified. The large number of degrees-of-freedom in the MMAS design are overcome with a Minimum Run Resolution V design. Publicly available algorithm and problem generator implementations are used throughout. The paper should therefore serve as an illustrative case study of the principled engineering of a stochastic heuristic."
            },
            "slug": "Tuning-the-Performance-of-the-MMAS-Heuristic-Ridge-Kudenko",
            "title": {
                "fragments": [],
                "text": "Tuning the Performance of the MMAS Heuristic"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "An in-depth Design of Experiments (DOE) methodology for the performance analysis of a stochastic heuristic for the Travelling Salesperson Problem (TSP) using the Response Surface Methodology."
            },
            "venue": {
                "fragments": [],
                "text": "SLS"
            },
            "year": 2007
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 1,
            "methodology": 19
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 25,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Algorithm-Runtime-Prediction:-Methods-and-(Extended-Hutter-Xu/d3e7d210ffcda4caedbb6719750a7ddfa125d365?sort=total-citations"
}