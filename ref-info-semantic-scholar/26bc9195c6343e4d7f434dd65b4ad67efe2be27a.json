{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110452917"
                        ],
                        "name": "Jerry Ye",
                        "slug": "Jerry-Ye",
                        "structuredName": {
                            "firstName": "Jerry",
                            "lastName": "Ye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jerry Ye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39578080"
                        ],
                        "name": "J. Chow",
                        "slug": "J.-Chow",
                        "structuredName": {
                            "firstName": "Jyh-Herng",
                            "lastName": "Chow",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Chow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108311747"
                        ],
                        "name": "Jiang Chen",
                        "slug": "Jiang-Chen",
                        "structuredName": {
                            "firstName": "Jiang",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiang Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749245"
                        ],
                        "name": "Zhaohui Zheng",
                        "slug": "Zhaohui-Zheng",
                        "structuredName": {
                            "firstName": "Zhaohui",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhaohui Zheng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 269038,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2ee4b8bc544020c14d8be093182093dc16327c26",
            "isKey": false,
            "numCitedBy": 259,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Stochastic Gradient Boosted Decision Trees (GBDT) is one of the most widely used learning algorithms in machine learning today. It is adaptable, easy to interpret, and produces highly accurate models. However, most implementations today are computationally expensive and require all training data to be in main memory. As training data becomes ever larger, there is motivation for us to parallelize the GBDT algorithm. Parallelizing decision tree training is intuitive and various approaches have been explored in existing literature. Stochastic boosting on the other hand is inherently a sequential process and have not been applied to distributed decision trees. In this work, we present two different distributed methods that generates exact stochastic GBDT models, the first is a MapReduce implementation and the second utilizes MPI on the Hadoop grid environment."
            },
            "slug": "Stochastic-gradient-boosted-distributed-decision-Ye-Chow",
            "title": {
                "fragments": [],
                "text": "Stochastic gradient boosted distributed decision trees"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Two different distributed methods that generates exact stochastic GBDT models are presented, the first is a MapReduce implementation and the second utilizes MPI on the Hadoop grid environment."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34547779"
                        ],
                        "name": "Biswanath Panda",
                        "slug": "Biswanath-Panda",
                        "structuredName": {
                            "firstName": "Biswanath",
                            "lastName": "Panda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Biswanath Panda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101285460"
                        ],
                        "name": "Josh Herbach",
                        "slug": "Josh-Herbach",
                        "structuredName": {
                            "firstName": "Josh",
                            "lastName": "Herbach",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josh Herbach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40632403"
                        ],
                        "name": "Sugato Basu",
                        "slug": "Sugato-Basu",
                        "structuredName": {
                            "firstName": "Sugato",
                            "lastName": "Basu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sugato Basu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692160"
                        ],
                        "name": "R. Bayardo",
                        "slug": "R.-Bayardo",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Bayardo",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bayardo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9775238,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9e6c798940c9998477a462b50e0a5b07259f1056",
            "isKey": false,
            "numCitedBy": 299,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Classification and regression tree learning on massive datasets is a common data mining task at Google, yet many state of the art tree learning algorithms require training data to reside in memory on a single machine. While more scalable implementations of tree learning have been proposed, they typically require specialized parallel computing architectures. In contrast, the majority of Google's computing infrastructure is based on commodity hardware. \n \nIn this paper, we describe PLANET: a scalable distributed framework for learning tree models over large datasets. PLANET defines tree learning as a series of distributed computations, and implements each one using the MapReduce model of distributed computation. We show how this framework supports scalable construction of classification and regression trees, as well as ensembles of such models. We discuss the benefits and challenges of using a MapReduce compute cluster for tree learning, and demonstrate the scalability of this approach by applying it to a real world learning task from the domain of computational advertising."
            },
            "slug": "PLANET:-Massively-Parallel-Learning-of-Tree-with-Panda-Herbach",
            "title": {
                "fragments": [],
                "text": "PLANET: Massively Parallel Learning of Tree Ensembles with MapReduce"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper describes PLANET: a scalable distributed framework for learning tree models over large datasets, and shows how this framework supports scalable construction of classification and regression trees, as well as ensembles of such models."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. VLDB Endow."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1988453"
                        ],
                        "name": "R. Bekkerman",
                        "slug": "R.-Bekkerman",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Bekkerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bekkerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47695762"
                        ],
                        "name": "M. Bilenko",
                        "slug": "M.-Bilenko",
                        "structuredName": {
                            "firstName": "Mikhail",
                            "lastName": "Bilenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bilenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144162125"
                        ],
                        "name": "J. Langford",
                        "slug": "J.-Langford",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Langford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Langford"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 94
                            }
                        ],
                        "text": "We summarize an approximate framework, which resembles the ideas proposed in past literatures [17, 2, 22], in Alg."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 37214152,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5be3165d56580b60e29ad1a4a08b124d6cb8264",
            "isKey": false,
            "numCitedBy": 372,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "This tutorial gives a broad view of modern approaches for scaling up machine learning and data mining methods on parallel/distributed platforms. Demand for scaling up machine learning is task-specific: for some tasks it is driven by the enormous dataset sizes, for others by model complexity or by the requirement for real-time prediction. Selecting a task-appropriate parallelization platform and algorithm requires understanding their benefits, trade-offs and constraints. This tutorial focuses on providing an integrated overview of state-of-the-art platforms and algorithm choices. These span a range of hardware options (from FPGAs and GPUs to multi-core systems and commodity clusters), programming frameworks (including CUDA, MPI, MapReduce, and DryadLINQ), and learning settings (e.g., semi-supervised and online learning). The tutorial is example-driven, covering a number of popular algorithms (e.g., boosted trees, spectral clustering, belief propagation) and diverse applications (e.g., recommender systems and object recognition in vision).\n The tutorial is based on (but not limited to) the material from our upcoming Cambridge U. Press edited book which is currently in production.\n Visit the tutorial website at http://hunch.net/~large_scale_survey/"
            },
            "slug": "Scaling-up-machine-learning:-parallel-and-Bekkerman-Bilenko",
            "title": {
                "fragments": [],
                "text": "Scaling up machine learning: parallel and distributed approaches"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "This tutorial gives a broad view of modern approaches for scaling up machine learning and data mining methods on parallel/distributed platforms and provides an integrated overview of state-of-the-art platforms and algorithm choices."
            },
            "venue": {
                "fragments": [],
                "text": "KDD '11 Tutorials"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108925678"
                        ],
                        "name": "Rie Johnson",
                        "slug": "Rie-Johnson",
                        "structuredName": {
                            "firstName": "Rie",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rie Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50728655"
                        ],
                        "name": "Tong Zhang",
                        "slug": "Tong-Zhang",
                        "structuredName": {
                            "firstName": "Tong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tong Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "This this resembles previous work on regularized greedy forest [22], but simplifies the objective and algorithm for parallelization."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A similar regularization technique has been used in Regularized greedy forest (RGF) [22] model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12471709,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af08e1d1659788d756a731d1c12c16275cae3914",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of learning a forest of nonlinear decision rules with general loss functions. The standard methods employ boosted decision trees such as Adaboost for exponential loss and Friedman's gradient boosting for general loss. In contrast to these traditional boosting algorithms that treat a tree learner as a black box, the method we propose directly learns decision forests via fully-corrective regularized greedy search using the underlying forest structure. Our method achieves higher accuracy and smaller models than gradient boosting on many of the datasets we have tested on."
            },
            "slug": "Learning-Nonlinear-Functions-Using-Regularized-Johnson-Zhang",
            "title": {
                "fragments": [],
                "text": "Learning Nonlinear Functions Using Regularized Greedy Forest"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper proposes a method that directly learns decision forests via fully-corrective regularized greedy search using the underlying forest structure and achieves higher accuracy and smaller models than gradient boosting on many of the datasets it has tested on."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2342481"
                        ],
                        "name": "Stephen Tyree",
                        "slug": "Stephen-Tyree",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Tyree",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen Tyree"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7446832"
                        ],
                        "name": "Kilian Q. Weinberger",
                        "slug": "Kilian-Q.-Weinberger",
                        "structuredName": {
                            "firstName": "Kilian",
                            "lastName": "Weinberger",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kilian Q. Weinberger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366935"
                        ],
                        "name": "Kunal Agrawal",
                        "slug": "Kunal-Agrawal",
                        "structuredName": {
                            "firstName": "Kunal",
                            "lastName": "Agrawal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kunal Agrawal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2746989"
                        ],
                        "name": "Jennifer Paykin",
                        "slug": "Jennifer-Paykin",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Paykin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jennifer Paykin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "Notably, it is also possible to directly construct approximate histograms of gradient statistics [22]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "We compare against pGBRT [22], the best previously pubished system on this task."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 62
                            }
                        ],
                        "text": "While there are some existing works on parallel tree boosting [22, 23, 19], the directions such as out-of-core computation, cache-aware and sparsity-aware learning have not been explored."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 94
                            }
                        ],
                        "text": "We summarize an approximate framework, which resembles the ideas proposed in past literatures [17, 2, 22], in Alg."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 64
                            }
                        ],
                        "text": "There are several existing works on parallelizing tree learning [22, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6697674,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7d36de51ea248046cb26eedd63cc6619109bd55a",
            "isKey": true,
            "numCitedBy": 155,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Gradient Boosted Regression Trees (GBRT) are the current state-of-the-art learning paradigm for machine learned web-search ranking - a domain notorious for very large data sets. In this paper, we propose a novel method for parallelizing the training of GBRT. Our technique parallelizes the construction of the individual regression trees and operates using the master-worker paradigm as follows. The data are partitioned among the workers. At each iteration, the worker summarizes its data-partition using histograms. The master processor uses these to build one layer of a regression tree, and then sends this layer to the workers, allowing the workers to build histograms for the next layer. Our algorithm carefully orchestrates overlap between communication and computation to achieve good performance.\n Since this approach is based on data partitioning, and requires a small amount of communication, it generalizes to distributed and shared memory machines, as well as clouds. We present experimental results on both shared memory machines and clusters for two large scale web search ranking data sets. We demonstrate that the loss in accuracy induced due to the histogram approximation in the regression tree creation can be compensated for through slightly deeper trees. As a result, we see no significant loss in accuracy on the Yahoo data sets and a very small reduction in accuracy for the Microsoft LETOR data. In addition, on shared memory machines, we obtain almost perfect linear speed-up with up to about 48 cores on the large data sets. On distributed memory machines, we get a speedup of 25 with 32 processors. Due to data partitioning our approach can scale to even larger data sets, on which one can reasonably expect even higher speedups."
            },
            "slug": "Parallel-boosted-regression-trees-for-web-search-Tyree-Weinberger",
            "title": {
                "fragments": [],
                "text": "Parallel boosted regression trees for web search ranking"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A novel method for parallelizing the training of GBRT, which parallelizes the construction of the individual regression trees and operates using the master-worker paradigm, and demonstrates that the loss in accuracy induced due to the histogram approximation in the regression tree creation can be compensated for through slightly deeper trees."
            },
            "venue": {
                "fragments": [],
                "text": "WWW"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39309572"
                        ],
                        "name": "X. Meng",
                        "slug": "X.-Meng",
                        "structuredName": {
                            "firstName": "Xiangrui",
                            "lastName": "Meng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Meng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2086593199"
                        ],
                        "name": "Joseph K. Bradley",
                        "slug": "Joseph-K.-Bradley",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Bradley",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph K. Bradley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065287033"
                        ],
                        "name": "Burak Yavuz",
                        "slug": "Burak-Yavuz",
                        "structuredName": {
                            "firstName": "Burak",
                            "lastName": "Yavuz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Burak Yavuz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144752747"
                        ],
                        "name": "Evan R. Sparks",
                        "slug": "Evan-R.-Sparks",
                        "structuredName": {
                            "firstName": "Evan",
                            "lastName": "Sparks",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Evan R. Sparks"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2697906"
                        ],
                        "name": "S. Venkataraman",
                        "slug": "S.-Venkataraman",
                        "structuredName": {
                            "firstName": "Shivaram",
                            "lastName": "Venkataraman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Venkataraman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2536434"
                        ],
                        "name": "Davies Liu",
                        "slug": "Davies-Liu",
                        "structuredName": {
                            "firstName": "Davies",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Davies Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114973651"
                        ],
                        "name": "Jeremy Freeman",
                        "slug": "Jeremy-Freeman",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Freeman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeremy Freeman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064759911"
                        ],
                        "name": "D. B. Tsai",
                        "slug": "D.-B.-Tsai",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Tsai",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. B. Tsai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2089931559"
                        ],
                        "name": "Manish Amde",
                        "slug": "Manish-Amde",
                        "structuredName": {
                            "firstName": "Manish",
                            "lastName": "Amde",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manish Amde"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060860697"
                        ],
                        "name": "Sean Owen",
                        "slug": "Sean-Owen",
                        "structuredName": {
                            "firstName": "Sean",
                            "lastName": "Owen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sean Owen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40413768"
                        ],
                        "name": "Doris Xin",
                        "slug": "Doris-Xin",
                        "structuredName": {
                            "firstName": "Doris",
                            "lastName": "Xin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Doris Xin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066641"
                        ],
                        "name": "Reynold Xin",
                        "slug": "Reynold-Xin",
                        "structuredName": {
                            "firstName": "Reynold",
                            "lastName": "Xin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Reynold Xin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143666627"
                        ],
                        "name": "M. Franklin",
                        "slug": "M.-Franklin",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Franklin",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Franklin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5985064"
                        ],
                        "name": "R. Zadeh",
                        "slug": "R.-Zadeh",
                        "structuredName": {
                            "firstName": "Reza",
                            "lastName": "Zadeh",
                            "middleNames": [
                                "Bosagh"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zadeh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143834867"
                        ],
                        "name": "M. Zaharia",
                        "slug": "M.-Zaharia",
                        "structuredName": {
                            "firstName": "Matei",
                            "lastName": "Zaharia",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Zaharia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145532827"
                        ],
                        "name": "Ameet S. Talwalkar",
                        "slug": "Ameet-S.-Talwalkar",
                        "structuredName": {
                            "firstName": "Ameet",
                            "lastName": "Talwalkar",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ameet S. Talwalkar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7956687,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3784b73a1f392160523400ec0309191c0a96d86f",
            "isKey": false,
            "numCitedBy": 1507,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Apache Spark is a popular open-source platform for large-scale data processing that is well-suited for iterative machine learning tasks. In this paper we present MLlib, Spark's open-source distributed machine learning library. MLlib provides efficient functionality for a wide range of learning settings and includes several underlying statistical, optimization, and linear algebra primitives. Shipped with Spark, MLlib supports several languages and provides a high-level API that leverages Spark's rich ecosystem to simplify the development of end-to-end machine learning pipelines. MLlib has experienced a rapid growth due to its vibrant open-source community of over 140 contributors, and includes extensive documentation to support further growth and to let users quickly get up to speed."
            },
            "slug": "MLlib:-Machine-Learning-in-Apache-Spark-Meng-Bradley",
            "title": {
                "fragments": [],
                "text": "MLlib: Machine Learning in Apache Spark"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "MLlib is presented, Spark's open-source distributed machine learning library that provides efficient functionality for a wide range of learning settings and includes several underlying statistical, optimization, and linear algebra primitives."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144785135"
                        ],
                        "name": "Ping Li",
                        "slug": "Ping-Li",
                        "structuredName": {
                            "firstName": "Ping",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ping Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676309"
                        ],
                        "name": "C. Burges",
                        "slug": "C.-Burges",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burges",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burges"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108728368"
                        ],
                        "name": "Qiang Wu",
                        "slug": "Qiang-Wu",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14476078,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8c710c68dab80036b55dd48fbf1da0ecd4854cb",
            "isKey": false,
            "numCitedBy": 456,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We cast the ranking problem as (1) multiple classification (\"Mc\") (2) multiple ordinal classification, which lead to computationally tractable learning algorithms for relevance ranking in Web search. We consider the DCG criterion (discounted cumulative gain), a standard quality measure in information retrieval. Our approach is motivated by the fact that perfect classifications result in perfect DCG scores and the DCG errors are bounded by classification errors. We propose using the Expected Relevance to convert class probabilities into ranking scores. The class probabilities are learned using a gradient boosting tree algorithm. Evaluations on large-scale datasets show that our approach can improve LambdaRank [5] and the regressions-based ranker [6], in terms of the (normalized) DCG scores. An efficient implementation of the boosting tree algorithm is also presented."
            },
            "slug": "McRank:-Learning-to-Rank-Using-Multiple-and-Li-Burges",
            "title": {
                "fragments": [],
                "text": "McRank: Learning to Rank Using Multiple Classification and Gradient Boosting"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work considers the DCG criterion (discounted cumulative gain), a standard quality measure in information retrieval, and proposes using the Expected Relevance to convert class probabilities into ranking scores."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1913774"
                        ],
                        "name": "Tianqi Chen",
                        "slug": "Tianqi-Chen",
                        "structuredName": {
                            "firstName": "Tianqi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianqi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34650964"
                        ],
                        "name": "Sameer Singh",
                        "slug": "Sameer-Singh",
                        "structuredName": {
                            "firstName": "Sameer",
                            "lastName": "Singh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sameer Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685978"
                        ],
                        "name": "B. Taskar",
                        "slug": "B.-Taskar",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Taskar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Taskar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730156"
                        ],
                        "name": "Carlos Guestrin",
                        "slug": "Carlos-Guestrin",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Guestrin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlos Guestrin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 118
                            }
                        ],
                        "text": "Gradient tree boosting has been successfully used in classification [12], learning to rank [5], structured prediction [8] as well as other fields."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 107
                            }
                        ],
                        "text": "This enables data scientists as well as researchers to build powerful variants of tree boosting algorithms [7, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13848337,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6390c4bcc2268b91deb7d268b69ff21b87748d98",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Conditional random elds (CRFs) are an important class of models for accurate structured prediction, but eective design of the feature functions is a major challenge when applying CRF models to real world data. Gradient boosting, which is used to automatically induce and select feature functions, is a natural candidate solution to the problem. However, it is non-trivial to derive gradient boosting algorithms for CRFs due to the dense Hessian matrices introduced by variable dependencies. Existing approaches thus use only rst-order information when optimizing likelihood, and hence face convergence issues. We incorporate second-order information by deriving a Markov Chain mixing rate bound to quantify the dependencies, and introduce a gradient boosting algorithm that iteratively optimizes an adaptive upper bound of the objective function. The resulting algorithm induces and selects features for CRFs via functional space optimization, with provable convergence guarantees. Experimental results on three real world datasets demonstrate that the mixing rate based upper bound is eective for learning CRFs with non-linear potentials."
            },
            "slug": "Efficient-Second-Order-Gradient-Boosting-for-Random-Chen-Singh",
            "title": {
                "fragments": [],
                "text": "Efficient Second-Order Gradient Boosting for Conditional Random Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work incorporates second-order information by deriving a Markov Chain mixing rate bound to quantify the dependencies, and introduces a gradient boosting algorithm that iteratively optimizes an adaptive upper bound of the objective function."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9913392,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f4493eff2531536a7aeb3fc11d62c30a8f487f6",
            "isKey": false,
            "numCitedBy": 4870,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Boosting is one of the most important recent developments in classification methodology. Boosting works by sequentially applying a classification algorithm to reweighted versions of the training data and then taking a weighted majority vote of the sequence of classifiers thus produced. For many classification algorithms, this simple strategy results in dramatic improvements in performance. We show that this seemingly mysterious phenomenon can be understood in terms of well-known statistical principles, namely additive modeling and maximum likelihood. For the two-class problem, boosting can be viewed as an approximation to additive modeling on the logistic scale using maximum Bernoulli likelihood as a criterion. We develop more direct approximations and show that they exhibit nearly identical results to boosting. Direct multiclass generalizations based on multinomial likelihood are derived that exhibit performance comparable to other recently proposed multiclass generalizations of boosting in most situations, and far superior in some. We suggest a minor modification to boosting that can reduce computation, often by factors of 10 to 50. Finally, we apply these insights to produce an alternative formulation of boosting decision trees. This approach, based on best-first truncated tree induction, often leads to better performance, and can provide interpretable descriptions of the aggregate decision rule. It is also much faster computationally, making it more suitable to large-scale data mining applications."
            },
            "slug": "Special-Invited-Paper-Additive-logistic-regression:-Friedman",
            "title": {
                "fragments": [],
                "text": "Special Invited Paper-Additive logistic regression: A statistical view of boosting"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work shows that this seemingly mysterious phenomenon of boosting can be understood in terms of well-known statistical principles, namely additive modeling and maximum likelihood, and develops more direct approximations and shows that they exhibit nearly identical results to boosting."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "Our system implements gradient boosting [10], which performs additive optimization in functional space."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "Among the machine learning methods used in practice, gradient tree boosting [10](1) is one technique that shines in many applications."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 39450643,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1679beddda3a183714d380e944fe6bf586c083cd",
            "isKey": false,
            "numCitedBy": 13931,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Function estimation/approximation is viewed from the perspective of numerical optimization in function space, rather than parameter space. A connection is made between stagewise additive expansions and steepest-descent minimization. A general gradient descent boosting paradigm is developed for additive expansions based on any fitting criterion. Specific algorithms are presented for least-squares, least absolute deviation, and Huber-M loss functions for regression, and multiclass logistic likelihood for classification. Special enhancements are derived for the particular case where the individual additive components are regression trees, and tools for interpreting such TreeBoost models are presented. Gradient boosting of regression trees produces competitive, highly robust, interpretable procedures for both regression and classification, especially appropriate for mining less than clean data. Connections between this approach and the boosting methods of Freund and Shapire and Friedman, Hastie and Tibshirani are discussed."
            },
            "slug": "Greedy-function-approximation:-A-gradient-boosting-Friedman",
            "title": {
                "fragments": [],
                "text": "Greedy function approximation: A gradient boosting machine."
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A general gradient descent boosting paradigm is developed for additive expansions based on any fitting criterion, and specific algorithms are presented for least-squares, least absolute deviation, and Huber-M loss functions for regression, and multiclass logistic likelihood for classification."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145797806"
                        ],
                        "name": "G. Ridgeway",
                        "slug": "G.-Ridgeway",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Ridgeway",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Ridgeway"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12781809,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "19610284b552cd509f1c467020933c2849c170ea",
            "isKey": false,
            "numCitedBy": 740,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Boosting takes on various forms with different programs using different loss functions, different base models, and different optimization schemes. The gbm package takes the approach described in [2] and [3]. Some of the terminology differs, mostly due to an effort to cast boosting terms into more standard statistical terminology (e.g. deviance). In addition, the gbm package implements boosting for models commonly used in statistics but not commonly associated with boosting. The Cox proportional hazard model, for example, is an incredibly useful model and the boosting framework applies quite readily with only slight modification [5]. Also some algorithms implemented in the gbm package differ from the standard implementation. The AdaBoost algorithm [1] has a particular loss function and a particular optimization algorithm associated with it. The gbm implementation of AdaBoost adopts AdaBoost\u2019s exponential loss function (its bound on misclassification rate) but uses Friedman\u2019s gradient descent algorithm rather than the original one proposed. So the main purposes of this document is to spell out in detail what the gbm package implements."
            },
            "slug": "Generalized-Boosted-Models:-A-guide-to-the-gbm-Ridgeway",
            "title": {
                "fragments": [],
                "text": "Generalized Boosted Models: A guide to the gbm package"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The main purposes of this document is to spell out in detail what the gbm package implements, mostly due to an effort to cast boosting terms into more standard statistical terminology."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1913774"
                        ],
                        "name": "Tianqi Chen",
                        "slug": "Tianqi-Chen",
                        "structuredName": {
                            "firstName": "Tianqi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianqi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49404233"
                        ],
                        "name": "Hang Li",
                        "slug": "Hang-Li",
                        "structuredName": {
                            "firstName": "Hang",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hang Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152290618"
                        ],
                        "name": "Qiang Yang",
                        "slug": "Qiang-Yang",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1811427"
                        ],
                        "name": "Yong Yu",
                        "slug": "Yong-Yu",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yong Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 107
                            }
                        ],
                        "text": "This enables data scientists as well as researchers to build powerful variants of tree boosting algorithms [7, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1414354,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8588ec3fe0bfc6ebb763d0270608b85a5afdea61",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Matrix factorization is among the most successful techniques for collaborative filtering. One challenge of collaborative filtering is how to utilize available auxiliary information to improve prediction accuracy. In this paper, we study the problem of utilizing auxiliary information as features of factorization and propose formalizing the problem as general functional matrix factorization, whose model includes conventional matrix factorization models as its special cases. Moreover, we propose a gradient boosting based algorithm to efficiently solve the optimization problem. Finally, we give two specific algorithms for efficient feature function construction for two specific tasks. Our method can construct more suitable feature functions by searching in an infinite functional space based on training data and thus can yield better prediction accuracy. The experimental results demonstrate that the proposed method out-performs the baseline methods on three realworld datasets."
            },
            "slug": "General-Functional-Matrix-Factorization-Using-Chen-Li",
            "title": {
                "fragments": [],
                "text": "General Functional Matrix Factorization Using Gradient Boosting"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper studies the problem of utilizing auxiliary information as features of factorization and proposes formalizing the problem as general functional matrix factorization, whose model includes conventional matrixfactorization models as its special cases."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2676309"
                        ],
                        "name": "C. Burges",
                        "slug": "C.-Burges",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Burges",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Burges"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 397316,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0df9c70875783a73ce1e933079f328e8cf5e9ea2",
            "isKey": false,
            "numCitedBy": 968,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "LambdaMART is the boosted tree version of LambdaRank, which is based on RankNet. RankNet, LambdaRank, and LambdaMART have proven to be very successful algorithms for solving real world ranking problems: for example an ensemble of LambdaMART rankers won Track 1 of the 2010 Yahoo! Learning To Rank Challenge. The details of these algorithms are spread across several papers and reports, and so here we give a self-contained, detailed and complete description of them."
            },
            "slug": "From-RankNet-to-LambdaRank-to-LambdaMART:-An-Burges",
            "title": {
                "fragments": [],
                "text": "From RankNet to LambdaRank to LambdaMART: An Overview"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "RankNet, LambdaRank, and LambdaMART have proven to be very successful algorithms for solving real world ranking problems and the details are spread across several papers and reports, so here is a self-contained, detailed and complete description of them."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730609"
                        ],
                        "name": "O. Chapelle",
                        "slug": "O.-Chapelle",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Chapelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chapelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145882798"
                        ],
                        "name": "Yi Chang",
                        "slug": "Yi-Chang",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5763769,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7df5a2760b055745f6d591c1ed7be5a7a23cf854",
            "isKey": false,
            "numCitedBy": 492,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning to rank for information retrieval has gained a lot of interest in the recent years but there is a lack for large real-world datasets to benchmark algorithms. That led us to publicly release two datasets used internally at Yahoo! for learning the web search ranking function. To promote these datasets and foster the development of state-of-the-art learning to rank algorithms, we organized the Yahoo! Learning to Rank Challenge in spring 2010. This paper provides an overview and an analysis of this challenge, along with a detailed description of the released datasets."
            },
            "slug": "Yahoo!-Learning-to-Rank-Challenge-Overview-Chapelle-Chang",
            "title": {
                "fragments": [],
                "text": "Yahoo! Learning to Rank Challenge Overview"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper provides an overview and an analysis of this challenge, along with a detailed description of the released datasets, used internally at Yahoo! for learning the web search ranking function."
            },
            "venue": {
                "fragments": [],
                "text": "Yahoo! Learning to Rank Challenge"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": "The first technique is shrinkage introduced by Friedman [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 55
                            }
                        ],
                        "text": "Specicially the second order method is originated from Friedman et al. [12]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16190154,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8bdda840ec8990e24c5a70db171edac330ebf650",
            "isKey": false,
            "numCitedBy": 4301,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Stochastic-gradient-boosting-Friedman",
            "title": {
                "fragments": [],
                "text": "Stochastic gradient boosting"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2570016"
                        ],
                        "name": "Fabian Pedregosa",
                        "slug": "Fabian-Pedregosa",
                        "structuredName": {
                            "firstName": "Fabian",
                            "lastName": "Pedregosa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fabian Pedregosa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3025780"
                        ],
                        "name": "G. Varoquaux",
                        "slug": "G.-Varoquaux",
                        "structuredName": {
                            "firstName": "Ga\u00ebl",
                            "lastName": "Varoquaux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Varoquaux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797840"
                        ],
                        "name": "Alexandre Gramfort",
                        "slug": "Alexandre-Gramfort",
                        "structuredName": {
                            "firstName": "Alexandre",
                            "lastName": "Gramfort",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexandre Gramfort"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52200573"
                        ],
                        "name": "V. Michel",
                        "slug": "V.-Michel",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Michel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Michel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8493461"
                        ],
                        "name": "B. Thirion",
                        "slug": "B.-Thirion",
                        "structuredName": {
                            "firstName": "Bertrand",
                            "lastName": "Thirion",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Thirion"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2958756"
                        ],
                        "name": "O. Grisel",
                        "slug": "O.-Grisel",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Grisel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Grisel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27257992"
                        ],
                        "name": "Mathieu Blondel",
                        "slug": "Mathieu-Blondel",
                        "structuredName": {
                            "firstName": "Mathieu",
                            "lastName": "Blondel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mathieu Blondel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1881041"
                        ],
                        "name": "Gilles Louppe",
                        "slug": "Gilles-Louppe",
                        "structuredName": {
                            "firstName": "Gilles",
                            "lastName": "Louppe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gilles Louppe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2780213"
                        ],
                        "name": "P. Prettenhofer",
                        "slug": "P.-Prettenhofer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Prettenhofer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Prettenhofer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067827437"
                        ],
                        "name": "Ron Weiss",
                        "slug": "Ron-Weiss",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ron Weiss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39571582"
                        ],
                        "name": "Ron J. Weiss",
                        "slug": "Ron-J.-Weiss",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Weiss",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ron J. Weiss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2081469"
                        ],
                        "name": "J. Vanderplas",
                        "slug": "J.-Vanderplas",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Vanderplas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Vanderplas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144720379"
                        ],
                        "name": "Alexandre Passos",
                        "slug": "Alexandre-Passos",
                        "structuredName": {
                            "firstName": "Alexandre",
                            "lastName": "Passos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexandre Passos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3084321"
                        ],
                        "name": "D. Cournapeau",
                        "slug": "D.-Cournapeau",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cournapeau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cournapeau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423884"
                        ],
                        "name": "M. Brucher",
                        "slug": "M.-Brucher",
                        "structuredName": {
                            "firstName": "Matthieu",
                            "lastName": "Brucher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brucher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35243423"
                        ],
                        "name": "M. Perrot",
                        "slug": "M.-Perrot",
                        "structuredName": {
                            "firstName": "Matthieu",
                            "lastName": "Perrot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Perrot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710398"
                        ],
                        "name": "E. Duchesnay",
                        "slug": "E.-Duchesnay",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Duchesnay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Duchesnay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10659969,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "168f28ac3c8c7ea63bf7ed25f2288e8b67e2fe74",
            "isKey": false,
            "numCitedBy": 43894,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net."
            },
            "slug": "Scikit-learn:-Machine-Learning-in-Python-Pedregosa-Varoquaux",
            "title": {
                "fragments": [],
                "text": "Scikit-learn: Machine Learning in Python"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems, focusing on bringing machine learning to non-specialists using a general-purpose high-level language."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31492919"
                        ],
                        "name": "Bogdan E. Popescu",
                        "slug": "Bogdan-E.-Popescu",
                        "structuredName": {
                            "firstName": "Bogdan",
                            "lastName": "Popescu",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bogdan E. Popescu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2421849,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "966ffe536f84efd15c1379dad9adffe90b20676f",
            "isKey": false,
            "numCitedBy": 120,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning a function of many arguments is viewed from the perspective of high\u2013 dimensional numerical quadrature. It is shown that many of the popular ensemble learning procedures can be cast in this framework. In particular randomized methods, including bagging and random forests, are seen to correspond to random Monte Carlo integration methods each based on particular importance sampling strategies. Non random boosting methods are seen to correspond to deterministic quasi Monte Carlo integration techniques. This view helps explain some of their properties and suggests modifications to them that can substantially improve their accuracy while dramatically improving computational performance."
            },
            "slug": "Importance-Sampled-Learning-Ensembles-Friedman-Popescu",
            "title": {
                "fragments": [],
                "text": "Importance Sampled Learning Ensembles"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "It is shown that many of the popular ensemble learning procedures can be cast in this framework and some of their properties are explained and modifications to them are suggested that can substantially improve their accuracy while dramatically improving computational performance."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113543585"
                        ],
                        "name": "J. Bennett",
                        "slug": "J.-Bennett",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bennett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bennett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47511653"
                        ],
                        "name": "S. Lanning",
                        "slug": "S.-Lanning",
                        "structuredName": {
                            "firstName": "Stan",
                            "lastName": "Lanning",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lanning"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 105
                            }
                        ],
                        "text": "Finally, it is the defacto choice of ensemble method and is used in challenges such as the Netflix prize [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9528522,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31af4b8793e93fd35e89569ccd663ae8777f0072",
            "isKey": false,
            "numCitedBy": 1965,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Netflix released a dataset containing 100 million anonymous movie ratings and challenged the data mining, machine learning and computer science communities to develop systems that could beat the accuracy of its recommendation system, Cinematch. We briefly describe the challenge itself, review related work and efforts, and summarize visible progress to date. Other potential uses of the data are outlined, including its application to the KDD Cup 2007."
            },
            "slug": "The-Netflix-Prize-Bennett-Lanning",
            "title": {
                "fragments": [],
                "text": "The Netflix Prize"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Netflix released a dataset containing 100 million anonymous movie ratings and challenged the data mining, machine learning and computer science communities to develop systems that could beat the accuracy of its recommendation system, Cinematch."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1849128"
                        ],
                        "name": "Rong-En Fan",
                        "slug": "Rong-En-Fan",
                        "structuredName": {
                            "firstName": "Rong-En",
                            "lastName": "Fan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rong-En Fan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2782886"
                        ],
                        "name": "Kai-Wei Chang",
                        "slug": "Kai-Wei-Chang",
                        "structuredName": {
                            "firstName": "Kai-Wei",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai-Wei Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793529"
                        ],
                        "name": "Cho-Jui Hsieh",
                        "slug": "Cho-Jui-Hsieh",
                        "structuredName": {
                            "firstName": "Cho-Jui",
                            "lastName": "Hsieh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cho-Jui Hsieh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144799660"
                        ],
                        "name": "Xiang-Rui Wang",
                        "slug": "Xiang-Rui-Wang",
                        "structuredName": {
                            "firstName": "Xiang-Rui",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiang-Rui Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711460"
                        ],
                        "name": "Chih-Jen Lin",
                        "slug": "Chih-Jen-Lin",
                        "structuredName": {
                            "firstName": "Chih-Jen",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chih-Jen Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3116168,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "268a4f8da15a42f3e0e71691f760ff5edbf9cec8",
            "isKey": false,
            "numCitedBy": 7779,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "LIBLINEAR is an open source library for large-scale linear classification. It supports logistic regression and linear support vector machines. We provide easy-to-use command-line tools and library calls for users and developers. Comprehensive documents are available for both beginners and advanced users. Experiments demonstrate that LIBLINEAR is very efficient on large sparse data sets."
            },
            "slug": "LIBLINEAR:-A-Library-for-Large-Linear-Fan-Chang",
            "title": {
                "fragments": [],
                "text": "LIBLINEAR: A Library for Large Linear Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "LIBLINEAR is an open source library for large-scale linear classification that supports logistic regression and linear support vector machines and provides easy-to-use command-line tools and library calls for users and developers."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34593690"
                        ],
                        "name": "Xinran He",
                        "slug": "Xinran-He",
                        "structuredName": {
                            "firstName": "Xinran",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinran He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110201567"
                        ],
                        "name": "Junfeng Pan",
                        "slug": "Junfeng-Pan",
                        "structuredName": {
                            "firstName": "Junfeng",
                            "lastName": "Pan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junfeng Pan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067754685"
                        ],
                        "name": "Ou Jin",
                        "slug": "Ou-Jin",
                        "structuredName": {
                            "firstName": "Ou",
                            "lastName": "Jin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ou Jin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35533477"
                        ],
                        "name": "T. Xu",
                        "slug": "T.-Xu",
                        "structuredName": {
                            "firstName": "Tianbing",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2156642908"
                        ],
                        "name": "Bo Liu",
                        "slug": "Bo-Liu",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087783054"
                        ],
                        "name": "Tao Xu",
                        "slug": "Tao-Xu",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3133663"
                        ],
                        "name": "Yanxin Shi",
                        "slug": "Yanxin-Shi",
                        "structuredName": {
                            "firstName": "Yanxin",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yanxin Shi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401146241"
                        ],
                        "name": "Antoine Atallah",
                        "slug": "Antoine-Atallah",
                        "structuredName": {
                            "firstName": "Antoine",
                            "lastName": "Atallah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antoine Atallah"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3234984"
                        ],
                        "name": "R. Herbrich",
                        "slug": "R.-Herbrich",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Herbrich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Herbrich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40261778"
                        ],
                        "name": "S. Bowers",
                        "slug": "S.-Bowers",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Bowers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bowers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3177568"
                        ],
                        "name": "J. Q. Candela",
                        "slug": "J.-Q.-Candela",
                        "structuredName": {
                            "firstName": "Joaquin",
                            "lastName": "Candela",
                            "middleNames": [
                                "Qui\u00f1onero"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Q. Candela"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2999385,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "daf9ed5dc6c6bad5367d7fd8561527da30e9b8dd",
            "isKey": false,
            "numCitedBy": 629,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Online advertising allows advertisers to only bid and pay for measurable user responses, such as clicks on ads. As a consequence, click prediction systems are central to most online advertising systems. With over 750 million daily active users and over 1 million active advertisers, predicting clicks on Facebook ads is a challenging machine learning task. In this paper we introduce a model which combines decision trees with logistic regression, outperforming either of these methods on its own by over 3%, an improvement with significant impact to the overall system performance. We then explore how a number of fundamental parameters impact the final prediction performance of our system. Not surprisingly, the most important thing is to have the right features: those capturing historical information about the user or ad dominate other types of features. Once we have the right features and the right model (decisions trees plus logistic regression), other factors play small roles (though even small improvements are important at scale). Picking the optimal handling for data freshness, learning rate schema and data sampling improve the model slightly, though much less than adding a high-value feature, or picking the right model to begin with."
            },
            "slug": "Practical-Lessons-from-Predicting-Clicks-on-Ads-at-He-Pan",
            "title": {
                "fragments": [],
                "text": "Practical Lessons from Predicting Clicks on Ads at Facebook"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper introduces a model which combines decision trees with logistic regression, outperforming either of these methods on its own by over 3%, an improvement with significant impact to the overall system performance."
            },
            "venue": {
                "fragments": [],
                "text": "ADKDD'14"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423230"
                        ],
                        "name": "L. Breiman",
                        "slug": "L.-Breiman",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Breiman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Breiman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 26
                            }
                        ],
                        "text": "This technique is used in RandomForest [4,\nAlgorithm 1: Exact Greedy Algorithm for Split Finding\nInput: I, instance set of current node Input: d, feature dimension gain\u2190 0 G\u2190 \u2211 i\u2208I gi, H \u2190 \u2211 i\u2208I hi for k = 1 to m do GL \u2190 0, HL \u2190 0 for j in sorted(I, by xjk) do\nGL \u2190 GL + gj , HL \u2190 HL + hj GR \u2190 G\u2212GL, HR \u2190 H \u2212HL score\u2190 max(score, G 2 L\nHL+\u03bb + G2R HR+\u03bb \u2212 G 2 H+\u03bb )\nend\nend Output: Split with max score\nAlgorithm 2: Approximate Algorithm for Split Finding\nfor k = 1 to m do Propose Sk = {sk1, sk2, \u00b7 \u00b7 \u00b7 skl} by percentiles on feature k. Proposal can be done per tree (global), or per split(local). end for k = 1 to m do\nGkv \u2190= \u2211 j\u2208{j|sk,v\u2265xjk>sk,v\u22121} gj\nHkv \u2190= \u2211 j\u2208{j|sk,v\u2265xjk>sk,v\u22121} hj\nend Follow same step as in previous section to find max score only among proposed splits."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 79
                            }
                        ],
                        "text": "Column sampling is a simple but effective technique borrowed from RandomForest [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 89141,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13d4c2f76a7c1a4d0a71204e1d5d263a3f5a7986",
            "isKey": false,
            "numCitedBy": 65885,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund & R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148\u2013156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression."
            },
            "slug": "Random-Forests-Breiman",
            "title": {
                "fragments": [],
                "text": "Random Forests"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the forest, and are also applicable to regression."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144785135"
                        ],
                        "name": "Ping Li",
                        "slug": "Ping-Li",
                        "structuredName": {
                            "firstName": "Ping",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ping Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 105
                            }
                        ],
                        "text": "Tree boosting has been shown to give state-of-the-art results on many standard classification benchmarks [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9020623,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e3e8d6cffe19a4aae526c988f0cf3d218ea601b0",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Logitboost is an influential boosting algorithm for classification. In this paper, we develop robust logitboost to provide an explicit formulation of tree-split criterion for building weak learners (regression trees) for logitboost. This formulation leads to a numerically stable implementation of logitboost. We then propose abc-logitboost for multi-class classification, by combining robust logitboost with the prior work of abc-boost. Previously, abc-boost was implemented as abc-mart using the mart algorithm. Our extensive experiments on multi-class classification compare four algorithms: mart, abcmart, (robust) logitboost, and abc-logitboost, and demonstrate the superiority of abc-logitboost. Comparisons with other learning methods including SVM and deep learning are also available through prior publications."
            },
            "slug": "Robust-LogitBoost-and-Adaptive-Base-Class-(ABC)-Li",
            "title": {
                "fragments": [],
                "text": "Robust LogitBoost and Adaptive Base Class (ABC) LogitBoost"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper develops robust logitboost to provide an explicit formulation of tree-split criterion for building weak learners (regression trees) for logitBoost, and proposes abc-logitboost for multi-class classification, by combining robust Logitboost with the prior work of abc."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1799297"
                        ],
                        "name": "M. Greenwald",
                        "slug": "M.-Greenwald",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Greenwald",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Greenwald"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144335444"
                        ],
                        "name": "S. Khanna",
                        "slug": "S.-Khanna",
                        "structuredName": {
                            "firstName": "Sanjeev",
                            "lastName": "Khanna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Khanna"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 84
                            }
                        ],
                        "text": "Quantile summary (without weights) is a classical problem in the database community [14, 24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 84
                            }
                        ],
                        "text": "When every instance has equal weights, an existing algorithm called quantile sketch [14, 24] solves the problem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13982939,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1f61892374c2be70f5924281c0d0e88dc4e02a25",
            "isKey": false,
            "numCitedBy": 519,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "An \u2208-approximate quantile summary of a sequence of N elements is a data structure that can answer quantile queries about the sequence to within a precision of \u2208N.\nWe present a new online algorithm for computing\u2208-approximate quantile summaries of very large data sequences. The algorithm has a worst-case space requirement of &Ogr;(1\u00f7\u2208 log(\u2208N)). This improves upon the previous best result of &Ogr;(1\u00f7\u2208 log2(\u2208N)). Moreover, in contrast to earlier deterministic algorithms, our algorithm does not require a priori knowledge of the length of the input sequence.\nFinally, the actual space bounds obtained on experimental data are significantly better than the worst case guarantees of our algorithm as well as the observed space requirements of earlier algorithms."
            },
            "slug": "Space-efficient-online-computation-of-quantile-Greenwald-Khanna",
            "title": {
                "fragments": [],
                "text": "Space-efficient online computation of quantile summaries"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The actual space bounds obtained on experimental data are significantly better than the worst case guarantees of the algorithm as well as the observed space requirements of earlier algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "SIGMOD '01"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731122"
                        ],
                        "name": "Qi Zhang",
                        "slug": "Qi-Zhang",
                        "structuredName": {
                            "firstName": "Qi",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qi Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49336997"
                        ],
                        "name": "Wei Wang",
                        "slug": "Wei-Wang",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 84
                            }
                        ],
                        "text": "Quantile summary (without weights) is a classical problem in the database community [14, 24]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 84
                            }
                        ],
                        "text": "When every instance has equal weights, an existing algorithm called quantile sketch [14, 24] solves the problem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 884789,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "03a0f978de91f70249dc39de75e8958c49df4583",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a fast algorithm for computing approximate quantiles in high speed data streams with deterministic error bounds. For data streams of size N where N is unknown in advance, our algorithm partitions the stream into sub-streams of exponentially increasing size as they arrive. For each sub-stream which has a fixed size, we compute and maintain a multi-level summary structure using a novel algorithm. In order to achieve high speed performance, the algorithm uses simple block-wise merge and sample operations. Overall, our algorithms for fixed-size streams and arbitrary-size streams have a computational cost of O(N log(1/epsivlogepsivN)) and an average per-element update cost of O(log logN) if epsiv is fixed."
            },
            "slug": "A-Fast-Algorithm-for-Approximate-Quantiles-in-High-Zhang-Wang",
            "title": {
                "fragments": [],
                "text": "A Fast Algorithm for Approximate Quantiles in High Speed Data Streams"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "A fast algorithm for computing approximate quantiles in high speed data streams with deterministic error bounds for data streams of size N where N is unknown in advance and the stream is partitioned into sub-streams of exponentially increasing size as they arrive."
            },
            "venue": {
                "fragments": [],
                "text": "19th International Conference on Scientific and Statistical Database Management (SSDBM 2007)"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3106783"
                        ],
                        "name": "J. Bed\u0151",
                        "slug": "J.-Bed\u0151",
                        "structuredName": {
                            "firstName": "Justin",
                            "lastName": "Bed\u0151",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bed\u0151"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706780"
                        ],
                        "name": "Cheng Soon Ong",
                        "slug": "Cheng-Soon-Ong",
                        "structuredName": {
                            "firstName": "Cheng Soon",
                            "lastName": "Ong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cheng Soon Ong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9882193,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04bdedb561c22d920e1b0145d0a342a68d2a4002",
            "isKey": false,
            "numCitedBy": 364,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the problem of rank aggregation: given a set of ranked lists, we want to form a consensus ranking. Furthermore, we consider the case of extreme lists: i.e., only the rank of the best or worst elements are known. We impute missing ranks and generalise Spearman's \u03c1 to extreme ranks. Our main contribution is the derivation of a non-parametric estimator for rank aggregation based on multivariate extensions of Spearman's \u03c1, which measures correlation between a set of ranked lists. Multivariate Spearman's \u03c1 is defined using copulas, and we show that the geometric mean of normalised ranks maximises multivariate correlation. Motivated by this, we propose a weighted geometric mean approach for learning to rank which has a closed form least squares solution. When only the best (top-k) or worst (bottom-k) elements of a ranked list are known, we impute the missing ranks by the average value, allowing us to apply Spearman's \u03c1. We discuss an optimistic and pessimistic imputation of missing values, which respectively maximise and minimise correlation, and show its effect on aggregating university rankings. Finally, we demonstrate good performance on the rank aggregation benchmarks MQ2007 and MQ2008."
            },
            "slug": "Multivariate-spearman's-\u03c1-for-aggregating-ranks-Bed\u0151-Ong",
            "title": {
                "fragments": [],
                "text": "Multivariate spearman's \u03c1 for aggregating ranks using copulas"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The main contribution is the derivation of a non-parametric estimator for rank aggregation based on multivariate extensions of Spearman's \u03c1, which measures correlation between a set of ranked lists."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Additive logistic regression: a statistical view of boosting. The annals of statistics"
            },
            "venue": {
                "fragments": [],
                "text": "Additive logistic regression: a statistical view of boosting. The annals of statistics"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The netflix prize Random forests"
            },
            "venue": {
                "fragments": [],
                "text": "Scaling Up Machine Learning : Parallel and Distributed Approaches"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 47
                            }
                        ],
                        "text": "The system is available as an open source package2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The present and the future of the kdd cup competition: an outsider's perspective"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The netflix prize Random forests"
            },
            "venue": {
                "fragments": [],
                "text": "Maching Learning"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 40
                            }
                        ],
                        "text": "However, usually more candidate points are needed for the global proposal because candidates are not refined after each split."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Random forests. Maching Learning"
            },
            "venue": {
                "fragments": [],
                "text": "Random forests. Maching Learning"
            },
            "year": 2001
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 7,
            "methodology": 11
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 30,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/XGBoost:-A-Scalable-Tree-Boosting-System-Chen-Guestrin/26bc9195c6343e4d7f434dd65b4ad67efe2be27a?sort=total-citations"
}