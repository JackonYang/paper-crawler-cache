{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118116274"
                        ],
                        "name": "Yunhong Zhou",
                        "slug": "Yunhong-Zhou",
                        "structuredName": {
                            "firstName": "Yunhong",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yunhong Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39856623"
                        ],
                        "name": "D. Wilkinson",
                        "slug": "D.-Wilkinson",
                        "structuredName": {
                            "firstName": "Dennis",
                            "lastName": "Wilkinson",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Wilkinson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143986781"
                        ],
                        "name": "R. Schreiber",
                        "slug": "R.-Schreiber",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schreiber",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schreiber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066007146"
                        ],
                        "name": "Rong Pan",
                        "slug": "Rong-Pan",
                        "structuredName": {
                            "firstName": "Rong",
                            "lastName": "Pan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rong Pan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 71
                            }
                        ],
                        "text": "(4) subsumes the special case of regularized low-rank approximation in [21, 30]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "1 ) Reconstruct R\u0302i from R\u0303i by ALS [30] end for"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[30] show that the alternating least squares (ALS) [11] approach is efficient for solving these low rank approximation problems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8574004,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4e8e3e40a25fba903f40246705c3beb3c122f523",
            "isKey": false,
            "numCitedBy": 780,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Many recommendation systems suggest items to users by utilizing the techniques of collaborative filtering(CF) based on historical records of items that the users have viewed, purchased, or rated. Two major problems that most CF approaches have to contend with are scalability and sparseness of the user profiles. To tackle these issues, in this paper, we describe a CF algorithm alternating-least-squares with weighted-?-regularization(ALS-WR), which is implemented on a parallel Matlab platform. We show empirically that the performance of ALS-WR (in terms of root mean squared error(RMSE)) monotonically improves with both the number of features and the number of ALS iterations. We applied the ALS-WR algorithm on a large-scale CF problem, the Netflix Challenge, with 1000 hidden features and obtained a RMSE score of 0.8985, which is one of the best results based on a pure method. In addition, combining with the parallel version of other known methods, we achieved a performance improvement of 5.91% over Netflix's own CineMatch recommendation system. Our method is simple and scales well to very large datasets."
            },
            "slug": "Large-Scale-Parallel-Collaborative-Filtering-for-Zhou-Wilkinson",
            "title": {
                "fragments": [],
                "text": "Large-Scale Parallel Collaborative Filtering for the Netflix Prize"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper describes a CF algorithm alternating-least-squares with weighted-?-regularization(ALS-WR), which is implemented on a parallel Matlab platform and shows empirically that the performance of ALS-WR monotonically improves with both the number of features and thenumber of ALS iterations."
            },
            "venue": {
                "fragments": [],
                "text": "AAIM"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143931934"
                        ],
                        "name": "Ingo Schwab",
                        "slug": "Ingo-Schwab",
                        "structuredName": {
                            "firstName": "Ingo",
                            "lastName": "Schwab",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ingo Schwab"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113288268"
                        ],
                        "name": "Alfred Kobs",
                        "slug": "Alfred-Kobs",
                        "structuredName": {
                            "firstName": "Alfred",
                            "lastName": "Kobs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alfred Kobs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52553663"
                        ],
                        "name": "Ivan Koychev",
                        "slug": "Ivan-Koychev",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Koychev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ivan Koychev"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17222217,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bf7da1d89a1e5e2dd530859ba31ba592b04403f3",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "An approach to learning user interests is presented that borrows from findings in the area of human-computer interaction, user modeling and information retrieval. It relies on positive evidences only, in consideration of the fact that users rarely supply the ratings needed by traditional learning algorithms, specifically not negative examples. Learning results are explicitly represented to account for the fact that in the area of user modeling explicit representations are known to be considerably more useful than purely implicit representations. A content-based recommendation approach is complemented by recommendation based on community membership, thus avoiding getting trapped in possible \"local optima\" of the content-based approaches. Finally, gradual forgetting of older observations has been introduced to better account for drifting user interests. The described framework has been extensively tested in a web-based information system for research funding opportunities."
            },
            "slug": "Learning-User-Interests-through-Positive-Examples-Schwab-Kobs",
            "title": {
                "fragments": [],
                "text": "Learning User Interests through Positive Examples Using Content Analysis and Collaborative Filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "An approach to learning user interests is presented that borrows from findings in the area of human-computer interaction, user modeling and information retrieval, and relies on positive evidences only, in consideration of the fact that users rarely supply the ratings needed by traditional learning algorithms."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2892654"
                        ],
                        "name": "Abhinandan Das",
                        "slug": "Abhinandan-Das",
                        "structuredName": {
                            "firstName": "Abhinandan",
                            "lastName": "Das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abhinandan Das"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145112445"
                        ],
                        "name": "Mayur Datar",
                        "slug": "Mayur-Datar",
                        "structuredName": {
                            "firstName": "Mayur",
                            "lastName": "Datar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mayur Datar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729828"
                        ],
                        "name": "A. Garg",
                        "slug": "A.-Garg",
                        "structuredName": {
                            "firstName": "Ashutosh",
                            "lastName": "Garg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Garg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153085314"
                        ],
                        "name": "S. Rajaram",
                        "slug": "S.-Rajaram",
                        "structuredName": {
                            "firstName": "Shyamsundar",
                            "lastName": "Rajaram",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Rajaram"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[8] studied news recommendation, while a click on a news story is a positive example, and a non-click indicates a negative example."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207163129,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e104b1968b9ec09af0f6b480a46fc1ce884c3bc",
            "isKey": false,
            "numCitedBy": 1649,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Several approaches to collaborative filtering have been studied but seldom have studies been reported for large (several millionusers and items) and dynamic (the underlying item set is continually changing) settings. In this paper we describe our approach to collaborative filtering for generating personalized recommendations for users of Google News. We generate recommendations using three approaches: collaborative filtering using MinHash clustering, Probabilistic Latent Semantic Indexing (PLSI), and covisitation counts. We combine recommendations from different algorithms using a linear model. Our approach is content agnostic and consequently domain independent, making it easily adaptable for other applications and languages with minimal effort. This paper will describe our algorithms and system setup in detail, and report results of running the recommendations engine on Google News."
            },
            "slug": "Google-news-personalization:-scalable-online-Das-Datar",
            "title": {
                "fragments": [],
                "text": "Google news personalization: scalable online collaborative filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper describes the approach to collaborative filtering for generating personalized recommendations for users of Google News using MinHash clustering, Probabilistic Latent Semantic Indexing, and covisitation counts, and combines recommendations from different algorithms using a linear model."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723357"
                        ],
                        "name": "Hwanjo Yu",
                        "slug": "Hwanjo-Yu",
                        "structuredName": {
                            "firstName": "Hwanjo",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hwanjo Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153034701"
                        ],
                        "name": "Jiawei Han",
                        "slug": "Jiawei-Han",
                        "structuredName": {
                            "firstName": "Jiawei",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiawei Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143922493"
                        ],
                        "name": "K. Chang",
                        "slug": "K.-Chang",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Chang",
                            "middleNames": [
                                "Chen-Chuan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Chang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 188
                            }
                        ],
                        "text": "When unlabeled data are available, a strategy to solve one-class classification problems is to use EM-like algorithms to iteratively predict the negative examples and learn the classifier [28, 17, 26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4362821,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f724a3aa8bd82d7a290ee09aaa88f303ee7a013",
            "isKey": false,
            "numCitedBy": 313,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Web page classification is one of the essential techniques for Web mining. Specifically, classifying Web pages of a user-interesting class is the first step of mining interesting information from the Web. However, constructing a classifier for an interesting class requires laborious pre-processing such as collecting positive and negative training examples. For instance, in order to construct a \"homepage\" classifier, one needs to collect a sample of homepages (positive examples) and a sample of non-homepages (negative examples). In particular, collecting negative training examples requires arduous work and special caution to avoid biasing them. We introduce in this paper the Positive Example Based Learning (PEBL) framework for Web page classification which eliminates the need for manually collecting negative training examples in pre-processing. We present an algorithm called Mapping-Convergence (M-C) that achieves classification accuracy (with positive and unlabeled data) as high as that of traditional SVM (with positive and negative data). Our experiments show that when the M-C algorithm uses the same amount of positive examples as that of traditional SVM, the M-C algorithm performs as well as traditional SVM."
            },
            "slug": "PEBL:-positive-example-based-learning-for-Web-page-Yu-Han",
            "title": {
                "fragments": [],
                "text": "PEBL: positive example based learning for Web page classification using SVM"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The Positive Example Based Learning (PEBL) framework for Web page classification is introduced which eliminates the need for manually collecting negative training examples in pre-processing and an algorithm called Mapping-Convergence (M-C) is presented that achieves classification accuracy as high as that of traditional SVM (with positive and negative data)."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805742"
                        ],
                        "name": "Benjamin M Marlin",
                        "slug": "Benjamin-M-Marlin",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Marlin",
                            "middleNames": [
                                "M"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin M Marlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804104"
                        ],
                        "name": "R. Zemel",
                        "slug": "R.-Zemel",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zemel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zemel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9330607"
                        ],
                        "name": "S. Roweis",
                        "slug": "S.-Roweis",
                        "structuredName": {
                            "firstName": "Sam",
                            "lastName": "Roweis",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roweis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145290352"
                        ],
                        "name": "M. Slaney",
                        "slug": "M.-Slaney",
                        "structuredName": {
                            "firstName": "Malcolm",
                            "lastName": "Slaney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Slaney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "In [2] and [19], the authors discuss the issue of modeling the distribution of missing values in collaborative filtering problems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9024470,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fee5bc9a391816be11c52b8559d62ea397bff90f",
            "isKey": false,
            "numCitedBy": 261,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Rating prediction is an important application, and a popular research topic in collaborative filtering. However, both the validity of learning algorithms, and the validity of standard testing procedures rest on the assumption that missing ratings are missing at random (MAR). In this paper we present the results of a user study in which we collect a random sample of ratings from current users of an online radio service. An analysis of the rating data collected in the study shows that the sample of random ratings has markedly different properties than ratings of user-selected songs. When asked to report on their own rating behaviour, a large number of users indicate they believe their opinion of a song does affect whether they choose to rate that song, a violation of the MAR condition. Finally, we present experimental results showing that incorporating an explicit model of the missing data mechanism can lead to significant improvements in prediction performance on the random sample of ratings."
            },
            "slug": "Collaborative-Filtering-and-the-Missing-at-Random-Marlin-Zemel",
            "title": {
                "fragments": [],
                "text": "Collaborative Filtering and the Missing at Random Assumption"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Experimental results are presented showing that incorporating an explicit model of the missing data mechanism can lead to significant improvements in prediction performance on the random sample of ratings."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714004"
                        ],
                        "name": "A. Mnih",
                        "slug": "A.-Mnih",
                        "structuredName": {
                            "firstName": "Andriy",
                            "lastName": "Mnih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mnih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7285098,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1626c940a64ad96a7ed53d7d6c0df63c6696956b",
            "isKey": false,
            "numCitedBy": 1880,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Most of the existing approaches to collaborative filtering cannot handle very large data sets. In this paper we show how a class of two-layer undirected graphical models, called Restricted Boltzmann Machines (RBM's), can be used to model tabular data, such as user's ratings of movies. We present efficient learning and inference procedures for this class of models and demonstrate that RBM's can be successfully applied to the Netflix data set, containing over 100 million user/movie ratings. We also show that RBM's slightly outperform carefully-tuned SVD models. When the predictions of multiple RBM models and multiple SVD models are linearly combined, we achieve an error rate that is well over 6% better than the score of Netflix's own system."
            },
            "slug": "Restricted-Boltzmann-machines-for-collaborative-Salakhutdinov-Mnih",
            "title": {
                "fragments": [],
                "text": "Restricted Boltzmann machines for collaborative filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "This paper shows how a class of two-layer undirected graphical models, called Restricted Boltzmann Machines (RBM's), can be used to model tabular data, such as user's ratings of movies, and demonstrates that RBM's can be successfully applied to the Netflix data set."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778725"
                        ],
                        "name": "J. Breese",
                        "slug": "J.-Breese",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Breese",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Breese"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099028"
                        ],
                        "name": "D. Heckerman",
                        "slug": "D.-Heckerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heckerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heckerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772349"
                        ],
                        "name": "C. Kadie",
                        "slug": "C.-Kadie",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Kadie",
                            "middleNames": [
                                "Myers"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Kadie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 179
                            }
                        ],
                        "text": "where \u03b4 (j) equals 1 if the item at position j is preferred by the user and 0 otherwise, and \u03b2 is the half-life parameter which is set to 5 in this paper, which is the same as in [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[5] introduced a half-life utility [13] (\u201ccfaccuracy\u201d [12]) to estimate of how likely a user will view/choose an item from a ranked list, which assumes that the user will view each consecutive item in the list with an exponential decay of possibility."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 13
                            }
                        ],
                        "text": "According to [5], Ru is defined as follows."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2885948,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "36b4a92c8eca6fd6d1b8588fc1fd0e3f89a16623",
            "isKey": false,
            "numCitedBy": 5689,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Collaborative filtering or recommender systems use a database about user preferences to predict additional topics or products a new user might like. In this paper we describe several algorithms designed for this task, including techniques based on correlation coefficients, vector-based similarity calculations, and statistical Bayesian methods. We compare the predictive accuracy of the various methods in a set of representative problem domains. We use two basic classes of evaluation metrics. The first characterizes accuracy over a set of individual predictions in terms of average absolute deviation. The second estimates the utility of a ranked list of suggested items. This metric uses an estimate of the probability that a user will see a recommendation in an ordered list. \n \nExperiments were run for datasets associated with 3 application areas, 4 experimental protocols, and the 2 evaluation metr rics for the various algorithms. Results indicate that for a wide range of conditions, Bayesian networks with decision trees at each node and correlation methods outperform Bayesian-clustering and vector-similarity methods. Between correlation and Bayesian networks, the preferred method depends on the nature of the dataset, nature of the application (ranked versus one-by-one presentation), and the availability of votes with which to make predictions. Other considerations include the size of database, speed of predictions, and learning time."
            },
            "slug": "Empirical-Analysis-of-Predictive-Algorithms-for-Breese-Heckerman",
            "title": {
                "fragments": [],
                "text": "Empirical Analysis of Predictive Algorithms for Collaborative Filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "Several algorithms designed for collaborative filtering or recommender systems are described, including techniques based on correlation coefficients, vector-based similarity calculations, and statistical Bayesian methods, to compare the predictive accuracy of the various methods in a set of representative problem domains."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145321667"
                        ],
                        "name": "B. Liu",
                        "slug": "B.-Liu",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788335"
                        ],
                        "name": "Yang Dai",
                        "slug": "Yang-Dai",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Dai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Dai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39952499"
                        ],
                        "name": "Xiaoli Li",
                        "slug": "Xiaoli-Li",
                        "structuredName": {
                            "firstName": "Xiaoli",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoli Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740222"
                        ],
                        "name": "Wee Sun Lee",
                        "slug": "Wee-Sun-Lee",
                        "structuredName": {
                            "firstName": "Wee",
                            "lastName": "Lee",
                            "middleNames": [
                                "Sun"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wee Sun Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144019071"
                        ],
                        "name": "Philip S. Yu",
                        "slug": "Philip-S.-Yu",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Yu",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philip S. Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 188
                            }
                        ],
                        "text": "When unlabeled data are available, a strategy to solve one-class classification problems is to use EM-like algorithms to iteratively predict the negative examples and learn the classifier [28, 17, 26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 371647,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b8ac3bfc5ca6913acfca19cde5d41da18e460deb",
            "isKey": false,
            "numCitedBy": 692,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the problem of building text classifiers using positive and unlabeled examples. The key feature of this problem is that there is no negative example for learning. Recently, a few techniques for solving this problem were proposed in the literature. These techniques are based on the same idea, which builds a classifier in two steps. Each existing technique uses a different method for each step. We first introduce some new methods for the two steps, and perform a comprehensive evaluation of all possible combinations of methods of the two steps. We then propose a more principled approach to solving the problem based on a biased formulation of SVM, and show experimentally that it is more accurate than the existing techniques."
            },
            "slug": "Building-text-classifiers-using-positive-and-Liu-Dai",
            "title": {
                "fragments": [],
                "text": "Building text classifiers using positive and unlabeled examples"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "A more principled approach to solving the problem of building text classifiers using positive and unlabeled examples based on a biased formulation of SVM is proposed, and it is shown experimentally that it is more accurate than the existing techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Third IEEE International Conference on Data Mining"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401829700"
                        ],
                        "name": "Shai Ben-David",
                        "slug": "Shai-Ben-David",
                        "structuredName": {
                            "firstName": "Shai",
                            "lastName": "Ben-David",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shai Ben-David"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727935"
                        ],
                        "name": "M. Lindenbaum",
                        "slug": "M.-Lindenbaum",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Lindenbaum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lindenbaum"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9328501,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cda0324c7f815d53d75149ea97b122f15e5b2f1c",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a mathematical model for learning the high-density areas of an unknown distribution from (unlabeled) random points drawn according to this distribution. While this type of a learning task has not been previously addressed in the computational learnability literature, we believe that this it a rather basic problem that appears in many practical learning scenarios. From a statistical theory standpoint, our model may be viewed as a restricted instance of the fundamental issue of inferring information about a probability distribution from the random samples it generates. From a computational learning angle, what we propose is a few framework of unsupervised concept learning. The examples provided to the learner in our model are not labeled (and are not necessarily all positive or all negative). The only information about their membership is indirectly disclosed to the student through the sampling distribution. We investigate the basic features of the proposed model and provide lower and upper bounds on the sample complexity of such learning tasks. We prove that classes whose VC-dimension is finite are learnable in a very strong sense, while on the other hand,\ufffd-covering numbers of a concept class impose lower bounds on the sample size needed for learning in our models. One direction of the proof involves a reduction of the density-level learnability to PAC learning with respect to fixed distributions (as well as some fundamental statistical lower bounds), while the sufficiency condition is proved through the introduction of a generic learning algorithm."
            },
            "slug": "Learning-Distributions-by-Their-Density-Levels:-A-a-Ben-David-Lindenbaum",
            "title": {
                "fragments": [],
                "text": "Learning Distributions by Their Density Levels: A Paradigm for Learning without a Teacher"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is proved that classes whose VC-dimension is finite are learnable in a very strong sense, while on the other hand,\ufffd-covering numbers of a concept class impose lower bounds on the sample size needed for learning in the authors' models."
            },
            "venue": {
                "fragments": [],
                "text": "J. Comput. Syst. Sci."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684176"
                        ],
                        "name": "Y. Azar",
                        "slug": "Y.-Azar",
                        "structuredName": {
                            "firstName": "Yossi",
                            "lastName": "Azar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Azar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742404"
                        ],
                        "name": "A. Fiat",
                        "slug": "A.-Fiat",
                        "structuredName": {
                            "firstName": "Amos",
                            "lastName": "Fiat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fiat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693265"
                        ],
                        "name": "Anna R. Karlin",
                        "slug": "Anna-R.-Karlin",
                        "structuredName": {
                            "firstName": "Anna",
                            "lastName": "Karlin",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anna R. Karlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3137076"
                        ],
                        "name": "Frank McSherry",
                        "slug": "Frank-McSherry",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "McSherry",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frank McSherry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748846"
                        ],
                        "name": "J. Saia",
                        "slug": "J.-Saia",
                        "structuredName": {
                            "firstName": "Jared",
                            "lastName": "Saia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Saia"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In [2] and [19], the authors discuss the issue of modeling the distribution of missing values in collaborative filtering problems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9990004,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "620cf63f101f20c03a2e530c287c2603839de15e",
            "isKey": false,
            "numCitedBy": 303,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Experimental evidence suggests that spectral techniques are valuable for a wide range of applications. A partial list of such applications include (i) semantic analysis of documents used to cluster documents into areas of interest, (ii) collaborative filtering --- the reconstruction of missing data items, and (iii) determining the relative importance of documents based on citation/link structure. Intuitive arguments can explain some of the phenomena that has been observed but little theoretical study has been done. In this paper we present a model for framing data mining tasks and a unified approach to solving the resulting data mining problems using spectral analysis. These results give strong justification to the use of spectral techniques for latent semantic indexing, collaborative filtering, and web site ranking."
            },
            "slug": "Spectral-analysis-of-data-Azar-Fiat",
            "title": {
                "fragments": [],
                "text": "Spectral analysis of data"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A model for framing data mining tasks and a unified approach to solving the resulting data mining problems using spectral analysis are presented, which give strong justification to the use of spectral techniques for latent semantic indexing, collaborative filtering, and web site ranking."
            },
            "venue": {
                "fragments": [],
                "text": "STOC '01"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145666101"
                        ],
                        "name": "Gustavo E. A. P. A. Batista",
                        "slug": "Gustavo-E.-A.-P.-A.-Batista",
                        "structuredName": {
                            "firstName": "Gustavo",
                            "lastName": "Batista",
                            "middleNames": [
                                "E.",
                                "A.",
                                "P.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gustavo E. A. P. A. Batista"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793286"
                        ],
                        "name": "R. Prati",
                        "slug": "R.-Prati",
                        "structuredName": {
                            "firstName": "Ronaldo",
                            "lastName": "Prati",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Prati"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737677"
                        ],
                        "name": "M. C. Monard",
                        "slug": "M.-C.-Monard",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Monard",
                            "middleNames": [
                                "Carolina"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. C. Monard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207155015,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6aae0dc122102693e8136856ffc8b72df7f78386",
            "isKey": false,
            "numCitedBy": 2618,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "There are several aspects that might influence the performance achieved by existing learning systems. It has been reported that one of these aspects is related to class imbalance in which examples in training data belonging to one class heavily outnumber the examples in the other class. In this situation, which is found in real world data describing an infrequent but important event, the learning system may have difficulties to learn the concept related to the minority class. In this work we perform a broad experimental evaluation involving ten methods, three of them proposed by the authors, to deal with the class imbalance problem in thirteen UCI data sets. Our experiments provide evidence that class imbalance does not systematically hinder the performance of learning systems. In fact, the problem seems to be related to learning with too few minority class examples in the presence of other complicating factors, such as class overlapping. Two of our proposed methods deal with these conditions directly, allying a known over-sampling method with data cleaning methods in order to produce better-defined class clusters. Our comparative experiments show that, in general, over-sampling methods provide more accurate results than under-sampling methods considering the area under the ROC curve (AUC). This result seems to contradict results previously published in the literature. Two of our proposed methods, Smote + Tomek and Smote + ENN, presented very good results for data sets with a small number of positive examples. Moreover, Random over-sampling, a very simple over-sampling method, is very competitive to more complex over-sampling methods. Since the over-sampling methods provided very good performance results, we also measured the syntactic complexity of the decision trees induced from over-sampled data. Our results show that these trees are usually more complex then the ones induced from original data. Random over-sampling usually produced the smallest increase in the mean number of induced rules and Smote + ENN the smallest increase in the mean number of conditions per rule, when compared among the investigated over-sampling methods."
            },
            "slug": "A-study-of-the-behavior-of-several-methods-for-data-Batista-Prati",
            "title": {
                "fragments": [],
                "text": "A study of the behavior of several methods for balancing machine learning training data"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work performs a broad experimental evaluation involving ten methods, three of them proposed by the authors, to deal with the class imbalance problem in thirteen UCI data sets, and shows that, in general, over-sampling methods provide more accurate results than under-sampled methods considering the area under the ROC curve (AUC)."
            },
            "venue": {
                "fragments": [],
                "text": "SKDD"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144859929"
                        ],
                        "name": "D. Kelly",
                        "slug": "D.-Kelly",
                        "structuredName": {
                            "firstName": "Diane",
                            "lastName": "Kelly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kelly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144113253"
                        ],
                        "name": "J. Teevan",
                        "slug": "J.-Teevan",
                        "structuredName": {
                            "firstName": "Jaime",
                            "lastName": "Teevan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Teevan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "Moreover, based on some user studies [14], if a customer is asked to provide many positive and negative examples before the system performs well, she would get a bad impression of it, and may decline to use the system."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14181461,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "235cf387b1a597078c9d9c1cbc794dd1e37b8dc3",
            "isKey": false,
            "numCitedBy": 829,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Relevance feedback has a history in information retrieval that dates back well over thirty years (c.f [SL96]). Relevance feedback is typically used for query expansion during short-term modeling of a user's immediate information need and for user profiling during long-term modeling of a user's persistent interests and preferences. Traditional relevance feedback methods require that users explicitly give feedback by, for example, specifying keywords, selecting and marking documents, or answering questions about their interests . Such relevance feedback methods force users to engage in additional activities beyond their normal searching behavior . Since the cost to the user is high and the benefits are not always apparent, it can be difficult to collect the necessary data and the effectiveness of explicit techniques can be limited."
            },
            "slug": "Implicit-feedback-for-inferring-user-preference:-a-Kelly-Teevan",
            "title": {
                "fragments": [],
                "text": "Implicit feedback for inferring user preference: a bibliography"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Traditional relevance feedback methods require that users explicitly give feedback by specifying keywords, selecting and marking documents, or answering questions about their interests, which can be difficult to collect the necessary data and the effectiveness of explicit techniques can be limited."
            },
            "venue": {
                "fragments": [],
                "text": "SIGF"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143893991"
                        ],
                        "name": "Sheng Zhang",
                        "slug": "Sheng-Zhang",
                        "structuredName": {
                            "firstName": "Sheng",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sheng Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108396422"
                        ],
                        "name": "Weihong Wang",
                        "slug": "Weihong-Wang",
                        "structuredName": {
                            "firstName": "Weihong",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weihong Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145983863"
                        ],
                        "name": "J. Ford",
                        "slug": "J.-Ford",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Ford",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728274"
                        ],
                        "name": "F. Makedon",
                        "slug": "F.-Makedon",
                        "structuredName": {
                            "firstName": "Fillia",
                            "lastName": "Makedon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Makedon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2855131"
                        ],
                        "name": "J. Pearlman",
                        "slug": "J.-Pearlman",
                        "structuredName": {
                            "firstName": "Justin",
                            "lastName": "Pearlman",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pearlman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 178
                            }
                        ],
                        "text": "Figure 3 shows the performance comparisons of different methods based on the missing as unknown strategy (Popularity and SVM), methods based on the missing as negative strategy (SVD and ALS-AMAN) and our proposed methods(wALS, sALS)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 260,
                                "start": 256
                            }
                        ],
                        "text": "In this paper, we use several well-known collaborative filtering algorithms combined with the AMAN strategy as our baselines, which include the alternating least squares with the missing as negative assumption (ALSAMAN), singular value decomposition (SVD) [29], and a neighborhood-based approach including user-user similarity[1] and item-item similarity algorithms[1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 15
                            }
                        ],
                        "text": "We can see for SVD, the performance will first increase and then drop as we increase the number of features."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 69
                            }
                        ],
                        "text": "Figure 2 shows the impact of the number of features (parameter d) on SVD and wALS."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 73
                            }
                        ],
                        "text": "In our following experiments, we will use the optimal feature number for SVD (10 for Yahoo news data and 16 for user-tag data) and wALS (50)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 33
                            }
                        ],
                        "text": "The same holds for the baselines SVD and ALS-AMAN."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 61
                            }
                        ],
                        "text": "The winner team [15] proposed a hybrid method combining both SVD and popularity using binary training data."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2866842,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0a63276066079d9a67ee7157b079d777729838f4",
            "isKey": true,
            "numCitedBy": 134,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Singular value decomposition (SVD), together with the expectation-maximization (EM) procedure, can be used to find a low-dimension model that maximizes the log-likelihood of observed ratings in recommendation systems. However, the computational cost of this approach is a major concern, since each iteration of the EM algorithm requires a new SVD computation. We present a novel algorithm that incorporates SVD approximation into the EM procedure to reduce the overall computational cost while maintaining accurate predictions. Furthermore, we propose a new framework for collaborating filtering in distributed recommendation systems that allows users to maintain their own rating profiles for privacy. A server periodically collects aggregate information from those users that are online to provide predictions for all users. Both theoretical analysis and experimental results show that this framework is effective and achieves almost the same prediction performance as that of centralized systems."
            },
            "slug": "Using-singular-value-decomposition-approximation-Zhang-Wang",
            "title": {
                "fragments": [],
                "text": "Using singular value decomposition approximation for collaborative filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A novel algorithm is presented that incorporates SVD approximation into the EM procedure to reduce the overall computational cost while maintaining accurate predictions, and a new framework for collaborating filtering in distributed recommendation systems that allows users to maintain their own rating profiles for privacy is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh IEEE International Conference on E-Commerce Technology (CEC'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2658798"
                        ],
                        "name": "Jonathan L. Herlocker",
                        "slug": "Jonathan-L.-Herlocker",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Herlocker",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan L. Herlocker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2478310"
                        ],
                        "name": "J. Konstan",
                        "slug": "J.-Konstan",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Konstan",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Konstan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739628"
                        ],
                        "name": "L. Terveen",
                        "slug": "L.-Terveen",
                        "structuredName": {
                            "firstName": "Loren",
                            "lastName": "Terveen",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Terveen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2579342"
                        ],
                        "name": "J. Riedl",
                        "slug": "J.-Riedl",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Riedl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Riedl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "[5] introduced a half-life utility [13] (\u201ccfaccuracy\u201d [12]) to estimate of how likely a user will view/choose an item from a ranked list, which assumes that the user will view each consecutive item in the list with an exponential decay of possibility."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207731647,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6aa1c88b810825ee80b8ed4c27d6577429b5d3b2",
            "isKey": false,
            "numCitedBy": 5715,
            "numCiting": 84,
            "paperAbstract": {
                "fragments": [],
                "text": "Recommender systems have been evaluated in many, often incomparable, ways. In this article, we review the key decisions in evaluating collaborative filtering recommender systems: the user tasks being evaluated, the types of analysis and datasets being used, the ways in which prediction quality is measured, the evaluation of prediction attributes other than quality, and the user-based evaluation of the system as a whole. In addition to reviewing the evaluation strategies used by prior researchers, we present empirical results from the analysis of various accuracy metrics on one content domain where all the tested metrics collapsed roughly into three equivalence classes. Metrics within each equivalency class were strongly correlated, while metrics from different equivalency classes were uncorrelated."
            },
            "slug": "Evaluating-collaborative-filtering-recommender-Herlocker-Konstan",
            "title": {
                "fragments": [],
                "text": "Evaluating collaborative filtering recommender systems"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "The key decisions in evaluating collaborative filtering recommender systems are reviewed: the user tasks being evaluated, the types of analysis and datasets being used, the ways in which prediction quality is measured, the evaluation of prediction attributes other than quality, and the user-based evaluation of the system as a whole."
            },
            "venue": {
                "fragments": [],
                "text": "TOIS"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2383107"
                        ],
                        "name": "Mikl\u00f3s Kurucz",
                        "slug": "Mikl\u00f3s-Kurucz",
                        "structuredName": {
                            "firstName": "Mikl\u00f3s",
                            "lastName": "Kurucz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mikl\u00f3s Kurucz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3286520"
                        ],
                        "name": "A. Bencz\u00far",
                        "slug": "A.-Bencz\u00far",
                        "structuredName": {
                            "firstName": "Andr\u00e1s",
                            "lastName": "Bencz\u00far",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bencz\u00far"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2062667758"
                        ],
                        "name": "Tam\u00e1s Kiss",
                        "slug": "Tam\u00e1s-Kiss",
                        "structuredName": {
                            "firstName": "Tam\u00e1s",
                            "lastName": "Kiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tam\u00e1s Kiss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29814624"
                        ],
                        "name": "Istv\u00e1n Nagy",
                        "slug": "Istv\u00e1n-Nagy",
                        "structuredName": {
                            "firstName": "Istv\u00e1n",
                            "lastName": "Nagy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Istv\u00e1n Nagy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39461952"
                        ],
                        "name": "A. Szab\u00f3",
                        "slug": "A.-Szab\u00f3",
                        "structuredName": {
                            "firstName": "Adrienn",
                            "lastName": "Szab\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Szab\u00f3"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2912070"
                        ],
                        "name": "Bal\u00e1zs Torma",
                        "slug": "Bal\u00e1zs-Torma",
                        "structuredName": {
                            "firstName": "Bal\u00e1zs",
                            "lastName": "Torma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bal\u00e1zs Torma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8586191,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49e56bff0fe90082d9c1b9ce5ca5c334815915c6",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "KDD Cup 2007 focuses on predicting aspects of movie rating behavior. We present our prediction method for Task 1 \u201cWho Rated What in 2006\u201d where the task is to predict which users rated which movies in 2006. We use the combination of the following predictors, listed in the order of their efficiency in the prediction: \u2022 The predicted number of ratings for each movie based on time series prediction, also using movie and DVD release dates and movie series detection by the edit distance of the titles. \u2022 The predicted number of ratings by each user by using the fact that ratings were sampled proportional to the margin. \u2022 The low rank approximation of the 0\u20131 matrix of known user\u2013movie pairs with rating. \u2022 The movie\u2013movie similarity matrix. \u2022 Association rules obtained by frequent sequence mining of user ratings considered as ordered itemsets. By combining the predictions by linear regression we obtained a prediction with root mean squared error 0.256; the first runner up result was 0.263 while a pure all zeroes prediction already gives 0.279, indicating the hardness of the task."
            },
            "slug": "Who-rated-what:-a-combination-of-SVD,-correlation-Kurucz-Bencz\u00far",
            "title": {
                "fragments": [],
                "text": "Who rated what: a combination of SVD, correlation and frequent sequence mining"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This paper presents the prediction method for Task 1 \u201cWho Rated What in 2006\u201d where the task is to predict which users rated which movies in 2006, and uses the combination of the following predictors."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2083464697"
                        ],
                        "name": "Frann Cois Denis",
                        "slug": "Frann-Cois-Denis",
                        "structuredName": {
                            "firstName": "Frann",
                            "lastName": "Cois Denis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Frann Cois Denis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In [9], Denis show that function classes learnable under the statistical query model are also learnable from positive and unlabeled examples if each positive example is left unlabeled with a constant probability."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4598551,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14c277610ce63372fb44163140d6457be84663e8",
            "isKey": false,
            "numCitedBy": 161,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning from positive examples occurs very frequently in natural learning. The PAC learning model of Valiant takes many features of natural learning into account, but in most cases it fails to describe such kind of learning. We show that in order to make the learning from positive data possible, extra-information about the underlying distribution must be provided to the learner. We deene a PAC learning model from positive and unlabeled examples. We also deene a PAC learning model from positive and unlabeled statistical queries. Relations with PAC model ((Val84]), statistical query model ((Kea93]) and constant-partition classiication noise model ((Dec97]) are studied. We show that k-DNF and k-decision lists are learnable in both models, i.e. with far less information than it is assumed in previously used algorithms."
            },
            "slug": "Pac-Learning-from-Positive-Statistical-Queries-Denis",
            "title": {
                "fragments": [],
                "text": "Pac Learning from Positive Statistical Queries ?"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is shown that k-DNF and k-decision lists are learnable in both models, i.e. with far less information than it is assumed in previously used algorithms."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403186049"
                        ],
                        "name": "Xu-Ying Liu",
                        "slug": "Xu-Ying-Liu",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Xu-Ying Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xu-Ying Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "147183340"
                        ],
                        "name": "Jianxin Wu",
                        "slug": "Jianxin-Wu",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Jianxin Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianxin Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403186058"
                        ],
                        "name": "Zhi-Hua Zhou",
                        "slug": "Zhi-Hua-Zhou",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Zhi-Hua Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhi-Hua Zhou"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "The idea is to use sampling to re-balance the data [3] [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62808464,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68bb1fcd6d5a4548aab2112bbb505e7e274655e4",
            "isKey": false,
            "numCitedBy": 1159,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Undersampling is a popular method in dealing with class-imbalance problems, which uses only a subset of the majority class and thus is very efficient. The main deficiency is that many majority class examples are ignored. We propose two algorithms to overcome this deficiency. EasyEnsemble samples several subsets from the majority class, trains a learner using each of them, and combines the outputs of those learners. BalanceCascade trains the learners sequentially, where in each step, the majority class examples that are correctly classified by the current trained learners are removed from further consideration. Experimental results show that both methods have higher Area Under the ROC Curve, F-measure, and G-mean values than many existing class-imbalance learning methods. Moreover, they have approximately the same training time as that of undersampling when the same number of weak classifiers is used, which is significantly faster than other methods."
            },
            "slug": "Exploratory-Undersampling-for-Class-Imbalance-Liu-Wu",
            "title": {
                "fragments": [],
                "text": "Exploratory Undersampling for Class-Imbalance Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experimental results show that the proposed EasyEnsemble and BalanceCascade algorithms have higher Area Under the ROC Curve, F-measure, and G-mean values than many existing class-imbalance learning methods."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113543585"
                        ],
                        "name": "J. Bennett",
                        "slug": "J.-Bennett",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bennett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bennett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722831"
                        ],
                        "name": "C. Elkan",
                        "slug": "C.-Elkan",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Elkan",
                            "middleNames": [
                                "Peter"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Elkan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145321667"
                        ],
                        "name": "B. Liu",
                        "slug": "B.-Liu",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50860274"
                        ],
                        "name": "Padhraic Smyth",
                        "slug": "Padhraic-Smyth",
                        "structuredName": {
                            "firstName": "Padhraic",
                            "lastName": "Smyth",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Padhraic Smyth"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754164"
                        ],
                        "name": "D. Tikk",
                        "slug": "D.-Tikk",
                        "structuredName": {
                            "firstName": "Domonkos",
                            "lastName": "Tikk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tikk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6143047,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "088c50a0407424b164e64e90ba2ed5bdec32cacd",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "The KDD Cup is the oldest of the many data mining competitions that are now popular [1]. It is an integral part of the annual ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD). In 2007, the traditional KDD Cup competition was augmented with a workshop with a focus on the concurrently active Netflix Prize competition [2]. The KDD Cup itself in 2007 consisted of a prediction competition using Netflix movie rating data, with tasks that were different and separate from those being used in the Netflix Prize itself. At the workshop, participants in both the KDD Cup and the Netflix Prize competition presented their results and analyses, and exchanged ideas."
            },
            "slug": "KDD-Cup-and-workshop-2007-Bennett-Elkan",
            "title": {
                "fragments": [],
                "text": "KDD Cup and workshop 2007"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The KDD Cup itself in 2007 consisted of a prediction competition using Netflix movie rating data, with tasks that were different and separate from those being used in the Netflix Prize itself."
            },
            "venue": {
                "fragments": [],
                "text": "SKDD"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3145329"
                        ],
                        "name": "Xu-Ying Liu",
                        "slug": "Xu-Ying-Liu",
                        "structuredName": {
                            "firstName": "Xu-Ying",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xu-Ying Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808816"
                        ],
                        "name": "Jianxin Wu",
                        "slug": "Jianxin-Wu",
                        "structuredName": {
                            "firstName": "Jianxin",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianxin Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145624000"
                        ],
                        "name": "Zhi-Hua Zhou",
                        "slug": "Zhi-Hua-Zhou",
                        "structuredName": {
                            "firstName": "Zhi-Hua",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhi-Hua Zhou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "The idea is to use sampling to re-balance the data [3] [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 62726606,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8021455c6fd84d0a9b1728d3d61fc14dc1466b04",
            "isKey": false,
            "numCitedBy": 769,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "Under-sampling is a class-imbalance learning method which uses only a subset of major class examples and thus is very efficient. The main deficiency is that many major class examples are ignored. We propose two algorithms to overcome the deficiency. EasyEnsemble samples several subsets from the major class, trains a learner using each of them, and combines the outputs of those learners. BalanceCascade is similar to EasyEnsemble except that it removes correctly classified major class examples of trained learners from further consideration. Experiments show that both of the proposed algorithms have better AUC scores than many existing class-imbalance learning methods. Moreover, they have approximately the same training time as that of under-sampling, which trains significantly faster than other methods."
            },
            "slug": "Exploratory-Under-Sampling-for-Class-Imbalance-Liu-Wu",
            "title": {
                "fragments": [],
                "text": "Exploratory Under-Sampling for Class-Imbalance Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Experiments show that the proposed algorithms, BalanceCascade and EasyEnsemble, have better AUC scores than many existing class-imbalance learning methods and have approximately the same training time as that of under-sampling, which trains significantly faster than other methods."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Data Mining (ICDM'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189092"
                        ],
                        "name": "John C. Platt",
                        "slug": "John-C.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Platt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404459229"
                        ],
                        "name": "J. Shawe-Taylor",
                        "slug": "J.-Shawe-Taylor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shawe-Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shawe-Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143957317"
                        ],
                        "name": "R. C. Williamson",
                        "slug": "R.-C.-Williamson",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Williamson",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. C. Williamson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 121
                            }
                        ],
                        "text": "Figure 3 shows the performance comparisons of different methods based on the missing as unknown strategy (Popularity and SVM), methods based on the missing as negative strategy (SVD and ALS-AMAN) and our proposed methods(wALS, sALS)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "Some research addresses problems where only examples of the positive class are available [22] (refer to one-class"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 34
                            }
                        ],
                        "text": "The idea is to create a one-class SVM classifier for every item, which takes a user\u2019s ratings on the remaining set of items as input features and predicts if the user\u2019s rating on the target item is positive or negative."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "In this paper, we also include one such algorithm, namely the one-class SVM [22] into our pool of baseline methods."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 36
                            }
                        ],
                        "text": "The set of training instances for a SVM classifier consists of the rating profiles of those users who have rated the target item, which should consists of positive examples only in the one-class collaborative filtering setting, which could be used to train a one-class SVM classifier for each target item."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "For one-class SVMs [22], the model is describing the single class and is learned only from positive examples."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 72
                            }
                        ],
                        "text": "In this paper, we also include one such\nalgorithm, namely the one-class SVM [22] into our pool of baseline methods."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2110475,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9cc912ae25797e5f7c0d73300d3968ad8339b411",
            "isKey": true,
            "numCitedBy": 4824,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "Suppose you are given some data set drawn from an underlying probability distribution P and you want to estimate a simple subset S of input space such that the probability that a test point drawn from P lies outside of S equals some a priori specified value between 0 and 1. We propose a method to approach this problem by trying to estimate a function f that is positive on S and negative on the complement. The functional form of f is given by a kernel expansion in terms of a potentially small subset of the training data; it is regularized by controlling the length of the weight vector in an associated feature space. The expansion coefficients are found by solving a quadratic programming problem, which we do by carrying out sequential optimization over pairs of input patterns. We also provide a theoretical analysis of the statistical performance of our algorithm. The algorithm is a natural extension of the support vector algorithm to the case of unlabeled data."
            },
            "slug": "Estimating-the-Support-of-a-High-Dimensional-Sch\u00f6lkopf-Platt",
            "title": {
                "fragments": [],
                "text": "Estimating the Support of a High-Dimensional Distribution"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The algorithm is a natural extension of the support vector algorithm to the case of unlabeled data by carrying out sequential optimization over pairs of input patterns and providing a theoretical analysis of the statistical performance of the algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2596290"
                        ],
                        "name": "Gary M. Weiss",
                        "slug": "Gary-M.-Weiss",
                        "structuredName": {
                            "firstName": "Gary",
                            "lastName": "Weiss",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gary M. Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1212431,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "efee5e554716d3f3cd5ecf163506fb01c24ce263",
            "isKey": false,
            "numCitedBy": 1369,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "Rare objects are often of great interest and great value. Until recently, however, rarity has not received much attention in the context of data mining. Now, as increasingly complex real-world problems are addressed, rarity, and the related problem of imbalanced data, are taking center stage. This article discusses the role that rare classes and rare cases play in data mining. The problems that can result from these two forms of rarity are described in detail, as are methods for addressing these problems. These descriptions utilize examples from existing research. So that this article provides a good survey of the literature on rarity in data mining. This article also demonstrates that rare classes and rare cases are very similar phenomena---both forms of rarity are shown to cause similar problems during data mining and benefit from the same remediation methods."
            },
            "slug": "Mining-with-rarity:-a-unifying-framework-Weiss",
            "title": {
                "fragments": [],
                "text": "Mining with rarity: a unifying framework"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is demonstrated that rare classes and rare cases are very similar phenomena---both forms of rarity are shown to cause similar problems during data mining and benefit from the same remediation methods."
            },
            "venue": {
                "fragments": [],
                "text": "SKDD"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706280"
                        ],
                        "name": "Nathan Srebro",
                        "slug": "Nathan-Srebro",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Srebro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nathan Srebro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35132120"
                        ],
                        "name": "T. Jaakkola",
                        "slug": "T.-Jaakkola",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Jaakkola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Jaakkola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 121
                            }
                        ],
                        "text": "Our first approach to tackle the one-class collaborative filtering problem is based on a weighted low-rank approximation [11, 24] technique."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "We can also see that compared to the AMAU strategies the missing as negative strategy is more effective."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "Following the AMAU strategy, it is difficult to adapt traditional collaborative filtering algorithms to obtain non-trivial solutions, as we discussed in Section 1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 211,
                                "start": 207
                            }
                        ],
                        "text": "On the other hand, if we treat missing as unknown, that is, ignore all the missing examples and utilize the positive examples only and then feed it into CF algorithms that only model non-missing data (as in [24]), a trivial solution arising from this approach is that all the predictions on missing values are positive examples."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 29
                            }
                        ],
                        "text": "As discussed above, AMAN and AMAU (no missing as negative) are two general strategies for collaborative filtering, which can be considered to be two extremes."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 38
                            }
                        ],
                        "text": "As \u03b1 \u2192 0, the methods are approaching the AMAU strategies and as \u03b1 \u2192 1, the methods are approaching the AMAU strategies."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "All missing as negative (AMAN) and all missing as unknown (AMAU) are therefore two extreme strategies in OCCF."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 63
                            }
                        ],
                        "text": "The first approach is based on weighted low rank approximation [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 186
                            }
                        ],
                        "text": "We evaluate our approaches weighting/sampling negative examples by comparing with two categories of baselines treating all missing as negative (AMAN) or treating all missing as unknown (AMAU)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 80
                            }
                        ],
                        "text": "We further discuss various weighting schemes different from naive schemes AMAU ([24]) and AMAN."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "The first method uses weighted low rank approximations [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [24], weighted low-rank approximations (wLRA) is applied to a CF problem with a naive weighting scheme assigning\u201c1\u201d to observed examples and\u201c0\u201dto missing (unobserved) values, which corresponds to the AMAU."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 75
                            }
                        ],
                        "text": "Our proposed solutions significantly outperform the two extremes (AMAN and AMAU) in OCCF problems, with at least 8% improvement over the best baseline approaches in our experiments."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5815325,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "755e566d3f10d057bc9e4908e4016ae6f7ca0753",
            "isKey": true,
            "numCitedBy": 787,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the common problem of approximating a target matrix with a matrix of lower rank. We provide a simple and efficient (EM) algorithm for solving weighted low-rank approximation problems, which, unlike their unweighted version, do not admit a closed-form solution in general. We analyze, in addition, the nature of locally optimal solutions that arise in this context, demonstrate the utility of accommodating the weights in reconstructing the underlying low-rank representation, and extend the formulation to non-Gaussian noise models such as logistic models. Finally, we apply the methods developed to a collaborative filtering task."
            },
            "slug": "Weighted-Low-Rank-Approximations-Srebro-Jaakkola",
            "title": {
                "fragments": [],
                "text": "Weighted Low-Rank Approximations"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This work provides a simple and efficient algorithm for solving weighted low-rank approximation problems, which, unlike their unweighted version, do not admit a closed-form solution in general."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2506249"
                        ],
                        "name": "C. Drummond",
                        "slug": "C.-Drummond",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Drummond",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Drummond"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796214"
                        ],
                        "name": "R. Holte",
                        "slug": "R.-Holte",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Holte",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Holte"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Another one is at the algorithmic level where cost-sensitive learning is used [10] [27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 204083391,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3c8151fd25b9c6897bd8fa5c4a88aebba49f1cb8",
            "isKey": false,
            "numCitedBy": 812,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper takes a new look at two sampling schemes commonly used to adapt machine learning algorithms to imbalanced classes and misclassification costs. It uses a performance analysis technique called cost curves to explore the interaction of over and undersampling with the decision tree learner C4.5. C4.5 was chosen as, when combined with one of the sampling schemes, it is quickly becoming the community standard when evaluating new cost sensitive learning algorithms. This paper shows that using C4.5 with undersampling establishes a reasonable standard for algorithmic comparison. But it is recommended that the cheapest class classifier be part of that standard as it can be better than under-sampling for relatively modest costs. Over-sampling, however, shows little sensitivity, there is often little dierence in performance when misclassification costs are changed."
            },
            "slug": "C4.5,-Class-Imbalance,-and-Cost-Sensitivity:-Why-Drummond-Holte",
            "title": {
                "fragments": [],
                "text": "C4.5, Class Imbalance, and Cost Sensitivity: Why Under-Sampling beats Over-Sampling"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper shows that using C4.5 with undersampling establishes a reasonable standard for algorithmic comparison, and it is recommended that the cheapest class classifier be part of that standard as it can be better than under-sampling for relatively modest costs."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099028"
                        ],
                        "name": "D. Heckerman",
                        "slug": "D.-Heckerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heckerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heckerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724065"
                        ],
                        "name": "D. M. Chickering",
                        "slug": "D.-M.-Chickering",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Chickering",
                            "middleNames": [
                                "Maxwell"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. M. Chickering"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50004012"
                        ],
                        "name": "Christopher Meek",
                        "slug": "Christopher-Meek",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Meek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Meek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745567"
                        ],
                        "name": "Robert Rounthwaite",
                        "slug": "Robert-Rounthwaite",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Rounthwaite",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Rounthwaite"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772349"
                        ],
                        "name": "C. Kadie",
                        "slug": "C.-Kadie",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Kadie",
                            "middleNames": [
                                "Myers"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Kadie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11581349,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30afca3a4056bc54deadc1c5794048436d1c9eb4",
            "isKey": false,
            "numCitedBy": 604,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a graphical model for probabilistic relationships--an alternative to the Bayesian network--called a dependency network. The graph of a dependency network, unlike a Bayesian network, is potentially cyclic. The probability component of a dependency network, like a Bayesian network, is a set of conditional distributions, one for each node given its parents. We identify several basic properties of this representation and describe a computationally efficient procedure for learning the graph and probability components from data. We describe the application of this representation to probabilistic inference, collaborative filtering (the task of predicting preferences), and the visualization of acausal predictive relationships."
            },
            "slug": "Dependency-Networks-for-Inference,-Collaborative-Heckerman-Chickering",
            "title": {
                "fragments": [],
                "text": "Dependency Networks for Inference, Collaborative Filtering, and Data Visualization"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This work describes a graphical model for probabilistic relationships--an alternative to the Bayesian network--called a dependency network and identifies several basic properties of this representation and describes a computationally efficient procedure for learning the graph and probability components from data."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725956"
                        ],
                        "name": "J. Vitter",
                        "slug": "J.-Vitter",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Vitter",
                            "middleNames": [
                                "Scott"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Vitter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "We use a fast (O (q)) random sampling algorithm [25] to generate new training data R\u0302 from the original training data R by negative example sampling given a sampling probability matrix P\u0302 and negative sample size q."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2973968,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "674dbc02fa263e317467525033f4a93d179cd007",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Several new methods are presented for selecting n records at random without replacement from a file containing N records. Each algorithm selects the records for the sample in a sequential manner\u2014in the same order the records appear in the file. The algorithms are online in that the records for the sample are selected iteratively with no preprocessing. The algorithms require a constant amount of space and are short and easy to implement. The main result of this paper is the design and analysis of Algorithm D, which does the sampling in O(n) time, on the average; roughly n uniform random variates are generated, and approximately n exponentiation operations (of the form ab, for real numbers a and b) are performed during the sampling. This solves an open problem in the literature. CPU timings on a large mainframe computer indicate that Algorithm D is significantly faster than the sampling algorithms in use today."
            },
            "slug": "Faster-methods-for-random-sampling-Vitter",
            "title": {
                "fragments": [],
                "text": "Faster methods for random sampling"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The main result of this paper is the design and analysis of Algorithm D, which does the sampling in O(n) time, on the average; roughly n uniform random variates are generated, and approximately n exponentiation operations are performed during the sampling."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1984
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423230"
                        ],
                        "name": "L. Breiman",
                        "slug": "L.-Breiman",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Breiman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Breiman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 44
                            }
                        ],
                        "text": "In particular, we use the bagging technique [6] (Algorithm 2)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 47328136,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d1ee87290fa827f1217b8fa2bccb3485da1a300e",
            "isKey": false,
            "numCitedBy": 15747,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Bagging predictors is a method for generating multiple versions of a predictor and using these to get an aggregated predictor. The aggregation averages over the versions when predicting a numerical outcome and does a plurality vote when predicting a class. The multiple versions are formed by making bootstrap replicates of the learning set and using these as new learning sets. Tests on real and simulated data sets using classification and regression trees and subset selection in linear regression show that bagging can give substantial gains in accuracy. The vital element is the instability of the prediction method. If perturbing the learning set can cause significant changes in the predictor constructed, then bagging can improve accuracy."
            },
            "slug": "Bagging-predictors-Breiman",
            "title": {
                "fragments": [],
                "text": "Bagging predictors"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Tests on real and simulated data sets using classification and regression trees and subset selection in linear regression show that bagging can give substantial gains in accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1888694"
                        ],
                        "name": "K. Gabriel",
                        "slug": "K.-Gabriel",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Gabriel",
                            "middleNames": [
                                "Ruben"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Gabriel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144903837"
                        ],
                        "name": "S. Zamir",
                        "slug": "S.-Zamir",
                        "structuredName": {
                            "firstName": "Shmuel",
                            "lastName": "Zamir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Zamir"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 121
                            }
                        ],
                        "text": "Our first approach to tackle the one-class collaborative filtering problem is based on a weighted low-rank approximation [11, 24] technique."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "[30] show that the alternating least squares (ALS) [11] approach is efficient for solving these low rank approximation problems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10740600,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ac4580463a508c95278f5b0885c527fdea8d3e21",
            "isKey": false,
            "numCitedBy": 312,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Reduced rank approximation of matrices has hitherto been possible only by unweighted least squares. This paper presents iterative techniques for obtaining such approximations when weights are introduced. The techniques involve criss-cross regressions with careful initialization. Possible applications of the approximation are in modelling, biplotting, contingency table analysis, fitting of missing values, checking outliers, etc."
            },
            "slug": "Lower-Rank-Approximation-of-Matrices-by-Least-With-Gabriel-Zamir",
            "title": {
                "fragments": [],
                "text": "Lower Rank Approximation of Matrices by Least Squares With Any Choice of Weights"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744007"
                        ],
                        "name": "Gediminas Adomavicius",
                        "slug": "Gediminas-Adomavicius",
                        "structuredName": {
                            "firstName": "Gediminas",
                            "lastName": "Adomavicius",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gediminas Adomavicius"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680593"
                        ],
                        "name": "A. Tuzhilin",
                        "slug": "A.-Tuzhilin",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Tuzhilin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tuzhilin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In this paper, we use several well-known collaborative filtering algorithms combined with the AMAN strategy as our baselines, which include the alternating least squares with the missing as negative assumption (ALS-AMAN), singular value decomposition (SVD) [29], and a neighborhood-based approach including user-based[1] and item-based algorithms[1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The first weighting scheme assumes that a missing data being a negative example has an equal chance over all users or all items, that is, it uniformly assign a weight \u03b4 \u2208 [0, 1] for \u201cnegative\u201d examples."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Generally we set Wij \u2208 [0, 1] where Rij = 0."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "1 Collaborative Filtering In the past, many researchers have explored collaborative filtering (CF) from different aspects ranging from improving the performance of algorithms to incorporating more resources from heterogeneous data sources [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206742345,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a51b7816d47a3985328531fdac8ca8a902fc6fb5",
            "isKey": true,
            "numCitedBy": 9707,
            "numCiting": 126,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an overview of the field of recommender systems and describes the current generation of recommendation methods that are usually classified into the following three main categories: content-based, collaborative, and hybrid recommendation approaches. This paper also describes various limitations of current recommendation methods and discusses possible extensions that can improve recommendation capabilities and make recommender systems applicable to an even broader range of applications. These extensions include, among others, an improvement of understanding of users and items, incorporation of the contextual information into the recommendation process, support for multicriteria ratings, and a provision of more flexible and less intrusive types of recommendations."
            },
            "slug": "Toward-the-next-generation-of-recommender-systems:-Adomavicius-Tuzhilin",
            "title": {
                "fragments": [],
                "text": "Toward the next generation of recommender systems: a survey of the state-of-the-art and possible extensions"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents an overview of the field of recommender systems and describes the current generation of recommendation methods that are usually classified into the following three main categories: content-based, collaborative, and hybrid recommendation approaches."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Knowledge and Data Engineering"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49814656"
                        ],
                        "name": "K. Barraclough",
                        "slug": "K.-Barraclough",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Barraclough",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Barraclough"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 119
                            }
                        ],
                        "text": "In fact, users rarely supply the ratings needed by traditional learning algorithms, specifically not negative examples [23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120156521,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "666010dc3621e1a08fb6830f03a1f7857c7377cc",
            "isKey": false,
            "numCitedBy": 38711,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "There is, I think, something ethereal about i \u2014the square root of minus one. I remember first hearing about it at school. It seemed an odd beast at that time\u2014an intruder hovering on the edge of reality.\n\nUsually familiarity dulls this sense of the bizarre, but in the case of i it was the reverse: over the years the sense of its surreal nature intensified. It seemed that it was impossible to write mathematics that described the real world in \u2026"
            },
            "slug": "I-and-i-Barraclough",
            "title": {
                "fragments": [],
                "text": "I and i"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "There is, I think, something ethereal about i \u2014the square root of minus one, which seems an odd beast at that time\u2014an intruder hovering on the edge of reality."
            },
            "venue": {
                "fragments": [],
                "text": "BMJ : British Medical Journal"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099028"
                        ],
                        "name": "D. Heckerman",
                        "slug": "D.-Heckerman",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Heckerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Heckerman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724065"
                        ],
                        "name": "D. M. Chickering",
                        "slug": "D.-M.-Chickering",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Chickering",
                            "middleNames": [
                                "Maxwell"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. M. Chickering"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50004012"
                        ],
                        "name": "Christopher Meek",
                        "slug": "Christopher-Meek",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Meek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher Meek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745567"
                        ],
                        "name": "Robert Rounthwaite",
                        "slug": "Robert-Rounthwaite",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Rounthwaite",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Rounthwaite"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772349"
                        ],
                        "name": "C. Kadie",
                        "slug": "C.-Kadie",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Kadie",
                            "middleNames": [
                                "Myers"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Kadie"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "[5] introduced a half-life utility [13] (\u201ccfaccuracy\u201d [12]) to estimate of how likely a user will view/choose an item from a ranked list, which assumes that the user will view each consecutive item in the list with an exponential decay of possibility."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 117699363,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e9a0f6b88dd9c8e923e028419d26b4b9fadad110",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Dependency-networks-for-inference-Heckerman-Chickering",
            "title": {
                "fragments": [],
                "text": "Dependency networks for inference"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144539424"
                        ],
                        "name": "N. Chawla",
                        "slug": "N.-Chawla",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Chawla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Chawla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743642"
                        ],
                        "name": "N. Japkowicz",
                        "slug": "N.-Japkowicz",
                        "structuredName": {
                            "firstName": "Nathalie",
                            "lastName": "Japkowicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Japkowicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3006543"
                        ],
                        "name": "Aleksander Kotcz",
                        "slug": "Aleksander-Kotcz",
                        "structuredName": {
                            "firstName": "Aleksander",
                            "lastName": "Kotcz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aleksander Kotcz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8501064,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74cc72bae68362dfa027f9ce444352597876a1be",
            "isKey": false,
            "numCitedBy": 1798,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Editorial:-special-issue-on-learning-from-data-sets-Chawla-Japkowicz",
            "title": {
                "fragments": [],
                "text": "Editorial: special issue on learning from imbalanced data sets"
            },
            "venue": {
                "fragments": [],
                "text": "SKDD"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740222"
                        ],
                        "name": "Wee Sun Lee",
                        "slug": "Wee-Sun-Lee",
                        "structuredName": {
                            "firstName": "Wee",
                            "lastName": "Lee",
                            "middleNames": [
                                "Sun"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wee Sun Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145321667"
                        ],
                        "name": "B. Liu",
                        "slug": "B.-Liu",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14322823,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41d9b4104b6d8cb8c135560b5f775bc8cd7a720d",
            "isKey": false,
            "numCitedBy": 345,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The problem of learning with positive and unlabeled examples arises frequently in retrieval applications. We transform the problem into a problem of learning with noise by labeling all unlabeled examples as negative and use a linear function to learn from the noisy examples. To learn a linear function with noise, we perform logistic regression after weighting the examples to handle noise rates of greater than a half. With appropriate regularization, the cost function of the logistic regression problem is convex, allowing the problem to be solved efficiently. We also propose a performance measure that can be estimated from positive and unlabeled examples for evaluating retrieval performance. The measure, which is proportional to the product of precision and recall, can be used with a validation set to select regularization parameters for logistic regression. Experiments on a text classification corpus show that the methods proposed are effective."
            },
            "slug": "Learning-with-Positive-and-Unlabeled-Examples-Using-Lee-Liu",
            "title": {
                "fragments": [],
                "text": "Learning with Positive and Unlabeled Examples Using Weighted Logistic Regression"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A performance measure that can be estimated from positive and unlabeled examples for evaluating retrieval performance, which is proportional to the product of precision and recall, can be used with a validation set to select regularization parameters for logistic regression."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053952609"
                        ],
                        "name": "Gill Ward",
                        "slug": "Gill-Ward",
                        "structuredName": {
                            "firstName": "Gill",
                            "lastName": "Ward",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gill Ward"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784682"
                        ],
                        "name": "T. Hastie",
                        "slug": "T.-Hastie",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Hastie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hastie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50056429"
                        ],
                        "name": "S. Barry",
                        "slug": "S.-Barry",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Barry",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Barry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2686171"
                        ],
                        "name": "J. Elith",
                        "slug": "J.-Elith",
                        "structuredName": {
                            "firstName": "Jane",
                            "lastName": "Elith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Elith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4429495"
                        ],
                        "name": "J. Leathwick",
                        "slug": "J.-Leathwick",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Leathwick",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Leathwick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 188
                            }
                        ],
                        "text": "When unlabeled data are available, a strategy to solve one-class classification problems is to use EM-like algorithms to iteratively predict the negative examples and learn the classifier [28, 17, 26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9968071,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "e78b5d40e5f85d42c753e779e05fa0b842c2b775",
            "isKey": false,
            "numCitedBy": 261,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Summary In ecological modeling of the habitat of a species, it can be prohibitively expensive to determine species absence. Presence\u2010only data consist of a sample of locations with observed presences and a separate group of locations sampled from the full landscape, with unknown presences. We propose an expectation\u2013maximization algorithm to estimate the underlying presence\u2013absence logistic model for presence\u2010only data. This algorithm can be used with any off\u2010the\u2010shelf logistic model. For models with stepwise fitting procedures, such as boosted trees, the fitting process can be accelerated by interleaving expectation steps within the procedure. Preliminary analyses based on sampling from presence\u2013absence records of fish in New Zealand rivers illustrate that this new procedure can reduce both deviance and the shrinkage of marginal effect estimates that occur in the naive model often used in practice. Finally, it is shown that the population prevalence of a species is only identifiable when there is some unrealistic constraint on the structure of the logistic model. In practice, it is strongly recommended that an estimate of population prevalence be provided."
            },
            "slug": "Presence\u2010Only-Data-and-the-EM-Algorithm-Ward-Hastie",
            "title": {
                "fragments": [],
                "text": "Presence\u2010Only Data and the EM Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "An expectation-maximization algorithm is proposed to estimate the underlying presence-absence logistic model for presence-only data and it is shown that the population prevalence of a species is only identifiable when there is some unrealistic constraint on the structure of theLogistic model."
            },
            "venue": {
                "fragments": [],
                "text": "Biometrics"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1693373"
                        ],
                        "name": "Bhavani Raskutti",
                        "slug": "Bhavani-Raskutti",
                        "structuredName": {
                            "firstName": "Bhavani",
                            "lastName": "Raskutti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bhavani Raskutti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97484233"
                        ],
                        "name": "A. Kowalczyk",
                        "slug": "A.-Kowalczyk",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Kowalczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kowalczyk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "A comparison of the two strategies can be found in [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 30487374,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "486edf39b88ad34db11628887a9e7b799ece43b9",
            "isKey": false,
            "numCitedBy": 338,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "There are many practical applications where learning from single class examples is either, the only possible solution, or has a distinct performance advantage. The first case occurs when obtaining examples of a second class is difficult, e.g., classifying sites of \"interest\" based on web accesses. The second situation is exemplified by the gene knock-out experiments for understanding Aryl Hydrocarbon Receptor signalling pathway that provided the data for the second task of the KDD 2002 Cup, where minority one-class SVMs significantly outperform models learnt using examples from both classes.This paper explores the limits of supervised learning of a two class discrimination from data with heavily unbalanced class proportions. We focus on the case of supervised learning with support vector machines. We consider the impact of both sampling and weighting imbalance compensation techniques and then extend the balancing to extreme situations when one of the classes is ignored completely and the learning is accomplished using examples from a single class.Our investigation with the data for KDD 2002 Cup as well as text benchmarks such as Reuters Newswire shows that there is a consistent pattern of performance differences between one and two-class learning for all SVMs investigated, and these patterns persist even with aggressive dimensionality reduction through automated feature selection. Using insight gained from the above analysis, we generate synthetic data showing similar pattern of performance."
            },
            "slug": "Extreme-re-balancing-for-SVMs:-a-case-study-Raskutti-Kowalczyk",
            "title": {
                "fragments": [],
                "text": "Extreme re-balancing for SVMs: a case study"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "There is a consistent pattern of performance differences between one and two-class learning for all SVMs investigated, and these patterns persist even with aggressive dimensionality reduction through automated feature selection."
            },
            "venue": {
                "fragments": [],
                "text": "SKDD"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2506249"
                        ],
                        "name": "C. Drummond",
                        "slug": "C.-Drummond",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Drummond",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Drummond"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 78
                            }
                        ],
                        "text": "Another one is at the algorithmic level where cost-sensitive learning is used [10] [27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6356183,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "144bbbafe2f0876c23295019b6e380c9fe4feda3",
            "isKey": false,
            "numCitedBy": 225,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper takes a new look at two sampling schemes commonly used to adapt machine algorithms to imbalanced classes and misclassification costs. It uses a performance analysis technique called cost curves to explore the interaction of over and under-sampling with the decision tree learner C4.5. C4.5 was chosen as, when combined with one of the sampling schemes, it is quickly becoming the community standard when evaluating new cost sensitive learning algorithms. This paper shows that using C4.5 with undersampling establishes a reasonable standard for algorithmic comparison. But it is recommended that the least cost classifier be part of that standard as it can be better than undersampling for relatively modest costs. Oversampling, however, shows little sensitivity, there is often little difference in performance when misclassification costs are changed."
            },
            "slug": "C-4-.-5-,-Class-Imbalance-,-and-Cost-Sensitivity-:-Drummond",
            "title": {
                "fragments": [],
                "text": "C 4 . 5 , Class Imbalance , and Cost Sensitivity : Why Under-Sampling beats OverSampling"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper shows that using C4.5 with undersampling establishes a reasonable standard for algorithmic comparison, and it is recommended that the least cost classifier be part of that standard as it can be better than under-sampling for relatively modest costs."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Re - stricted boltzmann machines for collaborative filter"
            },
            "venue": {
                "fragments": [],
                "text": "In ICML , pages"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Re - stricted boltzmann machines for collaborative filter"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Breiman . Bagging predictors"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Exploratory undersampling for classimbalance learn"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 17,
            "methodology": 13
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 39,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/One-Class-Collaborative-Filtering-Pan-Zhou/109de4531e279681919f7330f01b532a7201e4b9?sort=total-citations"
}