{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2509110"
                        ],
                        "name": "Chaojun Liu",
                        "slug": "Chaojun-Liu",
                        "structuredName": {
                            "firstName": "Chaojun",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chaojun Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36357862"
                        ],
                        "name": "Hui Jiang",
                        "slug": "Hui-Jiang",
                        "structuredName": {
                            "firstName": "Hui",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hui Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108186844"
                        ],
                        "name": "Xinwei Li",
                        "slug": "Xinwei-Li",
                        "structuredName": {
                            "firstName": "Xinwei",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinwei Li"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 20
                            }
                        ],
                        "text": "Recently, Liu et al [6] proposed a margin-based framework for discriminative training of GMMs in continuousdensity hidden Markov models (HMMs)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 21065100,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cc0d79c23e7692bbe781e2c041a9f28584294cae",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a new discriminative training method for estimating CDHMM (continuous density hidden Markov model) in speech recognition, based on the principle of maximizing the minimum relative multi-class separation margin. We show that the new training criterion can be formulated as a standard constrained minimax optimization problem. Then we show that the optimization problem can be solved by a GPD (generalized probabilistic descent) algorithm. Experimental results on E-set and Alphabet tasks (ISOLET database) showed that the new training criterion can achieve significant (up to 21%) error rate reduction over the popular MCE (minimum classification error) training method."
            },
            "slug": "Discriminative-training-of-CDHMMs-for-maximum-Liu-Jiang",
            "title": {
                "fragments": [],
                "text": "Discriminative training of CDHMMs for maximum relative separation margin"
            },
            "tldr": {
                "abstractSimilarityScore": 78,
                "text": "A new discriminative training method for estimating CDHMM (continuous density hidden Markov model) in speech recognition, based on the principle of maximizing the minimum relative multi-class separation margin, which can achieve significant error rate reduction over the popular MCE (minimum classification error) training method."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. (ICASSP '05). IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145259603"
                        ],
                        "name": "S. Young",
                        "slug": "S.-Young",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Young",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Young"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 122
                            }
                        ],
                        "text": "Much of the acoustic-phonetic modeling in automatic speech recognition (ASR) is handled by Gaussian mixture models (GMMs) [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 123
                            }
                        ],
                        "text": "It is therefore of interest to develop alternative learning paradigms that optimize discriminative measures of performance [1, 2, 3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59495019,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e854865394ccc46e46b415235a67ce8617c9f04",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter describes acoustic modelling in modern HMM-based LVCSR systems. The presentation emphasises the need to carefully balance model complexity with available training data, and the methods of state-tying and mixture-splitting are described as examples of how this can be done. Iterative parameter re-estimation using the forward-backward algorithm is then reviewed and the importance of the component occupation probabilities is emphasised. Using this as a basis, two powerful methods are presented for dealing with the inevitable mis-match between training and test data. Firstly, MLLR adaptation allows a set of HMM parameter transforms to be robustly estimated using small amounts of adaptation data. Secondly, MMI training based on lattices can be used to increase the inherent discrimination of the HMMs."
            },
            "slug": "Acoustic-Modelling-for-Large-Vocabulary-Continuous-Young",
            "title": {
                "fragments": [],
                "text": "Acoustic Modelling for Large Vocabulary Continuous Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "The presentation emphasises the need to carefully balance model complexity with available training data, and the methods of state-tying and mixture-splitting are described as examples of how this can be done."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2512508"
                        ],
                        "name": "Andrew K. Halberstadt",
                        "slug": "Andrew-K.-Halberstadt",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Halberstadt",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew K. Halberstadt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145898106"
                        ],
                        "name": "James R. Glass",
                        "slug": "James-R.-Glass",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Glass",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James R. Glass"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We applied large margin GMMs to well-benchmarked problems in phonetic classification and recognition on the TIMIT database [7, 8,  9 , 4]. We used the standard partition of training and test data and the same development set as in earlier work [9, 4]. All sa sentences were excluded."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We applied large margin GMMs to well-benchmarked problems in phonetic classification and recognition on the TIMIT database [7, 8, 9, 4]. We used the standard partition of training and test data and the same development set as in earlier work [ 9 , 4]. All sa sentences were excluded."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 40194303,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1fd4104e76c11edc45c5c26d064238512696b339",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe our recent efforts to improve acousticphonetic modeling by developing sets of heterogeneous, phoneclass-specific measurements, and combining these diverse measurements into a probabilistic classification framework. We first describe a baseline classifier using homogeneous measurements. After comparing selected sub-tasks to known human performance, we define sets of phone-class-specific measurements which improve within-class classification performance. Subsequently, we combine these heterogeneous measurements into an overall context-independent classification framework. We report on a series of phonetic classification experiments using the TIMIT acoustic-phonetic corpus. Our overall framework achieves 79.0% accuracy on the NIST core test set."
            },
            "slug": "Heterogeneous-acoustic-measurements-for-phonetic-1-Halberstadt-Glass",
            "title": {
                "fragments": [],
                "text": "Heterogeneous acoustic measurements for phonetic classification 1"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This paper describes a baseline classifier using homogeneous measurements, and defines sets of phone-class-specific measurements which improve within-class classification performance, and combines these heterogeneous measurements into an overall context-independent classification framework."
            },
            "venue": {
                "fragments": [],
                "text": "EUROSPEECH"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102429215"
                        ],
                        "name": "Kai-Fu Lee",
                        "slug": "Kai-Fu-Lee",
                        "structuredName": {
                            "firstName": "Kai-Fu",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai-Fu Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145058181"
                        ],
                        "name": "H. Hon",
                        "slug": "H.-Hon",
                        "structuredName": {
                            "firstName": "Hsiao-Wuen",
                            "lastName": "Hon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 123
                            }
                        ],
                        "text": "We applied large margin GMMs to well-benchmarked problems in phonetic classification and recognition on the TIMIT database [3, 7, 8, 9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 125
                            }
                        ],
                        "text": "In ongoing work, we are investigating the use of context-dependent phone models, which are known to reduce phone error rates [7, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 153
                            }
                        ],
                        "text": "Table 1 compares the phone error rates of these HMMs, obtained by aligning the results of Viterbi decoding with the ground-truth phonetic transcriptions [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 37373402,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3034afcd45fc190ed71982828b77f6e4154bdc5c",
            "isKey": false,
            "numCitedBy": 1044,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov modeling is extended to speaker-independent phone recognition. Using multiple codebooks of various linear-predictive-coding (LPC) parameters and discrete hidden Markov models (HMMs) the authors obtain a speaker-independent phone recognition accuracy of 58.8-73.8% on the TIMIT database, depending on the type of acoustic and language models used. In comparison, the performance of expert spectrogram readers is only 69% without use of higher level knowledge. The authors introduce the co-occurrence smoothing algorithm, which enables accurate recognition even with very limited training data. Since the results were evaluated on a standard database, they can be used as benchmarks to evaluate future systems. >"
            },
            "slug": "Speaker-independent-phone-recognition-using-hidden-Lee-Hon",
            "title": {
                "fragments": [],
                "text": "Speaker-independent phone recognition using hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The authors introduce the co-occurrence smoothing algorithm, which enables accurate recognition even with very limited training data, and can be used as benchmarks to evaluate future systems."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2512508"
                        ],
                        "name": "Andrew K. Halberstadt",
                        "slug": "Andrew-K.-Halberstadt",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Halberstadt",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew K. Halberstadt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145898106"
                        ],
                        "name": "James R. Glass",
                        "slug": "James-R.-Glass",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Glass",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James R. Glass"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 123
                            }
                        ],
                        "text": "We applied large margin GMMs to well-benchmarked problems in phonetic classification and recognition on the TIMIT database [3, 7, 8, 9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 105
                            }
                        ],
                        "text": "We used the standard partition of training and test data and the same development set as in earlier work [3, 9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2515764,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "46c62f33560642d9a051c94eeb7ebb6bc7fed24e",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe our recent efforts to improve acousticphonetic modeling by developing sets of heterogeneous, phoneclass-specific measurements, and combining these diverse measurements into a probabilistic classification framework. We first describe a baseline classifier using homogeneous measurements. After comparing selected sub-tasks to known human performance, we define sets of phone-class-specific measurements which improve within-class classification performance. Subsequently, we combine these heterogeneous measurements into an overall context-independent classification framework. We report on a series of phonetic classification experiments using the TIMIT acoustic-phonetic corpus. Our overall framework achieves 79.0% accuracy on the NIST core test set."
            },
            "slug": "HETEROGENEOUS-ACOUSTIC-MEASUREMENTS-FOR-PHONETIC-Halberstadt-Glass",
            "title": {
                "fragments": [],
                "text": "HETEROGENEOUS ACOUSTIC MEASUREMENTS FOR PHONETIC CLASSIFICATION"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This paper describes a baseline classifier using homogeneous measurements, and defines sets of phone-class-specific measurements which improve within-class classification performance, and combines these heterogeneous measurements into an overall context-independent classification framework."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2801698"
                        ],
                        "name": "A. Gunawardana",
                        "slug": "A.-Gunawardana",
                        "structuredName": {
                            "firstName": "Asela",
                            "lastName": "Gunawardana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gunawardana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143817088"
                        ],
                        "name": "M. Mahajan",
                        "slug": "M.-Mahajan",
                        "structuredName": {
                            "firstName": "Milind",
                            "lastName": "Mahajan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mahajan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723644"
                        ],
                        "name": "A. Acero",
                        "slug": "A.-Acero",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Acero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Acero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189092"
                        ],
                        "name": "John C. Platt",
                        "slug": "John-C.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Platt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 123
                            }
                        ],
                        "text": "It is therefore of interest to develop alternative learning paradigms that optimize discriminative measures of performance [1, 2, 3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 49
                            }
                        ],
                        "text": "7%) obtained by hidden conditional random fields [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 146
                            }
                        ],
                        "text": "We are also studying schemes for integrating the large margin training of GMMs with sequence models such as HMMs and/or conditional random fields [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 105
                            }
                        ],
                        "text": "We used the standard partition of training and test data and the same development set as in earlier work [3, 9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 123
                            }
                        ],
                        "text": "We applied large margin GMMs to well-benchmarked problems in phonetic classification and recognition on the TIMIT database [3, 7, 8, 9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1744924,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ad4cfdb0c0bb62bf1fa99cb3d0519cadd9cbc160",
            "isKey": true,
            "numCitedBy": 360,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we show the novel application of hidden conditional random fields (HCRFs) \u2013 conditional random fields with hidden state sequences \u2013 for modeling speech. Hidden state sequences are critical for modeling the non-stationarity of speech signals. We show that HCRFs can easily be trained using the simple direct optimization technique of stochastic gradient descent. We present the results on the TIMIT phone classification task and show that HCRFs outperforms comparable ML and CML/MMI trained HMMs. In fact, HCRF results on this task are the best single classifier results known to us. We note that the HCRF framework is easily extensible to recognition since it is a state and label sequence modeling technique. We also note that HCRFs have the ability to handle complex features without any change in training procedure."
            },
            "slug": "Hidden-conditional-random-fields-for-phone-Gunawardana-Mahajan",
            "title": {
                "fragments": [],
                "text": "Hidden conditional random fields for phone classification"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents the results on the TIMIT phone classification task and shows that HCRFs outperforms comparable ML and CML/MMI trained HMMs and has the ability to handle complex features without any change in training procedure."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145659093"
                        ],
                        "name": "S. Kapadia",
                        "slug": "S.-Kapadia",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Kapadia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kapadia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144782065"
                        ],
                        "name": "V. Valtchev",
                        "slug": "V.-Valtchev",
                        "structuredName": {
                            "firstName": "V.",
                            "lastName": "Valtchev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Valtchev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145259603"
                        ],
                        "name": "S. Young",
                        "slug": "S.-Young",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Young",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Young"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "It is therefore of interest to develop alternative learning paradigms that optimize discriminative measures of performance [2, 3, 4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We also observe, as in previous work [3], that discriminatively-trained context-independent phone models achieve lower error rates than context-dependent models trained by ML estimation."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 57374885,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fd6387ca1949d61356adee35708dcdbee1e4fd05",
            "isKey": false,
            "numCitedBy": 117,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Experiences with a phoneme recognition system for the TIMIT database which uses multiple mixture continuous-density monophone HMMs (hidden Markov models) trained using MMI (maximum mutual information) is reported. A comprehensive set of results are presented comparing the ML (maximum likelihood) and MMI training criteria for both diagonal and full covariance models. These results using simple monophone HMMs show that clear performance gains are achieved by MMI training. These results are comparable with the best reported by others, including those which use context-dependent models. In addition, a number of performance and implementation issues which are crucial to successful MMI training are discussed.<<ETX>>"
            },
            "slug": "MMI-training-for-continuous-phoneme-recognition-on-Kapadia-Valtchev",
            "title": {
                "fragments": [],
                "text": "MMI training for continuous phoneme recognition on the TIMIT database"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "These results using simple monophone HMMs show that clear performance gains are achieved by MMI training, and are comparable with the best reported by others, including those which use context-dependent models."
            },
            "venue": {
                "fragments": [],
                "text": "1993 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40268570"
                        ],
                        "name": "A. J. Robinson",
                        "slug": "A.-J.-Robinson",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Robinson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. J. Robinson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 123
                            }
                        ],
                        "text": "We applied large margin GMMs to well-benchmarked problems in phonetic classification and recognition on the TIMIT database [3, 7, 8, 9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 125
                            }
                        ],
                        "text": "In ongoing work, we are investigating the use of context-dependent phone models, which are known to reduce phone error rates [7, 8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14787570,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6629770cb6a00ad585918e71fe6dbad829ad0d1",
            "isKey": false,
            "numCitedBy": 543,
            "numCiting": 91,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an application of recurrent networks for phone probability estimation in large vocabulary speech recognition. The need for efficient exploitation of context information is discussed; a role for which the recurrent net appears suitable. An overview of early developments of recurrent nets for phone recognition is given along with the more recent improvements that include their integration with Markov models. Recognition results are presented for the DARPA TIMIT and Resource Management tasks, and it is concluded that recurrent nets are competitive with traditional means for performing phone probability estimation."
            },
            "slug": "An-application-of-recurrent-nets-to-phone-Robinson",
            "title": {
                "fragments": [],
                "text": "An application of recurrent nets to phone probability estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Recognition results are presented for the DARPA TIMIT and Resource Management tasks, and it is concluded that recurrent nets are competitive with traditional means for performing phone probability estimation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "150023694"
                        ],
                        "name": "A. N\u00e1das",
                        "slug": "A.-N\u00e1das",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "N\u00e1das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. N\u00e1das"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 47
                            }
                        ],
                        "text": "One common approach to discriminative training [2] estimates the means, covariance matrices, and mixture weights of these models that maximize the conditional log-likelihood \u2211 n log p(yn|xn)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 123
                            }
                        ],
                        "text": "It is therefore of interest to develop alternative learning paradigms that optimize discriminative measures of performance [1, 2, 3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120638127,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "79eb272eaf061cf4e65b8e61c9f02c027b3b6933",
            "isKey": false,
            "numCitedBy": 140,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "The choice of method for training a speech recognizer is posed as an optimization problem. The currently used method of maximum likelihood, while heuristic, is shown to be superior under certain assumptions to another heuristic: the method of conditional maximum likelihood."
            },
            "slug": "A-decision-theorectic-formulation-of-a-training-in-N\u00e1das",
            "title": {
                "fragments": [],
                "text": "A decision theorectic formulation of a training problem in speech recognition and a comparison of training by unconditional versus conditional maximum likelihood"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The currently used method of maximum likelihood, while heuristic, is shown to be superior under certain assumptions to another heuristic: the method of conditional maximum likelihood."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2014414"
                        ],
                        "name": "L. Vandenberghe",
                        "slug": "L.-Vandenberghe",
                        "structuredName": {
                            "firstName": "Lieven",
                            "lastName": "Vandenberghe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Vandenberghe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1843103"
                        ],
                        "name": "Stephen P. Boyd",
                        "slug": "Stephen-P.-Boyd",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Boyd",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen P. Boyd"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 81
                            }
                        ],
                        "text": "Its optimization can thus be formulated as a problem in semidefinite programming [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10531091,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "e309a155425162cf3b363b9393291b4f568416a0",
            "isKey": false,
            "numCitedBy": 2627,
            "numCiting": 265,
            "paperAbstract": {
                "fragments": [],
                "text": "In semidefinite programming, one minimizes a linear function subject to the constraint that an affine combination of symmetric matrices is positive semidefinite. Such a constraint is nonlinear and nonsmooth, but convex, so semidefinite programs are convex optimization problems. Semidefinite programming unifies several standard problems (e.g., linear and quadratic programming) and finds many applications in engineering and combinatorial optimization. Although semidefinite programs are much more general than linear programs, they are not much harder to solve. Most interior-point methods for linear programming have been generalized to semidefinite programs. As in linear programming, these methods have polynomial worst-case complexity and perform very well in practice. This paper gives a survey of the theory and applications of semidefinite programs and an introduction to primaldual interior-point methods for their solution."
            },
            "slug": "Semidefinite-Programming-Vandenberghe-Boyd",
            "title": {
                "fragments": [],
                "text": "Semidefinite Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A survey of the theory and applications of semidefinite programs and an introduction to primaldual interior-point methods for their solution are given."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM Rev."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 118
                            }
                        ],
                        "text": "Support vector machines (SVMs) currently provide stateof-the-art performance for many problems in pattern recognition [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 29871328,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d5051890e501117097eeffbd8ded87694f0d8063",
            "isKey": false,
            "numCitedBy": 6596,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "All rights reserved. No part of this book may be reproduced in any form by any electronic or mechanical means (including photocopying, recording, or information storage and retrieval) without permission in writing from the publisher."
            },
            "slug": "Learning-with-kernels-Smola",
            "title": {
                "fragments": [],
                "text": "Learning with kernels"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "This book is intended to be a guide to the art of self-consistency and should not be used as a substitute for a comprehensive guide to self-confidence."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 9,
            "methodology": 6,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 11,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/Large-Margin-Gaussian-Mixture-Modeling-for-Phonetic-Sha-Saul/e084bbb9cbbce7c0d282df263cf70cba4042f067?sort=total-citations"
}