{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308557"
                        ],
                        "name": "S. Hochreiter",
                        "slug": "S.-Hochreiter",
                        "structuredName": {
                            "firstName": "Sepp",
                            "lastName": "Hochreiter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hochreiter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145547836"
                        ],
                        "name": "A. S. Younger",
                        "slug": "A.-S.-Younger",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Younger",
                            "middleNames": [
                                "Steven"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. S. Younger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2927101"
                        ],
                        "name": "P. R. Conwell",
                        "slug": "P.-R.-Conwell",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Conwell",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. R. Conwell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 52872549,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "044b2c29e0a54dc689786bd4d029b9ba6e355d58",
            "isKey": false,
            "numCitedBy": 497,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces the application of gradient descent methods to meta-learning. The concept of \"meta-learning\", i.e. of a system that improves or discovers a learning algorithm, has been of interest in machine learning for decades because of its appealing applications. Previous meta-learning approaches have been based on evolutionary methods and, therefore, have been restricted to small models with few free parameters. We make meta-learning in large systems feasible by using recurrent neural networks withth eir attendant learning routines as meta-learning systems. Our system derived complex well performing learning algorithms from scratch. In this paper we also show that our approachp erforms non-stationary time series prediction."
            },
            "slug": "Learning-to-Learn-Using-Gradient-Descent-Hochreiter-Younger",
            "title": {
                "fragments": [],
                "text": "Learning to Learn Using Gradient Descent"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper makes meta- learning in large systems feasible by using recurrent neural networks with attendant learning routines as meta-learning systems and shows that the approach to gradient descent methods forms non-stationary time series prediction."
            },
            "venue": {
                "fragments": [],
                "text": "ICANN"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145547836"
                        ],
                        "name": "A. S. Younger",
                        "slug": "A.-S.-Younger",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Younger",
                            "middleNames": [
                                "Steven"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. S. Younger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308557"
                        ],
                        "name": "S. Hochreiter",
                        "slug": "S.-Hochreiter",
                        "structuredName": {
                            "firstName": "Sepp",
                            "lastName": "Hochreiter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hochreiter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2927101"
                        ],
                        "name": "P. R. Conwell",
                        "slug": "P.-R.-Conwell",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Conwell",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. R. Conwell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17937025,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c50e547cef9b1119324b7e483bf5503c1afc53be",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Introduces gradient descent methods applied to meta-learning (learning how to learn) in neural networks. Meta-learning has been of interest in the machine learning field for decades because of its appealing applications to intelligent agents, non-stationary time series, autonomous robots, and improved learning algorithms. Many previous neural network-based approaches toward meta-learning have been based on evolutionary methods. We show how to use gradient descent for meta-learning in recurrent neural networks. Based on previous work on fixed-weight learning neural networks, we hypothesize that any recurrent network topology and its corresponding learning algorithm(s) is a potential meta-learning system. We tested several recurrent neural network topologies and their corresponding forms of backpropagation for their ability to meta-learn. One of our systems, based on the long short-term memory neural network developed a learning algorithm that could learn any two-dimensional quadratic function (from a set of such functions) after only 30 training examples."
            },
            "slug": "Meta-learning-with-backpropagation-Younger-Hochreiter",
            "title": {
                "fragments": [],
                "text": "Meta-learning with backpropagation"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "One of the systems, based on the long short-term memory neural network developed a learning algorithm that could learn any two-dimensional quadratic function (from a set of such functions) after only 30 training examples."
            },
            "venue": {
                "fragments": [],
                "text": "IJCNN'01. International Joint Conference on Neural Networks. Proceedings (Cat. No.01CH37222)"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739396"
                        ],
                        "name": "N. Schraudolph",
                        "slug": "N.-Schraudolph",
                        "structuredName": {
                            "firstName": "Nicol",
                            "lastName": "Schraudolph",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Schraudolph"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 58
                            }
                        ],
                        "text": "In practice rescaling inputs and outputs of an LSTM optimizer using suitable constants (shared across all timesteps and functions f ) is sufficient to avoid this problem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 207
                            }
                        ],
                        "text": "Similar work has also been attacked in a filtering context [Feldkamp and Puskorius, 1998, Prokhorov et al., 2002], a line of work that is directly related to simple multi-timescale optimizers [Sutton, 1992, Schraudolph, 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6304315,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "812b49a877b98941f258f7c2bfc8e890963142bd",
            "isKey": false,
            "numCitedBy": 184,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Gain adaptation algorithms for neural networks typically adjust learning rates by monitoring the correlation between successive gradients. Here we discuss the limitations of this approach, and develop an alternative by extending Sutton''s work on linear systems to the general, nonlinear case. The resulting online algorithms are computationally little more expensive than other acceleration techniques, do not assume statistical independence between successive training patterns, and do not require an arbitrary smoothing parameter. In our benchmark experiments, they consistently outperform other acceleration methods, and show remarkable robustness when faced with non-i.i.d. sampling of the input space."
            },
            "slug": "Local-Gain-Adaptation-in-Stochastic-Gradient-Schraudolph",
            "title": {
                "fragments": [],
                "text": "Local Gain Adaptation in Stochastic Gradient Descent"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "The limitations of this approach are discussed, and an alternative is developed by extending Sutton''s work on linear systems to the general, nonlinear case, and the resulting online algorithms are computationally little more expensive than other acceleration techniques, and do not assume statistical independence between successive training patterns."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734693"
                        ],
                        "name": "John C. Duchi",
                        "slug": "John-C.-Duchi",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Duchi",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Duchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34840427"
                        ],
                        "name": "Elad Hazan",
                        "slug": "Elad-Hazan",
                        "structuredName": {
                            "firstName": "Elad",
                            "lastName": "Hazan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elad Hazan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 538820,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "413c1142de9d91804d6d11c67ff3fed59c9fc279",
            "isKey": false,
            "numCitedBy": 8094,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to find needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efficient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms."
            },
            "slug": "Adaptive-Subgradient-Methods-for-Online-Learning-Duchi-Hazan",
            "title": {
                "fragments": [],
                "text": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work describes and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies setting a learning rate and results in regret guarantees that are provably as good as the best proximal functions that can be chosen in hindsight."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2909364"
                        ],
                        "name": "J. Cloutier",
                        "slug": "J.-Cloutier",
                        "structuredName": {
                            "firstName": "Jocelyn",
                            "lastName": "Cloutier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cloutier"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1734973,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "d130325c41947a41a55a4431e9e8e15be89da8ea",
            "isKey": false,
            "numCitedBy": 248,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Summary form only given, as follows. The authors discuss an original approach to neural modeling based on the idea of searching, with learning methods, for a synaptic learning rule which is biologically plausible and yields networks that are able to learn to perform difficult tasks. The proposed method of automatically finding the learning rule relies on the idea of considering the synaptic modification rule as a parametric function. This function has local inputs and is the same in many neurons. The parameters that define this function can be estimated with known learning methods. For this optimization, particular attention is given to gradient descent and genetic algorithms. In both cases, estimation of this function consists of a joint global optimization of the synaptic modification function and the networks that are learning to perform some tasks. Both network architecture and the learning function can be designed within constraints derived from biological knowledge.<<ETX>>"
            },
            "slug": "Learning-a-synaptic-learning-rule-Bengio-Bengio",
            "title": {
                "fragments": [],
                "text": "Learning a synaptic learning rule"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "An original approach to neural modeling based on the idea of searching, with learning methods, for a synaptic learning rule which is biologically plausible and yields networks that are able to learn to perform difficult tasks is discussed."
            },
            "venue": {
                "fragments": [],
                "text": "IJCNN-91-Seattle International Joint Conference on Neural Networks"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726807"
                        ],
                        "name": "Diederik P. Kingma",
                        "slug": "Diederik-P.-Kingma",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Kingma",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik P. Kingma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6628106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "isKey": false,
            "numCitedBy": 91740,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm."
            },
            "slug": "Adam:-A-Method-for-Stochastic-Optimization-Kingma-Ba",
            "title": {
                "fragments": [],
                "text": "Adam: A Method for Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work introduces Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments, and provides a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2071479809"
                        ],
                        "name": "D. K. Naik",
                        "slug": "D.-K.-Naik",
                        "structuredName": {
                            "firstName": "Dattika",
                            "lastName": "Naik",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. K. Naik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1872039"
                        ],
                        "name": "R. Mammone",
                        "slug": "R.-Mammone",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Mammone",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Mammone"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 61444551,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b64e846fe88acaf302248249696c3b7badde41b5",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel method for training neural networks is introduced. The method uses an additional observing neural network called a meta-neural network (MNN) to direct the training of the basic neural network. The MNN provides the basic neural network with a step size and a direction vector which is optimal based on successful training strategies learned from problems solved previously. The combination of the MNN with the basic neural network is shown to improve learning rates for several problems when the MNN is trained on a similar problem. The MNN is shown to help solve the problem of sensitivity to initial weight vectors. In addition, computer simulations demonstrate the improvement in the learning rate of the enhanced neural network on a 4-b parity problem, when it has been trained on a different nonlinear Boolean function.<<ETX>>"
            },
            "slug": "Meta-neural-networks-that-learn-by-learning-Naik-Mammone",
            "title": {
                "fragments": [],
                "text": "Meta-neural networks that learn by learning"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A novel method for training neural networks using an additional observing neural network called a meta-neural network (MNN) to direct the training of the basic neural network and the MNN is shown to help solve the problem of sensitivity to initial weight vectors."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings 1992] IJCNN International Joint Conference on Neural Networks"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1682823"
                        ],
                        "name": "P. Tseng",
                        "slug": "P.-Tseng",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Tseng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Tseng"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "xample, in the deep learning community we have seen a proliferation of optimization methods specialized for high-dimensional, non-convex optimization problems. These include momentum [Nesterov, 1983, Tseng, 1998], Rprop [Riedmiller and Braun, 1993], Adagrad [Duchi et al., 2011], RMSprop [Tieleman and Hinton, 2012], and ADAM [Kingma and Ba, 2015]. More focused methods can also be applied when more structure o"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 40
                            }
                        ],
                        "text": "These include momentum [Nesterov, 1983, Tseng, 1998], Rprop [Riedmiller and Braun, 1993], Adagrad [Duchi et al., 2011], Adadelta [Zeiler, 2012], RMSprop [Tieleman and Hinton, 2012], and ADAM [Kingma and Ba, 2015]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18276525,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a296a1577478654a54a9f801f93f71b7d853c53",
            "isKey": false,
            "numCitedBy": 154,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider an incremental gradient method with momentum term for minimizing the sum of continuously differentiable functions. This method uses a new adaptive stepsize rule that decreases the stepsize whenever sufficient progress is not made. We show that if the gradients of the functions are bounded and Lipschitz continuous over a certain level set, then every cluster point of the iterates generated by the method is a stationary point. In addition, if the gradient of the functions have a certain growth property, then the method is either linearly convergent in some sense or the stepsizes are bounded away from zero. The new stepsize rule is much in the spirit of heuristic learning rules used in practice for training neural networks via backpropagation. As such, the new stepsize rule may suggest improvements on existing learning rules. Finally, extension of the method and the convergence results to constrained minimization is discussed, as are some implementation issues and numerical experience."
            },
            "slug": "An-Incremental-Gradient(-Projection)-Method-with-Tseng",
            "title": {
                "fragments": [],
                "text": "An Incremental Gradient(-Projection) Method with Momentum Term and Adaptive Stepsize Rule"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "An incremental gradient method with momentum term for minimizing the sum of continuously differentiable functions is considered, which uses a new adaptive stepsize rule that decreases the stepsize whenever sufficient progress is not made."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J. Optim."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48799969"
                        ],
                        "name": "Matthew D. Zeiler",
                        "slug": "Matthew-D.-Zeiler",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Zeiler",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew D. Zeiler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 102
                            }
                        ],
                        "text": "We compare our trained optimizers with standard optimizers used in Deep Learning: SGD, RMSprop, ADAM, Adadelta, Adagrad, and Rprop."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 18
                            }
                        ],
                        "text": ", 2011], Adadelta [Zeiler, 2012], RMSprop [Tieleman and Hinton, 2012], and ADAM [Kingma and Ba, 2015]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 130
                            }
                        ],
                        "text": "These include momentum [Nesterov, 1983, Tseng, 1998], Rprop [Riedmiller and Braun, 1993], Adagrad [Duchi et al., 2011], Adadelta [Zeiler, 2012], RMSprop [Tieleman and Hinton, 2012], and ADAM [Kingma and Ba, 2015]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7365802,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8729441d734782c3ed532a7d2d9611b438c0a09a",
            "isKey": false,
            "numCitedBy": 5509,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a novel per-dimension learning rate method for gradient descent called ADADELTA. The method dynamically adapts over time using only first order information and has minimal computational overhead beyond vanilla stochastic gradient descent. The method requires no manual tuning of a learning rate and appears robust to noisy gradient information, different model architecture choices, various data modalities and selection of hyperparameters. We show promising results compared to other methods on the MNIST digit classification task using a single machine and on a large scale voice dataset in a distributed cluster environment."
            },
            "slug": "ADADELTA:-An-Adaptive-Learning-Rate-Method-Zeiler",
            "title": {
                "fragments": [],
                "text": "ADADELTA: An Adaptive Learning Rate Method"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A novel per-dimension learning rate method for gradient descent called ADADELTA that dynamically adapts over time using only first order information and has minimal computational overhead beyond vanilla stochastic gradient descent is presented."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 175
                            }
                        ],
                        "text": "3 Training a convolutional network on CIFAR-10 Next we test the performance of the trained neural optimizers on optimizing classification performance for the CIFAR-10 dataset [Krizhevsky, 2009]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 129
                            }
                        ],
                        "text": "Next we test the performance of the trained neural optimizers on optimizing classification performance for the CIFAR-10 dataset [Krizhevsky, 2009]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18268744,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d90f06bb70a0a3dced62413346235c02b1aa086",
            "isKey": false,
            "numCitedBy": 17474,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Groups at MIT and NYU have collected a dataset of millions of tiny colour images from the web. It is, in principle, an excellent dataset for unsupervised training of deep generative models, but previous researchers who have tried this have found it dicult to learn a good set of lters from the images. We show how to train a multi-layer generative model that learns to extract meaningful features which resemble those found in the human visual cortex. Using a novel parallelization algorithm to distribute the work among multiple machines connected on a network, we show how training such a model can be done in reasonable time. A second problematic aspect of the tiny images dataset is that there are no reliable class labels which makes it hard to use for object recognition experiments. We created two sets of reliable labels. The CIFAR-10 set has 6000 examples of each of 10 classes and the CIFAR-100 set has 600 examples of each of 100 non-overlapping classes. Using these labels, we show that object recognition is signicantly improved by pre-training a layer of features on a large set of unlabeled tiny images."
            },
            "slug": "Learning-Multiple-Layers-of-Features-from-Tiny-Krizhevsky",
            "title": {
                "fragments": [],
                "text": "Learning Multiple Layers of Features from Tiny Images"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is shown how to train a multi-layer generative model that learns to extract meaningful features which resemble those found in the human visual cortex, using a novel parallelization algorithm to distribute the work among multiple machines connected on a network."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699645"
                        ],
                        "name": "R. Sutton",
                        "slug": "R.-Sutton",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Sutton",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sutton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 771841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c2dd697bbe99c2ec71c807580a00f7e723cc20ae",
            "isKey": false,
            "numCitedBy": 234,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Appropriate bias is widely viewed as the key to efficient learning and generalization. I present a new algorithm, the Incremental Delta-Bar-Delta (IDBD) algorithm, for the learning of appropriate biases based on previous learning experience. The IDBD algorithm is developed for the case of a simple, linear learning system--the LMS or delta rule with a separate learning-rate parameter for each input. The IDBD algorithm adjusts the learning-rate parameters, which are an important form of bias for this system. Because bias in this approach is adapted based on previous learning experience, the appropriate test beds are drifting or non-stationary learning tasks. For particular tasks of this type, I show that the IDBD algorithm performs better than ordinary LMS and in fact finds the optimal learning rates. The IDBD algorithm extends and improves over prior work by Jacobs and by me in that it is fully incremental and has only a single free parameter. This paper also extends previous work by presenting a derivation of the IDBD algorithm as gradient descent in the space of learning-rate parameters. Finally, I offer a novel interpretation of the IDBD algorithm as an incremental form of hold-one-out cross validation."
            },
            "slug": "Adapting-Bias-by-Gradient-Descent:-An-Incremental-Sutton",
            "title": {
                "fragments": [],
                "text": "Adapting Bias by Gradient Descent: An Incremental Version of Delta-Bar-Delta"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A new algorithm, the Incremental Delta-Bar-Delta (IDBD) algorithm, for the learning of appropriate biases based on previous learning experience, and a novel interpretation of the IDBD algorithm as an incremental form of hold-one-out cross validation."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145704247"
                        ],
                        "name": "James Martens",
                        "slug": "James-Martens",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Martens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Martens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785346"
                        ],
                        "name": "Roger B. Grosse",
                        "slug": "Roger-B.-Grosse",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Grosse",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roger B. Grosse"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11480464,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb4dc7277d1c8c3bc76dd7425eb1cc7cbaf99487",
            "isKey": false,
            "numCitedBy": 566,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an efficient method for approximating natural gradient descent in neural networks which we call Kronecker-Factored Approximate Curvature (K-FAC). K-FAC is based on an efficiently invertible approximation of a neural network's Fisher information matrix which is neither diagonal nor low-rank, and in some cases is completely non-sparse. It is derived by approximating various large blocks of the Fisher (corresponding to entire layers) as being the Kronecker product of two much smaller matrices. While only several times more expensive to compute than the plain stochastic gradient, the updates produced by K-FAC make much more progress optimizing the objective, which results in an algorithm that can be much faster than stochastic gradient descent with momentum in practice. And unlike some previously proposed approximate natural-gradient/Newton methods which use high-quality non-diagonal curvature matrices (such as Hessian-free optimization), K-FAC works very well in highly stochastic optimization regimes. This is because the cost of storing and inverting K-FAC's approximation to the curvature matrix does not depend on the amount of data used to estimate it, which is a feature typically associated only with diagonal or low-rank approximations to the curvature matrix."
            },
            "slug": "Optimizing-Neural-Networks-with-Kronecker-factored-Martens-Grosse",
            "title": {
                "fragments": [],
                "text": "Optimizing Neural Networks with Kronecker-factored Approximate Curvature"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "K-FAC is an efficient method for approximating natural gradient descent in neural networks which is based on an efficiently invertible approximation of a neural network's Fisher information matrix which is neither diagonal nor low-rank, and in some cases is completely non-sparse."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37755468"
                        ],
                        "name": "Christian Daniel",
                        "slug": "Christian-Daniel",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Daniel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Daniel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110316057"
                        ],
                        "name": "Jonathan Taylor",
                        "slug": "Jonathan-Taylor",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2388416"
                        ],
                        "name": "S. Nowozin",
                        "slug": "S.-Nowozin",
                        "structuredName": {
                            "firstName": "Sebastian",
                            "lastName": "Nowozin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Nowozin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17307331,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa2e56dce0718b922a2b61af48631f48126aff72",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "\n \n This paper investigates algorithms to automatically adapt the learning rate of neural networks (NNs). Starting with stochastic gradient descent, a large variety of learning methods has been proposed for the NN setting. However, these methods are usually sensitive to the initial learning rate which has to be chosen by the experimenter. We investigate several features and show how an adaptive controller can adjust the learning rate without prior knowledge of the learning problem at hand.\n \n"
            },
            "slug": "Learning-Step-Size-Controllers-for-Robust-Neural-Daniel-Taylor",
            "title": {
                "fragments": [],
                "text": "Learning Step Size Controllers for Robust Neural Network Training"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "Algorithms to automatically adapt the learning rate of neural networks (NNs) are investigated and it is shown how an adaptive controller can adjust thelearning rate without prior knowledge of the learning problem at hand."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145547836"
                        ],
                        "name": "A. S. Younger",
                        "slug": "A.-S.-Younger",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Younger",
                            "middleNames": [
                                "Steven"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. S. Younger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2927101"
                        ],
                        "name": "P. R. Conwell",
                        "slug": "P.-R.-Conwell",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Conwell",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. R. Conwell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2264754"
                        ],
                        "name": "N. E. Cotter",
                        "slug": "N.-E.-Cotter",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Cotter",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. E. Cotter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11354159,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f67e7dd2495500f3975f39e541fa38073d49a2ee",
            "isKey": false,
            "numCitedBy": 37,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Conventional artificial neural networks perform functional mappings from their input space to their output space. The synaptic weights encode information about the mapping in a manner analogous to long-term memory in biological systems. This paper presents a method of designing neural networks where recurrent signal loops store this knowledge in a manner analogous to short-term memory. The synaptic weights of these networks encode a learning algorithm. This gives these networks the ability to dynamically learn any functional mapping from a (possibly very large) set, without changing any synaptic weights. These networks are adaptive dynamic systems. Learning is online continually taking place as part of the network's overall behavior instead of a separate, externally driven process. We present four higher order fixed-weight learning networks. Two of these networks have standard backpropagation embedded in their synaptic weights. The other two utilize a more efficient gradient-descent-based learning rule. This new learning scheme was discovered by examining variations in fixed-weight topology. We present empirical tests showing that all these networks were able to successfully learn functions from both discrete (Boolean) and continuous function sets. Largely, the networks were robust with respect to perturbations in the synaptic weights. The exception was the recurrent connections used to store information. These required a tight tolerance of 0.5%. We found that the cost of these networks scaled approximately in proportion to the total number of synapses. We consider evolving fixed weight networks tailored to a specific problem class by analyzing the meta-learning cost surface of the networks presented."
            },
            "slug": "Fixed-weight-on-line-learning-Younger-Conwell",
            "title": {
                "fragments": [],
                "text": "Fixed-weight on-line learning"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A method of designing neural networks where recurrent signal loops store this knowledge in a manner analogous to short-term memory, which gives these networks the ability to dynamically learn any functional mapping from a (possibly very large) set, without changing any synaptic weights."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35030998"
                        ],
                        "name": "Adam Santoro",
                        "slug": "Adam-Santoro",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Santoro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Santoro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2258504"
                        ],
                        "name": "Sergey Bartunov",
                        "slug": "Sergey-Bartunov",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Bartunov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sergey Bartunov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46378362"
                        ],
                        "name": "M. Botvinick",
                        "slug": "M.-Botvinick",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Botvinick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Botvinick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688276"
                        ],
                        "name": "Daan Wierstra",
                        "slug": "Daan-Wierstra",
                        "structuredName": {
                            "firstName": "Daan",
                            "lastName": "Wierstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daan Wierstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2542999"
                        ],
                        "name": "T. Lillicrap",
                        "slug": "T.-Lillicrap",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Lillicrap",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lillicrap"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6466088,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3904315e2eca50d0086e4b7273f7fd707c652230",
            "isKey": false,
            "numCitedBy": 928,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Despite recent breakthroughs in the applications of deep neural networks, one setting that presents a persistent challenge is that of \"one-shot learning.\" Traditional gradient-based networks require a lot of data to learn, often through extensive iterative training. When new data is encountered, the models must inefficiently relearn their parameters to adequately incorporate the new information without catastrophic interference. Architectures with augmented memory capacities, such as Neural Turing Machines (NTMs), offer the ability to quickly encode and retrieve new information, and hence can potentially obviate the downsides of conventional models. Here, we demonstrate the ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples. We also introduce a new method for accessing an external memory that focuses on memory content, unlike previous methods that additionally use memory location-based focusing mechanisms."
            },
            "slug": "Meta-Learning-with-Memory-Augmented-Neural-Networks-Santoro-Bartunov",
            "title": {
                "fragments": [],
                "text": "Meta-Learning with Memory-Augmented Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3137672"
                        ],
                        "name": "Martin A. Riedmiller",
                        "slug": "Martin-A.-Riedmiller",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Riedmiller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin A. Riedmiller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145326760"
                        ],
                        "name": "H. Braun",
                        "slug": "H.-Braun",
                        "structuredName": {
                            "firstName": "Heinrich",
                            "lastName": "Braun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Braun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16848428,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "916ceefae4b11dadc3ee754ce590381c568c90de",
            "isKey": false,
            "numCitedBy": 4456,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "A learning algorithm for multilayer feedforward networks, RPROP (resilient propagation), is proposed. To overcome the inherent disadvantages of pure gradient-descent, RPROP performs a local adaptation of the weight-updates according to the behavior of the error function. Contrary to other adaptive techniques, the effect of the RPROP adaptation process is not blurred by the unforeseeable influence of the size of the derivative, but only dependent on the temporal behavior of its sign. This leads to an efficient and transparent adaptation process. The capabilities of RPROP are shown in comparison to other adaptive techniques.<<ETX>>"
            },
            "slug": "A-direct-adaptive-method-for-faster-backpropagation-Riedmiller-Braun",
            "title": {
                "fragments": [],
                "text": "A direct adaptive method for faster backpropagation learning: the RPROP algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A learning algorithm for multilayer feedforward networks, RPROP (resilient propagation), is proposed that performs a local adaptation of the weight-updates according to the behavior of the error function to overcome the inherent disadvantages of pure gradient-descent."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE International Conference on Neural Networks"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1395619597"
                        ],
                        "name": "Nicolas Boulanger-Lewandowski",
                        "slug": "Nicolas-Boulanger-Lewandowski",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Boulanger-Lewandowski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Boulanger-Lewandowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1996134"
                        ],
                        "name": "Razvan Pascanu",
                        "slug": "Razvan-Pascanu",
                        "structuredName": {
                            "firstName": "Razvan",
                            "lastName": "Pascanu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Razvan Pascanu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 108
                            }
                        ],
                        "text": "These global averaging cells (GACs) are sufficient to allow the networks to implement L2 gradient clipping [Bengio et al., 2013] assuming that each LSTM can compute the square of the gradient."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12485056,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ded103d0613e1a8f51f586cc1678aee3ff26e811",
            "isKey": false,
            "numCitedBy": 445,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "After a more than decade-long period of relatively little research activity in the area of recurrent neural networks, several new developments will be reviewed here that have allowed substantial progress both in understanding and in technical solutions towards more efficient training of recurrent networks. These advances have been motivated by and related to the optimization issues surrounding deep learning. Although recurrent networks are extremely powerful in what they can in principle represent in terms of modeling sequences, their training is plagued by two aspects of the same issue regarding the learning of long-term dependencies. Experiments reported here evaluate the use of clipping gradients, spanning longer time ranges with leaky integration, advanced momentum techniques, using more powerful output probability models, and encouraging sparser gradients to help symmetry breaking and credit assignment. The experiments are performed on text and music data and show off the combined effects of these techniques in generally improving both training and test error."
            },
            "slug": "Advances-in-optimizing-recurrent-networks-Bengio-Boulanger-Lewandowski",
            "title": {
                "fragments": [],
                "text": "Advances in optimizing recurrent networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Experiments reported here evaluate the use of clipping gradients, spanning longer time ranges with leaky integration, advanced momentum techniques, using more powerful output probability models, and encouraging sparser gradients to help symmetry breaking and credit assignment."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE International Conference on Acoustics, Speech and Signal Processing"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2373318"
                        ],
                        "name": "B. Lake",
                        "slug": "B.-Lake",
                        "structuredName": {
                            "firstName": "Brenden",
                            "lastName": "Lake",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Lake"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37774552"
                        ],
                        "name": "T. Ullman",
                        "slug": "T.-Ullman",
                        "structuredName": {
                            "firstName": "Tomer",
                            "lastName": "Ullman",
                            "middleNames": [
                                "David"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ullman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763295"
                        ],
                        "name": "J. Tenenbaum",
                        "slug": "J.-Tenenbaum",
                        "structuredName": {
                            "firstName": "Joshua",
                            "lastName": "Tenenbaum",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tenenbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1831199"
                        ],
                        "name": "S. Gershman",
                        "slug": "S.-Gershman",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Gershman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gershman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 196200552,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7260c0692f8d265e11c4e9c4c8ef4c185bd587ad",
            "isKey": false,
            "numCitedBy": 1588,
            "numCiting": 524,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Recent progress in artificial intelligence has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving performance that equals or even beats that of humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn and how they learn it. Specifically, we argue that these machines should (1) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (2) ground learning in intuitive theories of physics and psychology to support and enrich the knowledge that is learned; and (3) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations. We suggest concrete challenges and promising routes toward these goals that can combine the strengths of recent neural network advances with more structured cognitive models."
            },
            "slug": "Building-machines-that-learn-and-think-like-people-Lake-Ullman",
            "title": {
                "fragments": [],
                "text": "Building machines that learn and think like people"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is argued that truly human-like learning and thinking machines should build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems, and harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations."
            },
            "venue": {
                "fragments": [],
                "text": "Behavioral and Brain Sciences"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690247"
                        ],
                        "name": "T. Runarsson",
                        "slug": "T.-Runarsson",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Runarsson",
                            "middleNames": [
                                "Philip"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Runarsson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47398115"
                        ],
                        "name": "M. Jonsson",
                        "slug": "M.-Jonsson",
                        "structuredName": {
                            "firstName": "Magnus",
                            "lastName": "Jonsson",
                            "middleNames": [
                                "Thor"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Jonsson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60641576,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ad9b6c56748ff12fb10536d0c189fb6835b2e43",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper describes the application of neural networks as learning rules for the training of neural networks. The learning rule is part of the neural network architecture. As a result the learning rule is non-local and globally distributed within the network. The learning rules are evolved using an evolution strategy. The survival of a learning rule is based on its performance in training neural networks on a set of tasks. Training algorithms will be evolved for single layer artificial neural networks. Experimental results show that a learning rule of this type is very capable of generating an efficient training algorithm."
            },
            "slug": "Evolution-and-design-of-distributed-learning-rules-Runarsson-Jonsson",
            "title": {
                "fragments": [],
                "text": "Evolution and design of distributed learning rules"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Experimental results show that a learning rule of this type is very capable of generating an efficient training algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "2000 IEEE Symposium on Combinations of Evolutionary Computation and Neural Networks. Proceedings of the First IEEE Symposium on Combinations of Evolutionary Computation and Neural Networks (Cat. No.00"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16683347,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc22e87a26d020215afe91c751e5bdaddd8e4922",
            "isKey": false,
            "numCitedBy": 271,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Previous algorithms for supervised sequence learning are based on dynamic recurrent networks. This paper describes an alternative class of gradient-based systems consisting of two feedforward nets that learn to deal with temporal sequences using fast weights: The first net learns to produce context-dependent weight changes for the second net whose weights may vary very quickly. The method offers the potential for STM storage efficiency: A single weight (instead of a full-fledged unit) may be sufficient for storing temporal information. Various learning methods are derived. Two experiments with unknown time delays illustrate the approach. One experiment shows how the system can be used for adaptive temporary variable binding."
            },
            "slug": "Learning-to-Control-Fast-Weight-Memories:-An-to-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Learning to Control Fast-Weight Memories: An Alternative to Dynamic Recurrent Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "This paper describes an alternative class of gradient-based systems consisting of two feedforward nets that learn to deal with temporal sequences using fast weights: the first net learns to produce context-dependent weight changes for the second net whose weights may vary very quickly."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144570279"
                        ],
                        "name": "F. Bach",
                        "slug": "F.-Bach",
                        "structuredName": {
                            "firstName": "Francis",
                            "lastName": "Bach",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Bach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068720"
                        ],
                        "name": "Rodolphe Jenatton",
                        "slug": "Rodolphe-Jenatton",
                        "structuredName": {
                            "firstName": "Rodolphe",
                            "lastName": "Jenatton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rodolphe Jenatton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2599292"
                        ],
                        "name": "J. Mairal",
                        "slug": "J.-Mairal",
                        "structuredName": {
                            "firstName": "Julien",
                            "lastName": "Mairal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mairal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2533906"
                        ],
                        "name": "G. Obozinski",
                        "slug": "G.-Obozinski",
                        "structuredName": {
                            "firstName": "Guillaume",
                            "lastName": "Obozinski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Obozinski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ptimization 1 arXiv:1606.04474v1 [cs.NE] 14 Jun 2016 problem is known [Martens and Grosse, 2015]. In contrast, communities who focus on sparsity tend to favor very different approaches [Donoho, 2006, Bach et al., 2012]. This is even more the case for combinatorial optimization for which relaxations are often the norm [Nemhauser and Wolsey, 1988]. optimizer optimizee p a r a m et r u p d a t e s e ror s ig n a l Fi"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 56356708,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "224547e2d6991c0612830c28c269a569c5a33edc",
            "isKey": false,
            "numCitedBy": 901,
            "numCiting": 187,
            "paperAbstract": {
                "fragments": [],
                "text": "Sparse estimation methods are aimed at using or obtaining parsimonious representations of data or models. They were first dedicated to linear variable selection but numerous extensions have now emerged such as structured sparsity or kernel selection. It turns out that many of the related estimation problems can be cast as convex optimization problems by regularizing the empirical risk with appropriate nonsmooth norms. The goal of this monograph is to present from a general perspective optimization tools and techniques dedicated to such sparsity-inducing penalties. We cover proximal methods, block-coordinate descent, reweighted l2-penalized techniques, working-set and homotopy methods, as well as non-convex formulations and extensions, and provide an extensive set of experiments to compare various algorithms from a computational point of view."
            },
            "slug": "Optimization-with-Sparsity-Inducing-Penalties-Bach-Jenatton",
            "title": {
                "fragments": [],
                "text": "Optimization with Sparsity-Inducing Penalties"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This monograph covers proximal methods, block-coordinate descent, reweighted l2-penalized techniques, working-set and homotopy methods, as well as non-convex formulations and extensions, and provides an extensive set of experiments to compare various algorithms from a computational point of view."
            },
            "venue": {
                "fragments": [],
                "text": "Found. Trends Mach. Learn."
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144570279"
                        ],
                        "name": "F. Bach",
                        "slug": "F.-Bach",
                        "structuredName": {
                            "firstName": "Francis",
                            "lastName": "Bach",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Bach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068720"
                        ],
                        "name": "Rodolphe Jenatton",
                        "slug": "Rodolphe-Jenatton",
                        "structuredName": {
                            "firstName": "Rodolphe",
                            "lastName": "Jenatton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rodolphe Jenatton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2599292"
                        ],
                        "name": "J. Mairal",
                        "slug": "J.-Mairal",
                        "structuredName": {
                            "firstName": "Julien",
                            "lastName": "Mairal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mairal"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 102
                            }
                        ],
                        "text": "In contrast, communities who focus on sparsity tend to favor very different approaches [Donoho, 2006, Bach et al., 2012]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 123950470,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aad9544d3ffa4c146d5b528afe83ba4e656c62ee",
            "isKey": false,
            "numCitedBy": 255,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Sparse estimation methods are aimed at using or obtaining parsimonious representations of data or models. They were first dedicated to linear variable selection but numerous extensions have now emerged such as structured sparsity or kernel selection. It turns out that many of the related estimation problems can be cast as convex optimization problems by regularizing the empirical risk with appropriate nonsmooth norms. Optimization with Sparsity-Inducing Penalties presents optimization tools and techniques dedicated to such sparsity-inducing penalties from a general perspective. It covers proximal methods, block-coordinate descent, reweighted 2-penalized techniques, working-set and homotopy methods, as well as non-convex formulations and extensions, and provides an extensive set of experiments to compare various algorithms from a computational point of view. The presentation of Optimization with Sparsity-Inducing Penalties is essentially based on existing literature, but the process of constructing a general framework leads naturally to new results, connections and points of view. It is an ideal reference on the topic for anyone working in machine learning and related areas."
            },
            "slug": "Optimization-with-Sparsity-Inducing-Penalties-and-Bach-Jenatton",
            "title": {
                "fragments": [],
                "text": "Optimization with Sparsity-Inducing Penalties (Foundations and Trends(R) in Machine Learning)"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "Optimization with Sparsity-Inducing Penalties presents optimization tools and techniques dedicated to such sparsity-inducing penalties from a general perspective and provides an extensive set of experiments to compare various algorithms from a computational point of view."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1891828"
                        ],
                        "name": "Leon A. Gatys",
                        "slug": "Leon-A.-Gatys",
                        "structuredName": {
                            "firstName": "Leon",
                            "lastName": "Gatys",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Leon A. Gatys"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746183"
                        ],
                        "name": "Alexander S. Ecker",
                        "slug": "Alexander-S.-Ecker",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Ecker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander S. Ecker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731199"
                        ],
                        "name": "M. Bethge",
                        "slug": "M.-Bethge",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Bethge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bethge"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 5
                            }
                        ],
                        "text": "Each Neural Art problem starts from a a content image, c, and a style image, s, and is given by\nf(\u03b8) = \u03b1Lcontent(c, \u03b8) + \u03b2Lstyle(s, \u03b8) + \u03b3Lreg(\u03b8)\nThe minimizer of f is the styled image."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 88
                            }
                        ],
                        "text": "The recent work on artistic style transfer using convolutional networks, or Neural Art [Gatys et al., 2015], gives a natural testbed for our method, since each content and style image pair gives rise to a different optimization problem."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 25
                            }
                        ],
                        "text": "Details can be found in [Gatys et al., 2015]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 100
                            }
                        ],
                        "text": "4 Neural Art The recent work on artistic style transfer using convolutional networks, or Neural Art [Gatys et al., 2015], gives a natural testbed for our method, since each content and style image pair gives rise to a different optimization problem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 49
                            }
                        ],
                        "text": "We use this limited-memory approach in MNIST and Neural Art experiments."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13914930,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "f37e90c0bd5c4a9619ccfb763c45cb2d84abd3e6",
            "isKey": true,
            "numCitedBy": 1908,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In fine art, especially painting, humans have mastered the skill to create unique visual experiences through composing a complex interplay between the content and style of an image. Thus far the algorithmic basis of this process is unknown and there exists no artificial system with similar capabilities. However, in other key areas of visual perception such as object and face recognition near-human performance was recently demonstrated by a class of biologically inspired vision models called Deep Neural Networks. Here we introduce an artificial system based on a Deep Neural Network that creates artistic images of high perceptual quality. The system uses neural representations to separate and recombine content and style of arbitrary images, providing a neural algorithm for the creation of artistic images. Moreover, in light of the striking similarities between performance-optimised artificial neural networks and biological vision, our work offers a path forward to an algorithmic understanding of how humans create and perceive artistic imagery."
            },
            "slug": "A-Neural-Algorithm-of-Artistic-Style-Gatys-Ecker",
            "title": {
                "fragments": [],
                "text": "A Neural Algorithm of Artistic Style"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work introduces an artificial system based on a Deep Neural Network that creates artistic images of high perceptual quality and offers a path forward to an algorithmic understanding of how humans create and perceive artistic imagery."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2909364"
                        ],
                        "name": "J. Cloutier",
                        "slug": "J.-Cloutier",
                        "structuredName": {
                            "firstName": "Jocelyn",
                            "lastName": "Cloutier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cloutier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 16980098,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04df5041de8c0ba7bdc6edb76ba3e77728b9e93f",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a framework where a learning rule can be optimized within a parametric learning rule space. We define what we callparametric learning rules and present a theoretical study of theirgeneralization properties when estimated from a set of learning tasks and tested over another set of tasks. We corroborate the results of this study with practical experiments."
            },
            "slug": "On-the-search-for-new-learning-rules-for-ANNs-Bengio-Bengio",
            "title": {
                "fragments": [],
                "text": "On the search for new learning rules for ANNs"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A framework where a learning rule can be optimized within a parametric learning rule space and a theoretical study of their generalization properties when estimated from a set of learning tasks and tested over another set of tasks is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Processing Letters"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308557"
                        ],
                        "name": "S. Hochreiter",
                        "slug": "S.-Hochreiter",
                        "structuredName": {
                            "firstName": "Sepp",
                            "lastName": "Hochreiter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hochreiter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 106
                            }
                        ],
                        "text": "We implement the update rule for each coordinate using a two-layer Long Short Term Memory (LSTM) network [Hochreiter and Schmidhuber, 1997]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1915014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44d2abe2175df8153f465f6c39b68b76a0d40ab9",
            "isKey": false,
            "numCitedBy": 52390,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms."
            },
            "slug": "Long-Short-Term-Memory-Hochreiter-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Long Short-Term Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel, efficient, gradient based method called long short-term memory (LSTM) is introduced, which can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48041290"
                        ],
                        "name": "L. Feldkamp",
                        "slug": "L.-Feldkamp",
                        "structuredName": {
                            "firstName": "Lee",
                            "lastName": "Feldkamp",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Feldkamp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1974892"
                        ],
                        "name": "G. Puskorius",
                        "slug": "G.-Puskorius",
                        "structuredName": {
                            "firstName": "Gintaras",
                            "lastName": "Puskorius",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Puskorius"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 60
                            }
                        ],
                        "text": "Similar work has also been attacked in a filtering context [Feldkamp and Puskorius, 1998, Prokhorov et al., 2002], a line of work that is directly related to simple multi-timescale optimizers [Sutton, 1992, Schraudolph, 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 242,
                                "start": 213
                            }
                        ],
                        "text": "Preprocessing and postprocessing Optimizer inputs and outputs can have very different magnitudes depending on the class of function being optimized, but neural networks usually work robustly only for inputs and outputs which are neither very small nor very large."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58313181,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bbc0a570896ca9ecf87d8321ec49074214da31ee",
            "isKey": false,
            "numCitedBy": 114,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a coherent neural net based framework for solving various signal processing problems. It relies on the assertion that time-lagged recurrent networks possess the necessary representational capabilities to act as universal approximators of nonlinear dynamical systems. This applies to system identification, time-series prediction, nonlinear filtering, adaptive filtering, and temporal pattern classification. We address the development of models of nonlinear dynamical systems, in the form of time-lagged recurrent neural nets, which can be used without further training. We employ a weight update procedure based on the extended Kalman filter (EKF). Against the tendency for a net to forget earlier learning as it processes new examples, we develop a technique called multistream training. We demonstrate our framework by applying it to 4 problems. First, we show that a single time-lagged recurrent net can be trained to produce excellent one-time-step predictions for two different time series and also to be robust to severe errors in the input sequence. Second, we model stably a complex system containing significant process noise. The remaining two problems are drawn from real-world automotive applications. One involves input-output modeling of the dynamic behavior of a catalyst-sensor system which is exposed to an operating engine's exhaust stream, the other the real-time and continuous detection of engine misfire."
            },
            "slug": "A-signal-processing-framework-based-on-dynamic-with-Feldkamp-Puskorius",
            "title": {
                "fragments": [],
                "text": "A signal processing framework based on dynamic neural networks with application to problems in adaptation, filtering, and classification"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that a single time-lagged recurrent net can be trained to produce excellent one-time-step predictions for two different time series and also to be robust to severe errors in the input sequence."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "18424934"
                        ],
                        "name": "C. Nelson",
                        "slug": "C.-Nelson",
                        "structuredName": {
                            "firstName": "C",
                            "lastName": "Nelson",
                            "middleNames": [
                                "A"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Nelson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 114
                            }
                        ],
                        "text": "The idea of using learning to learn or meta-learning to acquire knowledge or inductive biases has a long history [Thrun and Pratt, 1998]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 114
                            }
                        ],
                        "text": "One challenge in applying RNNs in our setting is that we want to be able to optimize at least tens of thousands of parameters."
                    },
                    "intents": []
                }
            ],
            "corpusId": 11974053,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "53bb7789be36a58f865f2ec84f6d8f816ddaae6a",
            "isKey": false,
            "numCitedBy": 2272,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "In first year we were taught programming. Those lessons just happened to be in Modular 2. In later years, though, we were only introduced to other languages (most notably C and Java), and were expected to learn the rest ourselves. What I took from this experience was the ability to learn a new programming language myself, and because I had been taught the fundamental principles of programming, instead of any particular programming language, I was able to do that. This became more apparent, though, when I started working on the OCC, as it was developed in Visual Basic; a programming environment that I had never used before. After the few years of programming with Java, it came as quite a shock that Visual Basic did not have inheritance, even though it did have classes. Despite this, I was able to employ my knowledge of programming paradigms to this \u201cnew\u201d language, and produce just as well structured code as I could with any other language I was already familiar with."
            },
            "slug": "Learning-to-Learn-Nelson",
            "title": {
                "fragments": [],
                "text": "Learning to Learn"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Because I had been taught the fundamental principles of programming, instead of any particular programming language, I was able to learn a new programming language myself, and produce just as well structured code as I could with any other language I was already familiar with."
            },
            "venue": {
                "fragments": [],
                "text": "Encyclopedia of Machine Learning and Data Mining"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696678"
                        ],
                        "name": "D. Wolpert",
                        "slug": "D.-Wolpert",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Wolpert",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Wolpert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2957256"
                        ],
                        "name": "W. Macready",
                        "slug": "W.-Macready",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Macready",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Macready"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5553697,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8315dff3d304baf47c025f4b33535b9d693350c1",
            "isKey": false,
            "numCitedBy": 9370,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "A framework is developed to explore the connection between effective optimization algorithms and the problems they are solving. A number of \"no free lunch\" (NFL) theorems are presented which establish that for any algorithm, any elevated performance over one class of problems is offset by performance over another class. These theorems result in a geometric interpretation of what it means for an algorithm to be well suited to an optimization problem. Applications of the NFL theorems to information-theoretic aspects of optimization and benchmark measures of performance are also presented. Other issues addressed include time-varying optimization problems and a priori \"head-to-head\" minimax distinctions between optimization algorithms, distinctions that result despite the NFL theorems' enforcing of a type of uniformity over all algorithms."
            },
            "slug": "No-free-lunch-theorems-for-optimization-Wolpert-Macready",
            "title": {
                "fragments": [],
                "text": "No free lunch theorems for optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "A framework is developed to explore the connection between effective optimization algorithms and the problems they are solving and a number of \"no free lunch\" (NFL) theorems are presented which establish that for any algorithm, any elevated performance over one class of problems is offset by performance over another class."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Evol. Comput."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "89504302"
                        ],
                        "name": "Greg Wayne",
                        "slug": "Greg-Wayne",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Wayne",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Wayne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1841008"
                        ],
                        "name": "Ivo Danihelka",
                        "slug": "Ivo-Danihelka",
                        "structuredName": {
                            "firstName": "Ivo",
                            "lastName": "Danihelka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ivo Danihelka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 231,
                                "start": 212
                            }
                        ],
                        "text": "Conveniently, this structure of interaction with a large dynamically updated state corresponds in a fairly direct way to the architecture of a Neural Turing Machine (NTM), where Mt corresponds to the NTM memory [Graves et al., 2014]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 125
                            }
                        ],
                        "text": "We call this architecture an NTM-BFGS optimizer, because its use of external memory is similar to the Neural Turing Machine [Graves et al., 2014]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15299054,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3823aacea60bc1f2cabb9283144690a3d015db5",
            "isKey": false,
            "numCitedBy": 1651,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "We extend the capabilities of neural networks by coupling them to external memory resources, which they can interact with by attentional processes. The combined system is analogous to a Turing Machine or Von Neumann architecture but is differentiable end-toend, allowing it to be efficiently trained with gradient descent. Preliminary results demonstrate that Neural Turing Machines can infer simple algorithms such as copying, sorting, and associative recall from input and output examples."
            },
            "slug": "Neural-Turing-Machines-Graves-Wayne",
            "title": {
                "fragments": [],
                "text": "Neural Turing Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A combined system is analogous to a Turing Machine or Von Neumann architecture but is differentiable end-toend, allowing it to be efficiently trained with gradient descent."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2264754"
                        ],
                        "name": "N. E. Cotter",
                        "slug": "N.-E.-Cotter",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Cotter",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. E. Cotter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2927101"
                        ],
                        "name": "P. R. Conwell",
                        "slug": "P.-R.-Conwell",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Conwell",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. R. Conwell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 32951368,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8001b80755bb8b189f3e1a51db8d108303b9fe7b",
            "isKey": false,
            "numCitedBy": 30,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "A theorem describing how fixed-weight recurrent neural networks can approximate adaptive-weight learning algorithms is proved. The theorem applies to most networks and learning algorithms currently in use. It is concluded from the theorem that a system which exhibits learning behavior may exhibit no synaptic weight modifications. This idea is demonstrated by transforming a backward error propagation network into a fixed-weight system"
            },
            "slug": "Fixed-weight-networks-can-learn-Cotter-Conwell",
            "title": {
                "fragments": [],
                "text": "Fixed-weight networks can learn"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is concluded from the theorem that a system which exhibits learning behavior may exhibit no synaptic weight modifications, and it is demonstrated by transforming a backward error propagation network into a fixed-weight system."
            },
            "venue": {
                "fragments": [],
                "text": "1990 IJCNN International Joint Conference on Neural Networks"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16605993,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32437ae95b6c70517a325bb14d2b9c33473fb96f",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "A recurrent neural network is presented which (in principle) can, besides learning to solve problems posed by the environment, also use its own weights as input data and learn new (arbitrarily complex) algorithms for modifying its own weights in response to the environmental input and evaluations. The network uses subsets of its input and output units for observing its own errors and for explicitly analysing and manipulating all of its own weights, including those weights responsible for analyzing and manipulating weights. This effectively embeds a chain of meta-networks and meta-meta-. . .-networks into the network itself.<<ETX>>"
            },
            "slug": "A-neural-network-that-embeds-its-own-meta-levels-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "A neural network that embeds its own meta-levels"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A recurrent neural network is presented which (in principle) can, besides learning to solve problems posed by the environment, also use its own weights as input data and learn new (arbitrarily complex) algorithms for modifying itsown weights in response to the environmental input and evaluations."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE International Conference on Neural Networks"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2784955"
                        ],
                        "name": "J. Nocedal",
                        "slug": "J.-Nocedal",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "Nocedal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Nocedal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144731788"
                        ],
                        "name": "Stephen J. Wright",
                        "slug": "Stephen-J.-Wright",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Wright",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen J. Wright"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 164
                            }
                        ],
                        "text": "Such a memory, if appropriately designed could allow the optimizer to learn algorithms similar to (low-memory) approximations to Newton\u2019s method, e.g. (L-)BFGS [see Nocedal and Wright, 2006]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "hat is shared between coordinates. Such a memory, if appropriately designed could allow the optimizer to learn algorithms similar to (low-memory) approximations to Newton\u2019s method, e.g. (L-)BFGS [see Nocedal and Wright, 2006]. The reason for this interpretation is that such methods can be seen as a set of independent processes working coordinatewise, but communicating through the inverse Hessian approximation stored in t"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 198120256,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "43c3bfffdcd313c549b2045980855ea001d6f13b",
            "isKey": false,
            "numCitedBy": 10609,
            "numCiting": 270,
            "paperAbstract": {
                "fragments": [],
                "text": "Numerical Optimization presents a comprehensive and up-to-date description of the most effective methods in continuous optimization. It responds to the growing interest in optimization in engineering, science, and business by focusing on the methods that are best suited to practical problems. For this new edition the book has been thoroughly updated throughout. There are new chapters on nonlinear interior methods and derivative-free methods for optimization, both of which are used widely in practice and the focus of much current research. Because of the emphasis on practical methods, as well as the extensive illustrations and exercises, the book is accessible to a wide audience. It can be used as a graduate text in engineering, operations research, mathematics, computer science, and business. It also serves as a handbook for researchers and practitioners in the field. The authors have strived to produce a text that is pleasant to read, informative, and rigorous - one that reveals both the beautiful nature of the discipline and its practical side."
            },
            "slug": "Numerical-Optimization-Nocedal-Wright",
            "title": {
                "fragments": [],
                "text": "Numerical Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "Numerical Optimization presents a comprehensive and up-to-date description of the most effective methods in continuous optimization, responding to the growing interest in optimization in engineering, science, and business by focusing on the methods that are best suited to practical problems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110117732"
                        ],
                        "name": "Jieyu Zhao",
                        "slug": "Jieyu-Zhao",
                        "structuredName": {
                            "firstName": "Jieyu",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jieyu Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32239759"
                        ],
                        "name": "M. Wiering",
                        "slug": "M.-Wiering",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Wiering",
                            "middleNames": [
                                "A"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wiering"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14513370,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "6e7241121c688abbd9329bdcebce4b6320fc619d",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "We study task sequences that allow for speeding up the learner's average reward intake through appropriate shifts of inductive bias (changes of the learner's policy). To evaluate long-term effects of bias shifts setting the stage for later bias shifts we use the \u201csuccess-story algorithm\u201d (SSA). SSA is occasionally called at times that may depend on the policy itself. It uses backtracking to undo those bias shifts that have not been empirically observed to trigger long-term reward accelerations (measured up until the current SSA call). Bias shifts that survive SSA represent a lifelong success history. Until the next SSA call, they are considered useful and build the basis for additional bias shifts. SSA allows for plugging in a wide variety of learning algorithms. We plug in (1) a novel, adaptive extension of Levin search and (2) a method for embedding the learner's policy modification strategy within the policy itself (incremental self-improvement). Our inductive transfer case studies involve complex, partially observable environments where traditional reinforcement learning fails."
            },
            "slug": "Shifting-Inductive-Bias-with-Success-Story-Adaptive-Schmidhuber-Zhao",
            "title": {
                "fragments": [],
                "text": "Shifting Inductive Bias with Success-Story Algorithm, Adaptive Levin Search, and Incremental Self-Improvement"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "In inductive transfer case studies, task sequences that allow for speeding up the learner's average reward intake through appropriate shifts of inductive bias are studied through the use of the \u201csuccess-story algorithm\u201d (SSA)."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2353770"
                        ],
                        "name": "D. Prokhorov",
                        "slug": "D.-Prokhorov",
                        "structuredName": {
                            "firstName": "Danil",
                            "lastName": "Prokhorov",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Prokhorov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72641887"
                        ],
                        "name": "L. A. Feldkarnp",
                        "slug": "L.-A.-Feldkarnp",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Feldkarnp",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. A. Feldkarnp"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2196121"
                        ],
                        "name": "I. Tyukin",
                        "slug": "I.-Tyukin",
                        "structuredName": {
                            "firstName": "Ivan",
                            "lastName": "Tyukin",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Tyukin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 90
                            }
                        ],
                        "text": "Similar work has also been attacked in a filtering context [Feldkamp and Puskorius, 1998, Prokhorov et al., 2002], a line of work that is directly related to simple multi-timescale optimizers [Sutton, 1992, Schraudolph, 1999]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61451311,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "07a575ff2b4fdd892dfccefa38e4b24ec472663b",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we review recent results on the adaptive behavior attained with fixed-weight recurrent neural networks (meta-learning). We argue that such behavior is a natural consequence of prior training."
            },
            "slug": "Adaptive-behavior-with-fixed-weights-in-RNN:-an-Prokhorov-Feldkarnp",
            "title": {
                "fragments": [],
                "text": "Adaptive behavior with fixed weights in RNN: an overview"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "It is argued that adaptive behavior attained with fixed-weight recurrent neural networks (meta-learning) is a natural consequence of prior training."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2002 International Joint Conference on Neural Networks. IJCNN'02 (Cat. No.02CH37290)"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153302678"
                        ],
                        "name": "Jia Deng",
                        "slug": "Jia-Deng",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144847596"
                        ],
                        "name": "Wei Dong",
                        "slug": "Wei-Dong",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Dong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Dong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2040091191"
                        ],
                        "name": "Li-Jia Li",
                        "slug": "Li-Jia-Li",
                        "structuredName": {
                            "firstName": "Li-Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "94451829"
                        ],
                        "name": "K. Li",
                        "slug": "K.-Li",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 57246310,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2c733e34d48784a37d717fe43d9e93277a8c53e",
            "isKey": false,
            "numCitedBy": 28266,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called \u201cImageNet\u201d, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond."
            },
            "slug": "ImageNet:-A-large-scale-hierarchical-image-database-Deng-Dong",
            "title": {
                "fragments": [],
                "text": "ImageNet: A large-scale hierarchical image database"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new database called \u201cImageNet\u201d is introduced, a large-scale ontology of images built upon the backbone of the WordNet structure, much larger in scale and diversity and much more accurate than the current image datasets."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144972606"
                        ],
                        "name": "K. Hoffman",
                        "slug": "K.-Hoffman",
                        "structuredName": {
                            "firstName": "Karla",
                            "lastName": "Hoffman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Hoffman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728124"
                        ],
                        "name": "T. Ralphs",
                        "slug": "T.-Ralphs",
                        "structuredName": {
                            "firstName": "Ted",
                            "lastName": "Ralphs",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Ralphs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 100
                            }
                        ],
                        "text": "This is even more the case for combinatorial optimization for which relaxations are often the norm [Nemhauser and Wolsey, 1988]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 158
                            }
                        ],
                        "text": "Note, however that these earlier works do not directly address the transfer of a learned training procedure to novel problem instances and instead focus on adaptivity in the online setting."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8707032,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "4de3ad300efdafef428cce497af6d306442e59f0",
            "isKey": false,
            "numCitedBy": 1301,
            "numCiting": 143,
            "paperAbstract": {
                "fragments": [],
                "text": "Integer optimization problems are concerned with the efficient allocation of limited resources to meet a desired objective when some of the resources in question can only be divided into discrete parts. In such cases, the divisibility constraints on these resources, which may be people, machines, or other discrete inputs, may restrict the possible alternatives to a finite set. Nevertheless, there are usually too many alternatives to make complete enumeration a viable option for instances of realistic size. For example, an airline may need to determine crew schedules that minimize the total operating cost; an automotive manufacturer may want to determine the optimal mix of models to produce in order to maximize profit; or a flexible manufacturing facility may want to schedule production for a plant without knowing precisely what parts will be needed in future periods. In today\u2019s changing and competitive industrial environment, the difference between ad hoc planning methods and those that use sophisticated mathematical models to determine an optimal course of action can determine whether or not a company survives."
            },
            "slug": "Integer-and-Combinatorial-Optimization-Hoffman-Ralphs",
            "title": {
                "fragments": [],
                "text": "Integer and Combinatorial Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "In today\u2019s changing and competitive industrial environment, the difference between ad hoc planning methods and those that use sophisticated mathematical models to determine an optimal course of action can determine whether or not a company survives."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10299105"
                        ],
                        "name": "S. Frick",
                        "slug": "S.-Frick",
                        "structuredName": {
                            "firstName": "S",
                            "lastName": "Frick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Frick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ethods can also be applied when more structure of the optimization problem is known [Martens and Grosse, 2015]. In contrast, communities who focus on sparsity tend to favor very different approaches [Donoho, 2006, Bach et al., 2012]. This is even more the case for combinatorial optimization for which relaxations are often the norm [Nemhauser and Wolsey, 1988]. 30th Conference on Neural Information Processing "
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 88
                            }
                        ],
                        "text": "In contrast, communities who focus on sparsity tend to favor very different approaches [Donoho, 2006, Bach et al., 2012]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13622916,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e1630fbfb75c2c06bda9f76da139283f245b7cea",
            "isKey": false,
            "numCitedBy": 7872,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The steady growing number of quantum bits used in modern quantum information experiments gives rise to new problems. Especially if we want to determine the quantum state used in an experiment, i.e. ascertain the density matrix of the state, the number of needed measurement settings scales exponentially bad with \u0398(4n), where n is the number of qubits. Compressed sensing is a technique developed to overcome this problem by using matrix completion methods to reconstruct a full density matrix of low rank states with fewer measurements. This report explains themain ideas of compressed sensing to the reader and gives a (highly incomplete) overview of the work done in the field. It is my experience that proofs involving matrices can be shortened by 50% if one throws the matrices out. E. Artin"
            },
            "slug": "Compressed-Sensing-Frick",
            "title": {
                "fragments": [],
                "text": "Compressed Sensing"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This report explains the ideas of compressed sensing to the reader and gives a (highly incomplete) overview of the work done in the field and suggests that proofs involving matrices can be shortened by 50% if one throws the matrices out."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 87
                            }
                        ],
                        "text": "We compare our trained optimizers with standard optimizers used in Deep Learning: SGD, RMSprop, ADAM, Adadelta, Adagrad, and Rprop."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 42
                            }
                        ],
                        "text": ", 2011], Adadelta [Zeiler, 2012], RMSprop [Tieleman and Hinton, 2012], and ADAM [Kingma and Ba, 2015]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 122
                            }
                        ],
                        "text": "In the previous section we considered a coordinatewise architecture, which corresponds by analogy to a learned version of RMSprop or ADAM."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 169
                            }
                        ],
                        "text": "To avoid this difficulty we will use an optimizer m which operates coordinatewise on the parameters of the objective function, similar to other common update rules like RMSprop and ADAM."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 154
                            }
                        ],
                        "text": "These include momentum [Nesterov, 1983, Tseng, 1998], Rprop [Riedmiller and Braun, 1993], Adagrad [Duchi et al., 2011], Adadelta [Zeiler, 2012], RMSprop [Tieleman and Hinton, 2012], and ADAM [Kingma and Ba, 2015]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude"
            },
            "venue": {
                "fragments": [],
                "text": "COURSERA: Neural Networks for Machine Learning"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 311,
                                "start": 0
                            }
                        ],
                        "text": "Bengio et al. [1990, 1995] propose to learn updates which avoid back-propagation by using simple parametric rules. In relation to the focus of this paper the work of Bengio et al. could be characterized as learning to learn without gradient descent by gradient descent. The work of Runarsson and Jonsson [2000] builds upon this work by replacing the simple rule with a neural network."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 829,
                                "start": 0
                            }
                        ],
                        "text": "Bengio et al. [1990, 1995] propose to learn updates which avoid back-propagation by using simple parametric rules. In relation to the focus of this paper the work of Bengio et al. could be characterized as learning to learn without gradient descent by gradient descent. The work of Runarsson and Jonsson [2000] builds upon this work by replacing the simple rule with a neural network. Cotter and Conwell [1990], and later Younger et al. [1999], also show fixed-weight recurrent neural networks can exhibit dynamic behavior without need to modify their network weights. Similarly this has been shown in a filtering context [e.g. Feldkamp and Puskorius, 1998], which is directly related to simple multi-timescale optimizers [Sutton, 1992, Schraudolph, 1999]. Finally, the work of Younger et al. [2001] and Hochreiter et al. [2001] connects these different threads of research by allowing for the output of backpropagation from one network to feed into an additional learning network, with both networks trained jointly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 444,
                                "start": 0
                            }
                        ],
                        "text": "Bengio et al. [1990, 1995] propose to learn updates which avoid back-propagation by using simple parametric rules. In relation to the focus of this paper the work of Bengio et al. could be characterized as learning to learn without gradient descent by gradient descent. The work of Runarsson and Jonsson [2000] builds upon this work by replacing the simple rule with a neural network. Cotter and Conwell [1990], and later Younger et al. [1999], also show fixed-weight recurrent neural networks can exhibit dynamic behavior without need to modify their network weights."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning a synaptic learning"
            },
            "venue": {
                "fragments": [],
                "text": "rule. Universite\u0301 de Montre\u0301al,"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143676697"
                        ],
                        "name": "Y. Nesterov",
                        "slug": "Y.-Nesterov",
                        "structuredName": {
                            "firstName": "Yurii",
                            "lastName": "Nesterov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Nesterov"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 145918791,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "8d3a318b62d2e970122da35b2a2e70a5d12cc16f",
            "isKey": false,
            "numCitedBy": 3213,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-method-for-solving-the-convex-programming-problem-Nesterov",
            "title": {
                "fragments": [],
                "text": "A method for solving the convex programming problem with convergence rate O(1/k^2)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1983
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Meta-learning with memoryaugmented neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "In International Conference on Machine Learning,"
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 65
                            }
                        ],
                        "text": "We can then ask the question: What does it mean for an optimizer to be good?"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "URL https://www.flickr.com/photos/fbobolas/3822222947. Creative Commons Attribution-ShareAlike 2"
            },
            "venue": {
                "fragments": [],
                "text": "URL https://www.flickr.com/photos/fbobolas/3822222947. Creative Commons Attribution-ShareAlike 2"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural Turing machines. arXiv Report"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Turing machines. arXiv Report"
            },
            "year": 1410
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 11
                            }
                        ],
                        "text": "Similarly, Santoro et al. [2016] frame multi-task learning as generalization, however unlike our approach they directly train a base learner rather than a training algorithm."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 149
                            }
                        ],
                        "text": "2 A brief history and related work The idea of using learning to learn or meta-learning to acquire knowledge or inductive biases has a long history [Thrun and Pratt, 1998]. More recently, Lake et al. [2016] have argued forcefully for its importance as a building block in artificial intelligence."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Combinations of Evolutionary Computation and Neural Networks, pages 59\u201363"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "URL https://www.flickr.com/photos/fbobolas/ 3822222947"
            },
            "venue": {
                "fragments": [],
                "text": "brain-neurons,"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Meta - learning with memoryaugmented neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Machine Learning"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 3
                            }
                        ],
                        "text": "Given a distribution of functions f we will write the expected loss as\nL(\u03c6) = Ef [ f ( \u03b8\u2217(f, \u03c6) )] ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "URL https://www.flickr.com/photos/taylortotz101/6280077898"
            },
            "venue": {
                "fragments": [],
                "text": "URL https://www.flickr.com/photos/taylortotz101/6280077898"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 41
                            }
                        ],
                        "text": "Different behavior on each coordinate is achieved by using separate activations for each objective function parameter."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Evolutionary principles in self-referential learning; On learning how to learn: The meta-meta-... hook"
            },
            "venue": {
                "fragments": [],
                "text": "Evolutionary principles in self-referential learning; On learning how to learn: The meta-meta-... hook"
            },
            "year": 1987
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 15,
            "methodology": 10
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 48,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Learning-to-learn-by-gradient-descent-by-gradient-Andrychowicz-Denil/395dd01c0d24777c660cf195c4cfadcdf51fb7e8?sort=total-citations"
}