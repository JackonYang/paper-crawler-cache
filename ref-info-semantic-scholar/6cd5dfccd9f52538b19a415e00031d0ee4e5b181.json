{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2781709"
                        ],
                        "name": "Phillip Verbancsics",
                        "slug": "Phillip-Verbancsics",
                        "structuredName": {
                            "firstName": "Phillip",
                            "lastName": "Verbancsics",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Phillip Verbancsics"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745184"
                        ],
                        "name": "Josh Harguess",
                        "slug": "Josh-Harguess",
                        "structuredName": {
                            "firstName": "Josh",
                            "lastName": "Harguess",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josh Harguess"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 168
                            }
                        ],
                        "text": "MetaQNN obtains an error of 6.92% as compared to 21.2% reported by Bergstra et al. (2011) on CIFAR-10; and it obtains an error of 0.32% as compared to 7.9% reported by Verbancsics & Harguess (2013) on MNIST."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 281,
                                "start": 253
                            }
                        ],
                        "text": "However, to the best of our knowledge, networks designed with genetic algorithms, such as those generated with the NEAT algorithm (Stanley & Miikkulainen, 2002), have been unable to match the performance of hand-crafted networks on standard benchmarks (Verbancsics & Harguess, 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14633319,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fb300dc8dcf884cc8ddb3bff92e3e5df08d34dae",
            "isKey": true,
            "numCitedBy": 45,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "An important goal for the machine learning (ML) community is to create approaches that can learn solutions with human-level capability. One domain where humans have held a significant advantage is visual processing. A significant approach to addressing this gap has been machine learning approaches that are inspired from the natural systems, such as artificial neural networks (ANNs), evolutionary computation (EC), and generative and developmental systems (GDS). Research into deep learning has demonstrated that such architectures can achieve performance competitive with humans on some visual tasks; however, these systems have been primarily trained through supervised and unsupervised learning algorithms. Alternatively, research is showing that evolution may have a significant role in the development of visual systems. Thus this paper investigates the role neuro-evolution (NE) can take in deep learning. In particular, the Hypercube-based NeuroEvolution of Augmenting Topologies is a NE approach that can effectively learn large neural structures by training an indirect encoding that compresses the ANN weight pattern as a function of geometry. The results show that HyperNEAT struggles with performing image classification by itself, but can be effective in training a feature extractor that other ML approaches can learn from. Thus NeuroEvolution combined with other ML methods provides an intriguing area of research that can replicate the processes in nature."
            },
            "slug": "Generative-NeuroEvolution-for-Deep-Learning-Verbancsics-Harguess",
            "title": {
                "fragments": [],
                "text": "Generative NeuroEvolution for Deep Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The results show that HyperNEAT struggles with performing image classification by itself, but can be effective in training a feature extractor that other ML approaches can learn from, and NeuroEvolution combined with other ML methods provides an intriguing area of research that can replicate the processes in nature."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115913164"
                        ],
                        "name": "Min Lin",
                        "slug": "Min-Lin",
                        "structuredName": {
                            "firstName": "Min",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Min Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35370244"
                        ],
                        "name": "Qiang Chen",
                        "slug": "Qiang-Chen",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143653681"
                        ],
                        "name": "Shuicheng Yan",
                        "slug": "Shuicheng-Yan",
                        "structuredName": {
                            "firstName": "Shuicheng",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuicheng Yan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16636683,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e83ab70d0cbc003471e87ec306d27d9c80ecb16",
            "isKey": false,
            "numCitedBy": 4255,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel deep network structure called \"Network In Network\" (NIN) to enhance model discriminability for local patches within the receptive field. The conventional convolutional layer uses linear filters followed by a nonlinear activation function to scan the input. Instead, we build micro neural networks with more complex structures to abstract the data within the receptive field. We instantiate the micro neural network with a multilayer perceptron, which is a potent function approximator. The feature maps are obtained by sliding the micro networks over the input in a similar manner as CNN; they are then fed into the next layer. Deep NIN can be implemented by stacking mutiple of the above described structure. With enhanced local modeling via the micro network, we are able to utilize global average pooling over feature maps in the classification layer, which is easier to interpret and less prone to overfitting than traditional fully connected layers. We demonstrated the state-of-the-art classification performances with NIN on CIFAR-10 and CIFAR-100, and reasonable performances on SVHN and MNIST datasets."
            },
            "slug": "Network-In-Network-Lin-Chen",
            "title": {
                "fragments": [],
                "text": "Network In Network"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "With enhanced local modeling via the micro network, the proposed deep network structure NIN is able to utilize global average pooling over feature maps in the classification layer, which is easier to interpret and less prone to overfitting than traditional fully connected layers."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054800974"
                        ],
                        "name": "Ming Liang",
                        "slug": "Ming-Liang",
                        "structuredName": {
                            "firstName": "Ming",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109753669"
                        ],
                        "name": "Xiaolin Hu",
                        "slug": "Xiaolin-Hu",
                        "structuredName": {
                            "firstName": "Xiaolin",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaolin Hu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6075369,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4b39a79a1dc8e578e38ee4b7f00b4ec9ded50dd0",
            "isKey": false,
            "numCitedBy": 750,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years, the convolutional neural network (CNN) has achieved great success in many computer vision tasks. Partially inspired by neuroscience, CNN shares many properties with the visual system of the brain. A prominent difference is that CNN is typically a feed-forward architecture while in the visual system recurrent connections are abundant. Inspired by this fact, we propose a recurrent CNN (RCNN) for object recognition by incorporating recurrent connections into each convolutional layer. Though the input is static, the activities of RCNN units evolve over time so that the activity of each unit is modulated by the activities of its neighboring units. This property enhances the ability of the model to integrate the context information, which is important for object recognition. Like other recurrent neural networks, unfolding the RCNN through time can result in an arbitrarily deep network with a fixed number of parameters. Furthermore, the unfolded network has multiple paths, which can facilitate the learning process. The model is tested on four benchmark object recognition datasets: CIFAR-10, CIFAR-100, MNIST and SVHN. With fewer trainable parameters, RCNN outperforms the state-of-the-art models on all of these datasets. Increasing the number of parameters leads to even better performance. These results demonstrate the advantage of the recurrent structure over purely feed-forward structure for object recognition."
            },
            "slug": "Recurrent-convolutional-neural-network-for-object-Liang-Hu",
            "title": {
                "fragments": [],
                "text": "Recurrent convolutional neural network for object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "With fewer trainable parameters, RCNN outperforms the state-of-the-art models on all of these datasets and demonstrates the advantage of the recurrent structure over purely feed-forward structure for object recognition."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50521003"
                        ],
                        "name": "Chen-Yu Lee",
                        "slug": "Chen-Yu-Lee",
                        "structuredName": {
                            "firstName": "Chen-Yu",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chen-Yu Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21561136"
                        ],
                        "name": "Patrick W. Gallagher",
                        "slug": "Patrick-W.-Gallagher",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Gallagher",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick W. Gallagher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 148
                            }
                        ],
                        "text": "We finetuned the top ten models with the original plus extended training set, by creating preprocessed training and validation sets as described by Lee et al. (2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 157
                            }
                        ],
                        "text": "In addition, their performance is competitive against network designs that include complex layer types and training procedures (e.g., Clevert et al. (2015); Lee et al. (2016))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 142
                            }
                        ],
                        "text": "Moreover, we can generate not just one, but several varied, well-performing network designs, which can be ensembled to further boost the prediction performance."
                    },
                    "intents": []
                }
            ],
            "corpusId": 31884,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4b88e948121a87f00fb5aa0081d2044dde51ee36",
            "isKey": false,
            "numCitedBy": 391,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We seek to improve deep neural networks by generalizing the pooling operations that play a central role in current architectures. We pursue a careful exploration of approaches to allow pooling to learn and to adapt to complex and variable patterns. The two primary directions lie in (1) learning a pooling function via (two strategies of) combining of max and average pooling, and (2) learning a pooling function in the form of a tree-structured fusion of pooling filters that are themselves learned. In our experiments every generalized pooling operation we explore improves performance when used in place of average or max pooling. We experimentally demonstrate that the proposed pooling operations provide a boost in invariance properties relative to conventional pooling and set the state of the art on several widely adopted benchmark datasets; they are also easy to implement, and can be applied within various deep neural network architectures. These benefits come with only a light increase in computational overhead during training and a very modest increase in the number of model parameters."
            },
            "slug": "Generalizing-Pooling-Functions-in-Convolutional-and-Lee-Gallagher",
            "title": {
                "fragments": [],
                "text": "Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The proposed pooling operations provide a boost in invariance properties relative to conventional pooling and set the state of the art on several widely adopted benchmark datasets; they are also easy to implement, and can be applied within various deep neural network architectures."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060551"
                        ],
                        "name": "Jost Tobias Springenberg",
                        "slug": "Jost-Tobias-Springenberg",
                        "structuredName": {
                            "firstName": "Jost",
                            "lastName": "Springenberg",
                            "middleNames": [
                                "Tobias"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jost Tobias Springenberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2841331"
                        ],
                        "name": "A. Dosovitskiy",
                        "slug": "A.-Dosovitskiy",
                        "structuredName": {
                            "firstName": "Alexey",
                            "lastName": "Dosovitskiy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dosovitskiy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710872"
                        ],
                        "name": "T. Brox",
                        "slug": "T.-Brox",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Brox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Brox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3137672"
                        ],
                        "name": "Martin A. Riedmiller",
                        "slug": "Martin-A.-Riedmiller",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Riedmiller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin A. Riedmiller"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12998557,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0f84a81f431b18a78bd97f59ed4b9d8eda390970",
            "isKey": false,
            "numCitedBy": 3314,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Most modern convolutional neural networks (CNNs) used for object recognition are built using the same principles: Alternating convolution and max-pooling layers followed by a small number of fully connected layers. We re-evaluate the state of the art for object recognition from small images with convolutional networks, questioning the necessity of different components in the pipeline. We find that max-pooling can simply be replaced by a convolutional layer with increased stride without loss in accuracy on several image recognition benchmarks. Following this finding -- and building on other recent work for finding simple network structures -- we propose a new architecture that consists solely of convolutional layers and yields competitive or state of the art performance on several object recognition datasets (CIFAR-10, CIFAR-100, ImageNet). To analyze the network we introduce a new variant of the \"deconvolution approach\" for visualizing features learned by CNNs, which can be applied to a broader range of network structures than existing approaches."
            },
            "slug": "Striving-for-Simplicity:-The-All-Convolutional-Net-Springenberg-Dosovitskiy",
            "title": {
                "fragments": [],
                "text": "Striving for Simplicity: The All Convolutional Net"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is found that max-pooling can simply be replaced by a convolutional layer with increased stride without loss in accuracy on several image recognition benchmarks."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3255983"
                        ],
                        "name": "Volodymyr Mnih",
                        "slug": "Volodymyr-Mnih",
                        "structuredName": {
                            "firstName": "Volodymyr",
                            "lastName": "Mnih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volodymyr Mnih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145824029"
                        ],
                        "name": "David Silver",
                        "slug": "David-Silver",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Silver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Silver"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2228824"
                        ],
                        "name": "Andrei A. Rusu",
                        "slug": "Andrei-A.-Rusu",
                        "structuredName": {
                            "firstName": "Andrei",
                            "lastName": "Rusu",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrei A. Rusu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144056327"
                        ],
                        "name": "J. Veness",
                        "slug": "J.-Veness",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Veness",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Veness"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792298"
                        ],
                        "name": "Marc G. Bellemare",
                        "slug": "Marc-G.-Bellemare",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Bellemare",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc G. Bellemare"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3137672"
                        ],
                        "name": "Martin A. Riedmiller",
                        "slug": "Martin-A.-Riedmiller",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Riedmiller",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin A. Riedmiller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145600108"
                        ],
                        "name": "A. Fidjeland",
                        "slug": "A.-Fidjeland",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Fidjeland",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fidjeland"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2273072"
                        ],
                        "name": "Georg Ostrovski",
                        "slug": "Georg-Ostrovski",
                        "structuredName": {
                            "firstName": "Georg",
                            "lastName": "Ostrovski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Georg Ostrovski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48348688"
                        ],
                        "name": "Stig Petersen",
                        "slug": "Stig-Petersen",
                        "structuredName": {
                            "firstName": "Stig",
                            "lastName": "Petersen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stig Petersen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50388928"
                        ],
                        "name": "Charlie Beattie",
                        "slug": "Charlie-Beattie",
                        "structuredName": {
                            "firstName": "Charlie",
                            "lastName": "Beattie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charlie Beattie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49813280"
                        ],
                        "name": "A. Sadik",
                        "slug": "A.-Sadik",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Sadik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sadik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2460849"
                        ],
                        "name": "Ioannis Antonoglou",
                        "slug": "Ioannis-Antonoglou",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Antonoglou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ioannis Antonoglou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143776287"
                        ],
                        "name": "Helen King",
                        "slug": "Helen-King",
                        "structuredName": {
                            "firstName": "Helen",
                            "lastName": "King",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Helen King"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2106164"
                        ],
                        "name": "D. Kumaran",
                        "slug": "D.-Kumaran",
                        "structuredName": {
                            "firstName": "Dharshan",
                            "lastName": "Kumaran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kumaran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688276"
                        ],
                        "name": "Daan Wierstra",
                        "slug": "Daan-Wierstra",
                        "structuredName": {
                            "firstName": "Daan",
                            "lastName": "Wierstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daan Wierstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34313265"
                        ],
                        "name": "S. Legg",
                        "slug": "S.-Legg",
                        "structuredName": {
                            "firstName": "Shane",
                            "lastName": "Legg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Legg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48987704"
                        ],
                        "name": "D. Hassabis",
                        "slug": "D.-Hassabis",
                        "structuredName": {
                            "firstName": "Demis",
                            "lastName": "Hassabis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hassabis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 150
                            }
                        ],
                        "text": "The agent learns through random exploration and slowly begins to exploit its findings to select higher performing models using the - greedy strategy (Mnih et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 172
                            }
                        ],
                        "text": "Finally, when the state space is large or exploration is costly, the experience replay technique (Lin, 1993) has proved useful in experimental settings (Adam et al., 2012; Mnih et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We incorporate these techniques\u2014Q-learning, the -greedy strategy and experience replay\u2014in our algorithm design."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 120
                            }
                        ],
                        "text": "It would be possible to move to larger state-action spaces using methods for Q-function approximation (Bertsekas, 2015; Mnih et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 63
                            }
                        ],
                        "text": "We choose the behavior distribution using an -greedy strategy (Mnih et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 140
                            }
                        ],
                        "text": "For instance, methods using CNNs to approximate theQ-learning utility function (Watkins, 1989) have been successful in game-playing agents (Mnih et al., 2015; Silver et al., 2016) and robotic control (Lillicrap et al., 2015; Levine et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 205242740,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d",
            "isKey": true,
            "numCitedBy": 16393,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "The theory of reinforcement learning provides a normative account, deeply rooted in psychological and neuroscientific perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory processing systems, the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopaminergic neurons and temporal difference reinforcement learning algorithms. While reinforcement learning agents have achieved some successes in a variety of domains, their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games. We demonstrate that the deep Q-network agent, receiving only the pixels and the game score as inputs, was able to surpass the performance of all previous algorithms and achieve a level comparable to that of a professional human games tester across a set of 49 games, using the same algorithm, network architecture and hyperparameters. This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks."
            },
            "slug": "Human-level-control-through-deep-reinforcement-Mnih-Kavukcuoglu",
            "title": {
                "fragments": [],
                "text": "Human-level control through deep reinforcement learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work bridges the divide between high-dimensional sensory inputs and actions, resulting in the first artificial agent that is capable of learning to excel at a diverse array of challenging tasks."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39263338"
                        ],
                        "name": "Longxin Lin",
                        "slug": "Longxin-Lin",
                        "structuredName": {
                            "firstName": "Longxin",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Longxin Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 134
                            }
                        ],
                        "text": "The Q-value update is applied to the transitions in temporally reversed order, which has been shown to speed up Q-values convergence (Lin, 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 91
                            }
                        ],
                        "text": "We expedite the learning process through repeated memory sampling using experience replay (Lin, 1993)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 98
                            }
                        ],
                        "text": "Finally, when the state space is large or exploration is costly, the experience replay technique (Lin, 1993) has proved useful in experimental settings (Adam et al., 2012; Mnih et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60875658,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54c4cf3a8168c1b70f91cf78a3dc98b671935492",
            "isKey": false,
            "numCitedBy": 909,
            "numCiting": 71,
            "paperAbstract": {
                "fragments": [],
                "text": "Reinforcement learning agents are adaptive, reactive, and self-supervised. The aim of this dissertation is to extend the state of the art of reinforcement learning and enable its applications to complex robot-learning problems. In particular, it focuses on two issues. First, learning from sparse and delayed reinforcement signals is hard and in general a slow process. Techniques for reducing learning time must be devised. Second, most existing reinforcement learning methods assume that the world is a Markov decision process. This assumption is too strong for many robot tasks of interest. \nThis dissertation demonstrates how we can possibly overcome the slow learning problem and tackle non-Markovian environments, making reinforcement learning more practical for realistic robot tasks: (1) Reinforcement learning can be naturally integrated with artificial neural networks to obtain high-quality generalization, resulting in a significant learning speedup. Neural networks are used in this dissertation, and they generalize effectively even in the presence of noise and a large of binary and real-valued inputs. (2) Reinforcement learning agents can save many learning trials by using an action model, which can be learned on-line. With a model, an agent can mentally experience the effects of its actions without actually executing them. Experience replay is a simple technique that implements this idea, and is shown to be effective in reducing the number of action executions required. (3) Reinforcement learning agents can take advantage of instructive training instances provided by human teachers, resulting in a significant learning speedup. Teaching can also help learning agents avoid local optima during the search for optimal control. Simulation experiments indicate that even a small amount of teaching can save agents many learning trials. (4) Reinforcement learning agents can significantly reduce learning time by hierarchical learning--they first solve elementary learning problems and then combine solutions to the elementary problems to solve a complex problem. Simulation experiments indicate that a robot with hierarchical learning can solve a complex problem, which otherwise is hardly solvable within a reasonable time. (5) Reinforcement learning agents can deal with a wide range of non-Markovian environments by having a memory of their past. Three memory architectures are discussed. They work reasonably well for a variety of simple problems. One of them is also successfully applied to a nontrivial non-Markovian robot task. \nThe results of this dissertation rely on computer simulation, including (1) an agent operating in a dynamic and hostile environment and (2) a mobile robot operating in a noisy and non-Markovian environment. The robot simulator is physically realistic. This dissertation concludes that it is possible to build artificial agents than can acquire complex control policies effectively by reinforcement learning."
            },
            "slug": "Reinforcement-learning-for-robots-using-neural-Lin",
            "title": {
                "fragments": [],
                "text": "Reinforcement learning for robots using neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This dissertation concludes that it is possible to build artificial agents than can acquire complex control policies effectively by reinforcement learning and enable its applications to complex robot-learning problems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069136633"
                        ],
                        "name": "Adriana Romero",
                        "slug": "Adriana-Romero",
                        "structuredName": {
                            "firstName": "Adriana",
                            "lastName": "Romero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adriana Romero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2482072"
                        ],
                        "name": "Nicolas Ballas",
                        "slug": "Nicolas-Ballas",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Ballas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Ballas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127597"
                        ],
                        "name": "S. Kahou",
                        "slug": "S.-Kahou",
                        "structuredName": {
                            "firstName": "Samira",
                            "lastName": "Kahou",
                            "middleNames": [
                                "Ebrahimi"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kahou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3186079"
                        ],
                        "name": "Antoine Chassang",
                        "slug": "Antoine-Chassang",
                        "structuredName": {
                            "firstName": "Antoine",
                            "lastName": "Chassang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antoine Chassang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143706039"
                        ],
                        "name": "C. Gatta",
                        "slug": "C.-Gatta",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "Gatta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Gatta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2723173,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd85a549add0c7c7def36aca29837efd24b24080",
            "isKey": false,
            "numCitedBy": 2037,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "While depth tends to improve network performances, it also makes gradient-based training more difficult since deeper networks tend to be more non-linear. The recently proposed knowledge distillation approach is aimed at obtaining small and fast-to-execute models, and it has shown that a student network could imitate the soft output of a larger teacher network or ensemble of networks. In this paper, we extend this idea to allow the training of a student that is deeper and thinner than the teacher, using not only the outputs but also the intermediate representations learned by the teacher as hints to improve the training process and final performance of the student. Because the student intermediate hidden layer will generally be smaller than the teacher's intermediate hidden layer, additional parameters are introduced to map the student hidden layer to the prediction of the teacher hidden layer. This allows one to train deeper students that can generalize better or run faster, a trade-off that is controlled by the chosen student capacity. For example, on CIFAR-10, a deep student network with almost 10.4 times less parameters outperforms a larger, state-of-the-art teacher network."
            },
            "slug": "FitNets:-Hints-for-Thin-Deep-Nets-Romero-Ballas",
            "title": {
                "fragments": [],
                "text": "FitNets: Hints for Thin Deep Nets"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper extends the idea of a student network that could imitate the soft output of a larger teacher network or ensemble of networks, using not only the outputs but also the intermediate representations learned by the teacher as hints to improve the training process and final performance of the student."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736651"
                        ],
                        "name": "S. Levine",
                        "slug": "S.-Levine",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Levine",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46881670"
                        ],
                        "name": "Chelsea Finn",
                        "slug": "Chelsea-Finn",
                        "structuredName": {
                            "firstName": "Chelsea",
                            "lastName": "Finn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chelsea Finn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689992"
                        ],
                        "name": "P. Abbeel",
                        "slug": "P.-Abbeel",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Abbeel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Abbeel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 225
                            }
                        ],
                        "text": "For instance, methods using CNNs to approximate theQ-learning utility function (Watkins, 1989) have been successful in game-playing agents (Mnih et al., 2015; Silver et al., 2016) and robotic control (Lillicrap et al., 2015; Levine et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7242892,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b6b8a1b80891c96c28cc6340267b58186157e536",
            "isKey": false,
            "numCitedBy": 2526,
            "numCiting": 104,
            "paperAbstract": {
                "fragments": [],
                "text": "Policy search methods can allow robots to learn control policies for a wide range of tasks, but practical applications of policy search often require hand-engineered components for perception, state estimation, and low-level control. In this paper, we aim to answer the following question: does training the perception and control systems jointly end-to-end provide better performance than training each component separately? To this end, we develop a method that can be used to learn policies that map raw image observations directly to torques at the robot's motors. The policies are represented by deep convolutional neural networks (CNNs) with 92,000 parameters, and are trained using a partially observed guided policy search method, which transforms policy search into supervised learning, with supervision provided by a simple trajectory-centric reinforcement learning method. We evaluate our method on a range of real-world manipulation tasks that require close coordination between vision and control, such as screwing a cap onto a bottle, and present simulated comparisons to a range of prior policy search methods."
            },
            "slug": "End-to-End-Training-of-Deep-Visuomotor-Policies-Levine-Finn",
            "title": {
                "fragments": [],
                "text": "End-to-End Training of Deep Visuomotor Policies"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper develops a method that can be used to learn policies that map raw image observations directly to torques at the robot's motors, trained using a partially observed guided policy search method, with supervision provided by a simple trajectory-centric reinforcement learning method."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3119801"
                        ],
                        "name": "Xavier Glorot",
                        "slug": "Xavier-Glorot",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Glorot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xavier Glorot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 57
                            }
                        ],
                        "text": "All weights were initialized with Xavier initialization (Glorot & Bengio, 2010)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5575601,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b71ac1e9fb49420d13e084ac67254a0bbd40f83f",
            "isKey": false,
            "numCitedBy": 12591,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Whereas before 2006 it appears that deep multilayer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future. We first observe the influence of the non-linear activations functions. We find that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we find that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We find that a new non-linearity that saturates less can often be beneficial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difficult when the singular values of the Jacobian associated with each layer are far from 1. Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence. 1 Deep Neural Networks Deep learning methods aim at learning feature hierarchies with features from higher levels of the hierarchy formed by the composition of lower level features. They include Appearing in Proceedings of the 13 International Conference on Artificial Intelligence and Statistics (AISTATS) 2010, Chia Laguna Resort, Sardinia, Italy. Volume 9 of JMLR: WC Weston et al., 2008). Much attention has recently been devoted to them (see (Bengio, 2009) for a review), because of their theoretical appeal, inspiration from biology and human cognition, and because of empirical success in vision (Ranzato et al., 2007; Larochelle et al., 2007; Vincent et al., 2008) and natural language processing (NLP) (Collobert & Weston, 2008; Mnih & Hinton, 2009). Theoretical results reviewed and discussed by Bengio (2009), suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g. in vision, language, and other AI-level tasks), one may need deep architectures. Most of the recent experimental results with deep architecture are obtained with models that can be turned into deep supervised neural networks, but with initialization or training schemes different from the classical feedforward neural networks (Rumelhart et al., 1986). Why are these new algorithms working so much better than the standard random initialization and gradient-based optimization of a supervised training criterion? Part of the answer may be found in recent analyses of the effect of unsupervised pretraining (Erhan et al., 2009), showing that it acts as a regularizer that initializes the parameters in a \u201cbetter\u201d basin of attraction of the optimization procedure, corresponding to an apparent local minimum associated with better generalization. But earlier work (Bengio et al., 2007) had shown that even a purely supervised but greedy layer-wise procedure would give better results. So here instead of focusing on what unsupervised pre-training or semi-supervised criteria bring to deep architectures, we focus on analyzing what may be going wrong with good old (but deep) multilayer neural networks. Our analysis is driven by investigative experiments to monitor activations (watching for saturation of hidden units) and gradients, across layers and across training iterations. We also evaluate the effects on these of choices of activation function (with the idea that it might affect saturation) and initialization procedure (since unsupervised pretraining is a particular form of initialization and it has a drastic impact)."
            },
            "slug": "Understanding-the-difficulty-of-training-deep-Glorot-Bengio",
            "title": {
                "fragments": [],
                "text": "Understanding the difficulty of training deep feedforward neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2120874"
                        ],
                        "name": "Tobias Domhan",
                        "slug": "Tobias-Domhan",
                        "structuredName": {
                            "firstName": "Tobias",
                            "lastName": "Domhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tobias Domhan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060551"
                        ],
                        "name": "Jost Tobias Springenberg",
                        "slug": "Jost-Tobias-Springenberg",
                        "structuredName": {
                            "firstName": "Jost",
                            "lastName": "Springenberg",
                            "middleNames": [
                                "Tobias"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jost Tobias Springenberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 139
                            }
                        ],
                        "text": "Bayesian optimization has also been used (Shahriari et al., 2016) for automatic selection of network architectures (Bergstra et al., 2013; Domhan et al., 2015) and hyperparameters (Snoek et al., 2012; Swersky et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 75
                            }
                        ],
                        "text": "While there has been some work (Pinto et al., 2009; Bergstra et al., 2013; Domhan et al., 2015) on automated or computer-aided neural network design, new CNN architectures or network design elements are still primarily developed by researchers using new theoretical insights or intuition gained from\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 369457,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "efb4431579a46d9cfa51b4ebbd4ddb9f44a30246",
            "isKey": false,
            "numCitedBy": 438,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep neural networks (DNNs) show very strong performance on many machine learning problems, but they are very sensitive to the setting of their hyperparameters. Automated hyperparameter optimization methods have recently been shown to yield settings competitive with those found by human experts, but their widespread adoption is hampered by the fact that they require more computational resources than human experts. Humans have one advantage: when they evaluate a poor hyperparameter setting they can quickly detect (after a few steps of stochastic gradient descent) that the resulting network performs poorly and terminate the corresponding evaluation to save time. In this paper, we mimic the early termination of bad runs using a probabilistic model that extrapolates the performance from the first part of a learning curve. Experiments with a broad range of neural network architectures on various prominent object recognition benchmarks show that our resulting approach speeds up state-of-the-art hyperparameter optimization methods for DNNs roughly twofold, enabling them to find DNN settings that yield better performance than those chosen by human experts."
            },
            "slug": "Speeding-Up-Automatic-Hyperparameter-Optimization-Domhan-Springenberg",
            "title": {
                "fragments": [],
                "text": "Speeding Up Automatic Hyperparameter Optimization of Deep Neural Networks by Extrapolation of Learning Curves"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This paper mimics the early termination of bad runs using a probabilistic model that extrapolates the performance from the first part of a learning curve, enabling state-of-the-art hyperparameter optimization methods for DNNs to find DNN settings that yield better performance than those chosen by human experts."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39978391"
                        ],
                        "name": "Yangqing Jia",
                        "slug": "Yangqing-Jia",
                        "structuredName": {
                            "firstName": "Yangqing",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yangqing Jia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782282"
                        ],
                        "name": "Evan Shelhamer",
                        "slug": "Evan-Shelhamer",
                        "structuredName": {
                            "firstName": "Evan",
                            "lastName": "Shelhamer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Evan Shelhamer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7408951"
                        ],
                        "name": "Jeff Donahue",
                        "slug": "Jeff-Donahue",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Donahue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeff Donahue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3049736"
                        ],
                        "name": "Sergey Karayev",
                        "slug": "Sergey-Karayev",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Karayev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sergey Karayev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117314646"
                        ],
                        "name": "Jonathan Long",
                        "slug": "Jonathan-Long",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Long",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Long"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2983898"
                        ],
                        "name": "Ross B. Girshick",
                        "slug": "Ross-B.-Girshick",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Girshick",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross B. Girshick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687120"
                        ],
                        "name": "S. Guadarrama",
                        "slug": "S.-Guadarrama",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Guadarrama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Guadarrama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 29
                            }
                        ],
                        "text": "Our experiments using Caffe (Jia et al., 2014) took 8-10 days to complete for each dataset with a hardware setup consisting of 10 NVIDIA GPUs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 16
                            }
                        ],
                        "text": "To download the Caffe solver and prototext files, please visit https://bowenbaker.github.io/metaqnn/ ."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1799558,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6bdb186ec4726e00a8051119636d4df3b94043b5",
            "isKey": false,
            "numCitedBy": 13814,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments. Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community of contributors on GitHub. It powers ongoing research projects, large-scale industrial applications, and startup prototypes in vision, speech, and multimedia."
            },
            "slug": "Caffe:-Convolutional-Architecture-for-Fast-Feature-Jia-Shelhamer",
            "title": {
                "fragments": [],
                "text": "Caffe: Convolutional Architecture for Fast Feature Embedding"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Multimedia"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771551"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3080683"
                        ],
                        "name": "Shaoqing Ren",
                        "slug": "Shaoqing-Ren",
                        "structuredName": {
                            "firstName": "Shaoqing",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoqing Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206594692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "isKey": false,
            "numCitedBy": 97653,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation."
            },
            "slug": "Deep-Residual-Learning-for-Image-Recognition-He-Zhang",
            "title": {
                "fragments": [],
                "text": "Deep Residual Learning for Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work presents a residual learning framework to ease the training of networks that are substantially deeper than those used previously, and provides comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145824029"
                        ],
                        "name": "David Silver",
                        "slug": "David-Silver",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Silver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Silver"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1885349"
                        ],
                        "name": "Aja Huang",
                        "slug": "Aja-Huang",
                        "structuredName": {
                            "firstName": "Aja",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aja Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2772217"
                        ],
                        "name": "Chris J. Maddison",
                        "slug": "Chris-J.-Maddison",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Maddison",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris J. Maddison"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35099444"
                        ],
                        "name": "A. Guez",
                        "slug": "A.-Guez",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Guez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Guez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2175946"
                        ],
                        "name": "L. Sifre",
                        "slug": "L.-Sifre",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Sifre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Sifre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47568983"
                        ],
                        "name": "George van den Driessche",
                        "slug": "George-van-den-Driessche",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Driessche",
                            "middleNames": [
                                "van",
                                "den"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George van den Driessche"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4337102"
                        ],
                        "name": "Julian Schrittwieser",
                        "slug": "Julian-Schrittwieser",
                        "structuredName": {
                            "firstName": "Julian",
                            "lastName": "Schrittwieser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julian Schrittwieser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2460849"
                        ],
                        "name": "Ioannis Antonoglou",
                        "slug": "Ioannis-Antonoglou",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Antonoglou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ioannis Antonoglou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2749418"
                        ],
                        "name": "Vedavyas Panneershelvam",
                        "slug": "Vedavyas-Panneershelvam",
                        "structuredName": {
                            "firstName": "Vedavyas",
                            "lastName": "Panneershelvam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vedavyas Panneershelvam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1975889"
                        ],
                        "name": "Marc Lanctot",
                        "slug": "Marc-Lanctot",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Lanctot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc Lanctot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48373216"
                        ],
                        "name": "S. Dieleman",
                        "slug": "S.-Dieleman",
                        "structuredName": {
                            "firstName": "Sander",
                            "lastName": "Dieleman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dieleman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2401609"
                        ],
                        "name": "Dominik Grewe",
                        "slug": "Dominik-Grewe",
                        "structuredName": {
                            "firstName": "Dominik",
                            "lastName": "Grewe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dominik Grewe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4111313"
                        ],
                        "name": "John Nham",
                        "slug": "John-Nham",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Nham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Nham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2583391"
                        ],
                        "name": "Nal Kalchbrenner",
                        "slug": "Nal-Kalchbrenner",
                        "structuredName": {
                            "firstName": "Nal",
                            "lastName": "Kalchbrenner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nal Kalchbrenner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2542999"
                        ],
                        "name": "T. Lillicrap",
                        "slug": "T.-Lillicrap",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Lillicrap",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lillicrap"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40662181"
                        ],
                        "name": "M. Leach",
                        "slug": "M.-Leach",
                        "structuredName": {
                            "firstName": "Madeleine",
                            "lastName": "Leach",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Leach"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686971"
                        ],
                        "name": "T. Graepel",
                        "slug": "T.-Graepel",
                        "structuredName": {
                            "firstName": "Thore",
                            "lastName": "Graepel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Graepel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48987704"
                        ],
                        "name": "D. Hassabis",
                        "slug": "D.-Hassabis",
                        "structuredName": {
                            "firstName": "Demis",
                            "lastName": "Hassabis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Hassabis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 159
                            }
                        ],
                        "text": "For instance, methods using CNNs to approximate theQ-learning utility function (Watkins, 1989) have been successful in game-playing agents (Mnih et al., 2015; Silver et al., 2016) and robotic control (Lillicrap et al., 2015; Levine et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 515925,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "846aedd869a00c09b40f1f1f35673cb22bc87490",
            "isKey": false,
            "numCitedBy": 11516,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses \u2018value networks\u2019 to evaluate board positions and \u2018policy networks\u2019 to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away."
            },
            "slug": "Mastering-the-game-of-Go-with-deep-neural-networks-Silver-Huang",
            "title": {
                "fragments": [],
                "text": "Mastering the game of Go with deep neural networks and tree search"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Using this search algorithm, the program AlphaGo achieved a 99.8% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0.5, the first time that a computer program has defeated a human professional player in the full-sized game of Go."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2542999"
                        ],
                        "name": "T. Lillicrap",
                        "slug": "T.-Lillicrap",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Lillicrap",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lillicrap"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2323922"
                        ],
                        "name": "Jonathan J. Hunt",
                        "slug": "Jonathan-J.-Hunt",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Hunt",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan J. Hunt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1863250"
                        ],
                        "name": "A. Pritzel",
                        "slug": "A.-Pritzel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Pritzel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pritzel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2801204"
                        ],
                        "name": "N. Heess",
                        "slug": "N.-Heess",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Heess",
                            "middleNames": [
                                "Manfred",
                                "Otto"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Heess"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1968210"
                        ],
                        "name": "T. Erez",
                        "slug": "T.-Erez",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Erez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Erez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109481"
                        ],
                        "name": "Yuval Tassa",
                        "slug": "Yuval-Tassa",
                        "structuredName": {
                            "firstName": "Yuval",
                            "lastName": "Tassa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuval Tassa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145824029"
                        ],
                        "name": "David Silver",
                        "slug": "David-Silver",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Silver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Silver"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688276"
                        ],
                        "name": "Daan Wierstra",
                        "slug": "Daan-Wierstra",
                        "structuredName": {
                            "firstName": "Daan",
                            "lastName": "Wierstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daan Wierstra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16326763,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "024006d4c2a89f7acacc6e4438d156525b60a98f",
            "isKey": false,
            "numCitedBy": 6727,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "We adapt the ideas underlying the success of Deep Q-Learning to the continuous action domain. We present an actor-critic, model-free algorithm based on the deterministic policy gradient that can operate over continuous action spaces. Using the same learning algorithm, network architecture and hyper-parameters, our algorithm robustly solves more than 20 simulated physics tasks, including classic problems such as cartpole swing-up, dexterous manipulation, legged locomotion and car driving. Our algorithm is able to find policies whose performance is competitive with those found by a planning algorithm with full access to the dynamics of the domain and its derivatives. We further demonstrate that for many of the tasks the algorithm can learn policies end-to-end: directly from raw pixel inputs."
            },
            "slug": "Continuous-control-with-deep-reinforcement-learning-Lillicrap-Hunt",
            "title": {
                "fragments": [],
                "text": "Continuous control with deep reinforcement learning"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "This work presents an actor-critic, model-free algorithm based on the deterministic policy gradient that can operate over continuous action spaces, and demonstrates that for many of the tasks the algorithm can learn policies end-to-end: directly from raw pixel inputs."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32837403"
                        ],
                        "name": "J. Bergstra",
                        "slug": "J.-Bergstra",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bergstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bergstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2103302"
                        ],
                        "name": "R. Bardenet",
                        "slug": "R.-Bardenet",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Bardenet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bardenet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143674326"
                        ],
                        "name": "B. K\u00e9gl",
                        "slug": "B.-K\u00e9gl",
                        "structuredName": {
                            "firstName": "Bal\u00e1zs",
                            "lastName": "K\u00e9gl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. K\u00e9gl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11688126,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "03911c85305d42aa2eeb02be82ef6fb7da644dd0",
            "isKey": false,
            "numCitedBy": 2516,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Several recent advances to the state of the art in image classification benchmarks have come from better configurations of existing techniques rather than novel approaches to feature learning. Traditionally, hyper-parameter optimization has been the job of humans because they can be very efficient in regimes where only a few trials are possible. Presently, computer clusters and GPU processors make it possible to run more trials and we show that algorithmic approaches can find better results. We present hyper-parameter optimization results on tasks of training neural networks and deep belief networks (DBNs). We optimize hyper-parameters using random search and two new greedy sequential methods based on the expected improvement criterion. Random search has been shown to be sufficiently efficient for learning neural networks for several datasets, but we show it is unreliable for training DBNs. The sequential algorithms are applied to the most difficult DBN learning problems from [1] and find significantly better results than the best previously reported. This work contributes novel techniques for making response surface models P(y|x) in which many elements of hyper-parameter assignment (x) are known to be irrelevant given particular values of other elements."
            },
            "slug": "Algorithms-for-Hyper-Parameter-Optimization-Bergstra-Bardenet",
            "title": {
                "fragments": [],
                "text": "Algorithms for Hyper-Parameter Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work contributes novel techniques for making response surface models P(y|x) in which many elements of hyper-parameter assignment (x) are known to be irrelevant given particular values of other elements."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46708564"
                        ],
                        "name": "S. Saxena",
                        "slug": "S.-Saxena",
                        "structuredName": {
                            "firstName": "Shreya",
                            "lastName": "Saxena",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Saxena"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34602236"
                        ],
                        "name": "Jakob Verbeek",
                        "slug": "Jakob-Verbeek",
                        "structuredName": {
                            "firstName": "Jakob",
                            "lastName": "Verbeek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jakob Verbeek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 438087,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "197c8988ef21d0b58d363c21bafe1900c3089e3e",
            "isKey": false,
            "numCitedBy": 193,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Despite the success of CNNs, selecting the optimal architecture for a given task remains an open problem. Instead of aiming to select a single optimal architecture, we propose a \"fabric\" that embeds an exponentially large number of architectures. The fabric consists of a 3D trellis that connects response maps at different layers, scales, and channels with a sparse homogeneous local connectivity pattern. The only hyper-parameters of a fabric are the number of channels and layers. While individual architectures can be recovered as paths, the fabric can in addition ensemble all embedded architectures together, sharing their weights where their paths overlap. Parameters can be learned using standard methods based on back-propagation, at a cost that scales linearly in the fabric size. We present benchmark results competitive with the state of the art for image classification on MNIST and CIFAR10, and for semantic segmentation on the Part Labels dataset."
            },
            "slug": "Convolutional-Neural-Fabrics-Saxena-Verbeek",
            "title": {
                "fragments": [],
                "text": "Convolutional Neural Fabrics"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A \"fabric\" that embeds an exponentially large number of architectures that is competitive with the state of the art for image classification on MNIST and CIFAR10, and for semantic segmentation on the Part Labels dataset."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3142556"
                        ],
                        "name": "Pierre Sermanet",
                        "slug": "Pierre-Sermanet",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Sermanet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierre Sermanet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2127604"
                        ],
                        "name": "Soumith Chintala",
                        "slug": "Soumith-Chintala",
                        "structuredName": {
                            "firstName": "Soumith",
                            "lastName": "Chintala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Soumith Chintala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 235,
                                "start": 208
                            }
                        ],
                        "text": "These layers generate N learnable linear transformations of the input data, which is similar in spirit to preprocessing of input data from RGB to a different color spaces such as YUV, as found in prior work (Sermanet et al., 2012; 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6788752,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9f7f9aba0a6a966ce04e29e401ea28f9eae82f02",
            "isKey": false,
            "numCitedBy": 458,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We classify digits of real-world house numbers using convolutional neural networks (ConvNets). Con-vNets are hierarchical feature learning neural networks whose structure is biologically inspired. Unlike many popular vision approaches that are hand-designed, ConvNets can automatically learn a unique set of features optimized for a given task. We augmented the traditional ConvNet architecture by learning multi-stage features and by using Lp pooling and establish a new state-of-the-art of 95.10% accuracy on the SVHN dataset (48% error improvement). Furthermore, we analyze the benefits of different pooling methods and multi-stage features in ConvNets. The source code and a tutorial are available at eblearn.sf.net."
            },
            "slug": "Convolutional-neural-networks-applied-to-house-Sermanet-Chintala",
            "title": {
                "fragments": [],
                "text": "Convolutional neural networks applied to house numbers digit classification"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work augmented the traditional ConvNet architecture by learning multi-stage features and by using Lp pooling and establishes a new state-of-the-art of 95.10% accuracy on the SVHN dataset (48% error improvement)."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1846883"
                        ],
                        "name": "Kenneth O. Stanley",
                        "slug": "Kenneth-O.-Stanley",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Stanley",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth O. Stanley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686788"
                        ],
                        "name": "R. Miikkulainen",
                        "slug": "R.-Miikkulainen",
                        "structuredName": {
                            "firstName": "Risto",
                            "lastName": "Miikkulainen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Miikkulainen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 498161,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "d03c916d49268d48fde3b76a68e64af7761835e7",
            "isKey": false,
            "numCitedBy": 2994,
            "numCiting": 90,
            "paperAbstract": {
                "fragments": [],
                "text": "An important question in neuroevolution is how to gain an advantage from evolving neural network topologies along with weights. We present a method, NeuroEvolution of Augmenting Topologies (NEAT), which outperforms the best fixed-topology method on a challenging benchmark reinforcement learning task. We claim that the increased efficiency is due to (1) employing a principled method of crossover of different topologies, (2) protecting structural innovation using speciation, and (3) incrementally growing from minimal structure. We test this claim through a series of ablation studies that demonstrate that each component is necessary to the system as a whole and to each other. What results is signicantly faster learning. NEAT is also an important contribution to GAs because it shows how it is possible for evolution to both optimize and complexify solutions simultaneously, offering the possibility of evolving increasingly complex solutions over generations, and strengthening the analogy with biological evolution."
            },
            "slug": "Evolving-Neural-Networks-through-Augmenting-Stanley-Miikkulainen",
            "title": {
                "fragments": [],
                "text": "Evolving Neural Networks through Augmenting Topologies"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A method is presented, NeuroEvolution of Augmenting Topologies (NEAT), which outperforms the best fixed-topology method on a challenging benchmark reinforcement learning task and shows how it is possible for evolution to both optimize and complexify solutions simultaneously."
            },
            "venue": {
                "fragments": [],
                "text": "Evolutionary Computation"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771551"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3080683"
                        ],
                        "name": "Shaoqing Ren",
                        "slug": "Shaoqing-Ren",
                        "structuredName": {
                            "firstName": "Shaoqing",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoqing Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "2 1.92 0.39 34.57 R-CNN (Liang &amp; Hu, 2015) 7.72 1.77 0.31 31.75 MetaQNN (ensemble) 7.32 2.06 0.32 - MetaQNN (top model) 6.92 2.28 0.44 27.14 Resnet(110) (He et al., 2015) 6.61 - - - Resnet(1001) (He et al., 2016) 4.62 - - 22.71 ELU (Clevert et al., 2015) 6.55 - - 24.28 Tree+Max-Avg (Lee et al., 2016) 6.05 1.69 0.31 32.37 Table 4: Error Rate Comparison with state-of-the-art methods with complex layer types. We"
                    },
                    "intents": []
                }
            ],
            "corpusId": 6447277,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "77f0a39b8e02686fd85b01971f8feb7f60971f80",
            "isKey": true,
            "numCitedBy": 6555,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep residual networks have emerged as a family of extremely deep architectures showing compelling accuracy and nice convergence behaviors. In this paper, we analyze the propagation formulations behind the residual building blocks, which suggest that the forward and backward signals can be directly propagated from one block to any other block, when using identity mappings as the skip connections and after-addition activation. A series of ablation experiments support the importance of these identity mappings. This motivates us to propose a new residual unit, which makes training easier and improves generalization. We report improved results using a 1001-layer ResNet on CIFAR-10 (4.62 % error) and CIFAR-100, and a 200-layer ResNet on ImageNet. Code is available at: https://github.com/KaimingHe/resnet-1k-layers."
            },
            "slug": "Identity-Mappings-in-Deep-Residual-Networks-He-Zhang",
            "title": {
                "fragments": [],
                "text": "Identity Mappings in Deep Residual Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The propagation formulations behind the residual building blocks suggest that the forward and backward signals can be directly propagated from one block to any other block, when using identity mappings as the skip connections and after-addition activation."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144108062"
                        ],
                        "name": "Jasper Snoek",
                        "slug": "Jasper-Snoek",
                        "structuredName": {
                            "firstName": "Jasper",
                            "lastName": "Snoek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jasper Snoek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777528"
                        ],
                        "name": "H. Larochelle",
                        "slug": "H.-Larochelle",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Larochelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Larochelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722180"
                        ],
                        "name": "Ryan P. Adams",
                        "slug": "Ryan-P.-Adams",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Adams",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan P. Adams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 181
                            }
                        ],
                        "text": "Bayesian optimization has also been used (Shahriari et al., 2016) for automatic selection of network architectures (Bergstra et al., 2013; Domhan et al., 2015) and hyperparameters (Snoek et al., 2012; Swersky et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 632197,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e2089ae76fe914706e6fa90081a79c8fe01611e",
            "isKey": false,
            "numCitedBy": 5088,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters. Unfortunately, this tuning is often a \"black art\" requiring expert experience, rules of thumb, or sometimes brute-force search. There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. In this work, we consider this problem through the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). We show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expertlevel performance. We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks."
            },
            "slug": "Practical-Bayesian-Optimization-of-Machine-Learning-Snoek-Larochelle",
            "title": {
                "fragments": [],
                "text": "Practical Bayesian Optimization of Machine Learning Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work describes new algorithms that take into account the variable cost of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation and shows that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34917892"
                        ],
                        "name": "Djork-Arn\u00e9 Clevert",
                        "slug": "Djork-Arn\u00e9-Clevert",
                        "structuredName": {
                            "firstName": "Djork-Arn\u00e9",
                            "lastName": "Clevert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Djork-Arn\u00e9 Clevert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2465270"
                        ],
                        "name": "Thomas Unterthiner",
                        "slug": "Thomas-Unterthiner",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Unterthiner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Unterthiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308557"
                        ],
                        "name": "S. Hochreiter",
                        "slug": "S.-Hochreiter",
                        "structuredName": {
                            "firstName": "Sepp",
                            "lastName": "Hochreiter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hochreiter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 134
                            }
                        ],
                        "text": "In addition, their performance is competitive against network designs that include complex layer types and training procedures (e.g., Clevert et al. (2015); Lee et al. (2016))."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 119
                            }
                        ],
                        "text": "Moreover, we can generate not just one, but several varied, well-performing network designs, which can be ensembled to further boost the prediction performance."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5273326,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f63e917638553414526a0cc8550de4ad2d83fe7a",
            "isKey": false,
            "numCitedBy": 3703,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce the \"exponential linear unit\" (ELU) which speeds up learning in deep neural networks and leads to higher classification accuracies. Like rectified linear units (ReLUs), leaky ReLUs (LReLUs) and parametrized ReLUs (PReLUs), ELUs alleviate the vanishing gradient problem via the identity for positive values. However, ELUs have improved learning characteristics compared to the units with other activation functions. In contrast to ReLUs, ELUs have negative values which allows them to push mean unit activations closer to zero like batch normalization but with lower computational complexity. Mean shifts toward zero speed up learning by bringing the normal gradient closer to the unit natural gradient because of a reduced bias shift effect. While LReLUs and PReLUs have negative values, too, they do not ensure a noise-robust deactivation state. ELUs saturate to a negative value with smaller inputs and thereby decrease the forward propagated variation and information. Therefore, ELUs code the degree of presence of particular phenomena in the input, while they do not quantitatively model the degree of their absence. In experiments, ELUs lead not only to faster learning, but also to significantly better generalization performance than ReLUs and LReLUs on networks with more than 5 layers. On CIFAR-100 ELUs networks significantly outperform ReLU networks with batch normalization while batch normalization does not improve ELU networks. ELU networks are among the top 10 reported CIFAR-10 results and yield the best published result on CIFAR-100, without resorting to multi-view evaluation or model averaging. On ImageNet, ELU networks considerably speed up learning compared to a ReLU network with the same architecture, obtaining less than 10% classification error for a single crop, single model network."
            },
            "slug": "Fast-and-Accurate-Deep-Network-Learning-by-Linear-Clevert-Unterthiner",
            "title": {
                "fragments": [],
                "text": "Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "The \"exponential linear unit\" (ELU) which speeds up learning in deep neural networks and leads to higher classification accuracies and significantly better generalization performance than ReLUs and LReLUs on networks with more than 5 layers."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39263338"
                        ],
                        "name": "Longxin Lin",
                        "slug": "Longxin-Lin",
                        "structuredName": {
                            "firstName": "Longxin",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Longxin Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 169
                            }
                        ],
                        "text": "In addition, when the exploration cost is large (which is true for our problem setting), it is beneficial to use the experience replay technique for faster convergence (Lin, 1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We incorporate these techniques\u2014Q-learning, the -greedy strategy and experience replay\u2014in our algorithm design."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3248358,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9cd8193a66cf53143cbba6ccb0c7b9c2ebf2452b",
            "isKey": false,
            "numCitedBy": 1012,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "To date, reinforcement learning has mostly been studied solving simple learning tasks. Reinforcement learning methods that have been studied so far typically converge slowly. The purpose of this work is thus two-fold: 1) to investigate the utility of reinforcement learning in solving much more complicated learning tasks than previously studied, and 2) to investigate methods that will speed up reinforcement learning.This paper compares eight reinforcement learning frameworks:adaptive heuristic critic (AHC) learning due to Sutton,Q-learning due to Watkins, and three extensions to both basic methods for speeding up learning. The three extensions are experience replay, learning action models for planning, and teaching. The frameworks were investigated using connectionism as an approach to generalization. To evaluate the performance of different frameworks, a dynamic environment was used as a testbed. The environment is moderately complex and nondeterministic. This paper describes these frameworks and algorithms in detail and presents empirical evaluation of the frameworks."
            },
            "slug": "Self-improving-reactive-agents-based-on-learning,-Lin",
            "title": {
                "fragments": [],
                "text": "Self-improving reactive agents based on reinforcement learning, planning and teaching"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper compares eight reinforcement learning frameworks: Adaptive heuristic critic (AHC) learning due to Sutton, Q-learning due to Watkins, and three extensions to both basic methods for speeding up learning and two extensions are experience replay, learning action models for planning, and teaching."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34838386"
                        ],
                        "name": "K. Simonyan",
                        "slug": "K.-Simonyan",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Simonyan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Simonyan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 59
                            }
                        ],
                        "text": "Transfer Learning Ability: Network designs such as VGGnet (Simonyan & Zisserman, 2014) can be adopted to solve a variety of computer vision problems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14124313,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb42cf88027de515750f230b23b1a057dc782108",
            "isKey": false,
            "numCitedBy": 63195,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision."
            },
            "slug": "Very-Deep-Convolutional-Networks-for-Large-Scale-Simonyan-Zisserman",
            "title": {
                "fragments": [],
                "text": "Very Deep Convolutional Networks for Large-Scale Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This work investigates the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting using an architecture with very small convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754860"
                        ],
                        "name": "Kevin Swersky",
                        "slug": "Kevin-Swersky",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Swersky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Swersky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144108062"
                        ],
                        "name": "Jasper Snoek",
                        "slug": "Jasper-Snoek",
                        "structuredName": {
                            "firstName": "Jasper",
                            "lastName": "Snoek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jasper Snoek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722180"
                        ],
                        "name": "Ryan P. Adams",
                        "slug": "Ryan-P.-Adams",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Adams",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan P. Adams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 201
                            }
                        ],
                        "text": "Bayesian optimization has also been used (Shahriari et al., 2016) for automatic selection of network architectures (Bergstra et al., 2013; Domhan et al., 2015) and hyperparameters (Snoek et al., 2012; Swersky et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1311677,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d08d5f5aa142d6c44336cbed286d6c40ca6f5bf0",
            "isKey": false,
            "numCitedBy": 526,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Bayesian optimization has recently been proposed as a framework for automatically tuning the hyperparameters of machine learning models and has been shown to yield state-of-the-art performance with impressive ease and efficiency. In this paper, we explore whether it is possible to transfer the knowledge gained from previous optimizations to new tasks in order to find optimal hyperparameter settings more efficiently. Our approach is based on extending multi-task Gaussian processes to the framework of Bayesian optimization. We show that this method significantly speeds up the optimization process when compared to the standard single-task approach. We further propose a straightforward extension of our algorithm in order to jointly minimize the average error across multiple tasks and demonstrate how this can be used to greatly speed up k-fold cross-validation. Lastly, we propose an adaptation of a recently developed acquisition function, entropy search, to the cost-sensitive, multi-task setting. We demonstrate the utility of this new acquisition function by leveraging a small dataset to explore hyper-parameter settings for a large dataset. Our algorithm dynamically chooses which dataset to query in order to yield the most information per unit cost."
            },
            "slug": "Multi-Task-Bayesian-Optimization-Swersky-Snoek",
            "title": {
                "fragments": [],
                "text": "Multi-Task Bayesian Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes an adaptation of a recently developed acquisition function, entropy search, to the cost-sensitive, multi-task setting and demonstrates the utility of this new acquisition function by leveraging a small dataset to explore hyper-parameter settings for a large dataset."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053671127"
                        ],
                        "name": "Li Wan",
                        "slug": "Li-Wan",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Wan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Wan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48799969"
                        ],
                        "name": "Matthew D. Zeiler",
                        "slug": "Matthew-D.-Zeiler",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Zeiler",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew D. Zeiler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33551113"
                        ],
                        "name": "Sixin Zhang",
                        "slug": "Sixin-Zhang",
                        "structuredName": {
                            "firstName": "Sixin",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sixin Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2936324,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "38f35dd624cd1cf827416e31ac5e0e0454028eca",
            "isKey": false,
            "numCitedBy": 2105,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce DropConnect, a generalization of Dropout (Hinton et al., 2012), for regularizing large fully-connected layers within neural networks. When training with Dropout, a randomly selected subset of activations are set to zero within each layer. DropConnect instead sets a randomly selected subset of weights within the network to zero. Each unit thus receives input from a random subset of units in the previous layer. We derive a bound on the generalization performance of both Dropout and DropConnect. We then evaluate DropConnect on a range of datasets, comparing to Dropout, and show state-of-the-art results on several image recognition benchmarks by aggregating multiple DropConnect-trained models."
            },
            "slug": "Regularization-of-Neural-Networks-using-DropConnect-Wan-Zeiler",
            "title": {
                "fragments": [],
                "text": "Regularization of Neural Networks using DropConnect"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This work introduces DropConnect, a generalization of Dropout, for regularizing large fully-connected layers within neural networks, and derives a bound on the generalization performance of both Dropout and DropConnect."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726807"
                        ],
                        "name": "Diederik P. Kingma",
                        "slug": "Diederik-P.-Kingma",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Kingma",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik P. Kingma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 73
                            }
                        ],
                        "text": "Each model was trained for a total of 20 epochs with the Adam optimizer (Kingma & Ba, 2014) with \u03b21 = 0.9, \u03b22 = 0.999, \u03b5 = 10\u22128."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6628106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "isKey": true,
            "numCitedBy": 91740,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm."
            },
            "slug": "Adam:-A-Method-for-Stochastic-Optimization-Kingma-Ba",
            "title": {
                "fragments": [],
                "text": "Adam: A Method for Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work introduces Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments, and provides a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153440022"
                        ],
                        "name": "Ian J. Goodfellow",
                        "slug": "Ian-J.-Goodfellow",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Goodfellow",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian J. Goodfellow"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1393680089"
                        ],
                        "name": "David Warde-Farley",
                        "slug": "David-Warde-Farley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Warde-Farley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Warde-Farley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153583218"
                        ],
                        "name": "Mehdi Mirza",
                        "slug": "Mehdi-Mirza",
                        "structuredName": {
                            "firstName": "Mehdi",
                            "lastName": "Mirza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mehdi Mirza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760871"
                        ],
                        "name": "Aaron C. Courville",
                        "slug": "Aaron-C.-Courville",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Courville",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron C. Courville"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": " phase with the labeled . As decreases, the average accuracy goes up, demonstrating that the agent learns to select better-performing CNN architectures. Method CIFAR-10 SVHN MNIST CIFAR-100 Maxout (Goodfellow et al., 2013) 9.38 2.47 0.45 38.57 NIN (Lin et al., 2013) 8.81 2.35 0.47 35.68 FitNet (Romero et al., 2014) 8.39 2.42 0.51 35.04 HighWay (Srivastava et al., 2015) 7.72 - - - VGGnet (Simonyan &amp; Zisserman, 2014)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10600578,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7b915d508987b73b61eccd2b237e7ed099a2d29",
            "isKey": true,
            "numCitedBy": 1834,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of designing models to leverage a recently introduced approximate model averaging technique called dropout. We define a simple new model called maxout (so named because its output is the max of a set of inputs, and because it is a natural companion to dropout) designed to both facilitate optimization by dropout and improve the accuracy of dropout's fast approximate model averaging technique. We empirically verify that the model successfully accomplishes both of these tasks. We use maxout and dropout to demonstrate state of the art classification performance on four benchmark datasets: MNIST, CIFAR-10, CIFAR-100, and SVHN."
            },
            "slug": "Maxout-Networks-Goodfellow-Warde-Farley",
            "title": {
                "fragments": [],
                "text": "Maxout Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A simple new model called maxout is defined designed to both facilitate optimization by dropout and improve the accuracy of dropout's fast approximate model averaging technique."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30017846"
                        ],
                        "name": "N. Pinto",
                        "slug": "N.-Pinto",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Pinto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Pinto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3250342"
                        ],
                        "name": "D. Doukhan",
                        "slug": "D.-Doukhan",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doukhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doukhan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1865831"
                        ],
                        "name": "J. DiCarlo",
                        "slug": "J.-DiCarlo",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "DiCarlo",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. DiCarlo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2042941"
                        ],
                        "name": "D. Cox",
                        "slug": "D.-Cox",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cox",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cox"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 32
                            }
                        ],
                        "text": "While there has been some work (Pinto et al., 2009; Bergstra et al., 2013; Domhan et al., 2015) on automated or computer-aided neural network design, new CNN architectures or network design elements are still primarily developed by researchers using new theoretical insights or intuition gained from\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 103
                            }
                        ],
                        "text": "Other biologically inspired ideas have also been explored; motivated by screening methods in genetics, Pinto et al. (2009) proposed a high-throughput network selection approach where they randomly sample thousands of architectures and choose promising ones for further training."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 215779860,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "d46fd54609e09bcd135fd28750003185a5ee4125",
            "isKey": false,
            "numCitedBy": 254,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "While many models of biological object recognition share a common set of \u201cbroad-stroke\u201d properties, the performance of any one model depends strongly on the choice of parameters in a particular instantiation of that model\u2014e.g., the number of units per layer, the size of pooling kernels, exponents in normalization operations, etc. Since the number of such parameters (explicit or implicit) is typically large and the computational cost of evaluating one particular parameter set is high, the space of possible model instantiations goes largely unexplored. Thus, when a model fails to approach the abilities of biological visual systems, we are left uncertain whether this failure is because we are missing a fundamental idea or because the correct \u201cparts\u201d have not been tuned correctly, assembled at sufficient scale, or provided with enough training. Here, we present a high-throughput approach to the exploration of such parameter sets, leveraging recent advances in stream processing hardware (high-end NVIDIA graphic cards and the PlayStation 3's IBM Cell Processor). In analogy to high-throughput screening approaches in molecular biology and genetics, we explored thousands of potential network architectures and parameter instantiations, screening those that show promising object recognition performance for further analysis. We show that this approach can yield significant, reproducible gains in performance across an array of basic object recognition tasks, consistently outperforming a variety of state-of-the-art purpose-built vision systems from the literature. As the scale of available computational power continues to expand, we argue that this approach has the potential to greatly accelerate progress in both artificial vision and our understanding of the computational underpinning of biological vision."
            },
            "slug": "A-High-Throughput-Screening-Approach-to-Discovering-Pinto-Doukhan",
            "title": {
                "fragments": [],
                "text": "A High-Throughput Screening Approach to Discovering Good Forms of Biologically Inspired Visual Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This approach can yield significant, reproducible gains in performance across an array of basic object recognition tasks, consistently outperforming a variety of state-of-the-art purpose-built vision systems from the literature."
            },
            "venue": {
                "fragments": [],
                "text": "PLoS Comput. Biol."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709512"
                        ],
                        "name": "L. Kaelbling",
                        "slug": "L.-Kaelbling",
                        "structuredName": {
                            "firstName": "Leslie",
                            "lastName": "Kaelbling",
                            "middleNames": [
                                "Pack"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Kaelbling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144885169"
                        ],
                        "name": "M. Littman",
                        "slug": "M.-Littman",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Littman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Littman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760402"
                        ],
                        "name": "A. Moore",
                        "slug": "A.-Moore",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Moore",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Moore"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1708582,
            "fieldsOfStudy": [
                "Psychology"
            ],
            "id": "12d1d070a53d4084d88a77b8b143bad51c40c38f",
            "isKey": false,
            "numCitedBy": 7412,
            "numCiting": 229,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper surveys the field of reinforcement learning from a computer-science perspective. It is written to be accessible to researchers familiar with machine learning. Both the historical basis of the field and a broad selection of current work are summarized. Reinforcement learning is the problem faced by an agent that learns behavior through trial-and-error interactions with a dynamic environment. The work described here has a resemblance to work in psychology, but differs considerably in the details and in the use of the word \"reinforcement.\" The paper discusses central issues of reinforcement learning, including trading off exploration and exploitation, establishing the foundations of the field via Markov decision theory, learning from delayed reinforcement, constructing empirical models to accelerate learning, making use of generalization and hierarchy, and coping with hidden state. It concludes with a survey of some implemented systems and an assessment of the practical utility of current methods for reinforcement learning."
            },
            "slug": "Reinforcement-Learning:-A-Survey-Kaelbling-Littman",
            "title": {
                "fragments": [],
                "text": "Reinforcement Learning: A Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Central issues of reinforcement learning are discussed, including trading off exploration and exploitation, establishing the foundations of the field via Markov decision theory, learning from delayed reinforcement, constructing empirical models to accelerate learning, making use of generalization and hierarchy, and coping with hidden state."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30402784"
                        ],
                        "name": "Sander Adam",
                        "slug": "Sander-Adam",
                        "structuredName": {
                            "firstName": "Sander",
                            "lastName": "Adam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sander Adam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709638"
                        ],
                        "name": "L. Bu\u015foniu",
                        "slug": "L.-Bu\u015foniu",
                        "structuredName": {
                            "firstName": "Lucian",
                            "lastName": "Bu\u015foniu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bu\u015foniu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1705222"
                        ],
                        "name": "Robert Babu\u0161ka",
                        "slug": "Robert-Babu\u0161ka",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Babu\u0161ka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Babu\u0161ka"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 153
                            }
                        ],
                        "text": "Finally, when the state space is large or exploration is costly, the experience replay technique (Lin, 1993) has proved useful in experimental settings (Adam et al., 2012; Mnih et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14302893,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b1d730ad00d877b5ac6a1abb720483945a1904fd",
            "isKey": false,
            "numCitedBy": 182,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Reinforcement-learning (RL) algorithms can automatically learn optimal control strategies for nonlinear, possibly stochastic systems. A promising approach for RL control is experience replay (ER), which learns quickly from a limited amount of data, by repeatedly presenting these data to an underlying RL algorithm. Despite its benefits, ER RL has been studied only sporadically in the literature, and its applications have largely been confined to simulated systems. Therefore, in this paper, we evaluate ER RL on real-time control experiments that involve a pendulum swing-up problem and the vision-based control of a goalkeeper robot. These real-time experiments are complemented by simulation studies and comparisons with traditional RL. As a preliminary, we develop a general ER framework that can be combined with essentially any incremental RL technique, and instantiate this framework for the approximate Q-learning and SARSA algorithms. The successful real-time learning results that are presented here are highly encouraging for the applicability of ER RL in practice."
            },
            "slug": "Experience-Replay-for-Real-Time-Reinforcement-Adam-Bu\u015foniu",
            "title": {
                "fragments": [],
                "text": "Experience Replay for Real-Time Reinforcement Learning Control"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper evaluates ER RL on real-time control experiments that involve a pendulum swing-up problem and the vision-based control of a goalkeeper robot, and develops a general ER framework that can be combined with essentially any incremental RL technique, and instantiate this framework for the approximate Q-learning and SARSA algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32837403"
                        ],
                        "name": "J. Bergstra",
                        "slug": "J.-Bergstra",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bergstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bergstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2292273"
                        ],
                        "name": "Daniel Yamins",
                        "slug": "Daniel-Yamins",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Yamins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Yamins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2042941"
                        ],
                        "name": "D. Cox",
                        "slug": "D.-Cox",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cox",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cox"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 133
                            }
                        ],
                        "text": "Finally, the MetaQNN selected models comfortably outperform previous automated network design methods (Stanley & Miikkulainen, 2002; Bergstra et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 52
                            }
                        ],
                        "text": "While there has been some work (Pinto et al., 2009; Bergstra et al., 2013; Domhan et al., 2015) on automated or computer-aided neural network design, new CNN architectures or network design elements are still primarily developed by researchers using new theoretical insights or intuition gained from\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Moreover, we can generate not just one, but several varied, well-performing network designs, which can be ensembled to further boost the prediction performance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 9
                            }
                        ],
                        "text": "Notably, Bergstra et al. (2013) proposed a meta-modeling approach based on Tree of Parzen Estimators (TPE) (Bergstra et al., 2011) to choose both the type of layers and hyperparameters of feed-forward networks; however, they fail to match the performance of handcrafted networks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 116
                            }
                        ],
                        "text": "Bayesian optimization has also been used (Shahriari et al., 2016) for automatic selection of network architectures (Bergstra et al., 2013; Domhan et al., 2015) and hyperparameters (Snoek et al., 2012; Swersky et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3356163,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29935173af73aef20336db72d608e0ef5b0e0c16",
            "isKey": true,
            "numCitedBy": 1286,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Many computer vision algorithms depend on configuration settings that are typically hand-tuned in the course of evaluating the algorithm for a particular data set. While such parameter tuning is often presented as being incidental to the algorithm, correctly setting these parameter choices is frequently critical to realizing a method's full potential. Compounding matters, these parameters often must be re-tuned when the algorithm is applied to a new problem domain, and the tuning process itself often depends on personal experience and intuition in ways that are hard to quantify or describe. Since the performance of a given technique depends on both the fundamental quality of the algorithm and the details of its tuning, it is sometimes difficult to know whether a given technique is genuinely better, or simply better tuned. \n \nIn this work, we propose a meta-modeling approach to support automated hyperparameter optimization, with the goal of providing practical tools that replace hand-tuning with a reproducible and unbiased optimization process. Our approach is to expose the underlying expression graph of how a performance metric (e.g. classification accuracy on validation examples) is computed from hyperparameters that govern not only how individual processing steps are applied, but even which processing steps are included. A hyperparameter optimization algorithm transforms this graph into a program for optimizing that performance metric. Our approach yields state of the art results on three disparate computer vision problems: a face-matching verification task (LFW), a face identification task (PubFig83) and an object recognition task (CIFAR-10), using a single broad class of feed-forward vision architectures."
            },
            "slug": "Making-a-Science-of-Model-Search:-Hyperparameter-in-Bergstra-Yamins",
            "title": {
                "fragments": [],
                "text": "Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes a meta-modeling approach to support automated hyperparameter optimization, with the goal of providing practical tools that replace hand-tuning with a reproducible and unbiased optimization process."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "12394626"
                        ],
                        "name": "Alan Mosca",
                        "slug": "Alan-Mosca",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Mosca",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alan Mosca"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732378"
                        ],
                        "name": "G. D. Magoulas",
                        "slug": "G.-D.-Magoulas",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Magoulas",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. D. Magoulas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9181205,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0edd4d2a71e92faf4b818722464d5917ce0e9308",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditional models for question answering optimize using cross entropy loss, which encourages exact answers at the cost of penalizing nearby or overlapping answers that are sometimes equally accurate. We propose a mixed objective that combines cross entropy loss with self-critical policy learning. The objective uses rewards derived from word overlap to solve the misalignment between evaluation metric and optimization objective. In addition to the mixed objective, we improve dynamic coattention networks (DCN) with a deep residual coattention encoder that is inspired by recent work in deep self-attention and residual networks. Our proposals improve model performance across question types and input lengths, especially for long questions that requires the ability to capture long-term dependencies. On the Stanford Question Answering Dataset, our model achieves state-of-the-art results with 75.1% exact match accuracy and 83.1% F1, while the ensemble obtains 78.9% exact match accuracy and 86.0% F1."
            },
            "slug": "Under-review-as-a-conference-paper-at-ICLR-2017-Mosca-Magoulas",
            "title": {
                "fragments": [],
                "text": "Under review as a conference paper at ICLR 2017"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes a mixed objective that combines cross entropy loss with self-critical policy learning, and improves dynamic coattention networks (DCN) with a deep residual coatt attention encoder that is inspired by recent work in deep self-attention and residual networks."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1425082935"
                        ],
                        "name": "Xinyun Chen",
                        "slug": "Xinyun-Chen",
                        "structuredName": {
                            "firstName": "Xinyun",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinyun Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17735339,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "94e3e7bc3d23276f0ee2d1cb8f9d14aa19668d5f",
            "isKey": false,
            "numCitedBy": 488,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "An intriguing property of deep neural networks is the existence of adversarial examples, which can transfer among different architectures. These transferable adversarial examples may severely hinder deep neural network-based applications. Previous works mostly study the transferability using small scale datasets. In this work, we are the first to conduct an extensive study of the transferability over large models and a large scale dataset, and we are also the first to study the transferability of targeted adversarial examples with their target labels. We study both non-targeted and targeted adversarial examples, and show that while transferable non-targeted adversarial examples are easy to find, targeted adversarial examples generated using existing approaches almost never transfer with their target labels. Therefore, we propose novel ensemble-based approaches to generating transferable adversarial examples. Using such approaches, we observe a large proportion of targeted adversarial examples that are able to transfer with their target labels for the first time. We also present some geometric studies to help understanding the transferable adversarial examples. Finally, we show that the adversarial examples generated using ensemble-based approaches can successfully attack Clarifai.com, which is a black-box image classification system."
            },
            "slug": "Under-Review-as-a-Conference-Paper-at-Iclr-2017-Ex-Chen",
            "title": {
                "fragments": [],
                "text": "Under Review as a Conference Paper at Iclr 2017 Delving into Transferable Adversarial Ex- Amples and Black-box Attacks"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This work is the first to conduct an extensive study of the transferability over large models and a large scale dataset, and it is also theFirst to study the transferabilities of targeted adversarial examples with their target labels."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3142556"
                        ],
                        "name": "Pierre Sermanet",
                        "slug": "Pierre-Sermanet",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Sermanet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierre Sermanet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2127604"
                        ],
                        "name": "Soumith Chintala",
                        "slug": "Soumith-Chintala",
                        "structuredName": {
                            "firstName": "Soumith",
                            "lastName": "Chintala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Soumith Chintala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1342687,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a1306ce652f556fbb9e794d91084a29294298e6d",
            "isKey": false,
            "numCitedBy": 778,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "Pedestrian detection is a problem of considerable practical interest. Adding to the list of successful applications of deep learning methods to vision, we report state-of-the-art and competitive results on all major pedestrian datasets with a convolutional network model. The model uses a few new twists, such as multi-stage features, connections that skip layers to integrate global shape information with local distinctive motif information, and an unsupervised method based on convolutional sparse coding to pre-train the filters at each stage."
            },
            "slug": "Pedestrian-Detection-with-Unsupervised-Multi-stage-Sermanet-Kavukcuoglu",
            "title": {
                "fragments": [],
                "text": "Pedestrian Detection with Unsupervised Multi-stage Feature Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This work reports state-of-the-art and competitive results on all major pedestrian datasets with a convolutional network model that uses a few new twists, such as multi-stage features, connections that skip layers to integrate global shape information with local distinctive motif information."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827709"
                        ],
                        "name": "Joann\u00e8s Vermorel",
                        "slug": "Joann\u00e8s-Vermorel",
                        "structuredName": {
                            "firstName": "Joann\u00e8s",
                            "lastName": "Vermorel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joann\u00e8s Vermorel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "81080659"
                        ],
                        "name": "M. Mohri",
                        "slug": "M.-Mohri",
                        "structuredName": {
                            "firstName": "Mehryar",
                            "lastName": "Mohri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mohri"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 131
                            }
                        ],
                        "text": "However, in the case of large or continuous state spaces, the -greedy strategy of learning has been empirically shown to converge (Vermorel & Mohri, 2005)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15607155,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e6b0cc6b13ed794cc21eed16c896c7c57eb754c",
            "isKey": false,
            "numCitedBy": 483,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The multi-armed bandit problem for a gambler is to decide which arm of a K-slot machine to pull to maximize his total reward in a series of trials. Many real-world learning and optimization problems can be modeled in this way. Several strategies or algorithms have been proposed as a solution to this problem in the last two decades, but, to our knowledge, there has been no common evaluation of these algorithms. \n \nThis paper provides a preliminary empirical evaluation of several multi-armed bandit algorithms. It also describes and analyzes a new algorithm, Poker (Price Of Knowledge and Estimated Reward) whose performance compares favorably to that of other existing algorithms in several experiments. One remarkable outcome of our experiments is that the most naive approach, the e-greedy strategy, proves to be often hard to beat."
            },
            "slug": "Multi-armed-Bandit-Algorithms-and-Empirical-Vermorel-Mohri",
            "title": {
                "fragments": [],
                "text": "Multi-armed Bandit Algorithms and Empirical Evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new algorithm is described and analyzed, Poker (Price Of Knowledge and Estimated Reward) whose performance compares favorably to that of other existing algorithms in several experiments and proves to be often hard to beat."
            },
            "venue": {
                "fragments": [],
                "text": "ECML"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145738991"
                        ],
                        "name": "J. D. Schaffer",
                        "slug": "J.-D.-Schaffer",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Schaffer",
                            "middleNames": [
                                "David"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. D. Schaffer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145285040"
                        ],
                        "name": "L. D. Whitley",
                        "slug": "L.-D.-Whitley",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Whitley",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. D. Whitley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3035326"
                        ],
                        "name": "L. Eshelman",
                        "slug": "L.-Eshelman",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Eshelman",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Eshelman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 202
                            }
                        ],
                        "text": "Designing neural network architectures: Research on automating neural network design goes back to the 1980s when genetic algorithm-based approaches were proposed to find both architectures and weights (Schaffer et al., 1992)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60670877,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "afdf48aaf69a520ed6d5b4a50189facc0ebf4e37",
            "isKey": false,
            "numCitedBy": 621,
            "numCiting": 150,
            "paperAbstract": {
                "fragments": [],
                "text": "Various schemes for combining genetic algorithms and neural networks have been proposed and tested in recent years, but the literature is scattered among a variety of journals, proceedings and technical reports. Activity in this area is clearly increasing. The authors provide an overview of this body of literature drawing out common themes and providing, where possible, the emerging wisdom about what seems to work and what does not.<<ETX>>"
            },
            "slug": "Combinations-of-genetic-algorithms-and-neural-a-of-Schaffer-Whitley",
            "title": {
                "fragments": [],
                "text": "Combinations of genetic algorithms and neural networks: a survey of the state of the art"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An overview of this body of literature drawing out common themes and providing, where possible, the emerging wisdom about what seems to work and what does not is provided."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] COGANN-92: International Workshop on Combinations of Genetic Algorithms and Neural Networks"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067577"
                        ],
                        "name": "Bobak Shahriari",
                        "slug": "Bobak-Shahriari",
                        "structuredName": {
                            "firstName": "Bobak",
                            "lastName": "Shahriari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bobak Shahriari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754860"
                        ],
                        "name": "Kevin Swersky",
                        "slug": "Kevin-Swersky",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Swersky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Swersky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117966548"
                        ],
                        "name": "Ziyun Wang",
                        "slug": "Ziyun-Wang",
                        "structuredName": {
                            "firstName": "Ziyun",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ziyun Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722180"
                        ],
                        "name": "Ryan P. Adams",
                        "slug": "Ryan-P.-Adams",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Adams",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan P. Adams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 42
                            }
                        ],
                        "text": "Bayesian optimization has also been used (Shahriari et al., 2016) for automatic selection of network architectures (Bergstra et al., 2013; Domhan et al., 2015) and hyperparameters (Snoek et al., 2012; Swersky et al., 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14843594,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0a2586e0a5f8bb4e35aa0763a6b8bca428af6bd2",
            "isKey": false,
            "numCitedBy": 2376,
            "numCiting": 197,
            "paperAbstract": {
                "fragments": [],
                "text": "Big Data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing and storage architectures. The construction of such systems involves many distributed design choices. The end products (e.g., recommendation systems, medical analysis tools, real-time game engines, speech recognizers) thus involve many tunable configuration parameters. These parameters are often specified and hard-coded into the software by various developers or teams. If optimized jointly, these parameters can result in significant improvements. Bayesian optimization is a powerful tool for the joint optimization of design choices that is gaining great popularity in recent years. It promises greater automation so as to increase both product quality and human productivity. This review paper introduces Bayesian optimization, highlights some of its methodological aspects, and showcases a wide range of applications."
            },
            "slug": "Taking-the-Human-Out-of-the-Loop:-A-Review-of-Shahriari-Swersky",
            "title": {
                "fragments": [],
                "text": "Taking the Human Out of the Loop: A Review of Bayesian Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This review paper introduces Bayesian optimization, highlights some of its methodological aspects, and showcases a wide range of applications."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8536286"
                        ],
                        "name": "A. Bosselut",
                        "slug": "A.-Bosselut",
                        "structuredName": {
                            "firstName": "Antoine",
                            "lastName": "Bosselut",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bosselut"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39455775"
                        ],
                        "name": "Omer Levy",
                        "slug": "Omer-Levy",
                        "structuredName": {
                            "firstName": "Omer",
                            "lastName": "Levy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Omer Levy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14487640"
                        ],
                        "name": "Ari Holtzman",
                        "slug": "Ari-Holtzman",
                        "structuredName": {
                            "firstName": "Ari",
                            "lastName": "Holtzman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ari Holtzman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40479850"
                        ],
                        "name": "C. Ennis",
                        "slug": "C.-Ennis",
                        "structuredName": {
                            "firstName": "Corin",
                            "lastName": "Ennis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Ennis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145197953"
                        ],
                        "name": "D. Fox",
                        "slug": "D.-Fox",
                        "structuredName": {
                            "firstName": "Dieter",
                            "lastName": "Fox",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Fox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699545"
                        ],
                        "name": "Yejin Choi",
                        "slug": "Yejin-Choi",
                        "structuredName": {
                            "firstName": "Yejin",
                            "lastName": "Choi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yejin Choi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 51540074,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bcd857d75841aa3e92cd4284a8818aba9f6c0c3f",
            "isKey": false,
            "numCitedBy": 156,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Understanding procedural language requires anticipating the causal effects of actions, even when they are not explicitly stated. In this work, we introduce Neural Process Networks to understand procedural text through (neural) simulation of action dynamics. Our model complements existing memory architectures with dynamic entity tracking by explicitly modeling actions as state transformers. The model updates the states of the entities by executing learned action operators. Empirical results demonstrate that our proposed model can reason about the unstated causal effects of actions, allowing it to provide more accurate contextual information for understanding and generating procedural text, all while offering more interpretable internal representations than existing alternatives."
            },
            "slug": "Published-as-a-conference-paper-at-ICLR-2018-S-A-D-Bosselut-Levy",
            "title": {
                "fragments": [],
                "text": "Published as a conference paper at ICLR 2018 S IMULATING A CTION D YNAMICS WITH N EURAL P ROCESS N ETWORKS"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work introduces Neural Process Networks to understand procedural text through (neural) simulation of action dynamics, and complements existing memory architectures with dynamic entity tracking by explicitly modeling actions as state transformers."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804676"
                        ],
                        "name": "B. Kr\u00f6se",
                        "slug": "B.-Kr\u00f6se",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Kr\u00f6se",
                            "middleNames": [
                                "J.",
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Kr\u00f6se"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 62
                            }
                        ],
                        "text": "(3)\nEquation 3 is the simplest form of Q-learning proposed by Watkins (1989)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 80
                            }
                        ],
                        "text": "For instance, methods using CNNs to approximate theQ-learning utility function (Watkins, 1989) have been successful in game-playing agents (Mnih et al., 2015; Silver et al., 2016) and robotic control (Lillicrap et al., 2015; Levine et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 40597581,
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "id": "59b50a775542e87f078db35b868ac10ab43d4c75",
            "isKey": false,
            "numCitedBy": 3520,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-from-delayed-rewards-Kr\u00f6se",
            "title": {
                "fragments": [],
                "text": "Learning from delayed rewards"
            },
            "venue": {
                "fragments": [],
                "text": "Robotics Auton. Syst."
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786249"
                        ],
                        "name": "D. Bertsekas",
                        "slug": "D.-Bertsekas",
                        "structuredName": {
                            "firstName": "Dimitri",
                            "lastName": "Bertsekas",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bertsekas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 118800102,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef6008a4385e21aabda61daf7c5a1c075c08c860",
            "isKey": false,
            "numCitedBy": 514,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "c 2015 Dimitri P. Bertsekas All rights reserved. No part of this book may be reproduced in any form by any electronic or mechanical means (including photocopying, recording, or information storage and retrieval) without permission in writing from the publisher."
            },
            "slug": "Convex-Optimization-Algorithms-Bertsekas",
            "title": {
                "fragments": [],
                "text": "Convex Optimization Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "This book aims to provide a history of Balkan literature from 1989 to the present day in the context of the conflicts of the 1990s and beyond."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113979381"
                        ],
                        "name": "Xing Hao",
                        "slug": "Xing-Hao",
                        "structuredName": {
                            "firstName": "Xing",
                            "lastName": "Hao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xing Hao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8273966"
                        ],
                        "name": "Guigang Zhang",
                        "slug": "Guigang-Zhang",
                        "structuredName": {
                            "firstName": "Guigang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guigang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118869556"
                        ],
                        "name": "Shang Ma",
                        "slug": "Shang-Ma",
                        "structuredName": {
                            "firstName": "Shang",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shang Ma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 131
                            }
                        ],
                        "text": "Deep convolutional neural networks (CNNs) have seen great success in the past few years on a variety of machine learning problems (LeCun et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 140
                            }
                        ],
                        "text": "We make this assumption based on the hierarchical nature of the feature representations learned by neural networks with many hidden layers (LeCun et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1779661,
            "fieldsOfStudy": [
                "Education"
            ],
            "id": "4f8d648c52edf74e41b0996128aa536e13cc7e82",
            "isKey": false,
            "numCitedBy": 31384,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Deep-Learning-Hao-Zhang",
            "title": {
                "fragments": [],
                "text": "Deep Learning"
            },
            "venue": {
                "fragments": [],
                "text": "Int. J. Semantic Comput."
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "SM(10)] 2.36 10"
            },
            "venue": {
                "fragments": [],
                "text": "SM(10)] 2.36 10"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "review as a conference paper at ICLR"
            },
            "venue": {
                "fragments": [],
                "text": "review as a conference paper at ICLR"
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 235,
                                "start": 208
                            }
                        ],
                        "text": "These layers generate N learnable linear transformations of the input data, which is similar in spirit to preprocessing of input data from RGB to a different color spaces such as YUV, as found in prior work (Sermanet et al., 2012; 2013)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Convolutional neural networks applied to house numbers digit classification. ICPR"
            },
            "venue": {
                "fragments": [],
                "text": "Convolutional neural networks applied to house numbers digit classification. ICPR"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Published as a conference paper at ICLR 2017 Model Architecture Test Error (%) # Params"
            },
            "venue": {
                "fragments": [],
                "text": "Published as a conference paper at ICLR 2017 Model Architecture Test Error (%) # Params"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maxout networks. ICML (3)"
            },
            "venue": {
                "fragments": [],
                "text": "Maxout networks. ICML (3)"
            },
            "year": 2013
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 15,
            "methodology": 18,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 47,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Designing-Neural-Network-Architectures-using-Baker-Gupta/6cd5dfccd9f52538b19a415e00031d0ee4e5b181?sort=total-citations"
}