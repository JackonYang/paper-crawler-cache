{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2388276"
                        ],
                        "name": "R. Gramacy",
                        "slug": "R.-Gramacy",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gramacy",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gramacy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48723705"
                        ],
                        "name": "Herbert K. H. Lee",
                        "slug": "Herbert-K.-H.-Lee",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Lee",
                            "middleNames": [
                                "K.",
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Herbert K. H. Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 0
                            }
                        ],
                        "text": "Gramacy and Lee [62] proposed the integrated expected conditional improvement (IECI) acquisition function:\n\u03b1IECI(x) = \u222b x\u2032 (\u03b1EI(x \u2032,Dn)\u2212 \u03b1EI(x\u2032,Dn \u222a x)|x))h(x\u2032)dx.\n(60)\nThis gives the change in expected improvement from observing x under the density h. Choosing h to model the probability of satisfying the constraint encourages IECI to favor regions with a high probability of being valid."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "Gramacy and Lee [62] proposed the integrated expected conditional improvement (IECI) acquisition function"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9957600,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d14c006bb1eccb2a543ebe339c7c9024a8018c0f",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Optimization of complex functions, such as the output of computer simulators, is a difficult task that has received much attention in the literature. A less studied problem is that of optimization under unknown constraints, i.e., when the simulator must be invoked both to determine the typical real-valued response and to determine if a constraint has been violated, either for physical or policy reasons. We develop a statistical approach based on Gaussian processes and Bayesian learning to both approximate the unknown function and estimate the probability of meeting the constraints. A new integrated improvement criterion is proposed to recognize that responses from inputs that violate the constraint may still be informative about the function, and thus could potentially be useful in the optimization. The new criterion is illustrated on synthetic data, and on a motivating optimization problem from health care policy."
            },
            "slug": "Optimization-Under-Unknown-Constraints-Gramacy-Lee",
            "title": {
                "fragments": [],
                "text": "Optimization Under Unknown Constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new integrated improvement criterion is proposed to recognize that responses from inputs that violate the constraint may still be informative about the function, and thus could potentially be useful in the optimization."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 174
                            }
                        ],
                        "text": "body of work devoted to extending the algorithm, particularly in adding constraints to the optimization problem [6], [23], [131], and in modeling noisy functions [14], [75], [76]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 64427497,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "08c4fdd974d874c87ea87faa6b404a7b8eb72c73",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 182,
            "paperAbstract": {
                "fragments": [],
                "text": "The best-performing algorithms for many hard problems are highly parameterized. Selecting the best heuristics and tuning their parameters for optimal overall performance is often a difficult, tedious, and unsatisfying task. This thesis studies the automation of this important part of algorithm design: the configuration of discrete algorithm components and their continuous parameters to construct an algorithm with desirable empirical performance characteristics. Automated configuration procedures can facilitate algorithm development and be applied on the end user side to optimize performance for new instance types and optimization objectives. The use of such procedures separates high-level cognitive tasks carried out by humans from tedious low-level tasks that can be left to machines. We introduce two alternative algorithm configuration frameworks: iterated local search in parameter configuration space and sequential optimization based on response surface models. To the best of our knowledge, our local search approach is the first that goes beyond local optima. Our model-based search techniques significantly outperform existing techniques and extend them in ways crucial for general algorithm configuration: they can handle categorical parameters, optimization objectives defined across multiple instances, and tens of thousands of data points. We study how many runs to perform for evaluating a parameter configuration and how to set the cutoff time, after which algorithm runs are terminated unsuccessfully. We introduce data-driven approaches for making these choices adaptively, most notably the first general method for adaptively setting the cutoff time. Using our procedures\u2014to the best of our knowledge still the only ones applicable to these complex configuration tasks\u2014we configured state-of-the-art tree search and local search algorithms for SAT, as well as CPLEX, the most widely-used commercial optimization tool for solving mixed integer programs (MIP). In many cases, we achieved improvements of orders of magnitude over the algorithm default, thereby substantially improving the state of the art in solving a broad range of problems, including industrially relevant instances of SAT and MIP. Based on these results, we believe that automated algorithm configuration procedures, such as ours, will play an increasingly crucial role in the design of high-performance algorithms and will be widely used in academia and industry."
            },
            "slug": "Automated-configuration-of-algorithms-for-solving-Hutter",
            "title": {
                "fragments": [],
                "text": "Automated configuration of algorithms for solving hard computational problems"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This thesis studies the automation of this important part of algorithm design: the configuration of discrete algorithm components and their continuous parameters to construct an algorithm with desirable empirical performance characteristics and introduces data-driven approaches for making these choices adaptively."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32837403"
                        ],
                        "name": "J. Bergstra",
                        "slug": "J.-Bergstra",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bergstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bergstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2292273"
                        ],
                        "name": "Daniel Yamins",
                        "slug": "Daniel-Yamins",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Yamins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Yamins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2042941"
                        ],
                        "name": "D. Cox",
                        "slug": "D.-Cox",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cox",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cox"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 192
                            }
                        ],
                        "text": "This greatly extends the capabilities of the Bayesian optimization framework, allowing it to chain together individual algorithms to form sophisticated pipelines that can be jointly optimized [19], [151]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3356163,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29935173af73aef20336db72d608e0ef5b0e0c16",
            "isKey": false,
            "numCitedBy": 1286,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Many computer vision algorithms depend on configuration settings that are typically hand-tuned in the course of evaluating the algorithm for a particular data set. While such parameter tuning is often presented as being incidental to the algorithm, correctly setting these parameter choices is frequently critical to realizing a method's full potential. Compounding matters, these parameters often must be re-tuned when the algorithm is applied to a new problem domain, and the tuning process itself often depends on personal experience and intuition in ways that are hard to quantify or describe. Since the performance of a given technique depends on both the fundamental quality of the algorithm and the details of its tuning, it is sometimes difficult to know whether a given technique is genuinely better, or simply better tuned. \n \nIn this work, we propose a meta-modeling approach to support automated hyperparameter optimization, with the goal of providing practical tools that replace hand-tuning with a reproducible and unbiased optimization process. Our approach is to expose the underlying expression graph of how a performance metric (e.g. classification accuracy on validation examples) is computed from hyperparameters that govern not only how individual processing steps are applied, but even which processing steps are included. A hyperparameter optimization algorithm transforms this graph into a program for optimizing that performance metric. Our approach yields state of the art results on three disparate computer vision problems: a face-matching verification task (LFW), a face identification task (PubFig83) and an object recognition task (CIFAR-10), using a single broad class of feed-forward vision architectures."
            },
            "slug": "Making-a-Science-of-Model-Search:-Hyperparameter-in-Bergstra-Yamins",
            "title": {
                "fragments": [],
                "text": "Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes a meta-modeling approach to support automated hyperparameter optimization, with the goal of providing practical tools that replace hand-tuning with a reproducible and unbiased optimization process."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144108062"
                        ],
                        "name": "Jasper Snoek",
                        "slug": "Jasper-Snoek",
                        "structuredName": {
                            "firstName": "Jasper",
                            "lastName": "Snoek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jasper Snoek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777528"
                        ],
                        "name": "H. Larochelle",
                        "slug": "H.-Larochelle",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Larochelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Larochelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722180"
                        ],
                        "name": "Ryan P. Adams",
                        "slug": "Ryan-P.-Adams",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Adams",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan P. Adams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 17
                            }
                        ],
                        "text": "In this section, we discuss a parametric approach that captures dependence between the arms via a linear model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 632197,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e2089ae76fe914706e6fa90081a79c8fe01611e",
            "isKey": false,
            "numCitedBy": 5088,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters. Unfortunately, this tuning is often a \"black art\" requiring expert experience, rules of thumb, or sometimes brute-force search. There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. In this work, we consider this problem through the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). We show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expertlevel performance. We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks."
            },
            "slug": "Practical-Bayesian-Optimization-of-Machine-Learning-Snoek-Larochelle",
            "title": {
                "fragments": [],
                "text": "Practical Bayesian Optimization of Machine Learning Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work describes new algorithms that take into account the variable cost of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation and shows that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "28552618"
                        ],
                        "name": "M. Hoffman",
                        "slug": "M.-Hoffman",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hoffman",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hoffman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067577"
                        ],
                        "name": "Bobak Shahriari",
                        "slug": "Bobak-Shahriari",
                        "structuredName": {
                            "firstName": "Bobak",
                            "lastName": "Shahriari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bobak Shahriari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "In this section, we discuss a parametric approach that captures dependence between the arms via a linear model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2482948,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f06a88d506b52c6106624f1e6c0ea7ced2fb5e1",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of finding the maximizer of a nonlinear function that can only be evaluated, subject to noise, at a finite number of query locations. Further, we will assume that there is a constraint on the total number of permitted function evaluations. We introduce a Bayesian approach for this problem and show that it empirically outperforms both the existing frequentist counterpart and other Bayesian optimization methods. The Bayesian approach places emphasis on detailed modelling, including the modelling of correlations among the arms. As a result, it can perform well in situations where the number of arms is much larger than the number of allowed function evaluation, whereas the frequentist counterpart is inapplicable. This feature enables us to develop and deploy practical applications, such as automatic machine learning toolboxes. The paper presents comprehensive comparisons of the proposed approach with many Bayesian and bandit optimization techniques, the first comparison of many of these methods in the literature."
            },
            "slug": "On-correlation-and-budget-constraints-in-bandit-to-Hoffman-Shahriari",
            "title": {
                "fragments": [],
                "text": "On correlation and budget constraints in model-based bandit optimization with application to automatic machine learning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The paper presents comprehensive comparisons of the proposed approach with many Bayesian and bandit optimization techniques, the first comparison of many of these methods in the literature."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144108062"
                        ],
                        "name": "Jasper Snoek",
                        "slug": "Jasper-Snoek",
                        "structuredName": {
                            "firstName": "Jasper",
                            "lastName": "Snoek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jasper Snoek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757324"
                        ],
                        "name": "Oren Rippel",
                        "slug": "Oren-Rippel",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Rippel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Rippel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754860"
                        ],
                        "name": "Kevin Swersky",
                        "slug": "Kevin-Swersky",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Swersky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Swersky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3450996"
                        ],
                        "name": "Ryan Kiros",
                        "slug": "Ryan-Kiros",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Kiros",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan Kiros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143758120"
                        ],
                        "name": "N. Satish",
                        "slug": "N.-Satish",
                        "structuredName": {
                            "firstName": "Nadathur",
                            "lastName": "Satish",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Satish"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789372"
                        ],
                        "name": "N. Sundaram",
                        "slug": "N.-Sundaram",
                        "structuredName": {
                            "firstName": "Narayanan",
                            "lastName": "Sundaram",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sundaram"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8176660"
                        ],
                        "name": "Md. Mostofa Ali Patwary",
                        "slug": "Md.-Mostofa-Ali-Patwary",
                        "structuredName": {
                            "firstName": "Md.",
                            "lastName": "Patwary",
                            "middleNames": [
                                "Mostofa",
                                "Ali"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Md. Mostofa Ali Patwary"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764912"
                        ],
                        "name": "Prabhat",
                        "slug": "Prabhat",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Prabhat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Prabhat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722180"
                        ],
                        "name": "Ryan P. Adams",
                        "slug": "Ryan-P.-Adams",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Adams",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan P. Adams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12604141,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "93bc65d2842b8cc5f3cf72ebc5b8f75daeacea35",
            "isKey": false,
            "numCitedBy": 711,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "Bayesian optimization is an effective methodology for the global optimization of functions with expensive evaluations. It relies on querying a distribution over functions defined by a relatively cheap surrogate model. An accurate model for this distribution over functions is critical to the effectiveness of the approach, and is typically fit using Gaussian processes (GPs). However, since GPs scale cubically with the number of observations, it has been challenging to handle objectives whose optimization requires many evaluations, and as such, massively parallelizing the optimization. \n \nIn this work, we explore the use of neural networks as an alternative to GPs to model distributions over functions. We show that performing adaptive basis function regression with a neural network as the parametric form performs competitively with state-of-the-art GP-based approaches, but scales linearly with the number of data rather than cubically. This allows us to achieve a previously intractable degree of parallelism, which we apply to large scale hyperparameter optimization, rapidly finding competitive models on benchmark object recognition tasks using convolutional networks, and image caption generation using neural language models."
            },
            "slug": "Scalable-Bayesian-Optimization-Using-Deep-Neural-Snoek-Rippel",
            "title": {
                "fragments": [],
                "text": "Scalable Bayesian Optimization Using Deep Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work shows that performing adaptive basis function regression with a neural network as the parametric form performs competitively with state-of-the-art GP-based approaches, but scales linearly with the number of data rather than cubically, which allows for a previously intractable degree of parallelism."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117966548"
                        ],
                        "name": "Ziyun Wang",
                        "slug": "Ziyun-Wang",
                        "structuredName": {
                            "firstName": "Ziyun",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ziyun Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3355894"
                        ],
                        "name": "B. Shakibi",
                        "slug": "B.-Shakibi",
                        "structuredName": {
                            "firstName": "Babak",
                            "lastName": "Shakibi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Shakibi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107223896"
                        ],
                        "name": "L. Jin",
                        "slug": "L.-Jin",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Jin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 142
                            }
                        ],
                        "text": "This forms the basis of our likelihood model, in which the observations for arm a are drawn from a Gaussian distribution with mean xTaw and variance \u03c3\n2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 300634,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39174fc632574834c891bc7e9b5a4b2b68377f34",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Bayesian optimization is a powerful global optimization technique for expensive black-box functions. One of its shortcomings is that it requires auxiliary optimization of an acquisition function at each iteration. This auxiliary optimization can be costly and very hard to carry out in practice. Moreover, it creates serious theoretical concerns, as most of the convergence results assume that the exact optimum of the acquisition function can be found. In this paper, we introduce a new technique for efficient global optimization that combines Gaussian process confidence bounds and treed simultaneous optimistic optimization to eliminate the need for auxiliary optimization of acquisition functions. The experiments with global optimization benchmarks and a novel application to automatic information extraction demonstrate that the resulting technique is more efficient than the two approaches from which it draws inspiration. Unlike most theoretical analyses of Bayesian optimization with Gaussian processes, our finite-time convergence rate proofs do not require exact optimization of an acquisition function. That is, our approach eliminates the unsatisfactory assumption that a difficult, potentially NP-hard, problem has to be solved in order to obtain vanishing regret rates."
            },
            "slug": "Bayesian-Multi-Scale-Optimistic-Optimization-Wang-Shakibi",
            "title": {
                "fragments": [],
                "text": "Bayesian Multi-Scale Optimistic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This paper introduces a new technique for efficient global optimization that combines Gaussian process confidence bounds and treed simultaneous optimistic optimization to eliminate the need for auxiliary optimization of acquisition functions."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388404060"
                        ],
                        "name": "Kevin Leyton-Brown",
                        "slug": "Kevin-Leyton-Brown",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Leyton-Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Leyton-Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[80] proposed an approach based on GP-UCB where UCB is optimized using a range of n values, which produces a set of points that favor a range of exploration and exploitation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Even if the number of experiments required to reach the minimum does not change, parallel approaches can yield a substantial reduction in terms of wall-clock time [80], [143]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1807833,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a2a5cf65a6160669eea80997d6a2b996026d1eb",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "State-of-the-art algorithms for solving hard computational problems often expose many parameters whose settings critically affect empirical performance. Manually exploring the resulting combinatorial space of parameter settings is often tedious and unsatisfactory. Automated approaches for finding good parameter settings are becoming increasingly prominent and have recently lead to substantial improvements in the state of the art for solving a variety of computationally challenging problems. However, running such automated algorithm configuration procedures is typically very costly, involving many thousands of invocations of the algorithm to be configured. Here, we study the extent to which parallel computing can come to the rescue. We compare straightforward parallelization by multiple independent runs with a more sophisticated method of parallelizing the model-based configuration procedure SMAC. Empirical results for configuring the MIP solver CPLEX demonstrate that near-optimal speedups can be obtained with up to 16 parallel workers, and that 64 workers can still accomplish challenging configuration tasks that previously took 2 days in 1---2 hours. Overall, we show that our methods make effective use of large-scale parallel resources and thus substantially expand the practical applicability of algorithm configuration methods."
            },
            "slug": "Parallel-Algorithm-Configuration-Hutter-Hoos",
            "title": {
                "fragments": [],
                "text": "Parallel Algorithm Configuration"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Empirical results for configuring the MIP solver CPLEX demonstrate that near-optimal speedups can be obtained with up to 16 parallel workers, and that 64 workers can still accomplish challenging configuration tasks that previously took 2 days in 1---2 hours."
            },
            "venue": {
                "fragments": [],
                "text": "LION"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145228938"
                        ],
                        "name": "W. Welch",
                        "slug": "W.-Welch",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Welch",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Welch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815604"
                        ],
                        "name": "M. Schonlau",
                        "slug": "M.-Schonlau",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Schonlau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schonlau"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "(stochastic process analysis of computer experiments) [133]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[133] M."
                    },
                    "intents": []
                }
            ],
            "corpusId": 60822138,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e89ecae12b44191809befa31404bbc91bec395df",
            "isKey": false,
            "numCitedBy": 410,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "A complex mathematical model that produces output values from input values is now commonly called a computer model. This thesis considers the problem of finding the global optimum of the response with few function evaluations. A small number of function evaluations is desirable since the computer model is often expensive (time consuming) to evaluate. \nThe function to be optimized is modeled as a stochastic process from initial function evaluations. Points are sampled sequentially according to a criterion that combines promising prediction values with prediction uncertainty. Some graphical tools are given that allow early assessment about whether the modeling strategy will work well. The approach is generalized by introducing a parameter that controls how global versus local the search strategy is. Strategies to conduct the optimization in stages and for optimization subject to constraints on additional response variables are presented. \nSpecial consideration is given to the stopping criterion of the global optimization algorithm. The problem of achieving a tolerance on the global minimum can be represented by determining whether the first order statistic of N dependent variables is greater than a certain value. An algorithm is developed that quickly determines bounds on the probability of this event. \nA strategy to explore high-dimensional data informally through effect plots is presented. The interpretation of the plots is guided by pointwise standard errors of the effects which are developed. When used in the context of global optimization, the graphical analysis sheds light on the number and location of local optima."
            },
            "slug": "Computer-experiments-and-global-optimization-Welch-Schonlau",
            "title": {
                "fragments": [],
                "text": "Computer experiments and global optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This thesis considers the problem of finding the global optimum of the response with few function evaluations and presents strategies to conduct the optimization in stages and for optimization subject to constraints on additional response variables."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2582186"
                        ],
                        "name": "J. Azimi",
                        "slug": "J.-Azimi",
                        "structuredName": {
                            "firstName": "Javad",
                            "lastName": "Azimi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Azimi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143602278"
                        ],
                        "name": "A. Jalali",
                        "slug": "A.-Jalali",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Jalali",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Jalali"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694273"
                        ],
                        "name": "Xiaoli Z. Fern",
                        "slug": "Xiaoli-Z.-Fern",
                        "structuredName": {
                            "firstName": "Xiaoli",
                            "lastName": "Fern",
                            "middleNames": [
                                "Z."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoli Z. Fern"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 367,
                                "start": 363
                            }
                        ],
                        "text": "In academia, it is impacting a wide range of areas, including interactive user interfaces [26], robotics [101], [110], environmental monitoring [106], information extraction [157], combinatorial optimization [79], [158], automatic machine learning [16], [72], [143], [148], [151], sensor networks [55], [146], adaptive Monte Carlo (MC) [105], experimental design [11], and reinforcement learning [27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10458049,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea43add1837c0e074826ec8f18d0485e840639e7",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Bayesian Optimization aims at optimizing an unknown non-convex/concave function that is costly to evaluate. We are interested in application scenarios where concurrent function evaluations are possible. Under such a setting, BO could choose to either sequentially evaluate the function, one input at a time and wait for the output of the function before making the next selection, or evaluate the function at a batch of multiple inputs at once. These two different settings are commonly referred to as the sequential and batch settings of Bayesian Optimization. In general, the sequential setting leads to better optimization performance as each function evaluation is selected with more information, whereas the batch setting has an advantage in terms of the total experimental time (the number of iterations). In this work, our goal is to combine the strength of both settings. Specifically, we systematically analyze Bayesian optimization using Gaussian process as the posterior estimator and provide a hybrid algorithm that, based on the current state, dynamically switches between a sequential policy and a batch policy with variable batch sizes. We provide theoretical justification for our algorithm and present experimental results on eight benchmark BO problems. The results show that our method achieves substantial speedup (up to %78) compared to a pure sequential policy, without suffering any significant performance loss."
            },
            "slug": "Hybrid-Batch-Bayesian-Optimization-Azimi-Jalali",
            "title": {
                "fragments": [],
                "text": "Hybrid Batch Bayesian Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work systematically analyze Bayesian optimization using Gaussian process as the posterior estimator and provides a hybrid algorithm that, based on the current state, dynamically switches between a sequential policy and a batch policy with variable batch sizes."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2388276"
                        ],
                        "name": "R. Gramacy",
                        "slug": "R.-Gramacy",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gramacy",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gramacy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48723705"
                        ],
                        "name": "Herbert K. H. Lee",
                        "slug": "Herbert-K.-H.-Lee",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Lee",
                            "middleNames": [
                                "K.",
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Herbert K. H. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2957256"
                        ],
                        "name": "W. Macready",
                        "slug": "W.-Macready",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Macready",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Macready"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[63] proposed the treed GP model, which partitions the data and then applies a separate GP to each region."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8746722,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "320c39f8768ceff3da719623a2615b072ce682cc",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Computer experiments often require dense sweeps over input parameters to obtain a qualitative understanding of their response. Such sweeps can be prohibitively expensive, and are unnecessary in regions where the response is easy predicted; well-chosen designs could allow a mapping of the response with far fewer simulation runs. Thus, there is a need for computationally inexpensive surrogate models and an accompanying method for selecting small designs. We explore a general methodology for addressing this need that uses non-stationary Gaussian processes. Binary trees partition the input space to facilitate non-stationarity and a Bayesian interpretation provides an explicit measure of predictive uncertainty that can be used to guide sampling. Our methods are illustrated on several examples, including a motivating example involving computational fluid dynamics simulation of a NASA reentry vehicle."
            },
            "slug": "Parameter-space-exploration-with-Gaussian-process-Gramacy-Lee",
            "title": {
                "fragments": [],
                "text": "Parameter space exploration with Gaussian process trees"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A general methodology for addressing the need for computationally inexpensive surrogate models and an accompanying method for selecting small designs that uses non-stationary Gaussian processes is explored."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2120874"
                        ],
                        "name": "Tobias Domhan",
                        "slug": "Tobias-Domhan",
                        "structuredName": {
                            "firstName": "Tobias",
                            "lastName": "Domhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tobias Domhan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060551"
                        ],
                        "name": "Jost Tobias Springenberg",
                        "slug": "Jost-Tobias-Springenberg",
                        "structuredName": {
                            "firstName": "Jost",
                            "lastName": "Springenberg",
                            "middleNames": [
                                "Tobias"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jost Tobias Springenberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[47], [48] built a basis set manually based on previously collected training curves."
                    },
                    "intents": []
                }
            ],
            "corpusId": 369457,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "efb4431579a46d9cfa51b4ebbd4ddb9f44a30246",
            "isKey": false,
            "numCitedBy": 438,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep neural networks (DNNs) show very strong performance on many machine learning problems, but they are very sensitive to the setting of their hyperparameters. Automated hyperparameter optimization methods have recently been shown to yield settings competitive with those found by human experts, but their widespread adoption is hampered by the fact that they require more computational resources than human experts. Humans have one advantage: when they evaluate a poor hyperparameter setting they can quickly detect (after a few steps of stochastic gradient descent) that the resulting network performs poorly and terminate the corresponding evaluation to save time. In this paper, we mimic the early termination of bad runs using a probabilistic model that extrapolates the performance from the first part of a learning curve. Experiments with a broad range of neural network architectures on various prominent object recognition benchmarks show that our resulting approach speeds up state-of-the-art hyperparameter optimization methods for DNNs roughly twofold, enabling them to find DNN settings that yield better performance than those chosen by human experts."
            },
            "slug": "Speeding-Up-Automatic-Hyperparameter-Optimization-Domhan-Springenberg",
            "title": {
                "fragments": [],
                "text": "Speeding Up Automatic Hyperparameter Optimization of Deep Neural Networks by Extrapolation of Learning Curves"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This paper mimics the early termination of bad runs using a probabilistic model that extrapolates the performance from the first part of a learning curve, enabling state-of-the-art hyperparameter optimization methods for DNNs to find DNN settings that yield better performance than those chosen by human experts."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2760511"
                        ],
                        "name": "John-Alexander M. Assael",
                        "slug": "John-Alexander-M.-Assael",
                        "structuredName": {
                            "firstName": "John-Alexander",
                            "lastName": "Assael",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John-Alexander M. Assael"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117966548"
                        ],
                        "name": "Ziyun Wang",
                        "slug": "Ziyun-Wang",
                        "structuredName": {
                            "firstName": "Ziyun",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ziyun Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 50
                            }
                        ],
                        "text": "to handling heteroscedastic noise was proposed in [5] using a partitioning approach."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7989893,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9eafd854d54a71178d5a403a722ff01371c1bf92",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "Optimising black-box functions is important in many disciplines, such as tuning machine learning models, robotics, finance and mining exploration. Bayesian optimisation is a state-of-the-art technique for the global optimisation of black-box functions which are expensive to evaluate. At the core of this approach is a Gaussian process prior that captures our belief about the distribution over functions. However, in many cases a single Gaussian process is not flexible enough to capture non-stationarity in the objective function. Consequently, heteroscedasticity negatively affects performance of traditional Bayesian methods. In this paper, we propose a novel prior model with hierarchical parameter learning that tackles the problem of non-stationarity in Bayesian optimisation. Our results demonstrate substantial improvements in a wide range of applications, including automatic machine learning and mining exploration."
            },
            "slug": "Heteroscedastic-Treed-Bayesian-Optimisation-Assael-Wang",
            "title": {
                "fragments": [],
                "text": "Heteroscedastic Treed Bayesian Optimisation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes a novel prior model with hierarchical parameter learning that tackles the problem of non-stationarity in Bayesian optimisation and demonstrates substantial improvements in a wide range of applications, including automatic machine learning and mining exploration."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144180357"
                        ],
                        "name": "E. Brochu",
                        "slug": "E.-Brochu",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brochu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brochu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2221163"
                        ],
                        "name": "Vlad M. Cora",
                        "slug": "Vlad-M.-Cora",
                        "structuredName": {
                            "firstName": "Vlad",
                            "lastName": "Cora",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vlad M. Cora"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "Since w is an unobserved quantity, we treat it as a latent random variable with a prior distribution p(w), which captures our a priori beliefs about probable values for w before any data is observed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "This solver has 76 free parameters, which the designers must tune manually \u2013 an overwhelming number to deal with by hand."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1640103,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd5a26b89f0799db1cbc1dff5607cb6815739fe7",
            "isKey": false,
            "numCitedBy": 1765,
            "numCiting": 129,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a tutorial on Bayesian optimization, a method of finding the maximum of expensive cost functions. Bayesian optimization employs the Bayesian technique of setting a prior over the objective function and combining it with evidence to get a posterior function. This permits a utility-based selection of the next observation to make on the objective function, which must take into account both exploration (sampling from areas of high uncertainty) and exploitation (sampling areas likely to offer improvement over the current best observation). We also present two detailed extensions of Bayesian optimization, with experiments---active user modelling with preferences, and hierarchical reinforcement learning---and a discussion of the pros and cons of Bayesian optimization based on our experiences."
            },
            "slug": "A-Tutorial-on-Bayesian-Optimization-of-Expensive-to-Brochu-Cora",
            "title": {
                "fragments": [],
                "text": "A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "A tutorial on Bayesian optimization, a method of finding the maximum of expensive cost functions using the Bayesian technique of setting a prior over the objective function and combining it with evidence to get a posterior function."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2103302"
                        ],
                        "name": "R. Bardenet",
                        "slug": "R.-Bardenet",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Bardenet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bardenet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144184144"
                        ],
                        "name": "M. Brendel",
                        "slug": "M.-Brendel",
                        "structuredName": {
                            "firstName": "M\u00e1ty\u00e1s",
                            "lastName": "Brendel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brendel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143674326"
                        ],
                        "name": "B. K\u00e9gl",
                        "slug": "B.-K\u00e9gl",
                        "structuredName": {
                            "firstName": "Bal\u00e1zs",
                            "lastName": "K\u00e9gl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. K\u00e9gl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69343681"
                        ],
                        "name": "M. Sebag",
                        "slug": "M.-Sebag",
                        "structuredName": {
                            "firstName": "Mich\u00e8le",
                            "lastName": "Sebag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sebag"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 52
                            }
                        ],
                        "text": "property within the Bayesian optimization framework [12], [49], [79], [89], [148], [160]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[12] proposed an approach that learns a latent ranking function at each iteration using pairs of observations from within each task."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8791227,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea57e9e2d557fa6e944b69bbe4420ef61c122e4c",
            "isKey": false,
            "numCitedBy": 267,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Hyperparameter learning has traditionally been a manual task because of the limited number of trials. Today's computing infrastructures allow bigger evaluation budgets, thus opening the way for algorithmic approaches. Recently, surrogate-based optimization was successfully applied to hyperparameter learning for deep belief networks and to WEKA classifiers. The methods combined brute force computational power with model building about the behavior of the error function in the hyperparameter space, and they could significantly improve on manual hyperparameter tuning. What may make experienced practitioners even better at hyperparameter optimization is their ability to generalize across similar learning problems. In this paper, we propose a generic method to incorporate knowledge from previous experiments when simultaneously tuning a learning algorithm on new problems at hand. To this end, we combine surrogate-based ranking and optimization techniques for surrogate-based collaborative tuning (SCoT). We demonstrate SCoT in two experiments where it outperforms standard tuning techniques and single-problem surrogate-based optimization."
            },
            "slug": "Collaborative-hyperparameter-tuning-Bardenet-Brendel",
            "title": {
                "fragments": [],
                "text": "Collaborative hyperparameter tuning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A generic method to incorporate knowledge from previous experiments when simultaneously tuning a learning algorithm on new problems at hand is proposed and is demonstrated in two experiments where it outperforms standard tuning techniques and single-problem surrogate-based optimization."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "28552618"
                        ],
                        "name": "M. Hoffman",
                        "slug": "M.-Hoffman",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hoffman",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hoffman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144180357"
                        ],
                        "name": "E. Brochu",
                        "slug": "E.-Brochu",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brochu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brochu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[73] proposed the use of a portfolio containing multiple acquisition strategies."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8053165,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa068e347fe8fcec0b5c6497a9d3c7790dc46f56",
            "isKey": false,
            "numCitedBy": 204,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Bayesian optimization with Gaussian processes has become an increasingly popular tool in the machine learning community. It is efficient and can be used when very little is known about the objective function, making it popular in expensive black-box optimization scenarios. It uses Bayesian methods to sample the objective efficiently using an acquisition function which incorporates the model's estimate of the objective and the uncertainty at any given point. However, there are several different parameterized acquisition functions in the literature, and it is often unclear which one to use. Instead of using a single acquisition function, we adopt a portfolio of acquisition functions governed by an online multi-armed bandit strategy. We propose several portfolio strategies, the best of which we call GP-Hedge, and show that this method outperforms the best individual acquisition function. We also provide a theoretical bound on the algorithm's performance."
            },
            "slug": "Portfolio-Allocation-for-Bayesian-Optimization-Hoffman-Brochu",
            "title": {
                "fragments": [],
                "text": "Portfolio Allocation for Bayesian Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A portfolio of acquisition functions governed by an online multi-armed bandit strategy is proposed, the best of which is called GP-Hedge, and it is shown that this method outperforms the best individual acquisition function."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754860"
                        ],
                        "name": "Kevin Swersky",
                        "slug": "Kevin-Swersky",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Swersky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Swersky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144108062"
                        ],
                        "name": "Jasper Snoek",
                        "slug": "Jasper-Snoek",
                        "structuredName": {
                            "firstName": "Jasper",
                            "lastName": "Snoek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jasper Snoek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722180"
                        ],
                        "name": "Ryan P. Adams",
                        "slug": "Ryan-P.-Adams",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Adams",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan P. Adams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 24
                            }
                        ],
                        "text": "In this section, we discuss a parametric approach that captures dependence between the arms via a linear model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1311677,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d08d5f5aa142d6c44336cbed286d6c40ca6f5bf0",
            "isKey": false,
            "numCitedBy": 526,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Bayesian optimization has recently been proposed as a framework for automatically tuning the hyperparameters of machine learning models and has been shown to yield state-of-the-art performance with impressive ease and efficiency. In this paper, we explore whether it is possible to transfer the knowledge gained from previous optimizations to new tasks in order to find optimal hyperparameter settings more efficiently. Our approach is based on extending multi-task Gaussian processes to the framework of Bayesian optimization. We show that this method significantly speeds up the optimization process when compared to the standard single-task approach. We further propose a straightforward extension of our algorithm in order to jointly minimize the average error across multiple tasks and demonstrate how this can be used to greatly speed up k-fold cross-validation. Lastly, we propose an adaptation of a recently developed acquisition function, entropy search, to the cost-sensitive, multi-task setting. We demonstrate the utility of this new acquisition function by leveraging a small dataset to explore hyper-parameter settings for a large dataset. Our algorithm dynamically chooses which dataset to query in order to yield the most information per unit cost."
            },
            "slug": "Multi-Task-Bayesian-Optimization-Swersky-Snoek",
            "title": {
                "fragments": [],
                "text": "Multi-Task Bayesian Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes an adaptation of a recently developed acquisition function, entropy search, to the cost-sensitive, multi-task setting and demonstrates the utility of this new acquisition function by leveraging a small dataset to explore hyper-parameter settings for a large dataset."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117966548"
                        ],
                        "name": "Ziyun Wang",
                        "slug": "Ziyun-Wang",
                        "structuredName": {
                            "firstName": "Ziyun",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ziyun Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16957242,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "309d46e17ec29e88df4ecc41f284a5fa56a6d938",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Bayesian optimisation has gained great popularity as a tool for optimising the parameters of machine learning algorithms and models. Somewhat ironically, setting up the hyper-parameters of Bayesian optimisation methods is notoriously hard. While reasonable practical solutions have been advanced, they can often fail to find the best optima. Surprisingly, there is little theoretical analysis of this crucial problem in the literature. To address this, we derive a cumulative regret bound for Bayesian optimisation with Gaussian processes and unknown kernel hyper-parameters in the stochastic setting. The bound, which applies to the expected improvement acquisition function and sub-Gaussian observation noise, provides us with guidelines on how to design hyper-parameter estimation methods. A simple simulation demonstrates the importance of following these guidelines."
            },
            "slug": "Theoretical-Analysis-of-Bayesian-Optimisation-with-Wang-Freitas",
            "title": {
                "fragments": [],
                "text": "Theoretical Analysis of Bayesian Optimisation with Unknown Gaussian Process Hyper-Parameters"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A cumulative regret bound for Bayesian optimisation with Gaussian processes and unknown kernel hyper-parameters in the stochastic setting is derived, which applies to the expected improvement acquisition function and sub-Gaussian observation noise and provides guidelines on how to design hyper- parameters estimation methods."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2868444"
                        ],
                        "name": "Matthias Feurer",
                        "slug": "Matthias-Feurer",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Feurer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthias Feurer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060551"
                        ],
                        "name": "Jost Tobias Springenberg",
                        "slug": "Jost-Tobias-Springenberg",
                        "structuredName": {
                            "firstName": "Jost",
                            "lastName": "Springenberg",
                            "middleNames": [
                                "Tobias"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jost Tobias Springenberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "property within the Bayesian optimization framework [12], [49], [79], [89], [148], [160]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 119190,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9be7e7579fbec5d45e3e6ea1c4465258225a183d",
            "isKey": false,
            "numCitedBy": 325,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "\n \n Model selection and hyperparameter optimization is crucial in applying machine learning to a novel dataset. Recently, a subcommunity of machine learning has focused on solving this problem with Sequential Model-based Bayesian Optimization (SMBO), demonstrating substantial successes in many applications. However, for computationally expensive algorithms the overhead of hyperparameter optimization can still be prohibitive. In this paper we mimic a strategy human domain experts use: speed up optimization by starting from promising configurations that performed well on similar datasets. The resulting initialization technique integrates naturally into the generic SMBO framework and can be trivially applied to any SMBO method. To validate our approach, we perform extensive experiments with two established SMBO frameworks (Spearmint and SMAC) with complementary strengths; optimizing two machine learning frameworks on 57 datasets. Our initialization procedure yields mild improvements for low-dimensional hyperparameter optimization and substantially improves the state of the art for the more complex combined algorithm selection and hyperparameter optimization problem.\n \n"
            },
            "slug": "Initializing-Bayesian-Hyperparameter-Optimization-Feurer-Springenberg",
            "title": {
                "fragments": [],
                "text": "Initializing Bayesian Hyperparameter Optimization via Meta-Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper mimics a strategy human domain experts use: speed up optimization by starting from promising configurations that performed well on similar datasets, and substantially improves the state of the art for the more complex combined algorithm selection and hyperparameter optimization problem."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388574431"
                        ],
                        "name": "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato",
                        "slug": "Jos\u00e9-Miguel-Hern\u00e1ndez-Lobato",
                        "structuredName": {
                            "firstName": "Jos\u00e9 Miguel",
                            "lastName": "Hern\u00e1ndez-Lobato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33474456"
                        ],
                        "name": "M. Gelbart",
                        "slug": "M.-Gelbart",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Gelbart",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gelbart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3243579"
                        ],
                        "name": "Matthew W. Hoffman",
                        "slug": "Matthew-W.-Hoffman",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hoffman",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew W. Hoffman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722180"
                        ],
                        "name": "Ryan P. Adams",
                        "slug": "Ryan-P.-Adams",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Adams",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan P. Adams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744700"
                        ],
                        "name": "Zoubin Ghahramani",
                        "slug": "Zoubin-Ghahramani",
                        "structuredName": {
                            "firstName": "Zoubin",
                            "lastName": "Ghahramani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zoubin Ghahramani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[68] recently proposed a variation of the PES acquisition function to deal with the decoupled case, where the function and constraints can be evaluated independently."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9381435,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc2b95001c942f7431c28a7ddb4d43c68e060ba6",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Unknown constraints arise in many types of expensive black-box optimization problems. Several methods have been proposed recently for performing Bayesian optimization with constraints, based on the expected improvement (EI) heuristic. However, EI can lead to pathologies when used with constraints. For example, in the case of decoupled constraints--i.e., when one can independently evaluate the objective or the constraints--EI can encounter a pathology that prevents exploration. Additionally, computing EI requires a current best solution, which may not exist if none of the data collected so far satisfy the constraints. By contrast, informationbased approaches do not suffer from these failure modes. In this paper, we present a new information-based method called Predictive Entropy Search with Constraints (PESC). We analyze the performance of PESC and show that it compares favorably to EI-based approaches on synthetic and benchmark problems, as well as several real-world examples. We demonstrate that PESC is an effective algorithm that provides a promising direction towards a unified solution for constrained Bayesian optimization."
            },
            "slug": "Predictive-Entropy-Search-for-Bayesian-Optimization-Hern\u00e1ndez-Lobato-Gelbart",
            "title": {
                "fragments": [],
                "text": "Predictive Entropy Search for Bayesian Optimization with Unknown Constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents a new information-based method called Predictive Entropy Search with Constraints (PESC), and shows that it compares favorably to EI-based approaches on synthetic and benchmark problems, as well as several real-world examples."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144180357"
                        ],
                        "name": "E. Brochu",
                        "slug": "E.-Brochu",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brochu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brochu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2935553"
                        ],
                        "name": "Tyson Brochu",
                        "slug": "Tyson-Brochu",
                        "structuredName": {
                            "firstName": "Tyson",
                            "lastName": "Brochu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tyson Brochu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "With yi \u2208 {0, 1}, we denote the Bernoulli outcome of the treatment of patient i, and this has mean parameter f(ai) if the drug administered was ai."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8788234,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "122c45495b725e1c999c4f2a65c3a380631262d5",
            "isKey": false,
            "numCitedBy": 129,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "The computer graphics and animation fields are filled with applications that require the setting of tricky parameters. In many cases, the models are complex and the parameters unintuitive for non-experts. In this paper, we present an optimization method for setting parameters of a procedural fluid animation system by showing the user examples of different parametrized animations and asking for feedback. Our method employs the Bayesian technique of bringing in \"prior\" belief based on previous runs of the system and/or expert knowledge, to assist users in finding good parameter settings in as few steps as possible. To do this, we introduce novel extensions to Bayesian optimization, which permit effective learning for parameter-based procedural animation applications. We show that even when users are trying to find a variety of different target animations, the system can learn and improve. We demonstrate the effectiveness of our method compared to related active learning methods. We also present a working application for assisting animators in the challenging task of designing curl-based velocity fields, even with minimal domain knowledge other than identifying when a simulation \"looks right\"."
            },
            "slug": "A-Bayesian-interactive-optimization-approach-to-Brochu-Brochu",
            "title": {
                "fragments": [],
                "text": "A Bayesian interactive optimization approach to procedural animation design"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper presents an optimization method for setting parameters of a procedural fluid animation system by showing the user examples of different parametrized animations and asking for feedback, and introduces novel extensions to Bayesian optimization, which permit effective learning for parameter-based procedural animation applications."
            },
            "venue": {
                "fragments": [],
                "text": "SCA '10"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145343838"
                        ],
                        "name": "Andreas Krause",
                        "slug": "Andreas-Krause",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Krause",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Krause"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706780"
                        ],
                        "name": "Cheng Soon Ong",
                        "slug": "Cheng-Soon-Ong",
                        "structuredName": {
                            "firstName": "Cheng Soon",
                            "lastName": "Ong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cheng Soon Ong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 70
                            }
                        ],
                        "text": "property within the Bayesian optimization framework [12], [49], [79], [89], [148], [160]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "bandits [89]; Bayes regret bounds for TS [85], [127]; bounds for high-dimensional problems with an underlying low-rank structure [46]; bounds for parallel Bayesian optimization [45]; and improved regret bounds using mutual information [41]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2763630,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a1a51422cbdfc651d7726e8c613fc44f7fb4fc1",
            "isKey": false,
            "numCitedBy": 295,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "How should we design experiments to maximize performance of a complex system, taking into account uncontrollable environmental conditions? How should we select relevant documents (ads) to display, given information about the user? These tasks can be formalized as contextual bandit problems, where at each round, we receive context (about the experimental conditions, the query), and have to choose an action (parameters, documents). The key challenge is to trade off exploration by gathering data for estimating the mean payoff function over the context-action space, and to exploit by choosing an action deemed optimal based on the gathered data. We model the payoff function as a sample from a Gaussian process defined over the joint context-action space, and develop CGP-UCB, an intuitive upper-confidence style algorithm. We show that by mixing and matching kernels for contexts and actions, CGP-UCB can handle a variety of practical applications. We further provide generic tools for deriving regret bounds when using such composite kernel functions. Lastly, we evaluate our algorithm on two case studies, in the context of automated vaccine design and sensor management. We show that context-sensitive optimization outperforms no or naive use of context."
            },
            "slug": "Contextual-Gaussian-Process-Bandit-Optimization-Krause-Ong",
            "title": {
                "fragments": [],
                "text": "Contextual Gaussian Process Bandit Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work model the payoff function as a sample from a Gaussian process defined over the joint context-action space, and develops CGP-UCB, an intuitive upper-confidence style algorithm that shows that context-sensitive optimization outperforms no or naive use of context."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1393588417"
                        ],
                        "name": "T. Bartz-Beielstein",
                        "slug": "T.-Bartz-Beielstein",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Bartz-Beielstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Bartz-Beielstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2278193"
                        ],
                        "name": "C. Lasarczyk",
                        "slug": "C.-Lasarczyk",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Lasarczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lasarczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1950379"
                        ],
                        "name": "M. Preuss",
                        "slug": "M.-Preuss",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Preuss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Preuss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 162
                            }
                        ],
                        "text": "body of work devoted to extending the algorithm, particularly in adding constraints to the optimization problem [6], [23], [131], and in modeling noisy functions [14], [75], [76]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6815175,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a99e54554731bda87e72024bb58da8c902d9800",
            "isKey": false,
            "numCitedBy": 325,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "Sequential parameter optimization is a heuristic that combines classical and modern statistical techniques to improve the performance of search algorithms. To demonstrate its flexibility, three scenarios are discussed: (1) no experience how to choose the parameter setting of an algorithm is available, (2) a comparison with other algorithms is needed, and (3) an optimization algorithm has to be applied effectively and efficiently to a complex real-world optimization problem. Although sequential parameter optimization relies on enhanced statistical techniques such as design and analysis of computer experiments, it can be performed algorithmically and requires basically the specification of the relevant algorithm's parameters"
            },
            "slug": "Sequential-parameter-optimization-Bartz-Beielstein-Lasarczyk",
            "title": {
                "fragments": [],
                "text": "Sequential parameter optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "Although sequential parameter optimization relies on enhanced statistical techniques such as design and analysis of computer experiments, it can be performed algorithmically and requires basically the specification of the relevant algorithm's parameters."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Congress on Evolutionary Computation"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388404060"
                        ],
                        "name": "Kevin Leyton-Brown",
                        "slug": "Kevin-Leyton-Brown",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Leyton-Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Leyton-Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "3) Random Forests: Finally, as an alternative to GPs, random forest regression has been proposed as an expressive and flexible surrogate model in the context of sequential model-based algorithm configuration (SMAC) [79]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In a random forest model [27], [79], this is achieved by finer partitioning in regions of the space where the function changes rapidly, and more granular partitioning in regions where the function changes slowly."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "property within the Bayesian optimization framework [12], [49], [79], [89], [148], [160]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "proposed using the empirical variance in the predictions across trees in the ensemble [79]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[79] apply multistart local search."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "For example, when the function involves selecting between different algorithms as well as optimizing their hyperparameters, then certain sets of hyperparameters belonging to a given algorithm will be inactive if that algorithm is not selected [16], [79]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "algorithm configuration in [79] using a random forest model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In academia, it is impacting a wide range of areas, including interactive user interfaces [26], robotics [101], [110], environmental monitoring [106], information extraction [157], combinatorial optimization [79], [158], automatic machine learning [16], [72], [143], [148], [151], sensor networks [55], [146], adaptive Monte Carlo (MC) [105], experimental design [11], and reinforcement learning [27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6944647,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "728744423ff0fb7e327664ed4e6352a95bb6c893",
            "isKey": true,
            "numCitedBy": 2055,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "State-of-the-art algorithms for hard computational problems often expose many parameters that can be modified to improve empirical performance. However, manually exploring the resulting combinatorial space of parameter settings is tedious and tends to lead to unsatisfactory outcomes. Recently, automated approaches for solving this algorithm configuration problem have led to substantial improvements in the state of the art for solving various problems. One promising approach constructs explicit regression models to describe the dependence of target algorithm performance on parameter settings; however, this approach has so far been limited to the optimization of few numerical algorithm parameters on single instances. In this paper, we extend this paradigm for the first time to general algorithm configuration problems, allowing many categorical parameters and optimization for sets of instances. We experimentally validate our new algorithm configuration procedure by optimizing a local search and a tree search solver for the propositional satisfiability problem (SAT), as well as the commercial mixed integer programming (MIP) solver CPLEX. In these experiments, our procedure yielded state-of-the-art performance, and in many cases outperformed the previous best configuration approach."
            },
            "slug": "Sequential-Model-Based-Optimization-for-General-Hutter-Hoos",
            "title": {
                "fragments": [],
                "text": "Sequential Model-Based Optimization for General Algorithm Configuration"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper extends the explicit regression models paradigm for the first time to general algorithm configuration problems, allowing many categorical parameters and optimization for sets of instances, and yields state-of-the-art performance."
            },
            "venue": {
                "fragments": [],
                "text": "LION"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690162"
                        ],
                        "name": "D. Lizotte",
                        "slug": "D.-Lizotte",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lizotte",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lizotte"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 184
                            }
                        ],
                        "text": "Although this is the minimum requirement for Bayesian optimization, when gradients are available, they can be incorporated in the algorithm as well; see for example Sections 4.2.1 and 5.2.4 of [99]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 123325420,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "767256cacd1eeaaab0e1ecb158317389e0a9bf69",
            "isKey": true,
            "numCitedBy": 256,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Global optimization of non-convex functions over real vector spaces is a problem of widespread theoretical and practical interest. In the past fifty years, research in global optimization has produced many important approaches including Lipschitz optimization, simulated annealing, homotopy methods, genetic algorithms, and Bayesian response-surface methods. This work examines the last of these approaches. The Bayesian response-surface approach to global optimization maintains a posterior model of the function being optimized by combining a prior over functions with accumulating function evaluations. The model is then used to compute which point the method should acquire next in its search for the optimum of the function. Bayesian methods can be some of the most efficient approaches to optimization in terms of the number of function evaluations required, but they have significant drawbacks: Current approaches are needlessly data-inefficient, approximations to the Bayes-optimal acquisition criterion are poorly studied, and current approaches do not take advantage of the small-scale properties of differentiable functions near local optima. This work addresses each of these problems to make Bayesian methods more widely applicable."
            },
            "slug": "Practical-bayesian-optimization-Lizotte",
            "title": {
                "fragments": [],
                "text": "Practical bayesian optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work examines the last of the Bayesian response-surface approach to global optimization, which maintains a posterior model of the function being optimized by combining a prior over functions with accumulating function evaluations."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388404060"
                        ],
                        "name": "Kevin Leyton-Brown",
                        "slug": "Kevin-Leyton-Brown",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Leyton-Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Leyton-Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 320,
                                "start": 316
                            }
                        ],
                        "text": "Many researchers have noted that for certain classes of problems most dimensions do not change the objective function significantly; examples include hyperparameter optimization for neural networks and deep belief networks [17] and automatic configuration of state-of-the-art algorithms for solving NP-hard problems [77]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1130380,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "205172102afca365014b0ee9f470c94a00aff8c6",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Most state-of-the-art algorithms for large-scale optimization problems expose free parameters, giving rise to combinatorial spaces of possible configurations. Typically, these spaces are hard for humans to understand. In this work, we study a model-based approach for identifying a small set of both algorithm parameters and instance features that suffices for predicting empirical algorithm performance well. Our empirical analyses on a wide variety of hard combinatorial problem benchmarks spanning SAT, MIP, and TSP show that--for parameter configurations sampled uniformly at random--very good performance predictions can typically be obtained based on just two key parameters, and that similarly, few instance features and algorithm parameters suffice to predict the most salient algorithm performance characteristics in the combined configuration/feature space. We also use these models to identify settings of these key parameters that are predicted to achieve the best overall performance, both on average across instances and in an instance-specific way. This serves as a further way of evaluating model quality and also provides a tool for further understanding the parameter space. We provide software for carrying out this analysis on arbitrary problem domains and hope that it will help algorithm developers gain insights into the key parameters of their algorithms, the key features of their instances, and their interactions."
            },
            "slug": "Identifying-Key-Algorithm-Parameters-and-Instance-Hutter-Hoos",
            "title": {
                "fragments": [],
                "text": "Identifying Key Algorithm Parameters and Instance Features Using Forward Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work study's empirical analyses show that--for parameter configurations sampled uniformly at random--very good performance predictions can typically be obtained based on just two key parameters, and that similarly, few instance features and algorithm parameters suffice to predict the most salient algorithm performance characteristics in the combined configuration/feature space."
            },
            "venue": {
                "fragments": [],
                "text": "LION"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388574431"
                        ],
                        "name": "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato",
                        "slug": "Jos\u00e9-Miguel-Hern\u00e1ndez-Lobato",
                        "structuredName": {
                            "firstName": "Jos\u00e9 Miguel",
                            "lastName": "Hern\u00e1ndez-Lobato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3243579"
                        ],
                        "name": "Matthew W. Hoffman",
                        "slug": "Matthew-W.-Hoffman",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hoffman",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew W. Hoffman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744700"
                        ],
                        "name": "Zoubin Ghahramani",
                        "slug": "Zoubin-Ghahramani",
                        "structuredName": {
                            "firstName": "Zoubin",
                            "lastName": "Ghahramani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zoubin Ghahramani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1776111,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "19930c1c481daeba3118ac71aa52603472170024",
            "isKey": false,
            "numCitedBy": 449,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel information-theoretic approach for Bayesian optimization called Predictive Entropy Search (PES). At each iteration, PES selects the next evaluation point that maximizes the expected information gained with respect to the global maximum. PES codifies this intractable acquisition function in terms of the expected reduction in the differential entropy of the predictive distribution. This reformulation allows PES to obtain approximations that are both more accurate and efficient than other alternatives such as Entropy Search (ES). Furthermore, PES can easily perform a fully Bayesian treatment of the model hyperparameters while ES cannot. We evaluate PES in both synthetic and real-world applications, including optimization problems in machine learning, finance, biotechnology, and robotics. We show that the increased accuracy of PES leads to significant gains in optimization performance."
            },
            "slug": "Predictive-Entropy-Search-for-Efficient-Global-of-Hern\u00e1ndez-Lobato-Hoffman",
            "title": {
                "fragments": [],
                "text": "Predictive Entropy Search for Efficient Global Optimization of Black-box Functions"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work proposes a novel information-theoretic approach for Bayesian optimization called Predictive Entropy Search (PES), which codifies this intractable acquisition function in terms of the expected reduction in the differential entropy of the predictive distribution."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117966548"
                        ],
                        "name": "Ziyun Wang",
                        "slug": "Ziyun-Wang",
                        "structuredName": {
                            "firstName": "Ziyun",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ziyun Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36572609"
                        ],
                        "name": "M. Zoghi",
                        "slug": "M.-Zoghi",
                        "structuredName": {
                            "firstName": "Masrour",
                            "lastName": "Zoghi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Zoghi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072664138"
                        ],
                        "name": "David Matheson",
                        "slug": "David-Matheson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Matheson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Matheson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 89
                            }
                        ],
                        "text": "Our objective is to learn this function f : Rd 7\u2192 R for the purpose of choosing the best arm, and in the linear model we require f to be of the form fw(a) = xTaw, where the parameters w are now feature weights."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14136770,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "75a0a299e4bbcd1123e9000766ddaad13ec8ae10",
            "isKey": false,
            "numCitedBy": 271,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Bayesian optimization techniques have been successfully applied to robotics, planning, sensor placement, recommendation, advertising, intelligent user interfaces and automatic algorithm configuration. Despite these successes, the approach is restricted to problems of moderate dimension, and several workshops on Bayesian optimization have identified its scaling to high dimensions as one of the holy grails of the field. In this paper, we introduce a novel random embedding idea to attack this problem. The resulting Random EMbedding Bayesian Optimization (REMBO) algorithm is very simple and applies to domains with both categorical and continuous variables. The experiments demonstrate that REMBO can effectively solve high-dimensional problems, including automatic parameter configuration of a popular mixed integer linear programming solver."
            },
            "slug": "Bayesian-Optimization-in-High-Dimensions-via-Random-Wang-Zoghi",
            "title": {
                "fragments": [],
                "text": "Bayesian Optimization in High Dimensions via Random Embeddings"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel random embedding idea is introduced to attack high-dimensional Bayesian optimization problems, and the resulting Random EMbedding Bayesian Optimization (REMBO) algorithm is very simple and applies to domains with both categorical and continuous variables."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145974030"
                        ],
                        "name": "R. Garnett",
                        "slug": "R.-Garnett",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Garnett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Garnett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144484861"
                        ],
                        "name": "Michael A. Osborne",
                        "slug": "Michael-A.-Osborne",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Osborne",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael A. Osborne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145029236"
                        ],
                        "name": "S. Roberts",
                        "slug": "S.-Roberts",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Roberts",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roberts"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "The objective is to identify which arm of the bandit to pull, e.g., which drug to administer, which movie to recommend, or which advertisement to display."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12351251,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "6fc4c7a500a90bb23dbd33d3020338ea3f707019",
            "isKey": false,
            "numCitedBy": 134,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of selecting an optimal set of sensors, as determined, for example, by the predictive accuracy of the resulting sensor network. Given an underlying metric between pairs of set elements, we introduce a natural metric between sets of sensors for this task. Using this metric, we can construct covariance functions over sets, and thereby perform Gaussian process inference over a function whose domain is a power set. If the function has additional inputs, our covariances can be readily extended to incorporate them---allowing us to consider, for example, functions over both sets and time. These functions can then be optimized using Gaussian process global optimization (GPGO). We use the root mean squared error (RMSE) of the predictions made using a set of sensors at a particular time as an example of such a function to be optimized; the optimal point specifies the best choice of sensor locations. We demonstrate the resulting method by dynamically selecting the best subset of a given set of weather sensors for the prediction of the air temperature across the United Kingdom."
            },
            "slug": "Bayesian-optimization-for-sensor-set-selection-Garnett-Osborne",
            "title": {
                "fragments": [],
                "text": "Bayesian optimization for sensor set selection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A natural metric is introduced between sets of sensors that can be used to construct covariance functions over sets, and thereby perform Gaussian process inference over a function whose domain is a power set."
            },
            "venue": {
                "fragments": [],
                "text": "IPSN '10"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2125972"
                        ],
                        "name": "Thomas Desautels",
                        "slug": "Thomas-Desautels",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Desautels",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Desautels"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145343838"
                        ],
                        "name": "Andreas Krause",
                        "slug": "Andreas-Krause",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Krause",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Krause"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144751617"
                        ],
                        "name": "J. Burdick",
                        "slug": "J.-Burdick",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Burdick",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Burdick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 131
                            }
                        ],
                        "text": "Finally, there also exist variants of these algorithms for the contextual bandits [153] (see Section VIII-D) and parallel querying [45] (see Section V-E)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[45]; and improved regret bounds using mutual information [41]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 101
                            }
                        ],
                        "text": "Similar approaches are proposed in [58], [40] and a similar parallel extension to GP-UCB is proposed [45]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1262678,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a802bd3c0d63ee1e43f1e31633e90b399c1a789",
            "isKey": false,
            "numCitedBy": 372,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Can one parallelize complex exploration-exploitation tradeoffs? As an example, consider the problem of optimal high-throughput experimental design, where we wish to sequentially design batches of experiments in order to simultaneously learn a surrogate function mapping stimulus to response and identify the maximum of the function. We formalize the task as a multiarmed bandit problem, where the unknown payoff function is sampled from a Gaussian process (GP), and instead of a single arm, in each round we pull a batch of several arms in parallel. We develop GP-BUCB, a principled algorithm for choosing batches, based on the GP-UCB algorithm for sequential GP optimization. We prove a surprising result; as compared to the sequential approach, the cumulative regret of the parallel algorithm only increases by a constant factor independent of the batch size B. Our results provide rigorous theoretical support for exploiting parallelism in Bayesian global optimization. We demonstrate the effectiveness of our approach on two real-world applications."
            },
            "slug": "Parallelizing-Exploration-Exploitation-Tradeoffs-Desautels-Krause",
            "title": {
                "fragments": [],
                "text": "Parallelizing Exploration-Exploitation Tradeoffs with Gaussian Process Bandit Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work develops GP-BUCB, a principled algorithm for choosing batches, based on the GP-UCB algorithm for sequential GP optimization, and proves a surprising result; as compared to the sequential approach, the cumulative regret of the parallel algorithm only increases by a constant factor independent of the batch size B."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144108062"
                        ],
                        "name": "Jasper Snoek",
                        "slug": "Jasper-Snoek",
                        "structuredName": {
                            "firstName": "Jasper",
                            "lastName": "Snoek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jasper Snoek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754860"
                        ],
                        "name": "Kevin Swersky",
                        "slug": "Kevin-Swersky",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Swersky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Swersky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804104"
                        ],
                        "name": "R. Zemel",
                        "slug": "R.-Zemel",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Zemel",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zemel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722180"
                        ],
                        "name": "Ryan P. Adams",
                        "slug": "Ryan-P.-Adams",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Adams",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan P. Adams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 193
                            }
                        ],
                        "text": "One strategy is to convert a stationary kernel into a nonstationary one by transforming x using a parametric warping function x\u00f0w\u00de 1\u20444 w\u00f0x\u00de and then applying a stationary kernel to x\u00f0w\u00de [129], [145]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 167
                            }
                        ],
                        "text": "The beta warping approach has been shown to be highly effective on several benchmark problems as well as hyperparameter optimization for machine learning models [18], [145]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 36
                            }
                        ],
                        "text": "a beta cdf warping (originally from [145])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[145], who chose the warping function to be the cdf of the beta distribution"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1152498,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "17a5868dc7abfa9495af6b1ae71042a006238ebc",
            "isKey": false,
            "numCitedBy": 181,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "Bayesian optimization has proven to be a highly effective methodology for the global optimization of unknown, expensive and multimodal functions. The ability to accurately model distributions over functions is critical to the effectiveness of Bayesian optimization. Although Gaussian processes provide a flexible prior over functions, there are various classes of functions that remain difficult to model. One of the most frequently occurring of these is the class of non-stationary functions. The optimization of the hyperparameters of machine learning algorithms is a problem domain in which parameters are often manually transformed a priori, for example by optimizing in \"log-space,\" to mitigate the effects of spatially-varying length scale. We develop a methodology for automatically learning a wide family of bijective transformations or warpings of the input space using the Beta cumulative distribution function. We further extend the warping framework to multi-task Bayesian optimization so that multiple tasks can be warped into a jointly stationary space. On a set of challenging benchmark optimization tasks, we observe that the inclusion of warping greatly improves on the state-of-the-art, producing better results faster and more reliably."
            },
            "slug": "Input-Warping-for-Bayesian-Optimization-of-Snoek-Swersky",
            "title": {
                "fragments": [],
                "text": "Input Warping for Bayesian Optimization of Non-Stationary Functions"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "On a set of challenging benchmark optimization tasks, it is observed that the inclusion of warping greatly improves on the state-of-the-art, producing better results faster and more reliably."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143928655"
                        ],
                        "name": "C. Thornton",
                        "slug": "C.-Thornton",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Thornton",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Thornton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388404060"
                        ],
                        "name": "Kevin Leyton-Brown",
                        "slug": "Kevin-Leyton-Brown",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Leyton-Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Leyton-Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13952689,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a42ca00fc188beb5586ad4c7108b70aeb5317da0",
            "isKey": false,
            "numCitedBy": 1151,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Many different machine learning algorithms exist; taking into account each algorithm's hyperparameters, there is a staggeringly large number of possible alternatives overall. We consider the problem of simultaneously selecting a learning algorithm and setting its hyperparameters, going beyond previous work that attacks these issues separately. We show that this problem can be addressed by a fully automated approach, leveraging recent innovations in Bayesian optimization. Specifically, we consider a wide range of feature selection techniques (combining 3 search and 8 evaluator methods) and all classification approaches implemented in WEKA's standard distribution, spanning 2 ensemble methods, 10 meta-methods, 27 base classifiers, and hyperparameter settings for each classifier. On each of 21 popular datasets from the UCI repository, the KDD Cup 09, variants of the MNIST dataset and CIFAR-10, we show classification performance often much better than using standard selection and hyperparameter optimization methods. We hope that our approach will help non-expert users to more effectively identify machine learning algorithms and hyperparameter settings appropriate to their applications, and hence to achieve improved performance."
            },
            "slug": "Auto-WEKA:-combined-selection-and-hyperparameter-of-Thornton-Hutter",
            "title": {
                "fragments": [],
                "text": "Auto-WEKA: combined selection and hyperparameter optimization of classification algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This work considers the problem of simultaneously selecting a learning algorithm and setting its hyperparameters, going beyond previous work that attacks these issues separately and shows classification performance often much better than using standard selection and hyperparameter optimization methods."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50238440"
                        ],
                        "name": "W. Notz",
                        "slug": "W.-Notz",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Notz",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Notz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2011917"
                        ],
                        "name": "T. Santner",
                        "slug": "T.-Santner",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Santner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Santner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50475322"
                        ],
                        "name": "B. Williams",
                        "slug": "B.-Williams",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", [33] and [159])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[159] B."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10069227,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ef6e6f619e84ceb990fa62a3f57548b02c14c3a",
            "isKey": false,
            "numCitedBy": 184,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In the last ten to fifteen years many phenomena that could be studied only using physical experiments can now be studied by computer experiments. Advances in the mathematical modeling of many physical processes, in algorithms for solving mathematical systems, and in computer speeds, have combined to make it possible to augment or replace physical experiments with computer experiments. In a computer experiment, a response z( x), usually deterministic, is computed for each set of input variables, x, according to an experimental design strategy. This strategy is determined by the goal of the experiment and depends, for example, on whether response prediction at unsampled input sites or response optimization is of primary interest. \nWe are concerned with the commonly occuring situation in which there are two types of input variables: suppose x = ( xc, x e) where xc is a set of \u201ccontrol\u201d (manufacturing) variables and xe is a set of \u201cenvironmental\u201d (noise) variables. Manufacturing variables can be controlled while noise variables are not controllable but have values governed by some probability distribution. \nFor single response settings, we introduce a sequential experimental design for finding the optimum of e(x c) = E[z(x c, Xe)], where the expectation is taken over the distribution of the environmental variables. For bivariate response settings, we introduce a sequential experimental design for finding the constrained optimum of e1( xc)) = E[z( xc, X e)], subject to e2 (x c) = E[z2(x c, Xe)] \u2264 U. The approach is Bayesian; the prior information is that the responses are a draw from a stationary Gaussian stochastic process with correlation function belonging to a parametric family with unknown parameters. The idea of the methods is to compute the posterior expected \u201cimprovement\u201d over the current optimum for each untested site; the design selects the next site to maximize the expected improvement. Both procedures are illustrated by examples utilizing test functions from the numerical optimization literature."
            },
            "slug": "Sequential-design-of-computer-experiments-to-Notz-Santner",
            "title": {
                "fragments": [],
                "text": "Sequential design of computer experiments to minimize integrated response functions"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The idea of the methods is to compute the posterior expected \u201cimprovement\u201d over the current optimum for each untested site; the design selects the next site to maximize the expected improvement."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754860"
                        ],
                        "name": "Kevin Swersky",
                        "slug": "Kevin-Swersky",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Swersky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Swersky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704657"
                        ],
                        "name": "D. Duvenaud",
                        "slug": "D.-Duvenaud",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Duvenaud",
                            "middleNames": [
                                "Kristjanson"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Duvenaud"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144108062"
                        ],
                        "name": "Jasper Snoek",
                        "slug": "Jasper-Snoek",
                        "structuredName": {
                            "firstName": "Jasper",
                            "lastName": "Snoek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jasper Snoek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144484861"
                        ],
                        "name": "Michael A. Osborne",
                        "slug": "Michael-A.-Osborne",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Osborne",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael A. Osborne"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 147
                            }
                        ],
                        "text": "Recent work has focused on defining a fixed-length embedding of conditional spaces where a standard kernel using Euclidean distance can be applied [147]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6573057,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "61b0a3062378927334a6cc7cd3ebeebbb5f745a7",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "In practical Bayesian optimization, we must often search over structures with differing numbers of parameters. For instance, we may wish to search over neural network architectures with an unknown number of layers. To relate performance data gathered for different architectures, we define a new kernel for conditional parameter spaces that explicitly includes information about which parameters are relevant in a given structure. We show that this kernel improves model quality and Bayesian optimization results over several simpler baseline kernels."
            },
            "slug": "Raiders-of-the-Lost-Architecture:-Kernels-for-in-Swersky-Duvenaud",
            "title": {
                "fragments": [],
                "text": "Raiders of the Lost Architecture: Kernels for Bayesian Optimization in Conditional Parameter Spaces"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A new kernel for conditional parameter spaces that explicitly includes information about which parameters are relevant in a given structure is defined and it is shown that this kernel improves model quality and Bayesian optimization results over several simpler baseline kernels."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2944518"
                        ],
                        "name": "Julien Villemonteix",
                        "slug": "Julien-Villemonteix",
                        "structuredName": {
                            "firstName": "Julien",
                            "lastName": "Villemonteix",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julien Villemonteix"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144272396"
                        ],
                        "name": "E. V\u00e1zquez",
                        "slug": "E.-V\u00e1zquez",
                        "structuredName": {
                            "firstName": "Emmanuel",
                            "lastName": "V\u00e1zquez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. V\u00e1zquez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144970108"
                        ],
                        "name": "E. Walter",
                        "slug": "E.-Walter",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Walter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Walter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 127
                            }
                        ],
                        "text": "x by selecting the point that is expected to cause the largest reduction in entropy of the distribution p?\u00f0x j Dn\u00de [67], [69], [155]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 88
                            }
                        ],
                        "text": "Early work discretized the space X and computed the conditional entropy via MC sampling [155]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 147
                            }
                        ],
                        "text": "If the meta-criterion ESP\u00f0xjDn\u00de were minimized over the entire space X , ESP would reduce to the acquisition functions proposed by [67], [69], and [155]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 3264979,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "55290c9496fdf0df54dfdbb57117aa58386f98bc",
            "isKey": false,
            "numCitedBy": 304,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "In many global optimization problems motivated by engineering applications, the number of function evaluations is severely limited by time or cost. To ensure that each evaluation contributes to the localization of good candidates for the role of global minimizer, a sequential choice of evaluation points is usually carried out. In particular, when Kriging is used to interpolate past evaluations, the uncertainty associated with the lack of information on the function can be expressed and used to compute a number of criteria accounting for the interest of an additional evaluation at any given point. This paper introduces minimizers entropy as a new Kriging-based criterion for the sequential choice of points at which the function should be evaluated. Based on stepwise uncertainty reduction, it accounts for the informational gain on the minimizer expected from a new evaluation. The criterion is approximated using conditional simulations of the Gaussian process model behind Kriging, and then inserted into an algorithm similar in spirit to the Efficient Global Optimization (EGO) algorithm. An empirical comparison is carried out between our criterion and expected improvement, one of the reference criteria in the literature. Experimental results indicate major evaluation savings over EGO. Finally, the method, which we call IAGO (for Informational Approach to Global Optimization), is extended to robust optimization problems, where both the factors to be tuned and the function evaluations are corrupted by noise."
            },
            "slug": "An-informational-approach-to-the-global-of-Villemonteix-V\u00e1zquez",
            "title": {
                "fragments": [],
                "text": "An informational approach to the global optimization of expensive-to-evaluate functions"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper introduces minimizers entropy as a new Kriging-based criterion for the sequential choice of points at which the function should be evaluated, based on stepwise uncertainty reduction and is extended to robust optimization problems, where both the factors to be tuned and the function evaluations are corrupted by noise."
            },
            "venue": {
                "fragments": [],
                "text": "J. Glob. Optim."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764325"
                        ],
                        "name": "Radford M. Neal",
                        "slug": "Radford-M.-Neal",
                        "structuredName": {
                            "firstName": "Radford",
                            "lastName": "Neal",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Radford M. Neal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[118] R."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "There are many other examples of nonstationary covariance functions [3], [22], [54], [70], [118], [121], [126], [132] that have been proposed for GP regression along with closely related output warping techniques [141] that can also model certain kinds of nonstationary processes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60809283,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "db869fa192a3222ae4f2d766674a378e47013b1b",
            "isKey": false,
            "numCitedBy": 3633,
            "numCiting": 94,
            "paperAbstract": {
                "fragments": [],
                "text": "Artificial \"neural networks\" are widely used as flexible models for classification and regression applications, but questions remain about how the power of these models can be safely exploited when training data is limited. This book demonstrates how Bayesian methods allow complex neural network models to be used without fear of the \"overfitting\" that can occur with traditional training methods. Insight into the nature of these complex Bayesian models is provided by a theoretical investigation of the priors over functions that underlie them. A practical implementation of Bayesian neural network learning using Markov chain Monte Carlo methods is also described, and software for it is freely available over the Internet. Presupposing only basic knowledge of probability and statistics, this book should be of interest to researchers in statistics, engineering, and artificial intelligence."
            },
            "slug": "Bayesian-Learning-for-Neural-Networks-Neal",
            "title": {
                "fragments": [],
                "text": "Bayesian Learning for Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Bayesian Learning for Neural Networks shows that Bayesian methods allow complex neural network models to be used without fear of the \"overfitting\" that can occur with traditional neural network learning methods."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30561807"
                        ],
                        "name": "Edwin V. Bonilla",
                        "slug": "Edwin-V.-Bonilla",
                        "structuredName": {
                            "firstName": "Edwin",
                            "lastName": "Bonilla",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edwin V. Bonilla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1890071"
                        ],
                        "name": "K. M. A. Chai",
                        "slug": "K.-M.-A.-Chai",
                        "structuredName": {
                            "firstName": "Kian",
                            "lastName": "Chai",
                            "middleNames": [
                                "Ming",
                                "Adam"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. M. A. Chai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 63
                            }
                        ],
                        "text": "One method is to use the intrinsic model of coregionalization (ICM) [60], [136], [21] that utilizes the product kernel,\nk((x,m), (x\u2032,m\u2032)) = kX (x,x \u2032)kT (m,m \u2032)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "coregionalization (ICM) [21], [60], [136] that utilizes the product kernel"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 27
                            }
                        ],
                        "text": "An alternative view of the ICM model is that it defines a latent process that is rotated and scaled to produce each of the individual tasks."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10790217,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "10d10df314c1b58f5c83629e73a35185876cd4e2",
            "isKey": false,
            "numCitedBy": 901,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we investigate multi-task learning in the context of Gaussian Processes (GP). We propose a model that learns a shared covariance function on input-dependent features and a \"free-form\" covariance matrix over tasks. This allows for good flexibility when modelling inter-task dependencies while avoiding the need for large amounts of data for training. We show that under the assumption of noise-free observations and a block design, predictions for a given task only depend on its target values and therefore a cancellation of inter-task transfer occurs. We evaluate the benefits of our model on two practical applications: a compiler performance prediction problem and an exam score prediction task. Additionally, we make use of GP approximations and properties of our model in order to provide scalability to large data sets."
            },
            "slug": "Multi-task-Gaussian-Process-Prediction-Bonilla-Chai",
            "title": {
                "fragments": [],
                "text": "Multi-task Gaussian Process Prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "A model that learns a shared covariance function on input-dependent features and a \"free-form\" covariance matrix over tasks allows for good flexibility when modelling inter-task dependencies while avoiding the need for large amounts of data for training."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755465"
                        ],
                        "name": "Dani Yogatama",
                        "slug": "Dani-Yogatama",
                        "structuredName": {
                            "firstName": "Dani",
                            "lastName": "Yogatama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dani Yogatama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47648549"
                        ],
                        "name": "Lingpeng Kong",
                        "slug": "Lingpeng-Kong",
                        "structuredName": {
                            "firstName": "Lingpeng",
                            "lastName": "Kong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lingpeng Kong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685669"
                        ],
                        "name": "Noah A. Smith",
                        "slug": "Noah-A.-Smith",
                        "structuredName": {
                            "firstName": "Noah",
                            "lastName": "Smith",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noah A. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 71
                            }
                        ],
                        "text": "We use X to denote the n\u00d7 d design matrix in which row i is the feature vector associated with the arm pulled in the ith iteration, xai ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5656482,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2f1701b96ff8fef9eb94bf371d9de837ecc7b570",
            "isKey": false,
            "numCitedBy": 38,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "When applying machine learning to problems in NLP, there are many choices to make about how to represent input texts. These choices can have a big effect on performance, but they are often uninteresting to researchers or practitioners who simply need a module that performs well. We propose an approach to optimizing over this space of choices, formulating the problem as global optimization. We apply a sequential model-based optimization technique and show that our method makes standard linear models competitive with more sophisticated, expensive state-of-the-art methods based on latent variable models or neural networks on various topic classification and sentiment analysis problems. Our approach is a first step towards black-box NLP systems that work with raw text and do not require manual tuning."
            },
            "slug": "Bayesian-Optimization-of-Text-Representations-Yogatama-Kong",
            "title": {
                "fragments": [],
                "text": "Bayesian Optimization of Text Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work applies a sequential model-based optimization technique and shows that this method makes standard linear models competitive with more sophisticated, expensive state-of-the-art methods based on latent variable models or neural networks on various topic classification and sentiment analysis problems."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33474456"
                        ],
                        "name": "M. Gelbart",
                        "slug": "M.-Gelbart",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Gelbart",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gelbart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144108062"
                        ],
                        "name": "Jasper Snoek",
                        "slug": "Jasper-Snoek",
                        "structuredName": {
                            "firstName": "Jasper",
                            "lastName": "Snoek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jasper Snoek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722180"
                        ],
                        "name": "Ryan P. Adams",
                        "slug": "Ryan-P.-Adams",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Adams",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan P. Adams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[56] proposed the weighted expected improvement criterion (wEI) that multiplies EI by the probability of satisfying the constraints"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [56], a scenario was outlined in which a food company wished to design the best tasting cookie subject to the number of calories being below a certain level."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 948625,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "050ee7cb77800f4d07b517d028d1da8c0c48345b",
            "isKey": false,
            "numCitedBy": 273,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work on Bayesian optimization has shown its effectiveness in global optimization of difficult black-box objective functions. Many real-world optimization problems of interest also have constraints which are unknown a priori. In this paper, we study Bayesian optimization for constrained problems in the general case that noise may be present in the constraint functions, and the objective and constraints may be evaluated independently. We provide motivating practical examples, and present a general framework to solve such problems. We demonstrate the effectiveness of our approach on optimizing the performance of online latent Dirichlet allocation subject to topic sparsity constraints, tuning a neural network given test-time memory constraints, and optimizing Hamiltonian Monte Carlo to achieve maximal effectiveness in a fixed time, subject to passing standard convergence diagnostics."
            },
            "slug": "Bayesian-Optimization-with-Unknown-Constraints-Gelbart-Snoek",
            "title": {
                "fragments": [],
                "text": "Bayesian Optimization with Unknown Constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper studies Bayesian optimization for constrained problems in the general case that noise may be present in the constraint functions, and the objective and constraints may be evaluated independently."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31693738"
                        ],
                        "name": "Jacob R. Gardner",
                        "slug": "Jacob-R.-Gardner",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Gardner",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jacob R. Gardner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1940272"
                        ],
                        "name": "Matt J. Kusner",
                        "slug": "Matt-J.-Kusner",
                        "structuredName": {
                            "firstName": "Matt",
                            "lastName": "Kusner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matt J. Kusner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32622713"
                        ],
                        "name": "Z. Xu",
                        "slug": "Z.-Xu",
                        "structuredName": {
                            "firstName": "Zhixiang",
                            "lastName": "Xu",
                            "middleNames": [
                                "Eddie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7446832"
                        ],
                        "name": "Kilian Q. Weinberger",
                        "slug": "Kilian-Q.-Weinberger",
                        "structuredName": {
                            "firstName": "Kilian",
                            "lastName": "Weinberger",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kilian Q. Weinberger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2575774"
                        ],
                        "name": "J. Cunningham",
                        "slug": "J.-Cunningham",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Cunningham",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cunningham"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "A variant of wEI was proposed in [52] to deal with the case where the function is constrained to be less than some"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17104903,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5918ae75d71ff737ed002a0d2d4d720d8a94c6b6",
            "isKey": false,
            "numCitedBy": 266,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Bayesian optimization is a powerful framework for minimizing expensive objective functions while using very few function evaluations. It has been successfully applied to a variety of problems, including hyperparameter tuning and experimental design. However, this framework has not been extended to the inequality-constrained optimization setting, particularly the setting in which evaluating feasibility is just as expensive as evaluating the objective. Here we present constrained Bayesian optimization, which places a prior distribution on both the objective and the constraint functions. We evaluate our method on simulated and real data, demonstrating that constrained Bayesian optimization can quickly find optimal and feasible points, even when small feasible regions cause standard methods to fail."
            },
            "slug": "Bayesian-Optimization-with-Inequality-Constraints-Gardner-Kusner",
            "title": {
                "fragments": [],
                "text": "Bayesian Optimization with Inequality Constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work presents constrained Bayesian optimization, which places a prior distribution on both the objective and the constraint functions, and evaluates this method on simulated and real data, demonstrating that constrainedBayesian optimization can quickly find optimal and feasible points, even when small feasible regions cause standard methods to fail."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144630672"
                        ],
                        "name": "R. Benassi",
                        "slug": "R.-Benassi",
                        "structuredName": {
                            "firstName": "Romain",
                            "lastName": "Benassi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Benassi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691181"
                        ],
                        "name": "J. Bect",
                        "slug": "J.-Bect",
                        "structuredName": {
                            "firstName": "Julien",
                            "lastName": "Bect",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bect"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144272396"
                        ],
                        "name": "E. V\u00e1zquez",
                        "slug": "E.-V\u00e1zquez",
                        "structuredName": {
                            "firstName": "Emmanuel",
                            "lastName": "V\u00e1zquez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. V\u00e1zquez"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 176
                            }
                        ],
                        "text": "Estimating the hyperparameters of GP kernels with very few function evaluations is a challenging task, often with disastrous consequences as illustrated by a simple example in [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6424467,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e69596762f29162fe8e6ec48b7d69024bcd022ed",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of optimizing a real-valued continuous function f, which is supposed to be expensive to evaluate and, consequently, can only be evaluated a limited number of times. This article focuses on the Bayesian approach to this problem, which consists in combining evaluation results and prior information about f in order to efficiently select new evaluation points, as long as the budget for evaluations is not exhausted. \n \nThe algorithm called efficient global optimization (EGO), proposed by Jones, Schonlau and Welch (J. Global Optim., 13(4):455\u2013492, 1998), is one of the most popular Bayesian optimization algorithms. It is based on a sampling criterion called the expected improvement (EI), which assumes a Gaussian process prior about f. In the EGO algorithm, the parameters of the covariance of the Gaussian process are estimated from the evaluation results by maximum likelihood, and these parameters are then plugged in the EI sampling criterion. However, it is well-known that this plug-in strategy can lead to very disappointing results when the evaluation results do not carry enough information about f to estimate the parameters in a satisfactory manner. \n \nWe advocate a fully Bayesian approach to this problem, and derive an analytical expression for the EI criterion in the case of Student predictive distributions. Numerical experiments show that the fully Bayesian approach makes EI-based optimization more robust while maintaining an average loss similar to that of the EGO algorithm."
            },
            "slug": "Robust-Gaussian-Process-Based-Global-Optimization-a-Benassi-Bect",
            "title": {
                "fragments": [],
                "text": "Robust Gaussian Process-Based Global Optimization Using a Fully Bayesian Expected Improvement Criterion"
            },
            "tldr": {
                "abstractSimilarityScore": 35,
                "text": "Numerical experiments show that the fully Bayesian approach makes EI-based optimization more robust while maintaining an average loss similar to that of the EGO algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "LION"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3343244"
                        ],
                        "name": "D. Ginsbourger",
                        "slug": "D.-Ginsbourger",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ginsbourger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ginsbourger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2480706"
                        ],
                        "name": "R. L. Riche",
                        "slug": "R.-L.-Riche",
                        "structuredName": {
                            "firstName": "Rodolphe",
                            "lastName": "Riche",
                            "middleNames": [
                                "Le"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. L. Riche"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153321911"
                        ],
                        "name": "L. Carraro",
                        "slug": "L.-Carraro",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Carraro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Carraro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[57] proposed several approaches based on imputing the results of currently running experiments."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16501652,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "787ee940ff557f0dcf8d07e9c7ade39d00d5e3df",
            "isKey": false,
            "numCitedBy": 301,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "The optimization of expensive-to-evaluate functions generally relies on metamodel-based exploration strategies. Many deterministic global optimization algorithms used in the field of computer experiments are based on Kriging (Gaussian process regression). Starting with a spatial predictor including a measure of uncertainty, they proceed by iteratively choosing the point maximizing a criterion which is a compromise between predicted performance and uncertainty. Distributing the evaluation of such numerically expensive objective functions on many processors is an appealing idea. Here we investigate a multi-points optimization criterion, the multipoints expected improvement (\\(q-{\\mathbb E}I\\)), aimed at choosing several points at the same time. An analytical expression of the \\(q-{\\mathbb E}I\\) is given when q = 2, and a consistent statistical estimate is given for the general case. We then propose two classes of heuristic strategies meant to approximately optimize the \\(q-{\\mathbb E}I\\), and apply them to the classical Branin-Hoo test-case function. It is finally demonstrated within the covered example that the latter strategies perform as good as the best Latin Hypercubes and Uniform Designs ever found by simulation (2000 designs drawn at random for every q \u2208 [1,10])."
            },
            "slug": "Kriging-is-well-suited-to-parallelize-optimization-Ginsbourger-Riche",
            "title": {
                "fragments": [],
                "text": "Kriging is well-suited to parallelize optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work investigates a multi-points optimization criterion, the multipoints expected improvement (\\(q-{\\mathbb E}I\\)), aimed at choosing several points at the same time, and proposes two classes of heuristic strategies meant to approximately optimize the Q-EI, and applies them to the classical Branin-Hoo test-case function."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708654"
                        ],
                        "name": "R. Munos",
                        "slug": "R.-Munos",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Munos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Munos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 168
                            }
                        ],
                        "text": "In this section, we focus on the results concerning GP-based Bayesian optimization and defer detailed discussions of bandit algorithms to other dedicated surveys [29], [117]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 51740855,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "541571ba3ca170e5429454d9ad190a867263effd",
            "isKey": false,
            "numCitedBy": 228,
            "numCiting": 143,
            "paperAbstract": {
                "fragments": [],
                "text": "This work covers several aspects of the optimism in the face of uncertainty principle applied to large scale optimization problems under finite numerical budget. The initial motivation for the research reported here originated from the empirical success of the so-called Monte-Carlo Tree Search method popularized in computer-go and further extended to many other games as well as optimization and planning problems. Our objective is to contribute to the development of theoretical foundations of the field by characterizing the complexity of the underlying optimization problems and designing efficient algorithms with performance guarantees. The main idea presented here is that it is possible to decompose a complex decision making problem (such as an optimization problem in a large search space) into a sequence of elementary decisions, where each decision of the sequence is solved using a (stochastic) multi-armed bandit (simple mathematical model for decision making in stochastic environments). This so-called hierarchical bandit approach (where the reward observed by a bandit in the hierarchy is itself the return of another bandit at a deeper level) possesses the nice feature of starting the exploration by a quasi-uniform sampling of the space and then focusing progressively on the most promising area, at different scales, according to the evaluations observed so far, and eventually performing a local search around the global optima of the function. The performance of the method is assessed in terms of the optimality of the returned solution as a function of the number of function evaluations. Our main contribution to the field of function optimization is a class of hierarchical optimistic algorithms designed for general search spaces (such as metric spaces, trees, graphs, Euclidean spaces, ...) with different algorithmic instantiations depending on whether the evaluations are noisy or noiseless and whether some measure of the ''smoothness'' of the function is known or unknown. The performance of the algorithms depend on the local behavior of the function around its global optima expressed in terms of the quantity of near-optimal states measured with some metric. If this local smoothness of the function is known then one can design very efficient optimization algorithms (with convergence rate independent of the space dimension), and when it is not known, we can build adaptive techniques that can, in some cases, perform almost as well as when it is known."
            },
            "slug": "From-Bandits-to-Monte-Carlo-Tree-Search:-The-to-and-Munos",
            "title": {
                "fragments": [],
                "text": "From Bandits to Monte-Carlo Tree Search: The Optimistic Principle Applied to Optimization and Planning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The main idea presented here is that it is possible to decompose a complex decision making problem into a sequence of elementary decisions, where each decision of the sequence is solved using a (stochastic) multi-armed bandit (simple mathematical model for decision making in stochastic environments)."
            },
            "venue": {
                "fragments": [],
                "text": "Found. Trends Mach. Learn."
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32837403"
                        ],
                        "name": "J. Bergstra",
                        "slug": "J.-Bergstra",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bergstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bergstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2103302"
                        ],
                        "name": "R. Bardenet",
                        "slug": "R.-Bardenet",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Bardenet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bardenet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143674326"
                        ],
                        "name": "B. K\u00e9gl",
                        "slug": "B.-K\u00e9gl",
                        "structuredName": {
                            "firstName": "Bal\u00e1zs",
                            "lastName": "K\u00e9gl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. K\u00e9gl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "This rapidly becomes infeasible in the large spaces of realworld problems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11688126,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "03911c85305d42aa2eeb02be82ef6fb7da644dd0",
            "isKey": false,
            "numCitedBy": 2516,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Several recent advances to the state of the art in image classification benchmarks have come from better configurations of existing techniques rather than novel approaches to feature learning. Traditionally, hyper-parameter optimization has been the job of humans because they can be very efficient in regimes where only a few trials are possible. Presently, computer clusters and GPU processors make it possible to run more trials and we show that algorithmic approaches can find better results. We present hyper-parameter optimization results on tasks of training neural networks and deep belief networks (DBNs). We optimize hyper-parameters using random search and two new greedy sequential methods based on the expected improvement criterion. Random search has been shown to be sufficiently efficient for learning neural networks for several datasets, but we show it is unreliable for training DBNs. The sequential algorithms are applied to the most difficult DBN learning problems from [1] and find significantly better results than the best previously reported. This work contributes novel techniques for making response surface models P(y|x) in which many elements of hyper-parameter assignment (x) are known to be irrelevant given particular values of other elements."
            },
            "slug": "Algorithms-for-Hyper-Parameter-Optimization-Bergstra-Bardenet",
            "title": {
                "fragments": [],
                "text": "Algorithms for Hyper-Parameter Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work contributes novel techniques for making response surface models P(y|x) in which many elements of hyper-parameter assignment (x) are known to be irrelevant given particular values of other elements."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3343244"
                        ],
                        "name": "D. Ginsbourger",
                        "slug": "D.-Ginsbourger",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ginsbourger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ginsbourger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3130008"
                        ],
                        "name": "J. Janusevskis",
                        "slug": "J.-Janusevskis",
                        "structuredName": {
                            "firstName": "Janis",
                            "lastName": "Janusevskis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Janusevskis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2480706"
                        ],
                        "name": "R. L. Riche",
                        "slug": "R.-L.-Riche",
                        "structuredName": {
                            "firstName": "Rodolphe",
                            "lastName": "Riche",
                            "middleNames": [
                                "Le"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. L. Riche"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 123796880,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14b08c8271a09853ce9e4c002c0e44b896b90d04",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 91,
            "paperAbstract": {
                "fragments": [],
                "text": "During the last decade, Kriging-based sequential algorithms like EGO and its variants have become reference optimization methods in computer experiments. Such algorithms rely on the iterative maximization of a sampling criterion, the expected improvement (EI), which takes advantage of Kriging conditional distributions to make an explicit trade-off between promizing and uncertain search space points. We have recently worked on a multipoints EI criterion meant to simultaneously choose several points, which is useful for instance in synchronous parallel computation. Here we propose extensions of these works to asynchronous parallel optimization and focus on a variant of EI, EEI, for the case where some new evaluation(s) have to be done while the reponses of previously simulations are not all known yet. In particular, different issues regarding EEI's maximization are addressed, and a proxy strategy is proposed."
            },
            "slug": "Dealing-with-asynchronicity-in-parallel-Gaussian-Ginsbourger-Janusevskis",
            "title": {
                "fragments": [],
                "text": "Dealing with asynchronicity in parallel Gaussian Process based global optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This work proposes extensions of Kriging-based sequential algorithms to asynchronous parallel optimization and focuses on a variant of EI, EEI, for the case where some new evaluation(s) have to be done while the reponses of previously simulations are not all known yet."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726733"
                        ],
                        "name": "Ron Kohavi",
                        "slug": "Ron-Kohavi",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Kohavi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ron Kohavi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2032211"
                        ],
                        "name": "R. Longbotham",
                        "slug": "R.-Longbotham",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Longbotham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Longbotham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40307399"
                        ],
                        "name": "D. Sommerfield",
                        "slug": "D.-Sommerfield",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Sommerfield",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Sommerfield"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34133057"
                        ],
                        "name": "Randal M. Henne",
                        "slug": "Randal-M.-Henne",
                        "structuredName": {
                            "firstName": "Randal",
                            "lastName": "Henne",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Randal M. Henne"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17165746,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abc853bd9a67dd87ebce025a7dc94fb467b067b9",
            "isKey": false,
            "numCitedBy": 630,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "The web provides an unprecedented opportunity to evaluate ideas quickly using controlled experiments, also called randomized experiments, A/B tests (and their generalizations), split tests, Control/Treatment tests, MultiVariable Tests (MVT) and parallel flights. Controlled experiments embody the best scientific design for establishing a causal relationship between changes and their influence on user-observable behavior. We provide a practical guide to conducting online experiments, where end-users can help guide the development of features. Our experience indicates that significant learning and return-on-investment (ROI) are seen when development teams listen to their customers, not to the Highest Paid Person\u2019s Opinion (HiPPO). We provide several examples of controlled experiments with surprising results. We review the important ingredients of running controlled experiments, and discuss their limitations (both technical and organizational). We focus on several areas that are critical to experimentation, including statistical power, sample size, and techniques for variance reduction. We describe common architectures for experimentation systems and analyze their advantages and disadvantages. We evaluate randomization and hashing techniques, which we show are not as simple in practice as is often assumed. Controlled experiments typically generate large amounts of data, which can be analyzed using data mining techniques to gain deeper understanding of the factors influencing the outcome of interest, leading to new hypotheses and creating a virtuous cycle of improvements. Organizations that embrace controlled experiments with clear evaluation criteria can evolve their systems with automated optimizations and real-time analyses. Based on our extensive practical experience with multiple systems and organizations, we share key lessons that will help practitioners in running trustworthy controlled experiments."
            },
            "slug": "Controlled-experiments-on-the-web:-survey-and-guide-Kohavi-Longbotham",
            "title": {
                "fragments": [],
                "text": "Controlled experiments on the web: survey and practical guide"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work provides a practical guide to conducting online experiments, and shares key lessons that will help practitioners in running trustworthy controlled experiments, including statistical power, sample size, and techniques for variance reduction."
            },
            "venue": {
                "fragments": [],
                "text": "Data Mining and Knowledge Discovery"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3331580"
                        ],
                        "name": "O. Maron",
                        "slug": "O.-Maron",
                        "structuredName": {
                            "firstName": "Oded",
                            "lastName": "Maron",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Maron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760402"
                        ],
                        "name": "A. Moore",
                        "slug": "A.-Moore",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Moore",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Moore"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7930120,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b31b23e0cb60fbc857728d6b16bc5d61f71a643",
            "isKey": false,
            "numCitedBy": 355,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Selecting a good model of a set of input points by cross validation is a computationally intensive process, especially if the number of possible models or the number of training points is high. Techniques such as gradient descent are helpful in searching through the space of models, but problems such as local minima, and more importantly, lack of a distance metric between various models reduce the applicability of these search methods. Hoeffding Races is a technique for finding a good model for the data by quickly discarding bad models, and concentrating the computational effort at differentiating between the better ones. This paper focuses on the special case of leave-one-out cross validation applied to memory-based learning algorithms, but we also argue that it is applicable to any class of model selection problems."
            },
            "slug": "Hoeffding-Races:-Accelerating-Model-Selection-for-Maron-Moore",
            "title": {
                "fragments": [],
                "text": "Hoeffding Races: Accelerating Model Selection Search for Classification and Function Approximation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper focuses on the special case of leave-one-out cross validation applied to memory-based learning algorithms, but it is argued that it is applicable to any class of model selection problems."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2103302"
                        ],
                        "name": "R. Bardenet",
                        "slug": "R.-Bardenet",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Bardenet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bardenet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143674326"
                        ],
                        "name": "B. K\u00e9gl",
                        "slug": "B.-K\u00e9gl",
                        "structuredName": {
                            "firstName": "Bal\u00e1zs",
                            "lastName": "K\u00e9gl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. K\u00e9gl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": "In practice, the community has resorted to using various techniques such as discretization [143] and adaptive grids [13], or similarly, the divided rectangles approach of [83], which was used in [28], [110], [105]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7130568,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "560ac582a82dc0ce9765fc942f07f94908eaeeb3",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "In global optimization, when the evaluation of the target function is costly, the usual strategy is to learn a surrogate model for the target function and replace the initial optimization by the optimization of the model. Gaussian processes have been widely used since they provide an elegant way to model the fitness and to deal with the exploration-exploitation trade-off in a principled way. Several empirical criteria have been proposed to drive the model optimization, among which is the well-known Expected Improvement criterion. The major computational bottleneck of these algorithms is the exhaustive grid search used to optimize the highly multimodal merit function. In this paper, we propose a competitive \"adaptive grid\" approach, based on a properly derived cross-entropy optimization algorithm with mixture proposals. Experiments suggest that 1) we outperform the classical single-Gaussian cross-entropy method when the fitness function is highly multimodal, and 2) we improve on standard exhaustive search in GP-based surrogate optimization."
            },
            "slug": "Surrogating-the-surrogate:-accelerating-global-with-Bardenet-K\u00e9gl",
            "title": {
                "fragments": [],
                "text": "Surrogating the surrogate: accelerating Gaussian-process-based global optimization with a mixture cross-entropy algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Experiments suggest that 1) the competitive \"adaptive grid\" approach outperforms the classical single-Gaussian cross-entropy method when the fitness function is highly multimodal, and 2) it improves on standard exhaustive search in GP-based surrogate optimization."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118096690"
                        ],
                        "name": "Donald R. Jones",
                        "slug": "Donald-R.-Jones",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Jones",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donald R. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815604"
                        ],
                        "name": "M. Schonlau",
                        "slug": "M.-Schonlau",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Schonlau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schonlau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145228938"
                        ],
                        "name": "W. Welch",
                        "slug": "W.-Welch",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Welch",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Welch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "The typical estimation of the hyperparameters by maximizing the marginal likelihood [82], [126] can easily fall into traps, as shown in [32]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": "In [32], Bull provided both upper and lower bounds of simple regret for the EGO algorithm [82] in the deterministic setting."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "These improvement strategies have been empirically studied in the literature [27], [81], [82] and recently convergence rates have been proven for EI [32]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[82] as a refinement of the SPACE algorithm"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13068209,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "daa63f57c3fbe994c4356f8d986a22e696e776d2",
            "isKey": true,
            "numCitedBy": 5764,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "In many engineering optimization problems, the number of function evaluations is severely limited by time or cost. These problems pose a special challenge to the field of global optimization, since existing methods often require more function evaluations than can be comfortably afforded. One way to address this challenge is to fit response surfaces to data collected by evaluating the objective and constraint functions at a few points. These surfaces can then be used for visualization, tradeoff analysis, and optimization. In this paper, we introduce the reader to a response surface methodology that is especially good at modeling the nonlinear, multimodal functions that often occur in engineering. We then show how these approximating functions can be used to construct an efficient global optimization algorithm with a credible stopping rule. The key to using response surfaces for global optimization lies in balancing the need to exploit the approximating surface (by sampling where it is minimized) with the need to improve the approximation (by sampling where prediction error may be high). Striking this balance requires solving certain auxiliary problems which have previously been considered intractable, but we show how these computational obstacles can be overcome."
            },
            "slug": "Efficient-Global-Optimization-of-Expensive-Jones-Schonlau",
            "title": {
                "fragments": [],
                "text": "Efficient Global Optimization of Expensive Black-Box Functions"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper introduces the reader to a response surface methodology that is especially good at modeling the nonlinear, multimodal functions that often occur in engineering and shows how these approximating functions can be used to construct an efficient global optimization algorithm with a credible stopping rule."
            },
            "venue": {
                "fragments": [],
                "text": "J. Glob. Optim."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734627"
                        ],
                        "name": "Omid Madani",
                        "slug": "Omid-Madani",
                        "structuredName": {
                            "firstName": "Omid",
                            "lastName": "Madani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Omid Madani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690162"
                        ],
                        "name": "D. Lizotte",
                        "slug": "D.-Lizotte",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lizotte",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lizotte"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143686063"
                        ],
                        "name": "R. Greiner",
                        "slug": "R.-Greiner",
                        "structuredName": {
                            "firstName": "Russell",
                            "lastName": "Greiner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Greiner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 109
                            }
                        ],
                        "text": "arm identification problem, which is more suitable for the model selection task [7], [30], [50], [51], [72], [104]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5116710,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2ecc72ead9620e51072e5593b7158daf548672e",
            "isKey": false,
            "numCitedBy": 73,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Classical learning assumes the learner is given a labeled data sample, from which it learns a model. The field of Active Learning deals with the situation where the learner begins not with a training sample, but instead with resources that it can use to obtain information to help identify the optimal model. To better understand this task, this paper presents and analyses the simplified \"(budgeted) active model selection\" version, which captures the pure exploration aspect of many active learning problems in a clean and simple problem formulation. Here the learner can use a fixed budget of \"model probes\" (where each probe evaluates the specified model on a random indistinguishable instance) to identify which of a given set of possible models has the highest expected accuracy. Our goal is a policy that sequentially determines which model to probe next, based on the information observed so far. We present a formal description of this task, and show that it is NP-hard in general. We then investigate a number of algorithms for this task, including several existing ones (eg, \"Round-Robin\", \"Interval Estimation\", \"Gittins\") as well as some novel ones (e.g., \"Biased-Robin\"), describing first their approximation properties and then their empirical performance on various problem instances. We observe empirically that the simple biased-robin algorithm significantly outperforms the other algorithms in the case of identical costs and priors."
            },
            "slug": "Active-Model-Selection-Madani-Lizotte",
            "title": {
                "fragments": [],
                "text": "Active Model Selection"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper presents and analyses the simplified \"(budgeted) active model selection\" version, which captures the pure exploration aspect of many active learning problems in a clean and simple problem formulation, and shows that it is NP-hard in general."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145974030"
                        ],
                        "name": "R. Garnett",
                        "slug": "R.-Garnett",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Garnett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Garnett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144484861"
                        ],
                        "name": "Michael A. Osborne",
                        "slug": "Michael-A.-Osborne",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Osborne",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael A. Osborne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145029236"
                        ],
                        "name": "S. Roberts",
                        "slug": "S.-Roberts",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Roberts",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roberts"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 330,
                                "start": 319
                            }
                        ],
                        "text": "In academia, it is impacting a wide range of areas, including interactive user-interfaces [26], robotics [101], [110], environmental monitoring [106], information extraction [158], combinatorial optimisation [79], [159], automatic machine learning [16], [143], [148], [151], [72], sensor networks [55], [146], adaptive Monte Carlo [105], experimental design [11] and reinforcement learning [27]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 105
                            }
                        ],
                        "text": "For this reason we consider marginalizing out the hyperparameters using either quadrature or Monte Carlo [120], [26], [143]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 13
                            }
                        ],
                        "text": "Markov chain Monte Carlo (MCMC) methods [4] approximate the posterior with a sequence of samples that converge to the posterior; this is the approach taken in [135] on the probit model."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 69
                            }
                        ],
                        "text": "In addition to MC methods, one could also use quadrature as shown in [120]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 42
                            }
                        ],
                        "text": "] The expectation can be approximated via Monte Carlo with Thompson samples; and three simplifying assumptions are made to compute H(y | Dn,x,x?)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 387,
                                "start": 376
                            }
                        ],
                        "text": "It is popular for several reasons: 1) there are no free parameters other than the prior hyperparameters of the Bayesian model, 2) the strategy naturally trades off between exploration and exploitation based on its posterior beliefs on w; arms are explored only if they are likely (under the posterior) to be optimal, 3) the strategy is relatively easy to implement as long as Monte Carlo sampling mechanisms are available for the posterior model, and 4) the randomization in Thompson sampling makes it particularly appropriate for batch or delayed feedback settings where many selections an+1 are based on the identical posterior [135], [38]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 66
                            }
                        ],
                        "text": "(39)\nAs the name suggests, SSGP approximates this expectation via Monte Carlo estimation using m samples drawn from the spectral density so that\nk(x,x\u2032) \u2248 \u03bd m m\u2211 i=1 e\u2212i\u03c9 (i)Txei\u03c9 (i)Tx\u2032 (40)\nwhere \u03c9(i) \u223c s(\u03c9)/\u03bd."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 27
                            }
                        ],
                        "text": "Although this violates the Monte Carlo assumption and introduces a risk of\n10\noverfitting, it allows for a smaller number of basis functions with good predictive power [94]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 97
                            }
                        ],
                        "text": "(53)\nHowever, in practice it is impossible to sample directly from the posterior so Markov chain Monte Carlo (MCMC) and sequential Monte Carlo (SMC) techniques are used to produce a sequence of samples that are marginally distributed according to p(\u03b8 | Dn) in the limit of infinitely long chains."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 165
                            }
                        ],
                        "text": "Recently, the\n4 Bayesian optimization approach for the model selection and tuning task has received much attention in tuning deep belief networks [16], Markov chain Monte Carlo methods [105], [65], convolutional neural networks [143], [148], and automatically selecting among WEKA and scikit-learn offerings [151], [72]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 76
                            }
                        ],
                        "text": "Early work discretized the space X and computed the conditional entropy via Monte Carlo sampling [156]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 107
                            }
                        ],
                        "text": "Several authors have proposed to integrate out the hyperparameters using quadrature or Monte Carlo methods [120], [26], [143]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 24
                            }
                        ],
                        "text": "The common component in Monte Carlo (MC) methods is that they approximate the integral in (50) using M samples { \u03b8 (i) n }M i=1 from the posterior distribution p(\u03b8 | Dn):\nE\u03b8|Dn [\u03b1(x; \u03b8)] \u2248 1\nM M\u2211 i=1 \u03b1(x; \u03b8(i)n )."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 148
                            }
                        ],
                        "text": "In simple models like the BetaBernoulli, it is possible to compute this distribution in closed form, but more often it must be estimated via, e.g., Monte Carlo."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5101579,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e109a80439cc73611f70315cff2cc7e9b4e34f7d",
            "isKey": true,
            "numCitedBy": 225,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a novel Bayesian approach to global optimization using Gaussian processes. We frame the optimization of both noisy and noiseless functions as sequential decision problems, and introduce myopic and non-myopic solutions to them. Here our solutions can be tailored to exactly the degree of confidence we require of them. The use of Gaussian processes allows us to benefit from the incorporation of prior knowledge about our objective function, and also from any derivative observations. Using this latter fact, we introduce an innovative method to combat conditioning problems. Our algorithm demonstrates a significant improvement over its competitors in overall performance across a wide range of canonical test problems."
            },
            "slug": "Gaussian-Processes-for-Global-Optimization-Garnett-Osborne",
            "title": {
                "fragments": [],
                "text": "Gaussian Processes for Global Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A novel Bayesian approach to global optimization using Gaussian processes is introduced, frame the optimization of both noisy and noiseless functions as sequential decision problems, and introduces myopic and non-myopic solutions to them."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40132383"
                        ],
                        "name": "Phillip Boyle",
                        "slug": "Phillip-Boyle",
                        "structuredName": {
                            "firstName": "Phillip",
                            "lastName": "Boyle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Phillip Boyle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 117
                            }
                        ],
                        "text": "body of work devoted to extending the algorithm, particularly in adding constraints to the optimization problem [6], [23], [131], and in modeling noisy functions [14], [75], [76]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118429927,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb529f514ae4b5f2c61ecde551157e1dd2e9b3f1",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 115,
            "paperAbstract": {
                "fragments": [],
                "text": "Gaussian processes have proved to be useful and powerful constructs for the purposes of regression. The classical method proceeds by parameterising a covariance function, and then infers the parameters given the training data. In this thesis, the classical approach is augmented by interpreting Gaussian processes as the outputs of linear filters excited by white noise. This enables a straightforward definition of dependent Gaussian processes as the outputs of a multiple output linear filter excited by multiple noise sources. We show how dependent Gaussian processes defined in this way can also be used for the purposes of system identification. Onewell known problem with Gaussian process regression is that the computational complexity scales poorly with the amount of training data. We review one approximate solution that alleviates this problem, namely reduced rank Gaussian processes. We then show how the reduced rank approximation can be applied to allow for the efficient computation of dependent Gaussian processes. We then examine the application of Gaussian processes to the solution of other machine learning problems. To do so, we review methods for the parameterisation of full covariance matrices. Furthermore, we discuss how improvements can be made by marginalising over alternative models, and introduce methods to perform these computations efficiently. In particular, we introduce sequential annealed importance sampling as a method for calculating model evidence in an on-line fashion as new data arrives. Gaussian process regression can also be applied to optimisation. An algorithm is described that uses model comparison between multiple models to find the optimum of a function while taking as few samples as possible. This algorithm shows impressive performance on the standard control problem of double pole balancing. Finally, we describe how Gaussian processes can be used to efficiently estimate gradients of noisy functions, and numerically estimate integrals."
            },
            "slug": "Gaussian-Processes-for-Regression-and-Optimisation-Boyle",
            "title": {
                "fragments": [],
                "text": "Gaussian Processes for Regression and Optimisation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This thesis introduces sequential annealed importance sampling as a method for calculating model evidence in an on-line fashion as new data arrives and describes how Gaussian processes can be used to efficiently estimate gradients of noisy functions, and numerically estimate integrals."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32837403"
                        ],
                        "name": "J. Bergstra",
                        "slug": "J.-Bergstra",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bergstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bergstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": "To take advantage of this property, Bergstra and Bengio [17] proposed to simply use random search for optimizationVthe rationale being that points Shahriari et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 36
                            }
                        ],
                        "text": "To take advantage of this property, Bergstra and Bengio [17] proposed to simply use random search for optimization \u2013 the rationale being that points sampled uniformly at random in each dimension can densely cover each low-dimensional subspace."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "belief networks [17] and automatic configuration of state-of-the-art algorithms for solving NP-hard problems"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15700257,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "188e247506ad992b8bc62d6c74789e89891a984f",
            "isKey": true,
            "numCitedBy": 5726,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Grid search and manual search are the most widely used strategies for hyper-parameter optimization. This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid. Empirical evidence comes from a comparison with a large previous study that used grid search and manual search to configure neural networks and deep belief networks. Compared with neural networks configured by a pure grid search, we find that random search over the same domain is able to find models that are as good or better within a small fraction of the computation time. Granting random search the same computational budget, random search finds better models by effectively searching a larger, less promising configuration space. Compared with deep belief networks configured by a thoughtful combination of manual search and grid search, purely random search over the same 32-dimensional configuration space found statistically equal performance on four of seven data sets, and superior performance on one of seven. A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets. This phenomenon makes grid search a poor choice for configuring algorithms for new data sets. Our analysis casts some light on why recent \"High Throughput\" methods achieve surprising success--they appear to search through a large number of hyper-parameters because most hyper-parameters do not matter much. We anticipate that growing interest in large hierarchical models will place an increasing burden on techniques for hyper-parameter optimization; this work shows that random search is a natural baseline against which to judge progress in the development of adaptive (sequential) hyper-parameter optimization algorithms."
            },
            "slug": "Random-Search-for-Hyper-Parameter-Optimization-Bergstra-Bengio",
            "title": {
                "fragments": [],
                "text": "Random Search for Hyper-Parameter Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid, and shows that random search is a natural baseline against which to judge progress in the development of adaptive (sequential) hyper- parameter optimization algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680574"
                        ],
                        "name": "M. Seeger",
                        "slug": "M.-Seeger",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Seeger",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Seeger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145306271"
                        ],
                        "name": "Neil D. Lawrence",
                        "slug": "Neil-D.-Lawrence",
                        "structuredName": {
                            "firstName": "Neil",
                            "lastName": "Lawrence",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Neil D. Lawrence"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "1) Sparse pseudo-input Gaussian processes (SPGP): One early approach to modelling large n with Gaussian processes considered using m   n inducing pseudo-inputs to reduce the rank of the covariance matrix to m, resulting in a significant reduction in computational cost [137], [140]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 257,
                                "start": 252
                            }
                        ],
                        "text": "1) Sparse Pseudoinput Gaussian Processes (SPGPs): One early approach to modeling large n with GPs considered using m G n inducing pseudoinputs to reduce the rank of the covariance matrix to m, resulting in a significant reduction in computational cost [137], [140]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 142,
                                "start": 138
                            }
                        ],
                        "text": "In the seminal works on pseudo-input methods, the locations of the pseudo-inputs were selected to optimize the marginal likelihood of the SPGP [137], [140]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 141
                            }
                        ],
                        "text": "In the seminal works on pseudoinput methods, the locations of the pseudoinputs were selected to optimize the marginal likelihood of the SPGP [137], [140]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17404261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "145512a08a7cd79a0efb1f0503ddc6a4e4ef02dc",
            "isKey": true,
            "numCitedBy": 455,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a method for the sparse greedy approximation of Bayesian Gaussian process regression, featuring a novel heuristic for very fast forward selection. Our method is essentially as fast as an equivalent one which selects the \"support\" patterns at random, yet it can outperform random selection on hard curve fitting tasks. More importantly, it leads to a sufficiently stable approximation of the log marginal likelihood of the training data, which can be optimised to adjust a large number of hyperparameters automatically. We demonstrate the model selection capabilities of the algorithm in a range of experiments. In line with the development of our method, we present a simple view on sparse approximations for GP models and their underlying assumptions and show relations to other methods."
            },
            "slug": "Fast-Forward-Selection-to-Speed-Up-Sparse-Gaussian-Seeger-Williams",
            "title": {
                "fragments": [],
                "text": "Fast Forward Selection to Speed Up Sparse Gaussian Process Regression"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "A method for the sparse greedy approximation of Bayesian Gaussian process regression, featuring a novel heuristic for very fast forward selection, which leads to a sufficiently stable approximation of the log marginal likelihood of the training data, which can be optimised to adjust a large number of hyperparameters automatically."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144108062"
                        ],
                        "name": "Jasper Snoek",
                        "slug": "Jasper-Snoek",
                        "structuredName": {
                            "firstName": "Jasper",
                            "lastName": "Snoek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jasper Snoek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Snoek [142] and Gelbart et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[142] J."
                    },
                    "intents": []
                }
            ],
            "corpusId": 115316774,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e079604c7a00c43f06e214280cea18a89dcecef",
            "isKey": false,
            "numCitedBy": 41,
            "numCiting": 166,
            "paperAbstract": {
                "fragments": [],
                "text": "Bayesian Optimization and Semiparametric Models with Applications to Assistive Technology Jasper Snoek Doctor of Philosophy Graduate Department of Computer Science University of Toronto 2013 Advances in machine learning are having a profound impact on disciplines spanning the sciences. Assistive technology and health informatics are fields for which minor improvements achieved through leveraging more advanced machine learning algorithms can translate to major real world impact. However, successful application of machine learning currently requires broad domain knowledge to determine which model is appropriate for a given task, and model specific expertise to configure a model to a problem of interest. A major motivation for this thesis was: How can we make machine learning more accessible to assistive technology and health informatics researchers? Naturally, a complementary goal is to make machine learning more accessible in general. Specifically, in this thesis we explore how to automate the role of a machine learning expert through automatically adapting models and adjusting parameters to a given task of interest. This thesis consists of a number of contributions towards solving this challenging open problem in machine learning and these are empirically validated on four real-world applications. Through an interesting theoretical link between two seemingly disparate latent variable models, we create a hybrid model that allows one to flexibly interpolate over a parametric unsupervised neural network, a classification neural network and a non-parametric Gaussian process. We demonstrate empirically that this non-parametrically guided autoencoder allows one to learn a latent representation that is more useful for a given task of interest."
            },
            "slug": "Bayesian-Optimization-and-Semiparametric-Models-to-Snoek",
            "title": {
                "fragments": [],
                "text": "Bayesian Optimization and Semiparametric Models with Applications to Assistive Technology"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This thesis explores how to automate the role of a machine learning expert through automatically adapting models and adjusting parameters to a given task of interest, and creates a hybrid model that allows one to flexibly interpolate over a parametric unsupervised neural network, a classification neural network and a non-parametric Gaussian process."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388666962"
                        ],
                        "name": "M. L\u00e1zaro-Gredilla",
                        "slug": "M.-L\u00e1zaro-Gredilla",
                        "structuredName": {
                            "firstName": "Miguel",
                            "lastName": "L\u00e1zaro-Gredilla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. L\u00e1zaro-Gredilla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398493114"
                        ],
                        "name": "A. Figueiras-Vidal",
                        "slug": "A.-Figueiras-Vidal",
                        "structuredName": {
                            "firstName": "An\u00edbal",
                            "lastName": "Figueiras-Vidal",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Figueiras-Vidal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "Recently, such basis functions have also been learned from data by training deep belief networks [71], deep neural networks [93], [144], or by factoring the empirical covariance matrix of historical data [72], [146]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15691344,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22a0a54add27feb2d73dc727f58b69d0df4f4f4b",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "For regression tasks, traditional neural networks (NNs) have been superseded by Gaussian processes, which provide probabilistic predictions (input-dependent error bars), improved accuracy, and virtually no overfitting. Due to their high computational cost, in scenarios with massive data sets, one has to resort to sparse Gaussian processes, which strive to achieve similar performance with much smaller computational effort. In this context, we introduce a mixture of NNs with marginalized output weights that can both provide probabilistic predictions and improve on the performance of sparse Gaussian processes, at the same computational cost. The effectiveness of this approach is shown experimentally on some representative large data sets."
            },
            "slug": "Marginalized-Neural-Network-Mixtures-for-Regression-L\u00e1zaro-Gredilla-Figueiras-Vidal",
            "title": {
                "fragments": [],
                "text": "Marginalized Neural Network Mixtures for Large-Scale Regression"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A mixture of NNs with marginalized output weights that can both provide probabilistic predictions and improve on the performance of sparse Gaussian processes, at the same computational cost is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Neural Networks"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144180357"
                        ],
                        "name": "E. Brochu",
                        "slug": "E.-Brochu",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brochu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brochu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32951485"
                        ],
                        "name": "A. Ghosh",
                        "slug": "A.-Ghosh",
                        "structuredName": {
                            "firstName": "Abhijeet",
                            "lastName": "Ghosh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ghosh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[28] E."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In practice, the community has resorted to using various techniques such as discretization [143] and adaptive grids [13], or similarly, the divided rectangles approach of [83], which was used in [28], [105], and [110]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In [26] and [28], the authors use Bayesian optimization to set the parameters of several"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7062063,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "859d4b4b03cadff589164d71f97214a1c7b7b9b6",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an active learning algorithm that learns a continuous valuation model from discrete preferences. The algorithm automatically decides what items are best presented to an individual in order to find the item that they value highly in as few trials as possible, and exploits quirks of human psychology to minimize time and cognitive burden. To do this, our algorithm maximizes the expected improvement at each query without accurately modelling the entire valuation surface, which would be needlessly expensive. The problem is particularly difficult because the space of choices is infinite. We demonstrate the effectiveness of the new algorithm compared to related active learning methods. We also embed the algorithm within a decision making tool for assisting digital artists in rendering materials. The tool finds the best parameters while minimizing the number of queries."
            },
            "slug": "Active-Preference-Learning-with-Discrete-Choice-Brochu-Freitas",
            "title": {
                "fragments": [],
                "text": "Active Preference Learning with Discrete Choice Data"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "An active learning algorithm that learns a continuous valuation model from discrete preferences that maximizes the expected improvement at each query without accurately modelling the entire valuation surface, which would be needlessly expensive."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157110"
                        ],
                        "name": "Niranjan Srinivas",
                        "slug": "Niranjan-Srinivas",
                        "structuredName": {
                            "firstName": "Niranjan",
                            "lastName": "Srinivas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Niranjan Srinivas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145343838"
                        ],
                        "name": "Andreas Krause",
                        "slug": "Andreas-Krause",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Krause",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Krause"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144695232"
                        ],
                        "name": "S. Kakade",
                        "slug": "S.-Kakade",
                        "structuredName": {
                            "firstName": "Sham",
                            "lastName": "Kakade",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kakade"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680574"
                        ],
                        "name": "M. Seeger",
                        "slug": "M.-Seeger",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Seeger",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Seeger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 2
                            }
                        ],
                        "text": "The objective is to identify which arm of the bandit to pull, e.g., which drug to administer, which movie to recommend, or which advertisement to display."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 59031327,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c8413ab8de0c1b8f2e86402b8d737d94371610f",
            "isKey": false,
            "numCitedBy": 1656,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Many applications require optimizing an unknown, noisy function that is expensive to evaluate. We formalize this task as a multi-armed bandit problem, where the payoff function is either sampled from a Gaussian process (GP) or has low RKHS norm. We resolve the important open problem of deriving regret bounds for this setting, which imply novel convergence rates for GP optimization. We analyze GP-UCB, an intuitive upper-confidence based algorithm, and bound its cumulative regret in terms of maximal information gain, establishing a novel connection between GP optimization and experimental design. Moreover, by bounding the latter in terms of operator spectra, we obtain explicit sublinear regret bounds for many commonly used covariance functions. In some important cases, our bounds have surprisingly weak dependence on the dimensionality. In our experiments on real sensor data, GP-UCB compares favorably with other heuristical GP optimization approaches."
            },
            "slug": "Gaussian-Process-Optimization-in-the-Bandit-No-and-Srinivas-Krause",
            "title": {
                "fragments": [],
                "text": "Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work analyzes GP-UCB, an intuitive upper-confidence based algorithm, and bound its cumulative regret in terms of maximal information gain, establishing a novel connection between GP optimization and experimental design and obtaining explicit sublinear regret bounds for many commonly used covariance functions."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2081889"
                        ],
                        "name": "Edward Snelson",
                        "slug": "Edward-Snelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Snelson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edward Snelson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744700"
                        ],
                        "name": "Zoubin Ghahramani",
                        "slug": "Zoubin-Ghahramani",
                        "structuredName": {
                            "firstName": "Zoubin",
                            "lastName": "Ghahramani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zoubin Ghahramani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 264,
                                "start": 259
                            }
                        ],
                        "text": "1) Sparse Pseudoinput Gaussian Processes (SPGPs): One early approach to modeling large n with GPs considered using m G n inducing pseudoinputs to reduce the rank of the covariance matrix to m, resulting in a significant reduction in computational cost [137], [140]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 148
                            }
                        ],
                        "text": "In the seminal works on pseudoinput methods, the locations of the pseudoinputs were selected to optimize the marginal likelihood of the SPGP [137], [140]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 394337,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b6a2d80854651a56e0f023543131744f14f20ab4",
            "isKey": false,
            "numCitedBy": 1512,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new Gaussian process (GP) regression model whose co-variance is parameterized by the the locations of M pseudo-input points, which we learn by a gradient based optimization. We take M \u226a N, where N is the number of real data points, and hence obtain a sparse regression method which has O(M2N) training cost and O(M2) prediction cost per test case. We also find hyperparameters of the covariance function in the same joint optimization. The method can be viewed as a Bayesian regression model with particular input dependent noise. The method turns out to be closely related to several other sparse GP approaches, and we discuss the relation in detail. We finally demonstrate its performance on some large data sets, and make a direct comparison to other sparse GP methods. We show that our method can match full GP performance with small M, i.e. very sparse solutions, and it significantly outperforms other approaches in this regime."
            },
            "slug": "Sparse-Gaussian-Processes-using-Pseudo-inputs-Snelson-Ghahramani",
            "title": {
                "fragments": [],
                "text": "Sparse Gaussian Processes using Pseudo-inputs"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "It is shown that this new Gaussian process (GP) regression model can match full GP performance with small M, i.e. very sparse solutions, and it significantly outperforms other approaches in this regime."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690162"
                        ],
                        "name": "D. Lizotte",
                        "slug": "D.-Lizotte",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lizotte",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lizotte"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143686063"
                        ],
                        "name": "R. Greiner",
                        "slug": "R.-Greiner",
                        "structuredName": {
                            "firstName": "Russell",
                            "lastName": "Greiner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Greiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714772"
                        ],
                        "name": "Dale Schuurmans",
                        "slug": "Dale-Schuurmans",
                        "structuredName": {
                            "firstName": "Dale",
                            "lastName": "Schuurmans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dale Schuurmans"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 124
                            }
                        ],
                        "text": "When gradients are available, or can be cheaply approximated, one can use a multistarted quasiNewton hill-climbing approach [100], [143]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2568005,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "004c4ea284409e9ae338147bdd4f4d2aae955fd3",
            "isKey": false,
            "numCitedBy": 52,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Response surface methods, and global optimization techniques in general, are typically evaluated using a small number of standard synthetic test problems, in the hope that these are a good surrogate for real-world problems. We introduce a new, more rigorous methodology for evaluating global optimization techniques that is based on generating thousands of test functions and then evaluating algorithm performance on each one. The test functions are generated by sampling from a Gaussian process, which allows us to create a set of test functions that are interesting and diverse. They will have different numbers of modes, different maxima, etc., and yet they will be similar to each other in overall structure and level of difficulty. This approach allows for a much richer empirical evaluation of methods that is capable of revealing insights that would not be gained using a small set of test functions. To facilitate the development of large empirical studies for evaluating response surface methods, we introduce a dimension-independent measure of average test problem difficulty, and we introduce acquisition criteria that are invariant to vertical shifting and scaling of the objective function. We also use our experimental methodology to conduct a large empirical study of response surface methods. We investigate the influence of three properties\u2014parameter estimation, exploration level, and gradient information\u2014on the performance of response surface methods."
            },
            "slug": "An-experimental-methodology-for-response-surface-Lizotte-Greiner",
            "title": {
                "fragments": [],
                "text": "An experimental methodology for response surface optimization methods"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A dimension-independent measure of average test problem difficulty is introduced, and the influence of three properties\u2014parameter estimation, exploration level, and gradient information\u2014on the performance of response surface methods are investigated."
            },
            "venue": {
                "fragments": [],
                "text": "J. Glob. Optim."
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690162"
                        ],
                        "name": "D. Lizotte",
                        "slug": "D.-Lizotte",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lizotte",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lizotte"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2155450432"
                        ],
                        "name": "Tao Wang",
                        "slug": "Tao-Wang",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687780"
                        ],
                        "name": "Michael Bowling",
                        "slug": "Michael-Bowling",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bowling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Bowling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714772"
                        ],
                        "name": "Dale Schuurmans",
                        "slug": "Dale-Schuurmans",
                        "structuredName": {
                            "firstName": "Dale",
                            "lastName": "Schuurmans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dale Schuurmans"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 128
                            }
                        ],
                        "text": "In this section, we cover several such models, but for the sake of clarity, we first consider a generic family of models parameterized by w."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10441616,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d89e23d3267c75db75e2055951facc2d74f2908b",
            "isKey": false,
            "numCitedBy": 274,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Gait optimization is a basic yet challenging problem for both quadrupedal and bipedal robots. Although techniques for automating the process exist, most involve local function optimization procedures that suffer from three key drawbacks. Local optimization techniques are naturally plagued by local optima, make no use of the expensive gait evaluations once a local step is taken, and do not explicitly model noise in gait evaluation. These drawbacks increase the need for a large number of gait evaluations, making optimization slow, data inefficient, and manually intensive. We present a Bayesian approach based on Gaussian process regression that addresses all three drawbacks. It uses a global search strategy based on a posterior model inferred from all of the individual noisy evaluations. We demonstrate the technique on a quadruped robot, using it to optimize two different criteria: speed and smoothness. We show in both cases our technique requires dramatically fewer gait evaluations than state-of-the-art local gradient approaches."
            },
            "slug": "Automatic-Gait-Optimization-with-Gaussian-Process-Lizotte-Wang",
            "title": {
                "fragments": [],
                "text": "Automatic Gait Optimization with Gaussian Process Regression"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A Bayesian approach based on Gaussian process regression that addresses all three drawbacks of local optimization procedures, using a global search strategy based on a posterior model inferred from all of the individual noisy evaluations."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107327555"
                        ],
                        "name": "D. Huang",
                        "slug": "D.-Huang",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "115429409"
                        ],
                        "name": "T. Allen",
                        "slug": "T.-Allen",
                        "structuredName": {
                            "firstName": "Theodore",
                            "lastName": "Allen",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Allen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50238440"
                        ],
                        "name": "W. Notz",
                        "slug": "W.-Notz",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Notz",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Notz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065868465"
                        ],
                        "name": "N. Zheng",
                        "slug": "N.-Zheng",
                        "structuredName": {
                            "firstName": "Ning",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Zheng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "body of work devoted to extending the algorithm, particularly in adding constraints to the optimization problem [6], [23], [131], and in modeling noisy functions [14], [75], [76]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[75] D."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14688276,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c51104c58c3e05f487d87ee94ce2e3b2d11dce6",
            "isKey": false,
            "numCitedBy": 584,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new method that extends the efficient global optimization to address stochastic black-box systems. The method is based on a kriging meta-model that provides a global prediction of the objective values and a measure of prediction uncertainty at every point. The criterion for the infill sample selection is an augmented expected improvement function with desirable properties for stochastic responses. The method is empirically compared with the revised simplex search, the simultaneous perturbation stochastic approximation, and the DIRECT methods using six test problems from the literature. An application case study on an inventory system is also documented. The results suggest that the proposed method has excellent consistency and efficiency in finding global optimal solutions, and is particularly useful for expensive systems."
            },
            "slug": "Global-Optimization-of-Stochastic-Black-Box-Systems-Huang-Allen",
            "title": {
                "fragments": [],
                "text": "Global Optimization of Stochastic Black-Box Systems via Sequential Kriging Meta-Models"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "The proposed method is based on a kriging meta-model that provides a global prediction of the objective values and a measure of prediction uncertainty at every point and has excellent consistency and efficiency in finding global optimal solutions."
            },
            "venue": {
                "fragments": [],
                "text": "J. Glob. Optim."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38742457"
                        ],
                        "name": "A. Bull",
                        "slug": "A.-Bull",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Bull",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bull"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 29
                            }
                        ],
                        "text": "Since the pioneering work of [32] and [146], there"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 165
                            }
                        ],
                        "text": "Bayesian optimization algorithms because theoretical guarantees are only valid with the assumption that the exact optimizer is found and selected; see, for example, [32], [146], and [154]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "In [32], Bull provided both upper and lower bounds of simple regret for the EGO algorithm [82] in the deterministic setting."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 149
                            }
                        ],
                        "text": "These improvement strategies have been empirically studied in the literature [27], [81], [82] and recently convergence rates have been proven for EI [32]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 136
                            }
                        ],
                        "text": "The typical estimation of the hyperparameters by maximizing the marginal likelihood [82], [126] can easily fall into traps, as shown in [32]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6229688,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "81f9e2051a47ab85e90f5f19256d2b113aea4f9b",
            "isKey": true,
            "numCitedBy": 445,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Efficient global optimization is the problem of minimizing an unknown function f, using as few evaluations f(x) as possible. It can be considered as a continuum-armed bandit problem, with noiseless data and simple regret. Expected improvement is perhaps the most popular method for solving this problem; the algorithm performs well in experiments, but little is known about its theoretical properties. Implementing expected improvement requires a choice of Gaussian process prior, which determines an associated space of functions, its reproducing-kernel Hilbert space (RKHS). When the prior is fixed, expected improvement is known to converge on the minimum of any function in the RKHS. We begin by providing convergence rates for this procedure. The rates are optimal for functions of low smoothness, and we modify the algorithm to attain optimal rates for smoother functions. For practitioners, however, these results are somewhat misleading. Priors are typically not held fixed, but depend on parameters estimated from the data. For standard estimators, we show this procedure may never discover the minimum of f. We then propose alternative estimators, chosen to minimize the constants in the rate of convergence, and show these estimators retain the convergence rates of a fixed prior."
            },
            "slug": "Convergence-Rates-of-Efficient-Global-Optimization-Bull",
            "title": {
                "fragments": [],
                "text": "Convergence Rates of Efficient Global Optimization Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work provides convergence rates for expected improvement, and proposes alternative estimators, chosen to minimize the constants in the rate of convergence, and shows these estimators retain the convergence rates of a fixed prior."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2093514322"
                        ],
                        "name": "Nimalan Mahendran",
                        "slug": "Nimalan-Mahendran",
                        "structuredName": {
                            "firstName": "Nimalan",
                            "lastName": "Mahendran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nimalan Mahendran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117966548"
                        ],
                        "name": "Ziyun Wang",
                        "slug": "Ziyun-Wang",
                        "structuredName": {
                            "firstName": "Ziyun",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ziyun Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1811875"
                        ],
                        "name": "F. Hamze",
                        "slug": "F.-Hamze",
                        "structuredName": {
                            "firstName": "Firas",
                            "lastName": "Hamze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hamze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 55
                            }
                        ],
                        "text": "This rapidly becomes infeasible in the large spaces of realworld problems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18013276,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e37bb83b713e3b83706dfc0ee807bb497ed3873f",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new randomized strategy for adaptive MCMC using Bayesian optimization. This approach applies to nondifferentiable objective functions and trades off exploration and exploitation to reduce the number of potentially costly objective function evaluations. We demonstrate the strategy in the complex setting of sampling from constrained, discrete and densely connected probabilistic graphical models where, for each variation of the problem, one needs to adjust the parameters of the proposal mechanism automatically to ensure efficient mixing of the Markov chains."
            },
            "slug": "Adaptive-MCMC-with-Bayesian-Optimization-Mahendran-Wang",
            "title": {
                "fragments": [],
                "text": "Adaptive MCMC with Bayesian Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A new randomized strategy for adaptive MCMC using Bayesian optimization applies to nondifferentiable objective functions and trades off exploration and exploitation to reduce the number of potentially costly objective function evaluations."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114746099"
                        ],
                        "name": "D. Busby",
                        "slug": "D.-Busby",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Busby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Busby"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11311226,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b10547c6ff093c24d30835389b86cfe778100554",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Hierarchical-adaptive-experimental-design-for-Busby",
            "title": {
                "fragments": [],
                "text": "Hierarchical adaptive experimental design for Gaussian process emulators"
            },
            "venue": {
                "fragments": [],
                "text": "Reliab. Eng. Syst. Saf."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755465"
                        ],
                        "name": "Dani Yogatama",
                        "slug": "Dani-Yogatama",
                        "structuredName": {
                            "firstName": "Dani",
                            "lastName": "Yogatama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dani Yogatama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2482936"
                        ],
                        "name": "Gideon S. Mann",
                        "slug": "Gideon-S.-Mann",
                        "structuredName": {
                            "firstName": "Gideon",
                            "lastName": "Mann",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gideon S. Mann"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 83
                            }
                        ],
                        "text": "property within the Bayesian optimization framework [12], [49], [79], [89], [148], [160]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 319311,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d289c568cf52f9b448e81e5fdfbbac9f99c3090",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a fast and effective algorithm for automatic hyperparameter tuning that can generalize across datasets. Our method is an instance of sequential model-based optimization (SMBO) that transfers information by constructing a common response surface for all datasets, similar to Bardenet et al. (2013). The time complexity of reconstructing the response surface at every SMBO iteration in our method is linear in the number of trials (significantly less than previous work with comparable performance), allowing the method to realistically scale to many more datasets. Specifically, we use deviations from the per-dataset mean as the response values. We empirically show the superiority of our method on a large number of synthetic and real-world datasets for tuning hyperparameters of logistic regression and ensembles of classifiers."
            },
            "slug": "Efficient-Transfer-Learning-Method-for-Automatic-Yogatama-Mann",
            "title": {
                "fragments": [],
                "text": "Efficient Transfer Learning Method for Automatic Hyperparameter Tuning"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This work proposes a fast and effective algorithm for automatic hyperparameter tuning that can generalize across datasets and empirically shows the superiority of the method on a large number of synthetic and real-world datasets for tuning hyperparameters of logistic regression and ensembles of classifiers."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1888911"
                        ],
                        "name": "S. Digabel",
                        "slug": "S.-Digabel",
                        "structuredName": {
                            "firstName": "S\u00e9bastien",
                            "lastName": "Digabel",
                            "middleNames": [
                                "Le"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Digabel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2388276"
                        ],
                        "name": "R. Gramacy",
                        "slug": "R.-Gramacy",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Gramacy",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Gramacy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2414557"
                        ],
                        "name": "G. A. Gray",
                        "slug": "G.-A.-Gray",
                        "structuredName": {
                            "firstName": "Genetha",
                            "lastName": "Gray",
                            "middleNames": [
                                "Anne"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. A. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48723705"
                        ],
                        "name": "Herbert K. H. Lee",
                        "slug": "Herbert-K.-H.-Lee",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Lee",
                            "middleNames": [
                                "K.",
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Herbert K. H. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2925446"
                        ],
                        "name": "P. Ranjan",
                        "slug": "P.-Ranjan",
                        "structuredName": {
                            "firstName": "Pritam",
                            "lastName": "Ranjan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Ranjan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1417669773"
                        ],
                        "name": "Garth Weels",
                        "slug": "Garth-Weels",
                        "structuredName": {
                            "firstName": "Garth",
                            "lastName": "Weels",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Garth Weels"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4583616"
                        ],
                        "name": "Stefan M. Wild",
                        "slug": "Stefan-M.-Wild",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Wild",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefan M. Wild"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17822854,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4955ab553c8ed1adb55325a26c75d837e0e471b4",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Constrained blackbox optimization is a difficult problem, with most approaches coming from the mathematical programming literature. The statistical literature is sparse, especially in addressing problems with nontrivial constraints. This situation is unfortunate because statistical methods have many attractive properties: global scope, handling noisy objectives, sensitivity analysis, and so forth. To narrow that gap, we propose a combination of response surface modeling, expected improvement, and the augmented Lagrangian numerical optimization framework. This hybrid approach allows the statistical model to think globally and the augmented Lagrangian to act locally. We focus on problems where the constraints are the primary bottleneck, requiring expensive simulation to evaluate and substantial modeling effort to map out. In that context, our hybridization presents a simple yet effective solution that allows existing objective-oriented statistical approaches, like those based on Gaussian process surrogates and expected improvement heuristics, to be applied to the constrained setting with minor modification. This work is motivated by a challenging, real-data benchmark problem from hydrology where, even with a simple linear objective function, learning a nontrivial valid region complicates the search for a global minimum."
            },
            "slug": "Modeling-an-augmented-Lagrangian-for-improved-Digabel-Gramacy",
            "title": {
                "fragments": [],
                "text": "Modeling an augmented Lagrangian for improved blackbox constrained optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This hybridization presents a simple yet effective solution that allows existing objective-oriented statistical approaches, like those based on Gaussian process surrogates and expected improvement heuristics, to be applied to the constrained setting with minor modification."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3472959"
                        ],
                        "name": "C. Rasmussen",
                        "slug": "C.-Rasmussen",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Rasmussen",
                            "middleNames": [
                                "Edward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rasmussen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 90
                            }
                        ],
                        "text": "The typical estimation of the hyperparameters by maximizing the marginal likelihood [82], [126] can easily fall into traps, as shown in [32]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 168
                            }
                        ],
                        "text": "GP\u00f0 0; k\u00de is a nonparametric model that is fully characterized by its prior mean function 0 : X7!R and its positive\u2013definite kernel, or covariance function, k : X X7!R [126]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 105
                            }
                        ],
                        "text": "There are many other examples of nonstationary covariance functions [3], [22], [54], [70], [118], [121], [126], [132] that have been proposed for GP regression along with closely related output warping techniques [141] that can also model certain kinds of nonstationary processes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 148
                            }
                        ],
                        "text": "These kernels are parameterized by a smoothness parameter > 0, so called because samples from a GP with such a kernel are differentiable b 1c times [126]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1430472,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82266f6103bade9005ec555ed06ba20b5210ff22",
            "isKey": true,
            "numCitedBy": 18076,
            "numCiting": 231,
            "paperAbstract": {
                "fragments": [],
                "text": "Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received growing attention in the machine learning community over the past decade. The book provides a long-needed, systematic and unified treatment of theoretical and practical aspects of GPs in machine learning. The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics. The book deals with the supervised learning problem for both regression and classification, and includes detailed algorithms. A wide variety of covariance (kernel) functions are presented and their properties discussed. Model selection is discussed both from a Bayesian and classical perspective. Many connections to other well-known techniques from machine learning and statistics are discussed, including support vector machines, neural networks, splines, regularization networks, relevance vector machines and others. Theoretical issues including learning curves and the PAC-Bayesian framework are treated, and several approximation methods for learning with large datasets are discussed. The book contains illustrative examples and exercises. Code and datasets can be obtained on the web. Appendices provide mathematical background and a discussion of Gaussian Markov processes."
            },
            "slug": "Gaussian-Processes-for-Machine-Learning-Rasmussen-Williams",
            "title": {
                "fragments": [],
                "text": "Gaussian Processes for Machine Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics, and deals with the supervised learning problem for both regression and classification."
            },
            "venue": {
                "fragments": [],
                "text": "Adaptive computation and machine learning"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3124107"
                        ],
                        "name": "S. L. Scott",
                        "slug": "S.-L.-Scott",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Scott",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. L. Scott"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally, we introduce more recent developments in Section VIII."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 50
                            }
                        ],
                        "text": "In the generalized linear model, Thompson sampling draws a w\u0303 from the posterior p(w | Dn) using MCMC or a Laplace approximation, and then selects the arm with the highest expected reward given the sampled parameter w\u0303, i.e., an+1 = arg maxa g \u22121(xTa w\u0303)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 573750,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "edc92399f12c2f4f9c232feab790e7015c5ec36b",
            "isKey": false,
            "numCitedBy": 418,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "A multi-armed bandit is an experiment with the goal of accumulating rewards from a payoff distribution with unknown parameters that are to be learned sequentially. This article describes a heuristic for managing multi-armed bandits called randomized probability matching, which randomly allocates observations to arms according the Bayesian posterior probability that each arm is optimal. Advances in Bayesian computation have made randomized probability matching easy to apply to virtually any payoff distribution. This flexibility frees the experimenter to work with payoff distributions that correspond to certain classical experimental designs that have the potential to outperform methods that are \u2018optimal\u2019 in simpler contexts. I summarize the relationships between randomized probability matching and several related heuristics that have been used in the reinforcement learning literature. Copyright \u00a9 2010 John Wiley & Sons, Ltd."
            },
            "slug": "A-modern-Bayesian-look-at-the-multi-armed-bandit-Scott",
            "title": {
                "fragments": [],
                "text": "A modern Bayesian look at the multi-armed bandit"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A heuristic for managing multi-armed bandits called randomized probability matching is described, which randomly allocates observations to arms according the Bayesian posterior probability that each arm is optimal."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49600153"
                        ],
                        "name": "M. Locatelli",
                        "slug": "M.-Locatelli",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Locatelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Locatelli"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[102] M."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "There exist several early consistency proofs for GPbased Bayesian optimization algorithms, in the 1-D setting [102] and one for a simplification of the algorithm using"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 35799038,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "b94597ae958ed215bf57035774759fa8e5d89156",
            "isKey": false,
            "numCitedBy": 122,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper Bayesian analysis and Wiener process are used in orderto build an algorithm to solve the problem of globaloptimization.The paper is divided in two main parts.In the first part an already known algorithm is considered: a new (Bayesian)stopping ruleis added to it and some results are given, such asan upper bound for the number of iterations under the new stopping rule.In the second part a new algorithm is introduced in which the Bayesianapproach is exploited not onlyin the choice of the Wiener model but also in the estimationof the parameter \u03c32 of the Wiener process, whose value appears to bequite crucial.Some results about this algorithm are also given."
            },
            "slug": "Bayesian-Algorithms-for-One-Dimensional-Global-Locatelli",
            "title": {
                "fragments": [],
                "text": "Bayesian Algorithms for One-Dimensional Global Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "In this paper Bayesian analysis and Wiener process are used in orderto build an algorithm to solve the problem of globaloptimization and the Bayesian approach is exploited not only in the choice of the Wiener model but also in the estimation of the parameter \u03c32 of theWiener process."
            },
            "venue": {
                "fragments": [],
                "text": "J. Glob. Optim."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2941141"
                        ],
                        "name": "Josip Djolonga",
                        "slug": "Josip-Djolonga",
                        "structuredName": {
                            "firstName": "Josip",
                            "lastName": "Djolonga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josip Djolonga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145343838"
                        ],
                        "name": "Andreas Krause",
                        "slug": "Andreas-Krause",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Krause",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Krause"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678641"
                        ],
                        "name": "V. Cevher",
                        "slug": "V.-Cevher",
                        "structuredName": {
                            "firstName": "Volkan",
                            "lastName": "Cevher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Cevher"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 129
                            }
                        ],
                        "text": "bandits [89]; Bayes regret bounds for TS [85], [127]; bounds for high-dimensional problems with an underlying low-rank structure [46]; bounds for parallel Bayesian optimization [45]; and improved regret bounds using mutual information [41]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6794317,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d707502c9257ad843fb9dea35664c0c98b3ea4f7",
            "isKey": false,
            "numCitedBy": 141,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Many applications in machine learning require optimizing unknown functions defined over a high-dimensional space from noisy samples that are expensive to obtain. We address this notoriously hard challenge, under the assumptions that the function varies only along some low-dimensional subspace and is smooth (i.e., it has a low norm in a Reproducible Kernel Hilbert Space). In particular, we present the SI-BO algorithm, which leverages recent low-rank matrix recovery techniques to learn the underlying subspace of the unknown function and applies Gaussian Process Upper Confidence sampling for optimization of the function. We carefully calibrate the exploration-exploitation tradeoff by allocating the sampling budget to subspace estimation and function optimization, and obtain the first subexponential cumulative regret bounds and convergence rates for Bayesian optimization in high-dimensions under noisy observations. Numerical results demonstrate the effectiveness of our approach in difficult scenarios."
            },
            "slug": "High-Dimensional-Gaussian-Process-Bandits-Djolonga-Krause",
            "title": {
                "fragments": [],
                "text": "High-Dimensional Gaussian Process Bandits"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The SI-BO algorithm is presented, which leverages recent low-rank matrix recovery techniques to learn the underlying subspace of the unknown function and applies Gaussian Process Upper Confidence sampling for optimization of the function."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423230"
                        ],
                        "name": "L. Breiman",
                        "slug": "L.-Breiman",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Breiman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Breiman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 140
                            }
                        ],
                        "text": "More precisely, the random forest is an ensemble method where the weak learners are decision trees trained on random subsamples of the data [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "Introduced in 2001 [24], random forests are a class of scalable and highly parallelizable regression models that have been very successful in practice [42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 89141,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13d4c2f76a7c1a4d0a71204e1d5d263a3f5a7986",
            "isKey": false,
            "numCitedBy": 65885,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund & R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148\u2013156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression."
            },
            "slug": "Random-Forests-Breiman",
            "title": {
                "fragments": [],
                "text": "Random Forests"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the forest, and are also applicable to regression."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2074161150"
                        ],
                        "name": "Scott C. Clark",
                        "slug": "Scott-C.-Clark",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Clark",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott C. Clark"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "Similar approaches are proposed in [40] and [58] and a similar parallel extension to GP-UCB is proposed in [45]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60964231,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "fd7d3da4504e7ca7f8794633c131986a56126d71",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "There is a need for general-purpose methods for objectively evaluating the quality of single and metagenome assemblies, and for automatically detecting any errors they may contain. Current methods do not fully meet this need because they require a reference, only consider one of the many aspects of assembly quality, or lack statistical justification; none are designed to evaluate metagenome assemblies. In this work we present an Assembly Likelihood Evaluation (ALE) framework that overcomes these limitations, systematically evaluating the accuracy of an assembly in a reference-independent manner using rigorous statistical methods. This framework is comprehensive, and integrates read quality, mate pair orientation and insert length (for paired end reads), sequencing coverage, read alignment, and k-mer frequency. ALE pinpoints synthetic and real errors in both single and metagenomic assemblies, including single-base errors, insertions/deletions, genome rearrangements and chimeric assemblies presented in metagenomes. The ALE framework provides a comprehensive, reference-independent and statistically rigorous measure of single genome and metagenome assembly quality, which can be used to identify miss-assemblies or to optimize the assembly process."
            },
            "slug": "Parallel-Machine-Learning-Algorithms-In-And-Global-Clark",
            "title": {
                "fragments": [],
                "text": "Parallel Machine Learning Algorithms In Bioinformatics And Global Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work presents an Assembly Likelihood Evaluation (ALE) framework, a comprehensive, reference-independent and statistically rigorous measure of single genome and metagenome assembly quality, which can be used to identify miss-assemblies or to optimize the assembly process."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746871"
                        ],
                        "name": "K. Kersting",
                        "slug": "K.-Kersting",
                        "structuredName": {
                            "firstName": "Kristian",
                            "lastName": "Kersting",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kersting"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795065"
                        ],
                        "name": "C. Plagemann",
                        "slug": "C.-Plagemann",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Plagemann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Plagemann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2024042"
                        ],
                        "name": "P. Pfaff",
                        "slug": "P.-Pfaff",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Pfaff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Pfaff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725973"
                        ],
                        "name": "W. Burgard",
                        "slug": "W.-Burgard",
                        "structuredName": {
                            "firstName": "Wolfram",
                            "lastName": "Burgard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Burgard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", [86], [95], and"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[86] K."
                    },
                    "intents": []
                }
            ],
            "corpusId": 3332913,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0d24b4407a1abae48633de29b2722000984476f",
            "isKey": false,
            "numCitedBy": 294,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel Gaussian process (GP) approach to regression with input-dependent noise rates. We follow Goldberg et al.'s approach and model the noise variance using a second GP in addition to the GP governing the noise-free output value. In contrast to Goldberg et al., however, we do not use a Markov chain Monte Carlo method to approximate the posterior noise variance but a most likely noise approach. The resulting model is easy to implement and can directly be used in combination with various existing extensions of the standard GPs such as sparse approximations. Extensive experiments on both synthetic and real-world data, including a challenging perception problem in robotics, show the effectiveness of most likely heteroscedastic GP regression."
            },
            "slug": "Most-likely-heteroscedastic-Gaussian-process-Kersting-Plagemann",
            "title": {
                "fragments": [],
                "text": "Most likely heteroscedastic Gaussian process regression"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "This paper follows Goldberg et al.'s approach and model the noise variance using a second GP in addition to the GP governing the noise-free output value, using a Markov chain Monte Carlo method to approximate the posterior noise variance."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145751896"
                        ],
                        "name": "Daniel Russo",
                        "slug": "Daniel-Russo",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Russo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Russo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731282"
                        ],
                        "name": "Benjamin Van Roy",
                        "slug": "Benjamin-Van-Roy",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Van Roy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin Van Roy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In the generalized linear model, Thompson sampling draws a w\u0303 from the posterior p(w | Dn) using MCMC or a Laplace approximation, and then selects the arm with the highest expected reward given the sampled parameter w\u0303, i.e., an+1 = arg maxa g \u22121(xTa w\u0303)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5468643,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "28cf1bd6110e734e20fc63f727d0d5bba612b921",
            "isKey": false,
            "numCitedBy": 510,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper considers the use of a simple posterior sampling algorithm to balance between exploration and exploitation when learning to optimize actions such as in multiarmed bandit problems. The algorithm, also known as Thompson Sampling and as probability matching, offers significant advantages over the popular upper confidence bound (UCB) approach, and can be applied to problems with finite or infinite action spaces and complicated relationships among action rewards. We make two theoretical contributions. The first establishes a connection between posterior sampling and UCB algorithms. This result lets us convert regret bounds developed for UCB algorithms into Bayesian regret bounds for posterior sampling. Our second theoretical contribution is a Bayesian regret bound for posterior sampling that applies broadly and can be specialized to many model classes. This bound depends on a new notion we refer to as the eluder dimension, which measures the degree of dependence among action rewards. Compared to UCB..."
            },
            "slug": "Learning-to-Optimize-via-Posterior-Sampling-Russo-Roy",
            "title": {
                "fragments": [],
                "text": "Learning to Optimize via Posterior Sampling"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A Bayesian regret bound for posterior sampling is made that applies broadly and can be specialized to many model classes and depends on a new notion the authors refer to as the eluder dimension, which measures the degree of dependence among action rewards."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Oper. Res."
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Bo Chen",
                        "slug": "Bo-Chen",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143683066"
                        ],
                        "name": "R. Castro",
                        "slug": "R.-Castro",
                        "structuredName": {
                            "firstName": "Rui",
                            "lastName": "Castro",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Castro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145343838"
                        ],
                        "name": "Andreas Krause",
                        "slug": "Andreas-Krause",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Krause",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Krause"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[39] made significant progress by introducing a two stage strategy for optimization and variable selection of high-dimensional GPs."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6314510,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c416b2d027bcd82633f39f869750e0458a06f1ab",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Maximizing high-dimensional, nonconvex functions through noisy observations is a notoriously hard problem, but one that arises in many applications. In this paper, we tackle this challenge by modeling the unknown function as a sample from a high-dimensional Gaussian process (GP) distribution. Assuming that the unknown function only depends on few relevant variables, we show that it is possible to perform joint variable selection and GP optimization. We provide strong performance guarantees for our algorithm, bounding the sample complexity of variable selection, and as well as providing cumulative regret bounds. We further provide empirical evidence on the effectiveness of our algorithm on several benchmark optimization problems."
            },
            "slug": "Joint-Optimization-and-Variable-Selection-of-Chen-Castro",
            "title": {
                "fragments": [],
                "text": "Joint Optimization and Variable Selection of High-dimensional Gaussian Processes"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper modeling the unknown function as a sample from a high-dimensional Gaussian process (GP) distribution shows that it is possible to perform joint variable selection and GP optimization and provides strong performance guarantees for the algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144543541"
                        ],
                        "name": "P. Auer",
                        "slug": "P.-Auer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Auer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Auer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 84
                            }
                        ],
                        "text": "Originally, the upper confidence was given by frequentist Chernoff\u2013Hoeffding bounds [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 108
                            }
                        ],
                        "text": "Auer studied these bounds using frequentist techniques, and in adversarial multi-armed bandit settings [9], [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10485293,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "103f6fe35033f9327611ddafde74a2b544072980",
            "isKey": false,
            "numCitedBy": 1420,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "We show how a standard tool from statistics --- namely confidence bounds --- can be used to elegantly deal with situations which exhibit an exploitation-exploration trade-off. Our technique for designing and analyzing algorithms for such situations is general and can be applied when an algorithm has to make exploitation-versus-exploration decisions based on uncertain information provided by a random process. We apply our technique to two models with such an exploitation-exploration trade-off. For the adversarial bandit problem with shifting our new algorithm suffers only O((ST)1/2) regret with high probability over T trials with S shifts. Such a regret bound was previously known only in expectation. The second model we consider is associative reinforcement learning with linear value functions. For this model our technique improves the regret from O(T3/4) to O(T1/2)."
            },
            "slug": "Using-Confidence-Bounds-for-Trade-offs-Auer",
            "title": {
                "fragments": [],
                "text": "Using Confidence Bounds for Exploitation-Exploration Trade-offs"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "It is shown how a standard tool from statistics, namely confidence bounds, can be used to elegantly deal with situations which exhibit an exploitation-exploration trade-off, and improves the regret from O(T3/4) to T1/2."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2517795"
                        ],
                        "name": "Philipp Hennig",
                        "slug": "Philipp-Hennig",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Hennig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Hennig"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1814533"
                        ],
                        "name": "Christian J. Schuler",
                        "slug": "Christian-J.-Schuler",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Schuler",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian J. Schuler"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 121
                            }
                        ],
                        "text": "More recent work uses a discretization of the X to obtain a smooth approximation to p? and its expected information gain [67]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 115
                            }
                        ],
                        "text": "x by selecting the point that is expected to cause the largest reduction in entropy of the distribution p?\u00f0x j Dn\u00de [67], [69], [155]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 131
                            }
                        ],
                        "text": "If the meta-criterion ESP\u00f0xjDn\u00de were minimized over the entire space X , ESP would reduce to the acquisition functions proposed by [67], [69], and [155]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 166832,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "510ebe952f10eb5401f65fe5e31aee5bfa72322d",
            "isKey": false,
            "numCitedBy": 475,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Contemporary global optimization algorithms are based on local measures of utility, rather than a probability measure over location and value of the optimum. They thus attempt to collect low function values, not to learn about the optimum. The reason for the absence of probabilistic global optimizers is that the corresponding inference problem is intractable in several ways. This paper develops desiderata for probabilistic optimization algorithms, then presents a concrete algorithm which addresses each of the computational intractabilities with a sequence of approximations and explicitly addresses the decision problem of maximizing information gain from each evaluation."
            },
            "slug": "Entropy-Search-for-Information-Efficient-Global-Hennig-Schuler",
            "title": {
                "fragments": [],
                "text": "Entropy Search for Information-Efficient Global Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper develops desiderata for probabilistic optimization algorithms, then presents a concrete algorithm which addresses each of the computational intractabilities with a sequence of approximations and explicitly addresses the decision problem of maximizing information gain from each evaluation."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754860"
                        ],
                        "name": "Kevin Swersky",
                        "slug": "Kevin-Swersky",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Swersky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Swersky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144108062"
                        ],
                        "name": "Jasper Snoek",
                        "slug": "Jasper-Snoek",
                        "structuredName": {
                            "firstName": "Jasper",
                            "lastName": "Snoek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jasper Snoek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722180"
                        ],
                        "name": "Ryan P. Adams",
                        "slug": "Ryan-P.-Adams",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Adams",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan P. Adams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 84
                            }
                        ],
                        "text": "An attempt to incorporate this into the Bayesian optimization framework is given in [149]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[149] then use an ES-based acquisition function in order to determine whether to freeze a currently running experiment, thaw a previous experiment in order to resume training, or start a new experiment."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2425787,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "52d97890dbc290108136739ec2afe0f2b6c4f570",
            "isKey": false,
            "numCitedBy": 205,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we develop a dynamic form of Bayesian optimization for machine learning models with the goal of rapidly finding good hyperparameter settings. Our method uses the partial information gained during the training of a machine learning model in order to decide whether to pause training and start a new model, or resume the training of a previously-considered model. We specifically tailor our method to machine learning problems by developing a novel positive-definite covariance kernel to capture a variety of training curves. Furthermore, we develop a Gaussian process prior that scales gracefully with additional temporal observations. Finally, we provide an information-theoretic framework to automate the decision process. Experiments on several common machine learning models show that our approach is extremely effective in practice."
            },
            "slug": "Freeze-Thaw-Bayesian-Optimization-Swersky-Snoek",
            "title": {
                "fragments": [],
                "text": "Freeze-Thaw Bayesian Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "This paper develops a dynamic form of Bayesian optimization for machine learning models with the goal of rapidly finding good hyperparameter settings and provides an information-theoretic framework to automate the decision process."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708654"
                        ],
                        "name": "R. Munos",
                        "slug": "R.-Munos",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Munos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Munos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 119
                            }
                        ],
                        "text": "Simultaneous optimistic optimization (SOO) can reach the global optimum without knowledge of the function\u2019s smoothness [116]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 108
                            }
                        ],
                        "text": "Recent proposed optimistic optimization methods provide an alternative to Bayesian optimization [31], [87], [116]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9435176,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "5dc2dafbdc96d1bf6d960c64b1612dce542408c0",
            "isKey": false,
            "numCitedBy": 148,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider a global optimization problem of a deterministic function f in a semi-metric space, given a finite budget of n evaluations. The function f is assumed to be locally smooth (around one of its global maxima) with respect to a semi-metric l We describe two algorithms based on optimistic exploration that use a hierarchical partitioning of the space at all scales. A first contribution is an algorithm, DOO, that requires the knowledge of l. We report a finite-sample performance bound in terms of a measure of the quantity of near-optimal states. We then define a second algorithm, SOO, which does not require the knowledge of the semi-metric l under which f is smooth, and whose performance is almost as good as DOO optimally-fitted."
            },
            "slug": "Optimistic-Optimization-of-a-Deterministic-Function-Munos",
            "title": {
                "fragments": [],
                "text": "Optimistic Optimization of a Deterministic Function without the Knowledge of its Smoothness"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A finite-sample performance bound is reported in terms of a measure of the quantity of near-optimal states of the semi-metric function f under which f is smooth, and whose performance is almost as good as DOO optimally-fitted."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3038127"
                        ],
                        "name": "Victor Gabillon",
                        "slug": "Victor-Gabillon",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Gabillon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Victor Gabillon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678622"
                        ],
                        "name": "M. Ghavamzadeh",
                        "slug": "M.-Ghavamzadeh",
                        "structuredName": {
                            "firstName": "Mohammad",
                            "lastName": "Ghavamzadeh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ghavamzadeh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3254390"
                        ],
                        "name": "A. Lazaric",
                        "slug": "A.-Lazaric",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Lazaric",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lazaric"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "arm identification problem, which is more suitable for the model selection task [7], [30], [50], [51], [72], [104]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": "[30], [50], [51] and contextual bandits [2], [97], [112]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1168777,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d4a145888d2724843213b818367138dee5465df0",
            "isKey": false,
            "numCitedBy": 219,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the problem of identifying the best arm(s) in the stochastic multi-armed bandit setting. This problem has been studied in the literature from two different perspectives: fixed budget and fixed confidence. We propose a unifying approach that leads to a meta-algorithm called unified gap-based exploration (UGapE), with a common structure and similar theoretical analysis for these two settings. We prove a performance bound for the two versions of the algorithm showing that the two problems are characterized by the same notion of complexity. We also show how the UGapE algorithm as well as its theoretical analysis can be extended to take into account the variance of the arms and to multiple bandits. Finally, we evaluate the performance of UGapE and compare it with a number of existing fixed budget and fixed confidence algorithms."
            },
            "slug": "Best-Arm-Identification:-A-Unified-Approach-to-and-Gabillon-Ghavamzadeh",
            "title": {
                "fragments": [],
                "text": "Best Arm Identification: A Unified Approach to Fixed Budget and Fixed Confidence"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A performance bound is proved for the two versions of the UGapE algorithm showing that the two problems are characterized by the same notion of complexity."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7825380"
                        ],
                        "name": "Benedict C. May",
                        "slug": "Benedict-C.-May",
                        "structuredName": {
                            "firstName": "Benedict",
                            "lastName": "May",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benedict C. May"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33656309"
                        ],
                        "name": "N. Korda",
                        "slug": "N.-Korda",
                        "structuredName": {
                            "firstName": "Nathaniel",
                            "lastName": "Korda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Korda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087005"
                        ],
                        "name": "Anthony Lee",
                        "slug": "Anthony-Lee",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anthony Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31819180"
                        ],
                        "name": "D. Leslie",
                        "slug": "D.-Leslie",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Leslie",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Leslie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 51
                            }
                        ],
                        "text": "[30], [50], [51] and contextual bandits [2], [97], [112]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 16151060,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c445fdeb8dbca92404de6a466f1ad2cca687a78f",
            "isKey": false,
            "numCitedBy": 233,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "In sequential decision problems in an unknown environment, the decision maker often faces a dilemma over whether to explore to discover more about the environment, or to exploit current knowledge. We address the exploration-exploitation dilemma in a general setting encompassing both standard and contextualised bandit problems. The contextual bandit problem has recently resurfaced in attempts to maximise click-through rates in web based applications, a task with significant commercial interest. \n \nIn this article we consider an approach of Thompson (1933) which makes use of samples from the posterior distributions for the instantaneous value of each action. We extend the approach by introducing a new algorithm, Optimistic Bayesian Sampling (OBS), in which the probability of playing an action increases with the uncertainty in the estimate of the action value. This results in better directed exploratory behaviour. \n \nWe prove that, under unrestrictive assumptions, both approaches result in optimal behaviour with respect to the average reward criterion of Yang and Zhu (2002). We implement OBS and measure its performance in simulated Bernoulli bandit and linear regression domains, and also when tested with the task of personalised news article recommendation on a Yahoo! Front Page Today Module data set. We find that OBS performs competitively when compared to recently proposed benchmark algorithms and outperforms Thompson's method throughout."
            },
            "slug": "Optimistic-Bayesian-Sampling-in-Contextual-Bandit-May-Korda",
            "title": {
                "fragments": [],
                "text": "Optimistic Bayesian Sampling in Contextual-Bandit Problems"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An approach of Thompson (1933) which makes use of samples from the posterior distributions for the instantaneous value of each action is considered, and a new algorithm, Optimistic Bayesian Sampling (OBS), which performs competitively when compared to recently proposed benchmark algorithms and outperforms Thompson's method throughout."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388404060"
                        ],
                        "name": "Kevin Leyton-Brown",
                        "slug": "Kevin-Leyton-Brown",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Leyton-Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Leyton-Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48942559"
                        ],
                        "name": "E. Nudelman",
                        "slug": "E.-Nudelman",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Nudelman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Nudelman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701353"
                        ],
                        "name": "Y. Shoham",
                        "slug": "Y.-Shoham",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Shoham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Shoham"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "We can then express the expected payout (reward) of each arm as a function of this vector, i.e., f(a) = f(xa)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14498800,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5580b7fda70be1dacb2d9424d13b5f0ca2cd51c8",
            "isKey": false,
            "numCitedBy": 207,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new approach for understanding the algorithm-specific empiricalh ardness of NP-Hard problems. In this work we focus on the empirical hardness of the winner determination problem--an optimization problem arising in combinatorial auctions--when solved by ILOG's CPLEX software. We consider nine widely-used problem distributions and sample randomly from a continuum of parameter settings for each distribution. We identify a large number of distribution-nonspecific features of data instances and use statisticalregression techniques to learn, evaluate and interpret a function from these features to the predicted hardness of an instance."
            },
            "slug": "Learning-the-Empirical-Hardness-of-Optimization-The-Leyton-Brown-Nudelman",
            "title": {
                "fragments": [],
                "text": "Learning the Empirical Hardness of Optimization Problems: The Case of Combinatorial Auctions"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work focuses on the empirical hardness of the winner determination problem--an optimization problem arising in combinatorial auctions--when solved by ILOG's CPLEX software."
            },
            "venue": {
                "fragments": [],
                "text": "CP"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1857222"
                        ],
                        "name": "Hastagiri P. Vanchinathan",
                        "slug": "Hastagiri-P.-Vanchinathan",
                        "structuredName": {
                            "firstName": "Hastagiri",
                            "lastName": "Vanchinathan",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hastagiri P. Vanchinathan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2585403"
                        ],
                        "name": "I. Nikolic",
                        "slug": "I.-Nikolic",
                        "structuredName": {
                            "firstName": "Isidor",
                            "lastName": "Nikolic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Nikolic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1933978557"
                        ],
                        "name": "F. D. Bona",
                        "slug": "F.-D.-Bona",
                        "structuredName": {
                            "firstName": "F",
                            "lastName": "Bona",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. D. Bona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145343838"
                        ],
                        "name": "Andreas Krause",
                        "slug": "Andreas-Krause",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Krause",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Krause"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 117
                            }
                        ],
                        "text": "The techniques reviewed in this work have been successfully used for the recommendation of news articles [97], [38], [153]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 82
                            }
                        ],
                        "text": "Finally, there also exist variants of these algorithms for the contextual bandits [153] (see Section VIII-D) and parallel querying [45] (see Section V-E)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14664386,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5be0ae8724ac03cfc61fe360373083a786d8fef4",
            "isKey": false,
            "numCitedBy": 71,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the challenge of ranking recommendation lists based on click feedback by efficiently encoding similarities among users and among items. The key challenges are threefold: (1) combinatorial number of lists; (2) sparse feedback and (3) context dependent recommendations. We propose the CGPRank algorithm, which exploits prior information specified in terms of a Gaussian process kernel function, which allows to share feedback in three ways: Between positions in a list, between items, and between contexts. Under our model, we provide strong performance guarantees and empirically evaluate our algorithm on data from two large scale recommendation tasks: Yahoo! news article recommendation, and Google books. In our experiments, CGPRank significantly outperforms state-of-the-art multi-armed bandit and learning-to-rank methods, with an 18% increase in clicks."
            },
            "slug": "Explore-exploit-in-top-N-recommender-systems-via-Vanchinathan-Nikolic",
            "title": {
                "fragments": [],
                "text": "Explore-exploit in top-N recommender systems via Gaussian processes"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The CGPRank algorithm is proposed, which exploits prior information specified in terms of a Gaussian process kernel function, which allows to share feedback in three ways: Between positions in a list, between items, and between contexts."
            },
            "venue": {
                "fragments": [],
                "text": "RecSys '14"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35112676"
                        ],
                        "name": "S. Kuhnt",
                        "slug": "S.-Kuhnt",
                        "structuredName": {
                            "firstName": "Sonja",
                            "lastName": "Kuhnt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kuhnt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50676519"
                        ],
                        "name": "D. Steinberg",
                        "slug": "D.-Steinberg",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Steinberg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Steinberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "[128] (and more recently a book by Santner et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15210862,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b617b85b5add24d55bdbd952cb5bde52b01e4869",
            "isKey": false,
            "numCitedBy": 2858,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The design and analysis of computer experiments as a relatively young research field is not only of high importance for many industrial areas but also presents new challenges and open questions for statisticians. This editorial introduces a special issue devoted to the topic. The included papers present an interesting mixture of recent developments in the field as they cover fundamental research on the design of experiments, models and analysis methods as well as more applied research connected to real-life applications."
            },
            "slug": "Design-and-analysis-of-computer-experiments-Kuhnt-Steinberg",
            "title": {
                "fragments": [],
                "text": "Design and analysis of computer experiments"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The included papers present an interesting mixture of recent developments in the field as they cover fundamental research on the design of experiments, models and analysis methods as well as more applied research connected to real-life applications."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109650391"
                        ],
                        "name": "Julieta Martinez",
                        "slug": "Julieta-Martinez",
                        "structuredName": {
                            "firstName": "Julieta",
                            "lastName": "Martinez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julieta Martinez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710980"
                        ],
                        "name": "J. Little",
                        "slug": "J.-Little",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Little",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Little"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 147
                            }
                        ],
                        "text": "Our objective is to learn this function f : Rd 7\u2192 R for the purpose of choosing the best arm, and in the linear model we require f to be of the form fw(a) = xTaw, where the parameters w are now feature weights."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15977212,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "55eb5691479268718627a39237fadbe649b34ecc",
            "isKey": false,
            "numCitedBy": 2,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Nearest Neighbour Search in high-dimensional spaces is a common problem in Computer Vision. Although no algorithm better than linear search is known, approximate algorithms are commonly used to tackle this problem. The drawback of using such algorithms is that their performance depends highly on parameter tuning. While this process can be automated using standard empirical optimization techniques, tuning is still time-consuming. In this paper, we propose to use Empirical Hardness Models to reduce the number of parameter configurations that Bayesian Optimization has to try, speeding up the optimization process. Evaluation on standard benchmarks of SIFT and GIST descriptors shows the viability of our approach."
            },
            "slug": "Bayesian-Optimization-with-an-Empirical-Hardness-Martinez-Little",
            "title": {
                "fragments": [],
                "text": "Bayesian Optimization with an Empirical Hardness Model for approximate Nearest Neighbour Search"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper proposes to use Empirical Hardness Models to reduce the number of parameter configurations that Bayesian Optimization has to try, speeding up the optimization process."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Winter Conference on Applications of Computer Vision"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145974030"
                        ],
                        "name": "R. Garnett",
                        "slug": "R.-Garnett",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Garnett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Garnett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144484861"
                        ],
                        "name": "Michael A. Osborne",
                        "slug": "Michael-A.-Osborne",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Osborne",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael A. Osborne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145236972"
                        ],
                        "name": "S. Reece",
                        "slug": "S.-Reece",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Reece",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Reece"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145732981"
                        ],
                        "name": "A. Rogers",
                        "slug": "A.-Rogers",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Rogers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rogers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145029236"
                        ],
                        "name": "S. Roberts",
                        "slug": "S.-Roberts",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Roberts",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roberts"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "There are many other examples of nonstationary covariance functions [3], [22], [54], [70], [118], [121], [126], [132] that have been proposed for GP regression along with closely related output warping techniques [141] that can also model certain kinds of nonstationary processes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 112
                            }
                        ],
                        "text": "Another form of nonstationarity that is closely related to heteroscedasticity is a nonstationary amplitude [1], [54]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 52863369,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37abfe7b8363f266bfde852003f03e88a27340ef",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new sequential algorithm for making robust predictions in the presence of changepoints. Unlike previous approaches, which focus on the problem of detecting and locating changepoints, our algorithm focuses on the problem of making predictions even when such changes might be present. We introduce nonstationary covariance functions to be used in Gaussian process prediction that model such changes, and then proceed to demonstrate how to effectively manage the hyperparameters associated with those covariance functions. We further introduce covariance functions to be used in situations where our observation model undergoes changes, as is the case for sensor faults. By using Bayesian quadrature, we can integrate out the hyperparameters, allowing us to calculate the full marginal predictive distribution. Furthermore, if desired, the posterior distribution over putative changepoint locations can be calculated as a natural byproduct of our prediction algorithm."
            },
            "slug": "Sequential-Bayesian-Prediction-in-the-Presence-of-Garnett-Osborne",
            "title": {
                "fragments": [],
                "text": "Sequential Bayesian Prediction in the Presence of Changepoints and Faults"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A new sequential algorithm for making robust predictions in the presence of changepoints, which focuses on the problem of making predictions even when such changes might be present, and introduces nonstationary covariance functions to be used in Gaussian process prediction that model such changes, and demonstrates how to effectively manage the hyperparameters associated with those covariance function."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. J."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2244796"
                        ],
                        "name": "Amar Shah",
                        "slug": "Amar-Shah",
                        "structuredName": {
                            "firstName": "Amar",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amar Shah"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145771261"
                        ],
                        "name": "A. Wilson",
                        "slug": "A.-Wilson",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Wilson",
                            "middleNames": [
                                "Gordon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Wilson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744700"
                        ],
                        "name": "Zoubin Ghahramani",
                        "slug": "Zoubin-Ghahramani",
                        "structuredName": {
                            "firstName": "Zoubin",
                            "lastName": "Ghahramani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zoubin Ghahramani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 78
                            }
                        ],
                        "text": "This was done numerically in [143] and analytically using conjugate priors in [138], Fig."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8194863,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "ab6bcd19b7b411ddc3f247215b57e5db3ae67bbc",
            "isKey": false,
            "numCitedBy": 145,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the Student-t process as an alternative to the Gaussian process as a nonparametric prior over functions. We derive closed form expressions for the marginal likelihood and predictive distribution of a Student-t process, by integrating away an inverse Wishart process prior over the covariance kernel of a Gaussian process model. We show surprising equivalences between different hierarchical Gaussian process models leading to Student-t processes, and derive a new sampling scheme for the inverse Wishart process, which helps elucidate these equivalences. Overall, we show that a Student-t process can retain the attractive properties of a Gaussian process -- a nonparametric representation, analytic marginal and predictive distributions, and easy model selection through covariance kernels -- but has enhanced flexibility, and predictive covariances that, unlike a Gaussian process, explicitly depend on the values of training observations. We verify empirically that a Student-t process is especially useful in situations where there are changes in covariance structure, or in applications like Bayesian optimization, where accurate predictive covariances are critical for good performance. These advantages come at no additional computational cost over Gaussian processes."
            },
            "slug": "Student-t-Processes-as-Alternatives-to-Gaussian-Shah-Wilson",
            "title": {
                "fragments": [],
                "text": "Student-t Processes as Alternatives to Gaussian Processes"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "Overall, it is shown that a Student-t process can retain the attractive properties of a Gaussian process -- a nonparametric representation, analytic marginal and predictive distributions, and easy model selection through covariance kernels -- but has enhanced flexibility, and predictive covariances that, unlike aGaussian process, explicitly depend on the values of training observations."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35159852"
                        ],
                        "name": "R. Calandra",
                        "slug": "R.-Calandra",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Calandra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Calandra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145197867"
                        ],
                        "name": "Jan Peters",
                        "slug": "Jan-Peters",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Peters",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jan Peters"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3472959"
                        ],
                        "name": "C. Rasmussen",
                        "slug": "C.-Rasmussen",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Rasmussen",
                            "middleNames": [
                                "Edward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rasmussen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2261881"
                        ],
                        "name": "M. Deisenroth",
                        "slug": "M.-Deisenroth",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Deisenroth",
                            "middleNames": [
                                "Peter"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Deisenroth"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "For example, in [34] each sigmoidal layer of an L layer neural network is defined as L`(x) := \u03c3(W`x + B`) where \u03c3 is some sigmoidal non-linearity, and W` and B` are the layer parameters."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7888041,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f52b977f66d75ada48dc0f661f7dada7937a0252",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Off-the-shelf Gaussian Process (GP) covariance functions encode smoothness assumptions on the structure of the function to be modeled. To model complex and non-differentiable functions, these smoothness assumptions are often too restrictive. One way to alleviate this limitation is to find a different representation of the data by introducing a feature space. This feature space is often learned in an unsupervised way, which might lead to data representations that are not useful for the overall regression task. In this paper, we propose Manifold Gaussian Processes, a novel supervised method that jointly learns a transformation of the data into a feature space and a GP regression from the feature space to observed space. The Manifold GP is a full GP and allows to learn data representations, which are useful for the overall regression task. As a proof-of-concept, we evaluate our approach on complex non-smooth functions where standard GPs perform poorly, such as step functions and robotics tasks with contacts."
            },
            "slug": "Manifold-Gaussian-Processes-for-regression-Calandra-Peters",
            "title": {
                "fragments": [],
                "text": "Manifold Gaussian Processes for regression"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Manifold Gaussian Processes is a novel supervised method that jointly learns a transformation of the data into a feature space and a GP regression from the feature space to observed space, which allows to learn data representations, which are useful for the overall regression task."
            },
            "venue": {
                "fragments": [],
                "text": "2016 International Joint Conference on Neural Networks (IJCNN)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1405499515"
                        ],
                        "name": "Ruben Martinez-Cantin",
                        "slug": "Ruben-Martinez-Cantin",
                        "structuredName": {
                            "firstName": "Ruben",
                            "lastName": "Martinez-Cantin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruben Martinez-Cantin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701800"
                        ],
                        "name": "A. Doucet",
                        "slug": "A.-Doucet",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Doucet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Doucet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145186838"
                        ],
                        "name": "J. A. Castellanos",
                        "slug": "J.-A.-Castellanos",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Castellanos",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. A. Castellanos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2077953,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45aa6a67ce508ccbe74b74f5d60acb626727e914",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a simulation-based active policy learning algorithm for finite-horizon, partially-observed sequential decision processes. The algorithm is tested in the domain of robot navigation and exploration under uncertainty. In such a setting, the expected cost, that must be minimized, is a function of the belief state (filtering distribution). This filtering distribution is in turn nonlinear and subject to discontinuities, which arise because constraints in the robot motion and control models. As a result, the expected cost is non-differentiable and very expensive to simulate. The new algorithm overcomes the first difficulty and reduces the number of required simulations as follows. First, it assumes that we have carried out previous simulations which returned values of the expected cost for different corresponding policy parameters. Second, it fits a Gaussian process (GP) regression model to these values, so as to approximate the expected cost as a function of the policy parameters. Third, it uses the GP predicted mean and variance to construct a statistical measure that determines which policy parameters should be used in the next simulation. The process is then repeated using the new parameters and the newly gathered expected cost observation. Since the objective is to find the policy parameters that minimize the expected cost, this iterative active learning approach effectively trades-off between exploration (in regions where the GP variance is large) and exploitation (where the GP mean is low). In our experiments, a robot uses the proposed algorithm to plan an optimal path for accomplishing a series of tasks, while maximizing the information about its pose and map estimates. These estimates are obtained with a standard filter for simultaneous localization and mapping. Upon gathering new observations, the robot updates the state estimates and is able to replan a new path in the spirit of open-loop feedback control."
            },
            "slug": "Active-Policy-Learning-for-Robot-Planning-and-under-Martinez-Cantin-Freitas",
            "title": {
                "fragments": [],
                "text": "Active Policy Learning for Robot Planning and Exploration under Uncertainty"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A simulation-based active policy learning algorithm for finite-horizon, partially-observed sequential decision processes, tested in the domain of robot navigation and exploration under uncertainty, which effectively trades-off between exploration and exploitation."
            },
            "venue": {
                "fragments": [],
                "text": "Robotics: Science and Systems"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703744"
                        ],
                        "name": "Shipra Agrawal",
                        "slug": "Shipra-Agrawal",
                        "structuredName": {
                            "firstName": "Shipra",
                            "lastName": "Agrawal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shipra Agrawal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144260125"
                        ],
                        "name": "Navin Goyal",
                        "slug": "Navin-Goyal",
                        "structuredName": {
                            "firstName": "Navin",
                            "lastName": "Goyal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Navin Goyal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 185
                            }
                        ],
                        "text": "Though it was introduced in 1933 [150], TS has attracted renewed interest in the multiarmed bandit community, producing empirical evaluations [38], [135] as well as theoretical results [2], [85], [127]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 40
                            }
                        ],
                        "text": "[30], [50], [51] and contextual bandits [2], [97], [112]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 96146,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f26f1a3c034b96514fc092dee99acacedd9c380b",
            "isKey": false,
            "numCitedBy": 674,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Thompson Sampling is one of the oldest heuristics for multi-armed bandit problems. It is a randomized algorithm based on Bayesian ideas, and has recently generated significant interest after several studies demonstrated it to have better empirical performance compared to the state-of-the-art methods. However, many questions regarding its theoretical performance remained open. In this paper, we design and analyze a generalization of Thompson Sampling algorithm for the stochastic contextual multi-armed bandit problem with linear payoff functions, when the contexts are provided by an adaptive adversary. This is among the most important and widely studied version of the contextual bandits problem. We prove a high probability regret bound of O(d2/e\u221aT1+e) in time T for any 0 < e < 1, where d is the dimension of each context vector and e is a parameter used by the algorithm. Our results provide the first theoretical guarantees for the contextual version of Thompson Sampling, and are close to the lower bound of \u03a9(d\u221aT) for this problem. This essentially solves a COLT open problem of Chapelle and Li [COLT 2012]."
            },
            "slug": "Thompson-Sampling-for-Contextual-Bandits-with-Agrawal-Goyal",
            "title": {
                "fragments": [],
                "text": "Thompson Sampling for Contextual Bandits with Linear Payoffs"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A generalization of Thompson Sampling algorithm for the stochastic contextual multi-armed bandit problem with linear payoff functions, when the contexts are provided by an adaptive adversary is designed and analyzed."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1405499515"
                        ],
                        "name": "Ruben Martinez-Cantin",
                        "slug": "Ruben-Martinez-Cantin",
                        "structuredName": {
                            "firstName": "Ruben",
                            "lastName": "Martinez-Cantin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruben Martinez-Cantin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144180357"
                        ],
                        "name": "E. Brochu",
                        "slug": "E.-Brochu",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brochu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brochu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145186838"
                        ],
                        "name": "J. A. Castellanos",
                        "slug": "J.-A.-Castellanos",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Castellanos",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. A. Castellanos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701800"
                        ],
                        "name": "A. Doucet",
                        "slug": "A.-Doucet",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Doucet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Doucet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 54
                            }
                        ],
                        "text": "Since w is an unobserved quantity, we treat it as a latent random variable with a prior distribution p(w), which captures our a priori beliefs about probable values for w before any data is observed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15740223,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa23b59a8dd663ee98af5fe18689022b05ba35a2",
            "isKey": false,
            "numCitedBy": 215,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of online path planning for optimal sensing with a mobile robot. The objective of the robot is to learn the most about its pose and the environment given time constraints. We use a POMDP with a utility function that depends on the belief state to model the finite horizon planning problem. We replan as the robot progresses throughout the environment. The POMDP is high-dimensional, continuous, non-differentiable, nonlinear, non-Gaussian and must be solved in real-time. Most existing techniques for stochastic planning and reinforcement learning are therefore inapplicable. To solve this extremely complex problem, we propose a Bayesian optimization method that dynamically trades off exploration (minimizing uncertainty in unknown parts of the policy space) and exploitation (capitalizing on the current best solution). We demonstrate our approach with a visually-guide mobile robot. The solution proposed here is also applicable to other closely-related domains, including active vision, sequential experimental design, dynamic sensing and calibration with mobile sensors."
            },
            "slug": "A-Bayesian-exploration-exploitation-approach-for-a-Martinez-Cantin-Freitas",
            "title": {
                "fragments": [],
                "text": "A Bayesian exploration-exploitation approach for optimal online sensing and planning with a visually guided mobile robot"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A Bayesian optimization method that dynamically trades off exploration and exploitation for optimal sensing with a mobile robot and is applicable to other closely-related domains, including active vision, sequential experimental design, dynamic sensing and calibration with mobile sensors."
            },
            "venue": {
                "fragments": [],
                "text": "Auton. Robots"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40197700"
                        ],
                        "name": "Rom\u00e1n Marchant",
                        "slug": "Rom\u00e1n-Marchant",
                        "structuredName": {
                            "firstName": "Rom\u00e1n",
                            "lastName": "Marchant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rom\u00e1n Marchant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145726167"
                        ],
                        "name": "F. Ramos",
                        "slug": "F.-Ramos",
                        "structuredName": {
                            "firstName": "Fabio",
                            "lastName": "Ramos",
                            "middleNames": [
                                "Tozeto"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Ramos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 151
                            }
                        ],
                        "text": "Initially, we consider the simple case where the arms are independent insofar as observing the success or failure of one provides no information about another."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14312057,
            "fieldsOfStudy": [
                "Business",
                "Computer Science"
            ],
            "id": "66f35a821ac2e9b5af6575e309c5f751fabe9721",
            "isKey": false,
            "numCitedBy": 127,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Environmental Monitoring (EM) is typically performed using sensor networks that collect measurements in predefined static locations. The possibility of having one or more autonomous robots to perform this task increases versatility and reduces the number of necessary sensor nodes to cover the same area. However, several problems arise when making use of autonomous moving robots for EM. The main challenges are how to build an accurate spatial-temporal model while choosing locations for measuring the phenomenon. This paper addresses the problem by using Bayesian Optimisation for choosing sensing locations, and presents a new utility function that takes into account the distance travelled by a moving robot. The proposed methodology is tested in simulation and in a real environment. Compared to existing strategies, our approach exhibits slightly better accuracy in terms of RMSE error and considerably reduces the total distance travelled by the robot."
            },
            "slug": "Bayesian-optimisation-for-Intelligent-Environmental-Marchant-Ramos",
            "title": {
                "fragments": [],
                "text": "Bayesian optimisation for Intelligent Environmental Monitoring"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper uses Bayesian Optimisation for choosing sensing locations, and presents a new utility function that takes into account the distance travelled by a moving robot, and exhibits slightly better accuracy in terms of RMSE error and considerably reduces the totaldistance travelled by the robot."
            },
            "venue": {
                "fragments": [],
                "text": "2012 IEEE/RSJ International Conference on Intelligent Robots and Systems"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2578263"
                        ],
                        "name": "E. Kaufmann",
                        "slug": "E.-Kaufmann",
                        "structuredName": {
                            "firstName": "Emilie",
                            "lastName": "Kaufmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Kaufmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769551"
                        ],
                        "name": "O. Capp\u00e9",
                        "slug": "O.-Capp\u00e9",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Capp\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Capp\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2927057"
                        ],
                        "name": "Aur\u00e9lien Garivier",
                        "slug": "Aur\u00e9lien-Garivier",
                        "structuredName": {
                            "firstName": "Aur\u00e9lien",
                            "lastName": "Garivier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aur\u00e9lien Garivier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 104
                            }
                        ],
                        "text": "The GP-UCB algorithm has since been generalized to other Bayesian models by considering upper quantiles [84] instead of (45) defined below, which is more reminiscent of frequentist concentration bounds."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1287419,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76a3325fcb27a22cb5cef0e801a5e2b808c4648a",
            "isKey": false,
            "numCitedBy": 285,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Stochastic bandit problems have been analyzed from two dierent perspectives: a frequentist view, where the parameter is a deterministic unknown quantity, and a Bayesian approach, where the parameter is drawn from a prior distribution. We show in this paper that methods derived from this second perspective prove optimal when evaluated using the frequentist cumulated regret as a measure of performance. We give a general formulation for a class of Bayesian index policies that rely on quantiles of the posterior distribution. For binary bandits, we prove that the corresponding algorithm, termed BayesUCB, satisfies finite-time regret bounds that imply its asymptotic optimality. More generally, Bayes-UCB appears as an unifying framework for several variants of the UCB algorithm addressing dierent"
            },
            "slug": "On-Bayesian-Upper-Confidence-Bounds-for-Bandit-Kaufmann-Capp\u00e9",
            "title": {
                "fragments": [],
                "text": "On Bayesian Upper Confidence Bounds for Bandit Problems"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is proved that the corresponding algorithm, termed BayesUCB, satisfies finite-time regret bounds that imply its asymptotic optimality and gives a general formulation for a class of Bayesian index policies that rely on quantiles of the posterior distribution."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3255983"
                        ],
                        "name": "Volodymyr Mnih",
                        "slug": "Volodymyr-Mnih",
                        "structuredName": {
                            "firstName": "Volodymyr",
                            "lastName": "Mnih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Volodymyr Mnih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40868287"
                        ],
                        "name": "Csaba Szepesvari",
                        "slug": "Csaba-Szepesvari",
                        "structuredName": {
                            "firstName": "Csaba",
                            "lastName": "Szepesvari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Csaba Szepesvari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3015507"
                        ],
                        "name": "Jean-Yves Audibert",
                        "slug": "Jean-Yves-Audibert",
                        "structuredName": {
                            "firstName": "Jean-Yves",
                            "lastName": "Audibert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Yves Audibert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[113] V."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The traditional alternatives to cross validation include racing algorithms that use conservative concentration bounds to rule out underperforming models [107], [113]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 215753448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "76bfc5f80030b24a6b2d744acfe9374f4a7e0445",
            "isKey": false,
            "numCitedBy": 193,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Sampling is a popular way of scaling up machine learning algorithms to large datasets. The question often is how many samples are needed. Adaptive stopping algorithms monitor the performance in an online fashion and they can stop early, saving valuable resources. We consider problems where probabilistic guarantees are desired and demonstrate how recently-introduced empirical Bernstein bounds can be used to design stopping rules that are efficient. We provide upper bounds on the sample complexity of the new rules, as well as empirical results on model selection and boosting in the filtering setting."
            },
            "slug": "Empirical-Bernstein-stopping-Mnih-Szepesvari",
            "title": {
                "fragments": [],
                "text": "Empirical Bernstein stopping"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work considers problems where probabilistic guarantees are desired and demonstrates how recently-introduced empirical Bernstein bounds can be used to design stopping rules that are efficient, as well as providing upper bounds on the sample complexity of the new rules."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1887059"
                        ],
                        "name": "W. Loh",
                        "slug": "W.-Loh",
                        "structuredName": {
                            "firstName": "Wei-Yin",
                            "lastName": "Loh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Loh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "partition using classification and regression trees (CARTs) [25]; however, splitting was restricted to occur at data points rather than between them."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[25] L."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17654166,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3e708b0cd19818e0c7408765dd922835661f8a24",
            "isKey": false,
            "numCitedBy": 18809,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "Classification and regression trees are machine\u2010learning methods for constructing prediction models from data. The models are obtained by recursively partitioning the data space and fitting a simple prediction model within each partition. As a result, the partitioning can be represented graphically as a decision tree. Classification trees are designed for dependent variables that take a finite number of unordered values, with prediction error measured in terms of misclassification cost. Regression trees are for dependent variables that take continuous or ordered discrete values, with prediction error typically measured by the squared difference between the observed and predicted values. This article gives an introduction to the subject by reviewing some widely available algorithms and comparing their capabilities, strengths, and weakness in two examples. \u00a9 2011 John Wiley & Sons, Inc. WIREs Data Mining Knowl Discov 2011 1 14\u201023 DOI: 10.1002/widm.8"
            },
            "slug": "Classification-and-regression-trees-Loh",
            "title": {
                "fragments": [],
                "text": "Classification and regression trees"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This article gives an introduction to the subject of classification and regression trees by reviewing some widely available algorithms and comparing their capabilities, strengths, and weakness in two examples."
            },
            "venue": {
                "fragments": [],
                "text": "WIREs Data Mining Knowl. Discov."
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107603179"
                        ],
                        "name": "D. R. Jones",
                        "slug": "D.-R.-Jones",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Jones",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. R. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2563797"
                        ],
                        "name": "C. D. Perttunen",
                        "slug": "C.-D.-Perttunen",
                        "structuredName": {
                            "firstName": "Cary",
                            "lastName": "Perttunen",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. D. Perttunen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2424124"
                        ],
                        "name": "B. Stuckman",
                        "slug": "B.-Stuckman",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Stuckman",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Stuckman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 171
                            }
                        ],
                        "text": "In practice, the community has resorted to using various techniques such as discretization [143] and adaptive grids [13], or similarly, the divided rectangles approach of [83], which was used in [28], [105], and [110]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 123674634,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d7808f2ad77de7b71e83a2e79d27f2e3e12be8d5",
            "isKey": false,
            "numCitedBy": 1840,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new algorithm for finding the global minimum of a multivariate function subject to simple bounds. The algorithm is a modification of the standard Lipschitzian approach that eliminates the need to specify a Lipschitz constant. This is done by carrying out simultaneous searches using all possible constants from zero to infinity. On nine standard test functions, the new algorithm converges in fewer function evaluations than most competing methods.The motivation for the new algorithm stems from a different way of looking at the Lipschitz constant. In particular, the Lipschitz constant is viewed as a weighting parameter that indicates how much emphasis to place on global versus local search. In standard Lipschitzian methods, this constant is usually large because it must equal or exceed the maximum rate of change of the objective function. As a result, these methods place a high emphasis on global search and exhibit slow convergence. In contrast, the new algorithm carries out simultaneous searches using all possible constants, and therefore operates at both the global and local level. Once the global part of the algorithm finds the basin of convergence of the optimum, the local part of the algorithm quickly and automatically exploits it. This accounts for the fast convergence of the new algorithm on the test functions."
            },
            "slug": "Lipschitzian-optimization-without-the-Lipschitz-Jones-Perttunen",
            "title": {
                "fragments": [],
                "text": "Lipschitzian optimization without the Lipschitz constant"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2210196"
                        ],
                        "name": "J. Mockus",
                        "slug": "J.-Mockus",
                        "structuredName": {
                            "firstName": "Jonas",
                            "lastName": "Mockus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mockus"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 162
                            }
                        ],
                        "text": "Meanwhile, in the former Soviet Union, Mo\u010dkus and colleagues developed a multidimensional Bayesian optimization method using linear combinations of Wiener fields [114], [115]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 42695024,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82d51fac26b83f50ceb242b45fd6b1c88e94f867",
            "isKey": false,
            "numCitedBy": 277,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper a review of application of Bayesian approach to global and stochastic optimization of continuous multimodal functions is given. Advantages and disadvantages of Bayesian approach (average case analysis), comparing it with more usual minimax approach (worst case analysis) are discussed. New interactive version of software for global optimization is discussed. Practical multidimensional problems of global optimization are considered"
            },
            "slug": "Application-of-Bayesian-approach-to-numerical-of-Mockus",
            "title": {
                "fragments": [],
                "text": "Application of Bayesian approach to numerical methods of global and stochastic optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Advantages and disadvantages of Bayesian approach (average case analysis), comparing it with more usual minimax approach (worst case analysis) are discussed and new interactive version of software for global optimization is discussed."
            },
            "venue": {
                "fragments": [],
                "text": "J. Glob. Optim."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47681372"
                        ],
                        "name": "Lihong Li",
                        "slug": "Lihong-Li",
                        "structuredName": {
                            "firstName": "Lihong",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lihong Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48980295"
                        ],
                        "name": "Wei Chu",
                        "slug": "Wei-Chu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Chu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Chu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144162125"
                        ],
                        "name": "J. Langford",
                        "slug": "J.-Langford",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Langford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Langford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 110
                            }
                        ],
                        "text": "(53)\nHowever, in practice it is impossible to sample directly from the posterior so Markov chain Monte Carlo (MCMC) and sequential Monte Carlo (SMC) techniques are used to produce a sequence of samples that are marginally distributed according to p(\u03b8 | Dn) in the limit of infinitely long chains."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 26
                            }
                        ],
                        "text": "Markov chain Monte Carlo (MCMC) methods [4] approximate the posterior with a sequence of samples that converge to the posterior; this is the approach taken in [135] on the probit model."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 100
                            }
                        ],
                        "text": "In the generalized linear model, Thompson sampling draws a w\u0303 from the posterior p(w | Dn) using MCMC or a Laplace approximation, and then selects the arm with the highest expected reward given the sampled parameter w\u0303, i.e., an+1 = arg maxa g \u22121(xTa w\u0303)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": "Illustration of the Bayesian optimization procedure over three iterations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207178795,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ec0072bc37f83f1a81459df43289613e04cc61e1",
            "isKey": true,
            "numCitedBy": 2092,
            "numCiting": 97,
            "paperAbstract": {
                "fragments": [],
                "text": "Personalized web services strive to adapt their services (advertisements, news articles, etc.) to individual users by making use of both content and user information. Despite a few recent advances, this problem remains challenging for at least two reasons. First, web service is featured with dynamically changing pools of content, rendering traditional collaborative filtering methods inapplicable. Second, the scale of most web services of practical interest calls for solutions that are both fast in learning and computation.\n In this work, we model personalized recommendation of news articles as a contextual bandit problem, a principled approach in which a learning algorithm sequentially selects articles to serve users based on contextual information about the users and articles, while simultaneously adapting its article-selection strategy based on user-click feedback to maximize total user clicks.\n The contributions of this work are three-fold. First, we propose a new, general contextual bandit algorithm that is computationally efficient and well motivated from learning theory. Second, we argue that any bandit algorithm can be reliably evaluated offline using previously recorded random traffic. Finally, using this offline evaluation method, we successfully applied our new algorithm to a Yahoo! Front Page Today Module dataset containing over 33 million events. Results showed a 12.5% click lift compared to a standard context-free bandit algorithm, and the advantage becomes even greater when data gets more scarce."
            },
            "slug": "A-contextual-bandit-approach-to-personalized-news-Li-Chu",
            "title": {
                "fragments": [],
                "text": "A contextual-bandit approach to personalized news article recommendation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work model personalized recommendation of news articles as a contextual bandit problem, a principled approach in which a learning algorithm sequentially selects articles to serve users based on contextual information about the users and articles, while simultaneously adapting its article-selection strategy based on user-click feedback to maximize total user clicks."
            },
            "venue": {
                "fragments": [],
                "text": "WWW '10"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1811875"
                        ],
                        "name": "F. Hamze",
                        "slug": "F.-Hamze",
                        "structuredName": {
                            "firstName": "Firas",
                            "lastName": "Hamze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hamze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117966548"
                        ],
                        "name": "Ziyun Wang",
                        "slug": "Ziyun-Wang",
                        "structuredName": {
                            "firstName": "Ziyun",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ziyun Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "This rapidly becomes infeasible in the large spaces of realworld problems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11805562,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f22f841efcc7eb388d6a71e32af3631de31371db",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 87,
            "paperAbstract": {
                "fragments": [],
                "text": "This article introduces a new specialized algorithm for equilibrium Monte Carlo sampling of binary-valued systems, which allows for large moves in the state space. This is achieved by constructing self-avoiding walks (SAWs) in the state space. As a consequence, many bits are flipped in a single MCMC step. We name the algorithm SARDONICS, an acronym for Self-Avoiding Random Dynamics on Integer Complex Systems. The algorithm has several free parameters, but we show that Bayesian optimization can be used to automatically tune them. SARDONICS performs remarkably well in a broad number of sampling tasks: toroidal ferromagnetic and frustrated Ising models, 3D Ising models, restricted Boltzmann machines and chimera graphs arising in the design of quantum computers."
            },
            "slug": "Self-Avoiding-Random-Dynamics-on-Integer-Complex-Hamze-Wang",
            "title": {
                "fragments": [],
                "text": "Self-Avoiding Random Dynamics on Integer Complex Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A new specialized algorithm for equilibrium Monte Carlo sampling of binary-valued systems, which allows for large moves in the state space by constructing self-avoiding walks (SAWs) inThe algorithm has several free parameters, but it is shown that Bayesian optimization can be used to automatically tune them."
            },
            "venue": {
                "fragments": [],
                "text": "TOMC"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3444394"
                        ],
                        "name": "E. Ziegel",
                        "slug": "E.-Ziegel",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Ziegel",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Ziegel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 33
                            }
                        ],
                        "text": "Generalized linear models (GLMs) [119] allow more flexibility in the response variable through the introduction of a link function."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7218290,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2b461250c014b460e7c97b6138a3ee811f198f43",
            "isKey": false,
            "numCitedBy": 12303,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "This is the \u008e rst book on generalized linear models written by authors not mostly associated with the biological sciences. Subtitled \u201cWith Applications in Engineering and the Sciences,\u201d this book\u2019s authors all specialize primarily in engineering statistics. The \u008e rst author has produced several recent editions of Walpole, Myers, and Myers (1998), the last reported by Ziegel (1999). The second author has had several editions of Montgomery and Runger (1999), recently reported by Ziegel (2002). All of the authors are renowned experts in modeling. The \u008e rst two authors collaborated on a seminal volume in applied modeling (Myers and Montgomery 2002), which had its recent revised edition reported by Ziegel (2002). The last two authors collaborated on the most recent edition of a book on regression analysis (Montgomery, Peck, and Vining (2001), reported by Gray (2002), and the \u008e rst author has had multiple editions of his own regression analysis book (Myers 1990), the latest of which was reported by Ziegel (1991). A comparable book with similar objectives and a more speci\u008e c focus on logistic regression, Hosmer and Lemeshow (2000), reported by Conklin (2002), presumed a background in regression analysis and began with generalized linear models. The Preface here (p. xi) indicates an identical requirement but nonetheless begins with 100 pages of material on linear and nonlinear regression. Most of this will probably be a review for the readers of the book. Chapter 2, \u201cLinear Regression Model,\u201d begins with 50 pages of familiar material on estimation, inference, and diagnostic checking for multiple regression. The approach is very traditional, including the use of formal hypothesis tests. In industrial settings, use of p values as part of a risk-weighted decision is generally more appropriate. The pedagologic approach includes formulas and demonstrations for computations, although computing by Minitab is eventually illustrated. Less-familiar material on maximum likelihood estimation, scaled residuals, and weighted least squares provides more speci\u008e c background for subsequent estimation methods for generalized linear models. This review is not meant to be disparaging. The authors have packed a wealth of useful nuggets for any practitioner in this chapter. It is thoroughly enjoyable to read. Chapter 3, \u201cNonlinear Regression Models,\u201d is arguably less of a review, because regression analysis courses often give short shrift to nonlinear models. The chapter begins with a great example on the pitfalls of linearizing a nonlinear model for parameter estimation. It continues with the effective balancing of explicit statements concerning the theoretical basis for computations versus the application and demonstration of their use. The details of maximum likelihood estimation are again provided, and weighted and generalized regression estimation are discussed. Chapter 4 is titled \u201cLogistic and Poisson Regression Models.\u201d Logistic regression provides the basic model for generalized linear models. The prior development for weighted regression is used to motivate maximum likelihood estimation for the parameters in the logistic model. The algebraic details are provided. As in the development for linear models, some of the details are pushed into an appendix. In addition to connecting to the foregoing material on regression on several occasions, the authors link their development forward to their following chapter on the entire family of generalized linear models. They discuss score functions, the variance-covariance matrix, Wald inference, likelihood inference, deviance, and overdispersion. Careful explanations are given for the values provided in standard computer software, here PROC LOGISTIC in SAS. The value in having the book begin with familiar regression concepts is clearly realized when the analogies are drawn between overdispersion and nonhomogenous variance, or analysis of deviance and analysis of variance. The authors rely on the similarity of Poisson regression methods to logistic regression methods and mostly present illustrations for Poisson regression. These use PROC GENMOD in SAS. The book does not give any of the SAS code that produces the results. Two of the examples illustrate designed experiments and modeling. They include discussion of subset selection and adjustment for overdispersion. The mathematic level of the presentation is elevated in Chapter 5, \u201cThe Family of Generalized Linear Models.\u201d First, the authors unify the two preceding chapters under the exponential distribution. The material on the formal structure for generalized linear models (GLMs), likelihood equations, quasilikelihood, the gamma distribution family, and power functions as links is some of the most advanced material in the book. Most of the computational details are relegated to appendixes. A discussion of residuals returns one to a more practical perspective, and two long examples on gamma distribution applications provide excellent guidance on how to put this material into practice. One example is a contrast to the use of linear regression with a log transformation of the response, and the other is a comparison to the use of a different link function in the previous chapter. Chapter 6 considers generalized estimating equations (GEEs) for longitudinal and analogous studies. The \u008e rst half of the chapter presents the methodology, and the second half demonstrates its application through \u008e ve different examples. The basis for the general situation is \u008e rst established using the case with a normal distribution for the response and an identity link. The importance of the correlation structure is explained, the iterative estimation procedure is shown, and estimation for the scale parameters and the standard errors of the coef\u008e cients is discussed. The procedures are then generalized for the exponential family of distributions and quasi-likelihood estimation. Two of the examples are standard repeated-measures illustrations from biostatistical applications, but the last three illustrations are all interesting reworkings of industrial applications. The GEE computations in PROC GENMOD are applied to account for correlations that occur with multiple measurements on the subjects or restrictions to randomizations. The examples show that accounting for correlation structure can result in different conclusions. Chapter 7, \u201cFurther Advances and Applications in GLM,\u201d discusses several additional topics. These are experimental designs for GLMs, asymptotic results, analysis of screening experiments, data transformation, modeling for both a process mean and variance, and generalized additive models. The material on experimental designs is more discursive than prescriptive and as a result is also somewhat theoretical. Similar comments apply for the discussion on the quality of the asymptotic results, which wallows a little too much in reports on various simulation studies. The examples on screening and data transformations experiments are again reworkings of analyses of familiar industrial examples and another obvious motivation for the enthusiasm that the authors have developed for using the GLM toolkit. One can hope that subsequent editions will similarly contain new examples that will have caused the authors to expand the material on generalized additive models and other topics in this chapter. Designating myself to review a book that I know I will love to read is one of the rewards of being editor. I read both of the editions of McCullagh and Nelder (1989), which was reviewed by Schuenemeyer (1992). That book was not fun to read. The obvious enthusiasm of Myers, Montgomery, and Vining and their reliance on their many examples as a major focus of their pedagogy make Generalized Linear Models a joy to read. Every statistician working in any area of applied science should buy it and experience the excitement of these new approaches to familiar activities."
            },
            "slug": "Generalized-Linear-Models-Ziegel",
            "title": {
                "fragments": [],
                "text": "Generalized Linear Models"
            },
            "tldr": {
                "abstractSimilarityScore": 84,
                "text": "This is the \u008e rst book on generalized linear models written by authors not mostly associated with the biological sciences, and it is thoroughly enjoyable to read."
            },
            "venue": {
                "fragments": [],
                "text": "Technometrics"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388666962"
                        ],
                        "name": "M. L\u00e1zaro-Gredilla",
                        "slug": "M.-L\u00e1zaro-Gredilla",
                        "structuredName": {
                            "firstName": "Miguel",
                            "lastName": "L\u00e1zaro-Gredilla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. L\u00e1zaro-Gredilla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722732"
                        ],
                        "name": "M. Titsias",
                        "slug": "M.-Titsias",
                        "structuredName": {
                            "firstName": "Michalis",
                            "lastName": "Titsias",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Titsias"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[103]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8740432,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e47635c326206ca0dc5bccab0ceb8fc1d76bbe70",
            "isKey": false,
            "numCitedBy": 223,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Standard Gaussian processes (GPs) model observations' noise as constant throughout input space. This is often a too restrictive assumption, but one that is needed for GP inference to be tractable. In this work we present a non-standard variational approximation that allows accurate inference in heteroscedastic GPs (i.e., under input-dependent noise conditions). Computational cost is roughly twice that of the standard GP, and also scales as O(n3). Accuracy is verified by comparing with the golden standard MCMC and its effectiveness is illustrated on several synthetic and real datasets of diverse characteristics. An application to volatility forecasting is also considered."
            },
            "slug": "Variational-Heteroscedastic-Gaussian-Process-L\u00e1zaro-Gredilla-Titsias",
            "title": {
                "fragments": [],
                "text": "Variational Heteroscedastic Gaussian Process Regression"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work presents a non-standard variational approximation that allows accurate inference in heteroscedastic GPs (i.e., under input-dependent noise conditions) and its effectiveness is illustrated on several synthetic and real datasets of diverse characteristics."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38645568"
                        ],
                        "name": "J. Pinheiro",
                        "slug": "J.-Pinheiro",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Pinheiro",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pinheiro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2437910"
                        ],
                        "name": "D. Bates",
                        "slug": "D.-Bates",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Bates",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bates"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 65
                            }
                        ],
                        "text": "There are many ways to parameterize the task covariance function [123]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6875890,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "2ff55b99d6d94d331670719bb1df1827b4d502a7",
            "isKey": false,
            "numCitedBy": 423,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The estimation of variance-covariance matrices through optimization of an objective function, such as a log-likelihood function, is usually a difficult numerical problem. Since the estimates should be positive semi-definite matrices, we must use constrained optimization, or employ a parametrization that enforces this condition. We describe here five different parametrizations for variance-covariance matrices that ensure positive definiteness, thus leaving the estimation problem unconstrained. We compare the parametrizations based on their computational efficiency and statistical interpretability. The results described here are particularly useful in maximum likelihood and restricted maximum likelihood estimation in linear and non-linear mixed-effects models, but are also applicable to other areas of statistics."
            },
            "slug": "Unconstrained-parametrizations-for-matrices-Pinheiro-Bates",
            "title": {
                "fragments": [],
                "text": "Unconstrained parametrizations for variance-covariance matrices"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Five different parametrizations for variance-covariance matrices that ensure positive definiteness, thus leaving the estimation problem unconstrained in maximum likelihood and restricted maximum likelihood estimation in linear and non-linear mixed-effects models are described."
            },
            "venue": {
                "fragments": [],
                "text": "Stat. Comput."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815542"
                        ],
                        "name": "S\u00e9bastien Bubeck",
                        "slug": "S\u00e9bastien-Bubeck",
                        "structuredName": {
                            "firstName": "S\u00e9bastien",
                            "lastName": "Bubeck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S\u00e9bastien Bubeck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708654"
                        ],
                        "name": "R. Munos",
                        "slug": "R.-Munos",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Munos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Munos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806997"
                        ],
                        "name": "Gilles Stoltz",
                        "slug": "Gilles-Stoltz",
                        "structuredName": {
                            "firstName": "Gilles",
                            "lastName": "Stoltz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gilles Stoltz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 85
                            }
                        ],
                        "text": "arm identification problem, which is more suitable for the model selection task [7], [30], [50], [51], [72], [104]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[30], [50], [51] and contextual bandits [2], [97], [112]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8113833,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5902a8ae8bbd37d363972f69f16bd1b9eb6d3b6",
            "isKey": false,
            "numCitedBy": 414,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the framework of stochastic multi-armed bandit problems and study the possibilities and limitations of strategies that perform an online exploration of the arms. The strategies are assessed in terms of their simple regret, a regret notion that captures the fact that exploration is only constrained by the number of available rounds (not necessarily known in advance), in contrast to the case when the cumulative regret is considered and when exploitation needs to be performed at the same time.We believe that this performance criterion is suited to situations when the cost of pulling an arm is expressed in terms of resources rather than rewards. We discuss the links between the simple and the cumulative regret. The main result is that the required exploration-exploitation trade-offs are qualitatively different, in view of a general lower bound on the simple regret in terms of the cumulative regret."
            },
            "slug": "Pure-Exploration-in-Multi-armed-Bandits-Problems-Bubeck-Munos",
            "title": {
                "fragments": [],
                "text": "Pure Exploration in Multi-armed Bandits Problems"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The main result is that the required exploration-exploitation trade-offs are qualitatively different, in view of a general lower bound on the simple regret in terms of the cumulative regret."
            },
            "venue": {
                "fragments": [],
                "text": "ALT"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815542"
                        ],
                        "name": "S\u00e9bastien Bubeck",
                        "slug": "S\u00e9bastien-Bubeck",
                        "structuredName": {
                            "firstName": "S\u00e9bastien",
                            "lastName": "Bubeck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S\u00e9bastien Bubeck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708654"
                        ],
                        "name": "R. Munos",
                        "slug": "R.-Munos",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Munos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Munos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1806997"
                        ],
                        "name": "Gilles Stoltz",
                        "slug": "Gilles-Stoltz",
                        "structuredName": {
                            "firstName": "Gilles",
                            "lastName": "Stoltz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gilles Stoltz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40868287"
                        ],
                        "name": "Csaba Szepesvari",
                        "slug": "Csaba-Szepesvari",
                        "structuredName": {
                            "firstName": "Csaba",
                            "lastName": "Szepesvari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Csaba Szepesvari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Recent proposed optimistic optimization methods provide an alternative to Bayesian optimization [31], [87], [116]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[31] S."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15014372,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "57ff75c271f4a62b686946caf4ff5cd87acee77c",
            "isKey": false,
            "numCitedBy": 321,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider a generalization of stochastic bandits where the set of arms, X, is allowed to be a generic measurable space and the mean-payoff function is \"locally Lipschitz\" with respect to a dissimilarity function that is known to the decision maker. Under this condition we construct an arm selection policy, called HOO (hierarchical optimistic optimization), with improved regret bounds compared to previous results for a large class of problems. In particular, our results imply that if X is the unit hypercube in a Euclidean space and the mean-payoff function has a finite number of global maxima around which the behavior of the function is locally continuous with a known smoothness degree, then the expected regret of HOO is bounded up to a logarithmic factor by \u221an, that is, the rate of growth of the regret is independent of the dimension of the space. We also prove the minimax optimality of our algorithm when the dissimilarity is a metric. Our basic strategy has quadratic computational complexity as a function of the number of time steps and does not rely on the doubling trick. We also introduce a modified strategy, which relies on the doubling trick but runs in linearithmic time. Both results are improvements with respect to previous approaches."
            },
            "slug": "X-Armed-Bandits-Bubeck-Munos",
            "title": {
                "fragments": [],
                "text": "X-Armed Bandits"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "A generalization of stochastic bandits where the set of arms, X, is allowed to be a generic measurable space and the mean-payoff function is \"locally Lipschitz\" with respect to a dissimilarity function that is known to the decision maker is constructed."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3240893"
                        ],
                        "name": "Charles Audet",
                        "slug": "Charles-Audet",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Audet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles Audet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "151380925"
                        ],
                        "name": "J. Denni",
                        "slug": "J.-Denni",
                        "structuredName": {
                            "firstName": "Julien",
                            "lastName": "Denni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114877467"
                        ],
                        "name": "Douglas Moore",
                        "slug": "Douglas-Moore",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Moore",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Douglas Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40698158"
                        ],
                        "name": "A. Booker",
                        "slug": "A.-Booker",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Booker",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Booker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704765"
                        ],
                        "name": "P. Frank",
                        "slug": "P.-Frank",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Frank",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frank"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 157
                            }
                        ],
                        "text": "Since EGO\u2019s publication, there has evolved a body of work devoted to extending the algorithm, particularly in adding constraints to the optimization problem [6], [131], [23], and in modelling noisy functions [14], [75], [76]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62550311,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa69c712a0c6e7213e8fed4e00ec99e727a782cf",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an algorithm and provides test results for surrogate-model-based optimization. In this type of optimization, the objective and constraint functions are represented by global \"surrogates\", i.e. response models, of the \"true\" problem responses. In general, guarantees of global optimality are not possible. However, a robust surrogate-model-based optimization method is presented here that has good global search properties, and proven local convergence results. This paper describes methods for handling three key issues in surrogate-model-based optimization. These issues are maintaining a balance of effort between global design space exploration and local optimizer region refinement, maintaining good surrogate model conditioning as points \"pile up\" in local regions, and providing a provably convergent method for ensuring local optimality. Acknowledgments: Work of the first author was supported by NSERC (Natural Sciences and Engineering Research Council) fellowship PDF-2074321998, and the first three authors was supported by DOE DE-FG03-95ER25257, AFOSR F49620-98-10267, The Boeing Company, Sandia LG-4253, ExxonMobil and CRPC CCR-9120008. Copyright \u00a92000 by the American Institute of Aeronautics and Astronautics, Inc. All rights reserved."
            },
            "slug": "A-surrogate-model-based-method-for-constrained-Audet-Denni",
            "title": {
                "fragments": [],
                "text": "A surrogate-model-based method for constrained optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A robust surrogate-model-based optimization method is presented here that has good global search properties, and proven local convergence results, and providing a provably convergent method for ensuring local optimality."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2120874"
                        ],
                        "name": "Tobias Domhan",
                        "slug": "Tobias-Domhan",
                        "structuredName": {
                            "firstName": "Tobias",
                            "lastName": "Domhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tobias Domhan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060551"
                        ],
                        "name": "Jost Tobias Springenberg",
                        "slug": "Jost-Tobias-Springenberg",
                        "structuredName": {
                            "firstName": "Jost",
                            "lastName": "Springenberg",
                            "middleNames": [
                                "Tobias"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jost Tobias Springenberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": "[47], [48] built a basis set manually based on previously collected training curves."
                    },
                    "intents": []
                }
            ],
            "corpusId": 123977864,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e22b2772774ccc1e504b4e278eff7d6b8ae6aad",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "\u2022 Representative power increased by convex combination of individual models: \u2022 f x = wifi(x|\u03b8i) k i=1 + e with e ~ N 0, \u03c3 2 and wi = 1 k i=1 \u2022 Model uncertainty captured by MCMC \u2022 The prior encoded monotonicity assumption of each of the models \u2022 We obtained S = 100000 samples from 100 parallel chains of length 1500 with a burn-in of 500 \u2022 Let \u03be be the model\u2019s parameters w1, ... , wk , \u03b81, ... , \u03b8k , \u03c3 2 \u2022 Probability of improving over current best parameter setting:"
            },
            "slug": "Extrapolating-Learning-Curves-of-Deep-Neural-Domhan-Springenberg",
            "title": {
                "fragments": [],
                "text": "Extrapolating Learning Curves of Deep Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "Representative power increased by convex combination of individual models and the prior encoded monotonicity assumption of each of the models was obtained."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144543541"
                        ],
                        "name": "P. Auer",
                        "slug": "P.-Auer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Auer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Auer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388387856"
                        ],
                        "name": "N. Cesa-Bianchi",
                        "slug": "N.-Cesa-Bianchi",
                        "structuredName": {
                            "firstName": "Nicol\u00f2",
                            "lastName": "Cesa-Bianchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cesa-Bianchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In the generalized linear model, Thompson sampling draws a w\u0303 from the posterior p(w | Dn) using MCMC or a Laplace approximation, and then selects the arm with the highest expected reward given the sampled parameter w\u0303, i.e., an+1 = arg maxa g \u22121(xTa w\u0303)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13209702,
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "id": "26e17f6b62a7caec660b3356d49e879e6e0eeabc",
            "isKey": false,
            "numCitedBy": 1984,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "In the multiarmed bandit problem, a gambler must decide which arm of K nonidentical slot machines to play in a sequence of trials so as to maximize his reward. This classical problem has received much attention because of the simple model it provides of the trade-off between exploration (trying out each arm to find the best one) and exploitation (playing the arm believed to give the best payoff). Past solutions for the bandit problem have almost always relied on assumptions about the statistics of the slot machines. \nIn this work, we make no statistical assumptions whatsoever about the nature of the process generating the payoffs of the slot machines. We give a solution to the bandit problem in which an adversary, rather than a well-behaved stochastic process, has complete control over the payoffs. In a sequence of T plays, we prove that the per-round payoff of our algorithm approaches that of the best arm at the rate O(T-1/2). We show by a matching lower bound that this is the best possible. \nWe also prove that our algorithm approaches the per-round payoff of any set of strategies at a similar rate: if the best strategy is chosen from a pool of N strategies, then our algorithm approaches the per-round payoff of the strategy at the rate O((log N1/2 T-1/2). Finally, we apply our results to the problem of playing an unknown repeated matrix game. We show that our algorithm approaches the minimax payoff of the unknown game at the rate O(T-1/2)."
            },
            "slug": "The-Nonstochastic-Multiarmed-Bandit-Problem-Auer-Cesa-Bianchi",
            "title": {
                "fragments": [],
                "text": "The Nonstochastic Multiarmed Bandit Problem"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A solution to the bandit problem in which an adversary, rather than a well-behaved stochastic process, has complete control over the payoffs."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J. Comput."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144539890"
                        ],
                        "name": "N. Hansen",
                        "slug": "N.-Hansen",
                        "structuredName": {
                            "firstName": "Nikolaus",
                            "lastName": "Hansen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Hansen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069398"
                        ],
                        "name": "A. Ostermeier",
                        "slug": "A.-Ostermeier",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Ostermeier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ostermeier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "[158] use the CMA-ES method of [66], and Hutter et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7524826,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f1bdebedf07fd444628c955568f0d51e1a26835e",
            "isKey": false,
            "numCitedBy": 3374,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper puts forward two useful methods for self-adaptation of the mutation distribution - the concepts of derandomization and cumulation. Principle shortcomings of the concept of mutative strategy parameter control and two levels of derandomization are reviewed. Basic demands on the self-adaptation of arbitrary (normal) mutation distributions are developed. Applying arbitrary, normal mutation distributions is equiv-alent to applying a general, linear problem encoding. The underlying objective of mutative strategy parameter control is roughly to favor previously selected mutation steps in the future. If this objective is pursued rigor-ously, a completely derandomized self-adaptation scheme results, which adapts arbitrary normal mutation distributions. This scheme, called covariance matrix adaptation (CMA), meets the previously stated demands. It can still be considerably improved by cumulation - utilizing an evolution path rather than single search steps. Simulations on various test functions reveal local and global search properties of the evolution strategy with and without covariance matrix adaptation. Their performances are comparable only on perfectly scaled functions. On badly scaled, non-separable functions usually a speed up factor of several orders of magnitude is ob-served. On moderately mis-scaled functions a speed up factor of three to ten can be expected."
            },
            "slug": "Completely-Derandomized-Self-Adaptation-in-Hansen-Ostermeier",
            "title": {
                "fragments": [],
                "text": "Completely Derandomized Self-Adaptation in Evolution Strategies"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This paper puts forward two useful methods for self-adaptation of the mutation distribution - the concepts of derandomization and cumulation and reveals local and global search properties of the evolution strategy with and without covariance matrix adaptation."
            },
            "venue": {
                "fragments": [],
                "text": "Evolutionary Computation"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388404060"
                        ],
                        "name": "Kevin Leyton-Brown",
                        "slug": "Kevin-Leyton-Brown",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Leyton-Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Leyton-Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", tuning mixed integer solvers [78], [158], and tuning approximate nearest neighbor algorithms [109]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[78] F."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1105261,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "5552bcf12caf0e12541cc07a285a3c70470563d3",
            "isKey": false,
            "numCitedBy": 178,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "State-of-the-art solvers for mixed integer programming (MIP) problems are highly parameterized, and finding parameter settings that achieve high performance for specific types of MIP instances is challenging. We study the application of an automated algorithm configuration procedure to different MIP solvers, instance types and optimization objectives. We show that this fully-automated process yields substantial improvements to the performance of three MIP solvers: Cplex, Gurobi, and lpsolve. Although our method can be used \u201cout of the box\u201d without any domain knowledge specific to MIP, we show that it outperforms the Cplex special-purpose automated tuning tool."
            },
            "slug": "Automated-Configuration-of-Mixed-Integer-Solvers-Hutter-Hoos",
            "title": {
                "fragments": [],
                "text": "Automated Configuration of Mixed Integer Programming Solvers"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work studies the application of an automated algorithm configuration procedure to different MIP solvers, instance types and optimization objectives, and shows that this fully-automated process yields substantial improvements to the performance of three MIPsolvers: Cplex, Gurobi, and lpsolve."
            },
            "venue": {
                "fragments": [],
                "text": "CPAIOR"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144272396"
                        ],
                        "name": "E. V\u00e1zquez",
                        "slug": "E.-V\u00e1zquez",
                        "structuredName": {
                            "firstName": "Emmanuel",
                            "lastName": "V\u00e1zquez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. V\u00e1zquez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691181"
                        ],
                        "name": "J. Bect",
                        "slug": "J.-Bect",
                        "structuredName": {
                            "firstName": "Julien",
                            "lastName": "Bect",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bect"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 52065066,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "3c5ddc50b656c923b8173c8fc40b6c36f5cd3dac",
            "isKey": false,
            "numCitedBy": 185,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Convergence-properties-of-the-expected-improvement-V\u00e1zquez-Bect",
            "title": {
                "fragments": [],
                "text": "Convergence properties of the expected improvement algorithm with fixed mean and covariance functions"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70271984"
                        ],
                        "name": "A. ilinskas",
                        "slug": "A.-ilinskas",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "ilinskas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. ilinskas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 244,
                                "start": 239
                            }
                        ],
                        "text": "There exist several early consistency proofs for Gaussian process based Bayesian optimization algorithms, in the onedimensional setting [102] and one for a simplification of the algorithm using simplicial partitioning in higher dimensions [164]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 52043977,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4b8b2267600b0e1ab278a43b4488e6a934cf4b5a",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A statistical model for global optimization is constructed generalizing some properties of the Wiener process to the multidimensional case. An approach to the construction of global optimization algorithms is developed using the proposed statistical model. The convergence of an algorithm based on the constructed statistical model and simplicial partitioning is proved. Several versions of the algorithm are implemented and investigated. @ 2002 Elsevier Science Ltd. All rights reserved. Keywords-Global optimization, Statistical models, Partitioning, Simplices, Convergence"
            },
            "slug": "Global-Optimization-Based-on-a-Statistical-Model-ilinskas",
            "title": {
                "fragments": [],
                "text": "Global Optimization Based on a Statistical Model and Simplicial Partitioning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The convergence of an algorithm based on the constructed statistical model and simplicial partitioning is proved and several versions of the algorithm are implemented and investigated."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3038127"
                        ],
                        "name": "Victor Gabillon",
                        "slug": "Victor-Gabillon",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Gabillon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Victor Gabillon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678622"
                        ],
                        "name": "M. Ghavamzadeh",
                        "slug": "M.-Ghavamzadeh",
                        "structuredName": {
                            "firstName": "Mohammad",
                            "lastName": "Ghavamzadeh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ghavamzadeh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3254390"
                        ],
                        "name": "A. Lazaric",
                        "slug": "A.-Lazaric",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Lazaric",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Lazaric"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815542"
                        ],
                        "name": "S\u00e9bastien Bubeck",
                        "slug": "S\u00e9bastien-Bubeck",
                        "structuredName": {
                            "firstName": "S\u00e9bastien",
                            "lastName": "Bubeck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S\u00e9bastien Bubeck"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "arm identification problem, which is more suitable for the model selection task [7], [30], [50], [51], [72], [104]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "[30], [50], [51] and contextual bandits [2], [97], [112]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13982470,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9b0efc79f34dfff7a18a06954ded784e6399e906",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the problem of identifying the best arm in each of the bandits in a multi-bandit multi-armed setting. We first propose an algorithm called Gap-based Exploration (GapE) that focuses on the arms whose mean is close to the mean of the best arm in the same bandit (i.e., small gap). We then introduce an algorithm, called GapE-V, which takes into account the variance of the arms in addition to their gap. We prove an upper-bound on the probability of error for both algorithms. Since GapE and GapE-V need to tune an exploration parameter that depends on the complexity of the problem, which is often unknown in advance, we also introduce variations of these algorithms that estimate this complexity online. Finally, we evaluate the performance of these algorithms and compare them to other allocation strategies on a number of synthetic problems."
            },
            "slug": "Multi-Bandit-Best-Arm-Identification-Gabillon-Ghavamzadeh",
            "title": {
                "fragments": [],
                "text": "Multi-Bandit Best Arm Identification"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "This work proposes an algorithm called Gap-based Exploration (GapE) that focuses on the arms whose mean is close to the mean of the best arm in the same bandit (i.e., small gap), and introduces an algorithm, called GapE-V, which takes into account the variance of the arms in addition to their gap."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688482"
                        ],
                        "name": "S. Gr\u00fcnew\u00e4lder",
                        "slug": "S.-Gr\u00fcnew\u00e4lder",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Gr\u00fcnew\u00e4lder",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gr\u00fcnew\u00e4lder"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3015507"
                        ],
                        "name": "Jean-Yves Audibert",
                        "slug": "Jean-Yves-Audibert",
                        "structuredName": {
                            "firstName": "Jean-Yves",
                            "lastName": "Audibert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Yves Audibert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691022"
                        ],
                        "name": "M. Opper",
                        "slug": "M.-Opper",
                        "structuredName": {
                            "firstName": "Manfred",
                            "lastName": "Opper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Opper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404459229"
                        ],
                        "name": "J. Shawe-Taylor",
                        "slug": "J.-Shawe-Taylor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shawe-Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shawe-Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "See Section 4 of [64] for another introduction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 215763200,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a99af9810155bfcbec517c9799d65f88851d6594",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Bandit algorithms are concerned with trading exploration with exploitation where a number of options are available but we can only learn their quality by experimenting with them. We consider the scenario in which the reward distribution for arms is modelled by a Gaussian process and there is no noise in the observed reward. Our main result is to bound the regret experienced by algorithms relative to the a posteriori optimal strategy of playing the best arm throughout based on benign assumptions about the covariance function dening the Gaussian process. We further complement these upper bounds with corresponding lower bounds for particular covariance functions demonstrating that in general there is at most a logarithmic looseness in our upper bounds."
            },
            "slug": "Regret-Bounds-for-Gaussian-Process-Bandit-Problems-Gr\u00fcnew\u00e4lder-Audibert",
            "title": {
                "fragments": [],
                "text": "Regret Bounds for Gaussian Process Bandit Problems"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The main result is to bound the regret experienced by algorithms relative to the a posteriori optimal strategy of playing the best arm throughout based on benign assumptions about the covariance function dening the Gaussian process."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS 2010"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145974030"
                        ],
                        "name": "R. Garnett",
                        "slug": "R.-Garnett",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Garnett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Garnett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144484861"
                        ],
                        "name": "Michael A. Osborne",
                        "slug": "Michael-A.-Osborne",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Osborne",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael A. Osborne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2517795"
                        ],
                        "name": "Philipp Hennig",
                        "slug": "Philipp-Hennig",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Hennig",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Hennig"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 103
                            }
                        ],
                        "text": "We could do away with samples entirely and approximately integrate out the hyperparameters as shown in [53]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2609859,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d1ccefb48d6edc1e341314888ac3abc9abf23656",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an active learning method for discovering low-dimensional structure in high-dimensional Gaussian process (GP) tasks. Such problems are increasingly frequent and important, but have hitherto presented severe practical difficulties. We further introduce a novel technique for approximately marginalizing GP hyperparameters, yielding marginal predictions robust to hyperparameter mis-specification. Our method offers an efficient means of performing GP regression, quadrature, or Bayesian optimization in high-dimensional spaces."
            },
            "slug": "Active-Learning-of-Linear-Embeddings-for-Gaussian-Garnett-Osborne",
            "title": {
                "fragments": [],
                "text": "Active Learning of Linear Embeddings for Gaussian Processes"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "An active learning method for discovering low-dimensional structure in high-dimensional Gaussian process (GP) tasks and a novel technique for approximately marginalizing GP hyperparameters, yielding marginal predictions robust to hyperparameter mis-specification are introduced."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31558848"
                        ],
                        "name": "A. Rahimi",
                        "slug": "A.-Rahimi",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Rahimi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rahimi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9229182"
                        ],
                        "name": "B. Recht",
                        "slug": "B.-Recht",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Recht",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Recht"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 63
                            }
                        ],
                        "text": "However, using recent spectral sampling techniques [20], [94], [125], we can draw an"
                    },
                    "intents": []
                }
            ],
            "corpusId": 877929,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7a59fde27461a3ef4a21a249cc403d0d96e4a0d7",
            "isKey": false,
            "numCitedBy": 2862,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "To accelerate the training of kernel machines, we propose to map the input data to a randomized low-dimensional feature space and then apply existing fast linear methods. The features are designed so that the inner products of the transformed data are approximately equal to those in the feature space of a user specified shift-invariant kernel. We explore two sets of random features, provide convergence bounds on their ability to approximate various radial basis kernels, and show that in large-scale classification and regression tasks linear machine learning algorithms applied to these features outperform state-of-the-art large-scale kernel machines."
            },
            "slug": "Random-Features-for-Large-Scale-Kernel-Machines-Rahimi-Recht",
            "title": {
                "fragments": [],
                "text": "Random Features for Large-Scale Kernel Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Two sets of random features are explored, provided convergence bounds on their ability to approximate various radial basis kernels, and it is shown that in large-scale classification and regression tasks linear machine learning algorithms applied to these features outperform state-of-the-art large- scale kernel machines."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34908205"
                        ],
                        "name": "Levente Kocsis",
                        "slug": "Levente-Kocsis",
                        "structuredName": {
                            "firstName": "Levente",
                            "lastName": "Kocsis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Levente Kocsis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40868287"
                        ],
                        "name": "Csaba Szepesvari",
                        "slug": "Csaba-Szepesvari",
                        "structuredName": {
                            "firstName": "Csaba",
                            "lastName": "Szepesvari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Csaba Szepesvari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 102
                            }
                        ],
                        "text": "Recent proposed optimistic optimization methods provide an alternative to Bayesian optimization [31], [87], [116]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15184765,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e635d81a617d1239232a9c9a11a196c53dab8240",
            "isKey": false,
            "numCitedBy": 2651,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "For large state-space Markovian Decision Problems Monte-Carlo planning is one of the few viable approaches to find near-optimal solutions. In this paper we introduce a new algorithm, UCT, that applies bandit ideas to guide Monte-Carlo planning. In finite-horizon or discounted MDPs the algorithm is shown to be consistent and finite sample bounds are derived on the estimation error due to sampling. Experimental results show that in several domains, UCT is significantly more efficient than its alternatives."
            },
            "slug": "Bandit-Based-Monte-Carlo-Planning-Kocsis-Szepesvari",
            "title": {
                "fragments": [],
                "text": "Bandit Based Monte-Carlo Planning"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A new algorithm is introduced, UCT, that applies bandit ideas to guide Monte-Carlo planning and is shown to be consistent and finite sample bounds are derived on the estimation error due to sampling."
            },
            "venue": {
                "fragments": [],
                "text": "ECML"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102382028"
                        ],
                        "name": "D. Krige",
                        "slug": "D.-Krige",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Krige",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Krige"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 173
                            }
                        ],
                        "text": "At the same time, a large, related body of work emerged under the name kriging, in honour of the South African student who developed this technique at the University of the Witwatersrand [90], though largely popularized by Matheron and colleagues (e.g., [111])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 190
                            }
                        ],
                        "text": "At the same time, a large, related body of work emerged under the name \u2018\u2018kriging,\u2019\u2019 in honor of the South African student who developed this technique at the University of the Witwatersrand [90], though largely popularized by Matheron and colleagues (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 117319434,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "b8a3d23444cd33f1d74c62d5013f04e6acf0f763",
            "isKey": false,
            "numCitedBy": 2233,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Certain fundamental concepts in the application of statistics to mine valuation on the Witwatersrand are discussed, and general conclusions are drawn regarding the application of the lognormal curve to the frequency distribution of gold values. An indication is given of the reliability of present valuation methods on the Rand. It is shown that the existing over- and under-valuation of blocks of ore listed as high-grade and low-grade, respectively, can be explained statistically. Suggestions are made for the elimination of such errors and for the improvement of the general standard of mine valuation by the use of statistical theory."
            },
            "slug": "A-statistical-approach-to-some-basic-mine-valuation-Krige",
            "title": {
                "fragments": [],
                "text": "A statistical approach to some basic mine valuation problems on the Witwatersrand, by D.G. Krige, published in the Journal, December 1951 : introduction by the author"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1951
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1849455"
                        ],
                        "name": "C. Paciorek",
                        "slug": "C.-Paciorek",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Paciorek",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Paciorek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2130768"
                        ],
                        "name": "M. Schervish",
                        "slug": "M.-Schervish",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Schervish",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schervish"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 98
                            }
                        ],
                        "text": "There are many other examples of nonstationary covariance functions [3], [22], [54], [70], [118], [121], [126], [132] that have been proposed for GP regression along with closely related output warping techniques [141] that can also model certain kinds of nonstationary processes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7339083,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "430962596e38e127e52ffe980e6be820e3fd091b",
            "isKey": false,
            "numCitedBy": 323,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a class of nonstationary covariance functions for Gaussian process (GP) regression. Nonstationary covariance functions allow the model to adapt to functions whose smoothness varies with the inputs. The class includes a nonstationary version of the Matern stationary co-variance, in which the differentiability of the regression function is controlled by a parameter, freeing one from fixing the differentiability in advance. In experiments, the nonstationary GP regression model performs well when the input space is two or three dimensions, outperforming a neural network model and Bayesian free-knot spline models, and competitive with a Bayesian neural network, but is outperformed in one dimension by a state-of-the-art Bayesian free-knot spline model. The model readily generalizes to non-Gaussian data. Use of computational methods for speeding GP fitting may allow for implementation of the method on larger datasets."
            },
            "slug": "Nonstationary-Covariance-Functions-for-Gaussian-Paciorek-Schervish",
            "title": {
                "fragments": [],
                "text": "Nonstationary Covariance Functions for Gaussian Process Regression"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "In experiments, the nonstationary GP regression model performs well when the input space is two or three dimensions, outperforming a neural network model and Bayesian free-knot spline models, and competitive with a Bayesian neural network, but is outperformed in one dimension by a state-of-the-art BayesianFree-k not spline model."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3177568"
                        ],
                        "name": "J. Q. Candela",
                        "slug": "J.-Q.-Candela",
                        "structuredName": {
                            "firstName": "Joaquin",
                            "lastName": "Candela",
                            "middleNames": [
                                "Qui\u00f1onero"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Q. Candela"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3472959"
                        ],
                        "name": "C. Rasmussen",
                        "slug": "C.-Rasmussen",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Rasmussen",
                            "middleNames": [
                                "Edward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rasmussen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 161
                            }
                        ],
                        "text": "All sparse pseudoinput GP approximations can be specified in terms of the form used for the training and test conditionals q\u00f0f j u\u00de and q\u00f0f ? j u\u00de, respectively [124]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16005390,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "713fb831bf324690aa7a7e07ace3443770046007",
            "isKey": false,
            "numCitedBy": 1625,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We provide a new unifying view, including all existing proper probabilistic sparse approximations for Gaussian process regression. Our approach relies on expressing the effective prior which the methods are using. This allows new insights to be gained, and highlights the relationship between existing methods. It also allows for a clear theoretically justified ranking of the closeness of the known approximations to the corresponding full GPs. Finally we point directly to designs of new better sparse approximations, combining the best of the existing strategies, within attractive computational constraints."
            },
            "slug": "A-Unifying-View-of-Sparse-Approximate-Gaussian-Candela-Rasmussen",
            "title": {
                "fragments": [],
                "text": "A Unifying View of Sparse Approximate Gaussian Process Regression"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "A new unifying view, including all existing proper probabilistic sparse approximations for Gaussian process regression, relies on expressing the effective prior which the methods are using, and highlights the relationship between existing methods."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144543541"
                        ],
                        "name": "P. Auer",
                        "slug": "P.-Auer",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Auer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Auer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388387856"
                        ],
                        "name": "N. Cesa-Bianchi",
                        "slug": "N.-Cesa-Bianchi",
                        "structuredName": {
                            "firstName": "Nicol\u00f2",
                            "lastName": "Cesa-Bianchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cesa-Bianchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703537"
                        ],
                        "name": "Y. Freund",
                        "slug": "Y.-Freund",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Freund",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Freund"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716301"
                        ],
                        "name": "R. Schapire",
                        "slug": "R.-Schapire",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schapire",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schapire"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In the generalized linear model, Thompson sampling draws a w\u0303 from the posterior p(w | Dn) using MCMC or a Laplace approximation, and then selects the arm with the highest expected reward given the sampled parameter w\u0303, i.e., an+1 = arg maxa g \u22121(xTa w\u0303)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8963242,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "305d689afb6574ffec7b01e24431d541d0ce6f5d",
            "isKey": false,
            "numCitedBy": 829,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "In the multi-armed bandit problem, a gambler must decide which arm of K non-identical slot machines to play in a sequence of trials so as to maximize his reward. This classical problem has received much attention because of the simple model it provides of the trade-off between exploration (trying out each arm to find the best one) and exploitation (playing the arm believed to give the best payoff). Past solutions for the bandit problem have almost always relied on assumptions about the statistics of the slot machines. In this work, we make no statistical assumptions whatsoever about the nature of the process generating the payoffs of the slot machines. We give a solution to the bandit problem in which an adversary, rather than a well-behaved stochastic process, has complete control over the payoffs. In a sequence of T plays, we prove that the expected per-round payoff of our algorithm approaches that of the best arm at the rate O(T/sup -1/3/), and we give an improved rate of convergence when the best arm has fairly low payoff. We also consider a setting in which the player has a team of \"experts\" advising him on which arm to play; here, we give a strategy that will guarantee expected payoff close to that of the best expert. Finally, we apply our result to the problem of learning to play an unknown repeated matrix game against an all-powerful adversary."
            },
            "slug": "Gambling-in-a-rigged-casino:-The-adversarial-bandit-Auer-Cesa-Bianchi",
            "title": {
                "fragments": [],
                "text": "Gambling in a rigged casino: The adversarial multi-armed bandit problem"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A solution to the bandit problem in which an adversary, rather than a well-behaved stochastic process, has complete control over the payoffs is given."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of IEEE 36th Annual Foundations of Computer Science"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715051"
                        ],
                        "name": "Misha Denil",
                        "slug": "Misha-Denil",
                        "structuredName": {
                            "firstName": "Misha",
                            "lastName": "Denil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Misha Denil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809420"
                        ],
                        "name": "Loris Bazzani",
                        "slug": "Loris-Bazzani",
                        "structuredName": {
                            "firstName": "Loris",
                            "lastName": "Bazzani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Loris Bazzani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777528"
                        ],
                        "name": "H. Larochelle",
                        "slug": "H.-Larochelle",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Larochelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Larochelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 2
                            }
                        ],
                        "text": "The denominator p(D) is the marginal likelihood, or evidence, and is usually computationally intractable."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6661488,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72829d537f0ec8b1cc0ced2f278bb56ce89f1b0c",
            "isKey": false,
            "numCitedBy": 177,
            "numCiting": 71,
            "paperAbstract": {
                "fragments": [],
                "text": "We discuss an attentional model for simultaneous object tracking and recognition that is driven by gaze data. Motivated by theories of perception, the model consists of two interacting pathways, identity and control, intended to mirror the what and where pathways in neuroscience models. The identity pathway models object appearance and performs classification using deep (factored)-restricted Boltzmann machines. At each point in time, the observations consist of foveated images, with decaying resolution toward the periphery of the gaze. The control pathway models the location, orientation, scale, and speed of the attended object. The posterior distribution of these states is estimated with particle filtering. Deeper in the control pathway, we encounter an attentional mechanism that learns to select gazes so as to minimize tracking uncertainty. Unlike in our previous work, we introduce gaze selection strategies that operate in the presence of partial information and on a continuous action space. We show that a straightforward extension of the existing approach to the partial information setting results in poor performance, and we propose an alternative method based on modeling the reward surface as a gaussian process. This approach gives good performance in the presence of partial information and allows us to expand the action space from a small, discrete set of fixation points to a continuous domain."
            },
            "slug": "Learning-Where-to-Attend-with-Deep-Architectures-Denil-Bazzani",
            "title": {
                "fragments": [],
                "text": "Learning Where to Attend with Deep Architectures for Image Tracking"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "An attentional model for simultaneous object tracking and recognition that is driven by gaze data is discussed, and a straightforward extension of the existing approach to the partial information setting results in poor performance, and an alternative method based on modeling the reward surface as a gaussian process is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730609"
                        ],
                        "name": "O. Chapelle",
                        "slug": "O.-Chapelle",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Chapelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Chapelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47681372"
                        ],
                        "name": "Lihong Li",
                        "slug": "Lihong-Li",
                        "structuredName": {
                            "firstName": "Lihong",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lihong Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally, we introduce more recent developments in Section VIII."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 94
                            }
                        ],
                        "text": "In the generalized linear model, Thompson sampling draws a w\u0303 from the posterior p(w | Dn) using MCMC or a Laplace approximation, and then selects the arm with the highest expected reward given the sampled parameter w\u0303, i.e., an+1 = arg maxa g \u22121(xTa w\u0303)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "Illustration of the Bayesian optimization procedure over three iterations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6002655,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "ab867c140d2947511979c87e7ae580d9d3f0aeab",
            "isKey": false,
            "numCitedBy": 1106,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Thompson sampling is one of oldest heuristic to address the exploration / exploitation trade-off, but it is surprisingly unpopular in the literature. We present here some empirical results using Thompson sampling on simulated and real data, and show that it is highly competitive. And since this heuristic is very easy to implement, we argue that it should be part of the standard baselines to compare against."
            },
            "slug": "An-Empirical-Evaluation-of-Thompson-Sampling-Chapelle-Li",
            "title": {
                "fragments": [],
                "text": "An Empirical Evaluation of Thompson Sampling"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Empirical results using Thompson sampling on simulated and real data are presented, and it is shown that it is highly competitive and should be part of the standard baselines to compare against."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716777"
                        ],
                        "name": "A. Criminisi",
                        "slug": "A.-Criminisi",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Criminisi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Criminisi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143774737"
                        ],
                        "name": "J. Shotton",
                        "slug": "J.-Shotton",
                        "structuredName": {
                            "firstName": "Jamie",
                            "lastName": "Shotton",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shotton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796918"
                        ],
                        "name": "E. Konukoglu",
                        "slug": "E.-Konukoglu",
                        "structuredName": {
                            "firstName": "Ender",
                            "lastName": "Konukoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Konukoglu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62574244,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7dcfa66b0e6b661877d04a4b67286021d5957e9a",
            "isKey": false,
            "numCitedBy": 813,
            "numCiting": 118,
            "paperAbstract": {
                "fragments": [],
                "text": "This review presents a unified, efficient model of random decision forests which can be applied to a number of machine learning, computer vision, and medical image analysis tasks. \n \nOur model extends existing forest-based techniques as it unifies classification, regression, density estimation, manifold learning, semi-supervised learning, and active learning under the same decision forest framework. This gives us the opportunity to write and optimize the core implementation only once, with application to many diverse tasks. \n \nThe proposed model may be used both in a discriminative or generative way and may be applied to discrete or continuous, labeled or unlabeled data. \n \nThe main contributions of this review are: (1) Proposing a unified, probabilistic and efficient model for a variety of learning tasks; (2) Demonstrating margin-maximizing properties of classification forests; (3) Discussing probabilistic regression forests in comparison with other nonlinear regression algorithms; (4) Introducing density forests for estimating probability density functions; (5) Proposing an efficient algorithm for sampling from a density forest; (6) Introducing manifold forests for nonlinear dimensionality reduction; (7) Proposing new algorithms for transductive learning and active learning. Finally, we discuss how alternatives such as random ferns and extremely randomized trees stem from our more general forest model. \n \nThis document is directed at both students who wish to learn the basics of decision forests, as well as researchers interested in the new contributions. It presents both fundamental and novel concepts in a structured way, with many illustrative examples and real-world applications. Thorough comparisons with state-of-the-art algorithms such as support vector machines, boosting and Gaussian processes are presented and relative advantages and disadvantages discussed. The many synthetic examples and existing commercial applications demonstrate the validity of the proposed model and its flexibility."
            },
            "slug": "Decision-Forests:-A-Unified-Framework-for-Density-Criminisi-Shotton",
            "title": {
                "fragments": [],
                "text": "Decision Forests: A Unified Framework for Classification, Regression, Density Estimation, Manifold Learning and Semi-Supervised Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A unified, efficient model of random decision forests which can be applied to a number of machine learning, computer vision, and medical image analysis tasks is presented and relative advantages and disadvantages discussed."
            },
            "venue": {
                "fragments": [],
                "text": "Found. Trends Comput. Graph. Vis."
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37178915"
                        ],
                        "name": "A. Carpentier",
                        "slug": "A.-Carpentier",
                        "structuredName": {
                            "firstName": "Alexandra",
                            "lastName": "Carpentier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Carpentier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708654"
                        ],
                        "name": "R. Munos",
                        "slug": "R.-Munos",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Munos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Munos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "For linear bandits, Carpentier and Munos [35] recently proposed a compressed sensing strategy to attack problems with a high degree of sparsity."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7380181,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "4a91e5863005c60ec2a7eac44bff6446b2596f1f",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider a linear stochastic bandit problem where the dimension K of the unknown parameter is larger than the sampling budget n. In such cases, it is in general impossible to derive sub-linear regret bounds since usual linear bandit algorithms have a regret in O(K p n). In this paper we assume that is S sparse, i.e. has at most S non-zero components, and that the space of arms is the unit ball for the jj:jj2 norm. We combine ideas from Compressed Sensing and Bandit Theory and derive an algorithm with a regret bound in O(S p n). We detail an application to the problem of optimizing a function that depends on many variables but among which only a small number of them (initially unknown) are relevant."
            },
            "slug": "Bandit-Theory-meets-Compressed-Sensing-for-high-Carpentier-Munos",
            "title": {
                "fragments": [],
                "text": "Bandit Theory meets Compressed Sensing for high dimensional Stochastic Linear Bandit"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper combines ideas from Compressed Sensing and Bandit Theory and derive an algorithm with a regret bound in O(S p n), an application to the problem of optimizing a function that depends on many variables but among which only a small number of them are relevant."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3283191"
                        ],
                        "name": "V. Picheny",
                        "slug": "V.-Picheny",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Picheny",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Picheny"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3343244"
                        ],
                        "name": "D. Ginsbourger",
                        "slug": "D.-Ginsbourger",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ginsbourger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ginsbourger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 3
                            }
                        ],
                        "text": "in [122], where the authors construct a GP with nonstationary noise process that starts high when the"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 26208992,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dfc617e52c65291ee8941cd48bc5a92e6bd1208b",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "In the context of expensive numerical experiments, a promising solution for alleviating the computational costs consists of using partially converged simulations instead of exact solutions. The gain in computational time is at the price of precision in the response. This work addresses the issue of fitting a Gaussian process model to partially converged simulation data for further use in prediction. The main challenge consists of the adequate approximation of the error due to partial convergence, which is correlated in both design variables and time directions. Here, we propose fitting a Gaussian process in the joint space of design parameters and computational time. The model is constructed by building a nonstationary covariance kernel that reflects accurately the actual structure of the error. Practical solutions are proposed for solving parameter estimation issues associated with the proposed model. The method is applied to a computational fluid dynamics test case and shows significant improvement in p..."
            },
            "slug": "A-Nonstationary-Space-Time-Gaussian-Process-Model-Picheny-Ginsbourger",
            "title": {
                "fragments": [],
                "text": "A Nonstationary Space-Time Gaussian Process Model for Partially Converged Simulations"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work addresses the issue of fitting a Gaussian process model to partially converged simulation data for further use in prediction by building a nonstationary covariance kernel that reflects accurately the actual structure of the error."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM/ASA J. Uncertain. Quantification"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815542"
                        ],
                        "name": "S\u00e9bastien Bubeck",
                        "slug": "S\u00e9bastien-Bubeck",
                        "structuredName": {
                            "firstName": "S\u00e9bastien",
                            "lastName": "Bubeck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S\u00e9bastien Bubeck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388387856"
                        ],
                        "name": "N. Cesa-Bianchi",
                        "slug": "N.-Cesa-Bianchi",
                        "structuredName": {
                            "firstName": "Nicol\u00f2",
                            "lastName": "Cesa-Bianchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cesa-Bianchi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207179066,
            "fieldsOfStudy": [
                "Economics",
                "Computer Science"
            ],
            "id": "9ae45d013a90c4a562b1e380fe032b20d0779577",
            "isKey": false,
            "numCitedBy": 2154,
            "numCiting": 198,
            "paperAbstract": {
                "fragments": [],
                "text": "A multi-armed bandit problem - or, simply, a bandit problem - is a sequential allocation problem defined by a set of actions. At each time step, a unit resource is allocated to an action and some observable payoff is obtained. The goal is to maximize the total payoff obtained in a sequence of allocations. The name bandit refers to the colloquial term for a slot machine (a \"one-armed bandit\" in American slang). In a casino, a sequential allocation problem is obtained when the player is facing many slot machines at once (a \"multi-armed bandit\"), and must repeatedly choose where to insert the next coin. Multi-armed bandit problems are the most basic examples of sequential decision problems with an exploration-exploitation trade-off. This is the balance between staying with the option that gave highest payoffs in the past and exploring new options that might give higher payoffs in the future. Although the study of bandit problems dates back to the 1930s, exploration-exploitation trade-offs arise in several modern applications, such as ad placement, website optimization, and packet routing. Mathematically, a multi-armed bandit is defined by the payoff process associated with each option. In this book, the focus is on two extreme cases in which the analysis of regret is particularly simple and elegant: independent and identically distributed payoffs and adversarial payoffs. Besides the basic setting of finitely many actions, it also analyzes some of the most important variants and extensions, such as the contextual bandit model. This monograph is an ideal reference for students and researchers with an interest in bandit problems."
            },
            "slug": "Regret-Analysis-of-Stochastic-and-Nonstochastic-Bubeck-Cesa-Bianchi",
            "title": {
                "fragments": [],
                "text": "Regret Analysis of Stochastic and Nonstochastic Multi-armed Bandit Problems"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "The focus is on two extreme cases in which the analysis of regret is particularly simple and elegant: independent and identically distributed payoffs and adversarial payoffs."
            },
            "venue": {
                "fragments": [],
                "text": "Found. Trends Mach. Learn."
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3055651"
                        ],
                        "name": "E. Contal",
                        "slug": "E.-Contal",
                        "structuredName": {
                            "firstName": "Emile",
                            "lastName": "Contal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Contal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3087994"
                        ],
                        "name": "Vianney Perchet",
                        "slug": "Vianney-Perchet",
                        "structuredName": {
                            "firstName": "Vianney",
                            "lastName": "Perchet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vianney Perchet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715204"
                        ],
                        "name": "N. Vayatis",
                        "slug": "N.-Vayatis",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Vayatis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vayatis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 239,
                                "start": 235
                            }
                        ],
                        "text": "bandits [89]; Bayes regret bounds for TS [85], [127]; bounds for high-dimensional problems with an underlying low-rank structure [46]; bounds for parallel Bayesian optimization [45]; and improved regret bounds using mutual information [41]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9474720,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4dde6555e6cf51c25870aa49a80dfd18452b03f",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we analyze a generic algorithm scheme for sequential global optimization using Gaussian processes. The upper bounds we derive on the cumulative regret for this generic algorithm improve by an exponential factor the previously known bounds for algorithms like GP-UCB. We also introduce the novel Gaussian Process Mutual Information algorithm (GP-MI), which significantly improves further these upper bounds for the cumulative regret. We confirm the efficiency of this algorithm on synthetic and real tasks against the natural competitor, GP-UCB, and also the Expected Improvement heuristic."
            },
            "slug": "Gaussian-Process-Optimization-with-Mutual-Contal-Perchet",
            "title": {
                "fragments": [],
                "text": "Gaussian Process Optimization with Mutual Information"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "The upper bounds on the cumulative regret for this generic algorithm improve by an exponential factor the previously known bounds for algorithms like GP-UCB, and the novel Gaussian Process Mutual Information algorithm, GP-MI, is introduced, which significantly improves further these upper bounds."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388387856"
                        ],
                        "name": "N. Cesa-Bianchi",
                        "slug": "N.-Cesa-Bianchi",
                        "structuredName": {
                            "firstName": "Nicol\u00f2",
                            "lastName": "Cesa-Bianchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cesa-Bianchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755694"
                        ],
                        "name": "G. Lugosi",
                        "slug": "G.-Lugosi",
                        "structuredName": {
                            "firstName": "G\u00e1bor",
                            "lastName": "Lugosi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lugosi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The book of Cesa-Bianchi [36] is a good reference on the topic of online learning with experts and bandits in adversarial settings."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 28709420,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9fa9777415729cebfcbcb5ee667057e981f9912e",
            "isKey": false,
            "numCitedBy": 3247,
            "numCiting": 318,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Introduction 2. Prediction with expert advice 3. Tight bounds for specific losses 4. Randomized prediction 5. Efficient forecasters for large classes of experts 6. Prediction with limited feedback 7. Prediction and playing games 8. Absolute loss 9. Logarithmic loss 10. Sequential investment 11. Linear pattern recognition 12. Linear classification 13. Appendix."
            },
            "slug": "Prediction,-learning,-and-games-Cesa-Bianchi-Lugosi",
            "title": {
                "fragments": [],
                "text": "Prediction, learning, and games"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This chapter discusses prediction with expert advice, efficient forecasters for large classes of experts, and randomized prediction for specific losses."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36572609"
                        ],
                        "name": "M. Zoghi",
                        "slug": "M.-Zoghi",
                        "structuredName": {
                            "firstName": "Masrour",
                            "lastName": "Zoghi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Zoghi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16212258,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5cac07692791d5b75cc810050d5dad7070cfa926",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper analyzes the problem of Gaussian process (GP) bandits with deterministic observations. The analysis uses a branch and bound algorithm that is related to the UCB algorithm of (Srinivas et al., 2010). For GPs with Gaussian observation noise, with variance strictly greater than zero, (Srinivas et al., 2010) proved that the regret vanishes at the approximate rate of O(1/\u221at), where t is the number of observations. To complement their result, we attack the deterministic case and attain a much faster exponential convergence rate. Under some regularity assumptions, we show that the regret decreases asymptotically according to O(e-\u03c4t/(ln t)d/4) with high probability. Here, d is the dimension of the search space and \u03c4 is a constant that depends on the behaviour of the objective function near its global maximum."
            },
            "slug": "Exponential-Regret-Bounds-for-Gaussian-Process-with-Freitas-Smola",
            "title": {
                "fragments": [],
                "text": "Exponential Regret Bounds for Gaussian Process Bandits with Deterministic Observations"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This paper analyzes the problem of Gaussian process (GP) bandits with deterministic observations with a branch and bound algorithm that is related to the UCB algorithm and shows that the regret decreases asymptotically according to O(e-\u03c4t/(ln t)d/4) with high probability."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145489055"
                        ],
                        "name": "Y. Zhang",
                        "slug": "Y.-Zhang",
                        "structuredName": {
                            "firstName": "Y.",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729571"
                        ],
                        "name": "Kihyuk Sohn",
                        "slug": "Kihyuk-Sohn",
                        "structuredName": {
                            "firstName": "Kihyuk",
                            "lastName": "Sohn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kihyuk Sohn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144543406"
                        ],
                        "name": "Ruben Villegas",
                        "slug": "Ruben-Villegas",
                        "structuredName": {
                            "firstName": "Ruben",
                            "lastName": "Villegas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruben Villegas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144563871"
                        ],
                        "name": "Gang Pan",
                        "slug": "Gang-Pan",
                        "structuredName": {
                            "firstName": "Gang",
                            "lastName": "Pan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gang Pan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697141"
                        ],
                        "name": "Honglak Lee",
                        "slug": "Honglak-Lee",
                        "structuredName": {
                            "firstName": "Honglak",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Honglak Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 25
                            }
                        ],
                        "text": "This forms the basis of our likelihood model, in which the observations for arm a are drawn from a Gaussian distribution with mean xTaw and variance \u03c3\n2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1078871,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "215cf528ed98049724969ceb82c66e78edda8d51",
            "isKey": false,
            "numCitedBy": 175,
            "numCiting": 71,
            "paperAbstract": {
                "fragments": [],
                "text": "Object detection systems based on the deep convolutional neural network (CNN) have recently made ground-breaking advances on several object detection benchmarks. While the features learned by these high-capacity neural networks are discriminative for categorization, inaccurate localization is still a major source of error for detection. Building upon high-capacity CNN architectures, we address the localization problem by 1) using a search algorithm based on Bayesian optimization that sequentially proposes candidate regions for an object bounding box, and 2) training the CNN with a structured loss that explicitly penalizes the localization inaccuracy. In experiments, we demonstrate that each of the proposed methods improves the detection performance over the baseline method on PASCAL VOC 2007 and 2012 datasets. Furthermore, two methods are complementary and significantly outperform the previous state-of-the-art when combined."
            },
            "slug": "Improving-object-detection-with-deep-convolutional-Zhang-Sohn",
            "title": {
                "fragments": [],
                "text": "Improving object detection with deep convolutional networks via Bayesian optimization and structured prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work addresses the localization problem by using a search algorithm based on Bayesian optimization that sequentially proposes candidate regions for an object bounding box, and training the CNN with a structured loss that explicitly penalizes the localization inaccuracy."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722180"
                        ],
                        "name": "Ryan P. Adams",
                        "slug": "Ryan-P.-Adams",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Adams",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan P. Adams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152423211"
                        ],
                        "name": "O. Stegle",
                        "slug": "O.-Stegle",
                        "structuredName": {
                            "firstName": "Oliver",
                            "lastName": "Stegle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Stegle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 107
                            }
                        ],
                        "text": "Another form of nonstationarity that is closely related to heteroscedasticity is a nonstationary amplitude [1], [54]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5769314,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "333eb4aa2055c0981462b1fefd3421783b0be45c",
            "isKey": false,
            "numCitedBy": 45,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Stationarity is often an unrealistic prior assumption for Gaussian process regression. One solution is to predefine an explicit nonstationary covariance function, but such covariance functions can be difficult to specify and require detailed prior knowledge of the nonstationarity. We propose the Gaussian process product model (GPPM) which models data as the pointwise product of two latent Gaussian processes to nonparametrically infer nonstationary variations of amplitude. This approach differs from other nonparametric approaches to covariance function inference in that it operates on the outputs rather than the inputs, resulting in a significant reduction in computational cost and required data for inference. We present an approximate inference scheme using Expectation Propagation. This variational approximation yields convenient GP hyperparameter selection and compact approximate predictive distributions."
            },
            "slug": "Gaussian-process-product-models-for-nonparametric-Adams-Stegle",
            "title": {
                "fragments": [],
                "text": "Gaussian process product models for nonparametric nonstationarity"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The Gaussian process product model (GPPM) is proposed which models data as the pointwise product of two latent Gaussian processes to nonparametrically infer nonstationary variations of amplitude to reduce computational cost and required data for inference."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2578263"
                        ],
                        "name": "E. Kaufmann",
                        "slug": "E.-Kaufmann",
                        "structuredName": {
                            "firstName": "Emilie",
                            "lastName": "Kaufmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Kaufmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33656309"
                        ],
                        "name": "N. Korda",
                        "slug": "N.-Korda",
                        "structuredName": {
                            "firstName": "Nathaniel",
                            "lastName": "Korda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Korda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708654"
                        ],
                        "name": "R. Munos",
                        "slug": "R.-Munos",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Munos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Munos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 190
                            }
                        ],
                        "text": "Though it was introduced in 1933 [150], TS has attracted renewed interest in the multiarmed bandit community, producing empirical evaluations [38], [135] as well as theoretical results [2], [85], [127]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "bandits [89]; Bayes regret bounds for TS [85], [127]; bounds for high-dimensional problems with an underlying low-rank structure [46]; bounds for parallel Bayesian optimization [45]; and improved regret bounds using mutual information [41]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14803226,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "2e96fc720aabb0039f1e9819f4b78259924965ae",
            "isKey": false,
            "numCitedBy": 484,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "The question of the optimality of Thompson Sampling for solving the stochastic multi-armed bandit problem had been open since 1933. In this paper we answer it positively for the case of Bernoulli rewards by providing the first finite-time analysis that matches the asymptotic rate given in the Lai and Robbins lower bound for the cumulative regret. The proof is accompanied by a numerical comparison with other optimal policies, experiments that have been lacking in the literature until now for the Bernoulli case."
            },
            "slug": "Thompson-Sampling:-An-Asymptotically-Optimal-Kaufmann-Korda",
            "title": {
                "fragments": [],
                "text": "Thompson Sampling: An Asymptotically Optimal Finite-Time Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "The question of the optimality of Thompson Sampling for solving the stochastic multi-armed bandit problem is answered positively for the case of Bernoulli rewards by providing the first finite-time analysis that matches the asymptotic rate given in the Lai and Robbins lower bound for the cumulative regret."
            },
            "venue": {
                "fragments": [],
                "text": "ALT"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388666962"
                        ],
                        "name": "M. L\u00e1zaro-Gredilla",
                        "slug": "M.-L\u00e1zaro-Gredilla",
                        "structuredName": {
                            "firstName": "Miguel",
                            "lastName": "L\u00e1zaro-Gredilla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. L\u00e1zaro-Gredilla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3177568"
                        ],
                        "name": "J. Q. Candela",
                        "slug": "J.-Q.-Candela",
                        "structuredName": {
                            "firstName": "Joaquin",
                            "lastName": "Candela",
                            "middleNames": [
                                "Qui\u00f1onero"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Q. Candela"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3472959"
                        ],
                        "name": "C. Rasmussen",
                        "slug": "C.-Rasmussen",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Rasmussen",
                            "middleNames": [
                                "Edward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rasmussen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398493114"
                        ],
                        "name": "A. Figueiras-Vidal",
                        "slug": "A.-Figueiras-Vidal",
                        "structuredName": {
                            "firstName": "An\u00edbal",
                            "lastName": "Figueiras-Vidal",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Figueiras-Vidal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "However, using recent spectral sampling techniques [20], [94], [125], we can draw an"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 264,
                                "start": 260
                            }
                        ],
                        "text": "2) Sparse Spectrum Gaussian Processes (SSGPs): While inducing pseudoinputs reduce computational complexity by using a fixed number of points in the search space, sparse spectrum Gaussian processes (SSGPs) take a similar approach to the kernel\u2019s spectral space [94]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 156
                            }
                        ],
                        "text": "Although this violates the MC assumption and introduces a risk of overfitting, it allows for a smaller number of basis functions with good predictive power [94]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8501263,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f2b1b678ee6295136fdc25d04a804df95badd065",
            "isKey": false,
            "numCitedBy": 389,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new sparse Gaussian Process (GP) model for regression. The key novel idea is to sparsify the spectral representation of the GP. This leads to a simple, practical algorithm for regression tasks. We compare the achievable trade-offs between predictive accuracy and computational requirements, and show that these are typically superior to existing state-of-the-art sparse approximations. We discuss both the weight space and function space representations, and note that the new construction implies priors over functions which are always stationary, and can approximate any covariance function in this class."
            },
            "slug": "Sparse-Spectrum-Gaussian-Process-Regression-L\u00e1zaro-Gredilla-Candela",
            "title": {
                "fragments": [],
                "text": "Sparse Spectrum Gaussian Process Regression"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The achievable trade-offs between predictive accuracy and computational requirements are compared, and it is shown that these are typically superior to existing state-of-the-art sparse approximations."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3269957"
                        ],
                        "name": "A. Zilinskas",
                        "slug": "A.-Zilinskas",
                        "structuredName": {
                            "firstName": "Antanas",
                            "lastName": "Zilinskas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zilinskas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2404676"
                        ],
                        "name": "J. Zilinskas",
                        "slug": "J.-Zilinskas",
                        "structuredName": {
                            "firstName": "Julius",
                            "lastName": "Zilinskas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Zilinskas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 120339829,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "671dd47e4aadda5e3e7020c6854cd578d69d5d4b",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Global-optimization-based-on-a-statistical-model-Zilinskas-Zilinskas",
            "title": {
                "fragments": [],
                "text": "Global optimization based on a statistical model and simplicial partitioning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5054589"
                        ],
                        "name": "K. Chaloner",
                        "slug": "K.-Chaloner",
                        "structuredName": {
                            "firstName": "Kathryn",
                            "lastName": "Chaloner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Chaloner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1816502"
                        ],
                        "name": "I. Verdinelli",
                        "slug": "I.-Verdinelli",
                        "structuredName": {
                            "firstName": "Isabella",
                            "lastName": "Verdinelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Verdinelli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "See [37] for a detailed survey."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[37] K."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13676847,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8f79332b1361e9eaa9da3327f83f57dcac5cd11d",
            "isKey": false,
            "numCitedBy": 1718,
            "numCiting": 319,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reviews the literature on Bayesian experimental design, both for linear and nonlinear models. A uniied view of the topic is presented by putting experimental design in a decision theoretic framework. This framework justiies many optimality criteria, and opens new possibilities. Various design criteria become part of a single, coherent approach."
            },
            "slug": "Bayesian-Experimental-Design:-A-Review-Chaloner-Verdinelli",
            "title": {
                "fragments": [],
                "text": "Bayesian Experimental Design: A Review"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "This paper reviews the literature on Bayesian experimental design, both for linear and nonlinear models, and presents a uniied view of the topic by putting experimental design in a decision theoretic framework."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1941450"
                        ],
                        "name": "P. Sampson",
                        "slug": "P.-Sampson",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Sampson",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sampson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1957528"
                        ],
                        "name": "P. Guttorp",
                        "slug": "P.-Guttorp",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Guttorp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Guttorp"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "One strategy is to convert a stationary kernel into a nonstationary one by transforming x using a parametric warping function x\u00f0w\u00de 1\u20444 w\u00f0x\u00de and then applying a stationary kernel to x\u00f0w\u00de [129], [145]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[129] P."
                    },
                    "intents": []
                }
            ],
            "corpusId": 121792632,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "b451f70151e3d1cef39fce565dbf36a533579e5a",
            "isKey": false,
            "numCitedBy": 775,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Estimation of the covariance structure of spatial processes is a fundamental prerequisite for problems of spatial interpolation and the design of monitoring networks. We introduce a nonparametric approach to global estimation of the spatial covariance structure of a random function Z(x, t) observed repeatedly at times ti (i = 1, \u2026, T) at a finite number of sampling stations xi (i = 1, 2, \u2026, N) in the plane. Our analyses assume temporal stationarity but do not assume spatial stationarity (or isotropy). We analyze the spatial dispersions var(Z(xi, t) \u2212 Z(xj, t)) as a natural metric for the spatial covariance structure and model these as a general smooth function of the geographic coordinates of station pairs (xi, xj ). The model is constructed in two steps. First, using nonmetric multidimensional scaling (MDS) we compute a two-dimensional representation of the sampling stations for which a monotone function of interpoint distances \u03b4ij approximates the spatial dispersions. MDS transforms the problem..."
            },
            "slug": "Nonparametric-Estimation-of-Nonstationary-Spatial-Sampson-Guttorp",
            "title": {
                "fragments": [],
                "text": "Nonparametric Estimation of Nonstationary Spatial Covariance Structure"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49630843"
                        ],
                        "name": "C. Andrieu",
                        "slug": "C.-Andrieu",
                        "structuredName": {
                            "firstName": "Christophe",
                            "lastName": "Andrieu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Andrieu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701800"
                        ],
                        "name": "A. Doucet",
                        "slug": "A.-Doucet",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Doucet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Doucet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 13
                            }
                        ],
                        "text": "MCMC methods [4] approximate the posterior with a sequence of samples that converge to the posterior; this is the approach taken in [135] on the probit model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 38363,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "596dac923657992a817d3d68ae83f2fba9cf1ab8",
            "isKey": false,
            "numCitedBy": 2349,
            "numCiting": 169,
            "paperAbstract": {
                "fragments": [],
                "text": "This purpose of this introductory paper is threefold. First, it introduces the Monte Carlo method with emphasis on probabilistic machine learning. Second, it reviews the main building blocks of modern Markov chain Monte Carlo simulation, thereby providing and introduction to the remaining papers of this special issue. Lastly, it discusses new interesting research horizons."
            },
            "slug": "An-Introduction-to-MCMC-for-Machine-Learning-Andrieu-Freitas",
            "title": {
                "fragments": [],
                "text": "An Introduction to MCMC for Machine Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "This purpose of this introductory paper is to introduce the Monte Carlo method with emphasis on probabilistic machine learning and review the main building blocks of modern Markov chain Monte Carlo simulation."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722732"
                        ],
                        "name": "M. Titsias",
                        "slug": "M.-Titsias",
                        "structuredName": {
                            "firstName": "Michalis",
                            "lastName": "Titsias",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Titsias"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In contrast, a variational approach has since been proposed to marginalize the pseudoinputs to maximize fidelity to the original exact GP [152] rather than the likelihood of the approximate GP."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7811257,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4de6082e2af026b5925810f7e7a1b04736496e2",
            "isKey": false,
            "numCitedBy": 1122,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Sparse Gaussian process methods that use inducing variables require the selection of the inducing inputs and the kernel hyperparameters. We introduce a variational formulation for sparse approximations that jointly infers the inducing inputs and the kernel hyperparameters by maximizing a lower bound of the true log marginal likelihood. The key property of this formulation is that the inducing inputs are defined to be variational parameters which are selected by minimizing the Kullback-Leibler divergence between the variational distribution and the exact posterior distribution over the latent function values. We apply this technique to regression and we compare it with other approaches in the literature."
            },
            "slug": "Variational-Learning-of-Inducing-Variables-in-Titsias",
            "title": {
                "fragments": [],
                "text": "Variational Learning of Inducing Variables in Sparse Gaussian Processes"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "A variational formulation for sparse approximations that jointly infers the inducing inputs and the kernel hyperparameters by maximizing a lower bound of the true log marginal likelihood."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2081889"
                        ],
                        "name": "Edward Snelson",
                        "slug": "Edward-Snelson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Snelson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edward Snelson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3472959"
                        ],
                        "name": "C. Rasmussen",
                        "slug": "C.-Rasmussen",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Rasmussen",
                            "middleNames": [
                                "Edward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rasmussen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744700"
                        ],
                        "name": "Zoubin Ghahramani",
                        "slug": "Zoubin-Ghahramani",
                        "structuredName": {
                            "firstName": "Zoubin",
                            "lastName": "Ghahramani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zoubin Ghahramani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 213
                            }
                        ],
                        "text": "There are many other examples of nonstationary covariance functions [3], [22], [54], [70], [118], [121], [126], [132] that have been proposed for GP regression along with closely related output warping techniques [141] that can also model certain kinds of nonstationary processes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 97303,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5af14ca62e2b6f2c59b245d097b0c5093f8b36ce",
            "isKey": false,
            "numCitedBy": 308,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "We generalise the Gaussian process (GP) framework for regression by learning a nonlinear transformation of the GP outputs. This allows for non-Gaussian processes and non-Gaussian noise. The learning algorithm chooses a nonlinear transformation such that transformed data is well-modelled by a GP. This can be seen as including a preprocessing transformation as an integral part of the probabilistic modelling problem, rather than as an ad-hoc step. We demonstrate on several real regression problems that learning the transformation can lead to significantly better performance than using a regular GP, or a GP with a fixed transformation."
            },
            "slug": "Warped-Gaussian-Processes-Snelson-Rasmussen",
            "title": {
                "fragments": [],
                "text": "Warped Gaussian Processes"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This work generalises the Gaussian process (GP) framework for regression by learning a nonlinear transformation of the GP outputs, which allows for non-Gaussian processes and non- Gaussian noise."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": "Recently, such basis functions have also been learned from data by training deep belief networks [71], deep neural networks [93], [144], or by factoring the empirical covariance matrix of historical data [72], [146]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 477440,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f2e95236f0fccc0b70e757ac2ebbc79b7f51de0a",
            "isKey": false,
            "numCitedBy": 214,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "We show how to use unlabeled data and a deep belief net (DBN) to learn a good covariance kernel for a Gaussian process. We first learn a deep generative model of the unlabeled data using the fast, greedy algorithm introduced by [7]. If the data is high-dimensional and highly-structured, a Gaussian kernel applied to the top layer of features in the DBN works much better than a similar kernel applied to the raw input. Performance at both regression and classification can then be further improved by using backpropagation through the DBN to discriminatively fine-tune the covariance kernel."
            },
            "slug": "Using-Deep-Belief-Nets-to-Learn-Covariance-Kernels-Salakhutdinov-Hinton",
            "title": {
                "fragments": [],
                "text": "Using Deep Belief Nets to Learn Covariance Kernels for Gaussian Processes"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "This work shows how to use unlabeled data and a deep belief net (DBN) to learn a good covariance kernel for a Gaussian process."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725303"
                        ],
                        "name": "Y. Teh",
                        "slug": "Y.-Teh",
                        "structuredName": {
                            "firstName": "Yee",
                            "lastName": "Teh",
                            "middleNames": [
                                "Whye"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Teh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680574"
                        ],
                        "name": "M. Seeger",
                        "slug": "M.-Seeger",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Seeger",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Seeger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[136] M."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "coregionalization (ICM) [21], [60], [136] that utilizes the product kernel"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206400,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e33131dc7180e92be2f2dfd366aaf1c0ed50dee8",
            "isKey": false,
            "numCitedBy": 239,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a semiparametric model for regression and classification problems involving multiple response variables. The model makes use of a set of Gaussian processes to model the relationship to the inputs in a nonparametric fashion. Conditional dependencies between the responses can be captured through a linear mixture of the driving processes. This feature becomes important if some of the responses of predictive interest are less densely supplied by observed data than related auxiliary ones. We propose an efficient approximate inference scheme for this semiparametric model whose complexity is linear in the number of training data points."
            },
            "slug": "Semiparametric-latent-factor-models-Teh-Seeger",
            "title": {
                "fragments": [],
                "text": "Semiparametric latent factor models"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A semiparametric model for regression and classification problems involving multiple response variables makes use of a set of Gaussian processes to model the relationship to the inputs in a nonparametric fashion."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794818"
                        ],
                        "name": "S. Canu",
                        "slug": "S.-Canu",
                        "structuredName": {
                            "firstName": "St\u00e9phane",
                            "lastName": "Canu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Canu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "[95] Q."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": ", [86], [95], and"
                    },
                    "intents": []
                }
            ],
            "corpusId": 2891780,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "629ea0aa41191cc0f92ef83d2dc11ade9df04d36",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents an algorithm to estimate simultaneously both mean and variance of a non parametric regression problem. The key point is that we are able to estimate variance locally unlike standard Gaussian Process regression or SVMs. This means that our estimator adapts to the local noise. The problem is cast in the setting of maximum a posteriori estimation in exponential families. Unlike previous work, we obtain a convex optimization problem which can be solved via Newton's method."
            },
            "slug": "Heteroscedastic-Gaussian-process-regression-Le-Smola",
            "title": {
                "fragments": [],
                "text": "Heteroscedastic Gaussian process regression"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "An algorithm to estimate simultaneously both mean and variance of a non parametric regression problem which can be solved via Newton's method is presented and is able to estimate variance locally unlike standard Gaussian Process regression or SVMs."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3004771"
                        ],
                        "name": "L. Bornn",
                        "slug": "L.-Bornn",
                        "structuredName": {
                            "firstName": "Luke",
                            "lastName": "Bornn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bornn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2997535"
                        ],
                        "name": "G. Shaddick",
                        "slug": "G.-Shaddick",
                        "structuredName": {
                            "firstName": "Gavin",
                            "lastName": "Shaddick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Shaddick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31722372"
                        ],
                        "name": "J. Zidek",
                        "slug": "J.-Zidek",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Zidek",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Zidek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "There are many other examples of nonstationary covariance functions [3], [22], [54], [70], [118], [121], [126], [132] that have been proposed for GP regression along with closely related output warping techniques [141] that can also model certain kinds of nonstationary processes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11434420,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d441bd6c555aef5fcd52eb659094b256559b561e",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article, we propose a novel approach to modeling nonstationary spatial fields. The proposed method works by expanding the geographic plane over which these processes evolve into higher-dimensional spaces, transforming and clarifying complex patterns in the physical plane. By combining aspects of multidimensional scaling, group lasso, and latent variable models, a dimensionally sparse projection is found in which the originally nonstationary field exhibits stationarity. Following a comparison with existing methods in a simulated environment, dimension expansion is studied on a classic test-bed dataset historically used to study nonstationary models. Following this, we explore the use of dimension expansion in modeling air pollution in the United Kingdom, a process known to be strongly influenced by rural/urban effects, amongst others, which gives rise to a nonstationary field."
            },
            "slug": "Modeling-Nonstationary-Processes-Through-Dimension-Bornn-Shaddick",
            "title": {
                "fragments": [],
                "text": "Modeling Nonstationary Processes Through Dimension Expansion"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "The proposed method works by expanding the geographic plane over which these processes evolve into higher-dimensional spaces, transforming and clarifying complex patterns in the physical plane, by combining aspects of multidimensional scaling, group lasso, and latent variable models."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50416291"
                        ],
                        "name": "A. M. Schmidt",
                        "slug": "A.-M.-Schmidt",
                        "structuredName": {
                            "firstName": "Alexandra",
                            "lastName": "Schmidt",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. M. Schmidt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1406409112"
                        ],
                        "name": "A. O'Hagan",
                        "slug": "A.-O'Hagan",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "O'Hagan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. O'Hagan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 121405362,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "f6f7c1cd90983a05d39e5c974c1184047a71e564",
            "isKey": false,
            "numCitedBy": 292,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Summary. In geostatistics it is common practice to assume that the underlying spatial process is stationary and isotropic, i.e. the spatial distribution is unchanged when the origin of the index set is translated and under rotation about the origin. However, in environmental problems, such assumptions are not realistic since local influences in the correlation structure of the spatial process may be found in the data. The paper proposes a Bayesian model to address the anisot\u2010 ropy problem. Following Sampson and Guttorp, we define the correlation function of the spatial process by reference to a latent space, denoted by D, where stationarity and isotropy hold. The space where the gauged monitoring sites lie is denoted by G. We adopt a Bayesian approach in which the mapping between G and D is represented by an unknown function d(\u00b7). A Gaussian process prior distribution is defined for d(\u00b7). Unlike the Sampson\u2013Guttorp approach, the mapping of both gauged and ungauged sites is handled in a single framework, and predictive inferences take explicit account of uncertainty in the mapping. Markov chain Monte Carlo methods are used to obtain samples from the posterior distributions. Two examples are discussed: a simulated data set and the solar radiation data set that also was analysed by Sampson and Guttorp."
            },
            "slug": "Bayesian-inference-for-non\u2010stationary-spatial-via-Schmidt-O'Hagan",
            "title": {
                "fragments": [],
                "text": "Bayesian inference for non\u2010stationary spatial covariance structure via spatial deformations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118096690"
                        ],
                        "name": "Donald R. Jones",
                        "slug": "Donald-R.-Jones",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Jones",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donald R. Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8723392,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "a3db48fdc9aaf6921f269817ba4ed16b9b198394",
            "isKey": false,
            "numCitedBy": 1873,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a taxonomy of existing approaches for using response surfaces for global optimization. Each method is illustrated with a simple numerical example that brings out its advantages and disadvantages. The central theme is that methods that seem quite reasonable often have non-obvious failure modes. Understanding these failure modes is essential for the development of practical algorithms that fulfill the intuitive promise of the response surface approach."
            },
            "slug": "A-Taxonomy-of-Global-Optimization-Methods-Based-on-Jones",
            "title": {
                "fragments": [],
                "text": "A Taxonomy of Global Optimization Methods Based on Response Surfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This paper presents a taxonomy of existing approaches for using response surfaces for global optimization, illustrating each method with a simple numerical example that brings out its advantages and disadvantages."
            },
            "venue": {
                "fragments": [],
                "text": "J. Glob. Optim."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145880785"
                        ],
                        "name": "D. Higdon",
                        "slug": "D.-Higdon",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Higdon",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Higdon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10319165"
                        ],
                        "name": "Jenise L. Swall",
                        "slug": "Jenise-L.-Swall",
                        "structuredName": {
                            "firstName": "Jenise",
                            "lastName": "Swall",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jenise L. Swall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5182321"
                        ],
                        "name": "J. Kern",
                        "slug": "J.-Kern",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Kern",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kern"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 85
                            }
                        ],
                        "text": "There are many other examples of nonstationary covariance functions [3], [22], [54], [70], [118], [121], [126], [132] that have been proposed for GP regression along with closely related output warping techniques [141] that can also model certain kinds of nonstationary processes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 118792687,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "eea3e2297131f5b808a0dcd038f1ef2d9acbf0d4",
            "isKey": false,
            "numCitedBy": 302,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Standard geostatistical models assume stationarity and re ly on a variogram model to account for the spatial dependence in the observed data. In some instances, this assumption that the spatial dependence structure is constant throughout the sampling region is clearly violated. We present a spatial model which allows the spatial dependence structure to vary as a function of location. Unlike previous formulations which do not account for uncertainty in the sp cification of this non-stationarity (eg. Sampson and Guttorp (1992)), we develop a hierarchical mode l which can incorporate this uncertainty in the resulting inference. The non-stationary spatial dep endence is explained through a constructive \"process-convolution\" approach, which ensures that the re sulting covariance structure is valid. We apply this method to an example in toxic waste remediation."
            },
            "slug": "Non-Stationary-Spatial-Modeling-Higdon-Swall",
            "title": {
                "fragments": [],
                "text": "Non-Stationary Spatial Modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A spatial model which allows the spatial dependence structure to vary as a function of location and is explained through a constructive \"process-convolution\" approach, which ensures that the re sulting covariance structure is valid."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1776823"
                        ],
                        "name": "E. Anderes",
                        "slug": "E.-Anderes",
                        "structuredName": {
                            "firstName": "Ethan",
                            "lastName": "Anderes",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Anderes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145605141"
                        ],
                        "name": "M. Stein",
                        "slug": "M.-Stein",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Stein",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Stein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 68
                            }
                        ],
                        "text": "There are many other examples of nonstationary covariance functions [3], [22], [54], [70], [118], [121], [126], [132] that have been proposed for GP regression along with closely related output warping techniques [141] that can also model certain kinds of nonstationary processes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16992251,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "cdff994033415bc1352d75f17e20ef7e3e316dca",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new approach to the estimation of the deformation of an isotropic Gaussian random field on R 2 based on dense observations of a single realization of the deformed random field. Under this framework we investigate the identification and estimation of deformations. We then present a complete methodological package-from model assumptions to algorithmic recovery of the deformation-for the class of nonstationary processes obtained by deforming isotropic Gaussian random fields."
            },
            "slug": "Estimating-deformations-of-isotropic-Gaussian-on-Anderes-Stein",
            "title": {
                "fragments": [],
                "text": "Estimating deformations of isotropic Gaussian random fields on the plane"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A complete methodological package-from model assumptions to algorithmic recovery of the deformation-for the class of nonstationary processes obtained by deforming isotropic Gaussian random fields is presented."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 98
                            }
                        ],
                        "text": "By making these choices explicit, Bayesian optimization can be used to construct optimal programs [74]: that is to say, programs that run faster or compute better solutions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16782174,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0543827f43efd420fff5a815060175f00b728f67",
            "isKey": false,
            "numCitedBy": 202,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Avoid premature commitment, seek design alternatives, and automatically generate performance-optimized software."
            },
            "slug": "Programming-by-optimization-Hoos",
            "title": {
                "fragments": [],
                "text": "Programming by optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "Avoid premature commitment, seek design alternatives, and automatically generate performance-optimized software to avoid wasted effort and improve quality of life."
            },
            "venue": {
                "fragments": [],
                "text": "Commun. ACM"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3445947"
                        ],
                        "name": "T. Coburn",
                        "slug": "T.-Coburn",
                        "structuredName": {
                            "firstName": "Timothy",
                            "lastName": "Coburn",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Coburn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 63
                            }
                        ],
                        "text": "One method is to use the intrinsic model of coregionalization (ICM) [60], [136], [21] that utilizes the product kernel,\nk((x,m), (x\u2032,m\u2032)) = kX (x,x \u2032)kT (m,m \u2032)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "model of coregionalization (ICM) [60], [136], [21] that utilizes the product kernel,"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 27
                            }
                        ],
                        "text": "An alternative view of the ICM model is that it defines a latent process that is rotated and scaled to produce each of the individual tasks."
                    },
                    "intents": []
                }
            ],
            "corpusId": 19832909,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "23d3c8ca4b803473a6de60196117130dc0f9eaeb",
            "isKey": false,
            "numCitedBy": 3933,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Exploratory Data Analysis 2. The Random Functions Model 3. Inference and Modeling 4. Local Estimation: Accounting for a Single Attribute 5. Local Estimation: Accounting for Secondary Information 6. Assessment of Local Uncertainty 7. Assessment of Spatial Uncertainty 8. Summary"
            },
            "slug": "Geostatistics-for-Natural-Resources-Evaluation-Coburn",
            "title": {
                "fragments": [],
                "text": "Geostatistics for Natural Resources Evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper presents a meta-modelling framework that automates the very labor-intensive and therefore time-heavy and expensive process of manually cataloging and estimating the effects of noise in a discrete-time model."
            },
            "venue": {
                "fragments": [],
                "text": "Technometrics"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3085659"
                        ],
                        "name": "H. Kushner",
                        "slug": "H.-Kushner",
                        "structuredName": {
                            "firstName": "Harold",
                            "lastName": "Kushner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kushner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 38
                            }
                        ],
                        "text": "In the nonparametric setting, Kushner [91] used Wiener processes for unconstrained 1-D optimization problems."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "An early strategy in the literature, probability of improvement (PI) [91], measures the probability that a point x leads to an improvement upon ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 30
                            }
                        ],
                        "text": "In the nonparametric setting, Kushner [91] used Wiener processes for unconstrained one-dimensional optimization problems."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "Kushner\u2019s decision model was based on maximizing the probability of improvement."
                    },
                    "intents": []
                }
            ],
            "corpusId": 62599010,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "64c0650c3c559e540ad7fb73c4deadf340da474b",
            "isKey": true,
            "numCitedBy": 802,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-New-Method-of-Locating-the-Maximum-Point-of-an-in-Kushner",
            "title": {
                "fragments": [],
                "text": "A New Method of Locating the Maximum Point of an Arbitrary Multipeak Curve in the Presence of Noise"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1964
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2097739937"
                        ],
                        "name": "T. L. Lai Andherbertrobbins",
                        "slug": "T.-L.-Lai-Andherbertrobbins",
                        "structuredName": {
                            "firstName": "T",
                            "lastName": "Lai Andherbertrobbins",
                            "middleNames": [
                                "L"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. L. Lai Andherbertrobbins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 201
                            }
                        ],
                        "text": "However, this solution is intractable for general reward distributions, and so in practice sequential heuristics are used and analyzed in terms of a frequentist measure, namely cumulative regret [38], [92], [127], [135], [146]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "Dating back to the seminal work of Lai and Robbins [92] on the multiarmed bandit problem, the upper confidence bound criterion has been a popular way of negotiating exploration and exploitation, often with provable cumulative regret bounds."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 41
                            }
                        ],
                        "text": "Dating back to the seminal work of Lai & Robbins [92] on the multi-armed bandit problem, the upper confidence bound criterion has been a popular way of negotiating exploration and exploitation, often with provable cumulative regret bounds."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "In the bandits setting, Lai and Robbins [92] introduced upper confidence bounds (UCB) as approximate alternatives to Gittins indices in 1985."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 212
                            }
                        ],
                        "text": "making design choices dynamically as new evidence becomes available; a general strategy known as sequential experimental design or, in the multiarmed bandit literature, adaptive or dynamic allocation rules [59], [92]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18456561,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "572379c1d56e7e19422ae38218ee228c61aefb2f",
            "isKey": true,
            "numCitedBy": 2002,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Asymptotically-Efficient-Adaptive-Allocation-Rules-Andherbertrobbins",
            "title": {
                "fragments": [],
                "text": "Asymptotically Efficient Adaptive Allocation Rules"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 252,
                                "start": 248
                            }
                        ],
                        "text": "In academia, it is impacting a wide range of areas, including interactive user-interfaces [26], robotics [101], [110], environmental monitoring [106], information extraction [158], combinatorial optimisation [79], [159], automatic machine learning [16], [143], [148], [151], [72], sensor networks [55], [146], adaptive Monte Carlo [105], experimental design [11] and reinforcement learning [27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "Alternatively, [16] and [159] use the CMA-ES method of [66], and [79] apply multi-start local search."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 71
                            }
                        ],
                        "text": "tuning task has received much attention in tuning deep belief networks [16], Markov chain Monte Carlo methods [105], [65], convolutional neural networks [143], [148], and automatically selecting among WEKA and scikit-learn offerings [151], [72]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 94
                            }
                        ],
                        "text": "A simple approach is to define a separate GP for each group of jointly active hyperparameters [16], however this ignores dependencies between groups."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 253,
                                "start": 249
                            }
                        ],
                        "text": "For example, when the function involves selecting between different algorithms as well as optimizing their hyperparameters, then certain sets of hyperparameters belonging to a given algorithm will be inactive if that algorithm is not selected [79], [16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Algorithms for hyperparameter optimization"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Neural Information Processing Systems, pages 2546\u20132554,"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 10
                            }
                        ],
                        "text": "As in the Beta-Bernoulli case, this conjugate prior enables the posterior distribution to be computed easily, leading to another normal-inverse-gamma distribution, now\n6 with parameters\nwn = Vn(V \u22121 0 w0 + X Ty) (9) Vn = (V \u22121 0 + X\nTX)\u22121 (10) \u03b1n = \u03b10 + n/2 (11)\n\u03b2n = \u03b20 + 1\n2\n( wT0 V \u22121 0 w0 + y Ty \u2212wTnV\u22121n wn ) ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 12
                            }
                        ],
                        "text": "(7)\nFor the Beta-Bernoulli, this corresponds to simply drawing w\u0303 from (6) and then choosing the action with the largest w\u0303a."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 88
                            }
                        ],
                        "text": "We begin our discussion with a treatment of perhaps the simplest statistical model, the Beta-Bernoulli."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 34
                            }
                        ],
                        "text": "Algorithm 2 Thompson sampling for Beta-Bernoulli bandit Require: \u03b1, \u03b2: hyperparameters of the beta prior\n1: Initialize na,0 = na,1 = i = 0 for all a 2: repeat 3: for a = 1, . . . ,K do 4: w\u0303a \u223c Beta(\u03b1+ na,1, \u03b2 + na,0) 5: end for 6: ai = arg maxa w\u0303a 7: Observe yi by pulling arm ai 8: if yi = 0 then 9: nai,0 = nai,0 + 1\n10: else 11: nai,1 = nai,1 + 1 12: end if 13: i = i+ 1 14: until stopping criterion reached\nIn general, this number grows combinatorially in the number of components."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 72
                            }
                        ],
                        "text": "This presents challenges for approaches such as the independent Beta-Bernoulli model discussed in the previous section: modelling the arms as independent will lead to strategies that must try every option at least once."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 15
                            }
                        ],
                        "text": "Example of the Beta-Bernoulli model for A/B testing."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Proc. Int"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int"
            }
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50600633"
                        ],
                        "name": "J. Gittins",
                        "slug": "J.-Gittins",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Gittins",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gittins"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "When G 1, a Bayes-optimal sequence X can be computed for the Bernoulli bandit via dynamic programming, due to Gittins [59]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 117
                            }
                        ],
                        "text": "In the bandits setting, Lai and Robbins [92] introduced upper confidence bounds (UCB) as approximate alternatives to Gittins indices in 1985."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 113
                            }
                        ],
                        "text": "(19)\nWhen \u03b3   1, a Bayes-optimal sequence X can be computed for the Bernoulli bandit via dynamic programming, due to Gittins [59]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 210,
                                "start": 206
                            }
                        ],
                        "text": "making design choices dynamically as new evidence becomes available; a general strategy known as sequential experimental design or, in the multiarmed bandit literature, adaptive or dynamic allocation rules [59], [92]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17724147,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "843dfa6fc1c178aa3e0796017dc0d292f0b95b32",
            "isKey": true,
            "numCitedBy": 1454,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Bandit-processes-and-dynamic-allocation-indices-Gittins",
            "title": {
                "fragments": [],
                "text": "Bandit processes and dynamic allocation indices"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1979
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69498854"
                        ],
                        "name": "R. V. Churchill",
                        "slug": "R.-V.-Churchill",
                        "structuredName": {
                            "firstName": "Ruel",
                            "lastName": "Churchill",
                            "middleNames": [
                                "Vance"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. V. Churchill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "12873112"
                        ],
                        "name": "S. Bochner",
                        "slug": "S.-Bochner",
                        "structuredName": {
                            "firstName": "Salomon",
                            "lastName": "Bochner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Bochner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2577510"
                        ],
                        "name": "Morris Tenenbaum",
                        "slug": "Morris-Tenenbaum",
                        "structuredName": {
                            "firstName": "Morris",
                            "lastName": "Tenenbaum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Morris Tenenbaum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49849336"
                        ],
                        "name": "H. Pollard",
                        "slug": "H.-Pollard",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Pollard",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Pollard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "However, using recent spectral sampling techniques [20], [94], [125], we can draw an"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[20] S."
                    },
                    "intents": []
                }
            ],
            "corpusId": 124432796,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "df0eb0bee6fb77b53fb20c622a0994f7ba75ab44",
            "isKey": false,
            "numCitedBy": 384,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Lectures-on-Fourier-Integrals-Churchill-Bochner",
            "title": {
                "fragments": [],
                "text": "Lectures on Fourier Integrals"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1959
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144537223"
                        ],
                        "name": "D. Lindley",
                        "slug": "D.-Lindley",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lindley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lindley"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": ", how much information this query will provide as in [98]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 136
                            }
                        ],
                        "text": "In the Bayesian experimental design literature, this criterion is known as the D-optimality utility and was first introduced by Lindley [98]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 123582195,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ff5ff13ba3155cb24d8ff88607b816f8174c6bad",
            "isKey": false,
            "numCitedBy": 1331,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "On-a-Measure-of-the-Information-Provided-by-an-Lindley",
            "title": {
                "fragments": [],
                "text": "On a Measure of the Information Provided by an Experiment"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1956
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144301316"
                        ],
                        "name": "W. R. Thompson",
                        "slug": "W.-R.-Thompson",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Thompson",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. R. Thompson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In the generalized linear model, Thompson sampling draws a w\u0303 from the posterior p(w | Dn) using MCMC or a Laplace approximation, and then selects the arm with the highest expected reward given the sampled parameter w\u0303, i.e., an+1 = arg maxa g \u22121(xTa w\u0303)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 120462794,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "ee2cd1d17f833d3c157a1016a778c7c22af555a2",
            "isKey": false,
            "numCitedBy": 2355,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "ON-THE-LIKELIHOOD-THAT-ONE-UNKNOWN-PROBABILITY-IN-Thompson",
            "title": {
                "fragments": [],
                "text": "ON THE LIKELIHOOD THAT ONE UNKNOWN PROBABILITY EXCEEDS ANOTHER IN VIEW OF THE EVIDENCE OF TWO SAMPLES"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1933
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815604"
                        ],
                        "name": "M. Schonlau",
                        "slug": "M.-Schonlau",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Schonlau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schonlau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145228938"
                        ],
                        "name": "W. Welch",
                        "slug": "W.-Welch",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Welch",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Welch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118096690"
                        ],
                        "name": "Donald R. Jones",
                        "slug": "Donald-R.-Jones",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Jones",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donald R. Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 200
                            }
                        ],
                        "text": "The term Bayesian optimization was coined in the 1970s [115], but a popular version of the method has been known as efficient global optimization in the experimental design literature since the 1990s [134]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 58806889,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa2555e746b4d157a52d9bc4c63c9b386a720016",
            "isKey": false,
            "numCitedBy": 388,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Global-versus-local-search-in-constrained-of-models-Schonlau-Welch",
            "title": {
                "fragments": [],
                "text": "Global versus local search in constrained optimization of computer models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3015507"
                        ],
                        "name": "Jean-Yves Audibert",
                        "slug": "Jean-Yves-Audibert",
                        "structuredName": {
                            "firstName": "Jean-Yves",
                            "lastName": "Audibert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jean-Yves Audibert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "121645690"
                        ],
                        "name": "S\u00e9bastien Bubeck",
                        "slug": "S\u00e9bastien-Bubeck",
                        "structuredName": {
                            "firstName": "S\u00e9bastien",
                            "lastName": "Bubeck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S\u00e9bastien Bubeck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708654"
                        ],
                        "name": "R. Munos",
                        "slug": "R.-Munos",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Munos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Munos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 80
                            }
                        ],
                        "text": "arm identification problem, which is more suitable for the model selection task [7], [30], [50], [51], [72], [104]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 216050617,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "09c437e0edcacc6b2967b7da97395f94004b68c3",
            "isKey": false,
            "numCitedBy": 519,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of finding the best arm in a stochastic multi-armed bandit game. The regret of a forecaster is here defined by the gap between the mean reward of the optimal arm and the mean reward of the ultimately chosen arm. We propose a highly exploring UCB policy and a new algorithm based on successive rejects. We show that these algorithms are essentially optimal since their regret decreases exponentially at a rate which is, up to a logarithmic factor, the best possible. However, while the UCB policy needs the tuning of a parameter depending on the unobservable hardness of the task, the successive rejects policy benefits from being parameter-free, and also independent of the scaling of the rewards. As a by-product of our analysis, we show that identifying the best arm (when it is unique) requires a number of samples of order (up to a log(K) factor) \u03a3 i 1/\u03942i, where the sum is on the suboptimal arms and\u0394i represents the difference between the mean reward of the best arm and the one of arm i. This generalizes the well-known fact that one needs of order of 1/\u03942 samples to differentiate the means of two distributions with gap \u0394."
            },
            "slug": "Best-Arm-Identification-in-Multi-Armed-Bandits-Audibert-Bubeck",
            "title": {
                "fragments": [],
                "text": "Best Arm Identification in Multi-Armed Bandits"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes a highly exploring UCB policy and a new algorithm based on successive rejects that are essentially optimal since their regret decreases exponentially at a rate which is, up to a logarithmic factor, the best possible."
            },
            "venue": {
                "fragments": [],
                "text": "COLT"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9421473"
                        ],
                        "name": "M. Sasena",
                        "slug": "M.-Sasena",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Sasena",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sasena"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 114321095,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "161f2209b23354b0f628de40c063f69511bdecb2",
            "isKey": false,
            "numCitedBy": 390,
            "numCiting": 96,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Flexibility-and-efficiency-enhancements-for-global-Sasena",
            "title": {
                "fragments": [],
                "text": "Flexibility and efficiency enhancements for constrained global design optimization with kriging approximations."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Taking the Human Out of the Loop: A Review of Bayesian Optimization observations"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int. Conf. Mach. Learn"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "AutoML Workshop"
            },
            "venue": {
                "fragments": [],
                "text": "AutoML Workshop"
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 169
                            }
                        ],
                        "text": "Meanwhile, in the former Soviet Union, Mo\u010dkus and colleagues developed a multidimensional Bayesian optimization method using linear combinations of Wiener fields [114], [115]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 33
                            }
                        ],
                        "text": "One could instead measure the EI [115] which incorporates the amount of improvement."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 55
                            }
                        ],
                        "text": "The term Bayesian optimization was coined in the 1970s [115], but a popular version of the method has been known as efficient global optimization in the experimental design literature since the 1990s [134]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The application of Bayesian methods for seeking the extremum"
            },
            "venue": {
                "fragments": [],
                "text": "Toward Global Optimization"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Adv. Neural Inf. Process. Syst"
            },
            "venue": {
                "fragments": [],
                "text": "Adv. Neural Inf. Process. Syst"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 91
                            }
                        ],
                        "text": "There are many other examples of nonstationary covariance functions [3], [22], [54], [70], [118], [121], [126], [132] that have been proposed for GP regression along with closely related output warping techniques [141] that can also model certain kinds of nonstationary processes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bayesian learning for neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "Bayesian learning for neural networks"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "J . C . Gittins , \u2018 \u2018 Bandit processes and dynamic allocation indices J . Roy . Stat"
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans . Model . Comput . Simul"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "Alternatively, [16] and [159] use the CMA-ES method of [66], and [79] apply multi-start local search."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Completely derandomized selfadaptation in evolution strategies"
            },
            "venue": {
                "fragments": [],
                "text": "Evol. Comput., 9(2):159\u2013195,"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Portfolio allocation for Bayesian optimization Programming by optimization"
            },
            "venue": {
                "fragments": [],
                "text": "AI and Statistics"
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Freeze-thaw Bayesian optimization. arXiv preprint arXiv:1406"
            },
            "venue": {
                "fragments": [],
                "text": "Freeze-thaw Bayesian optimization. arXiv preprint arXiv:1406"
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The theory of regionalized variables and its applications. Cahier du Centre de Morphologie Mathematique"
            },
            "venue": {
                "fragments": [],
                "text": "Ecoles des Mines"
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Appl. Comput. Vis"
            },
            "venue": {
                "fragments": [],
                "text": "Appl. Comput. Vis"
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "J. Mach. Learn. Res"
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Conf. Mach. Learn"
            },
            "venue": {
                "fragments": [],
                "text": "Conf. Mach. Learn"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Adv. Neural Inf. Process. Syst"
            },
            "venue": {
                "fragments": [],
                "text": "Adv. Neural Inf. Process. Syst"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Variational learning of inducing variables in sparse Gaussian Shahriari et al.: Taking the Human Out of the Loop: A Review of Bayesian Optimization processes"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int. Conf"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Adv. Neural Inf. Process. Syst"
            },
            "venue": {
                "fragments": [],
                "text": "Adv. Neural Inf. Process. Syst"
            },
            "year": 2013
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "The book of Cesa-Bianchi and Lugosi [36] is a good reference on the"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Prediction, Learning, Games"
            },
            "venue": {
                "fragments": [],
                "text": "Prediction, Learning, Games"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Available: arXiv:1406"
            },
            "venue": {
                "fragments": [],
                "text": "Available: arXiv:1406"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 161
                            }
                        ],
                        "text": "The beta warping approach has been shown to be highly effective on several benchmark problems as well as hyperparameter optimization for machine learning models [18], [145]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Preliminary evaluation of hyperopt algorithms on HPOLib"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. Int. Conf. Mach. Learn. AutoML Workshop"
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "McDowell Award for Excellence in Research and the 2010 Mathematics of Information Technology and Complex Systems (MITACS) Young Researcher Award"
            },
            "venue": {
                "fragments": [],
                "text": "McDowell Award for Excellence in Research and the 2010 Mathematics of Information Technology and Complex Systems (MITACS) Young Researcher Award"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The theory of regionalized variables and its applications"
            },
            "venue": {
                "fragments": [],
                "text": "Cahier du Centre de Morphologie Mathematique, Ecoles des Mines"
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Most likely het - eroscedastic Gaussian process regression Bandit based Monte - Carlo planning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Syst"
            },
            "venue": {
                "fragments": [],
                "text": "Syst"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gaussian processes for global optimisation Learning and Intelligent Optimization"
            },
            "venue": {
                "fragments": [],
                "text": "Gaussian processes for global optimisation Learning and Intelligent Optimization"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 103
                            }
                        ],
                        "text": "For this reason, we consider marginalizing out the hyperparameters using either quadrature or MC [26], [120], [143]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 69
                            }
                        ],
                        "text": "In addition to MC methods, one could also use quadrature as shown in [120]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 104
                            }
                        ],
                        "text": "Several authors have proposed to integrate out the hyperparameters using quadrature or MC methods [26], [120], [143]."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Gaussian processes for global optimisation Learning and Intelligent Optimization, Berlin, Germany: Springer-Verlag"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Artif. Intell"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell"
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mach. Learn"
            },
            "venue": {
                "fragments": [],
                "text": "Mach. Learn"
            },
            "year": 2013
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Preliminary evaluation of hyperopt algorithms on HPOLib. International Conference on Machine Learning AutoML Workshop"
            },
            "venue": {
                "fragments": [],
                "text": "Preliminary evaluation of hyperopt algorithms on HPOLib. International Conference on Machine Learning AutoML Workshop"
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "under the supervision of Prof"
            },
            "venue": {
                "fragments": [],
                "text": "He is a Research Scientist at Google DeepMind, U.K. His doctoral research has mostly focused on attacking the weaknesses of Bayesian optimization as well as applications thereof for adaptive Markov chain Monte Carlo (MCMC) algorithms"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Expensive Optim. Problems"
            },
            "venue": {
                "fragments": [],
                "text": "Expensive Optim. Problems"
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Random forests. Machine learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Uncertainty Artif. Intell"
            },
            "venue": {
                "fragments": [],
                "text": "Uncertainty Artif. Intell"
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 127
                            }
                        ],
                        "text": "A more recent approach, the so-called entropy search portfolio (ESP), considers the use of an information-based metric instead [139]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 148
                            }
                        ],
                        "text": "Empirical evaluations show good performance which, however, seems to deteriorate in high dimensional problems, likely due to aggressive exploration [139]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An entropy search portfolio"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. NIPS Workshop Bayesian Optim"
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neural Inf. Process. Syst"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Inf. Process. Syst"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Recommender Syst"
            },
            "venue": {
                "fragments": [],
                "text": "Recommender Syst"
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Parallel algorithm configuration,'' Learning and Intelligent Optimization"
            },
            "venue": {
                "fragments": [],
                "text": "Parallel algorithm configuration,'' Learning and Intelligent Optimization"
            },
            "year": 2012
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 88,
            "methodology": 66
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 197,
        "totalPages": 20
    },
    "page_url": "https://www.semanticscholar.org/paper/Taking-the-Human-Out-of-the-Loop:-A-Review-of-Shahriari-Swersky/0a2586e0a5f8bb4e35aa0763a6b8bca428af6bd2?sort=total-citations"
}