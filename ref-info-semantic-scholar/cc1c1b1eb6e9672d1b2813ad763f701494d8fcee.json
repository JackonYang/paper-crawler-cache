{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145509576"
                        ],
                        "name": "Albert Cohen",
                        "slug": "Albert-Cohen",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Albert Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "18182536"
                        ],
                        "name": "Marc Sigler",
                        "slug": "Marc-Sigler",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Sigler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc Sigler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2506136"
                        ],
                        "name": "Sylvain Girbal",
                        "slug": "Sylvain-Girbal",
                        "structuredName": {
                            "firstName": "Sylvain",
                            "lastName": "Girbal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sylvain Girbal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731764"
                        ],
                        "name": "O. Temam",
                        "slug": "O.-Temam",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Temam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Temam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702824"
                        ],
                        "name": "David Parello",
                        "slug": "David-Parello",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Parello",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Parello"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800919"
                        ],
                        "name": "Nicolas Vasilache",
                        "slug": "Nicolas-Vasilache",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Vasilache",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Vasilache"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16965438,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "081fdf4787a2ec2cae16fa76a59c1747f4467e94",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Static compiler optimizations can hardly cope with the complex run-time behavior and hardware components interplay of modern processor architectures. Multiple architectural phenomena occur and interact simultaneously, which requires the optimizer to combine multiple program transformations. Whether these transformations are selected through static analysis and models, runtime feedback, or both, the underlying infrastructure must have the ability to perform long and complex compositions of program transformations in a flexible manner. Existing compilers are ill-equipped to perform that task because of rigid phase ordering, fragile selection rules using pattern matching, and cumbersome expression of loop transformations on syntax trees. Moreover, iterative optimization emerges as a pragmatic and general means to select an optimization strategy via machine learning and operations research. Searching for the composition of dozens of complex, dependent, parameterized transformations is a challenge for iterative approaches.The purpose of this article is threefold: (1) to facilitate the automatic search for compositions of program transformations, introducing a richer framework which improves on classical polyhedral representations, suitable for iterative optimization on a simpler, structured search space, (2) to illustrate, using several examples, that syntactic code representations close to the operational semantics hamper the composition of transformations, and (3) that complex compositions of transformations can be necessary to achieve significant performance benefits. The proposed framework relies on a unified polyhedral representation of loops and statements. The key is to clearly separate four types of actions associated with program transformations: iteration domain, schedule, data layout and memory access functions modifications. The framework is implemented within the Open64/ORC compiler, aiming for native IA64, AMD64 and IA32 code generation, along with source-to-source optimization of Fortran90, C and C++."
            },
            "slug": "Facilitating-the-search-for-compositions-of-program-Cohen-Sigler",
            "title": {
                "fragments": [],
                "text": "Facilitating the search for compositions of program transformations"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The purpose of this article is to facilitate the automatic search for compositions of program transformations, introducing a richer framework which improves on classical polyhedral representations, suitable for iterative optimization on a simpler, structured search space, and to illustrate that complex compositions of transformations can be necessary to achieve significant performance benefits."
            },
            "venue": {
                "fragments": [],
                "text": "ICS '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145509576"
                        ],
                        "name": "Albert Cohen",
                        "slug": "Albert-Cohen",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Albert Cohen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11815117,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f1a4e3593557aa40127a6de249f7835fe6f6c1a",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Compilation for todays microprocessor and multi-processor architectures is facing new challenges. Dealing with parallel execution, optimizations become overly specific and complex to be left to the programmer. Traditionally devoted to numerical applications, automatic parallelization addresses new program models, including non-affine nests of loops, recursive calls and pointer-based data structures. Parallelism detection is based on precise analyses, gathering compile-time information about run-time program properties. This information enables transformations useful to parallelism extraction and parallel code generation. This thesis focuses on aggressive analysis and transformation techniques from an instancewise point of view, that is from individual properties of each run-time instance of a program statement. Thanks to a novel formal language framework, we first investigate instancewise dependence and reaching definition analysis for recursive programs. This analysis is applied to memory expansion and parallelization of recursive programs, and promising results are exposed. The second part of this work addresses nests of loops with unrestricted conditionals, bounds and array subscripts. Parallelization via memory expansion is revisited in this context and solutions to challenging optimization problems are proposed."
            },
            "slug": "Program-Analysis-and-Transformation:-From-the-Model-Cohen",
            "title": {
                "fragments": [],
                "text": "Program Analysis and Transformation: From the Polytope Model to Formal Languages. (Analyse et transformation de programmes: du mod\u00e8le poly\u00e9drique aux langages formels)"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This thesis focuses on aggressive analysis and transformation techniques from an instancewise point of view, that is from individual properties of each run-time instance of a program statement, which is applied to memory expansion and parallelization of recursive programs."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800919"
                        ],
                        "name": "Nicolas Vasilache",
                        "slug": "Nicolas-Vasilache",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Vasilache",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicolas Vasilache"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769333"
                        ],
                        "name": "C. Bastoul",
                        "slug": "C.-Bastoul",
                        "structuredName": {
                            "firstName": "C\u00e9dric",
                            "lastName": "Bastoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bastoul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145509576"
                        ],
                        "name": "Albert Cohen",
                        "slug": "Albert-Cohen",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Albert Cohen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9474356,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e8a732e85540102732a0e729a26009891a7548b6",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "The polyhedral model is known to be a powerful framework to reason about high level loop transformations. Recent developments in optimizing compilers broke some generally accepted ideas about the limitations of this model. First, thanks to advances in dependence analysis for irregular access patterns, its applicability which was supposed to be limited to very simple loop nests has been extended to wide code regions. Then, new algorithms made it possible to compute the target code for hundreds of statements while this code generation step was expected not to be scalable. Such theoretical advances and new software tools allowed actors from both academia and industry to study more complex and realistic cases. Unfortunately, despite strong optimization potential of a given transformation for e.g., parallelism or data locality, code generation may still be challenging or result in high control overhead. This paper presents scalable code generation methods that make possible the application of increasingly complex program transformations. By studying the transformations themselves, we show how it is possible to benefit from their properties to dramatically improve both code generation quality and space/time complexity, with respect to the best state-of-the-art code generation tool. In addition, we build on these improvements to present a new algorithm improving generated code performance for strided domains and reindexed schedules."
            },
            "slug": "Polyhedral-Code-Generation-in-the-Real-World-Vasilache-Bastoul",
            "title": {
                "fragments": [],
                "text": "Polyhedral Code Generation in the Real World"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "By studying the transformations themselves, it is shown how it is possible to benefit from their properties to dramatically improve both code generation quality and space/time complexity, with respect to the best state-of-the-art code generation tool."
            },
            "venue": {
                "fragments": [],
                "text": "CC"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769333"
                        ],
                        "name": "C. Bastoul",
                        "slug": "C.-Bastoul",
                        "structuredName": {
                            "firstName": "C\u00e9dric",
                            "lastName": "Bastoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bastoul"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 78
                            }
                        ],
                        "text": "lattice polyhedra or linearly bounded lattices) is known to be a hard problem.(21,37)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14687806,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea360e5f5a06f6ff60bccb431af2c9bdbefc9aea",
            "isKey": false,
            "numCitedBy": 63,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Supercompilers look for the best execution order of the statement instances in the most compute intensive kernels. It has been extensively shown that the polyhedral model provides convenient abstractions to find and perform the useful program transformations. Nevertheless, the current polyhedral code generation algorithms lack for flexibility by adressing mainly unimodular or at least invertible transformation functions. Moreover, their complexity is challenging for large problems (with many statements). In this paper, we discuss a general transformation framework able to deal with non-unimodular, non-invertible functions. A completed and improved version of one of the best algorithms known so far is presented to actually perform the code generation. Experimental evidence proves the ability of our framework to handle real-life problems."
            },
            "slug": "Efficient-code-generation-for-automatic-and-Bastoul",
            "title": {
                "fragments": [],
                "text": "Efficient code generation for automatic parallelization and optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Experimental evidence proves the ability of the general transformation framework able to deal with non-unimodular, non-invertible functions to handle real-life problems."
            },
            "venue": {
                "fragments": [],
                "text": "Second International Symposium on Parallel and Distributed Computing, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702824"
                        ],
                        "name": "David Parello",
                        "slug": "David-Parello",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Parello",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Parello"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731764"
                        ],
                        "name": "O. Temam",
                        "slug": "O.-Temam",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Temam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Temam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145509576"
                        ],
                        "name": "Albert Cohen",
                        "slug": "Albert-Cohen",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Albert Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47265791"
                        ],
                        "name": "J. Verdun",
                        "slug": "J.-Verdun",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Verdun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Verdun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 109
                            }
                        ],
                        "text": "However, considering the ability to perform complex transformations, or complex sequences of transformations,(4,5) iterative optimization and machine learning compilation will fare no better than existing compilers on top of which they are currently implemented."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 613,
                                "start": 610
                            }
                        ],
                        "text": "At the same time, we will outline why this representation has several benefits for the implementation of program transformations: (1) it is generic and can serve to implement a large array of program transformations, (2) it isolates the root effects of program transformations, (3) it allows generalized versions of classical loop transformations to be defined without reference to any syntactic code, (4) this enables transparent composition of program transformations because applying program transformations has no effect on the representation complexity that makes it less generic or harder to manipulate, (5) and this eventually adds structure (commutativity, confluence, linearity) to the optimization search space."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3058281,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "adf35ce72b96aceb8868dc0b0b8c41fbdac1f9df",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Because processor architectures are increasingly complex, it is increasingly difficult to embed accurate machine models within compilers. As a result, compiler efficiency tends to decrease. Currently, the trend is on top-down approaches: static compilers are progressively augmented with information from the architecture as in profile-based, iterative or dynamic compilation techniques. However, for the moment, fairly elementary architectural information is used. In this article, we adopt a bottom-up approach to the architecture complexity issue: we assume we know everything about the behavior of the program on the architecture. We present a manual but systematic process for optimizing a program on a complex processor architecture using extensive dynamic analysis, and we find that a small set of run-time information is sufficient to drive an efficient process. We have experimentally observed on an Alpha 21264 that this approach can yield significant performance improvement on Spec benchmarks, beyond peak Spec. We are currently using this approach for optimizing customer applications."
            },
            "slug": "Towards-a-Systematic,-Pragmatic-and-Program-Process-Parello-Temam",
            "title": {
                "fragments": [],
                "text": "Towards a Systematic, Pragmatic and Architecture-Aware Program Optimization Process for Complex Processors"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This article presents a manual but systematic process for optimizing a program on a complex processor architecture using extensive dynamic analysis, and finds that a small set of run-time information is sufficient to drive an efficient process."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the ACM/IEEE SC2004 Conference"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145509576"
                        ],
                        "name": "Albert Cohen",
                        "slug": "Albert-Cohen",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Albert Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2506136"
                        ],
                        "name": "Sylvain Girbal",
                        "slug": "Sylvain-Girbal",
                        "structuredName": {
                            "firstName": "Sylvain",
                            "lastName": "Girbal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sylvain Girbal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731764"
                        ],
                        "name": "O. Temam",
                        "slug": "O.-Temam",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Temam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Temam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 102
                            }
                        ],
                        "text": "We call Static Control Part (SCoP) any maximal syntactic program segment satisfying these constraints.(25)"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6430468,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6aa16acc0b0dc4de0440a92adc1bcd60400fcde4",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We wish to extend the effectiveness of loop-restructuring compilers by improving the robustness of loop transformations and easing their composition in long sequences. We propose a formal and practical framework for program transformation. Our framework is well suited for iterative optimization techniques searching not only for the appropriate parameters of a given transformation, but for the program transformations themselves, and especially for compositions of program transformations. This framework is based on a unified polyhedral representation of loops and statements, enabling the application of generalized control and data transformations without reference to a syntactic program representation. The key to our framework is to clearly separate the impact of each program transformation on three independent components: the iteration domain, the iteration schedule and the memory access functions. The composition of generalized transformations builds on normalization rules specific to each component of the representation. Our techniques have been implemented on top of Open64/ORC."
            },
            "slug": "A-Polyhedral-Approach-to-Ease-the-Composition-of-Cohen-Girbal",
            "title": {
                "fragments": [],
                "text": "A Polyhedral Approach to Ease the Composition of Program Transformations"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work proposes a formal and practical framework for program transformation based on a unified polyhedral representation of loops and statements, enabling the application of generalized control and data transformations without reference to a syntactic program representation."
            },
            "venue": {
                "fragments": [],
                "text": "Euro-Par"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10214063"
                        ],
                        "name": "M. E. Wolf",
                        "slug": "M.-E.-Wolf",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Wolf",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. E. Wolf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 274,
                                "start": 268
                            }
                        ],
                        "text": "Our representation allows us to compose transformations without reference to a syntactic form, as opposed to previous polyhedral models where a single-step transformation captures the whole loop nest optimization(8,11) or intermediate code generation steps are needed.(9,10) Let us better illustrate the advantage of expressing loop transformations as \u201csyntax-free\u201d function compositions, considering again the example in Fig."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 129
                            }
                        ],
                        "text": "Compared to the attempts at expressing a large array of program transformations as matrix operations within the polyhedral model,(9,10,14) the distinctive asset of our representation lies in the simplicity of the formalism to compose non-unimodular transformations across long, flexible sequences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60571968,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0fac4fda963d53a8e2b4ca5717393b8900358d32",
            "isKey": false,
            "numCitedBy": 210,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "Researchers have identified a core set of program transformations that are effective in array-based loop nest optimization: these loop transformations include interchange, skewing, reversal and tiling. Researchers have studied these transformations individually for their legality and effect on parallelism and memory hierarchy performance; but they have not discussed in any detail how to choose the combination of transformations that best optimizes a loop nest. Other researchers have taken another approach: they consider each loop nest as a whole, applying an elegant matrix theory of loop nest transformation, but one that is only applicable to a limited class of loop nests, those whose dependences can be expressed as distance vectors. In this limited context, the problems of memory hierarchy improvement and parallelization are simplified, but their approach has not been extended to apply to general loop nests. \nWe have combined the elegance of the matrix theory with the generality of general dependence vectors into a new theory of loop transformation. This theory has enabled us to apply an algorithmic approach to solving optimization goals. Using this theory, we have developed efficient algorithms for the compiler to use to improve memory hierarchy utilization and parallelism of general loop nests. The parallelization improving algorithm maximizes the degree of parallelism within a loop nest, at either a coarse or fine granularity. The locality improving algorithm uses the same theory, and also reuse information about array accesses within loop nests, to guide the transformation process. The parallelization and locality improvement algorithms are unified so that locality and parallelism can be improved simultaneously without significantly reducing either. \nWe have implemented versions of these algorithms in Stanford's SUIF compiler and performed experimentation on the Perfect Club and the NASA kernels. We have found compiler locality improvement to significantly improve performance when applicable. We have also demonstrated a tremendous sensitivity of performance on tile size for tiled codes on machines with direct-mapped or low set associativity caches."
            },
            "slug": "Improving-locality-and-parallelism-in-nested-loops-Wolf",
            "title": {
                "fragments": [],
                "text": "Improving locality and parallelism in nested loops"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Using the elegance of the matrix theory with the generality of general dependence vectors into a new theory of loop transformation, efficient algorithms for the compiler to use to improve memory hierarchy utilization and parallelism of general loop nests are developed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793602"
                        ],
                        "name": "P. Knijnenburg",
                        "slug": "P.-Knijnenburg",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Knijnenburg",
                            "middleNames": [
                                "M.",
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Knijnenburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2802912"
                        ],
                        "name": "T. Kisuki",
                        "slug": "T.-Kisuki",
                        "structuredName": {
                            "firstName": "Toru",
                            "lastName": "Kisuki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kisuki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686222"
                        ],
                        "name": "K. Gallivan",
                        "slug": "K.-Gallivan",
                        "structuredName": {
                            "firstName": "Kyle",
                            "lastName": "Gallivan",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Gallivan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401533251"
                        ],
                        "name": "M. O\u2019Boyle",
                        "slug": "M.-O\u2019Boyle",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "O\u2019Boyle",
                            "middleNames": [
                                "F.",
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. O\u2019Boyle"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1252659,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a11e97507f78ca77080632cd7165a0b6a2672f1d",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Iterative compilation, where we search for the best program transformation based on profile feedback information, has been highly successful in determining good program optimizations, typically outperforming all static approaches. However, this benefit has come at a price, namely, a large number of executions of the target program which in many cases is unacceptable. This paper is concerned with reducing the number of program executions needed by iterative compilation by incorporating static models. We examine how static models may be incorporated into a purely iterative approach by developing several characterized heuristics. We empirically explore the tradeoff between reducing the number of executions required and the ultimate performance achieved for differing parameters or slack factors. We focus on tiling and unrolling as transformations and cache models as a test case for the feasibility of this approach. We show that a highly accurate model, used as a filter to profiling and appropriately parameterized, can reduce the number of executions by 50%. We also show that using a simple model to rank transformations and profiling, only those with the highest ranking can reduce the number of executions even further up to 70%, in cases where there is only a limited number of profiles available. We conclude that a production compiler might perform best using the last approach, gaining the benefit of iterative compilation at a much reduced cost. Copyright \u00a9 2004 John Wiley & Sons, Ltd."
            },
            "slug": "The-effect-of-cache-models-on-iterative-compilation-Knijnenburg-Kisuki",
            "title": {
                "fragments": [],
                "text": "The effect of cache models on iterative compilation for combined tiling and unrolling"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper examines how static models may be incorporated into a purely iterative approach by developing several characterized heuristics, and concludes that a production compiler might perform best using the last approach."
            },
            "venue": {
                "fragments": [],
                "text": "Concurr. Comput. Pract. Exp."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689939"
                        ],
                        "name": "L. Rauchwerger",
                        "slug": "L.-Rauchwerger",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rauchwerger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rauchwerger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729097"
                        ],
                        "name": "D. Padua",
                        "slug": "D.-Padua",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Padua",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Padua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 52
                            }
                        ],
                        "text": "(41) The main transformations include privatization (32,47,48) for dependence removal and unimodular transformations or node splitting to rearrange dependences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2192423,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5847bc6079c89978ea91e2311b1a61fa5961024e",
            "isKey": false,
            "numCitedBy": 319,
            "numCiting": 89,
            "paperAbstract": {
                "fragments": [],
                "text": "Current parallelizing compilers cannot identify a significant fraction of parallelizable loops because they have complex or statically insufficiently defined access patterns. As parallelizable loops arise frequently in practice, we advocate a novel framework for their identification: speculatively execute the loop as a doall, and apply a fully parallel data dependence test to determine if it had any cross-iteration dependences; if the test fails, then the loop is re-executed serially. Since, from our experience, a significant amount of the available parallelism in Fortran programs can be exploited by loops transformed through privatization and reduction parallelization, our methods can speculatively apply these transformations and then check their validity at run-time. Another important contribution of this paper is a novel method for reduction recognition which goes beyond syntactic pattern matching; it detects at run-time if the values stored in an array participate in a reduction operation, even if they are transferred through private variables and/or are affected by statically unpredictable control flow. We present experimental results on loops from the PERFECT Benchmarks which substantiate our claim that these techniques can yield significant speedups which are often superior to those obtainable by inspector/executor methods."
            },
            "slug": "The-LRPD-test:-speculative-run-time-parallelization-Rauchwerger-Padua",
            "title": {
                "fragments": [],
                "text": "The LRPD test: speculative run-time parallelization of loops with privatization and reduction parallelization"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Experimental results from the PERFECT Benchmarks substantiate the claim that speculatively executing loops as a doall and applying a fully parallel data dependence test to determine if it had any cross-iteration dependences can yield significant speedups which are often superior to those obtainable by inspector/executor methods."
            },
            "venue": {
                "fragments": [],
                "text": "PLDI '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10609611"
                        ],
                        "name": "J. Collard",
                        "slug": "J.-Collard",
                        "structuredName": {
                            "firstName": "Jean-Francois",
                            "lastName": "Collard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Collard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 3034755,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3c1a7f54374682a9bd1303c0082e553224b7bbb4",
            "isKey": false,
            "numCitedBy": 32,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic parallelization of imperative sequential programs has focused on nests offor-loops. The most recent of them consist in finding an affine mapping with respect to the loop indices to simultaneously capture the temporal and spatial properties of the parallelized program. Such a mapping is usually called a \u201cspace-time transformation.\u201dThis work describes an extension of these techniques towhile-loops using speculative execution. We show that space-time transformations are a good framework for summing up previous restructuration techniques ofwhile-loop, such as pipelining. Moreover, we show that these transformations can be derived and applied automatically."
            },
            "slug": "Automatic-parallelization-ofwhile-loops-using-Collard",
            "title": {
                "fragments": [],
                "text": "Automatic parallelization ofwhile-loops using speculative execution"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that space-time transformations are a good framework for summing up previous restructuration techniques ofwhile-loop, such as pipelining, and that these transformations can be derived and applied automatically."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Parallel Programming"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144022269"
                        ],
                        "name": "W. Pugh",
                        "slug": "W.-Pugh",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Pugh",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Pugh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 129
                            }
                        ],
                        "text": "Compared to the attempts at expressing a large array of program transformations as matrix operations within the polyhedral model,(9,10,14) the distinctive asset of our representation lies in the simplicity of the formalism to compose non-unimodular transformations across long, flexible sequences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14351145,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "01f2893273d7e26dc38dea1069eea7f7314451f6",
            "isKey": false,
            "numCitedBy": 90,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Many different kinds of loop transformations have been described, such as loop interchange, loop skewing and loop fusion. Each transformation requires its own particular set of dependence analysis tests and paraltelizing a section of code may require perforfig a series of transformations. The only way to decide if there is a way of parallelizing a section of code is to try all possible sequences of transformations, which presents a difficult search problem. We present a uniform method of performing loop optimization. Rather than optimizing a program by performing a murky search through a series of transformations, our method considers a very powerful class of program transformations that includes any transformation that also can be obtained by any sequence of standard loop transformations. This optimization technique uniformly encompasses the effects of parallelization, loop fusion, loop splitting, loop interchange, loop skewing and statement reordering, as well as transformations not previously described. Thus, we only need to perform one program transformation. We show that standard techniques for representing dependencies (dependence directions and dependence distances) are insufficient for this type of optimization and describe a more powerful technique, dependence relations, that have sufficient descriptive power."
            },
            "slug": "Uniform-techniques-for-loop-optimization-Pugh",
            "title": {
                "fragments": [],
                "text": "Uniform techniques for loop optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that standard techniques for representing dependencies (dependence directions and dependence distances) are insufficient for this type of optimization and described a more powerful technique, dependence relations, that have sufficient descriptive power."
            },
            "venue": {
                "fragments": [],
                "text": "ICS '91"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769333"
                        ],
                        "name": "C. Bastoul",
                        "slug": "C.-Bastoul",
                        "structuredName": {
                            "firstName": "C\u00e9dric",
                            "lastName": "Bastoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bastoul"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 258,
                                "start": 254
                            }
                        ],
                        "text": "This strategy is fully implemented in the code generation phase and is triggered by annotations (carrying depth information) of the statements whose surrounding loops need to be unrolled; unrolling occurs in the separation algorithm of the code generator(22) when all the statements being printed out are marked for unrolling at the current depth."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": "15(a),(22) where i is the iteration vector, igp is the vector of constant parameters, and t is the time-vector, i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "of duplicated control,(22) to generate efficient control for full SPECfp2000 benchmarks and for SCoPs with more than 1700 statements."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 115
                            }
                        ],
                        "text": "The best syntax tree construction scheme consists in a recursive application of domain projections and separations.(22,23) The final code is deduced from the set of constraints describing the polyhedra attached to each node in the tree."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 182
                            }
                        ],
                        "text": "Eventually, we use a code generation technique suitable to a polyhedral representation that is again significantly more robust than the code generation proposed in the Omega library.(22)"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7971227,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2f48fb9fd31390c56609f00510accf5c56f9f9b",
            "isKey": false,
            "numCitedBy": 518,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Many advances in automatic parallelization and optimization have been achieved through the polyhedral model. It has been extensively shown that this computational model provides convenient abstractions to reason about and apply program transformations. Nevertheless, the complexity of code generation has long been a deterrent for using polyhedral representation in optimizing compilers. First, code generators have a hard time coping with generated code size and control overhead that may spoil theoretical benefits achieved by the transformations. Second, this step is usually time consuming, hampering the integration of the polyhedral framework in production compilers or feedback-directed, iterative optimization schemes. Moreover, current code generation algorithms only cover a restrictive set of possible transformation functions. This paper discusses a general transformation framework able to deal with nonunimodular, noninvertible, nonintegral or even nonuniform functions. It presents several improvements to a state-of-the-art code generation algorithm. Two directions are explored: generated code size and code generator efficiency. Experimental evidence proves the ability of the improved method to handle real-life problems."
            },
            "slug": "Code-generation-in-the-polyhedral-model-is-easier-Bastoul",
            "title": {
                "fragments": [],
                "text": "Code generation in the polyhedral model is easier than you think"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A general transformation framework able to deal with nonunimodular, noninvertible, nonintegral or even nonuniform functions is discussed and several improvements to a state-of-the-art code generation algorithm are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 13th International Conference on Parallel Architecture and Compilation Techniques, 2004. PACT 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2020735"
                        ],
                        "name": "Fabien Quiller\u00e9",
                        "slug": "Fabien-Quiller\u00e9",
                        "structuredName": {
                            "firstName": "Fabien",
                            "lastName": "Quiller\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fabien Quiller\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747659"
                        ],
                        "name": "S. Rajopadhye",
                        "slug": "S.-Rajopadhye",
                        "structuredName": {
                            "firstName": "Sanjay",
                            "lastName": "Rajopadhye",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Rajopadhye"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17541827,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6acc40233bc71d9f5f31ade4fa9209d8c67af9be",
            "isKey": false,
            "numCitedBy": 107,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "The polyhedral model provides a single unified foundation for systolic array synthesis and automatic parallelization of loop programs. We investigate the problem of memory reuse when compiling Alpha (a functional language based on this model). Direct compilation would require unacceptably large memory (for example O(n3) for matrix multiplication). Researchers have previously addressed the problem of memory reuse, and the analysis that this entails for projective memory allocations. This paper addresses, for a given schedule, the choice of the projections so as to minimize the volume of the residual memory. We prove tight bounds on the number of linearly independent projection vectors. Our method is constructive, yielding an optimal memory allocation. We extend the method to modular functions, and deal with the subsequent problems of code generation. Our ideas are illustrated on a number of examples generated by the current version of the Alpha compiler."
            },
            "slug": "Optimizing-memory-usage-in-the-polyhedral-model-Quiller\u00e9-Rajopadhye",
            "title": {
                "fragments": [],
                "text": "Optimizing memory usage in the polyhedral model"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper addresses, for a given schedule, the choice of the projections so as to minimize the volume of the residual memory, and proves tight bounds on the number of linearly independent projection vectors."
            },
            "venue": {
                "fragments": [],
                "text": "TOPL"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704888"
                        ],
                        "name": "M. Griebl",
                        "slug": "M.-Griebl",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Griebl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Griebl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10609611"
                        ],
                        "name": "J. Collard",
                        "slug": "J.-Collard",
                        "structuredName": {
                            "firstName": "Jean-Francois",
                            "lastName": "Collard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Collard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6202525,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c7c64be9822d53fc47f40766a23ff718dd7940ce",
            "isKey": false,
            "numCitedBy": 40,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic parallelization of imperative programs has focused on nests of do loops with affine bounds and affine dependences, because in this case execution domains and dependences can be precisely known at compile-time. When dynamic control structures, such as while loops, are used, existing methods for conversion to single-assignment form and domain scanning are inapplicable. This paper gives an algorithm to automatically generate parallel code, together with an algorithm to possibly convert the program to single-assignment form."
            },
            "slug": "Generation-of-Synchronous-Code-for-Automatic-of-Griebl-Collard",
            "title": {
                "fragments": [],
                "text": "Generation of Synchronous Code for Automatic Parallelization of while Loops"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An algorithm to automatically generate parallel code, together with an algorithm to possibly convert the program to single-assignment form, to help with automatic parallelization of imperative programs."
            },
            "venue": {
                "fragments": [],
                "text": "Euro-Par"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769333"
                        ],
                        "name": "C. Bastoul",
                        "slug": "C.-Bastoul",
                        "structuredName": {
                            "firstName": "C\u00e9dric",
                            "lastName": "Bastoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bastoul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1838186"
                        ],
                        "name": "P. Feautrier",
                        "slug": "P.-Feautrier",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Feautrier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Feautrier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 79
                            }
                        ],
                        "text": "This can be used to quickly filter out or correct any violating transformation,(63) or even better, using the Farkas lemma as proposed by Feautrier,(8) to recast this implicit characterization into an explicit list of domains (of Farkas multipliers) enclosing the very values of all matrix coefficients associated with legal transformations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 92
                            }
                        ],
                        "text": "This idea is derived from the \u201cchunking\u201d transformation for automatic locality optimization;(63,64) it is the subject of active ongoing work."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11271968,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "27f8a5c9ac01e1f197c7a6f3a14136687bd235cb",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Program transformations are one of the most valuable compiler techniques to improve data locality. However, restructuring compilers have a hard time coping with data dependences. A typical solution is to focus on program parts where the dependences are simple enough to enable any transformation. For more complex problems is only addressed the question of checking whether a transformation is legal or not. In this paper we propose to go further. Starting from a transformation with no guarantee on legality, we show how we can correct it for dependence satisfaction with no consequence on its locality properties. Generating code having the best locality is a direct application of this result."
            },
            "slug": "More-Legal-Transformations-for-Locality-Bastoul-Feautrier",
            "title": {
                "fragments": [],
                "text": "More Legal Transformations for Locality"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper shows how to correct a transformation with no guarantee on legality for dependence satisfaction with no consequence on its locality properties, and generates code having the best locality."
            },
            "venue": {
                "fragments": [],
                "text": "Euro-Par"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6366028"
                        ],
                        "name": "Christian J. Bell",
                        "slug": "Christian-J.-Bell",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Bell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian J. Bell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "151492251"
                        ],
                        "name": "Weiyu Chen",
                        "slug": "Weiyu-Chen",
                        "structuredName": {
                            "firstName": "Weiyu",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weiyu Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1773866"
                        ],
                        "name": "D. Bonachea",
                        "slug": "D.-Bonachea",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Bonachea",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bonachea"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731111"
                        ],
                        "name": "K. Yelick",
                        "slug": "K.-Yelick",
                        "structuredName": {
                            "firstName": "Katherine",
                            "lastName": "Yelick",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Yelick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 144
                            }
                        ],
                        "text": "Thanks to third-party tools based on Open64, this framework supports source-to-source optimization, using the robust C unparser of Berkeley UPC,(67) and planning a port of the Fortran90 unparser from Open64/SL."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5941605,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d7f72552ab4c6949ab25cc5fac8643d7894c458",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "The Cray X1 was recently introduced as the first in a new line of parallel systems to combine high-bandwidth vector processing with an MPP system architecture. Alongside capabilities such as automatic fine-grained data parallelism through the use of vector instructions, the X1 offers hardware support for a transparent global-address space (GAS), which makes it an interesting target for GAS languages. In this paper, we describe our experience with developing a portable, open-source and high performance compiler for Unified Parallel C (UPC), a SPMD global-address space language extension of ISO C. As part of our implementation effort, we evaluate the X1's hardware support for GAS languages and provide empirical performance characterizations in the context of leveraging features such as vectorization and global pointers for the Berkeley UPC compiler. We discuss several difficulties encountered in the Cray C compiler which are likely to present challenges for many users, especially implementors of libraries and source-to-source translators. Finally, we analyze the performance of our compiler on some benchmark programs and show that, while there are some limitations of the current compilation approach, the Berkeley UPC compiler uses the X1 network more effectively than MPI or SHMEM, and generates serial code whose vectorizability is comparable to the original C code."
            },
            "slug": "Evaluating-support-for-global-address-space-on-the-Bell-Chen",
            "title": {
                "fragments": [],
                "text": "Evaluating support for global address space languages on the Cray X1"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The experience with developing a portable, open-source and high performance compiler for Unified Parallel C (UPC), a SPMD global-address space language extension of ISO C is described and the performance of the compiler is analyzed."
            },
            "venue": {
                "fragments": [],
                "text": "ICS '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769333"
                        ],
                        "name": "C. Bastoul",
                        "slug": "C.-Bastoul",
                        "structuredName": {
                            "firstName": "C\u00e9dric",
                            "lastName": "Bastoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bastoul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145509576"
                        ],
                        "name": "Albert Cohen",
                        "slug": "Albert-Cohen",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Albert Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2506136"
                        ],
                        "name": "Sylvain Girbal",
                        "slug": "Sylvain-Girbal",
                        "structuredName": {
                            "firstName": "Sylvain",
                            "lastName": "Girbal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sylvain Girbal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1956589"
                        ],
                        "name": "Saurabh Sharma",
                        "slug": "Saurabh-Sharma",
                        "structuredName": {
                            "firstName": "Saurabh",
                            "lastName": "Sharma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saurabh Sharma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731764"
                        ],
                        "name": "O. Temam",
                        "slug": "O.-Temam",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Temam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Temam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 156
                            }
                        ],
                        "text": "Our tool extracts large and representative SCoPs for SPECfp2000 benchmarks: on average, 88% of the statements belong to a SCoP containing at least one loop.(69) To refine these statistics, Figs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14364034,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "41f5e46eea538f867cd9c3d96020224604581451",
            "isKey": false,
            "numCitedBy": 146,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We seek to extend the scope and efficiency of iterative compilation techniques by searching not only for program transformation parameters but for the most appropriate transformations themselves. For that purpose, we need a generic way to express program transformations and compositions of transformations. In this article, we introduce a framework for the polyhedral representation of a wide range of transformations in a unified way. We also show that it is possible to generate efficient code after the application of polyhedral program transformations. Finally, we demonstrate an implementation of the polyhedral representation and code generation techniques in the Open64/ORC compiler."
            },
            "slug": "Putting-Polyhedral-Loop-Transformations-to-Work-Bastoul-Cohen",
            "title": {
                "fragments": [],
                "text": "Putting Polyhedral Loop Transformations to Work"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A framework for the polyhedral representation of a wide range of transformations in a unified way is introduced and it is shown that it is possible to generate efficient code after the application of polyhedral program transformations."
            },
            "venue": {
                "fragments": [],
                "text": "LCPC"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401533251"
                        ],
                        "name": "M. O\u2019Boyle",
                        "slug": "M.-O\u2019Boyle",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "O\u2019Boyle",
                            "middleNames": [
                                "F.",
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. O\u2019Boyle"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 94
                            }
                        ],
                        "text": "Optimizers based on more advanced rewriting systems(19) and most non-syntactic representations(3,10,20) will still peel an iteration of the first and last loops."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "Closer to our work, the MARS compiler(20) has been applied to iterative optimization;(72) this compiler\u2019s goal is to unify classical dependencebased loop transformations with data storage optimizations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "This paper does not bring any improvement to the existing solutions to this problem,(20) which are sufficiently mature already to express complex data layout transformations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 37922849,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ccb274304cb0cac333a5306a60f7556dce3e7230",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an automatic parallelising compiler, MARS, targeted for shared memory machines. It uses a data partitioning approach, traditionally used for distributed memory machines, in order to globally reduce overheads such as communication and synchronisation. Its high-level linear algebraic representation allows direct application of, for instance, unimodular transformations and global application of data transformation. Although a data based approach allows global analysis and in many instances outperforms local, loop-orientated parallelisation approaches, we have identified two particular problems when applying data parallelism to sequential Fortran 77 as opposed to data parallel dialects tailored to distributed memory targets. This paper describes two techniques to overcome these problems and evaluates their applicability. Preliminary results, on two SPECf92 benchmarks, show that with these optimisations, MARS outperforms existing state-of-the art loop based auto-parallelisation approaches."
            },
            "slug": "MARS:-A-Distributed-Memory-Approach-to-Shared-O\u2019Boyle",
            "title": {
                "fragments": [],
                "text": "MARS: A Distributed Memory Approach to Shared Memory Compilation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Preliminary results, on two SPECf92 benchmarks, show that with these optimisations, MARS outperforms existing state-of-the art loop based auto-parallelisation approaches."
            },
            "venue": {
                "fragments": [],
                "text": "LCR"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1630506780"
                        ],
                        "name": "Run-Time Systems for Scalable Computers",
                        "slug": "Run-Time-Systems-for-Scalable-Computers",
                        "structuredName": {
                            "firstName": "Run-Time",
                            "lastName": "Computers",
                            "middleNames": [
                                "Systems",
                                "for",
                                "Scalable"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Run-Time Systems for Scalable Computers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727597"
                        ],
                        "name": "S. Dwarkadas",
                        "slug": "S.-Dwarkadas",
                        "structuredName": {
                            "firstName": "Sandhya",
                            "lastName": "Dwarkadas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dwarkadas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 29082677,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9d8a9b47129b1667e22219023db286ba1620def2",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "I/O, Data-Intensive Computing.- A Collective I/O Scheme Based on Compiler Analysis.- Achieving Robust, Scalable Cluster I/O in Java.- High Level Programming Methodologies for Data Intensive Computations.- Static Analysis.- Static Analysis for Guarded Code.- A Framework for Efficient Register Allocation through Selective Register Demotion.- A Comparison of Locality Transformations for Irregular Codes.- OpenMP Support.- UPMLIB: A Runtime System for Tuning the Memory Performance of OpenMP Programs on Scalable Shared-Memory Multiprocessors.- Performance Evaluation of OpenMP Applications with Nested Parallelism.- Adaptive Parallelism for OpenMP Task Parallel Programs.- Synchronization.- Optimizing Mutual Exclusion Synchronization in Explicitly Parallel Programs.- Detecting Read-Only Methods in Java.- Software DSM.- The Effect of Contention on the Scalability of Page-Based Software Shared Memory Systems.- Measuring Consistency Costs for Distributed Shared Data.- Compilation and Runtime Optimizations for Software Distributed Shared Memory.- Heterogeneous/Meta-Computing.- Run-Time Support for Distributed Sharing in Typed Languages.- InterWeave: A Middleware System for Distributed Shared State.- Run-Time Support for Adaptive Heavyweight Services.- An Infrastructure for Monitoring and Management in Computational Grids.- Issues of Load.- Realistic CPU Workloads through Host Load Trace Playback.- Thread Migration and Load Balancing in Heterogeneous Environments.- Compiler-Supported Parallelism.- Toward Compiler Support for Scalable Parallelism Using Multipartitioning.- Speculative Parallelization of Partially Parallel Loops."
            },
            "slug": "Languages,-Compilers,-and-Run-Time-Systems-for-Computers-Dwarkadas",
            "title": {
                "fragments": [],
                "text": "Languages, Compilers, and Run-Time Systems for Scalable Computers"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper discusses the development of Runtime Optimizations for Scalable Parallelism using Multipartitioning, and the effect of Contention on the Scalability of Page-Based Software Shared Memory Systems."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "28513548"
                        ],
                        "name": "Amy W. Lim",
                        "slug": "Amy-W.-Lim",
                        "structuredName": {
                            "firstName": "Amy",
                            "lastName": "Lim",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amy W. Lim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40063567"
                        ],
                        "name": "Shih-Wei Liao",
                        "slug": "Shih-Wei-Liao",
                        "structuredName": {
                            "firstName": "Shih-Wei",
                            "lastName": "Liao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Wei Liao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682108"
                        ],
                        "name": "M. Lam",
                        "slug": "M.-Lam",
                        "structuredName": {
                            "firstName": "Monica",
                            "lastName": "Lam",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 55
                            }
                        ],
                        "text": "Although some polyhedral works have been built on SUIF,(11,13) they do not address the composition issue and rely on a weaker code generation method."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 17
                            }
                        ],
                        "text": "Array contraction(6,13) and its generalization called storage mapping optimization(56\u201358) allows to control the overhead due to expansion techniques."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 111
                            }
                        ],
                        "text": "Affine schedules have also been applied to the extraction and characterization of bulk-synchronous parallelism.(11,13,36) Array expansion is a generalization of privatization that leverages on the precision of array dependence analysis in the polyhedral model(33,54,55)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2860549,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "598863f81fc8fae6647a65cade0a323f79efe197",
            "isKey": false,
            "numCitedBy": 150,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Applicable to arbitrary sequences and nests of loops, affine partitioning is a program transformation framework that unifies many previously proposed loop transformations, including unimodular transforms, fusion, fission, reindexing, scaling and statement reordering. Algorithms based on affine partitioning have been shown to be effective for parallelization and communication minimization. This paper presents algorithms that improve data locality using affine partitioning.\nBlocking and array contraction are two important optimizations that have been shown to be useful for data locality. Blocking creates a set of inner loops so that data brought into the faster levels of the memory hierarchy can be reused. Array contraction reduces an array to a scalar variable and thereby reduces the number of memory operations executed and the memory footprint. Loop transforms are often necessary to make blocking and array contraction possible.\n By bringing the full generality of affine partitioning to bear on the problem, our locality algorithm can find more contractable arrays than previously possible. This paper also generalizes the concept of blocking and shows that affine partitioning allows the benefits of blocking be realized in arbitrarily nested loops. Experimental results on a number of benchmarks and a complete multigrid application in aeronautics indicates that affine partitioning is effective in practice."
            },
            "slug": "Blocking-and-array-contraction-across-arbitrarily-Lim-Liao",
            "title": {
                "fragments": [],
                "text": "Blocking and array contraction across arbitrarily nested loops using affine partitioning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper generalizes the concept of blocking and shows that affine partitioning allows the benefits of blocking be realized in arbitrarily nested loops, and can find more contractable arrays than previously possible."
            },
            "venue": {
                "fragments": [],
                "text": "PPoPP '01"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702824"
                        ],
                        "name": "David Parello",
                        "slug": "David-Parello",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Parello",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Parello"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731764"
                        ],
                        "name": "O. Temam",
                        "slug": "O.-Temam",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Temam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Temam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47265791"
                        ],
                        "name": "J. Verdun",
                        "slug": "J.-Verdun",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Verdun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Verdun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 109
                            }
                        ],
                        "text": "However, considering the ability to perform complex transformations, or complex sequences of transformations,(4,5) iterative optimization and machine learning compilation will fare no better than existing compilers on top of which they are currently implemented."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 405,
                                "start": 402
                            }
                        ],
                        "text": "At the same time, we will outline why this representation has several benefits for the implementation of program transformations: (1) it is generic and can serve to implement a large array of program transformations, (2) it isolates the root effects of program transformations, (3) it allows generalized versions of classical loop transformations to be defined without reference to any syntactic code, (4) this enables transparent composition of program transformations because applying program transformations has no effect on the representation complexity that makes it less generic or harder to manipulate, (5) and this eventually adds structure (commutativity, confluence, linearity) to the optimization search space."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12254805,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1508306e526da9ed6ecf0ed6f684a7aed03dc237",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "As the complexity of processor architectures increases, there is a widening gap between peak processor performance and sustained processor performance so that programs now tend to exploit only a fraction of available performance. While there is a tremendous amount of literature on program optimizations, compiler optimizations lack efficiency because they are plagued by three flaws: (1) they often implicitly use simplified, if not simplistic, models of processor architecture, (2) they usually focus on a single processor component (e.g., cache) and ignore the interactions among multiple components, (3) the most heavily nvestigated components (e.g., caches) sometimes have only a small impact on overall performance. Through the in-depth analysis of a simple program kernel, we want to show that understanding the complex interactions between programs and the numerous processor architecture components is both feasible and critical to design efficient program optimizations."
            },
            "slug": "On-Increasing-Architecture-Awareness-in-Program-to-Parello-Temam",
            "title": {
                "fragments": [],
                "text": "On Increasing Architecture Awareness in Program Optimizations to Bridge the Gap between Peak and Sustained Processor Performance &#8212; Matrix-Multiply Revisited"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Through the in-depth analysis of a simple program kernel, it is shown that understanding the complex interactions between programs and the numerous processor architecture components is both feasible and critical to design efficient program optimizations."
            },
            "venue": {
                "fragments": [],
                "text": "ACM/IEEE SC 2002 Conference (SC'02)"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3343018"
                        ],
                        "name": "H. Dietz",
                        "slug": "H.-Dietz",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Dietz",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Dietz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 27166276,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "707cc106ee092fea9a536b8dacab4f8c4ab359c2",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Languages-and-Compilers-for-Parallel-Computing-Dietz",
            "title": {
                "fragments": [],
                "text": "Languages and Compilers for Parallel Computing"
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1987955"
                        ],
                        "name": "Nawaaz Ahmed",
                        "slug": "Nawaaz-Ahmed",
                        "structuredName": {
                            "firstName": "Nawaaz",
                            "lastName": "Ahmed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nawaaz Ahmed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144827979"
                        ],
                        "name": "N. Mateev",
                        "slug": "N.-Mateev",
                        "structuredName": {
                            "firstName": "Nikolay",
                            "lastName": "Mateev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Mateev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1776186"
                        ],
                        "name": "K. Pingali",
                        "slug": "K.-Pingali",
                        "structuredName": {
                            "firstName": "Keshav",
                            "lastName": "Pingali",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Pingali"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 66
                            }
                        ],
                        "text": "Existing formalisms have been designed for black-box optimization,(8,11,12) and applying a classical loop transformation within them \u2013 as proposed in Ref."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2845533,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "db5911eecf93c3be2f3554b7bdc240c2220c54aa",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 113,
            "paperAbstract": {
                "fragments": [],
                "text": "Linear loop transformations and tiling are known to be very effective for enhancing locality of reference in perfectly-nested loops. However, they cannot be applied directly to imperfectly-nested loops. Some compilers attempt to convert imperfectly-nested loops into perfectly-nested loops by using statement sinking, loop fusion, etc., and then apply locality enhancing transformations to the resulting perfectly-nested loops, but the approaches used are fairly ad hoc and may fail even for simple programs. In this paper, we present a systematic approach for synthesizing transformations to enhance locality in imperfectly-nested loops. The key idea is to embed the iteration space of each statement into a special iteration space called the product space. The product space can be viewed as a perfectly-nested loop nest, so embedding generalizes techniques like statement sinking and loop fusion which are used in ad hoc ways in current compilers to produce perfectly-nested loops from imperfectly-nested ones. In contrast to these ad hoc techniques however, our embeddings are chosen carefully to enhance locality. The product space can itself be transformed to increase locality further, after which fully permutable loops can be tiled. The final code generation step may produce imperfectly-nested loops as output if that is desirable. We present experimental evidence for the effectiveness of this approach, using dense numerical linear algebra benchmarks, relaxation codes, and the tomcatv code from the SPEC benchmarks."
            },
            "slug": "Synthesizing-Transformations-for-Locality-of-Loop-Ahmed-Mateev",
            "title": {
                "fragments": [],
                "text": "Synthesizing Transformations for Locality Enhancement of Imperfectly-Nested Loop Nests"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This paper presents a systematic approach for synthesizing transformations to enhance locality in imperfectly-nested loops by embedding the iteration space of each statement into a special iteration space called the product space, which generalizes techniques like statement sinking and loop fusion used in ad hoc ways in current compilers."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Parallel Programming"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144022269"
                        ],
                        "name": "W. Pugh",
                        "slug": "W.-Pugh",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Pugh",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Pugh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697800"
                        ],
                        "name": "D. Wonnacott",
                        "slug": "D.-Wonnacott",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Wonnacott",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Wonnacott"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11673698,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "75b0ef2efd7b24ff990eec6eb7059590694cbd49",
            "isKey": false,
            "numCitedBy": 124,
            "numCiting": 92,
            "paperAbstract": {
                "fragments": [],
                "text": "Traditional array dependence analysis, which detects potential memory aliasing of array references is a key analysis technique for automatic parallelization. Recent studies of benchmark codes indicate that limitations of analysis cause many compilers to overlook large amounts of potential parallelism, and that exploiting this parallelism requires algorithms to answer new question about array references, not just get better answers to the old questions of aliasing. We need to ask about the flow of values in arrays, to check the legality of array privatization, and about the conditions under which a dependence exists, to obtain information about conditional parallelism. In some cases, we must answer these questions about code containing nonlinear terms in loop bounds or subscripts. This article describes techniques for phrasing these questions in terms of systems of contstraints. Conditional dependence analysis can be performed with a constraint operation we call the \"gist\" operation. When subscripts and loop bounds are affine, questions about the flow of values in array variables can be phrased in terms of Presburger Arithmetic. When the constraints describing a dependence are not affine, we introduce uninterpreted function symbols to represent the nonaffine terms. Our constraint language also provides a rich language for communication with the dependence analyzer, by either the programmer or other phases of the compiler. This article also documents our investigations of the praticality of our approach. The worst-case complexity of Presburger Arithmetic indicates that it might be unsuitable for any practical application. However, we have found that analysis of benchmark programs does not cause the exponential growth in the number of constraints that could occur in the worst case. We have studied the constraints produced during our aanalysis, and identified characteristics that keep our algorithms free of exponential behavior in practice."
            },
            "slug": "Constraint-based-array-dependence-analysis-Pugh-Wonnacott",
            "title": {
                "fragments": [],
                "text": "Constraint-based array dependence analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Techniques for phrasing questions about the flow of values in arrays, to check the legality of array privatization, and about the conditions under which a dependence exists in terms of systems of contstraints are described."
            },
            "venue": {
                "fragments": [],
                "text": "TOPL"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718247"
                        ],
                        "name": "Denis Barthou",
                        "slug": "Denis-Barthou",
                        "structuredName": {
                            "firstName": "Denis",
                            "lastName": "Barthou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Denis Barthou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145509576"
                        ],
                        "name": "Albert Cohen",
                        "slug": "Albert-Cohen",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Albert Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10609611"
                        ],
                        "name": "J. Collard",
                        "slug": "J.-Collard",
                        "structuredName": {
                            "firstName": "Jean-Francois",
                            "lastName": "Collard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Collard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 148
                            }
                        ],
                        "text": "(11,13,36) Array expansion is a generalization of privatization that leverages on the precision of array dependence analysis in the polyhedral model(33,54,55)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 940862,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "840ec9173dd5a5a52eee8dff2d219d451fe4447b",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Memory expansions are classical means to extract parallelism from imperative programs. However, current techniques require some runtime mechanism to restore data flow when expansion maps have two definitions reaching the same use to two different memory locations (e.g., \u03c6 functions in the SSA framework). This paper presents an expansion framework for any type of data structure in any imperative program, without the need for dynamic data flow restoration. The key idea is to group together definitions that reach a common use. We show that such an expansion boils down to mapping each group to a memory cell."
            },
            "slug": "Maximal-Static-Expansion-Barthou-Cohen",
            "title": {
                "fragments": [],
                "text": "Maximal Static Expansion"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper presents an expansion framework for any type of data structure in any imperative program, without the need for dynamic data flow restoration, to group together definitions that reach a common use."
            },
            "venue": {
                "fragments": [],
                "text": "POPL '98"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2912411"
                        ],
                        "name": "F. Irigoin",
                        "slug": "F.-Irigoin",
                        "structuredName": {
                            "firstName": "Fran\u00e7ois",
                            "lastName": "Irigoin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Irigoin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2913872"
                        ],
                        "name": "P. Jouvelot",
                        "slug": "P.-Jouvelot",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Jouvelot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Jouvelot"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3317184"
                        ],
                        "name": "R. Triolet",
                        "slug": "R.-Triolet",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Triolet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Triolet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "PIPS ( 71 ) is one of the most complete loop restructuring compiler, implementing polyhedral analyses and transformations (including affine scheduling) and interprocedural analyses (array regions, alias)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15561989,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eca0ea8a741df3fffb40882b0b6c976d9eeb0839",
            "isKey": false,
            "numCitedBy": 230,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "PIPS is an experhnental FORTRAN source-to-source parallelizer that combines the goal of exploring interprocedural and semantical analysis with a requirement for compilation speed. We present in this paper the main features of PIPS, i.e., demand-driven architecture, automatic support for multiple implementation languages, structured control graph, predicates and regions for interprocedural analysis and global nested loop paralle~lzation, with an emphasis on its core data structures and transformation phases. Some preliminary results on the practical impact of our design choices are discussed. This research is partially funded by DRET, under contract 87-017."
            },
            "slug": "Semantical-interprocedural-parallelization:-an-of-Irigoin-Jouvelot",
            "title": {
                "fragments": [],
                "text": "Semantical interprocedural parallelization: an overview of the PIPS project"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The main features of PIPS are presented, i.e., demand-driven architecture, automatic support for multiple implementation languages, structured control graph, predicates and regions for interprocedural analysis and global nested loop paralle~lzation, with an emphasis on its core data structures and transformation phases."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145597416"
                        ],
                        "name": "W. Kelly",
                        "slug": "W.-Kelly",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Kelly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Kelly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144022269"
                        ],
                        "name": "W. Pugh",
                        "slug": "W.-Pugh",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Pugh",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Pugh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50593802"
                        ],
                        "name": "E. Rosser",
                        "slug": "E.-Rosser",
                        "structuredName": {
                            "firstName": "Evan",
                            "lastName": "Rosser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Rosser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 166
                            }
                        ],
                        "text": "To date, the most thorough application of the polyhedral representation was the Petit dependence analyzer and loop restructuring tool,(10) based on the Omega library.(73) It provides space-time mappings for iteration reordering, and it shares our emphasis on per-statement transformations, but it is intended as a research tool for small kernels only."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60915757,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "39a0018bf60ae72b34e61d83129c2808525718a7",
            "isKey": false,
            "numCitedBy": 138,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "There has been a great amount of recent work toward unifying iteration reordering transformations. Many of these approaches represent transformations as affine mappings from the original iteration space to a new iteration space. These approaches show a great deal of promise, but they all rely on the ability to generate code that iterates over the points in these new iteration spaces in the appropriate order. This problem has been fairly well-studied in the case where all statements use the same mapping. We have developed an algorithm for the less well-studied case where each statement uses a potentially different mapping. Unlike many other approaches, our algorithm can also generate code from mappings corresponding to loop blocking. We address the important trade-off between reducing control overhead and duplicating code.<<ETX>>"
            },
            "slug": "Code-generation-for-multiple-mappings-Kelly-Pugh",
            "title": {
                "fragments": [],
                "text": "Code generation for multiple mappings"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work has developed an algorithm that addresses the important trade-off between reducing control overhead and duplicating code and can also generate code from mappings corresponding to loop blocking."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings Frontiers '95. The Fifth Symposium on the Frontiers of Massively Parallel Computation"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769333"
                        ],
                        "name": "C. Bastoul",
                        "slug": "C.-Bastoul",
                        "structuredName": {
                            "firstName": "C\u00e9dric",
                            "lastName": "Bastoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bastoul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1838186"
                        ],
                        "name": "P. Feautrier",
                        "slug": "P.-Feautrier",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Feautrier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Feautrier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 92
                            }
                        ],
                        "text": "This idea is derived from the \u201cchunking\u201d transformation for automatic locality optimization;(63,64) it is the subject of active ongoing work."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6676338,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ffb522ce93e16718083d11d03a6af5587681018",
            "isKey": false,
            "numCitedBy": 50,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Cache memories were invented to decouple fast processors from slow memories. However, this decoupling is only partial, and many researchers have attempted to improve cache use by program optimization. Potential benefits are significant since both energy dissipation and performance highly depend on the traffic between memory levels. But modeling the traffic is difficult; this observation has led to the use of heuristic methods for steering program transformations. In this paper, we propose another approach: we simplify the cache model and we organize the target program in such a way that an asymptotic evaluation of the memory traffic is possible. This information is used by our optimization algorithm in order to find the best reordering of the program operations, at least in an asymptotic sense. Our method optimizes both temporal and spatial locality. It can be applied to any static control program with arbitrary dependences. The optimizer has been partially implemented and applied to non-trivial programs. We present experimental evidence that the amount of cache misses is drastically reduced with corresponding performance improvements."
            },
            "slug": "Improving-Data-Locality-by-Chunking-Bastoul-Feautrier",
            "title": {
                "fragments": [],
                "text": "Improving Data Locality by Chunking"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper simplifies the cache model and organizes the target program in such a way that an asymptotic evaluation of the memory traffic is possible, and presents experimental evidence that the amount of cache misses is drastically reduced with corresponding performance improvements."
            },
            "venue": {
                "fragments": [],
                "text": "CC"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46938648"
                        ],
                        "name": "E. Visser",
                        "slug": "E.-Visser",
                        "structuredName": {
                            "firstName": "Eelco",
                            "lastName": "Visser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Visser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "Optimizers based on more advanced rewriting systems(19) and most non-syntactic representations(3,10,20) will still peel an iteration of the first and last loops."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13967250,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e43e26ee9670c4924fbadddab8a1146e45d803c6",
            "isKey": false,
            "numCitedBy": 377,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Program transformation is used in many areas of software engineering. Examples include compilation, optimization, synthesis, refactoring, migration, normalization and improvement [15]. Rewrite rules are a natural formalism for expressing single program transformations. However, using a standard strategy for normalizing a program with a set of rewrite rules is not adequate for implementing program transformation systems. It may be necessary to apply a rule only in some phase of a transformation, to apply rules in some order, or to apply a rule only to part of a program. These restrictions may be necessary to avoid non-termination or to choose a specific path in a non-con uent rewrite system."
            },
            "slug": "Stratego:-A-Language-for-Program-Transformation-on-Visser",
            "title": {
                "fragments": [],
                "text": "Stratego: A Language for Program Transformation Based on Rewriting Strategies"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Using a standard strategy for normalizing a program with a set of rewrite rules is not adequate for implementing program transformation systems, so restrictions may be necessary to apply a rule only in some phase of a transformation."
            },
            "venue": {
                "fragments": [],
                "text": "RTA"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1985764"
                        ],
                        "name": "A. Eichenberger",
                        "slug": "A.-Eichenberger",
                        "structuredName": {
                            "firstName": "Alexandre",
                            "lastName": "Eichenberger",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Eichenberger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143856977"
                        ],
                        "name": "Peng Wu",
                        "slug": "Peng-Wu",
                        "structuredName": {
                            "firstName": "Peng",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peng Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409617947"
                        ],
                        "name": "K. O'Brien",
                        "slug": "K.-O'Brien",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "O'Brien",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. O'Brien"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8003144,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cfc00c0037aa396719285be287f5e0848786ecc4",
            "isKey": false,
            "numCitedBy": 207,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "When vectorizing for SIMD architectures that are commonly employed by today's multimedia extensions, one of the new challenges that arise is the handling of memory alignment. Prior research has focused primarily on vectorizing loops where all memory references are properly aligned. An important aspect of this problem, namely, how to vectorize misaligned memory references, still remains unaddressed.This paper presents a compilation scheme that systematically vectorizes loops in the presence of misaligned memory references. The core of our technique is to automatically reorganize data in registers to satisfy the alignment requirement imposed by the hardware. To reduce the data reorganization overhead, we propose several techniques to minimize the number of data reorganization operations generated. During the code generation, our algorithm also exploits temporal reuse when aligning references that access contiguous memory across loop iterations. Our code generation scheme guarantees to never load the same data associated with a single static access twice. Experimental results indicate near peak speedup factors, e.g., 3.71 for 4 data per vector and 6.06 for 8 data per vector, respectively, for a set of loops where 75% or more of the static memory references are misaligned."
            },
            "slug": "Vectorization-for-SIMD-architectures-with-alignment-Eichenberger-Wu",
            "title": {
                "fragments": [],
                "text": "Vectorization for SIMD architectures with alignment constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents a compilation scheme that systematically vectorizes loops in the presence of misaligned memory references, and proposes several techniques to minimize the number of data reorganization operations generated."
            },
            "venue": {
                "fragments": [],
                "text": "PLDI '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1981698"
                        ],
                        "name": "S. Rus",
                        "slug": "S.-Rus",
                        "structuredName": {
                            "firstName": "Silvius",
                            "lastName": "Rus",
                            "middleNames": [
                                "Vasile"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Rus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109581066"
                        ],
                        "name": "Dongmin Zhang",
                        "slug": "Dongmin-Zhang",
                        "structuredName": {
                            "firstName": "Dongmin",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dongmin Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689939"
                        ],
                        "name": "L. Rauchwerger",
                        "slug": "L.-Rauchwerger",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rauchwerger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rauchwerger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 258,
                                "start": 254
                            }
                        ],
                        "text": "For example, a modernized version of Polaris has been used to (fully) automatically extract vast amounts of effectively exploitable parallelism in scientific codes, using hybrid analysis: a combination of static, dynamic and speculative dependence tests.(62) Yet these results used no prior loop transformation to enhance scalability through additional parallelism extraction or to coarsen its grain."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9027553,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d36e8f3c393169e4942e3ef20435e265e3ce3db7",
            "isKey": false,
            "numCitedBy": 21,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a framework for the analysis of memory reference sets addressed by induction variables without closed forms. This framework relies on a new data structure, the value evolution graph (VEG), which models the global flow of values taken by induction variable with and without closed forms. We describe the application of our framework to array data-flow analysis, privatization, and dependence analysis. This results in the automatic parallelization of loops that contain arrays addressed by induction variables without closed forms. We implemented this framework in the Polaris research compiler. We present experimental results on a set of codes from the PERFECT, SPEC, and NCSA benchmark suites."
            },
            "slug": "The-value-evolution-graph-and-its-use-in-memory-Rus-Zhang",
            "title": {
                "fragments": [],
                "text": "The value evolution graph and its use in memory reference analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "A framework for the analysis of memory reference sets addressed by induction variables without closed forms is introduced, which relies on a new data structure, the value evolution graph (VEG), which models the global flow of values taken by induction variable with and withoutclosed forms."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 13th International Conference on Parallel Architecture and Compilation Techniques, 2004. PACT 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709408"
                        ],
                        "name": "M. Strout",
                        "slug": "M.-Strout",
                        "structuredName": {
                            "firstName": "Michelle",
                            "lastName": "Strout",
                            "middleNames": [
                                "Mills"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Strout"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144852271"
                        ],
                        "name": "L. Carter",
                        "slug": "L.-Carter",
                        "structuredName": {
                            "firstName": "Larry",
                            "lastName": "Carter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Carter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144704592"
                        ],
                        "name": "J. Ferrante",
                        "slug": "J.-Ferrante",
                        "structuredName": {
                            "firstName": "Jeanne",
                            "lastName": "Ferrante",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ferrante"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143852058"
                        ],
                        "name": "B. Simon",
                        "slug": "B.-Simon",
                        "structuredName": {
                            "firstName": "Beth",
                            "lastName": "Simon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Simon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14247237,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a231e4d87c90d1f1c865dc84a0200837560feb9c",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper studies the relationship between storage requirements and performance. Storage-related dependences inhibit optimizations for locality and parallelism. Techniques such as renaming and array expansion can eliminate all storage-related dependences, but do so at the expense of increased storage. This paper introduces the universal occupancy vector (UOV) for loops with a regular stencil of dependences. The UOV provides a schedule-independent storage reuse pattern that introduces no further dependences (other than those implied by true flow dependences). OV-mapped code requires less storage than full array expansion and only slightly more storage than schedule-dependent minimal storage.We show that determine if a vector is a UOV is NPcomplete. However, an easily constructed but possibly nonminimal UOV can be used. We also present a branch and bound algorithm which finds the minimal UOV, while still maintaining a legal UOV at all times.Our experimental results show that the use of OV-mapped storage, coupled with tiling for locality, achieves better performance than tiling after array expansion, and accommodates larger problem sizes than untilable, storage-optimized code. F'urthermore, storage mapping based on the UOV introduces negligible runtime overhead."
            },
            "slug": "Schedule-independent-storage-mapping-for-loops-Strout-Carter",
            "title": {
                "fragments": [],
                "text": "Schedule-independent storage mapping for loops"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The experimental results show that the use of OV-mapped storage, coupled with tiling for locality, achieves better performance than tiling after array expansion, and accommodates larger problem sizes than untilable, storage-optimized code."
            },
            "venue": {
                "fragments": [],
                "text": "ASPLOS VIII"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1838186"
                        ],
                        "name": "P. Feautrier",
                        "slug": "P.-Feautrier",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Feautrier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Feautrier"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 1902814,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd0cbf0ed87ec9947b301a0b48fe60e0d5051cb7",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "A common problem in restructuring programs for vector or parallel execution is the suppression of false dependencies which originate in the reuse of the same memory cell for unrelated values. The method is simple and well understood in the case of scalars. This paper gives the general solution for the case of arrays. The expansion is done in two steps: first, modify all definitions of the offending array in order to obtain the single assignment property. Then, reconstruct the original data flow by adapting all uses of the array. This is done with the help of a new algorithm for solving parametric integer programs. The technique is quite general and may be used for other purposes, including program checking, collecting array predicates, etc\u2026"
            },
            "slug": "Array-expansion-Feautrier",
            "title": {
                "fragments": [],
                "text": "Array expansion"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The general solution for the case of arrays of false dependencies is given, which is to modify all definitions of the offending array in order to obtain the single assignment property."
            },
            "venue": {
                "fragments": [],
                "text": "ICS '88"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2237764"
                        ],
                        "name": "Vincent Lefebvre",
                        "slug": "Vincent-Lefebvre",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Lefebvre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Lefebvre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1838186"
                        ],
                        "name": "P. Feautrier",
                        "slug": "P.-Feautrier",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Feautrier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Feautrier"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 32647834,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "58e276439efc66d5676c1bd391a7714e93e35ef7",
            "isKey": false,
            "numCitedBy": 115,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automatic-Storage-Management-for-Parallel-Programs-Lefebvre-Feautrier",
            "title": {
                "fragments": [],
                "text": "Automatic Storage Management for Parallel Programs"
            },
            "venue": {
                "fragments": [],
                "text": "Parallel Comput."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144616193"
                        ],
                        "name": "R. Allen",
                        "slug": "R.-Allen",
                        "structuredName": {
                            "firstName": "Randy",
                            "lastName": "Allen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Allen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70455556"
                        ],
                        "name": "K. Kennedy",
                        "slug": "K.-Kennedy",
                        "structuredName": {
                            "firstName": "Ken",
                            "lastName": "Kennedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kennedy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13978052,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e8ddfb7574926d50b75937424ff907b53d264ca6",
            "isKey": false,
            "numCitedBy": 824,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "The recent success of vector computers such as the Cray-1 and array processors such as those manufactured by Floating Point Systems has increased interest in making vector operations available to the FORTRAN programmer. The FORTRAN standards committee is currently considering a successor to FORTRAN 77, usually called FORTRAN 8x, that will permit the programmer to explicitly specify vector and array operations.\nAlthough FORTRAN 8x will make it convenient to specify explicit vector operations in new programs, it does little for existing code. In order to benefit from the power of vector hardware, existing programs will need to be rewritten in some language (presumably FORTRAN 8x) that permits the explicit specification of vector operations. One way to avoid a massive manual recoding effort is to provide a translator that discovers the parallelism implicit in a FORTRAN program and automatically rewrites that program in FORTRAN 8x.\nSuch a translation from FORTRAN to FORTRAN 8x is not straightforward because FORTRAN DO loops are not always semantically equivalent to the corresponding FORTRAN 8x parallel operation. The semantic difference between these two constructs is precisely captured by the concept of dependence. A translation from FORTRAN to FORTRAN 8x preserves the semantics of the original program if it preserves the dependences in that program.\nThe theoretical background is developed here for employing data dependence to convert FORTRAN programs to parallel form. Dependence is defined and characterized in terms of the conditions that give rise to it; accurate tests to determine dependence are presented; and transformations that use dependence to uncover additional parallelism are discussed."
            },
            "slug": "Automatic-translation-of-FORTRAN-programs-to-vector-Allen-Kennedy",
            "title": {
                "fragments": [],
                "text": "Automatic translation of FORTRAN programs to vector form"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The theoretical background is developed here for employing data dependence to convert FORTRAN programs to parallel form and transformations that use dependence to uncover additional parallelism are discussed."
            },
            "venue": {
                "fragments": [],
                "text": "TOPL"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144211012"
                        ],
                        "name": "A. Bik",
                        "slug": "A.-Bik",
                        "structuredName": {
                            "firstName": "Aart",
                            "lastName": "Bik",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1807630"
                        ],
                        "name": "M. Girkar",
                        "slug": "M.-Girkar",
                        "structuredName": {
                            "firstName": "Milind",
                            "lastName": "Girkar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Girkar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2076761744"
                        ],
                        "name": "Paul M. Grey",
                        "slug": "Paul-M.-Grey",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Grey",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul M. Grey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145176935"
                        ],
                        "name": "Xinmin Tian",
                        "slug": "Xinmin-Tian",
                        "structuredName": {
                            "firstName": "Xinmin",
                            "lastName": "Tian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinmin Tian"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16085692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5afe81cf448c928d23fc0cf9e385c3febe92fda0",
            "isKey": false,
            "numCitedBy": 147,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent extensions to the Intel\u00ae Architecture feature the SIMD technique to enhance the performance of computational intensive applications that perform the same operation on different elements in a data set. To date, much of the code that exploits these extensions has been hand-coded. The task of the programmer is substantially simplified, however, if a compiler does this exploitation automatically. The high-performance Intel\u00ae C++/Fortran compiler supports automatic translation of serial loops into code that uses the SIMD extensions to the Intel\u00ae Architecture. This paper provides a detailed overview of the automatic vectorization methods used by this compiler together with an experimental validation of their effectiveness."
            },
            "slug": "Automatic-Intra-Register-Vectorization-for-the-Bik-Girkar",
            "title": {
                "fragments": [],
                "text": "Automatic Intra-Register Vectorization for the Intel\u00ae Architecture"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A detailed overview of the automatic vectorization methods used by the high-performance Intel\u00ae C++/Fortran compiler together with an experimental validation of their effectiveness are provided."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Parallel Programming"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145971118"
                        ],
                        "name": "K. Cooper",
                        "slug": "K.-Cooper",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Cooper",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Cooper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144922029"
                        ],
                        "name": "D. Subramanian",
                        "slug": "D.-Subramanian",
                        "structuredName": {
                            "firstName": "Devika",
                            "lastName": "Subramanian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Subramanian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750325"
                        ],
                        "name": "Linda Torczon",
                        "slug": "Linda-Torczon",
                        "structuredName": {
                            "firstName": "Linda",
                            "lastName": "Torczon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Linda Torczon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Technically, the purpose of this paper is threefold: (1) to show that syntactic code representations close to the operational semantics lead to rigid phase ordering and cumbersome expression of architecture-aware loop transformations, ( 2 ) to illustrate how complex transformation sequences may be needed to achieve significant performance benefits, (3) to facilitate the automatic search for program transformation sequences, improving on ..."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15275185,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "741c5d504b4555ac22a8c3d1bf422015a0cb7fa9",
            "isKey": false,
            "numCitedBy": 205,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Historically, compilers have operated by applying a fixed set of optimizations in a predetermined order. We call such an ordered list of optimizations a compilation sequence. This paper describes a prototype system that uses biased random search to discover a program-specific compilation sequence that minimizes an explicit, external objective function. The result is a compiler framework that adapts its behavior to the application being compiled, to the pool of available transformations, to the objective function, and to the target machine.This paper describes experiments that attempt to characterize the space that the adaptive compiler must search. The preliminary results suggest that optimal solutions are rare and that local minima are frequent. If this holds true, biased random searches, such as a genetic algorithm, should find good solutions more quickly than simpler strategies, such as hill climbing."
            },
            "slug": "Adaptive-Optimizing-Compilers-for-the-21st-Century-Cooper-Subramanian",
            "title": {
                "fragments": [],
                "text": "Adaptive Optimizing Compilers for the 21st Century"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A prototype system that uses biased random search to discover a program-specific compilation sequence that minimizes an explicit, external objective function is described, which is a compiler framework that adapts its behavior to the application being compiled, to the pool of available transformations, toThe objective function, and to the target machine."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of Supercomputing"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144198209"
                        ],
                        "name": "Jingling Xue",
                        "slug": "Jingling-Xue",
                        "structuredName": {
                            "firstName": "Jingling",
                            "lastName": "Xue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jingling Xue"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 171
                            }
                        ],
                        "text": "Many academic approaches to automatic parallelization have used the polyhedral model \u2013 and partially ordered affine schedules in particular \u2013 to describe fine grain vector(8,50,51) or systolic(52,53) parallelism."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7811341,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "407d33aed802f2596c96aa0e0107377267c9b856",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Automating-Non-Unimodular-Loop-Transformations-for-Xue",
            "title": {
                "fragments": [],
                "text": "Automating Non-Unimodular Loop Transformations for Massive Parallelism"
            },
            "venue": {
                "fragments": [],
                "text": "Parallel Comput."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "28513548"
                        ],
                        "name": "Amy W. Lim",
                        "slug": "Amy-W.-Lim",
                        "structuredName": {
                            "firstName": "Amy",
                            "lastName": "Lim",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amy W. Lim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682108"
                        ],
                        "name": "M. Lam",
                        "slug": "M.-Lam",
                        "structuredName": {
                            "firstName": "Monica",
                            "lastName": "Lam",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lam"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 55
                            }
                        ],
                        "text": "Although some polyhedral works have been built on SUIF,(11,13) they do not address the composition issue and rely on a weaker code generation method."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 212
                            }
                        ],
                        "text": "Our representation allows us to compose transformations without reference to a syntactic form, as opposed to previous polyhedral models where a single-step transformation captures the whole loop nest optimization(8,11) or intermediate code generation steps are needed."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "This was best illustrated by affine scheduling(8,10) and partitioning(11) algorithms."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 111
                            }
                        ],
                        "text": "Affine schedules have also been applied to the extraction and characterization of bulk-synchronous parallelism.(11,13,36) Array expansion is a generalization of privatization that leverages on the precision of array dependence analysis in the polyhedral model(33,54,55)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 66
                            }
                        ],
                        "text": "Existing formalisms have been designed for black-box optimization,(8,11,12) and applying a classical loop transformation within them \u2013 as proposed in Ref."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2366258,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e83bde11c3a58d37e6b750b9828bb25db3e643bb",
            "isKey": true,
            "numCitedBy": 65,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper describes a parallelization algorithm for programs consisting of arbitrary nestings of loops and sequences of loops. The code produced by our algorithm yields all the degrees of communication-free parallelism that can be obtained via loop fission, fusion, interchange, reversal, skewing, scaling, reindexing and statement reordering. The algorithm first assigns the iterations of instructions in the program to processors via affine processor mappings, then generates the correct code by ensuring that the code executed by each processor is a subsequence of the original sequential execution sequence."
            },
            "slug": "Communication-Free-Parallelization-via-Affine-Lim-Lam",
            "title": {
                "fragments": [],
                "text": "Communication-Free Parallelization via Affine Transformations"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "The paper describes a parallelization algorithm for programs consisting of arbitrary nestings of loops and sequences of loops that yields all the degrees of communication-free parallelism that can be obtained via loop fission, fusion, interchange, reversal, skewing, scaling, reindexing and statement reordering."
            },
            "venue": {
                "fragments": [],
                "text": "LCPC"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10609611"
                        ],
                        "name": "J. Collard",
                        "slug": "J.-Collard",
                        "structuredName": {
                            "firstName": "Jean-Francois",
                            "lastName": "Collard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Collard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 26662407,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "251457b35c278c892baeb3719a71a143f9cdd7a8",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThis book details program analyses and transformations that extract the flow of data in computer memory systems. It emphasizes a framework for the optimization of code for imperative programs and greater computer systems efficiency. In addition, it shows that correctness of program transformations is guaranteed by the conservation of data flow. \nProfessionals and researchers in software engineering, computer engineering, program design analysis, and compiler design will benefit from its presentation of data-flow methods and memory optimization of compilers."
            },
            "slug": "Reasoning-About-Program-Transformations-Collard",
            "title": {
                "fragments": [],
                "text": "Reasoning About Program Transformations"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This book details program analyses and transformations that extract the flow of data in computer memory systems and shows that correctness of program transformations is guaranteed by the conservation of data flow."
            },
            "venue": {
                "fragments": [],
                "text": "Springer New York"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1838186"
                        ],
                        "name": "P. Feautrier",
                        "slug": "P.-Feautrier",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Feautrier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Feautrier"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5738544,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7cd685371e267a499ded869a934a4cffed591aec",
            "isKey": false,
            "numCitedBy": 454,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a program written in a simple imperative language (assignment statements,for loops, affine indices and loop limits), this paper presents an algorithm for analyzing the patterns along which values flow as the execution proceeds. For each array or scalar reference, the result is the name and iteration vector of the source statement as a function of the iteration vector of the referencing statement. The paper discusses several applications of the method: conversion of a program to a set of recurrence equations, array and scalar expansion, program verification and parallel program construction."
            },
            "slug": "Dataflow-analysis-of-array-and-scalar-references-Feautrier",
            "title": {
                "fragments": [],
                "text": "Dataflow analysis of array and scalar references"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This paper presents an algorithm for analyzing the patterns along which values flow as the execution proceeds, and discusses several applications of the method: conversion of a program to a set of recurrence equations, array and scalar expansion, program verification and parallel program construction."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Parallel Programming"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2802912"
                        ],
                        "name": "T. Kisuki",
                        "slug": "T.-Kisuki",
                        "structuredName": {
                            "firstName": "Toru",
                            "lastName": "Kisuki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kisuki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793602"
                        ],
                        "name": "P. Knijnenburg",
                        "slug": "P.-Knijnenburg",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Knijnenburg",
                            "middleNames": [
                                "M.",
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Knijnenburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401533251"
                        ],
                        "name": "M. O\u2019Boyle",
                        "slug": "M.-O\u2019Boyle",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "O\u2019Boyle",
                            "middleNames": [
                                "F.",
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. O\u2019Boyle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706624"
                        ],
                        "name": "H. Wijshoff",
                        "slug": "H.-Wijshoff",
                        "structuredName": {
                            "firstName": "Harry",
                            "lastName": "Wijshoff",
                            "middleNames": [
                                "A.",
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Wijshoff"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 45
                            }
                        ],
                        "text": "This invariant brings two strong properties: (1) it suppresses scheduling ambiguities at code generation time, and (2) it guarantees that rulecompliant transformation of the schedule and will preserve sequentiality of the whole SCoP, independently of iteration domains."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 53
                            }
                        ],
                        "text": "Technically, the purpose of this paper is threefold: (1) to show that syntactic code representations close to the operational semantics lead to rigid phase ordering and cumbersome expression of architecture-aware loop transformations, (2) to illustrate how complex transformation sequences may be needed to achieve significant performance benefits, (3) to facilitate the automatic search for program transformation sequences, improving on classical polyhedral representations to better support operation research strategies in a simpler, structured search space."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 49
                            }
                        ],
                        "text": "A dS,1 \u00b7 \u00b7 \u00b7 A dS,dS 0 0 \u00b7 \u00b7 \u00b7 0 \u03b2 dS \uf8f9 \uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb (1)"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 130
                            }
                        ],
                        "text": "At the same time, we will outline why this representation has several benefits for the implementation of program transformations: (1) it is generic and can serve to implement a large array of program transformations, (2) it isolates the root effects of program transformations, (3) it allows generalized versions of classical loop transformations to be defined without reference to any syntactic code, (4) this enables transparent composition of program transformations because applying program transformations has no effect on the representation complexity that makes it less generic or harder to manipulate, (5) and this eventually adds structure (commutativity, confluence, linearity) to the optimization search space."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9298136,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b9976636034c726a4e7f898fe51afaf12869a839",
            "isKey": true,
            "numCitedBy": 78,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a novel approach to program optimization, namely, iterative compilation. This technique enables compilers to deliver e cient code by searching for the best sequence of optimizations using pro le-directed feedback. We have implemented this iterative approach in an existing compiler system which is designed for embedded systems and compared its performance to two of the best known static techniques. Initial experimental results show that this approach delivers an average improvement of 35% over existing techniques and delivers e cient code with reasonable compilation times."
            },
            "slug": "Iterative-Compilation-in-Program-Optimization-Kisuki-Knijnenburg",
            "title": {
                "fragments": [],
                "text": "Iterative Compilation in Program Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "Initial experimental results show that this novel approach to program optimization, namely, iterative compilation, delivers an average improvement of 35% over existing techniques and delivers e cient code with reasonable compilation times."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1879660"
                        ],
                        "name": "S. Carr",
                        "slug": "S.-Carr",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Carr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Carr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48493240"
                        ],
                        "name": "C. Ding",
                        "slug": "C.-Ding",
                        "structuredName": {
                            "firstName": "Chen",
                            "lastName": "Ding",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Ding"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2569672"
                        ],
                        "name": "P. Sweany",
                        "slug": "P.-Sweany",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Sweany",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Sweany"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 670365,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7d636377db09c4e6ed95db8cb378c4bfb5debfcf",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "To take advantage of recent architectural improvements in microprocessors, advanced compiler optimizations such as software pipelining have been developed. Unfortunately, not all loops have enough parallelism in the innermost loop body to take advantage of all of the resources a machine provides. Unroll-and-jam is a transformation that can be used to increase the amount of parallelism in the innermost loop body by making better use of resources and limiting the effects of recurrences. We demonstrate how unroll-and-jam can significantly improve the initiation interval in a software-pipelined loop. Improvements in the initiation interval of greater than 40% are common, while dramatic improvements of a factor of 5 are possible."
            },
            "slug": "Improving-software-pipelining-with-unroll-and-jam-Carr-Ding",
            "title": {
                "fragments": [],
                "text": "Improving software pipelining with unroll-and-jam"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is demonstrated how unroll-and-jam can significantly improve the initiation interval in a software-pipelined loop."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of HICSS-29: 29th Hawaii International Conference on System Sciences"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3271797"
                        ],
                        "name": "P. Tu",
                        "slug": "P.-Tu",
                        "structuredName": {
                            "firstName": "Peng",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729097"
                        ],
                        "name": "D. Padua",
                        "slug": "D.-Padua",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Padua",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Padua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 294133,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ff78b91c560e66d6c6de7dfee75dfee63868fb4",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Array privatization is one of the most effective transformations for the exploitation of parallelism. In this paper, we present a technique for automatic array privatization. Our algorithm uses data flow analysis of array references to identify privatizable arrays intraprocedurally as well as interprocedurally. It employs static and dynamic resolution to determine the last value of a lived private array. We compare the result of automatic array privatization with that of manual array privatization and identify directions for future improvement. To enhance the effectiveness of our algorithm, we develop a goal directly technique to analysis symbolic variables in the present of conditional statements, loops and index arrays."
            },
            "slug": "Automatic-Array-Privatization-Tu-Padua",
            "title": {
                "fragments": [],
                "text": "Automatic Array Privatization"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper uses data flow analysis of array references to identify privatizable arrays intraprocedural as well as interprocedurally and develops a goal directly technique to analysis symbolic variables in the present of conditional statements, loops and index arrays."
            },
            "venue": {
                "fragments": [],
                "text": "Compiler Optimizations for Scalable Parallel Systems Languages"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145971118"
                        ],
                        "name": "K. Cooper",
                        "slug": "K.-Cooper",
                        "structuredName": {
                            "firstName": "Keith",
                            "lastName": "Cooper",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Cooper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143896454"
                        ],
                        "name": "Mary W. Hall",
                        "slug": "Mary-W.-Hall",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Hall",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mary W. Hall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144516069"
                        ],
                        "name": "R. Hood",
                        "slug": "R.-Hood",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Hood",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hood"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70455556"
                        ],
                        "name": "K. Kennedy",
                        "slug": "K.-Kennedy",
                        "structuredName": {
                            "firstName": "Ken",
                            "lastName": "Kennedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kennedy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766093"
                        ],
                        "name": "K. McKinley",
                        "slug": "K.-McKinley",
                        "structuredName": {
                            "firstName": "Kathryn",
                            "lastName": "McKinley",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. McKinley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398109299"
                        ],
                        "name": "J. Mellor-Crummey",
                        "slug": "J.-Mellor-Crummey",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Mellor-Crummey",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mellor-Crummey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1750325"
                        ],
                        "name": "Linda Torczon",
                        "slug": "Linda-Torczon",
                        "structuredName": {
                            "firstName": "Linda",
                            "lastName": "Torczon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Linda Torczon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1904029"
                        ],
                        "name": "S. Warren",
                        "slug": "S.-Warren",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Warren",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Warren"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ParaScope ( 40 ) and Polaris (41) are dependence based, source-to-source parallelizers for Fortran."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62517894,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e19baff36b238b92cafb2146fdbaa1a4e5b123d0",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "The ParaScope parallel programming environment, developed to support scientific programming of shared-memory multiprocessors, is described. It includes a collection of tools that use global program analysis to help users develop and debug parallel programs. The focus is on ParaScope's compilation system. The compilation system extends the traditional single-procedure compiler by providing a mechanism for managing the compilation of complete programs. The ParaScope editor brings both compiler analysis and user expertise to bear on program parallelization. The debugging system detects and reports timing-dependent errors, called data races, in execution of parallel programs. A project aimed at extending ParaScope to support programming in FORTRAN D, a machine-independent parallel programming language for use with both distributed-memory and shared-memory parallel computers, is described. >"
            },
            "slug": "The-ParaScope-parallel-programming-environment-Cooper-Hall",
            "title": {
                "fragments": [],
                "text": "The ParaScope parallel programming environment"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A project aimed at extending ParaScope to support programming in FORTRAN D, a machine-independent parallel programming language for use with both distributed-memory and shared-memory parallel computers, is described."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "28513548"
                        ],
                        "name": "Amy W. Lim",
                        "slug": "Amy-W.-Lim",
                        "structuredName": {
                            "firstName": "Amy",
                            "lastName": "Lim",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amy W. Lim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682108"
                        ],
                        "name": "M. Lam",
                        "slug": "M.-Lam",
                        "structuredName": {
                            "firstName": "Monica",
                            "lastName": "Lam",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lam"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 143078,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bcc4228662290f7f85bb471c4933bd101e8ce43d",
            "isKey": false,
            "numCitedBy": 208,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents the first algorithm to find the optimal affine transform that maximizes the degree of parallelism while minimizing the degree of synchronization in a program with arbitrary loop nestings and affine data accesses. The problem is formulated without the use of imprecise data dependence abstractions such as data dependence vectors. The algorithm presented subsumes previously proposed program transformation algorithms that are based on unimodular transformations, loop fusion, fission, scaling, reindexing and/or statement reordering."
            },
            "slug": "Maximizing-parallelism-and-minimizing-with-affine-Lim-Lam",
            "title": {
                "fragments": [],
                "text": "Maximizing parallelism and minimizing synchronization with affine transforms"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The algorithm presented subsumes previously proposed program transformation algorithms that are based on unimodular transformations, loop fusion, fission, scaling, reindexing and/or statement reordering."
            },
            "venue": {
                "fragments": [],
                "text": "POPL '97"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2344093"
                        ],
                        "name": "D. Naishlos",
                        "slug": "D.-Naishlos",
                        "structuredName": {
                            "firstName": "Dorit",
                            "lastName": "Naishlos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Naishlos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40556667"
                        ],
                        "name": "Leehod Baruch",
                        "slug": "Leehod-Baruch",
                        "structuredName": {
                            "firstName": "Leehod",
                            "lastName": "Baruch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Leehod Baruch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2744911"
                        ],
                        "name": "R. Eres",
                        "slug": "R.-Eres",
                        "structuredName": {
                            "firstName": "Revital",
                            "lastName": "Eres",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Eres"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2062320"
                        ],
                        "name": "Olga Golovanevsky",
                        "slug": "Olga-Golovanevsky",
                        "structuredName": {
                            "firstName": "Olga",
                            "lastName": "Golovanevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Olga Golovanevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3160559"
                        ],
                        "name": "Mustafa Hagog",
                        "slug": "Mustafa-Hagog",
                        "structuredName": {
                            "firstName": "Mustafa",
                            "lastName": "Hagog",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mustafa Hagog"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2292387"
                        ],
                        "name": "Razya Ladelsky",
                        "slug": "Razya-Ladelsky",
                        "structuredName": {
                            "firstName": "Razya",
                            "lastName": "Ladelsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Razya Ladelsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2374886"
                        ],
                        "name": "Victor Leikehman",
                        "slug": "Victor-Leikehman",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Leikehman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Victor Leikehman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3305063"
                        ],
                        "name": "Mircea Namolaru",
                        "slug": "Mircea-Namolaru",
                        "structuredName": {
                            "firstName": "Mircea",
                            "lastName": "Namolaru",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mircea Namolaru"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153090846"
                        ],
                        "name": "Ira Rosen",
                        "slug": "Ira-Rosen",
                        "structuredName": {
                            "firstName": "Ira",
                            "lastName": "Rosen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ira Rosen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38737579"
                        ],
                        "name": "A. Zaks",
                        "slug": "A.-Zaks",
                        "structuredName": {
                            "firstName": "Ayal",
                            "lastName": "Zaks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zaks"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16032201,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fd07f94dbbc844a07ce02d9f965a6167fbd8ad91",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Vectorization is an optimization technique that has traditionally targeted vector processors. The importance of this optimization has increased in recent years with the introduction of SIMD (single instruction multiple data) extensions to general purpose processors, and with the growing significance of applications that can benefit from this functionality. With the adoption of the new Tree SSA optimization framework, GCC is ready to take on the challenge of automatic vectorization. In this paper we describe the design and implementation of a loop-based vectorizer in GCC. We discuss the new issues that arise when vectorizing for SIMD extensions as opposed to traditional vectorization. We also present preliminary results and future work."
            },
            "slug": "Autovectorization-in-GCC-Naishlos-Baruch",
            "title": {
                "fragments": [],
                "text": "Autovectorization in GCC"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The design and implementation of a loop-based vectorizer in GCC is described and the new issues that arise when vectorizing for SIMD extensions as opposed to traditional vectorization are discussed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144022269"
                        ],
                        "name": "W. Pugh",
                        "slug": "W.-Pugh",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Pugh",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Pugh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 171
                            }
                        ],
                        "text": "Many academic approaches to automatic parallelization have used the polyhedral model \u2013 and partially ordered affine schedules in particular \u2013 to describe fine grain vector(8,50,51) or systolic(52,53) parallelism."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3174094,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "285024b15197b5face8bdef1d03f36949b8339c4",
            "isKey": false,
            "numCitedBy": 950,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "The Omega test is an integer programming algorithm that can determine whether a dependence exists between two array references, and if so, under what conditions. Conventional wisdom holds that integer programming techniques are far too expensive to be used for dependence analysis, except as a method of last resort for situations that cannot be decided by simpler methods. We present evidence that suggests this wisdom is wrong, and that the Omega test is competitive with approximate algorithms used in practice and suitable for use in production compilers. The Omega test is based on an extension of FourierMotzkin variable elimination to integer programming, and has worst-case exponential time complexity. However, we show that for many situations in which other (polynomial) methods are accurate, the Omega test has low order polynomial time complexity. The Omega test can be used to simplify integer programming problems, rather than just deciding them. This has many applications, including accurately and efficiently computing dependence direction and distance vectors."
            },
            "slug": "The-Omega-test:-A-fast-and-practical-integer-for-Pugh",
            "title": {
                "fragments": [],
                "text": "The Omega test: A fast and practical integer programming algorithm for dependence analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Evidence is presented that suggests conventional wisdom is wrong, and that the Omega test is competitive with approximate algorithms used in practice and suitable for use in production compilers, and has low order polynomial time complexity."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 1991 ACM/IEEE Conference on Supercomputing (Supercomputing '91)"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50073003"
                        ],
                        "name": "M. Wolfe",
                        "slug": "M.-Wolfe",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Wolfe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wolfe"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 95
                            }
                        ],
                        "text": "Up to now, the easy composition of transformations was restricted to unimodular transformations(6), with some extensions to singular transformations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 125
                            }
                        ],
                        "text": "Multiple refinement of this abstraction have been proposed, including dependence directions, distances, vectors and intervals(6) to improve the precision about the localization of the actual dependences between run-time statement instances."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 53
                            }
                        ],
                        "text": "First of all, by imposing phase ordering constraints,(6) they lack the ability to perform long sequences of transformations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 17
                            }
                        ],
                        "text": "Array contraction(6,13) and its generalization called storage mapping optimization(56\u201358) allows to control the overhead due to expansion techniques."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 160
                            }
                        ],
                        "text": "(41) The main transformations include privatization (32,47,48) for dependence removal and unimodular transformations or node splitting to rearrange dependences.(6,49)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 143
                            }
                        ],
                        "text": "Practically, in most cases, loop unrolling by a factor b an be implemented as a combination of strip-mining (by a factor b) and full unrolling.(6) Strip-mining itself may be implemented in several ways in a polyhedral setting."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 36080832,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b7c7fbce6a693ba54e63bc8742afd25f20f4f2d0",
            "isKey": true,
            "numCitedBy": 1445,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. High Performance Systems. An Example Program: Matrix Multiplication. Structure of a Compiler. 2. Programming Language Features. Languages for High Performance. Sequential and Parallel Loops. Roundoff Error. 3. Basic Graph Concepts. Sets, Tuples, Logic. Graphs. Control Dependence. 4. Review of Linear Algebra. Real Vectors and Matrices. Integer Matrices and Lattices. Linear System of Equations. System of Integer Equations. Systems of Linear Inequalities. Systems of Integer Linear Inequalities. Extreme Values of Affine Functions. 5. Data Dependence. Data Dependence in Loops. Data Dependence in Conditionals. Data Dependence in Parallel Loops. Program Dependence Graph. 6. Scalar Analysis with Factored Use-Def Chains. Constructing Factored Use-Def Chains. FUD Chains for Arrays. Finding All Reaching Definitions. Implicit References in FUD Chains. InductionVariables Using FUD Chains. Constant Propagation with FUD Chains. Data Dependence for Scalars. 7. Data Dependence Analysis for Arrays. Building the Dependence System. Dependence System Solvers. General Solver. Summary of Solvers. Complications. Run-time Dependence Testing. 8. Other Dependence Problems. Array Region Analysis. Pointer Analysis. I/O Dependence. Procedure Calls. Interprocedural Analysis. 9. Loop Restructuring. Simpile Transformations. Loop Fusion. Loop Fission. Loop Reversal. Loop Interchanging. Loop Skewing. Linear Loop Transformations. Strip-Mining. Loop Tiling. Other Loop Transformations. Interprocedural Transformations. 10. Optimizing for Locality. Single Reference to Each Array. Multiple References. General Tiling. Fission and Fusion for Locality. 11. Concurrency Analysis. Code for Concurrent Loops. Concurrency from Sequential Loops. Concurrency from Parallel Loops. Nested Loops. Roundoff Error. Exceptions and Debuggers. 12. Vector Analysis. Vector Code. Vector Code from Sequential Loops. Vector Code from Forall Loops. Nested Loops. Roundoff Error, Exceptions, and Debuggers. Multivector Computers. 13. Message-Passing Machines. SIMD Machines. MIMD Machines. Data Layout. Parallel Code for Array Assignment. Remote Data Access. Automatic Data Layout. Multiple Array Assignments. Other Topics. 14. Scalable Shared-Memory Machines. Global Cache Coherence. Local Cache Coherence. Latency Tolerant Machines. Glossary. References. Author Index. Index. 0805327304T04062001"
            },
            "slug": "High-performance-compilers-for-parallel-computing-Wolfe",
            "title": {
                "fragments": [],
                "text": "High performance compilers for parallel computing"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This book discusses Programming Language Features, Data Dependence, Dependence System Solvers, and Run-time Dependence Testing for High Performance Systems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2020735"
                        ],
                        "name": "Fabien Quiller\u00e9",
                        "slug": "Fabien-Quiller\u00e9",
                        "structuredName": {
                            "firstName": "Fabien",
                            "lastName": "Quiller\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fabien Quiller\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747659"
                        ],
                        "name": "S. Rajopadhye",
                        "slug": "S.-Rajopadhye",
                        "structuredName": {
                            "firstName": "Sanjay",
                            "lastName": "Rajopadhye",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Rajopadhye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143860773"
                        ],
                        "name": "D. Wilde",
                        "slug": "D.-Wilde",
                        "structuredName": {
                            "firstName": "Doran",
                            "lastName": "Wilde",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Wilde"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": "method(23) with some additional improvements to guarantee the absence"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 115
                            }
                        ],
                        "text": "The best syntax tree construction scheme consists in a recursive application of domain projections and separations.(22,23) The final code is deduced from the set of constraints describing the polyhedra attached to each node in the tree."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14709233,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d56126a645271da916ad339df27a2bac1b75d320",
            "isKey": false,
            "numCitedBy": 206,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "Automatic parallelization in the polyhedral model is based on affine transformations from an original computation domain (iteration space) to a target space-time domain, often with a different transformation for each variable. Code generation is an often ignored step in this process that has a significant impact on the quality of the final code. It involves making a trade-off between code size and control code simplification/optimization. Previous methods of doing code generation are based on loop splitting, however they have nonoptimal behavior when working on parameterized programs. We present a general parameterized method for code generation based on dual representation of polyhedra. Our algorithm uses a simple recursion on the dimensions of the domains, and enables fine control over the tradeoff between code size and control overhead."
            },
            "slug": "Generation-of-Efficient-Nested-Loops-from-Polyhedra-Quiller\u00e9-Rajopadhye",
            "title": {
                "fragments": [],
                "text": "Generation of Efficient Nested Loops from Polyhedra"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work presents a general parameterized method for code generation based on dual representation of polyhedra that uses a simple recursion on the dimensions of the domains, and enables fine control over the tradeoff between code size and control overhead."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Parallel Programming"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1862295"
                        ],
                        "name": "Aashish Phansalkar",
                        "slug": "Aashish-Phansalkar",
                        "structuredName": {
                            "firstName": "Aashish",
                            "lastName": "Phansalkar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aashish Phansalkar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33901930"
                        ],
                        "name": "A. Joshi",
                        "slug": "A.-Joshi",
                        "structuredName": {
                            "firstName": "Ajay",
                            "lastName": "Joshi",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Joshi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717133"
                        ],
                        "name": "L. Eeckhout",
                        "slug": "L.-Eeckhout",
                        "structuredName": {
                            "firstName": "Lieven",
                            "lastName": "Eeckhout",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Eeckhout"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1703238"
                        ],
                        "name": "L. John",
                        "slug": "L.-John",
                        "structuredName": {
                            "firstName": "Lizy",
                            "lastName": "John",
                            "middleNames": [
                                "Kurian"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. John"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 195
                            }
                        ],
                        "text": "Interestingly, this weakness is confirmed by the historical evolution of the SPEC CPU benchmarks themselves, partly driven by the need to avoid pattern-matching attacks from commercial compilers.(17) To illustrate this point we have attempted to perform the above program transformations targeting the Alpha 21364 EV7, using KAP C (V4."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17224711,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6e0ccdf55165b5ae2a19f1a109073e954d0f4a2c",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Standard Performance Evaluation Corporation (SPEC) CPU benchmark suite which was first released in 1989 as a collection of 10 computation-intensive benchmark programs (average size of 2.5 billion dynamic instructions per program), is now in its fourth generation and has grown to 26 programs (average size of 230 billion dynamic instructions per program). In order to keep pace with the architectural enhancements, technological advancements, software improvements, and emerging workloads, new programs were added, programs susceptible to compiler attacks were retired, program run times were increased, and memory activity of programs was increased in every generation of the benchmark suite. The objective of this paper is to understand how the inherent characteristics of SPEC benchmark programs have evolved over the last 1.5 decades \u2013 which aspects have changed and which have not. We measured and analyzed a collection of microarchitecture-independent metrics related to the instruction mix, data locality, branch predictability, and parallelism to understand the changes in generic workload characteristics with the evolution of benchmark suites. Surprisingly, we find that other than a dramatic increase in the dynamic instruction count and increasingly poor temporal data locality, the inherent program characteristics have pretty much remained unchanged. We also observe that SPEC CPU2000 benchmark suite is more diverse than its ancestors, but still has a over 50% redundancy in programs. Based on our key findings and learnings from this study: (i) we make recommendations to SPEC that will be useful in selecting programs for future benchmark suites, (ii) speculate about the trend of future SPEC CPU benchmark workloads, and (iii) provide a scientific methodology for selecting representative workloads should the cost of simulating the entire benchmark be prohibitively high."
            },
            "slug": "FOUR-GENERATIONS-OF-SPEC-CPU-BENCHMARKS-:-WHAT-HAS-Phansalkar-Joshi",
            "title": {
                "fragments": [],
                "text": "FOUR GENERATIONS OF SPEC CPU BENCHMARKS : WHAT HAS CHANGED AND WHAT HAS NOT"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Surprisingly, it is found that other than a dramatic increase in the dynamic instruction count and increasingly poor temporal data locality, the inherent program characteristics have pretty much remained unchanged."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733001"
                        ],
                        "name": "A. Darte",
                        "slug": "A.-Darte",
                        "structuredName": {
                            "firstName": "Alain",
                            "lastName": "Darte",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Darte"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145552986"
                        ],
                        "name": "Y. Robert",
                        "slug": "Y.-Robert",
                        "structuredName": {
                            "firstName": "Yves",
                            "lastName": "Robert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Robert"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 78
                            }
                        ],
                        "text": "lattice polyhedra or linearly bounded lattices) is known to be a hard problem.(21,37)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1428972,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e8b606391c6eaf78d1f70bb3c3961f291964002a",
            "isKey": false,
            "numCitedBy": 67,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Mapping-Uniform-Loop-Nests-Onto-Distributed-Memory-Darte-Robert",
            "title": {
                "fragments": [],
                "text": "Mapping Uniform Loop Nests Onto Distributed Memory Architectures"
            },
            "venue": {
                "fragments": [],
                "text": "Parallel Comput."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1838186"
                        ],
                        "name": "P. Feautrier",
                        "slug": "P.-Feautrier",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Feautrier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Feautrier"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Existing formalisms have been designed for black-box optimization, ( 8 ,11,12) and applying a classical loop transformation within them \u2013 as proposed in Ref."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12851421,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16de6f9e2bf6ee1068dbca8c9e5446295c904315",
            "isKey": false,
            "numCitedBy": 459,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Programs and systems of recurrence equations may be represented as sets of actions which are to be executed subject to precedence constraints. In may cases, actions may be labelled by integral vectors in some iterations domains, and precedence constraints may be described by affine relations. A schedule for such a program is a function which assigns an execution data to each action. Knowledge of such a schedule allows one to estimate the intrinsic degree of parallelism of the program and to compile a parallel version for multiprocessor architectures or systolic arrays. This paper deals with the problem of finding closed form schedules as affine or piecewise affine functions of the iteration vector. An algorithm is presented which reduces the scheduling problem to a parametric linear program of small size, which can be readily solved by an efficient algorithm."
            },
            "slug": "Some-efficient-solutions-to-the-affine-scheduling-Feautrier",
            "title": {
                "fragments": [],
                "text": "Some efficient solutions to the affine scheduling problem. I. One-dimensional time"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper deals with the problem of finding closed form schedules as affine or piecewise affine functions of the iteration vector and presents an algorithm which reduces the scheduling problem to a parametric linear program of small size, which can be readily solved by an efficient algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Parallel Programming"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2222707"
                        ],
                        "name": "D. Maydan",
                        "slug": "D.-Maydan",
                        "structuredName": {
                            "firstName": "Dror",
                            "lastName": "Maydan",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Maydan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709150"
                        ],
                        "name": "Saman P. Amarasinghe",
                        "slug": "Saman-P.-Amarasinghe",
                        "structuredName": {
                            "firstName": "Saman",
                            "lastName": "Amarasinghe",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saman P. Amarasinghe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682108"
                        ],
                        "name": "M. Lam",
                        "slug": "M.-Lam",
                        "structuredName": {
                            "firstName": "Monica",
                            "lastName": "Lam",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lam"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 52
                            }
                        ],
                        "text": "(41) The main transformations include privatization (32,47,48) for dependence removal and unimodular transformations or node splitting to rearrange dependences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11827796,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "62839543df336a080d65437ac82faf409f484421",
            "isKey": false,
            "numCitedBy": 205,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Data-flow analysis of scalar variables and data dependence analysis on array elements are two important program analyses used in optimizing and parallelizing compilers. Traditional data-flow analysis models accesses of array elements simply as accesses to the entire array, and is inadequate for parallelizing loops in array-based programs. On the other hand, data dependence analysis differentiates between different array elements but is flow-insensitive.\nThis paper studies the combination of these two analyses\u2014data-flow analyses\u2014data-flow analysis of accesses to individual array elements. The problem of finding precise array dataflow information in the domain of loop nests where the loop bounds and array indices are affine functions of loop indices was first formulated by Feautrier. Feautrier's algorithm, based on parametric integer programming techniques, is general but inefficient. This paper presents an efficient algorithm that can find the same precise information for many of the programs found in practice. In this paper, we argue that data-flow analysis of individual array elements is necessary for effective automatic parallelization. In particular, we demonstrate the use of array data-flow analysis in an important optimization known as array privatization.\nBy demonstrating that array data-flow analysis can be computed efficiently and by showing the importance of the optimizations enabled by the analysis, this paper suggests that array data-flow analysis may become just as important in future optimizing and parallelizing compilers as data-flow and data dependence analysis are in today's compilers."
            },
            "slug": "Array-data-flow-analysis-and-its-use-in-array-Maydan-Amarasinghe",
            "title": {
                "fragments": [],
                "text": "Array-data flow analysis and its use in array privatization"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "It is argued that data-flow analysis of individual array elements is necessary for effective automatic parallelization and suggested that array data-flows analysis may become just as important in future optimizing and parallelizing compilers as data- flow and data dependence analysis are in today's compilers."
            },
            "venue": {
                "fragments": [],
                "text": "POPL '93"
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1838186"
                        ],
                        "name": "P. Feautrier",
                        "slug": "P.-Feautrier",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Feautrier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Feautrier"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 10
                            }
                        ],
                        "text": "Feautrier,(8) Kelly and Pugh,(10) proposed an encoding that characterizes the order of execution of each statement instance within code sections with multiple and non-perfectly nested loop nests."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 171
                            }
                        ],
                        "text": "Many academic approaches to automatic parallelization have used the polyhedral model \u2013 and partially ordered affine schedules in particular \u2013 to describe fine grain vector(8,50,51) or systolic(52,53) parallelism."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 212
                            }
                        ],
                        "text": "Our representation allows us to compose transformations without reference to a syntactic form, as opposed to previous polyhedral models where a single-step transformation captures the whole loop nest optimization(8,11) or intermediate code generation steps are needed."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 46
                            }
                        ],
                        "text": "This was best illustrated by affine scheduling(8,10) and partitioning(11) algorithms."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 148
                            }
                        ],
                        "text": "This can be used to quickly filter out or correct any violating transformation,(63) or even better, using the Farkas lemma as proposed by Feautrier,(8) to recast this implicit characterization into an explicit list of domains (of Farkas multipliers) enclosing the very values of all matrix coefficients associated with legal transformations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 66
                            }
                        ],
                        "text": "Existing formalisms have been designed for black-box optimization,(8,11,12) and applying a classical loop transformation within them \u2013 as proposed in Ref."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 23417662,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "486986fb365f072146cb9648ab408b0c567ae019",
            "isKey": true,
            "numCitedBy": 384,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper extends the algorithms which were developed in Part I to cases in which there is no affine schedule, i.e. to problems whose parallel complexity is polynomial but not linear. The natural generalization is to multidimensional schedules with lexicographic ordering as temporal succession. Multidimensional affine schedules, are, in a sense, equivalent to polynomial schedules, and are much easier to handle automatically. Furthermore, there is a strong connection between multidimensional schedules and loop nests, which allows one to prove that a static control program always has a multidimensional schedule. Roughly, a larger dimension indicates less parallelism. In the algorithm which is presented here, this dimension is computed dynamically, and is just sufficient for scheduling the source program. The algorithm lends itself to a \u201cdivide and conquer\u201d strategy. The paper gives some experimental evidence for the applicability, performances and limitations of the algorithm."
            },
            "slug": "Some-efficient-solutions-to-the-affine-scheduling-Feautrier",
            "title": {
                "fragments": [],
                "text": "Some efficient solutions to the affine scheduling problem. Part II. Multidimensional time"
            },
            "tldr": {
                "abstractSimilarityScore": 76,
                "text": "This paper extends the algorithms which were developed in Part I to cases in which there is no affine schedule, i.e. to problems whose parallel complexity is polynomial but not linear, and gives some experimental evidence for the applicability, performances and limitations of the algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Parallel Programming"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143896454"
                        ],
                        "name": "Mary W. Hall",
                        "slug": "Mary-W.-Hall",
                        "structuredName": {
                            "firstName": "Mary",
                            "lastName": "Hall",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mary W. Hall"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2158004198"
                        ],
                        "name": "Jennifer M. Anderson",
                        "slug": "Jennifer-M.-Anderson",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Anderson",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jennifer M. Anderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709150"
                        ],
                        "name": "Saman P. Amarasinghe",
                        "slug": "Saman-P.-Amarasinghe",
                        "structuredName": {
                            "firstName": "Saman",
                            "lastName": "Amarasinghe",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saman P. Amarasinghe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "119749490"
                        ],
                        "name": "Brian R. Murphy",
                        "slug": "Brian-R.-Murphy",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Murphy",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian R. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40063567"
                        ],
                        "name": "Shih-Wei Liao",
                        "slug": "Shih-Wei-Liao",
                        "structuredName": {
                            "firstName": "Shih-Wei",
                            "lastName": "Liao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Wei Liao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678618"
                        ],
                        "name": "E. Bugnion",
                        "slug": "E.-Bugnion",
                        "structuredName": {
                            "firstName": "Edouard",
                            "lastName": "Bugnion",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Bugnion"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39682108"
                        ],
                        "name": "M. Lam",
                        "slug": "M.-Lam",
                        "structuredName": {
                            "firstName": "Monica",
                            "lastName": "Lam",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "SUIF(42) is a platform for implementing advanced compiler prototypes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9539062,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "024abe25f1dc77f18672f44c1c020be3e57cc3fe",
            "isKey": false,
            "numCitedBy": 638,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "This article describes automatic parallelization techniques in the SUIF (Stanford University Intermediate Format) compiler that result in good multiprocessor performance for array-based numerical programs. Parallelizing compilers for multiprocessors face many hurdles. However, SUIF's robust analysis and memory optimization techniques enabled speedups on three fourths of the NAS and SPECfp95 benchmark programs."
            },
            "slug": "Maximizing-Multiprocessor-Performance-with-the-SUIF-Hall-Anderson",
            "title": {
                "fragments": [],
                "text": "Maximizing Multiprocessor Performance with the SUIF Compiler"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "Automatic parallelization techniques in the SUIF (Stanford University Intermediate Format) compiler that result in good multiprocessor performance for array-based numerical programs."
            },
            "venue": {
                "fragments": [],
                "text": "Digit. Tech. J."
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39742262"
                        ],
                        "name": "Shun Long",
                        "slug": "Shun-Long",
                        "structuredName": {
                            "firstName": "Shun",
                            "lastName": "Long",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shun Long"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401533251"
                        ],
                        "name": "M. O\u2019Boyle",
                        "slug": "M.-O\u2019Boyle",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "O\u2019Boyle",
                            "middleNames": [
                                "F.",
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. O\u2019Boyle"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "references do not compromise the ability to fuse the three loops, as shown in Fig. 12. Optimizers based on more advanced rewriting systems (19) and most non-syntactic representations ( 3 ,10,20) will still peel an iteration of the first and last loops."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Recently, a similar unified representation has been applied to the optimization of compute-intensive Java programs, combining machine learning and iterative optimization; ( 3 ) again, despite the unification of multiple transforma-"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Technically, the purpose of this paper is threefold: (1) to show that syntactic code representations close to the operational semantics lead to rigid phase ordering and cumbersome expression of architecture-aware loop transformations, (2) to illustrate how complex transformation sequences may be needed to achieve significant performance benefits, ( 3 ) to facilitate the automatic search for program transformation sequences, improving on ..."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1373069,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "81b14252aa6a935a20c75ff3d9a17c6f02424663",
            "isKey": true,
            "numCitedBy": 45,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a portable,machine learning-based approach to Java optimisation. This approach uses an instance-based learning scheme to select good transformations drawn from Pugh 's Unified Transformation Framework [11]. This approach was implemented and applied to a number of numerical Java benchmarks on two platforms. Using this scheme, we are able to gain over 70% of the performance improvement found when using an exhaustive iterative search of the best compiler optimisations. Thus we have a scheme that gives a high level of portable performance without any excessive compilations."
            },
            "slug": "Adaptive-java-optimisation-using-instance-based-Long-O\u2019Boyle",
            "title": {
                "fragments": [],
                "text": "Adaptive java optimisation using instance-based learning"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A portable, machine learning-based approach to Java optimisation that is able to gain over 70% of the performance improvement found when using an exhaustive iterative search of the best compiler optimisations."
            },
            "venue": {
                "fragments": [],
                "text": "ICS '04"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143986781"
                        ],
                        "name": "R. Schreiber",
                        "slug": "R.-Schreiber",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Schreiber",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schreiber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792473"
                        ],
                        "name": "S. Aditya",
                        "slug": "S.-Aditya",
                        "structuredName": {
                            "firstName": "Shail",
                            "lastName": "Aditya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Aditya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144273697"
                        ],
                        "name": "B. R. Rau",
                        "slug": "B.-R.-Rau",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Rau",
                            "middleNames": [
                                "Ramakrishna"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. R. Rau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2204447"
                        ],
                        "name": "V. Kathail",
                        "slug": "V.-Kathail",
                        "structuredName": {
                            "firstName": "Vinod",
                            "lastName": "Kathail",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Kathail"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721289"
                        ],
                        "name": "S. Mahlke",
                        "slug": "S.-Mahlke",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Mahlke",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mahlke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769800"
                        ],
                        "name": "S. Abraham",
                        "slug": "S.-Abraham",
                        "structuredName": {
                            "firstName": "Santosh",
                            "lastName": "Abraham",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Abraham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145939350"
                        ],
                        "name": "G. Snider",
                        "slug": "G.-Snider",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Snider",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Snider"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1807365,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1eba773ac66bc44c04cc5961449191eaa3023911",
            "isKey": false,
            "numCitedBy": 147,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The PICO-N system automatically synthesizes embedded nonprogrammable accelerators to be used as co-processors for functions expressed as loop nests in C. The output is synthesizable VHDL that defines the accelerator at the register transfer level (RTL). The system generates a synchronous array of customized VLIW (very-long instruction word) processors, their controller local memory, and interfaces. The system also modifies the user's application software to make use of the generated accelerator. The user indicates the throughput to be achieved by specifying the number of processors and their initiation interval. In experimental comparisons, PICO-N designs are slightly more costly than hand-designed accelerators with the same performance."
            },
            "slug": "High-level-synthesis-of-nonprogrammable-hardware-Schreiber-Aditya",
            "title": {
                "fragments": [],
                "text": "High-level synthesis of nonprogrammable hardware accelerators"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "The PICO-N system automatically synthesizes embedded nonprogrammable accelerators to be used as co-processors for functions expressed as loop nests in C to generate a synchronous array of customized VLIW processors, their controller local memory, and interfaces."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings IEEE International Conference on Application-Specific Systems, Architectures, and Processors"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3317184"
                        ],
                        "name": "R. Triolet",
                        "slug": "R.-Triolet",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Triolet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Triolet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1838186"
                        ],
                        "name": "P. Feautrier",
                        "slug": "P.-Feautrier",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Feautrier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Feautrier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2912411"
                        ],
                        "name": "F. Irigoin",
                        "slug": "F.-Irigoin",
                        "structuredName": {
                            "firstName": "Fran\u00e7ois",
                            "lastName": "Irigoin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Irigoin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206613281,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "458eafbdf8fd7e27562feb3c621b6b81febb00c5",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Scientific programs must be transformed and adapted to supercomputers to be executed efficiently. Automatic parallelization has been a very active research field for the past few years and effective restructuring compilers have been developed."
            },
            "slug": "Automatic-Parallelization-of-Fortran-Programs-in-of-Triolet-Feautrier",
            "title": {
                "fragments": [],
                "text": "Automatic Parallelization of Fortran Programs in the Presence of Procedure Calls"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "Automatic parallelization of scientific programs must be transformed and adapted to supercomputers to be executed efficiently and effective restructuring compilers have been developed."
            },
            "venue": {
                "fragments": [],
                "text": "ESOP"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "119360481"
                        ],
                        "name": "W. Blume",
                        "slug": "W.-Blume",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Blume",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Blume"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1681644"
                        ],
                        "name": "R. Doallo",
                        "slug": "R.-Doallo",
                        "structuredName": {
                            "firstName": "Ram\u00f3n",
                            "lastName": "Doallo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Doallo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727592"
                        ],
                        "name": "R. Eigenmann",
                        "slug": "R.-Eigenmann",
                        "structuredName": {
                            "firstName": "Rudolf",
                            "lastName": "Eigenmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Eigenmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065332141"
                        ],
                        "name": "John Grout",
                        "slug": "John-Grout",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Grout",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Grout"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2449782"
                        ],
                        "name": "J. Hoeflinger",
                        "slug": "J.-Hoeflinger",
                        "structuredName": {
                            "firstName": "Jay",
                            "lastName": "Hoeflinger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hoeflinger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143887565"
                        ],
                        "name": "T. Lawrence",
                        "slug": "T.-Lawrence",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Lawrence",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Lawrence"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108395388"
                        ],
                        "name": "Jaejin Lee",
                        "slug": "Jaejin-Lee",
                        "structuredName": {
                            "firstName": "Jaejin",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jaejin Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729097"
                        ],
                        "name": "D. Padua",
                        "slug": "D.-Padua",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Padua",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Padua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144619558"
                        ],
                        "name": "Y. Paek",
                        "slug": "Y.-Paek",
                        "structuredName": {
                            "firstName": "Yunheung",
                            "lastName": "Paek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Paek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1801581"
                        ],
                        "name": "W. Pottenger",
                        "slug": "W.-Pottenger",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Pottenger",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Pottenger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689939"
                        ],
                        "name": "L. Rauchwerger",
                        "slug": "L.-Rauchwerger",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Rauchwerger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Rauchwerger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3271797"
                        ],
                        "name": "P. Tu",
                        "slug": "P.-Tu",
                        "structuredName": {
                            "firstName": "Peng",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Tu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45872187,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "05a6fbd47079368bcd2dfa5f9cd74e8a176be8ad",
            "isKey": false,
            "numCitedBy": 381,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Parallel programming tools are limited, making effective parallel programming difficult and cumbersome. Compilers that translate conventional sequential programs into parallel form would liberate programmers from the complexities of explicit, machine oriented parallel programming. The paper discusses parallel programming with Polaris, an experimental translator of conventional Fortran programs that target machines such as the Cray T3D."
            },
            "slug": "Parallel-Programming-with-Polaris-Blume-Doallo",
            "title": {
                "fragments": [],
                "text": "Parallel Programming with Polaris"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Polaris, an experimental translator of conventional Fortran programs that target machines such as the Cray T3D, is discussed, which would liberate programmers from the complexities of explicit, machine oriented parallel programming."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157338354"
                        ],
                        "name": "Wei Li",
                        "slug": "Wei-Li",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1776186"
                        ],
                        "name": "K. Pingali",
                        "slug": "K.-Pingali",
                        "structuredName": {
                            "firstName": "Keshav",
                            "lastName": "Pingali",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Pingali"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 149
                            }
                        ],
                        "text": "Up to now, the easy composition of transformations was restricted to unimodular transformations(6), with some extensions to singular transformations.(15) The key to our approach is to clearly separate the four different types of actions performed by program transformations: modification of the iteration domain (loop bounds and strides), modification of the schedule of each individual statement, modification of the access functions (array subscripts), and modification of the data layout (array declarations)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5688067,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "a98fdf0ce1928599235175fcbafdf376c7f2d117",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we discuss a loop transformation framework that is based on integer non-singular matrices. The transformations included in this framework are called \u039b-transformations and include permutation, skewing and reversal, as well as a transformation calledloop scaling. This framework is more general than existing ones; however, it is also more difficult to generate code in our framework. This paper shows how integer lattice theory can be used to generate efficient code. An added advantage of our framework over existing ones is that there is a simple completion algorithm which, given a partial transformation matrix, produces a full transformation matrix that satisfies all dependences. This completion procedure has applications in parallelization and in the generation of code for NUMA machines."
            },
            "slug": "A-singular-loop-transformation-framework-based-on-Li-Pingali",
            "title": {
                "fragments": [],
                "text": "A singular loop transformation framework based on non-singular matrices"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "It is shown how integer lattice theory can be used to generate efficient code in a loop transformation framework based on integer non-singular matrices."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Parallel Programming"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144022269"
                        ],
                        "name": "W. Pugh",
                        "slug": "W.-Pugh",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Pugh",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Pugh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697800"
                        ],
                        "name": "D. Wonnacott",
                        "slug": "D.-Wonnacott",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Wonnacott",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Wonnacott"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 117
                            }
                        ],
                        "text": "6We implemented an exact one when all array accesses are affine;(59) graceful degradations exist for the general case(60,61) but are not supported yet."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9745838,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8675ea2987faea8eb995cdec19cc4d1c791a76e9",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Standard array data dependence techniques can only reason about linear constraints. There has also been work on analyzing some dependences involving polynomial constraints. Analyzing array data dependences in real-world programs requires handling many \u201cunanalyzable\u201d terms: subscript arrays, run-time tests, function calls."
            },
            "slug": "Non-Linear-Array-Dependence-Analysis-Pugh-Wonnacott",
            "title": {
                "fragments": [],
                "text": "Non-Linear Array Dependence Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "Standard array data dependence techniques can only reason about linear constraints, but there has been work on analyzing some dependences involving polynomial constraints, which requires handling many \"unanalyzable\" terms."
            },
            "venue": {
                "fragments": [],
                "text": "LCR"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733001"
                        ],
                        "name": "A. Darte",
                        "slug": "A.-Darte",
                        "structuredName": {
                            "firstName": "Alain",
                            "lastName": "Darte",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Darte"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145552986"
                        ],
                        "name": "Y. Robert",
                        "slug": "Y.-Robert",
                        "structuredName": {
                            "firstName": "Yves",
                            "lastName": "Robert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Robert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41070781"
                        ],
                        "name": "F. Vivien",
                        "slug": "F.-Vivien",
                        "structuredName": {
                            "firstName": "Fr\u00e9d\u00e9ric",
                            "lastName": "Vivien",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Vivien"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5208148,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "a3af5a000bdb8a0c6b59597e6367e8613812dce5",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 92,
            "paperAbstract": {
                "fragments": [],
                "text": "I Unidimensional Problems.- 1 Scheduling DAGs without Communications.- 2 Scheduling DAGs with Communications.- 3 Cyclic Scheduling.- II Multidimensional Problems.- 4 Systems of Uniform Recurrence Equations.- 5 Parallelism Detection in Nested Loops."
            },
            "slug": "Scheduling-and-Automatic-Parallelization-Darte-Robert",
            "title": {
                "fragments": [],
                "text": "Scheduling and Automatic Parallelization"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "Scheduling DAGs without Communications, Parallelism Detection in Nested Loops, and Systems of Uniform Recurrence Equations."
            },
            "venue": {
                "fragments": [],
                "text": "Birkh\u00e4user Boston"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145811910"
                        ],
                        "name": "U. Banerjee",
                        "slug": "U.-Banerjee",
                        "structuredName": {
                            "firstName": "Utpal",
                            "lastName": "Banerjee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Banerjee"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 160
                            }
                        ],
                        "text": "(41) The main transformations include privatization (32,47,48) for dependence removal and unimodular transformations or node splitting to rearrange dependences.(6,49)"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 117765229,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0e3046376d340ffd760d7c7f5eab3dada98a7f26",
            "isKey": false,
            "numCitedBy": 713,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "1. Introduction.- 2. Basic Concepts.- 2.1. Relations and Graphs.- 2.2. Orders on Vectors.- 2.3. Program Model.- 3. Dependence.- 3.1. Dependence Concepts.- 3.2. The Dependence Problem.- 4. Bounds of Linear Functions.- 4.1. Introduction.- 4.2. Bounds in Rectangles.- 4.3. Bounds in Trapezoids.- 5. Linear Diophantine Equations.- 5.1. Introduction.- 5.2. Greatest Common Divisors.- 5.3. Single Equation in Two Variables.- 5.4. Single Equation in Many Variables.- 5.5. Systems of Equations.- Appendix to Chapter 5.- 6. Dependence Tests.- 6.1. Introduction.- 6.2. One-Dimensional Arrays, Single Loops.- 6.3. One-Dimensional Arrays.- 6.4. General Case.- 6.5. Miscellaneous Comments.- References."
            },
            "slug": "Dependence-analysis-for-supercomputing-Banerjee",
            "title": {
                "fragments": [],
                "text": "Dependence analysis for supercomputing"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This chapter discusses one-Dimensional Arrays, Single Loops, and Dependence Tests, which are tests of the theory of Dependence on Vectors and its application to Systems of Equations."
            },
            "venue": {
                "fragments": [],
                "text": "The Kluwer international series in engineering and computer science"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718247"
                        ],
                        "name": "Denis Barthou",
                        "slug": "Denis-Barthou",
                        "structuredName": {
                            "firstName": "Denis",
                            "lastName": "Barthou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Denis Barthou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10609611"
                        ],
                        "name": "J. Collard",
                        "slug": "J.-Collard",
                        "structuredName": {
                            "firstName": "Jean-Francois",
                            "lastName": "Collard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Collard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1838186"
                        ],
                        "name": "P. Feautrier",
                        "slug": "P.-Feautrier",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Feautrier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Feautrier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 117
                            }
                        ],
                        "text": "6We implemented an exact one when all array accesses are affine;(59) graceful degradations exist for the general case(60,61) but are not supported yet."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11443424,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "ab9b504f1a0618fc4250b7c8089e23cfeaba506c",
            "isKey": false,
            "numCitedBy": 89,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Exact array dataflow analysis can be achieved in the general case if the only control structures are <italic>do</italic>-loops and structural <italic>if</italic>s, and if loop counter bounds and array subscripts are affine expressions of englobing loop counters and possibly some integer constants. In this paper, we begin the study of dataflow analysis of dynamic control programs, where arbitrary <italic>if</italic>s and <italic>while</italic>s are allowed. In the general case, this dataflow analysis can only be fuzzy."
            },
            "slug": "Fuzzy-array-dataflow-analysis-Barthou-Collard",
            "title": {
                "fragments": [],
                "text": "Fuzzy array dataflow analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper begins the study of dataflow analysis of dynamic control programs, where arbitrary <italic>if</italic]s and <italia>while</italics>s are allowed."
            },
            "venue": {
                "fragments": [],
                "text": "PPOPP '95"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3050922"
                        ],
                        "name": "Corinne Ancourt",
                        "slug": "Corinne-Ancourt",
                        "structuredName": {
                            "firstName": "Corinne",
                            "lastName": "Ancourt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Corinne Ancourt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2912411"
                        ],
                        "name": "F. Irigoin",
                        "slug": "F.-Irigoin",
                        "structuredName": {
                            "firstName": "Fran\u00e7ois",
                            "lastName": "Irigoin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Irigoin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1469859,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f4f362af709c2890db6c6f920d0b565c91b4521",
            "isKey": false,
            "numCitedBy": 376,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L\u2019archive ouverte pluridisciplinaire HAL, est destin\u00e9e au d\u00e9p\u00f4t et \u00e0 la diffusion de documents scientifiques de niveau recherche, publi\u00e9s ou non, \u00e9manant des \u00e9tablissements d\u2019enseignement et de recherche fran\u00e7ais ou \u00e9trangers, des laboratoires publics ou priv\u00e9s. Scanning polyhedra with DO loops Corinne Ancourt, Fran\u00e7ois Irigoin"
            },
            "slug": "Scanning-polyhedra-with-DO-loops-Ancourt-Irigoin",
            "title": {
                "fragments": [],
                "text": "Scanning polyhedra with DO loops"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "HAL is a multi-disciplinary open access archive for the deposit and dissemination of scientific research documents, whether they are published or not, for teaching and research institutions in France or abroad, or from public or private research centers."
            },
            "venue": {
                "fragments": [],
                "text": "PPOPP '91"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "Advanced example B[1] = 0 for (i=0; i<99; i++) A[i] = A[1] ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 1
                            }
                        ],
                        "text": "B[1] = 0 for (i=0; i<99; i++) A[i] = A[1] ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 25
                            }
                        ],
                        "text": "Dead code before fusion B[1] = 0 for (i=0; i<99; i++) a = ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 1
                            }
                        ],
                        "text": "B[1] = 0 for (i=0; i<99; i++) A[i] = ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 27
                            }
                        ],
                        "text": "Fusion of the three loops B[1] = 0 for (i=0; i<99; i++) A[i] = ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 1
                            }
                        ],
                        "text": "B[1] = 0 for (i=0; i<100; i++) A A[i] = ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 1
                            }
                        ],
                        "text": "B[1] = 0 for (i=0; i<100; i++) A A[i] = A[1] ."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "It  erative compilation in program optimization,Proc. CPC\u201910 (Compilers for Parallel Computers"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145597416"
                        ],
                        "name": "W. Kelly",
                        "slug": "W.-Kelly",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Kelly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Kelly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144022269"
                        ],
                        "name": "W. Pugh",
                        "slug": "W.-Pugh",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Pugh",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Pugh"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 29
                            }
                        ],
                        "text": "Feautrier,(8) Kelly and Pugh,(10) proposed an encoding that characterizes the order of execution of each statement instance within code sections with multiple and non-perfectly nested loop nests."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 94
                            }
                        ],
                        "text": "Optimizers based on more advanced rewriting systems(19) and most non-syntactic representations(3,10,20) will still peel an iteration of the first and last loops."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 129
                            }
                        ],
                        "text": "Compared to the attempts at expressing a large array of program transformations as matrix operations within the polyhedral model,(9,10,14) the distinctive asset of our representation lies in the simplicity of the formalism to compose non-unimodular transformations across long, flexible sequences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 46
                            }
                        ],
                        "text": "This was best illustrated by affine scheduling(8,10) and partitioning(11) algorithms."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 134
                            }
                        ],
                        "text": "To date, the most thorough application of the polyhedral representation was the Petit dependence analyzer and loop restructuring tool,(10) based on the Omega library."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 274,
                                "start": 268
                            }
                        ],
                        "text": "Our representation allows us to compose transformations without reference to a syntactic form, as opposed to previous polyhedral models where a single-step transformation captures the whole loop nest optimization(8,11) or intermediate code generation steps are needed.(9,10) Let us better illustrate the advantage of expressing loop transformations as \u201csyntax-free\u201d function compositions, considering again the example in Fig."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 60616277,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af3bbe9483ba31b68d50b91878405358101f0e50",
            "isKey": true,
            "numCitedBy": 50,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Optimization-within-a-unified-transformation-Kelly-Pugh",
            "title": {
                "fragments": [],
                "text": "Optimization within a unified transformation framework"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37440949"
                        ],
                        "name": "G. Perrin",
                        "slug": "G.-Perrin",
                        "structuredName": {
                            "firstName": "Guy-Ren\u00e9",
                            "lastName": "Perrin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Perrin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733001"
                        ],
                        "name": "A. Darte",
                        "slug": "A.-Darte",
                        "structuredName": {
                            "firstName": "Alain",
                            "lastName": "Darte",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Darte"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 63234067,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "17712680efcebd69e144c161e2ec2dba0a70edf6",
            "isKey": false,
            "numCitedBy": 46,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Data-Parallel-Programming-Model-Perrin-Darte",
            "title": {
                "fragments": [],
                "text": "The Data Parallel Programming Model"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060929010"
                        ],
                        "name": "Klaus H. Ecker",
                        "slug": "Klaus-H.-Ecker",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Ecker",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Klaus H. Ecker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 111
                            }
                        ],
                        "text": "Affine schedules have also been applied to the extraction and characterization of bulk-synchronous parallelism.(11,13,36) Array expansion is a generalization of privatization that leverages on the precision of array dependence analysis in the polyhedral model(33,54,55)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 344,
                                "start": 340
                            }
                        ],
                        "text": "First of all, parallel affine schedules are not the only way to express parallelism (in fact, they are mostly practical to describe bulk-synchronous parallelism), and in case they would be used to specify a partial ordering of statement instances, it is always possible to extend the schedule with \u201cspatial\u201d dimensions to make A invertible.(36) Schedule density."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62214684,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f8d61f343757c5f7a6293721ed4ad048dbe062b5",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Scheduling-and-Automatic-Parallelization.-Alain-and-Ecker",
            "title": {
                "fragments": [],
                "text": "Scheduling and Automatic Parallelization. Alain Darte, Yves Robert and Fr\u00e9d\u00e9ric Vivien, Birkh\u00e4user, New York, ISBN 0-8176-4149-1"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793602"
                        ],
                        "name": "P. Knijnenburg",
                        "slug": "P.-Knijnenburg",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Knijnenburg",
                            "middleNames": [
                                "M.",
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Knijnenburg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2802912"
                        ],
                        "name": "T. Kisuki",
                        "slug": "T.-Kisuki",
                        "structuredName": {
                            "firstName": "Toru",
                            "lastName": "Kisuki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Kisuki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686222"
                        ],
                        "name": "K. Gallivan",
                        "slug": "K.-Gallivan",
                        "structuredName": {
                            "firstName": "Kyle",
                            "lastName": "Gallivan",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Gallivan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 38818380,
            "fieldsOfStudy": [
                "Computer Science",
                "Economics"
            ],
            "id": "0487dd8f7732c10d1d0c6e04a965d18790da8e8e",
            "isKey": false,
            "numCitedBy": 7,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In iterative compilation we search for the best program transformations by profiling many variants and selecting the one with the shortest execution time. Since this approach is extremely time consuming, we discuss in this paper how to incorporate static models. We show that a highly accurate model as a filter to profiling can reduce the number of executions by 50%. We also show that using a simple model to rank transformations and profiling only those with highest ranking can reduce the number of executions even further, in case we have a limited number of profiles at our disposal. We conclude that a production compiler might perform best using the last approach."
            },
            "slug": "Cache-Models-for-Iterative-Compilation-Knijnenburg-Kisuki",
            "title": {
                "fragments": [],
                "text": "Cache Models for Iterative Compilation"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that a highly accurate model as a filter to profiling can reduce the number of executions by 50% and that using a simple model to rank transformations and profiling only those with highest ranking can reduce that number even further."
            },
            "venue": {
                "fragments": [],
                "text": "Euro-Par"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "MARS: a Distributed Memory Approach to Share  d Memory Compilation, Proc. Language, Compilers and Runtime Systems for Scalable"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Scanning Polyhedra with DO Loop, ACM Symp. on Principles and Practice of Parallel Programming (PPoPP'91)"
            },
            "venue": {
                "fragments": [],
                "text": "Scanning Polyhedra with DO Loop, ACM Symp. on Principles and Practice of Parallel Programming (PPoPP'91)"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Code Generation in the Polyhedral Model Is Ea  sier Than You Think,Parallel Architectures and Compilation Techniques"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximizing application performance through interprocedural optimization with the PathScale EKO compiler suite"
            },
            "venue": {
                "fragments": [],
                "text": "Maximizing application performance through interprocedural optimization with the PathScale EKO compiler suite"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fuzzy array  d taflow analysis,  ACM Symp. on Principles and Practice of Parallel Programming"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 52
                            }
                        ],
                        "text": "(41) The main transformations include privatization (32,47,48) for dependence removal and unimodular transformations or node splitting to rearrange dependences."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic Array Privatization, 6th Workshop on Languages and Compilers for Parallel Computing, number"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Program Analysis and Transformation: from the Polytope Model to Formal Languages, PhD Thesis, Universit\u00e9 de Versailles, France"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1999
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Standard Performance Evaluation Corp"
            },
            "venue": {
                "fragments": [],
                "text": "Standard Performance Evaluation Corp"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Verdun, On Increasing Arch ite ture Awareness in Pro- gram Optimizations to Bridge the Gap between Peak and Sustai ned Processor Performance? Matrix-Multiply Revisited,SuperComputing\u201902"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Unified Transformation Framework"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report CS- TR-3725,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Performance Compilers for Parallel Computing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximal Static E  xpansion,Intl"
            },
            "venue": {
                "fragments": [],
                "text": "J. of Parallel Programming,"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Open Research Compiler, http://ipf-orc.sourceforge.net"
            },
            "venue": {
                "fragments": [],
                "text": "Open Research Compiler, http://ipf-orc.sourceforge.net"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Language for Program Transformation based on Rewriting Strategies. System Description of Stratego 0"
            },
            "venue": {
                "fragments": [],
                "text": "Rewriting Techniques and Applications (RTA'01)"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Analysis for Supercomputing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Polyhedral Approach t  o Ease the Composition of Program Transformations,  Euro-Par\u201904"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 192
                            }
                        ],
                        "text": "Many academic approaches to automatic parallelization have used the polyhedral model \u2013 and partially ordered affine schedules in particular \u2013 to describe fine grain vector(8,50,51) or systolic(52,53) parallelism."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Hardware Design Methodology with the Alpha Language, FDL\u201901"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Polyhedral Code G  eneration in the Real World, Proceedings of the International Conference on Compiler Co  nstruction (ETAPS CC\u201906"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic Storage Managem  ent for Parallel Programs"
            },
            "venue": {
                "fragments": [],
                "text": "Paral- lel Computing,"
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Improving data locality by chunking, CC Intl. Conf. on Compiler Construction, number 2622 in LNCS"
            },
            "venue": {
                "fragments": [],
                "text": "Improving data locality by chunking, CC Intl. Conf. on Compiler Construction, number 2622 in LNCS"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "More Legal Transformations  f r Locality, Euro-Par\u201910"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic Array Privatization, 6 th Workshop on Languages and Compilers for Parallel Computing, number 768 in LNCS"
            },
            "venue": {
                "fragments": [],
                "text": "Automatic Array Privatization, 6 th Workshop on Languages and Compilers for Parallel Computing, number 768 in LNCS"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "More Legal Transformations for Locality, Euro-Par'10, number 3149 in LNCS"
            },
            "venue": {
                "fragments": [],
                "text": "More Legal Transformations for Locality, Euro-Par'10, number 3149 in LNCS"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Array Datafl ow Analysis and its Use in Array Privatization,20thACM Symp. on Principles of Programming Languages"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automating non-unimodular loop transformation  s for massive parallelism,  Parallel Computing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 109
                            }
                        ],
                        "text": "The whole infrastructure is implemented as a free (GPL) add-on to the Open64/ORC/EKOPath family of compilers.(16,66) Optimization is performed in two runs of the compiler, with one intermediate run of our tool, using intermediate dumps of the intermediate representation (the ."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "4 and is compatible with PathScale EKOPath(66) native code generator for AMD64 and IA32."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximizing Application Performance Through Interprocedural Optimization with the PathScale EKO compiler suite, http://www.pathscale.com/whitepapers.html"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic Array Privatization, 6thWorkshop on Languages and Compilers for Parallel Computing, number"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Semi-Automatic Composition of Loop Transformations 57"
            },
            "venue": {
                "fragments": [],
                "text": "Semi-Automatic Composition of Loop Transformations 57"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wonnacott,  Constraint-Based Array Dependence Analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Ph.D. thesis, University of Maryland"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic I  ntra-Register Vectorization for the Intel Architecture,  Intl"
            },
            "venue": {
                "fragments": [],
                "text": "J. of Parallel Programming"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic parallelization of While-Loo  ps using speculative execution,  I tl"
            },
            "venue": {
                "fragments": [],
                "text": "J. of Parallel Programming,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Code generation for multiple mappings, Frontiers'95 Symp. on the frontiers of massively parallel computation"
            },
            "venue": {
                "fragments": [],
                "text": "Code generation for multiple mappings, Frontiers'95 Symp. on the frontiers of massively parallel computation"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fuzzy Array  Dataflow Analysis,J. of Parallel and Distributed Computing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Array Region Analyses and Applications, Ph.D"
            },
            "venue": {
                "fragments": [],
                "text": "thesis, E\u0301cole Nationale Supe\u0301rieure des Mines de Paris (ENSMP), France (December"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Semi-Automatic Composition of Loop Transformations 55"
            },
            "venue": {
                "fragments": [],
                "text": "Semi-Automatic Composition of Loop Transformations 55"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Generation of e  ffici nt nested loops from polyhedra,Intl"
            },
            "venue": {
                "fragments": [],
                "text": "J. of Parallel Programming"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Omega test: a fast and practical integer prog ramming algorithm for de- pendence analysis,  ACM/IEEE Conf. on Supercomputing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Vivien,  Scheduling and Automatic Parallelization"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximizing application performance through in  terprocedural optimization with the PathScale EKO compiler suite,  http://www.pathscale.com/whitepapers.html"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Schedu  le-Independant Storage Mapping for Loops,ACM Symp. on Architectural Support for Programming Languag es and Operating Systems"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Efficient code generation for automatic para  llelization and optimization,ISPDC\u20192"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE International Symposium on Parallel and Distrib  uted Computing"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximizing Multiprocessor Performance w  ith the SUIF Compiler,IEEE"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Maximal Static Expansion, Intl. J. of Parallel Programming"
            },
            "venue": {
                "fragments": [],
                "text": "Maximal Static Expansion, Intl. J. of Parallel Programming"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automatic parallelization of While-Loops using speculative execution, Intl"
            },
            "venue": {
                "fragments": [],
                "text": "J. of Parallel Programming,"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Code generation for mult iple mappings,Frontiers\u201995 Symp. on the frontiers of massively parallel computation"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Open-source Compiler Technology for Source-to-Source Optimization"
            },
            "venue": {
                "fragments": [],
                "text": "Open-source Compiler Technology for Source-to-Source Optimization"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Nonlinear array dependence ana lysis, Proc. Third Workshop on Languages, Compilers and Run-Time Systems for Scalable C"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Data Parallel Programming Model, number 1132 in LNCS"
            },
            "venue": {
                "fragments": [],
                "text": "The Data Parallel Programming Model, number 1132 in LNCS"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Communication-Free Parallelizat ion via Affine Transformations, 24thACM Symp. on Principles of Programming Languages"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The ParaScope Parallel Program  ming Environment"
            },
            "venue": {
                "fragments": [],
                "text": "Proceed- ings of the IEEE,"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dataflow Analysis of Scalar and Array Refer  ences,Intl"
            },
            "venue": {
                "fragments": [],
                "text": "J. of Parallel Program- ming,"
            },
            "year": 1991
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 165
                            }
                        ],
                        "text": "In the polyhedral model, it is possible to refine this definition further and to compute an exact dependence information, as soon as all array references are affine.(59) Exact dependences are classically captured by a system of affine inequalities over iteration vectors; when considering a syntactic loop nest, dependences at depth p between access functions F and F in statements S and T are exactly captured by the following union of polyhedra:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "6We implemented an exact one when all array accesses are affine;(59) graceful degradations exist for the general case(60,61) but are not supported yet."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dataflow Analysis of Scalar and Array References"
            },
            "venue": {
                "fragments": [],
                "text": "Intl. J. Parallel Program,"
            },
            "year": 1991
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 34,
            "methodology": 22
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 123,
        "totalPages": 13
    },
    "page_url": "https://www.semanticscholar.org/paper/Semi-Automatic-Composition-of-Loop-Transformations-Girbal-Vasilache/cc1c1b1eb6e9672d1b2813ad763f701494d8fcee?sort=total-citations"
}