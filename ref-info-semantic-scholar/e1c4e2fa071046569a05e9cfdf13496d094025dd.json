{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256269"
                        ],
                        "name": "C. Farabet",
                        "slug": "C.-Farabet",
                        "structuredName": {
                            "firstName": "Cl\u00e9ment",
                            "lastName": "Farabet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Farabet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35130633"
                        ],
                        "name": "Cyril Poulet",
                        "slug": "Cyril-Poulet",
                        "structuredName": {
                            "firstName": "Cyril",
                            "lastName": "Poulet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cyril Poulet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2183554"
                        ],
                        "name": "Jefferson Y. Han",
                        "slug": "Jefferson-Y.-Han",
                        "structuredName": {
                            "firstName": "Jefferson",
                            "lastName": "Han",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jefferson Y. Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 567,
                                "start": 561
                            }
                        ],
                        "text": "We also compared the performance of our dynamically configurable CNN coprocessor (20 convolvers, 128-bit memory port width) with leading CNN workload implementations reported\nrecently on several platforms: (a) 128-core, 1.35GHz NVIDIA\u2019s GPU with 1.5GB RAM, and a fast PCI Express connection to the x86 host [26] (b) an internal software implementation on an dualsocket, quad-core, 2.33 GHz Intel Xeon (Intel Multicore with eight 2.33 GHz cores), and (c) a 200 MHz, fixed architecture CNN co-processor called CNP that was implemented on a Virtex 4 FPGA part from Xilinx [9]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 70
                            }
                        ],
                        "text": "Results for the 200 MHz CNP (column \u201cCNP\u201d in Table 3) were taken from [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 138
                            }
                        ],
                        "text": "33 GHz cores), and (c) a 200 MHz, fixed architecture CNN co-processor called CNP that was implemented on a Virtex 4 FPGA part from Xilinx [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "In [9], no attempt is made to alter the hardware computing paths to match type or extent of parallelism in the workload."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 113
                            }
                        ],
                        "text": "Due to clock frequencies in the GHz range, the GPU and the Intel Multicore implementations consume more than 150 Watts."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 53
                            }
                        ],
                        "text": "The 200 MHz Virtex4 implementation consumes 15 Watts [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 163,
                                "start": 157
                            }
                        ],
                        "text": "This architecture uses one hardware convolver for data processing, and a general-purpose soft-processor for control, all implemented on a Virtex 4 FPGA from Xilinx."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 52
                            }
                        ],
                        "text": "The \u201cMobile Robot Vision\u201d workload is obtained from [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 52
                            }
                        ],
                        "text": "An FPGA implementation of CNN was reported recently [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5339694,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "07956c7cf9bf4267b86d52aa4143c17a4aa5d0d6",
            "isKey": true,
            "numCitedBy": 328,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional Networks (ConvNets) are biologicallyinspired hierarchical architectures that can be trained to perform a variety of detection, recognition and segmentation tasks. ConvNets have a feed-forward architecture consisting of multiple linear convolution filters interspersed with pointwise non-linear squashing functions. This paper presents an efficient implementation of ConvNets on a low-end DSPoriented Field Programmable Gate Array (FPGA). The implementation exploits the inherent parallelism of ConvNets and takes full advantage of multiple hardware multiplyaccumulate units on the FPGA. The entire system uses a single FPGA with an external memory module, and no extra parts. A network compiler software was implemented, which takes a description of a trained ConvNet and compiles it into a sequence of instructions for the ConvNet Processor (CNP). A ConvNet face detection system was implemented and tested. Face detection on a 512 \u00d7 384 frame takes 100ms (10 frames per second), which corresponds to an average performance of 3.4\u00d7109 connections per second for this 340 million connection network. The design can be used for low-power, lightweight embedded vision systems for micro-UAVs and other small robots."
            },
            "slug": "CNP:-An-FPGA-based-processor-for-Convolutional-Farabet-Poulet",
            "title": {
                "fragments": [],
                "text": "CNP: An FPGA-based processor for Convolutional Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The implementation exploits the inherent parallelism of ConvNets and takes full advantage of multiple hardware multiplyaccumulate units on the FPGA and can be used for low-power, lightweight embedded vision systems for micro-UAVs and other small robots."
            },
            "venue": {
                "fragments": [],
                "text": "2009 International Conference on Field Programmable Logic and Applications"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2091832248"
                        ],
                        "name": "O. Nomura",
                        "slug": "O.-Nomura",
                        "structuredName": {
                            "firstName": "Osamu",
                            "lastName": "Nomura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Nomura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729515"
                        ],
                        "name": "T. Morie",
                        "slug": "T.-Morie",
                        "structuredName": {
                            "firstName": "Takashi",
                            "lastName": "Morie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Morie"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": "LSI architectures using a mixed analog-digital approach [20] as well as several FPGA-based implementations have also been proposed [3][4][5][6][7][19][24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 117
                            }
                        ],
                        "text": "Feed-forward, multi-layer artificial neural networks like the Convolutional Neural Networks (CNN) [2][11][13][16][17][20][23] have found increasing use in several new applications because they have the potential to process vast amounts of labeled data to automatically learn and extract complex features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 39364538,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "212b95d8fbc90086075cf804449abba2902d4813",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The hierarchical convolutional neural network models are considered promising for robust object detection/recognition. These models require huge computational power for performing a large number of multiply-and-accumulation (MAC) operations. In this paper, first we discuss efficient calculation schemes suitable for 2D MAC operations. Then we review the related algorithms and LSI architecture proposed in our previous work, in which we use a projection-field-type network architecture with sorting of neuron outputs by magnitude. For the LSI implementation, we adopt a merged/mixed analog-digital circuit approach using a large number of analog or pulse modulation circuits. We demonstrate the validity of our LSI architecture by testing proof-of-concept LSIs. It is essential to develop efficient and parallel A/D and D/A conversion circuits in order to connect a lot of on-chip analog circuits with the external digital system. In this paper, we also propose such an A/D conversion circuit scheme."
            },
            "slug": "Projection-Field-Type-VLSI-Convolutional-Neural-Nomura-Morie",
            "title": {
                "fragments": [],
                "text": "Projection-Field-Type VLSI Convolutional Neural Networks Using Merged/Mixed Analog-Digital Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is essential to develop efficient and parallel A/D and D/A conversion circuits in order to connect a lot of on-chip analog circuits with the external digital system, and this paper proposes such an A/ D conversion circuit scheme."
            },
            "venue": {
                "fragments": [],
                "text": "ICONIP"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145840115"
                        ],
                        "name": "S. Lawrence",
                        "slug": "S.-Lawrence",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Lawrence",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lawrence"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145157784"
                        ],
                        "name": "C. Lee Giles",
                        "slug": "C.-Lee-Giles",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Giles",
                            "middleNames": [
                                "Lee"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lee Giles"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733691"
                        ],
                        "name": "A. Tsoi",
                        "slug": "A.-Tsoi",
                        "structuredName": {
                            "firstName": "Ah",
                            "lastName": "Tsoi",
                            "middleNames": [
                                "Chung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tsoi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144288586"
                        ],
                        "name": "A. Back",
                        "slug": "A.-Back",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Back",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Back"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 47
                            }
                        ],
                        "text": "The \u201cFace Detection\u201d workload is obtained from [25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 104
                            }
                        ],
                        "text": "There are no reported LSI implementations of CNNs but several software implementations on GPUs exist [8][25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2883848,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "86890c82b589e24007c56e1f40c5f928a0e04183",
            "isKey": false,
            "numCitedBy": 2734,
            "numCiting": 108,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a hybrid neural-network for human face recognition which compares favourably with other methods. The system combines local image sampling, a self-organizing map (SOM) neural network, and a convolutional neural network. The SOM provides a quantization of the image samples into a topological space where inputs that are nearby in the original space are also nearby in the output space, thereby providing dimensionality reduction and invariance to minor changes in the image sample, and the convolutional neural network provides partial invariance to translation, rotation, scale, and deformation. The convolutional network extracts successively larger features in a hierarchical set of layers. We present results using the Karhunen-Loeve transform in place of the SOM, and a multilayer perceptron (MLP) in place of the convolutional network for comparison. We use a database of 400 images of 40 individuals which contains quite a high degree of variability in expression, pose, and facial details. We analyze the computational complexity and discuss how new classes could be added to the trained recognizer."
            },
            "slug": "Face-recognition:-a-convolutional-neural-network-Lawrence-Giles",
            "title": {
                "fragments": [],
                "text": "Face recognition: a convolutional neural-network approach"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A hybrid neural-network for human face recognition which compares favourably with other methods and analyzes the computational complexity and discusses how new classes could be added to the trained recognizer."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Neural Networks"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 229,
                                "start": 226
                            }
                        ],
                        "text": "If we represent the 25 distinct weights as a 5 x 5 matrix (also called as the kernel matrix), then outputs of all the 784 hidden units can be computed as the convolution of the 32 x 32 input image with the 5 x 5 kernel matrix [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": false,
            "numCitedBy": 35624,
            "numCiting": 246,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2906871"
                        ],
                        "name": "A. Omondi",
                        "slug": "A.-Omondi",
                        "structuredName": {
                            "firstName": "Amos",
                            "lastName": "Omondi",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Omondi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3906447"
                        ],
                        "name": "J. Rajapakse",
                        "slug": "J.-Rajapakse",
                        "structuredName": {
                            "firstName": "Jagath",
                            "lastName": "Rajapakse",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Rajapakse"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5115595,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ba80210a6cc79855f757d5bcf7a4594a98aa8341",
            "isKey": false,
            "numCitedBy": 270,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "The development of neural networks has now reached the stage where they are employed in a large variety of practical contexts. However, to date the majority of such implementations have been in software. While it is generally recognised that hardware implementations could, through performance advantages, greatly increase the use of neural networks, to date the relatively high cost of developing Application-Specific Integrated Circuits (ASICs) has meant that only a small number of hardware neurocomputers has gone beyond the research-prototype stage. The situation has now changed dramatically: with the appearance of large, dense, highly parallel FPGA circuits it has now become possible to envisage putting large-scale neural networks in hardware, to get high performance at low costs. This in turn makes it practical to develop hardware neural-computing devices for a wide range of applications, ranging from embedded devices in high-volume/low-cost consumer electronics to large-scale stand-alone neurocomputers. Not surprisingly, therefore, research in the area has recently rapidly increased, and even sharper growth can be expected in the next decade or so. Nevertheless, the many opportunities offered by FPGAs also come with many challenges, since most of the existing body of knowledge is based on ASICs (which are not as constrained as FPGAs). These challenges range from the choice of data representation, to the implementation of specialized functions, through to the realization of massively parallel neural networks; and accompanying these are important secondary issues, such as development tools and technology transfer. All these issues are currently being investigated by a large number of researchers, who start from different bases and proceed by different methods, in such a way that there is no systematic core knowledge to start from, evaluate alternatives, validate claims, and so forth. FPGA Implementations of Neural Networks aims to be a timely one that fill this gap in three ways: First, it will contain appropriate foundational material and therefore be appropriate for advanced students or researchers new to the field. Second, it will capture the state of the art, in both depth and breadth and therefore be useful researchers currently active in the field. Third, it will cover directions for future research, i.e. embryonic areas as well as more speculative ones."
            },
            "slug": "FPGA-Implementations-of-Neural-Networks-Omondi-Rajapakse",
            "title": {
                "fragments": [],
                "text": "FPGA Implementations of Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "FPGA Implementations of Neural Networks aims to be a timely one that fill this gap in three ways: first, it will contain appropriate foundational material and therefore be appropriate for advanced students or researchers new to the field, and secondly will capture the state of the art, in both depth and breadth andTherefore be useful researchers currently active in the field."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1836897"
                        ],
                        "name": "K. Korekado",
                        "slug": "K.-Korekado",
                        "structuredName": {
                            "firstName": "Keisuke",
                            "lastName": "Korekado",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Korekado"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729515"
                        ],
                        "name": "T. Morie",
                        "slug": "T.-Morie",
                        "structuredName": {
                            "firstName": "Takashi",
                            "lastName": "Morie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Morie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2091832248"
                        ],
                        "name": "O. Nomura",
                        "slug": "O.-Nomura",
                        "structuredName": {
                            "firstName": "Osamu",
                            "lastName": "Nomura",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Nomura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114915700"
                        ],
                        "name": "T. Nakano",
                        "slug": "T.-Nakano",
                        "structuredName": {
                            "firstName": "Teppei",
                            "lastName": "Nakano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Nakano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3241082"
                        ],
                        "name": "M. Matsugu",
                        "slug": "M.-Matsugu",
                        "structuredName": {
                            "firstName": "Masakazu",
                            "lastName": "Matsugu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Matsugu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47699439"
                        ],
                        "name": "A. Iwata",
                        "slug": "A.-Iwata",
                        "structuredName": {
                            "firstName": "Atsushi",
                            "lastName": "Iwata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Iwata"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Feed-forward, multi-layer artificial neural networks like the Convolutional Neural Networks (CNN) [2] [11] [ 13 ] [16] [17] [20] [23] have found increasing use in several new applications because they have the potential to process vast amounts of labeled data to automatically learn and extract complex features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 23489399,
            "fieldsOfStudy": [
                "Engineering",
                "Computer Science"
            ],
            "id": "88d82e50ed2317952783fabc57f788efed96e7ce",
            "isKey": false,
            "numCitedBy": 14,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes an image-filtering processor LSI based on a hybrid approach using pulse-width modulation (PWM) and digital circuits. The LSI has been designed for implementing convolutional neural networks with a very large convolution-kernel size. The LSI designed using a 0.35 /spl mu/m CMOS performs 6-bit precision convolutions for an image of 80/spl times/80 pixels with a kernel size of up to 51/spl times/51 pixels within 8.2 ms. All operations for the fabricated LSI have been successfully verified. The power consumption estimated from SPICE simulation is 280 mW."
            },
            "slug": "An-image-filtering-processor-for-face/object-using-Korekado-Morie",
            "title": {
                "fragments": [],
                "text": "An image filtering processor for face/object recognition using merged/mixed analog-digital architecture"
            },
            "tldr": {
                "abstractSimilarityScore": 89,
                "text": "This paper proposes an image-filtering processor LSI based on a hybrid approach using pulse-width modulation (PWM) and digital circuits for implementing convolutional neural networks with a very large convolution-kernel size."
            },
            "venue": {
                "fragments": [],
                "text": "Digest of Technical Papers. 2005 Symposium on VLSI Circuits, 2005."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2557686"
                        ],
                        "name": "Fabian Nasse",
                        "slug": "Fabian-Nasse",
                        "structuredName": {
                            "firstName": "Fabian",
                            "lastName": "Nasse",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fabian Nasse"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2020614"
                        ],
                        "name": "Christian Thurau",
                        "slug": "Christian-Thurau",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Thurau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Thurau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749475"
                        ],
                        "name": "G. Fink",
                        "slug": "G.-Fink",
                        "structuredName": {
                            "firstName": "Gernot",
                            "lastName": "Fink",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Fink"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1067914,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "61e5522564e9563181c4016a212fee0561794759",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we consider the problem of face detection under pose variations. Unlike other contributions, a focus of this work resides within efficient implementation utilizing the computational powers of modern graphics cards. The proposed system consists of a parallelized implementation of convolutional neural networks (CNNs) with a special emphasize on also parallelizing the detection process. Experimental validation in a smart conference room with 4 active ceiling-mounted cameras shows a dramatic speed-gain under real-life conditions."
            },
            "slug": "Face-Detection-Using-GPU-Based-Convolutional-Neural-Nasse-Thurau",
            "title": {
                "fragments": [],
                "text": "Face Detection Using GPU-Based Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The proposed system consists of a parallelized implementation of convolutional neural networks with a special emphasize on also parallelizing the detection process, which shows a dramatic speed-gain under real-life conditions."
            },
            "venue": {
                "fragments": [],
                "text": "CAIP"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399230800"
                        ],
                        "name": "Francisco Cardells-Tormo",
                        "slug": "Francisco-Cardells-Tormo",
                        "structuredName": {
                            "firstName": "Francisco",
                            "lastName": "Cardells-Tormo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Francisco Cardells-Tormo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144762975"
                        ],
                        "name": "Pep-Lluis Molinet",
                        "slug": "Pep-Lluis-Molinet",
                        "structuredName": {
                            "firstName": "Pep-Lluis",
                            "lastName": "Molinet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pep-Lluis Molinet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2163636855"
                        ],
                        "name": "Jordi Sempere-Agull\u00f3",
                        "slug": "Jordi-Sempere-Agull\u00f3",
                        "structuredName": {
                            "firstName": "Jordi",
                            "lastName": "Sempere-Agull\u00f3",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jordi Sempere-Agull\u00f3"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2790381"
                        ],
                        "name": "L. Baldez",
                        "slug": "L.-Baldez",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Baldez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baldez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2163637166"
                        ],
                        "name": "Marc Bautista-Palacios",
                        "slug": "Marc-Bautista-Palacios",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Bautista-Palacios",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc Bautista-Palacios"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 134
                            }
                        ],
                        "text": "LSI architectures using a mixed analog-digital approach [20] as well as several FPGA-based implementations have also been proposed [3][4][5][6][7][19][24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 38413211,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "636330354a3d234dca8770bc781eb684170beb87",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "Two-dimensional convolutions are local by nature; hence every pixel in the output image is computed using surrounding information, i.e., a moving window of pixels. Although the operation is simple, the hardware is conditioned by the fact that due to bandwidth efficiency full raster rows must be read from the external memory, and that a row-major image scan should be performed to support shift-variant convolutions. When extending the architectures developed in prior-art to support shift-variant convolutions, we realize that they require large amounts of on-chip memory. While this fact may not have a large cost increase in ASIC implementations, it makes field-programmable gate arrays (FPGA) implementations expensive or not feasible. In this paper, we propose several novel FPGA-efficient architectures for generating a moving window over a row-wise print path. Because the proposed concepts have different throughput and resource utilization, we provide a criteria to choose the optimum one for any design point."
            },
            "slug": "Area-efficient-2-D-shift-variant-convolvers-for-Cardells-Tormo-Molinet",
            "title": {
                "fragments": [],
                "text": "Area-efficient 2-D shift-variant convolvers for FPGA-based digital image processing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes several novel FPGA-efficient architectures for generating a moving window over a row-wise print path and provides a criteria to choose the optimum one for any design point."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Circuits and Systems II: Express Briefs"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3212659"
                        ],
                        "name": "K. Benkrid",
                        "slug": "K.-Benkrid",
                        "structuredName": {
                            "firstName": "Khaled",
                            "lastName": "Benkrid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Benkrid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3385606"
                        ],
                        "name": "S. Belkacemi",
                        "slug": "S.-Belkacemi",
                        "structuredName": {
                            "firstName": "Samir",
                            "lastName": "Belkacemi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Belkacemi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 131
                            }
                        ],
                        "text": "LSI architectures using a mixed analog-digital approach [20] as well as several FPGA-based implementations have also been proposed [3][4][5][6][7][19][24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 20933056,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "50457707fc63eabb76689fdff5e225c47b865f9f",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We present the design and implementation of a 2D convolution core for video applications optimised for the Xilinx low cost 3.3V SpartanXL/spl trade/ FPGA family. The core is parameterised and scaleable in terms of the convolution window size and coefficients, the input pixel word length and the image size. The window coefficients are represented as sum/subtract of power of twos in canonical signed digit (CSD) representation, which means that the usually costly multiplication operation can be easily implemented by a small number of simple shift-and-add operations, leading to considerable hardware savings. Optimised FPGA configurations capable of processing real-time PAL video are automatically generated from high-level descriptions of generic 2D convolutions, in the form of EDIF netlists, in less than 1 sec."
            },
            "slug": "Design-and-implementation-of-a-2D-convolution-core-Benkrid-Belkacemi",
            "title": {
                "fragments": [],
                "text": "Design and implementation of a 2D convolution core for video applications on FPGAs"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The design and implementation of a 2D convolution core for video applications optimised for the Xilinx low cost 3.3V SpartanXL/spl trade/ FPGA family is presented, which means that the usually costly multiplication operation can be easily implemented by a small number of simple shift-and-add operations, leading to considerable hardware savings."
            },
            "venue": {
                "fragments": [],
                "text": "Third International Workshop on Digital and Computational Video, 2002. DCV 2002. Proceedings."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39176658"
                        ],
                        "name": "R. G. Giron\u00e9s",
                        "slug": "R.-G.-Giron\u00e9s",
                        "structuredName": {
                            "firstName": "Rafael",
                            "lastName": "Giron\u00e9s",
                            "middleNames": [
                                "Gadea"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. G. Giron\u00e9s"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1402076260"
                        ],
                        "name": "R. Colom-Palero",
                        "slug": "R.-Colom-Palero",
                        "structuredName": {
                            "firstName": "Ricardo",
                            "lastName": "Colom-Palero",
                            "middleNames": [
                                "Jos\u00e9"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Colom-Palero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403952930"
                        ],
                        "name": "Joaqu\u00edn Cerd\u00e1-Boluda",
                        "slug": "Joaqu\u00edn-Cerd\u00e1-Boluda",
                        "structuredName": {
                            "firstName": "Joaqu\u00edn",
                            "lastName": "Cerd\u00e1-Boluda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joaqu\u00edn Cerd\u00e1-Boluda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403435540"
                        ],
                        "name": "A. Sebasti\u00e0-Cort\u00e9s",
                        "slug": "A.-Sebasti\u00e0-Cort\u00e9s",
                        "structuredName": {
                            "firstName": "Angel",
                            "lastName": "Sebasti\u00e0-Cort\u00e9s",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Sebasti\u00e0-Cort\u00e9s"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 143
                            }
                        ],
                        "text": "LSI architectures using a mixed analog-digital approach [20] as well as several FPGA-based implementations have also been proposed [3][4][5][6][7][19][24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 42099939,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8071316266b758b27cd288dc0895f131b032233f",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper describes the implementation of a systolic array for a multilayer perceptron with a hardware-friendly learning algorithm. A pipelined modification of the on-line backpropagation algorithm is shown and explained. It better exploits the parallelism because both the forward and backward phases can be performed simultaneously. The neural network performance for the proposed modification is discussed and compared with the standard so-called on-line backpropagation algorithm in typical databases and with the various precisions required. Although the preliminary results are positive, subsequent theoretical analysis and further experiments with different training sets will be necessary. For this reason our VLSI systolic architecture\u2014together with the combination of FPGA reconfiguration properties and a design flow based on generic VHDL\u2014can create a reusable, flexible, and fast method of designing a complete ANN on a single FPGA and can permit very fast hardware verifications for our trials of the Pipeline On-line Backpropagation algorithm and the standard algorithms."
            },
            "slug": "FPGA-Implementation-of-a-Pipelined-On-Line-Giron\u00e9s-Colom-Palero",
            "title": {
                "fragments": [],
                "text": "FPGA Implementation of a Pipelined On-Line Backpropagation"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "The paper describes the implementation of a systolic array for a multilayer perceptron with a hardware-friendly learning algorithm that can create a reusable, flexible, and fast method of designing a complete ANN on a single FPGA and can permit very fast hardware verifications for trials of the Pipeline On-line Backpropagation algorithm and the standard algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "J. VLSI Signal Process."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 98
                            }
                        ],
                        "text": "Feed-forward, multi-layer artificial neural networks like the Convolutional Neural Networks (CNN) [2][11][13][16][17][20][23] have found increasing use in several new applications because they have the potential to process vast amounts of labeled data to automatically learn and extract complex features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2617020,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "57458bc1cffe5caa45a885af986d70f723f406b4",
            "isKey": false,
            "numCitedBy": 5064,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance."
            },
            "slug": "A-unified-architecture-for-natural-language-deep-Collobert-Weston",
            "title": {
                "fragments": [],
                "text": "A unified architecture for natural language processing: deep neural networks with multitask learning"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This work describes a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense using a language model."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153728644"
                        ],
                        "name": "Hui Zhang",
                        "slug": "Hui-Zhang",
                        "structuredName": {
                            "firstName": "Hui",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hui Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3281955"
                        ],
                        "name": "Mingxin Xia",
                        "slug": "Mingxin-Xia",
                        "structuredName": {
                            "firstName": "Mingxin",
                            "lastName": "Xia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mingxin Xia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793365"
                        ],
                        "name": "G. Hu",
                        "slug": "G.-Hu",
                        "structuredName": {
                            "firstName": "Guangshu",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Hu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 137
                            }
                        ],
                        "text": "LSI architectures using a mixed analog-digital approach [20] as well as several FPGA-based implementations have also been proposed [3][4][5][6][7][19][24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5660247,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4625d89223cacffce8eebce78092daec2036fde2",
            "isKey": false,
            "numCitedBy": 60,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Two-dimensional (2-D) convolution is widely used in image and video processing. Although the operation is simple, 2-D convolution is however both computationally expensive and memory-intensive. Field-programmable-gate-array (FPGA)-based parallel processing architectures were proposed to accelerate calculations for 2-D convolution. And data buffers implemented with FPGA on-chip resources were used to avoid direct access to external memories. Full buffering and partial buffering (PB) schemes were adopted in previous works. The former would consume a large amount of FPGA resources, while the latter would cause a sharp increase in external memory bus bandwidth. In this brief, we present a multiwindow PB scheme for FPGA-based 2-D convolvers. Compared with the aforementioned methods, the new buffering strategy exhibits a good balance between on-chip resource utilization and external memory bus bandwidth, and therefore is suitable for low-cost FPGA implementation"
            },
            "slug": "A-Multiwindow-Partial-Buffering-Scheme-for-2-D-Zhang-Xia",
            "title": {
                "fragments": [],
                "text": "A Multiwindow Partial Buffering Scheme for FPGA-Based 2-D Convolvers"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Compared with the aforementioned methods, the new buffering strategy exhibits a good balance between on-chip resource utilization and external memory bus bandwidth, and therefore is suitable for low-cost FPGA implementation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Circuits and Systems II: Express Briefs"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3176645"
                        ],
                        "name": "Antony W. Savich",
                        "slug": "Antony-W.-Savich",
                        "structuredName": {
                            "firstName": "Antony",
                            "lastName": "Savich",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Antony W. Savich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1843211"
                        ],
                        "name": "M. Moussa",
                        "slug": "M.-Moussa",
                        "structuredName": {
                            "firstName": "Medhat",
                            "lastName": "Moussa",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Moussa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701669"
                        ],
                        "name": "S. Areibi",
                        "slug": "S.-Areibi",
                        "structuredName": {
                            "firstName": "Shawki",
                            "lastName": "Areibi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Areibi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 140
                            }
                        ],
                        "text": "LSI architectures using a mixed analog-digital approach [20] as well as several FPGA-based implementations have also been proposed [3][4][5][6][7][19][24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8470509,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8399d125a71c2a1ffa2404359f58401e00b33a8",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, arithmetic representations for implementing multilayer perceptrons trained using the error backpropagation algorithm (MLP-BP) neural networks on field-programmable gate arrays (FPGAs) are examined in detail. Both floating-point (FLP) and fixed-point (FXP) formats are studied and the effect of precision of representation and FPGA area requirements are considered. A generic very high-speed integrated circuit hardware description language (VHDL) program was developed to help experiment with a large number of formats and designs. The results show that an MLP-BP network uses less clock cycles and consumes less real estate when compiled in an FXP format, compared with a larger and slower functioning compilation in an FLP format with similar data representation width, in bits, or a similar precision and range"
            },
            "slug": "The-Impact-of-Arithmetic-Representation-on-MLP-BP-A-Savich-Moussa",
            "title": {
                "fragments": [],
                "text": "The Impact of Arithmetic Representation on Implementing MLP-BP on FPGAs: A Study"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The results show that an MLP-BP network uses less clock cycles and consumes less real estate when compiled in an FXP format, compared with a larger and slower functioning compilation in an FLP format with similar data representation width, in bits, or a similar precision and range."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Neural Networks"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2243801"
                        ],
                        "name": "Jim Mutch",
                        "slug": "Jim-Mutch",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Mutch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jim Mutch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 443,
                                "start": 439
                            }
                        ],
                        "text": "By varying the number of convolvers in a computational element (Y), as well as the total number of computational elements (X), we can control the extent to which the two different parallelisms are parlayed to match the exact computational workload of any layer of a CNN. Note that by replacing the convolver primitive with a different functional unit, we can easily implement different feed-forward neural networks and classifiers such as HMAX [17][27], Deep Belief Networks [29][30] and HoG methods [28]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 139
                            }
                        ],
                        "text": "Our coprocessor (with different functional units) can easily implement different feed-forward neural networks and classifiers such as HMAX [17][27], DBN [29][30]and HoG methods [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 173
                            }
                        ],
                        "text": "Note that by replacing the convolver primitive with a different functional unit, we can easily implement different feed-forward neural networks and classifiers such as HMAX [17][27], Deep Belief Networks [29][30] and HoG methods [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 113
                            }
                        ],
                        "text": "Feed-forward, multi-layer artificial neural networks like the Convolutional Neural Networks (CNN) [2][11][13][16][17][20][23] have found increasing use in several new applications because they have the potential to process vast amounts of labeled data to automatically learn and extract complex features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1427294,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9e65fcb0e04174577f211d702d3f837e3624c5b",
            "isKey": true,
            "numCitedBy": 548,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We apply a biologically inspired model of visual object recognition to the multiclass object categorization problem. Our model modifies that of Serre, Wolf, and Poggio. As in that work, we first apply Gabor filters at all positions and scales; feature complexity and position/scale invariance are then built up by alternating template matching and max pooling operations. We refine the approach in several biologically plausible ways, using simple versions of sparsification and lateral inhibition. We demonstrate the value of retaining some position and scale information above the intermediate feature level. Using feature selection we arrive at a model that performs better with fewer features. Our final model is tested on the Caltech 101 object categories and the UIUC car localization task, in both cases achieving state-of-the-art performance. The results strengthen the case for using this class of model in computer vision."
            },
            "slug": "Multiclass-Object-Recognition-with-Sparse,-Features-Mutch-Lowe",
            "title": {
                "fragments": [],
                "text": "Multiclass Object Recognition with Sparse, Localized Features"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A biologically inspired model of visual object recognition to the multiclass object categorization problem, modifies that of Serre, Wolf, and Poggio, and demonstrates the value of retaining some position and scale information above the intermediate feature level."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145007186"
                        ],
                        "name": "D. Wolf",
                        "slug": "D.-Wolf",
                        "structuredName": {
                            "firstName": "Denis",
                            "lastName": "Wolf",
                            "middleNames": [
                                "Fernando"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Wolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144050092"
                        ],
                        "name": "R. Romero",
                        "slug": "R.-Romero",
                        "structuredName": {
                            "firstName": "Roseli",
                            "lastName": "Romero",
                            "middleNames": [
                                "Ap.",
                                "Francelin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Romero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144428156"
                        ],
                        "name": "E. Marques",
                        "slug": "E.-Marques",
                        "structuredName": {
                            "firstName": "Eduardo",
                            "lastName": "Marques",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Marques"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 150
                            }
                        ],
                        "text": "LSI architectures using a mixed analog-digital approach [20] as well as several FPGA-based implementations have also been proposed [3][4][5][6][7][19][24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 54939306,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a501e9f1349f5b8d59df130db801abd7bdf3026",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Artificial Neural Networks are applied for solving a wide variety of problems in several areas such as: robotics, image processing, and pattern recognition. Many applications demand a high computing power and the traditional software implementation are not sufficient. Hardware implementations of neural network algorithms are very interesting due their high performance. In this paper, an implementation that joins the software flexibility with the excellent hardware performance has been performed through the use of reconfigurable computing and embedded processors technologies. Keywords\uf8e7 Neural Networks, MLP, FPGA, Reconfigurable Computing, Embedded Processors"
            },
            "slug": "USING-EMBEDDED-PROCESSORS-IN-HARDWARE-MODELS-OF-Wolf-Romero",
            "title": {
                "fragments": [],
                "text": "USING EMBEDDED PROCESSORS IN HARDWARE MODELS OF ARTIFICIAL NEURAL NETWORKS"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "An implementation that joins the software flexibility with the excellent hardware performance has been performed through the use of reconfigurable computing and embedded processors technologies."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2979876"
                        ],
                        "name": "R. Raina",
                        "slug": "R.-Raina",
                        "structuredName": {
                            "firstName": "Rajat",
                            "lastName": "Raina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Raina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070938295"
                        ],
                        "name": "Anand Madhavan",
                        "slug": "Anand-Madhavan",
                        "structuredName": {
                            "firstName": "Anand",
                            "lastName": "Madhavan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anand Madhavan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 474,
                                "start": 454
                            }
                        ],
                        "text": "By varying the number of convolvers in a computational element (Y), as well as the total number of computational elements (X), we can control the extent to which the two different parallelisms are parlayed to match the exact computational workload of any layer of a CNN. Note that by replacing the convolver primitive with a different functional unit, we can easily implement different feed-forward neural networks and classifiers such as HMAX [17][27], Deep Belief Networks [29][30] and HoG methods [28]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 153
                            }
                        ],
                        "text": "Our coprocessor (with different functional units) can easily implement different feed-forward neural networks and classifiers such as HMAX [17][27], DBN [29][30]and HoG methods [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 208,
                                "start": 204
                            }
                        ],
                        "text": "Note that by replacing the convolver primitive with a different functional unit, we can easily implement different feed-forward neural networks and classifiers such as HMAX [17][27], Deep Belief Networks [29][30] and HoG methods [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 392458,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e337c5e4c23999c36f64bcb33ebe6b284e1bcbf1",
            "isKey": false,
            "numCitedBy": 643,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "The promise of unsupervised learning methods lies in their potential to use vast amounts of unlabeled data to learn complex, highly nonlinear models with millions of free parameters. We consider two well-known unsupervised learning models, deep belief networks (DBNs) and sparse coding, that have recently been applied to a flurry of machine learning applications (Hinton & Salakhutdinov, 2006; Raina et al., 2007). Unfortunately, current learning algorithms for both models are too slow for large-scale applications, forcing researchers to focus on smaller-scale models, or to use fewer training examples.\n In this paper, we suggest massively parallel methods to help resolve these problems. We argue that modern graphics processors far surpass the computational capabilities of multicore CPUs, and have the potential to revolutionize the applicability of deep unsupervised learning methods. We develop general principles for massively parallelizing unsupervised learning tasks using graphics processors. We show that these principles can be applied to successfully scaling up learning algorithms for both DBNs and sparse coding. Our implementation of DBN learning is up to 70 times faster than a dual-core CPU implementation for large models. For example, we are able to reduce the time required to learn a four-layer DBN with 100 million free parameters from several weeks to around a single day. For sparse coding, we develop a simple, inherently parallel algorithm, that leads to a 5 to 15-fold speedup over previous methods."
            },
            "slug": "Large-scale-deep-unsupervised-learning-using-Raina-Madhavan",
            "title": {
                "fragments": [],
                "text": "Large-scale deep unsupervised learning using graphics processors"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is argued that modern graphics processors far surpass the computational capabilities of multicore CPUs, and have the potential to revolutionize the applicability of deep unsupervised learning methods."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1981539"
                        ],
                        "name": "Thomas Serre",
                        "slug": "Thomas-Serre",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Serre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Serre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145128145"
                        ],
                        "name": "Lior Wolf",
                        "slug": "Lior-Wolf",
                        "structuredName": {
                            "firstName": "Lior",
                            "lastName": "Wolf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lior Wolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 143
                            }
                        ],
                        "text": "Our coprocessor (with different functional units) can easily implement different feed-forward neural networks and classifiers such as HMAX [17][27], DBN [29][30]and HoG methods [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 177
                            }
                        ],
                        "text": "Note that by replacing the convolver primitive with a different functional unit, we can easily implement different feed-forward neural networks and classifiers such as HMAX [17][27], Deep Belief Networks [29][30] and HoG methods [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 260426,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "040c23e5a409fbdedd5032263dfcb1a4d7dfd200",
            "isKey": false,
            "numCitedBy": 970,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a novel set of features for robust object recognition. Each element of this set is a complex feature obtained by combining position- and scale-tolerant edge-detectors over neighboring positions and multiple orientations. Our system's architecture is motivated by a quantitative model of visual cortex. We show that our approach exhibits excellent recognition performance and outperforms several state-of-the-art systems on a variety of image datasets including many different object categories. We also demonstrate that our system is able to learn from very few examples. The performance of the approach constitutes a suggestive plausibility proof for a class of feedforward models of object recognition in cortex."
            },
            "slug": "Object-recognition-with-features-inspired-by-visual-Serre-Wolf",
            "title": {
                "fragments": [],
                "text": "Object recognition with features inspired by visual cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The performance of the approach constitutes a suggestive plausibility proof for a class of feedforward models of object recognition in cortex and exhibits excellent recognition performance and outperforms several state-of-the-art systems on a variety of image datasets including many different object categories."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1697141"
                        ],
                        "name": "Honglak Lee",
                        "slug": "Honglak-Lee",
                        "structuredName": {
                            "firstName": "Honglak",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Honglak Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785346"
                        ],
                        "name": "Roger B. Grosse",
                        "slug": "Roger-B.-Grosse",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Grosse",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roger B. Grosse"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2615814"
                        ],
                        "name": "R. Ranganath",
                        "slug": "R.-Ranganath",
                        "structuredName": {
                            "firstName": "Rajesh",
                            "lastName": "Ranganath",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ranganath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 157
                            }
                        ],
                        "text": "Our coprocessor (with different functional units) can easily implement different feed-forward neural networks and classifiers such as HMAX [17][27], DBN [29][30]and HoG methods [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 208
                            }
                        ],
                        "text": "Note that by replacing the convolver primitive with a different functional unit, we can easily implement different feed-forward neural networks and classifiers such as HMAX [17][27], Deep Belief Networks [29][30] and HoG methods [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12008458,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e80f755bcbf10479afd2338cec05211fdbd325c",
            "isKey": false,
            "numCitedBy": 2528,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "There has been much interest in unsupervised learning of hierarchical generative models such as deep belief networks. Scaling such models to full-sized, high-dimensional images remains a difficult problem. To address this problem, we present the convolutional deep belief network, a hierarchical generative model which scales to realistic image sizes. This model is translation-invariant and supports efficient bottom-up and top-down probabilistic inference. Key to our approach is probabilistic max-pooling, a novel technique which shrinks the representations of higher layers in a probabilistically sound way. Our experiments show that the algorithm learns useful high-level visual features, such as object parts, from unlabeled images of objects and natural scenes. We demonstrate excellent performance on several visual recognition tasks and show that our model can perform hierarchical (bottom-up and top-down) inference over full-sized images."
            },
            "slug": "Convolutional-deep-belief-networks-for-scalable-of-Lee-Grosse",
            "title": {
                "fragments": [],
                "text": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "The convolutional deep belief network is presented, a hierarchical generative model which scales to realistic image sizes and is translation-invariant and supports efficient bottom-up and top-down probabilistic inference."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '09"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46670825"
                        ],
                        "name": "Kristian R. Nichols",
                        "slug": "Kristian-R.-Nichols",
                        "structuredName": {
                            "firstName": "Kristian",
                            "lastName": "Nichols",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristian R. Nichols"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052516121"
                        ],
                        "name": "M. Moussa",
                        "slug": "M.-Moussa",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Moussa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Moussa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701669"
                        ],
                        "name": "S. Areibi",
                        "slug": "S.-Areibi",
                        "structuredName": {
                            "firstName": "Shawki",
                            "lastName": "Areibi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Areibi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 146
                            }
                        ],
                        "text": "LSI architectures using a mixed analog-digital approach [20] as well as several FPGA-based implementations have also been proposed [3][4][5][6][7][19][24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1935173,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d4f15eae8685611324c666888a52703c19255e0d",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Aritificial Neural Networks (ANNs) implemented on FieldProgrammable Gate Arrays (FPGAs) have traditionally used a minimal allowable precision of 16-bit fixed-point. This approach is considered to be an optimal precision vs. area tradeoff for FPGA based ANNs because quality of performance is maintained, while making efficient use of the limited hardware resources available in a FPGA. However, limited precision of 16-bit fixed-point allows for quantization errors in calculations, the problems of which an engineer must deal with when testing and validating circuits. On the other hand, floating-point precision limits quantization errors and this form of numerical representation can be used in any application. This paper examines the feasibility of using floatingpoint arithmetic in the implementation of the backpropagation algorithm on single FPGA based platforms."
            },
            "slug": "Feasibility-of-Floating-Point-Arithmetic-in-FPGA-Nichols-Moussa",
            "title": {
                "fragments": [],
                "text": "Feasibility of Floating-Point Arithmetic in FPGA based Artificial Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper examines the feasibility of using floatingpoint arithmetic in the implementation of the backpropagation algorithm on single FPGA based platforms."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2301680"
                        ],
                        "name": "Bryan Catanzaro",
                        "slug": "Bryan-Catanzaro",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "Catanzaro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bryan Catanzaro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789372"
                        ],
                        "name": "N. Sundaram",
                        "slug": "N.-Sundaram",
                        "structuredName": {
                            "firstName": "Narayanan",
                            "lastName": "Sundaram",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sundaram"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732330"
                        ],
                        "name": "K. Keutzer",
                        "slug": "K.-Keutzer",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Keutzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Keutzer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2127615,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2635f61333900a6b4cd9b5db5d4c3bc31363b2ff",
            "isKey": false,
            "numCitedBy": 405,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent developments in programmable, highly parallel Graphics Processing Units (GPUs) have enabled high performance implementations of machine learning algorithms. We describe a solver for Support Vector Machine training running on a GPU, using the Sequential Minimal Optimization algorithm and an adaptive first and second order working set selection heuristic, which achieves speedups of 9-35x over LIBSVM running on a traditional processor. We also present a GPU-based system for SVM classification which achieves speedups of 81-138x over LIBSVM (5-24x over our own CPU based SVM classifier)."
            },
            "slug": "Fast-support-vector-machine-training-and-on-Catanzaro-Sundaram",
            "title": {
                "fragments": [],
                "text": "Fast support vector machine training and classification on graphics processors"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A solver for Support Vector Machine training run on a GPU, using the Sequential Minimal Optimization algorithm and an adaptive first and second order working set selection heuristic, which achieves speedups of 9-35x over LIBSVM running on a traditional processor."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144705062"
                        ],
                        "name": "P. Mirowski",
                        "slug": "P.-Mirowski",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Mirowski",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Mirowski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2505629"
                        ],
                        "name": "D. Madhavan",
                        "slug": "D.-Madhavan",
                        "structuredName": {
                            "firstName": "Deepak",
                            "lastName": "Madhavan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Madhavan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2305833"
                        ],
                        "name": "R. Kuzniecky",
                        "slug": "R.-Kuzniecky",
                        "structuredName": {
                            "firstName": "Ruben",
                            "lastName": "Kuzniecky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kuzniecky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 109
                            }
                        ],
                        "text": "Feed-forward, multi-layer artificial neural networks like the Convolutional Neural Networks (CNN) [2][11][13][16][17][20][23] have found increasing use in several new applications because they have the potential to process vast amounts of labeled data to automatically learn and extract complex features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14028568,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "966ce7b2567280088ee1d5816cee9e06d12fa19d",
            "isKey": false,
            "numCitedBy": 157,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent research suggests that electrophysiological changes develop minutes to hours before the actual clinical onset in focal epileptic seizures. Seizure prediction is a major field of neurological research, enabled by statistical analysis methods applied to features derived from intracranial Electroencephalographic (EEG) recordings of brain activity. However, no reliable seizure prediction method is ready for clinical applications. In this study, we use modern machine learning techniques to predict seizures from a number of features proposed in the literature. We concentrate on aggregated features that encode the relationship between pairs of EEG channels, such as cross-correlation, nonlinear interdependence, difference of Lyapunov exponents and wavelet analysis-based synchrony such as phase locking. We compare L1-regularized logistic regression, convolutional networks, and support vector machines. Results are reported on the standard Freiburg EEG dataset which contains data from 21 patients suffering from medically intractable focal epilepsy. For each patient, at least one method predicts 100% of the seizures on average 60 minutes before the onset, with no false alarm. Possible future applications include implantable devices capable of warning the patient of an upcoming seizure as well as implanted drug-delivery devices."
            },
            "slug": "Comparing-SVM-and-convolutional-networks-for-from-Mirowski-LeCun",
            "title": {
                "fragments": [],
                "text": "Comparing SVM and convolutional networks for epileptic seizure prediction from intracranial EEG"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Modern machine learning techniques are used to predict seizures from a number of features proposed in the literature, concentrating on aggregated features that encode the relationship between pairs of EEG channels, such as cross-correlation, nonlinear interdependence, difference of Lyapunov exponents and wavelet analysis-based synchrony such as phase locking."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Workshop on Machine Learning for Signal Processing"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143870558"
                        ],
                        "name": "Bhanu Prasad",
                        "slug": "Bhanu-Prasad",
                        "structuredName": {
                            "firstName": "Bhanu",
                            "lastName": "Prasad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bhanu Prasad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145816989"
                        ],
                        "name": "S. Prasanna",
                        "slug": "S.-Prasanna",
                        "structuredName": {
                            "firstName": "S.",
                            "lastName": "Prasanna",
                            "middleNames": [
                                "R.",
                                "Mahadeva"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Prasanna"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 149,
                                "start": 145
                            }
                        ],
                        "text": "Feed-forward multilayer neural networks [12] are computational models that are widely used in diverse domains such as video and image processing [22], medical diagnosis systems [14] and financial forecasting [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 30871581,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3944b098968e5f13deb0c78b41dad0fea869694b",
            "isKey": false,
            "numCitedBy": 48,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Humans are remarkable in processing speech, audio, image and some biomedical signals. Artificial neural networks are proved to be successful in performing several cognitive, industrial and scientific tasks. This peer reviewed book presents some recent advances and surveys on the applications of artificial neural networks in the areas of speech, audio, image and biomedical signal processing. It consists of 18 chapters prepared by some reputed researchers and practitioners around the globe."
            },
            "slug": "Speech,-Audio,-Image-and-Biomedical-Signal-using-Prasad-Prasanna",
            "title": {
                "fragments": [],
                "text": "Speech, Audio, Image and Biomedical Signal Processing using Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This peer reviewed book presents some recent advances and surveys on the applications of artificial neural networks in the areas of speech, audio, image and biomedical signal processing."
            },
            "venue": {
                "fragments": [],
                "text": "Studies in Computational Intelligence"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735300"
                        ],
                        "name": "S. Haykin",
                        "slug": "S.-Haykin",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Haykin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Haykin"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "Feed-forward multilayer neural networks [12] are computational models that are widely used in diverse domains such as video and image processing [22], medical diagnosis systems [14] and financial forecasting [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60504238,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ce70030c9d4e2ce2280cc15f50da42ea755d37d3",
            "isKey": false,
            "numCitedBy": 4926,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "For graduate-level neural network courses offered in the departments of Computer Engineering, Electrical Engineering, and Computer Science. Neural Networks and Learning Machines, Third Edition is renowned for its thoroughness and readability. This well-organized and completely upto-date text remains the most comprehensive treatment of neural networks from an engineering perspective. This is ideal for professional engineers and research scientists. Matlab codes used for the computer experiments in the text are available for download at: http://www.pearsonhighered.com/haykin/ Refocused, revised and renamed to reflect the duality of neural networks and learning machines, this edition recognizes that the subject matter is richer when these topics are studied together. Ideas drawn from neural networks and machine learning are hybridized to perform improved learning tasks beyond the capability of either independently."
            },
            "slug": "Neural-Networks-and-Learning-Machines-Haykin",
            "title": {
                "fragments": [],
                "text": "Neural Networks and Learning Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Refocused, revised and renamed to reflect the duality of neural networks and learning machines, this edition recognizes that the subject matter is richer when these topics are studied together."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48950628"
                        ],
                        "name": "N. Dalal",
                        "slug": "N.-Dalal",
                        "structuredName": {
                            "firstName": "Navneet",
                            "lastName": "Dalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dalal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 177
                            }
                        ],
                        "text": "Our coprocessor (with different functional units) can easily implement different feed-forward neural networks and classifiers such as HMAX [17][27], DBN [29][30]and HoG methods [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 233,
                                "start": 229
                            }
                        ],
                        "text": "Note that by replacing the convolver primitive with a different functional unit, we can easily implement different feed-forward neural networks and classifiers such as HMAX [17][27], Deep Belief Networks [29][30] and HoG methods [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206590483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cec734d7097ab6b1e60d95228ffd64248eb89d66",
            "isKey": false,
            "numCitedBy": 29471,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds."
            },
            "slug": "Histograms-of-oriented-gradients-for-human-Dalal-Triggs",
            "title": {
                "fragments": [],
                "text": "Histograms of oriented gradients for human detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection, and the influence of each stage of the computation on performance is studied."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2315504"
                        ],
                        "name": "R. Hadsell",
                        "slug": "R.-Hadsell",
                        "structuredName": {
                            "firstName": "Raia",
                            "lastName": "Hadsell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hadsell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3142556"
                        ],
                        "name": "Pierre Sermanet",
                        "slug": "Pierre-Sermanet",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Sermanet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierre Sermanet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144050629"
                        ],
                        "name": "J. Ben",
                        "slug": "J.-Ben",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Ben",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ben"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767093"
                        ],
                        "name": "A. Erkan",
                        "slug": "A.-Erkan",
                        "structuredName": {
                            "firstName": "Ayse",
                            "lastName": "Erkan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Erkan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085624"
                        ],
                        "name": "Marco Scoffier",
                        "slug": "Marco-Scoffier",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Scoffier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Scoffier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145636949"
                        ],
                        "name": "Urs Muller",
                        "slug": "Urs-Muller",
                        "structuredName": {
                            "firstName": "Urs",
                            "lastName": "Muller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Urs Muller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 101
                            }
                        ],
                        "text": "Feed-forward, multi-layer artificial neural networks like the Convolutional Neural Networks (CNN) [2][11][13][16][17][20][23] have found increasing use in several new applications because they have the potential to process vast amounts of labeled data to automatically learn and extract complex features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5277920,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d8f527d1a96b0dae209daa6a241cf3255a6ec0d",
            "isKey": false,
            "numCitedBy": 227,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Most vision\u2010based approaches to mobile robotics suffer from the limitations imposed by stereo obstacle detection, which is short range and prone to failure. We present a self\u2010supervised learning process for long\u2010range vision that is able to accurately classify complex terrain at distances up to the horizon, thus allowing superior strategic planning. The success of the learning process is due to the self\u2010supervised training data that are generated on every frame: robust, visually consistent labels from a stereo module; normalized wide\u2010context input windows; and a discriminative and concise feature representation. A deep hierarchical network is trained to extract informative and meaningful features from an input image, and the features are used to train a real\u2010time classifier to predict traversability. The trained classifier sees obstacles and paths from 5 to more than 100 m, far beyond the maximum stereo range of 12 m, and adapts very quickly to new environments. The process was developed and tested on the LAGR (Learning Applied to Ground Robots) mobile robot. Results from a ground truth data set, as well as field test results, are given. \u00a9 2009 Wiley Periodicals, Inc."
            },
            "slug": "Learning-long\u2010range-vision-for-autonomous-off\u2010road-Hadsell-Sermanet",
            "title": {
                "fragments": [],
                "text": "Learning long\u2010range vision for autonomous off\u2010road driving"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work presents a self\u2010supervised learning process for long\u2010range vision that is able to accurately classify complex terrain at distances up to the horizon, thus allowing superior strategic planning."
            },
            "venue": {
                "fragments": [],
                "text": "J. Field Robotics"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46537147"
                        ],
                        "name": "M. Nakajima",
                        "slug": "M.-Nakajima",
                        "structuredName": {
                            "firstName": "Masami",
                            "lastName": "Nakajima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Nakajima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31622867"
                        ],
                        "name": "H. Noda",
                        "slug": "H.-Noda",
                        "structuredName": {
                            "firstName": "Hideyuki",
                            "lastName": "Noda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Noda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3024821"
                        ],
                        "name": "K. Dosaka",
                        "slug": "K.-Dosaka",
                        "structuredName": {
                            "firstName": "Katsumi",
                            "lastName": "Dosaka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Dosaka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058164999"
                        ],
                        "name": "K. Nakata",
                        "slug": "K.-Nakata",
                        "structuredName": {
                            "firstName": "Kiyoshi",
                            "lastName": "Nakata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Nakata"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47901869"
                        ],
                        "name": "Motoki Higashida",
                        "slug": "Motoki-Higashida",
                        "structuredName": {
                            "firstName": "Motoki",
                            "lastName": "Higashida",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Motoki Higashida"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145779375"
                        ],
                        "name": "O. Yamamoto",
                        "slug": "O.-Yamamoto",
                        "structuredName": {
                            "firstName": "Osamu",
                            "lastName": "Yamamoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Yamamoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50527558"
                        ],
                        "name": "K. Mizumoto",
                        "slug": "K.-Mizumoto",
                        "structuredName": {
                            "firstName": "Katsuya",
                            "lastName": "Mizumoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Mizumoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49699858"
                        ],
                        "name": "H. Kondo",
                        "slug": "H.-Kondo",
                        "structuredName": {
                            "firstName": "Hiroyuki",
                            "lastName": "Kondo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kondo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2249283"
                        ],
                        "name": "Y. Shimazu",
                        "slug": "Y.-Shimazu",
                        "structuredName": {
                            "firstName": "Yukihiko",
                            "lastName": "Shimazu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Shimazu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34725215"
                        ],
                        "name": "K. Arimoto",
                        "slug": "K.-Arimoto",
                        "structuredName": {
                            "firstName": "Kazutami",
                            "lastName": "Arimoto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Arimoto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47402350"
                        ],
                        "name": "K. Saitoh",
                        "slug": "K.-Saitoh",
                        "structuredName": {
                            "firstName": "Kazunori",
                            "lastName": "Saitoh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Saitoh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50303174"
                        ],
                        "name": "Toru Shimizu",
                        "slug": "Toru-Shimizu",
                        "structuredName": {
                            "firstName": "Toru",
                            "lastName": "Shimizu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toru Shimizu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 3209046,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23882d0c256cf9dbf55eb8b1820af23b11de4a2a",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "The matrix processing engine (MTX) is a massively parallel processor based on the matrix architecture. 40GOPS (16b additions) is achieved at 200MHz clock frequency and 250mW power dissipation. 2048 ALUs and 1Mb SRAM connected by a flexible switching network are integrated in 3.1mm2 using a 90nm CMOS process"
            },
            "slug": "A-40GOPS-250mW-massively-parallel-processor-based-Nakajima-Noda",
            "title": {
                "fragments": [],
                "text": "A 40GOPS 250mW massively parallel processor based on matrix architecture"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "The matrix processing engine (MTX) is a massively parallel processor based on the matrix architecture that achieves 40GOPS (16b additions) at 200MHz clock frequency and 250mW power dissipation."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE International Solid State Circuits Conference - Digest of Technical Papers"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145408620"
                        ],
                        "name": "P. Lisboa",
                        "slug": "P.-Lisboa",
                        "structuredName": {
                            "firstName": "Paulo",
                            "lastName": "Lisboa",
                            "middleNames": [
                                "J.",
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Lisboa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727163"
                        ],
                        "name": "P. Szczepaniak",
                        "slug": "P.-Szczepaniak",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Szczepaniak",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Szczepaniak"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145848456"
                        ],
                        "name": "J. Mason",
                        "slug": "J.-Mason",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Mason",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mason"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145409328"
                        ],
                        "name": "E. Ifeachor",
                        "slug": "E.-Ifeachor",
                        "structuredName": {
                            "firstName": "Emmanuel",
                            "lastName": "Ifeachor",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Ifeachor"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 181,
                                "start": 177
                            }
                        ],
                        "text": "Feed-forward multilayer neural networks [12] are computational models that are widely used in diverse domains such as video and image processing [22], medical diagnosis systems [14] and financial forecasting [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7594199,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4499a809b86e95e1b5efaf2755f5a24803c78c21",
            "isKey": false,
            "numCitedBy": 93,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Tutorial and Review.- 1 The Bayesian Paradigm: Second Generation Neural Computing.- 1.1 Introduction.- 1.2 Theory.- 1.2.1 Bayesian Learning.- 1.2.2 The Evidence Framework.- 1.2.2.1 Error bars.- 1.2.2.2 Moderated outputs.- 1.2.2.3 Regularisation.- 1.2.3 Committees.- 1.3 Example Results.- 1.4 Conclusion.- 2 The Role of the Artificial Neural Network in the Characterisation of Complex Systems and the Prediction of Disease.- 2.1 Introduction.- 2.2 Diagnosis of Disease.- 2.3 Outcome Prediction.- 2.4 Conclusion.- 3 Genetic Evolution of Neural Network Architectures.- 3.1 Introduction.- 3.2 Stability: The 'Bias/Variance Problem'.- 3.3 Genetic Algorithms and Artificial Neural Networks.- 3.3.1 Description of a General Method for Evolving ANN Architecture (EANN).- 3.3.2 Prediction of Depression After Mania.- 3.3.3 EANN and the Agreement/Transparency Choice.- 3.3.4 ANN and the Stability/Specialisation Choice.- 3.4 Conclusion.- Computer Aided Diagnosis.- 4 The Application of PAPNET to Diagnostic Cytology.- 4.1 Introduction.- 4.2 First Efforts at Automation in Cytology.- 4.3 Neural Networks.- 4.4 The PAPNET System.- 4.4.1 Components of the PAPNET System.- 4.4.1.1 Technical factors affecting the performance of the machine.- 4.4.2 Performance of the PAPNET System.- 4.4.2.1 Cervicovaginal smears.- 4.4.3 Application of the PAPNET System to Smears of Sputum.- 4.4.4 Application of the PAPNET System to Smears of Urinary Sediment.- 4.4.5 Application of the PAPNET System to Oesophageal Smears.- 4.5 Comment.- 5 ProstAsure Index - A Serum-Based Neural Network-Derived Composite Index for Early Detection of Prostate Cancer.- 5.1 Introduction.- 5.2 Clinical Background of Prostate Cancer and Derivation of the ProstAsure Index Algorithm.- 5.3 Validation of PI with Independent Clinical Data.- 5.4 Issues in Developing PI.- 5.5 Conclusion.- 6 Neurometric Assessment of Adequacy of Intraoperative Anaesthetic.- 6.1 Intraoperative Awareness.- 6.2 Measuring Sensory Perception.- 6.3 Clinical Data.- 6.4 Results.- 6.5 Implementation.- 6.6 Clinical Deployment.- 6.7 Healthcare Benefit.- 6.8 Additional Studies.- 7 Classifying Spinal Measurements Using a Radial Basis Function Network.- 7.1 Introduction.- 7.2 Data.- 7.2.1 The Spines.- 7.2.2 The Measurements.- 7.2.3 Preprocessing the Data.- 7.3 Radial Basis Functions and Networks.- 7.4 Matrix Notation.- 7.5 Training RBF Networks.- 7.5.1 The Unsupervised Learning Stage.- 7.5.2 The Supervised Learning Stage.- 7.5.2.1 Regularisation as an aid to avoid over-fitting.- 7.5.2.2 Calculating the regularisation coefficients and the weights.- 7.5.2.3 Forward subset selection of RBFs.- 7.5.2.4 Input feature selection.- 7.6 Results.- 7.7 Conclusion.- 8 GEORGIA: An Overview.- 8.1 Introduction.- 8.2 The Medical Decision Support System.- 8.3 Learning Pattern Generation.- 8.4 Software and Hardware Implementation.- 8.5 Re-Training and Re-Configuring the MDSS.- 8.6 Introducing GEORGIA's Man-to-Computer Interface.- 8.7 Conclusion.- 9 Patient Monitoring Using an Artificial Neural Network.- 9.1 Overview of the Medical Context.- 9.2 Basic Statistical Appraisal of Vital Function Data.- 9.3 Neural Network Details.- 9.3.1 Default Training.- 9.4 Implementation.- 9.5 Clinical Trials.- 9.6 Clinical Practice.- 10 Benchmark of Approaches to Sequential Diagnosis.- 10.1 Introduction.- 10.2 Preliminaries.- 10.3 Methods.- 10.3.1 The Probabilistic Algorithm.- 10.3.1.1 The diagnostic algorithm for first order markov chains - the Markov I algorithm.- 10.3.1.2 The diagnostic algorithm for second order markov chains - the Markov II algorithm.- 10.3.2 The Fuzzy Methods.- 10.3.2.1 The algorithm without context - fuzzy 0.- 10.3.2.2 The algorithm with first-order context - fuzzy lA.- 10.3.2.3 The reduced algorithm with first-order context - fuzzy 1B.- 10.3.2.4 The algorithm with second-order context - fuzzy 2A.- 10.3.2.5 The reduced algorithm with second-order context - fuzzy 2B.- 10.3.3 The Neural Network Approach.- 10.4 A Practical Example - Comparative Analysis of Methods.- 10.5 Conclusion.- 11 Application of Neural Networks in the Diagnosis of Pathological Speech.- 11.1 Introduction.- 11.2 The Research Material and the Problems Considered.- 11.2.1 Dental Prosthetics.- 11.2.2 Maxillofacial Surgery.- 11.2.3 Orthodontics.- 11.2.4 Laryngology.- 11.3 The Signal Parameterisation.- 11.4 The Application of the Neural Networks and the Results.- 11.5 Conclusion.- Signal Processing.- 12 Independent Components Analysis.- 12.1 Introduction.- 12.2 Theory.- 12.2.1 The Decorrelating Manifold.- 12.2.2 The Choice of Non-Linearity.- 12.2.3 Model-Order Estimation.- 12.3 Non-Stationary ICA.- 12.3.1 Illustration.- 12.4 Applications.- 12.4.1 Source Separation.- 12.4.2 Source Number and Estimation.- 12.5 Conclusion.- 13 Rest EEG Hidden Dynamics as a Discriminant for Brain Tumour Classification.- 13.1 Introduction.- 13.2 Characterising Hidden Dynamics.- 13.3 The Clinical Study.- 13.4 The Minimum Markov Order.- 13.5 Conclusion.- 14 Artifical Neural Network Control on Functional Electrical Stimulation Assisted Gait for Persons with Spinal Cord Injury.- 14.1 Introduction.- 14.2 Methods.- 14.3 Results.- 14.4 Discussion.- 15 The Application of Neural Networks to Interpret Evoked Potential Waveforms.- 15.1 Introduction.- 15.2 The Medical Conditions Studied.- 15.3 The Evoked Potentials.- 15.4 The Relationship Between the CNV and the Medical Conditions.- 15.5 Experimental Procedures.- 15.6 Data Pre-Processing.- 15.7 Feature Extraction.- 15.8 Normalisation.- 15.9 The Artificial Neural Networks.- 15.9.1 The Simplified Fuzzy ARTMAP.- 15.9.2 The Probabilistic Simplified Fuzzy ARTMAP.- 15.9.3 ANN Training and Accuracy.- 15.9.3.1 Small numbers of training vectors.- 15.9.3.2 Simplified fuzzy ARTMAP.- 15.9.3.3 Committees of ANNs.- 15.10 Validation Issues.- 15.10.1 Technical Aspects of Validation.- 15.10.2 Clinical Aspects of Validation.- 15.11 Results.- 15.12 Implementation Considerations.- 15.13 Future Developments.- Image Processing.- 16 Intelligent Decision Support Systems in the Cytodiagnosis of Breast Carcinoma.- 16.1 Introduction.- 16.2 Previous Work on Decision Support in this Domain.- 16.3 The Data Set in this Study.- 16.3.1 Study Population.- 16.3.2 Input Variables.- 16.3.3 Partitioning of the Data.- 16.4 Human Performance.- 16.5 Logistic Regression.- 16.6 Data Derived Decision Tree.- 16.7 Multi-Layer Perceptron Neural Networks.- 16.8 Adaptive Resonance Theory Mapping (ARTMAP) Neural Networks.- 16.8.1 Potential Advantages of ARTMAP.- 16.8.2 ARTMAP Architecture and Methodology.- 16.8.3 Results from the Cascaded System.- 16.8.4 Symbolic Rule Extraction.- 16.9 Assessment of the Different Decision Support Systems.- 17 A Neural-Based System for the Automatic Classificaton and Follow-Up of Diabetic Retinopathies.- 17.1 Introduction.- 17.2 The DRA System.- 17.3 Hybrid Module.- 17.4 Committee Algorithms.- 17.4.1 New Selection Algorithms.- 17.4.1.1 Greedy selection.- 17.4.1.2 Pseudo-exhaustive selection.- 17.4.2 Sequential Cooperation.- 17.4.3 Experimental Results.- 17.5 Related Work.- 17.6 Validation of the DRA System.- 17.7 Conclusion.- 18 Classification of Chromosomes: A Comparative Study of Neural Network and Statistical Approaches.- 18.1 Introduction.- 18.1.1 Chromosome Analysis and its Applications.- 18.1.2 Chromosome Classification.- 18.1.3 Experimental Data.- 18.2 The Neural Network Classifier.- 18.2.1 Representation of Chromosome Features.- 18.2.2 Network Topology and Training.- 18.2.3 Incorporating Non-Banding Features.- 18.3 Classification Performance.- 18.3.1 Classification Experiments.- 18.3.2 Comparison with Statistical Classifiers.- 18.3.3 The Influence of Training-Set Size.- 18.4 The Use of Context in Classification.- 18.4.1 The Karyotyping Constraint.- 18.4.2 Applying the Constraint by a Network.- 18.4.3 Results of Applying the Context Network.- 18.5 Conclusion and Discussion.- 18.5.1 Comparison with Statistical Classifiers.- 18.5.2 Training Set Size and Application of Context.- 18.5.3 Biological Context.- 19 The Importance of Features and Primitives for Multi-dimensional/Multi-channel Image Processing.- 19.1 Introduction.- 19.2 The Image Data Level.- 19.3 From Image Data to Symbolic Primitives.- 19.4 Region Segmentation Quality and Training Phase.- 19.5 Validation of Image Segmentation.- 19.6 Segmentation Complexity and Quantitative Error Evaluation.- 19.7 Feature Description.- 19.8 Feature Selection.- 19.9 A Preliminary Overview of Application Results.- 19.10 Conclusion."
            },
            "slug": "Artificial-Neural-Networks-in-Biomedicine-Lisboa-Szczepaniak",
            "title": {
                "fragments": [],
                "text": "Artificial Neural Networks in Biomedicine"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "The Bayesian Paradigm: Second Generation Neural Computing is presented, which aims to clarify the role of the Artificial Neural Network in the Characterisation of Complex Systems and the Prediction of Disease and issues in developing PI."
            },
            "venue": {
                "fragments": [],
                "text": "Perspectives in Neural Computing"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4505173"
                        ],
                        "name": "J. Dixon",
                        "slug": "J.-Dixon",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Dixon",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dixon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 172
                            }
                        ],
                        "text": "Even if C increases by two or three orders of magnitude (very unlikely due to power and hardware constraints), fortunately, integer factorization for small numbers is fast [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 20969316,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "41c5341ea5409468e4d68ad14fce820c78bc51b2",
            "isKey": false,
            "numCitedBy": 125,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "The paper describes a \"probabilistic algorithm\" for finding a factor of any large composite integer n (the required input is the integer n together with an auxiliary sequence of random numbers). It is proved that the expected number of operations which will be required is O(exp{ 83Qn n In In n)l/2)) for some constant f > 0. Asymptotically, this algorithm is much faster than any previously analyzed algorithm for factoring integers; earlier algorithms have all required O(na) operations where a > 1/5."
            },
            "slug": "Asymptotically-fast-factorization-of-integers-Dixon",
            "title": {
                "fragments": [],
                "text": "Asymptotically fast factorization of integers"
            },
            "tldr": {
                "abstractSimilarityScore": 35,
                "text": "It is proved that the expected number of operations which will be required is O(exp{ 83Qn n In In n)l/2) for some constant f > 0."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41127338"
                        ],
                        "name": "P. McNelis",
                        "slug": "P.-McNelis",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "McNelis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. McNelis"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 208
                            }
                        ],
                        "text": "Feed-forward multilayer neural networks [12] are computational models that are widely used in diverse domains such as video and image processing [22], medical diagnosis systems [14] and financial forecasting [15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 151092679,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "52236181faeb95e8f1742062f4dd0a19b588a9c3",
            "isKey": false,
            "numCitedBy": 136,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface 1. Introduction 2. What Are Neural Networks 3. Estimation of a Network with Evolutionary Computation 4. Evaluation of Network Estimation 5. Estimation and Forecasting with Artificial Data 6. Times Series: Examples from Industry and Finance 7. Inflation and Deflation: Hong Kong and Japan 8. Classification: Credit Card Default and Bank Failures 9. Dimensionality Reduction and Implied Volatility Forecasting"
            },
            "slug": "Neural-Networks-in-Finance:-Gaining-Predictive-Edge-McNelis",
            "title": {
                "fragments": [],
                "text": "Neural Networks in Finance: Gaining Predictive Edge in the Market (Academic Press Advanced Finance Series)"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "89687593"
                        ],
                        "name": "Korekado Keisuke",
                        "slug": "Korekado-Keisuke",
                        "structuredName": {
                            "firstName": "Korekado",
                            "lastName": "Keisuke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Korekado Keisuke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152222495"
                        ],
                        "name": "Morie Takashi",
                        "slug": "Morie-Takashi",
                        "structuredName": {
                            "firstName": "Morie",
                            "lastName": "Takashi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Morie Takashi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1392153738"
                        ],
                        "name": "N. Osamu",
                        "slug": "N.-Osamu",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Osamu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Osamu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71846030"
                        ],
                        "name": "Nakano Teppei",
                        "slug": "Nakano-Teppei",
                        "structuredName": {
                            "firstName": "Nakano",
                            "lastName": "Teppei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nakano Teppei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "73047045"
                        ],
                        "name": "Matsugu Masakazu",
                        "slug": "Matsugu-Masakazu",
                        "structuredName": {
                            "firstName": "Matsugu",
                            "lastName": "Masakazu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matsugu Masakazu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52644595"
                        ],
                        "name": "Iwata Atsushi",
                        "slug": "Iwata-Atsushi",
                        "structuredName": {
                            "firstName": "Iwata",
                            "lastName": "Atsushi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Iwata Atsushi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 105
                            }
                        ],
                        "text": "Feed-forward, multi-layer artificial neural networks like the Convolutional Neural Networks (CNN) [2][11][13][16][17][20][23] have found increasing use in several new applications because they have the potential to process vast amounts of labeled data to automatically learn and extract complex features."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 203695228,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "40bfd17d20bdf0ec87e1418256525019828799dd",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "An-Image-Filtering-Processor-for-Face/Object-Using-Keisuke-Takashi",
            "title": {
                "fragments": [],
                "text": "An Image Filtering Processor for Face/Object Recognition Using Merged/Mixed Analog-Digital Architecture"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Design and implementation of a 2 D convolution core for video applications on FPGAs , \" Digital and Computational Video , 2002"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Multiclass object recognition with sparse"
            },
            "venue": {
                "fragments": [],
                "text": "localized features. International Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Back , Face Recognition : A Convolutional Neural Network Approach"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Neural Networks"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 218,
                                "start": 215
                            }
                        ],
                        "text": "These computation models serve one of two roles: pattern recognition to provide a meaningful categorization of input patterns, or functional approximation where the models find a smooth function that approximates the actual mapping between input and output patterns."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Area-efficient 2-D shiftvariant convolvers for FPGA-based digital image processing Circuits and Systems II: Express Briefs"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 101
                            }
                        ],
                        "text": "There are no reported LSI implementations of CNNs but several software implementations on GPUs exist [8][25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fast Support Vector Training and Classification on Graphics Processors"
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning, 25th International Conference on, (ICML 2008), Jul. 2008."
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Face Detection using GPU - based Convolutional Neural Network \u201d"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 16,
            "methodology": 15
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 36,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/A-dynamically-configurable-coprocessor-for-neural-Chakradhar-Sankaradass/e1c4e2fa071046569a05e9cfdf13496d094025dd?sort=total-citations"
}