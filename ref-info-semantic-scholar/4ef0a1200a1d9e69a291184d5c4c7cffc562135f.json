{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054518634"
                        ],
                        "name": "Ben Weiss",
                        "slug": "Ben-Weiss",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ben Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 204
                            }
                        ],
                        "text": "However, recent work has demonstrated acceleration and obtained good performance on CPUs, on the order of one second per megapixel [Durand and Dorsey 2002; Pham and van Vliet 2005; Paris and Durand 2006; Weiss 2006]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12619942,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2766abee30785af4ea4f34aab86f81941fbd4590",
            "isKey": false,
            "numCitedBy": 265,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Median filtering is a cornerstone of modern image processing and is used extensively in smoothing and de-noising applications. The fastest commercial implementations (e.g. in Adobe\u00ae Photoshop\u00ae CS2) exhibit O(r) runtime in the radius of the filter, which limits their usefulness in realtime or resolution-independent contexts. We introduce a CPU-based, vectorizable O(log r) algorithm for median filtering, to our knowledge the most efficient yet developed. Our algorithm extends to images of any bit-depth, and can also be adapted to perform bilateral filtering. On 8-bit data our median filter outperforms Photoshop's implementation by up to a factor of fifty."
            },
            "slug": "Fast-median-and-bilateral-filtering-Weiss",
            "title": {
                "fragments": [],
                "text": "Fast median and bilateral filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work introduces a CPU-based, vectorizable O(log r) algorithm for median filtering, to its knowledge the most efficient yet developed and extended to images of any bit-depth, and can also be adapted to perform bilateral filtering."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH 2006"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34822000"
                        ],
                        "name": "Tuan Q. Pham",
                        "slug": "Tuan-Q.-Pham",
                        "structuredName": {
                            "firstName": "Tuan",
                            "lastName": "Pham",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tuan Q. Pham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1729533"
                        ],
                        "name": "L. V. Vliet",
                        "slug": "L.-V.-Vliet",
                        "structuredName": {
                            "firstName": "Lucas",
                            "lastName": "Vliet",
                            "middleNames": [
                                "J.",
                                "van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. V. Vliet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5998491,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "de3674fcc48261b8b7963f478cf760001fbb3a97",
            "isKey": false,
            "numCitedBy": 261,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Bilateral filtering is an edge-preserving filtering technique that employs both geometric closeness and photometric similarity of neighboring pixels to construct its filter kernel. Multi-dimensional bilateral filtering is computationally expensive because the adaptive kernel has to be recomputed at every pixel. In this paper, we present a separable implementation of the bilateral filter. The separable implementation offers equivalent adaptive filtering capability at a fraction of execution time compared to the traditional filter. Because of this efficiency, the separable bilateral filter can be used for fast preprocessing of images and videos. Experiments show that better image quality and higher compression efficiency is achievable if the original video is preprocessed with the separable bilateral filter."
            },
            "slug": "Separable-bilateral-filtering-for-fast-video-Pham-Vliet",
            "title": {
                "fragments": [],
                "text": "Separable bilateral filtering for fast video preprocessing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The separable implementation of the bilateral filter offers equivalent adaptive filtering capability at a fraction of execution time compared to the traditional filter."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE International Conference on Multimedia and Expo"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086151"
                        ],
                        "name": "Carlo Tomasi",
                        "slug": "Carlo-Tomasi",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "Tomasi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlo Tomasi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737048"
                        ],
                        "name": "R. Manduchi",
                        "slug": "R.-Manduchi",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Manduchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Manduchi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14308539,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "bfeaf424a2ea6ca4702d545c6e959e2caeb68e9b",
            "isKey": false,
            "numCitedBy": 8377,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Bilateral filtering smooths images while preserving edges, by means of a nonlinear combination of nearby image values. The method is noniterative, local, and simple. It combines gray levels or colors based on both their geometric closeness and their photometric similarity, and prefers near values to distant values in both domain and range. In contrast with filters that operate on the three bands of a color image separately, a bilateral filter can enforce the perceptual metric underlying the CIE-Lab color space, and smooth colors and preserve edges in a way that is tuned to human perception. Also, in contrast with standard filtering, bilateral filtering produces no phantom colors along edges in color images, and reduces phantom colors where they appear in the original image."
            },
            "slug": "Bilateral-filtering-for-gray-and-color-images-Tomasi-Manduchi",
            "title": {
                "fragments": [],
                "text": "Bilateral filtering for gray and color images"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "In contrast with filters that operate on the three bands of a color image separately, a bilateral filter can enforce the perceptual metric underlying the CIE-Lab color space, and smooth colors and preserve edges in a way that is tuned to human perception."
            },
            "venue": {
                "fragments": [],
                "text": "Sixth International Conference on Computer Vision (IEEE Cat. No.98CH36271)"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065808108"
                        ],
                        "name": "Pietro Perona",
                        "slug": "Pietro-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pietro Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14502908,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "496c3d75b81b336411e53da1ac632a8139655604",
            "isKey": false,
            "numCitedBy": 12608,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "A new definition of scale-space is suggested, and a class of algorithms used to realize a diffusion process is introduced. The diffusion coefficient is chosen to vary spatially in such a way as to encourage intraregion smoothing rather than interregion smoothing. It is shown that the 'no new maxima should be generated at coarse scales' property of conventional scale space is preserved. As the region boundaries in the approach remain sharp, a high-quality edge detector which successfully exploits global information is obtained. Experimental results are shown on a number of images. Parallel hardware implementations are made feasible because the algorithm involves elementary, local operations replicated over the image. >"
            },
            "slug": "Scale-Space-and-Edge-Detection-Using-Anisotropic-Perona-Malik",
            "title": {
                "fragments": [],
                "text": "Scale-Space and Edge Detection Using Anisotropic Diffusion"
            },
            "tldr": {
                "abstractSimilarityScore": 87,
                "text": "A new definition of scale-space is suggested, and a class of algorithms used to realize a diffusion process is introduced, chosen to vary spatially in such a way as to encourage intra Region smoothing rather than interregion smoothing."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057741248"
                        ],
                        "name": "Eric P. Bennett",
                        "slug": "Eric-P.-Bennett",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Bennett",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric P. Bennett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145170879"
                        ],
                        "name": "L. McMillan",
                        "slug": "L.-McMillan",
                        "structuredName": {
                            "firstName": "Leonard",
                            "lastName": "McMillan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. McMillan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3337416,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "201fed356fc9d39d3b9d81b029ba71cc798cc7ec",
            "isKey": false,
            "numCitedBy": 141,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We enhance underexposed, low dynamic range videos by adaptively and independently varying the exposure at each photoreceptor in a post-process. This virtual exposure is a dynamic function of both the spatial neighborhood and temporal history at each pixel. Temporal integration enables us to expand the image's dynamic range while simultaneously reducing noise. Our non-linear exposure variation and denoising filters smoothly transition from temporal to spatial for moving scene elements. Our virtual exposure framework also supports temporally coherent per frame tone mapping. Our system outputs restored video sequences with significantly reduced noise, increased exposure time of dark pixels, intact motion, and improved details."
            },
            "slug": "Video-enhancement-using-per-pixel-virtual-exposures-Bennett-McMillan",
            "title": {
                "fragments": [],
                "text": "Video enhancement using per-pixel virtual exposures"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "This work enhances underexposed, low dynamic range videos by adaptively and independently varying the exposure at each photoreceptor in a post-process, which is a dynamic function of both the spatial neighborhood and temporal history at each pixel."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157788337"
                        ],
                        "name": "Stephen M. Smith",
                        "slug": "Stephen-M.-Smith",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Smith",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen M. Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144431498"
                        ],
                        "name": "M. Brady",
                        "slug": "M.-Brady",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Brady",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brady"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15033310,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a891df6349236ace22780bec4951a88af785fdf",
            "isKey": false,
            "numCitedBy": 3526,
            "numCiting": 121,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a new approach to low level image processing; in particular, edge and corner detection and structure preserving noise reduction.Non-linear filtering is used to define which parts of the image are closely related to each individual pixel; each pixel has associated with it a local image region which is of similar brightness to that pixel. The new feature detectors are based on the minimization of this local image region, and the noise reduction method uses this region as the smoothing neighbourhood. The resulting methods are accurate, noise resistant and fast.Details of the new feature detectors and of the new noise reduction method are described, along with test results."
            },
            "slug": "SUSAN\u2014A-New-Approach-to-Low-Level-Image-Processing-Smith-Brady",
            "title": {
                "fragments": [],
                "text": "SUSAN\u2014A New Approach to Low Level Image Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "This paper describes a new approach to low level image processing; in particular, edge and corner detection and structure preserving noise reduction and the resulting methods are accurate, noise resistant and fast."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2037710"
                        ],
                        "name": "N. Sochen",
                        "slug": "N.-Sochen",
                        "structuredName": {
                            "firstName": "Nir",
                            "lastName": "Sochen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sochen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143923265"
                        ],
                        "name": "R. Kimmel",
                        "slug": "R.-Kimmel",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Kimmel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kimmel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7726541"
                        ],
                        "name": "R. Malladi",
                        "slug": "R.-Malladi",
                        "structuredName": {
                            "firstName": "Ravi",
                            "lastName": "Malladi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Malladi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1718044,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1189d969dbba1a46296cf100bf3448d9a3be60dd",
            "isKey": false,
            "numCitedBy": 646,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new geometrical framework based on which natural flows for image scale space and enhancement are presented. We consider intensity images as surfaces in the (x, I) space. The image is, thereby, a two-dimensional (2-D) surface in three-dimensional (3-D) space for gray-level images, and 2-D surfaces in five dimensions for color images. The new formulation unifies many classical schemes and algorithms via a simple scaling of the intensity contrast, and results in new and efficient schemes. Extensions to multidimensional signals become natural and lead to powerful denoising and scale space algorithms."
            },
            "slug": "A-general-framework-for-low-level-vision-Sochen-Kimmel",
            "title": {
                "fragments": [],
                "text": "A general framework for low level vision"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A new geometrical framework based on which natural flows for image scale space and enhancement are presented, which unifies many classical schemes and algorithms via a simple scaling of the intensity contrast, and results in new and efficient schemes."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Image Process."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2084468499"
                        ],
                        "name": "Georg Petschnigg",
                        "slug": "Georg-Petschnigg",
                        "structuredName": {
                            "firstName": "Georg",
                            "lastName": "Petschnigg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Georg Petschnigg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717841"
                        ],
                        "name": "R. Szeliski",
                        "slug": "R.-Szeliski",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Szeliski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Szeliski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1820412"
                        ],
                        "name": "Maneesh Agrawala",
                        "slug": "Maneesh-Agrawala",
                        "structuredName": {
                            "firstName": "Maneesh",
                            "lastName": "Agrawala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maneesh Agrawala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1400248273"
                        ],
                        "name": "Michael F. Cohen",
                        "slug": "Michael-F.-Cohen",
                        "structuredName": {
                            "firstName": "Michael F.",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael F. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144201188"
                        ],
                        "name": "Hugues Hoppe",
                        "slug": "Hugues-Hoppe",
                        "structuredName": {
                            "firstName": "Hugues",
                            "lastName": "Hoppe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hugues Hoppe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769685"
                        ],
                        "name": "K. Toyama",
                        "slug": "K.-Toyama",
                        "structuredName": {
                            "firstName": "Kentaro",
                            "lastName": "Toyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Toyama"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 78680,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e735bcf14791d301a14602e6164843cf3d28404f",
            "isKey": false,
            "numCitedBy": 917,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Digital photography has made it possible to quickly and easily take a pair of images of low-light environments: one with flash to capture detail and one without flash to capture ambient illumination. We present a variety of applications that analyze and combine the strengths of such flash/no-flash image pairs. Our applications include denoising and detail transfer (to merge the ambient qualities of the no-flash image with the high-frequency flash detail), white-balancing (to change the color tone of the ambient image), continuous flash (to interactively adjust flash intensity), and red-eye removal (to repair artifacts in the flash image). We demonstrate how these applications can synthesize new images that are of higher quality than either of the originals."
            },
            "slug": "Digital-photography-with-flash-and-no-flash-image-Petschnigg-Szeliski",
            "title": {
                "fragments": [],
                "text": "Digital photography with flash and no-flash image pairs"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A variety of applications that analyze and combine the strengths of flash/no-flash image pairs can synthesize new images that are of higher quality than either of the originals."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2664448"
                        ],
                        "name": "Jiangjian Xiao",
                        "slug": "Jiangjian-Xiao",
                        "structuredName": {
                            "firstName": "Jiangjian",
                            "lastName": "Xiao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiangjian Xiao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "146876323"
                        ],
                        "name": "Hui Cheng",
                        "slug": "Hui-Cheng",
                        "structuredName": {
                            "firstName": "Hui",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hui Cheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733393"
                        ],
                        "name": "H. Sawhney",
                        "slug": "H.-Sawhney",
                        "structuredName": {
                            "firstName": "Harpreet",
                            "lastName": "Sawhney",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sawhney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145206607"
                        ],
                        "name": "C. Rao",
                        "slug": "C.-Rao",
                        "structuredName": {
                            "firstName": "Cen",
                            "lastName": "Rao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144970789"
                        ],
                        "name": "M. Isnardi",
                        "slug": "M.-Isnardi",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Isnardi",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Isnardi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18879073,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "be9aa06e6aa2c78acf90d8bef161d3cfe4c667e6",
            "isKey": false,
            "numCitedBy": 274,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Using the variational approaches to estimate optical flow between two frames, the flow discontinuities between different motion fields are usually not distinguished even when an anisotropic diffusion operator is applied. In this paper, we propose a multi-cue driven adaptive bilateral filter to regularize the flow computation, which is able to achieve the smoothly varied optical flow field with highly desirable motion discontinuities. First, we separate the traditional one-step variational updating model into a two-step filtering-based updating model. Then, employing our occlusion detector, we reformulate the energy functional of optical flow estimation by explicitly introducing an occlusion term to balance the energy loss due to the occlusion or mismatches. Furthermore, based on the two-step updating framework, a novel multi-cue driven bilateral filter is proposed to substitute the original anisotropic diffusion process, and it is able to adaptively control the diffusion process according to the occlusion detection, image intensity dissimilarity, and motion dissimilarity. After applying our approach on various video sources (movie and TV) in the presence of occlusion, motion blurring, non-rigid deformation, and weak textureness, we generate a spatial-coherent flow field between each pair of input frames and detect more accurate flow discontinuities along the motion boundaries."
            },
            "slug": "Bilateral-Filtering-Based-Optical-Flow-Estimation-Xiao-Cheng",
            "title": {
                "fragments": [],
                "text": "Bilateral Filtering-Based Optical Flow Estimation with Occlusion Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel multi-cue driven adaptive bilateral filter is proposed to substitute the original anisotropic diffusion process, and it is able to adaptively control the diffusion process according to the occlusion detection, image intensity Dissimilarity, and motion dissimilarity."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143708263"
                        ],
                        "name": "Yung-Yu Chuang",
                        "slug": "Yung-Yu-Chuang",
                        "structuredName": {
                            "firstName": "Yung-Yu",
                            "lastName": "Chuang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yung-Yu Chuang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1763086"
                        ],
                        "name": "Alexei A. Efros",
                        "slug": "Alexei-A.-Efros",
                        "structuredName": {
                            "firstName": "Alexei",
                            "lastName": "Efros",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexei A. Efros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055109649"
                        ],
                        "name": "J. Ruskin",
                        "slug": "J.-Ruskin",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Ruskin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ruskin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145403226"
                        ],
                        "name": "F. Durand",
                        "slug": "F.-Durand",
                        "structuredName": {
                            "firstName": "Fr\u00e9do",
                            "lastName": "Durand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Durand"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2444123,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "668dd032ebf7dab476cfa842d8a31ee22cd9f841",
            "isKey": false,
            "numCitedBy": 1676,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new technique for the display of high-dynamic-range images, which reduces the contrast while preserving detail. It is based on a two-scale decomposition of the image into a base layer,..."
            },
            "slug": "Fast-bilateral-filtering-for-the-display-of-images-Chuang-Efros",
            "title": {
                "fragments": [],
                "text": "Fast bilateral filtering for the display of high-dynamic-range images"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A new technique for the display of high-dynamic-range images, which reduces the contrast while preserving detail, is presented, based on a two-scale decomposition of the image into a base layer."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2096445694"
                        ],
                        "name": "V. Aurich",
                        "slug": "V.-Aurich",
                        "structuredName": {
                            "firstName": "Volker",
                            "lastName": "Aurich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Aurich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2866274"
                        ],
                        "name": "J. Weule",
                        "slug": "J.-Weule",
                        "structuredName": {
                            "firstName": "J\u00f6rg",
                            "lastName": "Weule",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weule"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 31354989,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "72857b712b39c41eac6438f776d6a98a0a29bfd9",
            "isKey": false,
            "numCitedBy": 334,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new diffusion method for edge preserving smoothing of images. In contrast to other methods it is not based on an anisotropic modification of the heat conductance equation, rather on a modification of the way the solution of the heat conductance equation is obtained by convolving the initial data with a Gaussian kernel. Hence the method uses simple non-linear modifications of Gaussian filters, thus avoiding iteration steps and convergence problems. A chain of three to five filters with suitable parameters provides excellent smoothing of fine image details without destroying the coarser structures. The size and contrast of the eliminated details can be selected. The choice of the parameters is not critical and the edges are not displaced when changing the scale. The filter stages can be implemented efficiently on almost any parallel hardware architecture."
            },
            "slug": "Non-Linear-Gaussian-Filters-Performing-Edge-Aurich-Weule",
            "title": {
                "fragments": [],
                "text": "Non-Linear Gaussian Filters Performing Edge Preserving Diffusion"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The method uses simple non-linear modifications of Gaussian filters, thus avoiding iteration steps and convergence problems and providing excellent smoothing of fine image details without destroying the coarser structures."
            },
            "venue": {
                "fragments": [],
                "text": "DAGM-Symposium"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737690"
                        ],
                        "name": "E. Eisemann",
                        "slug": "E.-Eisemann",
                        "structuredName": {
                            "firstName": "Elmar",
                            "lastName": "Eisemann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Eisemann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145403226"
                        ],
                        "name": "F. Durand",
                        "slug": "F.-Durand",
                        "structuredName": {
                            "firstName": "Fr\u00e9do",
                            "lastName": "Durand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Durand"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11388007,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "eee03c81f38281479220ce323ee08e95ef84e541",
            "isKey": false,
            "numCitedBy": 374,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We enhance photographs shot in dark environments by combining a picture taken with the available light and one taken with the flash. We preserve the ambiance of the original lighting and insert the sharpness from the flash image. We use the bilateral filter to decompose the images into detail and large scale. We reconstruct the image using the large scale of the available lighting and the detail of the flash. We detect and correct flash shadows. This combines the advantages of available illumination and flash photography."
            },
            "slug": "Flash-photography-enhancement-via-intrinsic-Eisemann-Durand",
            "title": {
                "fragments": [],
                "text": "Flash photography enhancement via intrinsic relighting"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work uses the bilateral filter to decompose the images into detail and large scale and reconstruct the image using the large scale of the available lighting and the detail of the flash to enhance photographs shot in dark environments."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Graph."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064793913"
                        ],
                        "name": "Kenneth Chiu",
                        "slug": "Kenneth-Chiu",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Chiu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth Chiu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50743727"
                        ],
                        "name": "M. Herf",
                        "slug": "M.-Herf",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Herf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Herf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144033462"
                        ],
                        "name": "P. Shirley",
                        "slug": "P.-Shirley",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Shirley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Shirley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706258"
                        ],
                        "name": "S. Swamy",
                        "slug": "S.-Swamy",
                        "structuredName": {
                            "firstName": "Somashekhar",
                            "lastName": "Swamy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Swamy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757878"
                        ],
                        "name": "C. Wang",
                        "slug": "C.-Wang",
                        "structuredName": {
                            "firstName": "C",
                            "lastName": "Wang",
                            "middleNames": [
                                "T"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48015774"
                        ],
                        "name": "Kurt Zimmerman",
                        "slug": "Kurt-Zimmerman",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Zimmerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kurt Zimmerman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 171
                            }
                        ],
                        "text": "\u2026is usually smooth except at shadow boundaries [Oh et al. 2001], and tone mapping suffers from haloing artifacts when a low-pass filter is used to drive local adjustment [Chiu et al. 1993], a problem which can be solved with nonlinear filters [Tumblin and Turk 1999; Durand and Dorsey 2002]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 117
                            }
                        ],
                        "text": "We demonstrate our method on a variety of applications such as image editing, transfer of photographic look, and contrast enhancement of medical images."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7982670,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "8b9d479a254f6128b93864ae3420c3083e98b85b",
            "isKey": false,
            "numCitedBy": 265,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm is presented that scales the pixel intensities of a computer generated greyscale image so that they are all displayable on a standard CRT. This scaling is spatially nonuniform over the image in that different pixels with the same intensity in the original image may have different intensities in the resulting image. The goal of this scaling transformation is to produce an image on the CRT that perceptually mimics the calculated image, while staying within the physical limitations of the CRT."
            },
            "slug": "Spatially-Nonuniform-Scaling-Functions-for-High-Chiu-Herf",
            "title": {
                "fragments": [],
                "text": "Spatially Nonuniform Scaling Functions for High Contrast Images"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38551815"
                        ],
                        "name": "Anat Levin",
                        "slug": "Anat-Levin",
                        "structuredName": {
                            "firstName": "Anat",
                            "lastName": "Levin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anat Levin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684384"
                        ],
                        "name": "Dani Lischinski",
                        "slug": "Dani-Lischinski",
                        "structuredName": {
                            "firstName": "Dani",
                            "lastName": "Lischinski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dani Lischinski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30400079"
                        ],
                        "name": "Yair Weiss",
                        "slug": "Yair-Weiss",
                        "structuredName": {
                            "firstName": "Yair",
                            "lastName": "Weiss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yair Weiss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11713946,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bad97714e7b7ca4f8e49dd1fefc05e7d9bea6658",
            "isKey": false,
            "numCitedBy": 1222,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Colorization is a computer-assisted process of adding color to a monochrome image or movie. The process typically involves segmenting images into regions and tracking these regions across image sequences. Neither of these tasks can be performed reliably in practice; consequently, colorization requires considerable user intervention and remains a tedious, time-consuming, and expensive task.In this paper we present a simple colorization method that requires neither precise image segmentation, nor accurate region tracking. Our method is based on a simple premise; neighboring pixels in space-time that have similar intensities should have similar colors. We formalize this premise using a quadratic cost function and obtain an optimization problem that can be solved efficiently using standard techniques. In our approach an artist only needs to annotate the image with a few color scribbles, and the indicated colors are automatically propagated in both space and time to produce a fully colorized image or sequence. We demonstrate that high quality colorizations of stills and movie clips may be obtained from a relatively modest amount of user input."
            },
            "slug": "Colorization-using-optimization-Levin-Lischinski",
            "title": {
                "fragments": [],
                "text": "Colorization using optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper presents a simple colorization method that requires neither precise image segmentation, nor accurate region tracking, and demonstrates that high quality colorizations of stills and movie clips may be obtained from a relatively modest amount of user input."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Graph."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2914934"
                        ],
                        "name": "J. Tumblin",
                        "slug": "J.-Tumblin",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Tumblin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tumblin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713189"
                        ],
                        "name": "Greg Turk",
                        "slug": "Greg-Turk",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Turk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Turk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 37
                            }
                        ],
                        "text": "Keywords: Computational Photography, Edge-Aware Image Processing, Bilateral Filter, Real-time Video Processing"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 103
                            }
                        ],
                        "text": "In this work, we dramatically accelerate and generalize the bilateral filter, enabling a variety of edge-aware image processing applications in real-time on high-resolution inputs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1239037,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "611c85469c4effd67ae99ccc92456597547424e4",
            "isKey": false,
            "numCitedBy": 494,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "High contrast scenes are difficult to depict on low contrast displays without loss of important fine details and textures. Skilled artists preserve these details by drawing scene contents in coarseto-fine order using a hierarchy of scene boundaries and shadings. We build a similar hierarchy using multiple instances of a new low curvature image simplifier (LCIS), a partial differential equation inspired by anisotropic diffusion. Each LCIS reduces the scene to many smooth regions that are bounded by sharp gradient discontinuities, and a single parameter K chosen for each LCIS controls region size and boundary complexity. With a few chosen K values (K1 > K2 > K3:::) LCIS makes a set of progressively simpler images, and image differences form a hierarchy of increasingly important details, boundaries and large features. We construct a high detail, low contrast display image from this hierarchy by compressing only the large features, then adding back all small details. Unlike linear filter hierarchies such as wavelets, filter banks, or image pyramids, LCIS hierarchies do not smooth across scene boundaries, avoiding \u201chalo\u201d artifacts common to previous contrast reducing methods and some tone reproduction operators. We demonstrate LCIS effectiveness on several example images. CR Descriptors: I.3.3 [Computer Graphics]: Picture/image generation Display algorithms; I.4.1 [Image Processing and Computer Vision]: Enhancement -Digitization and Image Capture"
            },
            "slug": "LCIS:-a-boundary-hierarchy-for-detail-preserving-Tumblin-Turk",
            "title": {
                "fragments": [],
                "text": "LCIS: a boundary hierarchy for detail-preserving contrast reduction"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work builds a similar hierarchy using multiple instances of a new low curvature image simplifier (LCIS), a partial differential equation inspired by anisotropic diffusion, and constructs a high detail, low contrast display image by compressing only the large features, then adding back all small details."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH '99"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145799132"
                        ],
                        "name": "Sylvain Paris",
                        "slug": "Sylvain-Paris",
                        "structuredName": {
                            "firstName": "Sylvain",
                            "lastName": "Paris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sylvain Paris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145403226"
                        ],
                        "name": "F. Durand",
                        "slug": "F.-Durand",
                        "structuredName": {
                            "firstName": "Fr\u00e9do",
                            "lastName": "Durand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Durand"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1482395,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c8cbeb547f3c982c820794ec9cf431b133aba57",
            "isKey": false,
            "numCitedBy": 682,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract\nThe bilateral filter is a nonlinear filter that smoothes a signal while preserving strong edges. It has demonstrated great effectiveness for a variety of problems in computer vision and computer graphics, and fast versions have been proposed. Unfortunately, little is known about the accuracy of such accelerations. In this paper, we propose a new signal-processing analysis of the bilateral filter which complements the recent studies that analyzed it as a PDE or as a robust statistical estimator. The key to our analysis is to express the filter in a higher-dimensional space where the signal intensity is added to the original domain dimensions. Importantly, this signal-processing perspective allows us to develop a novel bilateral filtering acceleration using downsampling in space and intensity. This affords a principled expression of accuracy in terms of bandwidth and sampling. The bilateral filter can be expressed as linear convolutions in this augmented space followed by two simple nonlinearities. This allows us to derive criteria for downsampling the key operations and achieving important acceleration of the bilateral filter. We show that, for the same running time, our method is more accurate than previous acceleration techniques. Typically, we are able to process a 2\u00a0megapixel image using our acceleration technique in less than a second, and have the result be visually similar to the exact computation that takes several tens of minutes. The acceleration is most effective with large spatial kernels. Furthermore, this approach extends naturally to color images and cross bilateral filtering.\n"
            },
            "slug": "A-Fast-Approximation-of-the-Bilateral-Filter-Using-Paris-Durand",
            "title": {
                "fragments": [],
                "text": "A Fast Approximation of the Bilateral Filter Using a Signal Processing Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new signal-processing analysis of the bilateral filter is proposed which complements the recent studies that analyzed it as a PDE or as a robust statistical estimator and develops a novel bilateral filtering acceleration using downsampling in space and intensity."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143794303"
                        ],
                        "name": "P. Willis",
                        "slug": "P.-Willis",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Willis",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Willis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 41371454,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "348dd599a9aa37688815a90fbb859c3cfa5f79c5",
            "isKey": false,
            "numCitedBy": 13,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Alpha colours were introduced for image compositing, using a pixel coverage model. Algebraically they resemble homogeneous coordinates, widely used in projective geometry calculations. We show why this is the case. This allows us to extend alpha beyond compositing, to all colour calculations regardless of whether pixels are involved and without the need for a coverage model. Our approach includes multi\u2010channel spectral calculations and removes the need for 7 channel and 6 channel alpha colour operations. It provides a unified explanation of pre\u2010multiplied and non pre\u2010multiplied colours, including negative coordinates and infinite points in colour space. It permits filter and illumination operations. It unifies the three existing significant compositing models in a single framework. It achieves this with a physically\u2010plausible energy basis."
            },
            "slug": "Projective-Alpha-Colour-Willis",
            "title": {
                "fragments": [],
                "text": "Projective Alpha Colour"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work provides a unified explanation of pre\u2010multiplied and non pre\u2010 multiplied colours, including negative coordinates and infinite points in colour space, and unifies the three existing significant compositing models in a single framework with a physically\u2010plausible energy basis."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Graph. Forum"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40656963"
                        ],
                        "name": "Soonmin Bae",
                        "slug": "Soonmin-Bae",
                        "structuredName": {
                            "firstName": "Soonmin",
                            "lastName": "Bae",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Soonmin Bae"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145799132"
                        ],
                        "name": "Sylvain Paris",
                        "slug": "Sylvain-Paris",
                        "structuredName": {
                            "firstName": "Sylvain",
                            "lastName": "Paris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sylvain Paris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145403226"
                        ],
                        "name": "F. Durand",
                        "slug": "F.-Durand",
                        "structuredName": {
                            "firstName": "Fr\u00e9do",
                            "lastName": "Durand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Durand"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 262,
                                "start": 247
                            }
                        ],
                        "text": "\u2026large-scale base layer and a detail layer for tone mapping [Durand and Dorsey 2002], flash/no-flash image fusion [Petschnigg et al. 2004; Eisemann and Durand 2004], and a wealth of other appli-\ncations [Bennett and McMillan 2005; Xiao et al. 2006; Bae et al. 2006; Winnemo\u0308ller et al. 2006]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13421812,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "33a23e37be8402b51a1d74b2254b2723741223dd",
            "isKey": false,
            "numCitedBy": 198,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new approach to tone management for photographs. Whereas traditional tone-mapping operators target a neutral and faithful rendition of the input image, we explore pictorial looks by controlling visual qualities such as the tonal balance and the amount of detail. Our method is based on a two-scale non-linear decomposition of an image. We modify the different layers based on their histograms and introduce a technique that controls the spatial variation of detail. We introduce a Poisson correction that prevents potential gradient reversal and preserves detail. In addition to directly controlling the parameters, the user can transfer the look of a model photograph to the picture being edited."
            },
            "slug": "Two-scale-tone-management-for-photographic-look-Bae-Paris",
            "title": {
                "fragments": [],
                "text": "Two-scale tone management for photographic look"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work introduces a Poisson correction that prevents potential gradient reversal and preserves detail, and introduces a technique that controls the spatial variation of detail in the two-scale non-linear decomposition of an image."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH '06"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3532952"
                        ],
                        "name": "D. Barash",
                        "slug": "D.-Barash",
                        "structuredName": {
                            "firstName": "Danny",
                            "lastName": "Barash",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Barash"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16459918,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "3d6e4a68f3f0d6a803a3dd30138aa92ca62f96db",
            "isKey": false,
            "numCitedBy": 569,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, the relationship between bilateral filtering and anisotropic diffusion is examined. The bilateral filtering approach represents a large class of nonlinear digital image filters. We first explore the connection between anisotropic diffusion and adaptive smoothing, and then the connection between adaptive smoothing and bilateral filtering. Previously, adaptive smoothing was considered to be an inconsistent approximation to the nonlinear diffusion equation. We extend adaptive smoothing to make it consistent, thus enabling a unified viewpoint that relates nonlinear digital image filters and the nonlinear diffusion equation."
            },
            "slug": "A-Fundamental-Relationship-between-Bilateral-and-Barash",
            "title": {
                "fragments": [],
                "text": "A Fundamental Relationship between Bilateral Filtering, Adaptive Smoothing, and the Nonlinear Diffusion Equation"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716722"
                        ],
                        "name": "D. DeCarlo",
                        "slug": "D.-DeCarlo",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "DeCarlo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. DeCarlo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144341195"
                        ],
                        "name": "A. Santella",
                        "slug": "A.-Santella",
                        "structuredName": {
                            "firstName": "Anthony",
                            "lastName": "Santella",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Santella"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13614730,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "8da5d20ad02700a764019ebf1c8ccf10191e3243",
            "isKey": false,
            "numCitedBy": 568,
            "numCiting": 71,
            "paperAbstract": {
                "fragments": [],
                "text": "Good information design depends on clarifying the meaningful structure in an image. We describe a computational approach to stylizing and abstracting photographs that explicitly responds to this design goal. Our system transforms images into a line-drawing style using bold edges and large regions of constant color. To do this, it represents images as a hierarchical structure of parts and boundaries computed using state-of-the-art computer vision. Our system identifies the meaningful elements of this structure using a model of human perception and a record of a user's eye movements in looking at the photo; the system renders a new image using transformations that preserve and highlight these visual elements. Our method thus represents a new alternative for non-photorealistic rendering both in its visual style, in its approach to visual form, and in its techniques for interaction."
            },
            "slug": "Stylization-and-abstraction-of-photographs-DeCarlo-Santella",
            "title": {
                "fragments": [],
                "text": "Stylization and abstraction of photographs"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This work describes a computational approach to stylizing and abstracting photographs that explicitly responds to the design goal of good information design and represents a new alternative for non-photorealistic rendering both in its visual style, in its approach to visual form, and in its techniques for interaction."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Graph."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3086603"
                        ],
                        "name": "N. Goodnight",
                        "slug": "N.-Goodnight",
                        "structuredName": {
                            "firstName": "Nolan",
                            "lastName": "Goodnight",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Goodnight"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2266717"
                        ],
                        "name": "Cliff Woolley",
                        "slug": "Cliff-Woolley",
                        "structuredName": {
                            "firstName": "Cliff",
                            "lastName": "Woolley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cliff Woolley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143966148"
                        ],
                        "name": "G. Lewin",
                        "slug": "G.-Lewin",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Lewin",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Lewin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10127169"
                        ],
                        "name": "D. Luebke",
                        "slug": "D.-Luebke",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Luebke",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Luebke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66542640"
                        ],
                        "name": "G. Humphreys",
                        "slug": "G.-Humphreys",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Humphreys",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Humphreys"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7644631,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "51975981e993eb25ffcf0650ac80fa9b8c424445",
            "isKey": false,
            "numCitedBy": 261,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a case study in the application of graphics hardware to general-purpose numeric computing. Specifically, we describe a system, built on programmable graphics hardware, able to solve a variety of partial differential equations with complex boundary conditions. Many areas of graphics, simulation, and computational science require efficient techniques for solving such equations. Our system implements the multigrid method, a fast and popular approach to solving large boundary value problems. We demonstrate the viability of this technique by using it to accelerate three applications: simulation of heat transfer, modeling of fluid mechanics, and tone mapping of high dynamic range images. We analyze the performance of our solver and discuss several issues, including techniques for improving the computational efficiency of iterative grid-based computations for the GPU."
            },
            "slug": "A-multigrid-solver-for-boundary-value-problems-Goodnight-Woolley",
            "title": {
                "fragments": [],
                "text": "A multigrid solver for boundary value problems using programmable graphics hardware"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A system, built on programmable graphics hardware, able to solve a variety of partial differential equations with complex boundary conditions, and implements the multigrid method, a fast and popular approach to solving large boundary value problems."
            },
            "venue": {
                "fragments": [],
                "text": "HWWS '03"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685272"
                        ],
                        "name": "J. Blinn",
                        "slug": "J.-Blinn",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Blinn",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Blinn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 84
                            }
                        ],
                        "text": "It is also similar to the homogeneous interpretation of premultiplied alpha colors [Blinn 1996; Willis 2006]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 70
                            }
                        ],
                        "text": "Filling: For each pixel at position (x, y):\n\u0393 ([x/ss] , [y/ss] , [I(x, y)/sr]) += (I(x, y), 1)\nwhere [ \u00b7 ] is the closest-integer operator."
                    },
                    "intents": []
                }
            ],
            "corpusId": 28313484,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "f7e65777a532701d883592e2c197056219a69660",
            "isKey": false,
            "numCitedBy": 6,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "The computer graphics universe consists of pixels. Pixels, in turn, consist of components: red, green, blue, and the coverage or opacity value alpha. For various reasons it is convenient to store and process a given rgb/spl alpha/ quadruple with the rgb values already multiplied by /spl alpha/. This was first pointed out in the original Porter-Duff compositing paper (1984) and I presented some further justifications in an earlier column (\"Image Compositing-Theory\", ibid., p.83-7, Sept. 1994). This premultiplication has some other interesting implications, and that's what I discuss this time."
            },
            "slug": "Fun-with-premultiplied-alpha-Blinn",
            "title": {
                "fragments": [],
                "text": "Fun with premultiplied alpha"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This column discusses premultiplication, which is convenient to store and process a given rgb/spl alpha/ quadruple with the rgb values already multiplied by /spl alpha/."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Computer Graphics and Applications"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2228323"
                        ],
                        "name": "M. Felsberg",
                        "slug": "M.-Felsberg",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Felsberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Felsberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1934088"
                        ],
                        "name": "Per-Erik Forss\u00e9n",
                        "slug": "Per-Erik-Forss\u00e9n",
                        "structuredName": {
                            "firstName": "Per-Erik",
                            "lastName": "Forss\u00e9n",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Per-Erik Forss\u00e9n"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725647"
                        ],
                        "name": "H. Scharr",
                        "slug": "H.-Scharr",
                        "structuredName": {
                            "firstName": "Hanno",
                            "lastName": "Scharr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Scharr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15670766,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "92f3ced8bcba8514c9afe8ac3de736ee374302cd",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present a new and efficient method to implement robust smoothing of low-level signal features: B-spline channel smoothing. This method consists of three steps: encoding of the signal features into channels, averaging of the channels, and decoding of the channels. We show that linear smoothing of channels is equivalent to robust smoothing of the signal features if we make use of quadratic B-splines to generate the channels. The linear decoding from B-spline channels allows the derivation of a robust error norm, which is very similar to Tukey's biweight error norm. We compare channel smoothing with three other robust smoothing techniques: nonlinear diffusion, bilateral filtering, and mean-shift filtering, both theoretically and on a 2D orientation-data smoothing task. Channel smoothing is found to be superior in four respects: it has a lower computational complexity, it is easy to implement, it chooses the global minimum error instead of the nearest local minimum, and it can also be used on nonlinear spaces, such as orientation space."
            },
            "slug": "Channel-smoothing:-efficient-robust-smoothing-of-Felsberg-Forss\u00e9n",
            "title": {
                "fragments": [],
                "text": "Channel smoothing: efficient robust smoothing of low-level signal features"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Channel smoothing is found to be superior in four respects: it has a lower computational complexity, it is easy to implement, it chooses the global minimum error instead of the nearest local minimum, and it can also be used on nonlinear spaces, such as orientation space."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684384"
                        ],
                        "name": "Dani Lischinski",
                        "slug": "Dani-Lischinski",
                        "structuredName": {
                            "firstName": "Dani",
                            "lastName": "Lischinski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dani Lischinski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709900"
                        ],
                        "name": "Zeev Farbman",
                        "slug": "Zeev-Farbman",
                        "structuredName": {
                            "firstName": "Zeev",
                            "lastName": "Farbman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zeev Farbman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143711233"
                        ],
                        "name": "M. Uyttendaele",
                        "slug": "M.-Uyttendaele",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Uyttendaele",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Uyttendaele"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717841"
                        ],
                        "name": "R. Szeliski",
                        "slug": "R.-Szeliski",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Szeliski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Szeliski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12568445,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1bf3ad795c2452addc2621664948fd3144c82bb7",
            "isKey": false,
            "numCitedBy": 322,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new interactive tool for making local adjustments of tonal values and other visual parameters in an image. Rather than carefully selecting regions or hand-painting layer masks, the user quickly indicates regions of interest by drawing a few simple brush strokes and then uses sliders to adjust the brightness, contrast, and other parameters in these regions. The effects of the user's sparse set of constraints are interpolated to the entire image using an edge-preserving energy minimization method designed to prevent the propagation of tonal adjustments to regions of significantly different luminance. The resulting system is suitable for adjusting ordinary and high dynamic range images, and provides the user with much more creative control than existing tone mapping algorithms. Our tool is also able to produce a tone mapping automatically, which may serve as a basis for further local adjustments, if so desired. The constraint propagation approach developed in this paper is a general one, and may also be used to interactively control a variety of other adjustments commonly performed in the digital darkroom."
            },
            "slug": "Interactive-local-adjustment-of-tonal-values-Lischinski-Farbman",
            "title": {
                "fragments": [],
                "text": "Interactive local adjustment of tonal values"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The user's sparse set of constraints are interpolated to the entire image using an edge-preserving energy minimization method designed to prevent the propagation of tonal adjustments to regions of significantly different luminance."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH '06"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38551815"
                        ],
                        "name": "Anat Levin",
                        "slug": "Anat-Levin",
                        "structuredName": {
                            "firstName": "Anat",
                            "lastName": "Levin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anat Levin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1403920739"
                        ],
                        "name": "A. Rav-Acha",
                        "slug": "A.-Rav-Acha",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Rav-Acha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rav-Acha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684384"
                        ],
                        "name": "Dani Lischinski",
                        "slug": "Dani-Lischinski",
                        "structuredName": {
                            "firstName": "Dani",
                            "lastName": "Lischinski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dani Lischinski"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1288223,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23e811c0d4165b38aecbc27d6d0a525f0cc50f58",
            "isKey": false,
            "numCitedBy": 318,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "We present spectral matting: a new approach to natural image matting that automatically computes a basis set of fuzzy matting components from the smallest eigenvectors of a suitably defined Laplacian matrix. Thus, our approach extends spectral segmentation techniques, whose goal is to extract hard segments, to the extraction of soft matting components. These components may then be used as building blocks to easily construct semantically meaningful foreground mattes, either in an unsupervised fashion, or based on a small amount of user input."
            },
            "slug": "Spectral-Matting-Levin-Rav-Acha",
            "title": {
                "fragments": [],
                "text": "Spectral Matting"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055460158"
                        ],
                        "name": "John Hart",
                        "slug": "John-Hart",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John Hart"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 64813808,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6cae8a08979c34110a85428f06c973b38828eac6",
            "isKey": false,
            "numCitedBy": 1478,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "ACM-Transactions-on-Graphics-Hart",
            "title": {
                "fragments": [],
                "text": "ACM Transactions on Graphics"
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH 2004"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767791"
                        ],
                        "name": "B. Oh",
                        "slug": "B.-Oh",
                        "structuredName": {
                            "firstName": "Byong",
                            "lastName": "Oh",
                            "middleNames": [
                                "Mok"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Oh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108828899"
                        ],
                        "name": "Max Chen",
                        "slug": "Max-Chen",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Max Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143607090"
                        ],
                        "name": "J. Dorsey",
                        "slug": "J.-Dorsey",
                        "structuredName": {
                            "firstName": "Julie",
                            "lastName": "Dorsey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dorsey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145403226"
                        ],
                        "name": "F. Durand",
                        "slug": "F.-Durand",
                        "structuredName": {
                            "firstName": "Fr\u00e9do",
                            "lastName": "Durand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Durand"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 52810271,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "30fbf8f722a41e19ff611290f6aab6dd8ce829c3",
            "isKey": false,
            "numCitedBy": 397,
            "numCiting": 206,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an image-based modeling and editing system that takes a single photo as input. We represent a scene as a layered collection of depth images, where each pixel encodes both color and depth. Starting from an input image, we employ a suite of user-assisted techniques, based on a painting metaphor, to assign depths and extract layers. We introduce two specific editing operations. The first, a \u201cclone brushing tool,\u201d permits the distortion-free copying of parts of a picture, by using a parameterization optimization technique. The second, a \u201ctexture-illuminance decoupling filter,\u201d discounts the effect of illumination on uniformly textured areas, by decoupling large- and small-scale features via bilateral filtering. Our system enables editing from different viewpoints, extracting and grouping of image-based objects, and modifying the shape, color, and illumination of these objects."
            },
            "slug": "Image-based-modeling-and-photo-editing-Oh-Chen",
            "title": {
                "fragments": [],
                "text": "Image-based modeling and photo editing"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "An image-based modeling and editing system that takes a single photo as input and employs a suite of user-assisted techniques, based on a painting metaphor, to assign depths and extract layers, enabling editing from different viewpoints and modifying the shape, color, and illumination of these objects."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 87
                            }
                        ],
                        "text": "Since the vertex processor is the only unit that can perform a true scatter operation [Harris and Luebke 2004], we rasterize a vertex array of single pixel points and use a vertex shader to determine the output position."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "GPGPU"
            },
            "venue": {
                "fragments": [],
                "text": "Course notes of the ACM SIGGRAPH conference."
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Course notes of the ACM SIGGRAPH conference"
            },
            "venue": {
                "fragments": [],
                "text": "Course notes of the ACM SIGGRAPH conference"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 287,
                                "start": 264
                            }
                        ],
                        "text": "\u2026large-scale base layer and a detail layer for tone mapping [Durand and Dorsey 2002], flash/no-flash image fusion [Petschnigg et al. 2004; Eisemann and Durand 2004], and a wealth of other appli-\ncations [Bennett and McMillan 2005; Xiao et al. 2006; Bae et al. 2006; Winnemo\u0308ller et al. 2006]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Realtime video abstraction"
            },
            "venue": {
                "fragments": [],
                "text": "ACM Transactions on Graphics 25, 3, 1221 \u2013 1226. Proceedings of the ACM SIGGRAPH conference."
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Realtime video abstraction"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the ACM SIGGRAPH conference"
            },
            "year": 2006
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 4,
            "methodology": 2,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 31,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/Real-time-edge-aware-image-processing-with-the-grid-Chen-Paris/4ef0a1200a1d9e69a291184d5c4c7cffc562135f?sort=total-citations"
}