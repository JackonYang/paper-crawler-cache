{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7377735"
                        ],
                        "name": "Yunji Chen",
                        "slug": "Yunji-Chen",
                        "structuredName": {
                            "firstName": "Yunji",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yunji Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068286576"
                        ],
                        "name": "Tao Luo",
                        "slug": "Tao-Luo",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39419985"
                        ],
                        "name": "Shaoli Liu",
                        "slug": "Shaoli-Liu",
                        "structuredName": {
                            "firstName": "Shaoli",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoli Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145407329"
                        ],
                        "name": "Shijin Zhang",
                        "slug": "Shijin-Zhang",
                        "structuredName": {
                            "firstName": "Shijin",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shijin Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37167270"
                        ],
                        "name": "Liqiang He",
                        "slug": "Liqiang-He",
                        "structuredName": {
                            "firstName": "Liqiang",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liqiang He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110368816"
                        ],
                        "name": "Jia Wang",
                        "slug": "Jia-Wang",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3353457"
                        ],
                        "name": "Ling Li",
                        "slug": "Ling-Li",
                        "structuredName": {
                            "firstName": "Ling",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ling Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144049725"
                        ],
                        "name": "Tianshi Chen",
                        "slug": "Tianshi-Chen",
                        "structuredName": {
                            "firstName": "Tianshi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianshi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719934"
                        ],
                        "name": "Zhiwei Xu",
                        "slug": "Zhiwei-Xu",
                        "structuredName": {
                            "firstName": "Zhiwei",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhiwei Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145550877"
                        ],
                        "name": "Ninghui Sun",
                        "slug": "Ninghui-Sun",
                        "structuredName": {
                            "firstName": "Ninghui",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ninghui Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731764"
                        ],
                        "name": "O. Temam",
                        "slug": "O.-Temam",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Temam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Temam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 8
                            }
                        ],
                        "text": "DianNao [7, 8] is one such example, which effectively accelerates representative neural network algorithms to benefit different ML scenarios (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6838992,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4157ed3db4c656854e69931cb6089b64b08784b9",
            "isKey": false,
            "numCitedBy": 1065,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "Many companies are deploying services, either for consumers or industry, which are largely based on machine-learning algorithms for sophisticated processing of large amounts of data. The state-of-the-art and most popular such machine-learning algorithms are Convolutional and Deep Neural Networks (CNNs and DNNs), which are known to be both computationally and memory intensive. A number of neural network accelerators have been recently proposed which can offer high computational capacity/area ratio, but which remain hampered by memory accesses. However, unlike the memory wall faced by processors on general-purpose workloads, the CNNs and DNNs memory footprint, while large, is not beyond the capability of the on chip storage of a multi-chip system. This property, combined with the CNN/DNN algorithmic characteristics, can lead to high internal bandwidth and low external communications, which can in turn enable high-degree parallelism at a reasonable area cost. In this article, we introduce a custom multi-chip machine-learning architecture along those lines. We show that, on a subset of the largest known neural network layers, it is possible to achieve a speedup of 450.65x over a GPU, and reduce the energy by 150.31x on average for a 64-chip system. We implement the node down to the place and route at 28nm, containing a combination of custom storage and computational units, with industry-grade interconnects."
            },
            "slug": "DaDianNao:-A-Machine-Learning-Supercomputer-Chen-Luo",
            "title": {
                "fragments": [],
                "text": "DaDianNao: A Machine-Learning Supercomputer"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This article introduces a custom multi-chip machine-learning architecture, showing that, on a subset of the largest known neural network layers, it is possible to achieve a speedup of 450.65x over a GPU, and reduce the energy by 150.31x on average for a 64-chip system."
            },
            "venue": {
                "fragments": [],
                "text": "2014 47th Annual IEEE/ACM International Symposium on Microarchitecture"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3080400"
                        ],
                        "name": "Abhinandan Majumdar",
                        "slug": "Abhinandan-Majumdar",
                        "structuredName": {
                            "firstName": "Abhinandan",
                            "lastName": "Majumdar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abhinandan Majumdar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2468150"
                        ],
                        "name": "S. Cadambi",
                        "slug": "S.-Cadambi",
                        "structuredName": {
                            "firstName": "Srihari",
                            "lastName": "Cadambi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Cadambi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2948456"
                        ],
                        "name": "M. Becchi",
                        "slug": "M.-Becchi",
                        "structuredName": {
                            "firstName": "Michela",
                            "lastName": "Becchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Becchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752242"
                        ],
                        "name": "S. Chakradhar",
                        "slug": "S.-Chakradhar",
                        "structuredName": {
                            "firstName": "Srimat",
                            "lastName": "Chakradhar",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chakradhar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775043"
                        ],
                        "name": "H. Graf",
                        "slug": "H.-Graf",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Graf",
                            "middleNames": [
                                "Peter"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Graf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 170
                            }
                        ],
                        "text": "proposed an accelerator called MAPLE which can accelerate matrix/vector operation and ranking used in five ML technique families (including neural network, SVM, k-means) [27, 28]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12757959,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "53f0a82495bf6f4d1a265aeeaeee0f11695741ec",
            "isKey": false,
            "numCitedBy": 42,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Applications that use learning and classification algorithms operate on large amounts of unstructured data, and have stringent performance constraints. For such applications, the performance of general purpose processors scales poorly with data size because of their limited support for fine-grained parallelism and absence of software-managed caches. The large intermediate data in these applications also limits achievable performance on many-core processors such as GPUs. To accelerate such learning applications, we present a programmable accelerator that can execute multiple learning and classification algorithms. To architect such an accelerator, we profile five representative workloads, and find that their computationally intensive portions can be formulated as matrix or vector operations generating large amounts of intermediate data, which are then reduced by a secondary operation such as array ranking, finding max/min and aggregation. Our proposed accelerator, called MAPLE, has hundreds of simple processing elements (PEs) laid out in a two-dimensional grid, with two key features. First, it uses dynamic in-memory processing where on-chip memory blocks perform the secondary reduction operations. Second, MAPLE uses banked off-chip memory, and organizes its PEs into independent groups each with its own off-chip memory bank. These two features allow MAPLE to scale its performance with data size. We also present an Atom based energy-efficient heterogeneous system with MAPLE as the accelerator that satisfies the application\u2019s performance requirements at a lower system power. This article describes the MAPLE architecture, explores its design space with a simulator, illustrates how to automatically map application kernels to the hardware, and presents its performance improvement and energy benefits over classic server-based implementations. We implement a 512-PE FPGA prototype of MAPLE and find that it is 1.5-10x faster than a 2.5 GHz quad-core Xeon processor despite running at a modest 125 MHz clock rate. With MAPLE connected to a 1.6GHz dual-core Atom, we show an energy improvement of 38-84% over the Xeon server coupled to a 1.3 GHz 240 core Tesla GPU."
            },
            "slug": "A-Massively-Parallel,-Energy-Efficient-Programmable-Majumdar-Cadambi",
            "title": {
                "fragments": [],
                "text": "A Massively Parallel, Energy Efficient Programmable Accelerator for Learning and Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The MAPLE architecture is described, its design space is explored with a simulator, how to automatically map application kernels to the hardware is illustrated, and its performance improvement and energy benefits over classic server-based implementations are presented."
            },
            "venue": {
                "fragments": [],
                "text": "TACO"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144049725"
                        ],
                        "name": "Tianshi Chen",
                        "slug": "Tianshi-Chen",
                        "structuredName": {
                            "firstName": "Tianshi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianshi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678776"
                        ],
                        "name": "Zidong Du",
                        "slug": "Zidong-Du",
                        "structuredName": {
                            "firstName": "Zidong",
                            "lastName": "Du",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zidong Du"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145550877"
                        ],
                        "name": "Ninghui Sun",
                        "slug": "Ninghui-Sun",
                        "structuredName": {
                            "firstName": "Ninghui",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ninghui Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110368816"
                        ],
                        "name": "Jia Wang",
                        "slug": "Jia-Wang",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7514065"
                        ],
                        "name": "Chengyong Wu",
                        "slug": "Chengyong-Wu",
                        "structuredName": {
                            "firstName": "Chengyong",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chengyong Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7377735"
                        ],
                        "name": "Yunji Chen",
                        "slug": "Yunji-Chen",
                        "structuredName": {
                            "firstName": "Yunji",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yunji Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731764"
                        ],
                        "name": "O. Temam",
                        "slug": "O.-Temam",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Temam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Temam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207209696,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22e477a9fdde86ab1f8f4dafdb4d88ea37e31fbd",
            "isKey": false,
            "numCitedBy": 1235,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Machine-Learning tasks are becoming pervasive in a broad range of domains, and in a broad range of systems (from embedded systems to data centers). At the same time, a small set of machine-learning algorithms (especially Convolutional and Deep Neural Networks, i.e., CNNs and DNNs) are proving to be state-of-the-art across many applications. As architectures evolve towards heterogeneous multi-cores composed of a mix of cores and accelerators, a machine-learning accelerator can achieve the rare combination of efficiency (due to the small number of target algorithms) and broad application scope. Until now, most machine-learning accelerator designs have focused on efficiently implementing the computational part of the algorithms. However, recent state-of-the-art CNNs and DNNs are characterized by their large size. In this study, we design an accelerator for large-scale CNNs and DNNs, with a special emphasis on the impact of memory on accelerator design, performance and energy. We show that it is possible to design an accelerator with a high throughput, capable of performing 452 GOP/s (key NN operations such as synaptic weight multiplications and neurons outputs additions) in a small footprint of 3.02 mm2 and 485 mW; compared to a 128-bit 2GHz SIMD processor, the accelerator is 117.87x faster, and it can reduce the total energy by 21.08x. The accelerator characteristics are obtained after layout at 65 nm. Such a high throughput in a small footprint can open up the usage of state-of-the-art machine-learning algorithms in a broad set of systems and for a broad set of applications."
            },
            "slug": "DianNao:-a-small-footprint-high-throughput-for-Chen-Du",
            "title": {
                "fragments": [],
                "text": "DianNao: a small-footprint high-throughput accelerator for ubiquitous machine-learning"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This study designs an accelerator for large-scale CNNs and DNNs, with a special emphasis on the impact of memory on accelerator design, performance and energy, and shows that it is possible to design an accelerator with a high throughput, capable of performing 452 GOP/s in a small footprint."
            },
            "venue": {
                "fragments": [],
                "text": "ASPLOS 2014"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3080400"
                        ],
                        "name": "Abhinandan Majumdar",
                        "slug": "Abhinandan-Majumdar",
                        "structuredName": {
                            "firstName": "Abhinandan",
                            "lastName": "Majumdar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abhinandan Majumdar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2468150"
                        ],
                        "name": "S. Cadambi",
                        "slug": "S.-Cadambi",
                        "structuredName": {
                            "firstName": "Srihari",
                            "lastName": "Cadambi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Cadambi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752242"
                        ],
                        "name": "S. Chakradhar",
                        "slug": "S.-Chakradhar",
                        "structuredName": {
                            "firstName": "Srimat",
                            "lastName": "Chakradhar",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chakradhar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 170
                            }
                        ],
                        "text": "proposed an accelerator called MAPLE which can accelerate matrix/vector operation and ranking used in five ML technique families (including neural network, SVM, k-means) [27, 28]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12294721,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e09ea9ec2da26f483f442935b7c1ccdefaa41c3e",
            "isKey": false,
            "numCitedBy": 19,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Embedded learning applications in automobiles, surveillance, robotics, and defense are computationally intensive, and process large amounts of real-time data. Systems for such workloads have to balance stringent performance constraints within limited power budgets. High performance computer processing units (CPUs) and graphics processing units (GPUs) cannot be used in an embedded platform due to power issues. In this letter, we propose a low power heterogeneous system consisting of an Atom processor supported by multiple accelerators that target these workloads, and seek to find if such a system can satisfy performance requirements in an energy-efficient manner. We build our low-power system using an Atom processor, an ION, a GPU, and a field-programmable gate array (FPGA)-based custom accelerator, and study its performance and power characteristics using four representative workloads. With such a system, we show an energy improvement of 42-85% over a server comprising a 2.27 GHz quadcore Xeon coupled to a 1.3 GHz 240 core Tesla GPU."
            },
            "slug": "An-Energy-Efficient-Heterogeneous-System-for-and-Majumdar-Cadambi",
            "title": {
                "fragments": [],
                "text": "An Energy-Efficient Heterogeneous System for Embedded Learning and Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This letter builds a low-power system using an Atom processor, an ION, a GPU, and a field-programmable gate array (FPGA)-based custom accelerator, and study its performance and power characteristics using four representative workloads."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Embedded Systems Letters"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2711977"
                        ],
                        "name": "George Teodoro",
                        "slug": "George-Teodoro",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Teodoro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George Teodoro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109467387"
                        ],
                        "name": "R. S. Oliveira",
                        "slug": "R.-S.-Oliveira",
                        "structuredName": {
                            "firstName": "Rafael",
                            "lastName": "Oliveira",
                            "middleNames": [
                                "Sachetto"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. S. Oliveira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3291200"
                        ],
                        "name": "O. Sertel",
                        "slug": "O.-Sertel",
                        "structuredName": {
                            "firstName": "Olcay",
                            "lastName": "Sertel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Sertel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797197"
                        ],
                        "name": "M. G\u00fcrcan",
                        "slug": "M.-G\u00fcrcan",
                        "structuredName": {
                            "firstName": "Metin",
                            "lastName": "G\u00fcrcan",
                            "middleNames": [
                                "Nafi"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. G\u00fcrcan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691267"
                        ],
                        "name": "Wagner Meira Jr",
                        "slug": "Wagner-Meira-Jr",
                        "structuredName": {
                            "firstName": "Wagner",
                            "lastName": "Meira Jr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wagner Meira Jr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710813"
                        ],
                        "name": "\u00dcmit V. \u00c7ataly\u00fcrek",
                        "slug": "\u00dcmit-V.-\u00c7ataly\u00fcrek",
                        "structuredName": {
                            "firstName": "\u00dcmit",
                            "lastName": "\u00c7ataly\u00fcrek",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "\u00dcmit V. \u00c7ataly\u00fcrek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145897855"
                        ],
                        "name": "R. Ferreira",
                        "slug": "R.-Ferreira",
                        "structuredName": {
                            "firstName": "Renato",
                            "lastName": "Ferreira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Ferreira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 87
                            }
                        ],
                        "text": "This result complies with two recent investigations which reported GPU to have 15x-49x [38] and 10x-60x [9] speedups over SIMD CPU for ML applications."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 18062455,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d31f7645751573fcac75a727df03c4b5d5389bd0",
            "isKey": false,
            "numCitedBy": 81,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "GPUs have recently evolved into very fast parallel co-processors capable of executing general purpose computations extremely efficiently. At the same time, multi-core CPUs evolution continued and today's CPUs have 4-8 cores. These two trends, however, have followed independent paths in the sense that we are aware of very few works that consider both devices cooperating to solve general computations. In this paper we investigate the coordinated use of CPU and GPU to improve efficiency of applications even further than using either device independently. We use Anthill runtime environment, a data-flow oriented framework in which applications are decomposed into a set of event-driven filters, where for each event, the runtime system can use either GPU or CPU for its processing. For evaluation, we use a histopathology application that uses image analysis techniques to classify tumor images for neuroblas-toma prognosis. Our experimental environment includes dual and octa-core machines, augmented with GPUs and we evaluate our approach's performance for standalone and distributed executions. Our experiments show that a pure GPU optimization of the application achieved a factor of 15 to 49 times improvement over the single core CPU version, depending on the versions of the CPUs and GPUs. We also show that the execution can be further reduced by a factor of about 2 by using our runtime system that effectively choreographs the execution to run cooperatively both on GPU and on a single core of CPU. We improve on that by adding more cores, all of which were previously neglected or used ineffectively. In addition, the evaluation on a distributed environment has shown near linear scalability to multiple hosts."
            },
            "slug": "Coordinating-the-use-of-GPU-and-CPU-for-improving-Teodoro-Oliveira",
            "title": {
                "fragments": [],
                "text": "Coordinating the use of GPU and CPU for improving performance of compute intensive applications"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper investigates the coordinated use of CPU and GPU to improve efficiency of applications even further than using either device independently, using Anthill runtime environment, a data-flow oriented framework in which applications are decomposed into a set of event-driven filters."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE International Conference on Cluster Computing and Workshops"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2468150"
                        ],
                        "name": "S. Cadambi",
                        "slug": "S.-Cadambi",
                        "structuredName": {
                            "firstName": "Srihari",
                            "lastName": "Cadambi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Cadambi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1844230"
                        ],
                        "name": "Igor Durdanovic",
                        "slug": "Igor-Durdanovic",
                        "structuredName": {
                            "firstName": "Igor",
                            "lastName": "Durdanovic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Igor Durdanovic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2101580"
                        ],
                        "name": "V. Jakkula",
                        "slug": "V.-Jakkula",
                        "structuredName": {
                            "firstName": "Venkata",
                            "lastName": "Jakkula",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Jakkula"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2329060"
                        ],
                        "name": "M. Sankaradass",
                        "slug": "M.-Sankaradass",
                        "structuredName": {
                            "firstName": "Murugan",
                            "lastName": "Sankaradass",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sankaradass"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3165487"
                        ],
                        "name": "E. Cosatto",
                        "slug": "E.-Cosatto",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Cosatto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Cosatto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752242"
                        ],
                        "name": "S. Chakradhar",
                        "slug": "S.-Chakradhar",
                        "structuredName": {
                            "firstName": "Srimat",
                            "lastName": "Chakradhar",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chakradhar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775043"
                        ],
                        "name": "H. Graf",
                        "slug": "H.-Graf",
                        "structuredName": {
                            "firstName": "Hans",
                            "lastName": "Graf",
                            "middleNames": [
                                "Peter"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Graf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 75
                            }
                        ],
                        "text": "There are also many dedicated accelerators for k-Means [17, 22, 30] or SVM [4, 31], due to their broad applications in industry."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16813648,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c2ce21f7541af90add6ec99164d077a8d4d284f",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a massively parallel FPGA-based coprocessor for Support Vector Machines (SVMs), a machine learning algorithm whose applications include recognition tasks such as learning scenes, situations and concepts, and reasoning tasks such as analyzing the recognized scenes and semantics. The coprocessor architecture, targeted at both SVM training and classification, is based on clusters of vector processing elements (VPEs) operating in single-instruction multiple data (SIMD) mode to take advantage of large amounts of data parallelism in the application. We use the FPGA\u2019s DSP elements as parallel multiply-accumulators (MACs), a core computation in SVMs. A key feature of the architecture is that it is customized to low precision arithmetic which permits one DSP unit to perform two or more MACs in parallel. Low precision also reduces the required number of parallel off-chip memory accesses by packing multiple data words on the FPGA-memory bus. We have built a prototype using an off-the-shelf PCI-based FPGA card with a Xilinx Virtex 5 FPGA and 1GB DDR2 memory. For SVM training, we observe application-level end-to-end computation speeds of over 9 billion multiply-accumulates per second (GMACs). For SVM classification, using data packing, the application speed increases to 14 GMACs. The FPGA-based system is about 20x faster than a dual Opteron 2.2 GHz processor CPU, and dissipates around 10W of power."
            },
            "slug": "A-Massively-Parallel-FPGA-Based-Coprocessor-for-Cadambi-Durdanovic",
            "title": {
                "fragments": [],
                "text": "A Massively Parallel FPGA-Based Coprocessor for Support Vector Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "A massively parallel FPGA-based coprocessor for Support Vector Machines (SVMs), a machine learning algorithm whose applications include recognition tasks such as learning scenes, situations and concepts, and reasoning taskssuch as analyzing the recognized scenes and semantics is presented."
            },
            "venue": {
                "fragments": [],
                "text": "2009 17th IEEE Symposium on Field Programmable Custom Computing Machines"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3259377"
                        ],
                        "name": "E. Manolakos",
                        "slug": "E.-Manolakos",
                        "structuredName": {
                            "firstName": "Elias",
                            "lastName": "Manolakos",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Manolakos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2982820"
                        ],
                        "name": "I. Stamoulias",
                        "slug": "I.-Stamoulias",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Stamoulias",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Stamoulias"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 92
                            }
                        ],
                        "text": "Manolakos and Stamoulias designed two highperformance parallel array architectures for k-NN [29, 36]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8705960,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c430950a4d363928bbbeca5ada01f29d8407e073",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "We present the systematic design of two linear array IP cores for the k-nearest neighbor (k-NN) benchmark classifier. The need for real-time classification of data vectors with possibly thousands of features (dimensions) motivates the implementation of this widely used algorithm in hardware in order to achieve very high performance by exploiting block pipelining and parallel processing. The two linear array architectures that we designed have been described as soft IP cores in fully parameterizable VHDL that can be used to synthesize effortlessly different k-NN parallel architectures for any desirable combination of the problem size parameters. They have been evaluated for a large variety of parameter combinations and Xilinx FPGAs. It is shown that they can be used to solve efficiently very large size k-NN classification problems, even with thousands of training vectors or vector dimensions, using a single, moderate size FPGA device. Furthermore the FPGA implementations exceed by a factor of two the performance of optimized NVIDIA CUDA API software implementations for the powerful GeForce 8800GTX GPU."
            },
            "slug": "IP-cores-design-for-the-kNN-classifier-Manolakos-Stamoulias",
            "title": {
                "fragments": [],
                "text": "IP-cores design for the kNN classifier"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "The systematic design of two linear array IP cores for the k-nearest neighbor (k-NN) benchmark classifier are presented and it is shown that they can be used to solve efficiently very large size k-NN classification problems, even with thousands of training vectors or vector dimensions, using a single, moderate size FPGA device."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2010 IEEE International Symposium on Circuits and Systems"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2982820"
                        ],
                        "name": "I. Stamoulias",
                        "slug": "I.-Stamoulias",
                        "structuredName": {
                            "firstName": "Ioannis",
                            "lastName": "Stamoulias",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Stamoulias"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3259377"
                        ],
                        "name": "E. Manolakos",
                        "slug": "E.-Manolakos",
                        "structuredName": {
                            "firstName": "Elias",
                            "lastName": "Manolakos",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Manolakos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 92
                            }
                        ],
                        "text": "Manolakos and Stamoulias designed two highperformance parallel array architectures for k-NN [29, 36]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18769303,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3daf7f079546131b9616123e0e013e47344ec2e7",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We designed a variety of k-nearest-neighbor parallel architectures for FPGAs in the form of parameterizable soft IP cores. We show that they can be used to solve large classification problems with thousands of training vectors, or thousands of vector dimensions using a single FPGA, and achieve very high throughput. They can be used to flexibly synthesize architectures that also cover: 1NN classification (vector quantization), multishot queries (with different k), LOOCV cross-validation, and compare favorably to GPU implementations. To the best of our knowledge this is the first attempt to design flexible IP cores for the popular kNN classifier."
            },
            "slug": "Parallel-architectures-for-the-kNN-classifier-of-IP-Stamoulias-Manolakos",
            "title": {
                "fragments": [],
                "text": "Parallel architectures for the kNN classifier -- design of soft IP cores and FPGA implementations"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "This work designs a variety of k-nearest-neighbor parallel architectures for FPGAs in the form of parameterizable soft IP cores for the popular kNN classifier that can be used to solve large classification problems with thousands of training vectors, and achieve very high throughput."
            },
            "venue": {
                "fragments": [],
                "text": "TECS"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706809"
                        ],
                        "name": "Marc'Aurelio Ranzato",
                        "slug": "Marc'Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Marc'Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc'Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3089272"
                        ],
                        "name": "R. Monga",
                        "slug": "R.-Monga",
                        "structuredName": {
                            "firstName": "Rajat",
                            "lastName": "Monga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Monga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145139947"
                        ],
                        "name": "Matthieu Devin",
                        "slug": "Matthieu-Devin",
                        "structuredName": {
                            "firstName": "Matthieu",
                            "lastName": "Devin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthieu Devin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32131713"
                        ],
                        "name": "G. Corrado",
                        "slug": "G.-Corrado",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Corrado",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Corrado"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118440152"
                        ],
                        "name": "Kai Chen",
                        "slug": "Kai-Chen",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "Recent debates on deep learning [24] even triggers the rebirth of hardware neural network [37], a hot topic in 1990s [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206741597,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72e93aa6767ee683de7f001fa72f1314e40a8f35",
            "isKey": false,
            "numCitedBy": 2112,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of building high-level, class-specific feature detectors from only unlabeled data. For example, is it possible to learn a face detector using only unlabeled images? To answer this, we train a deep sparse autoencoder on a large dataset of images (the model has 1 billion connections, the dataset has 10 million 200\u00d7200 pixel images downloaded from the Internet). We train this network using model parallelism and asynchronous SGD on a cluster with 1,000 machines (16,000 cores) for three days. Contrary to what appears to be a widely-held intuition, our experimental results reveal that it is possible to train a face detector without having to label images as containing a face or not. Control experiments show that this feature detector is robust not only to translation but also to scaling and out-of-plane rotation. We also find that the same network is sensitive to other high-level concepts such as cat faces and human bodies. Starting from these learned features, we trained our network to recognize 22,000 object categories from ImageNet and achieve a leap of 70% relative improvement over the previous state-of-the-art."
            },
            "slug": "Building-high-level-features-using-large-scale-Le-Ranzato",
            "title": {
                "fragments": [],
                "text": "Building high-level features using large scale unsupervised learning"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "Contrary to what appears to be a widely-held intuition, the experimental results reveal that it is possible to train a face detector without having to label images as containing a face or not."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE International Conference on Acoustics, Speech and Signal Processing"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731764"
                        ],
                        "name": "O. Temam",
                        "slug": "O.-Temam",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Temam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Temam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 90
                            }
                        ],
                        "text": "Recent debates on deep learning [24] even triggers the rebirth of hardware neural network [37], a hot topic in 1990s [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 22162503,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "174053deb839012191fc26aef2a42942d3b81e64",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "After the hype of the 1990s, where companies like Intel or Philips built commercial hardware systems based on neural networks, the approach quickly lost ground for multiple reasons: hardware neural networks were no match for software neural networks run on rapidly progressing general-purpose processors, their application scope was considered too limited, and even progress in machine-learning theory overshadowed neural networks. However, in the past few years, a remarkable convergence of trends and innovations is casting a new light on neural networks and could make them valuable components of future computing systems. Trends in technology call for architectures which can sustain a large number of defects, something neural networks are intrinsically capable of. Tends in applications, summarized in the recent RMS categorization, highlight a number of key algorithms which are eligible to neural networks implementations. At the same time, innovations in technology, such as the recent realization of a memristor, are creating the conditions for the efficient hardware implementation of neural networks. Innovations in machine learning, with the recent advent of Deep Networks, have revived interest in neural networks. Finally, recent findings in neurobiology carry even greater prospects, where detailed explanations of how complex functions, such as vision, can be implemented further open up the defect-tolerance and application potential of neural network architectures."
            },
            "slug": "The-rebirth-of-neural-networks-Temam",
            "title": {
                "fragments": [],
                "text": "The rebirth of neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A remarkable convergence of trends and innovations is casting a new light on neural networks, which could make them valuable components of future computing systems and open up the defect-tolerance and application potential of neural network architectures."
            },
            "venue": {
                "fragments": [],
                "text": "ISCA"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8919978"
                        ],
                        "name": "Markos Papadonikolakis",
                        "slug": "Markos-Papadonikolakis",
                        "structuredName": {
                            "firstName": "Markos",
                            "lastName": "Papadonikolakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Markos Papadonikolakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4408876"
                        ],
                        "name": "C. Bouganis",
                        "slug": "C.-Bouganis",
                        "structuredName": {
                            "firstName": "Christos-Savvas",
                            "lastName": "Bouganis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bouganis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 75
                            }
                        ],
                        "text": "There are also many dedicated accelerators for k-Means [17, 22, 30] or SVM [4, 31], due to their broad applications in industry."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2784932,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f4e372cdce030f95ec8208582ea04ed41496672",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Support Vector Machines is a powerful supervised learning tool. Its training phase, however, is a time-consuming task and heavily dependent on the training dataset size and dimensionality. In this work, we propose a scalable FPGA architecture for the acceleration of SVM training, which exploits the heterogeneous nature of the device and the diversities of the precision requirements among the dataset attributes. The maximum parallelization potential is obtained by maintaining the usage of DSPs and logic resources at the initial ratio of the FPGA device. The results demonstrate the efficiency of the heterogeneous architecture in both homogeneous and heterogeneous datasets. The proposed architecture outperforms other proposed designs by more than 6 times, in terms of raw computational speed."
            },
            "slug": "A-Heterogeneous-FPGA-Architecture-for-Support-Papadonikolakis-Bouganis",
            "title": {
                "fragments": [],
                "text": "A Heterogeneous FPGA Architecture for Support Vector Machine Training"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes a scalable FPGA architecture for the acceleration of SVM training, which exploits the heterogeneous nature of the device and the diversities of the precision requirements among the dataset attributes."
            },
            "venue": {
                "fragments": [],
                "text": "2010 18th IEEE Annual International Symposium on Field-Programmable Custom Computing Machines"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053262121"
                        ],
                        "name": "Vincent Garcia",
                        "slug": "Vincent-Garcia",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Garcia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Garcia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778070"
                        ],
                        "name": "E. Debreuve",
                        "slug": "E.-Debreuve",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Debreuve",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Debreuve"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144459223"
                        ],
                        "name": "M. Barlaud",
                        "slug": "M.-Barlaud",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Barlaud",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Barlaud"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 2
                            }
                        ],
                        "text": ", [18]), the efficiency is limited, because they spend too many efforts on flexibly supporting diverse application domains."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5981221,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "19d2b786fec5ded4d6cdca0e21f3c3f5264ecadf",
            "isKey": false,
            "numCitedBy": 515,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical measures coming from information theory represent interesting bases for image and video processing tasks such as image retrieval and video object tracking. For example, let us mention the entropy and the Kullback-Leibler divergence. Accurate estimation of these measures requires to adapt to the local sample density, especially if the data are high-dimensional. The k nearest neighbor (kNN) framework has been used to define efficient variable-bandwidth kernel-based estimators with such a locally adaptive property. Unfortunately, these estimators are computationally intensive since they rely on searching neighbors among large sets of d-dimensional vectors. This computational burden can be reduced by pre-structuring the data, e.g. using binary trees as proposed by the approximated nearest neighbor (ANN) library. Yet, the recent opening of graphics processing units (GPU) to general-purpose computation by means of the NVIDIA CUDA API offers the image and video processing community a powerful platform with parallel calculation capabilities. In this paper, we propose a CUDA implementation of the ldquobrute forcerdquo kNN search and we compare its performances to several CPU-based implementations including an equivalent brute force algorithm and ANN. We show a speed increase on synthetic and real data by up to one or two orders of magnitude depending on the data, with a quasi-linear behavior with respect to the data size in a given, practical range."
            },
            "slug": "Fast-k-nearest-neighbor-search-using-GPU-Garcia-Debreuve",
            "title": {
                "fragments": [],
                "text": "Fast k nearest neighbor search using GPU"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A CUDA implementation of the ldquobrute forcerdquo kNN search and it is shown a speed increase on synthetic and real data by up to one or two orders of magnitude depending on the data, with a quasi-linear behavior with respect to the data size in a given, practical range."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895356"
                        ],
                        "name": "D. Ciresan",
                        "slug": "D.-Ciresan",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Ciresan",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ciresan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2514691"
                        ],
                        "name": "U. Meier",
                        "slug": "U.-Meier",
                        "structuredName": {
                            "firstName": "Ueli",
                            "lastName": "Meier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "U. Meier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2426718"
                        ],
                        "name": "Jonathan Masci",
                        "slug": "Jonathan-Masci",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Masci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Masci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6803671"
                        ],
                        "name": "L. Gambardella",
                        "slug": "L.-Gambardella",
                        "structuredName": {
                            "firstName": "Luca",
                            "lastName": "Gambardella",
                            "middleNames": [
                                "Maria"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Gambardella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 104
                            }
                        ],
                        "text": "This result complies with two recent investigations which reported GPU to have 15x-49x [38] and 10x-60x [9] speedups over SIMD CPU for ML applications."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 904144,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a47ba057a858f8c024d2518cc3731fc7eb40de1",
            "isKey": false,
            "numCitedBy": 1188,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a fast, fully parameterizable GPU implementation of Convolutional Neural Network variants. Our feature extractors are neither carefully designed nor pre-wired, but rather learned in a supervised way. Our deep hierarchical architectures achieve the best published results on benchmarks for object classification (NORB, CIFAR10) and handwritten digit recognition (MNIST), with error rates of 2.53%, 19.51%, 0.35%, respectively. Deep nets trained by simple back-propagation perform better than more shallow ones. Learning is surprisingly rapid. NORB is completely trained within five epochs. Test error rates on MNIST drop to 2.42%, 0.97% and 0.48% after 1, 3 and 17 epochs, respectively."
            },
            "slug": "Flexible,-High-Performance-Convolutional-Neural-for-Ciresan-Meier",
            "title": {
                "fragments": [],
                "text": "Flexible, High Performance Convolutional Neural Networks for Image Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "A fast, fully parameterizable GPU implementation of Convolutional Neural Network variants and their feature extractors are neither carefully designed nor pre-wired, but rather learned in a supervised way."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503540"
                        ],
                        "name": "Hanaa M. Hussain",
                        "slug": "Hanaa-M.-Hussain",
                        "structuredName": {
                            "firstName": "Hanaa",
                            "lastName": "Hussain",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanaa M. Hussain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3212659"
                        ],
                        "name": "K. Benkrid",
                        "slug": "K.-Benkrid",
                        "structuredName": {
                            "firstName": "Khaled",
                            "lastName": "Benkrid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Benkrid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748166"
                        ],
                        "name": "H. Seker",
                        "slug": "H.-Seker",
                        "structuredName": {
                            "firstName": "Huseyin",
                            "lastName": "Seker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Seker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1805610"
                        ],
                        "name": "A. Erdogan",
                        "slug": "A.-Erdogan",
                        "structuredName": {
                            "firstName": "Ahmet",
                            "lastName": "Erdogan",
                            "middleNames": [
                                "Teyfik"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Erdogan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 55
                            }
                        ],
                        "text": "There are also many dedicated accelerators for k-Means [17, 22, 30] or SVM [4, 31], due to their broad applications in industry."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15135392,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a1913f293facdb8c6c162d5763b8b7743c1794d",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The Microarray is a technique used by biologists to perform many genome experiments simultaneously, which produces very large datasets. Analysis of these datasets is a challenge for scientists especially as the number of genome databases is increasing rapidly every year. K-means clustering is an unsupervised data mining technique used widely by bioinformaticians to analyze Microarray data. However, K-means can take between a few seconds to several days to process Microarray data depending on the size of these datasets. This puts a limit on the complexity of biological problems which can be asked by bioinfomaticians, and hence may result in an incomplete solution to the problem. In order to overcome such problems, we propose a highly parallel hardware design to accelerate the K-means clustering of Microarray data by implementing the K-means algorithm in Field Programmable Gate Arrays (FPGA). Our implementation is particularly suitable for server solution as it allows for processing many different datasets simultaneously. We have designed, and implemented five k-mean cores on Xilinx Virtex4 XC4VLX25 FPGA, and tested them on a sample of real Yeast Microarray data. Our design achieved about 51.7\u00d7 speed-up when compared to a software model while being 206.8\u00d7 more energy efficient."
            },
            "slug": "FPGA-implementation-of-K-means-algorithm-for-An-to-Hussain-Benkrid",
            "title": {
                "fragments": [],
                "text": "FPGA implementation of K-means algorithm for bioinformatics application: An accelerated approach to clustering Microarray data"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This work proposes a highly parallel hardware design to accelerate the K-means clustering of Microarray data by implementing the K -means algorithm in Field Programmable Gate Arrays (FPGA)."
            },
            "venue": {
                "fragments": [],
                "text": "2011 NASA/ESA Conference on Adaptive Hardware and Systems (AHS)"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256269"
                        ],
                        "name": "C. Farabet",
                        "slug": "C.-Farabet",
                        "structuredName": {
                            "firstName": "Cl\u00e9ment",
                            "lastName": "Farabet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Farabet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1940285"
                        ],
                        "name": "B. Martini",
                        "slug": "B.-Martini",
                        "structuredName": {
                            "firstName": "Berin",
                            "lastName": "Martini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Martini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2079955555"
                        ],
                        "name": "B. Corda",
                        "slug": "B.-Corda",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Corda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Corda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2447628"
                        ],
                        "name": "Polina Akselrod",
                        "slug": "Polina-Akselrod",
                        "structuredName": {
                            "firstName": "Polina",
                            "lastName": "Akselrod",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Polina Akselrod"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2889774"
                        ],
                        "name": "E. Culurciello",
                        "slug": "E.-Culurciello",
                        "structuredName": {
                            "firstName": "Eugenio",
                            "lastName": "Culurciello",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Culurciello"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 85
                            }
                        ],
                        "text": "In this trend, a number of successful neural network accelerators have been proposed [7, 15, 26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 851574,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "204710a6a6d935150b5b16daf74493dea6d1b7a2",
            "isKey": false,
            "numCitedBy": 349,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a scalable dataflow hardware architecture optimized for the computation of general-purpose vision algorithms \u2014 neuFlow \u2014 and a dataflow compiler \u2014 luaFlow \u2014 that transforms high-level flow-graph representations of these algorithms into machine code for neuFlow. This system was designed with the goal of providing real-time detection, categorization and localization of objects in complex scenes, while consuming 10 Watts when implemented on a Xilinx Virtex 6 FPGA platform, or about ten times less than a laptop computer, and producing speedups of up to 100 times in real-world applications. We present an application of the system on street scene analysis, segmenting 20 categories on 500 \u00d7 375 frames at 12 frames per second on our custom hardware neuFlow."
            },
            "slug": "NeuFlow:-A-runtime-reconfigurable-dataflow-for-Farabet-Martini",
            "title": {
                "fragments": [],
                "text": "NeuFlow: A runtime reconfigurable dataflow processor for vision"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A scalable dataflow hardware architecture optimized for the computation of general-purpose vision algorithms \u2014 neuFlow \u2014 and a dataflow compiler \u2014 luaFlow \u2014 that transforms high-level flow-graph representations of these algorithms into machine code for neu Flow are presented."
            },
            "venue": {
                "fragments": [],
                "text": "CVPR 2011 WORKSHOPS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2125286015"
                        ],
                        "name": "David E. Rumelhari",
                        "slug": "David-E.-Rumelhari",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhari",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David E. Rumelhari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2125288353"
                        ],
                        "name": "Geoffrey E. Hintont",
                        "slug": "Geoffrey-E.-Hintont",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hintont",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hintont"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "82961593"
                        ],
                        "name": "Ronald",
                        "slug": "Ronald",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Ronald",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2070444145"
                        ],
                        "name": "J.",
                        "slug": "J.",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "J.",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J."
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2058683052"
                        ],
                        "name": "Williams",
                        "slug": "Williams",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Williams",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 237368852,
            "fieldsOfStudy": [
                "Environmental Science"
            ],
            "id": "ae3fe34be9230c98b04d68b4621c89b7dbc2d717",
            "isKey": false,
            "numCitedBy": 1078,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "delineating the absolute indigeneity of amino acids in fossils. As AMS iechniques are refined to handle smaller samples, it may also become possible to date individual amino acid enantiomers by the \u00b0C method. If one enantiomer is entirely derived from the other by racemization during diagenesis, the individual Dp. and L-enantiomers for a given amino acid should have identical \u201cC ages. Older, more poorly preserved fossils may not always prove amenable to the determination of amino acid indigeneity by the stable isotope method, as the prospects for complete replacement of indigenous amino acids with non-indigenous amino acids increases with time. As non-indigenous amino acids undergo racemization, the enantiomers may have identical isotopic compositions and still not be related to the original organisms. Such a circumstance may, however, become easier to recognize as more information becomes available concerning the distribution and stable isotopic composition of the amino acid constituents of modern representatives of fossil organisms. Also, AMS dates on individual amino acid enantiomers may, in some cases, help to clarify indigeneity problems, in particular when stratigraphic controls can be used to estimate a general age range for the fossil in question. Finally, the development of techniques for determining the stable isotopic compasition of amino acid enantiomers may enable us to establish whether non-racemic amino acids in some carbonaceous meteorites\u201d are indigenous, or result in part from terrestrial contamination. M.H.E. thanks the NSF, Division of Earth Sciences (grant | EAR-8352085) and the folowing contributors to his Presidential Young Investigator Award for partial support of this research: LETTERSTONATURE 533"
            },
            "slug": "Learning-representations-by-backpropagating-errors-Rumelhari-Hintont",
            "title": {
                "fragments": [],
                "text": "Learning representations by backpropagating errors"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398987690"
                        ],
                        "name": "Ahmed Al-Maashri",
                        "slug": "Ahmed-Al-Maashri",
                        "structuredName": {
                            "firstName": "Ahmed",
                            "lastName": "Al-Maashri",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ahmed Al-Maashri"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723845"
                        ],
                        "name": "M. DeBole",
                        "slug": "M.-DeBole",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "DeBole",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. DeBole"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144490976"
                        ],
                        "name": "M. Cotter",
                        "slug": "M.-Cotter",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Cotter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Cotter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2916636"
                        ],
                        "name": "N. Chandramoorthy",
                        "slug": "N.-Chandramoorthy",
                        "structuredName": {
                            "firstName": "Nandhini",
                            "lastName": "Chandramoorthy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Chandramoorthy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409958726"
                        ],
                        "name": "Yang Xiao",
                        "slug": "Yang-Xiao",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Xiao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Xiao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733274"
                        ],
                        "name": "N. Vijaykrishnan",
                        "slug": "N.-Vijaykrishnan",
                        "structuredName": {
                            "firstName": "Narayanan",
                            "lastName": "Vijaykrishnan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Vijaykrishnan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143804422"
                        ],
                        "name": "C. Chakrabarti",
                        "slug": "C.-Chakrabarti",
                        "structuredName": {
                            "firstName": "Chaitali",
                            "lastName": "Chakrabarti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Chakrabarti"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 85
                            }
                        ],
                        "text": "In this trend, a number of successful neural network accelerators have been proposed [7, 15, 26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14878401,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29fc8380eccdd1b4e2f8d9dd8faac6a2c3906230",
            "isKey": false,
            "numCitedBy": 47,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Video analytics introduce new levels of intelligence to automated scene understanding. Neuromorphic algorithms, such as HMAX, are proposed as robust and accurate algorithms that mimic the processing in the visual cortex of the brain. HMAX, for instance, is a versatile algorithm that can be repurposed to target several visual recognition applications. This paper presents the design and evaluation of hardware accelerators for extracting visual features for universal recognition. The recognition applications include object recognition, face identification, facial expression recognition, and action recognition. These accelerators were validated on a multi-FPGA platform and significant performance enhancement and power efficiencies were demonstrated when compared to CMP and GPU platforms. Results demonstrate as much as 7.6X speedup and 12.8X more power-efficient performance when compared to those platforms."
            },
            "slug": "Accelerating-neuromorphic-vision-algorithms-for-Al-Maashri-DeBole",
            "title": {
                "fragments": [],
                "text": "Accelerating neuromorphic vision algorithms for recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "This paper presents the design and evaluation of hardware accelerators for extracting visual features for universal recognition and demonstrates significant performance enhancement and power efficiencies when compared to CMP and GPU platforms."
            },
            "venue": {
                "fragments": [],
                "text": "DAC Design Automation Conference 2012"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189092"
                        ],
                        "name": "John C. Platt",
                        "slug": "John-C.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Platt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685083"
                        ],
                        "name": "N. Cristianini",
                        "slug": "N.-Cristianini",
                        "structuredName": {
                            "firstName": "Nello",
                            "lastName": "Cristianini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cristianini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404459229"
                        ],
                        "name": "J. Shawe-Taylor",
                        "slug": "J.-Shawe-Taylor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shawe-Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shawe-Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 32
                            }
                        ],
                        "text": "The most time-consuming step in SMO is to compute the N \u00d7 N kernel matrix K (N is the total number of training instances), a symmetric matrix recording kernel function values of all possible pairs of training instances."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 184
                            }
                        ],
                        "text": "At the SVM training phase, the goal is finding appropriate coefficients \u03b1i that maximize the geometric margin, and a common training algorithm is Sequential Minimal Optimization (SMO) [32]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1204938,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "32484f6d111bf21f1395a34a087991a9041dd0ae",
            "isKey": false,
            "numCitedBy": 1878,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new learning architecture: the Decision Directed Acyclic Graph (DDAG), which is used to combine many two-class classifiers into a multiclass classifier. For an N-class problem, the DDAG contains N(N - 1)/2 classifiers, one for each pair of classes. We present a VC analysis of the case when the node classifiers are hyperplanes; the resulting bound on the test error depends on N and on the margin achieved at the nodes, but not on the dimension of the space. This motivates an algorithm, DAGSVM, which operates in a kernel-induced feature space and uses two-class maximal margin hyperplanes at each decision-node of the DDAG. The DAGSVM is substantially faster to train and evaluate than either the standard algorithm or Max Wins, while maintaining comparable accuracy to both of these algorithms."
            },
            "slug": "Large-Margin-DAGs-for-Multiclass-Classification-Platt-Cristianini",
            "title": {
                "fragments": [],
                "text": "Large Margin DAGs for Multiclass Classification"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An algorithm, DAGSVM, is presented, which operates in a kernel-induced feature space and uses two-class maximal margin hyperplanes at each decision-node of the DDAG, which is substantially faster to train and evaluate than either the standard algorithm or Max Wins, while maintaining comparable accuracy to both of these algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "We use MNIST [25] and UCI data [1] as benchmarks of ML techniques, see Table 4."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": false,
            "numCitedBy": 35624,
            "numCiting": 246,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117881943"
                        ],
                        "name": "Tong Zhang",
                        "slug": "Tong-Zhang",
                        "structuredName": {
                            "firstName": "Tong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tong Zhang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "Gradient descent is a common solution to this training task [41]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5306879,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0ef7d9e618cbb507d69f8ebcdc60b8a1f3135bff",
            "isKey": false,
            "numCitedBy": 1016,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Linear prediction methods, such as least squares for regression, logistic regression and support vector machines for classification, have been extensively used in statistics and machine learning. In this paper, we study stochastic gradient descent (SGD) algorithms on regularized forms of linear prediction methods. This class of methods, related to online algorithms such as perceptron, are both efficient and very simple to implement. We obtain numerical rate of convergence for such algorithms, and discuss its implications. Experiments on text data will be provided to demonstrate numerical and statistical consequences of our theoretical findings."
            },
            "slug": "Solving-large-scale-linear-prediction-problems-Zhang",
            "title": {
                "fragments": [],
                "text": "Solving large scale linear prediction problems using stochastic gradient descent algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Stochastic gradient descent algorithms on regularized forms of linear prediction methods, related to online algorithms such as perceptron, are studied, and numerical rate of convergence for such algorithms is obtained."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341779"
                        ],
                        "name": "J. R. Quinlan",
                        "slug": "J.-R.-Quinlan",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Quinlan",
                            "middleNames": [
                                "Ross"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. R. Quinlan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 937841,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "79ea6a5a68e05065f82acd11a478aa7eac5f6c06",
            "isKey": false,
            "numCitedBy": 1664,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Breiman's bagging and Freund and Schapire's boosting are recent methods for improving the predictive power of classifier learning systems. Both form a set of classifiers that are combined by voting, bagging by generating replicated bootstrap samples of the data, and boosting by adjusting the weights of training instances. This paper reports results of applying both techniques to a system that learns decision trees and testing on a representative collection of datasets. While both approaches substantially improve predictive accuracy, boosting shows the greater benefit. On the other hand, boosting also produces severe degradation on some datasets. A small change to the way that boosting combines the votes of learned classifiers reduces this downside and also leads to slightly better results on most of the datasets considered."
            },
            "slug": "Bagging,-Boosting,-and-C4.5-Quinlan",
            "title": {
                "fragments": [],
                "text": "Bagging, Boosting, and C4.5"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "Results of applying Breiman's bagging and Freund and Schapire's boosting to a system that learns decision trees and testing on a representative collection of datasets show boosting shows the greater benefit."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI, Vol. 1"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388558063"
                        ],
                        "name": "A. Silva-Filho",
                        "slug": "A.-Silva-Filho",
                        "structuredName": {
                            "firstName": "Abel",
                            "lastName": "Silva-Filho",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Silva-Filho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691084"
                        ],
                        "name": "A. Frery",
                        "slug": "A.-Frery",
                        "structuredName": {
                            "firstName": "Alejandro",
                            "lastName": "Frery",
                            "middleNames": [
                                "C\u00e9sar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Frery"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3298304"
                        ],
                        "name": "C. Araujo",
                        "slug": "C.-Araujo",
                        "structuredName": {
                            "firstName": "Cristiano",
                            "lastName": "Araujo",
                            "middleNames": [
                                "Coelho",
                                "De"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Araujo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409086626"
                        ],
                        "name": "Haglay Alice",
                        "slug": "Haglay-Alice",
                        "structuredName": {
                            "firstName": "Haglay",
                            "lastName": "Alice",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haglay Alice"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052359967"
                        ],
                        "name": "Jorge Cerqueira",
                        "slug": "Jorge-Cerqueira",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "Cerqueira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jorge Cerqueira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069331923"
                        ],
                        "name": "Juliana A. Loureiro",
                        "slug": "Juliana-A.-Loureiro",
                        "structuredName": {
                            "firstName": "Juliana",
                            "lastName": "Loureiro",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Juliana A. Loureiro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1934976"
                        ],
                        "name": "M. Lima",
                        "slug": "M.-Lima",
                        "structuredName": {
                            "firstName": "Manoel",
                            "lastName": "Lima",
                            "middleNames": [
                                "Eusebio",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Lima"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110929793"
                        ],
                        "name": "Maria das Gracas S. Oliveira",
                        "slug": "Maria-das-Gracas-S.-Oliveira",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Oliveira",
                            "middleNames": [
                                "das",
                                "Gracas",
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Maria das Gracas S. Oliveira"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27085971"
                        ],
                        "name": "M. M. Horta",
                        "slug": "M.-M.-Horta",
                        "structuredName": {
                            "firstName": "Michelle",
                            "lastName": "Horta",
                            "middleNames": [
                                "Matos"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. M. Horta"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 55
                            }
                        ],
                        "text": "There are also many dedicated accelerators for k-Means [17, 22, 30] or SVM [4, 31], due to their broad applications in industry."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16402,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a97c6af6016bb775cfe06b99df5b52bab847e72e",
            "isKey": false,
            "numCitedBy": 78,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Unsupervised clustering is a powerful technique for understanding multispectral and hyperspectral images, k-means being one of the most used iterative approaches. It is a simple though computationally expensive algorithm, particularly for clustering large hyperspectral images into many categories. Software implementation presents advantages such as flexibility and low cost for implementation of complex functions. However, it presents limitations, such as difficulties in exploiting parallelism for high performance applications. In order to accelerate the k-means clustering, a hardware implementation could be used. The disadvantage in this approach is that any change in the project requires previous knowledge of the hardware design process and can take several weeks to be implemented. In order to improve the design methodology, an automatic and parameterized implementation for hyperspectral images has been developed in a hardware/software codesign approach. An unsupervised clustering technique k-means that uses the Euclidian distance to calculate the pixel to centers distance was used as a case study to validate the methodology. Two implementations, a software and a hardware/software codesign one, have been implemented. Although the hardware component operates at 40 MHz, being 12.5 times less than the software operating frequency (PC), the codesign implementation was approximately 2 times faster than software one."
            },
            "slug": "Hyperspectral-images-clustering-on-reconfigurable-Silva-Filho-Frery",
            "title": {
                "fragments": [],
                "text": "Hyperspectral images clustering on reconfigurable hardware using the k-means algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An automatic and parameterized implementation for hyperspectral images has been developed in a hardware/software codesign approach and an unsupervised clustering technique k-means that uses the Euclidian distance to calculate the pixel to centers distance was used as a case study to validate the methodology."
            },
            "venue": {
                "fragments": [],
                "text": "16th Symposium on Integrated Circuits and Systems Design, 2003. SBCCI 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145115014"
                        ],
                        "name": "Corinna Cortes",
                        "slug": "Corinna-Cortes",
                        "structuredName": {
                            "firstName": "Corinna",
                            "lastName": "Cortes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Corinna Cortes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50560492"
                        ],
                        "name": "V. Vapnik",
                        "slug": "V.-Vapnik",
                        "structuredName": {
                            "firstName": "Vladimir",
                            "lastName": "Vapnik",
                            "middleNames": [
                                "Naumovich"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Vapnik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 52874011,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "52b7bf3ba59b31f362aa07f957f1543a29a4279e",
            "isKey": false,
            "numCitedBy": 33675,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "The support-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data.High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated. We also compare the performance of the support-vector network to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition."
            },
            "slug": "Support-Vector-Networks-Cortes-Vapnik",
            "title": {
                "fragments": [],
                "text": "Support-Vector Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated and the performance of the support- vector network is compared to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144509099"
                        ],
                        "name": "M. Kauffman",
                        "slug": "M.-Kauffman",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Kauffman",
                            "middleNames": [
                                "R.",
                                "Hern\u00e1ndez"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kauffman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "81426350"
                        ],
                        "name": "San Mateo",
                        "slug": "San-Mateo",
                        "structuredName": {
                            "firstName": "San",
                            "lastName": "Mateo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "San Mateo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3011435"
                        ],
                        "name": "E. Prescott",
                        "slug": "E.-Prescott",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Prescott",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Prescott"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 183
                            }
                        ],
                        "text": "The famous no-free-lunch theorem from the ML domain is a good summary of the above situation: any learning technique cannot perform universally better than another learning technique [39]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15897108,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "604954a3600f749b25a9f52317a42d13a8ec0339",
            "isKey": false,
            "numCitedBy": 603,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Plutowski, M., et al. (1994). Cross-validation estimates integrated mean squared error. In Advances in neural information processing systems 6, Cowan et al. some constant set by k and m. It's also true that E(C OTS | \u03c6, d X) is not drastically different if one considers d X 's with a different m'. Accordingly, our summand doesn't vary drastically between d X 's of one m' and d X 's of another. Since n >> m and \u03c0(x) is uniform though, almost all of the terms in the sum have m' = m."
            },
            "slug": "The-Lack-of-A-Priori-Distinctions-Between-Learning-Kauffman-Mateo",
            "title": {
                "fragments": [],
                "text": "The Lack of A Priori Distinctions Between Learning Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It's true that n >> m and \u03c0(x) is uniform though, almost all of the terms in the sum have m' = m, so the summand doesn't vary drastically between d X 's of one m' and d X's of another."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143914308"
                        ],
                        "name": "T. Maruyama",
                        "slug": "T.-Maruyama",
                        "structuredName": {
                            "firstName": "Tsutomu",
                            "lastName": "Maruyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Maruyama"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 55
                            }
                        ],
                        "text": "There are also many dedicated accelerators for k-Means [17, 22, 30] or SVM [4, 31], due to their broad applications in industry."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 42626369,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6e7c6d76b0eeead22851339f1e52846b8ae72674",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "K-means clustering is a very popular clustering technique, which is used in numerous applications. However, clustering is a time consuming task, particularly for large dataset, and large number of clusters. In this paper, we show that real-time k-means clustering can be realized for large size color images (24-bit full color RGB) and large number of clusters (up to 256) using an off-the-shelf FPGA (field programmable gate arrays) board. In our current implementation with one FPGA, the performance for 512 times 512 and 640 times 480 pixel images is more than 30fps, and 20-30 fps for 756 times 512 pixel images in average when dividing to 256 clusters"
            },
            "slug": "Real-time-K-Means-Clustering-for-Color-Images-on-Maruyama",
            "title": {
                "fragments": [],
                "text": "Real-time K-Means Clustering for Color Images on Reconfigurable Hardware"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that real-time k-means clustering can be realized for large size color images and large number of clusters using an off-the-shelf FPGA (field programmable gate arrays) board."
            },
            "venue": {
                "fragments": [],
                "text": "18th International Conference on Pattern Recognition (ICPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": "Pre-training can be done by training Restricted Boltzmann Machines (RBMs) [21], in which the most time-consuming steps are iterative feedforward computation and backforward computation (which includes similar operations to feedforward computation)1"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207596505,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9360e5ce9c98166bb179ad479a9d2919ff13d022",
            "isKey": false,
            "numCitedBy": 4595,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "It is possible to combine multiple latent-variable models of the same data by multiplying their probability distributions together and then renormalizing. This way of combining individual expert models makes it hard to generate samples from the combined model but easy to infer the values of the latent variables of each expert, because the combination rule ensures that the latent variables of different experts are conditionally independent when given the data. A product of experts (PoE) is therefore an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary. Training a PoE by maximizing the likelihood of the data is difficult because it is hard even to approximate the derivatives of the renormalization term in the combination rule. Fortunately, a PoE can be trained using a different objective function called contrastive divergence whose derivatives with regard to the parameters can be approximated accurately and efficiently. Examples are presented of contrastive divergence learning using several types of expert on several types of data."
            },
            "slug": "Training-Products-of-Experts-by-Minimizing-Hinton",
            "title": {
                "fragments": [],
                "text": "Training Products of Experts by Minimizing Contrastive Divergence"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A product of experts (PoE) is an interesting candidate for a perceptual system in which rapid inference is vital and generation is unnecessary because it is hard even to approximate the derivatives of the renormalization term in the combination rule."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145183709"
                        ],
                        "name": "J. Weston",
                        "slug": "J.-Weston",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Weston",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Weston"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 161
                            }
                        ],
                        "text": "Over the past decade, an emerging type of MLP called Deep Neural Network (DNN) has attracted broad interests of both the machine learning community and industry [10, 13, 20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2617020,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "57458bc1cffe5caa45a885af986d70f723f406b4",
            "isKey": false,
            "numCitedBy": 5064,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance."
            },
            "slug": "A-unified-architecture-for-natural-language-deep-Collobert-Weston",
            "title": {
                "fragments": [],
                "text": "A unified architecture for natural language processing: deep neural networks with multitask learning"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This work describes a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense using a language model."
            },
            "venue": {
                "fragments": [],
                "text": "ICML '08"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35188630"
                        ],
                        "name": "George E. Dahl",
                        "slug": "George-E.-Dahl",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Dahl",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George E. Dahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144580027"
                        ],
                        "name": "Dong Yu",
                        "slug": "Dong-Yu",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723644"
                        ],
                        "name": "A. Acero",
                        "slug": "A.-Acero",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Acero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Acero"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 161
                            }
                        ],
                        "text": "Over the past decade, an emerging type of MLP called Deep Neural Network (DNN) has attracted broad interests of both the machine learning community and industry [10, 13, 20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14862572,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6658bbf68995731b2083195054ff45b4eca38b3a",
            "isKey": false,
            "numCitedBy": 2684,
            "numCiting": 93,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel context-dependent (CD) model for large-vocabulary speech recognition (LVSR) that leverages recent advances in using deep belief networks for phone recognition. We describe a pre-trained deep neural network hidden Markov model (DNN-HMM) hybrid architecture that trains the DNN to produce a distribution over senones (tied triphone states) as its output. The deep belief network pre-training algorithm is a robust and often helpful way to initialize deep neural networks generatively that can aid in optimization and reduce generalization error. We illustrate the key components of our model, describe the procedure for applying CD-DNN-HMMs to LVSR, and analyze the effects of various modeling choices on performance. Experiments on a challenging business search dataset demonstrate that CD-DNN-HMMs can significantly outperform the conventional context-dependent Gaussian mixture model (GMM)-HMMs, with an absolute sentence accuracy improvement of 5.8% and 9.2% (or relative error reduction of 16.0% and 23.2%) over the CD-GMM-HMMs trained using the minimum phone error rate (MPE) and maximum-likelihood (ML) criteria, respectively."
            },
            "slug": "Context-Dependent-Pre-Trained-Deep-Neural-Networks-Dahl-Yu",
            "title": {
                "fragments": [],
                "text": "Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A pre-trained deep neural network hidden Markov model (DNN-HMM) hybrid architecture that trains the DNN to produce a distribution over senones (tied triphone states) as its output that can significantly outperform the conventional context-dependent Gaussian mixture model (GMM)-HMMs."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Audio, Speech, and Language Processing"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 205001834,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "052b1d8ce63b07fec3de9dbb583772d860b7c769",
            "isKey": false,
            "numCitedBy": 20461,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal \u2018hidden\u2019 units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1."
            },
            "slug": "Learning-representations-by-back-propagating-errors-Rumelhart-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning representations by back-propagating errors"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "Back-propagation repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector, which helps to represent important features of the task domain."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2134734"
                        ],
                        "name": "Y. Yeh",
                        "slug": "Y.-Yeh",
                        "structuredName": {
                            "firstName": "Yao-Jung",
                            "lastName": "Yeh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Yeh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2438055"
                        ],
                        "name": "Hui-Ya Li",
                        "slug": "Hui-Ya-Li",
                        "structuredName": {
                            "firstName": "Hui-Ya",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hui-Ya Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143854007"
                        ],
                        "name": "Wen-Jyi Hwang",
                        "slug": "Wen-Jyi-Hwang",
                        "structuredName": {
                            "firstName": "Wen-Jyi",
                            "lastName": "Hwang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wen-Jyi Hwang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462414"
                        ],
                        "name": "C. Fang",
                        "slug": "C.-Fang",
                        "structuredName": {
                            "firstName": "Chiung-Yao",
                            "lastName": "Fang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "Yeh et al. designed a k-NN accelerator on FPGA [40]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 36
                            }
                        ],
                        "text": "designed a k-NN accelerator on FPGA [40]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 143
                            }
                        ],
                        "text": "For ML techniques that have broad yet important applications in both cloud servers and mobile ends, of course, there have been some successful FPGA/ASIC accelerators, but each of which of-\nten targets at only a single ML technique or technique family."
                    },
                    "intents": []
                }
            ],
            "corpusId": 31284587,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e244b6e45e6fb2dc89c1c119231710ac42b0069",
            "isKey": true,
            "numCitedBy": 21,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "A novel algorithm for field programmable gate array (FPGA) realization of kNN classifier is presented in this paper. The algorithm identifies first k closest vectors in the design set of a kNN classifier for each input vector by performing the partial distance search (PDS) in the wavelet domain. It employs subspace search, bitplane reduction and multiple-coefficient accumulation techniques for the effective reduction of the area complexity and computation latency. The proposed implementation has been embedded in a softcore CPU for physical performance measurement. Experimental results show that the implementation provides a cost-effective solution to the FPGA realization of kNN classification systems where both high throughput and low area cost are desired."
            },
            "slug": "FPGA-Implementation-of-k-NN-Classifier-Based-on-and-Yeh-Li",
            "title": {
                "fragments": [],
                "text": "FPGA Implementation of k NN Classifier Based on Wavelet Transform and Partial Distance Search"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Experimental results show that the implementation provides a cost-effective solution to the FPGA realization of kNN classification systems where both high throughput and low area cost are desired."
            },
            "venue": {
                "fragments": [],
                "text": "SCIA"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2416462"
                        ],
                        "name": "G. Cybenko",
                        "slug": "G.-Cybenko",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Cybenko",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cybenko"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 120
                            }
                        ],
                        "text": "We empirically evaluate the impact of the above hardware optimizations on the accuracies of k-NN, k-Means, SVM, LR, and MLP."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 42
                            }
                        ],
                        "text": "Over the past decade, an emerging type of MLP called Deep Neural Network (DNN) has attracted broad interests of both the machine learning community and industry [10, 13, 20]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 29
                            }
                        ],
                        "text": "Multi-Layer Perceptron (MLP) [12] is a classical artificial neural network that can model the non-linear relationship between inputs and outputs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3958369,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8da1dda34ecc96263102181448c94ec7d645d085",
            "isKey": false,
            "numCitedBy": 6456,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we demonstrate that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube; only mild conditions are imposed on the univariate function. Our results settle an open question about representability in the class of single hidden layer neural networks. In particular, we show that arbitrary decision regions can be arbitrarily well approximated by continuous feedforward neural networks with only a single internal, hidden layer and any continuous sigmoidal nonlinearity. The paper discusses approximation properties of other possible types of nonlinearities that might be implemented by artificial neural networks."
            },
            "slug": "Approximation-by-superpositions-of-a-sigmoidal-Cybenko",
            "title": {
                "fragments": [],
                "text": "Approximation by superpositions of a sigmoidal function"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "It is demonstrated that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Control. Signals Syst."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341779"
                        ],
                        "name": "J. R. Quinlan",
                        "slug": "J.-R.-Quinlan",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Quinlan",
                            "middleNames": [
                                "Ross"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. R. Quinlan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 196
                            }
                        ],
                        "text": "We evaluate PuDianNao and baseline processor on 7 ML techniques, including k-NN, k-Means, deep neural network, linear regression, support vector machine, naive bayes, and classification tree (ID3 [33])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "For example, CART uses Gini impurity [3], ID3 uses information gain [33], and C4."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 189902138,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "058bb096ce1507cd65b91e341317a8ab11a675de",
            "isKey": false,
            "numCitedBy": 1064,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The technology for building knowledge-based systems by inductive inference from examples has been demonstrated successfully in several practical applications. This paper summarizes an approach to synthesizing decision trees that has been used in a variety of systems, and it describes one such system, ID3, in detail. Results from recent studies show ways in which the methodology can be modified to deal with information that is noisy and/or incomplete. A reported shortcoming of the basic algorithm is discussed and two means of overcoming it are compared. The paper concludes with illustrations of current research directions."
            },
            "slug": "Induction-of-decision-trees-Quinlan",
            "title": {
                "fragments": [],
                "text": "Induction of decision trees"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper summarizes an approach to synthesizing decision trees that has been used in a variety of systems, and it describes one such system, ID3, in detail, which is described in detail."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713919"
                        ],
                        "name": "P. Langley",
                        "slug": "P.-Langley",
                        "structuredName": {
                            "firstName": "Pat",
                            "lastName": "Langley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Langley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2706719"
                        ],
                        "name": "Wayne Iba",
                        "slug": "Wayne-Iba",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Iba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wayne Iba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123928894"
                        ],
                        "name": "K. Thompson",
                        "slug": "K.-Thompson",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Thompson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Thompson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 115
                            }
                        ],
                        "text": "Naive Bayes (NB) is a probabilistic classifier based on Bayes\u2019 theorem and the Maximum-a Posteriori (MAP) paradigm [23]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 21634132,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e40ea249dfad6d8d133b7917ca031c0b32410a5",
            "isKey": false,
            "numCitedBy": 1357,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present an average-case analysis of the Bayesian classifier, a simple induction algorithm that fares remarkably well on many learning tasks. Our analysis assumes a monotone conjunctive target concept, and independent, noise-free Boolean attributes. We calculate the probability that the algorithm will induce an arbitrary pair of concept descriptions and then use this to compute the probability of correct classification over the instance space. The analysis takes into account the number of training instances, the number of attributes, the distribution of these attributes, and the level of class noise. We also explore the behavioral implications of the analysis by presenting predicted learning curves for artificial domains, and give experimental results on these domains as a check on our reasoning."
            },
            "slug": "An-Analysis-of-Bayesian-Classifiers-Langley-Iba",
            "title": {
                "fragments": [],
                "text": "An Analysis of Bayesian Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "An average-case analysis of the Bayesian classifier, a simple induction algorithm that fares remarkably well on many learning tasks, and explores the behavioral implications of the analysis by presenting predicted learning curves for artificial domains."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144718788"
                        ],
                        "name": "L. Deng",
                        "slug": "L.-Deng",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144580027"
                        ],
                        "name": "Dong Yu",
                        "slug": "Dong-Yu",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35188630"
                        ],
                        "name": "George E. Dahl",
                        "slug": "George-E.-Dahl",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Dahl",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "George E. Dahl"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40360972"
                        ],
                        "name": "Abdel-rahman Mohamed",
                        "slug": "Abdel-rahman-Mohamed",
                        "structuredName": {
                            "firstName": "Abdel-rahman",
                            "lastName": "Mohamed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abdel-rahman Mohamed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3111912"
                        ],
                        "name": "Navdeep Jaitly",
                        "slug": "Navdeep-Jaitly",
                        "structuredName": {
                            "firstName": "Navdeep",
                            "lastName": "Jaitly",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Navdeep Jaitly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33666044"
                        ],
                        "name": "A. Senior",
                        "slug": "A.-Senior",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Senior",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Senior"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2657155"
                        ],
                        "name": "Vincent Vanhoucke",
                        "slug": "Vincent-Vanhoucke",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Vanhoucke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Vanhoucke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14902530"
                        ],
                        "name": "P. Nguyen",
                        "slug": "P.-Nguyen",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Nguyen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Nguyen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784851"
                        ],
                        "name": "T. Sainath",
                        "slug": "T.-Sainath",
                        "structuredName": {
                            "firstName": "Tara",
                            "lastName": "Sainath",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Sainath"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144707379"
                        ],
                        "name": "Brian Kingsbury",
                        "slug": "Brian-Kingsbury",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Kingsbury",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian Kingsbury"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 161
                            }
                        ],
                        "text": "Over the past decade, an emerging type of MLP called Deep Neural Network (DNN) has attracted broad interests of both the machine learning community and industry [10, 13, 20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206485943,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31868290adf1c000c611dfc966b514d5a34e8d23",
            "isKey": false,
            "numCitedBy": 7484,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "Most current speech recognition systems use hidden Markov models (HMMs) to deal with the temporal variability of speech and Gaussian mixture models (GMMs) to determine how well each state of each HMM fits a frame or a short window of frames of coefficients that represents the acoustic input. An alternative way to evaluate the fit is to use a feed-forward neural network that takes several frames of coefficients as input and produces posterior probabilities over HMM states as output. Deep neural networks (DNNs) that have many hidden layers and are trained using new methods have been shown to outperform GMMs on a variety of speech recognition benchmarks, sometimes by a large margin. This article provides an overview of this progress and represents the shared views of four research groups that have had recent successes in using DNNs for acoustic modeling in speech recognition."
            },
            "slug": "Deep-Neural-Networks-for-Acoustic-Modeling-in-The-Hinton-Deng",
            "title": {
                "fragments": [],
                "text": "Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "This article provides an overview of progress and represents the shared views of four research groups that have had recent successes in using DNNs for acoustic modeling in speech recognition."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Signal Processing Magazine"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37736528"
                        ],
                        "name": "N. Altman",
                        "slug": "N.-Altman",
                        "structuredName": {
                            "firstName": "Naomi",
                            "lastName": "Altman",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Altman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 27
                            }
                        ],
                        "text": "k-Nearest Neighbors (k-NN) [2] is a simple yet widely-used learning algorithm that directly uses the k nearest neighbors of a testing instance to determine the label (classification or regression result) of the instance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17002880,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "7dcd4ac966093dc332e29811020b6a6cc3a53d75",
            "isKey": false,
            "numCitedBy": 3786,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Nonparametric regression is a set of techniques for estimating a regression curve without making strong assumptions about the shape of the true regression function. These techniques are therefore useful for building and checking parametric models, as well as for data description. Kernel and nearest-neighbor regression estimators are local versions of univariate location estimators, and so they can readily be introduced to beginning students and consulting clients who are familiar with such summaries as the sample mean and median."
            },
            "slug": "An-Introduction-to-Kernel-and-Nearest-Neighbor-Altman",
            "title": {
                "fragments": [],
                "text": "An Introduction to Kernel and Nearest-Neighbor Nonparametric Regression"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Kernel and nearest-neighbor regression estimators are local versions of univariate location estimators, and so they can readily be introduced to beginning students and consulting clients who are familiar with such summaries as the sample mean and median."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2534720"
                        ],
                        "name": "E. Chan",
                        "slug": "E.-Chan",
                        "structuredName": {
                            "firstName": "Ernie",
                            "lastName": "Chan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Chan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 183,
                                "start": 180
                            }
                        ],
                        "text": "In application domains such as financial quantitative trading, linear regression is more widely-used than neural network due to the simplicity and interpretability of linear model [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 107025947,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "b4bd3064be71375d0d29b418d0f221db9e2ec9cd",
            "isKey": false,
            "numCitedBy": 64,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Praise for Algorithmic Trading\"Algorithmic Trading is an insightful book on quantitative trading written by a seasoned practitioner. What sets this book apart from many others in the space is the emphasis on real examples as opposed to just theory. Concepts are not only described, they are brought to life with actual trading strategies, which give the reader insight into how and why each strategy was developed, how it was implemented, and even how it was coded. This book is a valuable resource for anyone looking to create their own systematic trading strategies and those involved in manager selection, where the knowledge contained in this book will lead to a more informed and nuanced conversation with managers.\"DAREN SMITH, CFA, CAIA, FSA, Managing Director, Manager Selection & Portfolio Construction, University of Toronto Asset Management\"Using an excellent selection of mean reversion and momentum strategies, Ernie explains the rationale behind each one, shows how to test it, how to improve it, and discusses implementation issues. His book is a careful, detailed exposition of the scientific method applied to strategy development. For serious retail traders, I know of no other book that provides this range of examples and level of detail. His discussions of how regime changes affect strategies, and of risk management, are invaluable bonuses.\"Roger Hunter, Mathematician and Algorithmic Trader"
            },
            "slug": "Algorithmic-Trading:-Winning-Strategies-and-Their-Chan",
            "title": {
                "fragments": [],
                "text": "Algorithmic Trading: Winning Strategies and Their Rationale"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39566019"
                        ],
                        "name": "D. Steinberg",
                        "slug": "D.-Steinberg",
                        "structuredName": {
                            "firstName": "Dan",
                            "lastName": "Steinberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Steinberg"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 116184048,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9d2892ae0f10825a8c0d89ae3d00979a8aa758d3",
            "isKey": false,
            "numCitedBy": 241,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "10.1 Antecedents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180 10.2 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181 10.3 A Running Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181 10.4 The Algorithm Briefly Stated . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183 10.5 Splitting Rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185 10.6 Prior Probabilities and Class Balancing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187 10.7 Missing Value Handling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189 10.8 Attribute Importance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190 10.9 Dynamic Feature Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191 10.10 Cost-Sensitive Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192 10.11 Stopping Rules, Pruning, Tree Sequences, and Tree Selection . . . . . . . . . 193 10.12 Probability Trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194 10.13 Theoretical Foundations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196 10.14 Post-CART Related Research . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196 10.15 Software Availability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198 10.16 Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199"
            },
            "slug": "CART:-Classification-and-Regression-Trees-Steinberg",
            "title": {
                "fragments": [],
                "text": "CART: Classification and Regression Trees"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101347210"
                        ],
                        "name": "A. L. Edwards",
                        "slug": "A.-L.-Edwards",
                        "structuredName": {
                            "firstName": "Allen",
                            "lastName": "Edwards",
                            "middleNames": [
                                "Louis"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. L. Edwards"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "Linear Regression (LR) [14] is a supervised learning technique which models the relationship between a scalar response variable y and a d-dimensional vector variable x = (x1, x2xd) T with a linear function y = \u2211d i=0 \u03b8ixi (where x0 always equals to 1)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 154688707,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "624b46ffed01b26cf8d15e3abab20330a72d5f5b",
            "isKey": false,
            "numCitedBy": 636,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "An introduction to linear regression and correlation , An introduction to linear regression and correlation , \u0645\u0631\u06a9\u0632 \u0641\u0646\u0627\u0648\u0631\u06cc \u0627\u0637\u0644\u0627\u0639\u0627\u062a \u0648 \u0627\u0637\u0644\u0627\u0639 \u0631\u0633\u0627\u0646\u06cc \u06a9\u0634\u0627\u0648\u0631\u0632\u06cc"
            },
            "slug": "An-introduction-to-linear-regression-and-Edwards",
            "title": {
                "fragments": [],
                "text": "An introduction to linear regression and correlation."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1985
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2140578338"
                        ],
                        "name": "E. Forgy",
                        "slug": "E.-Forgy",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Forgy",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Forgy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "k-Means [16] is an unsupervised ML technique which partitions N instances into k clusters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 118110564,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5c4feeae0d911e30866b7149c1195cd8c007199b",
            "isKey": false,
            "numCitedBy": 2298,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Cluster-analysis-of-multivariate-data-:-efficiency-Forgy",
            "title": {
                "fragments": [],
                "text": "Cluster analysis of multivariate data : efficiency versus interpretability of classifications"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1965
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149146007"
                        ],
                        "name": "Gang Li",
                        "slug": "Gang-Li",
                        "structuredName": {
                            "firstName": "Gang",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gang Li"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 90
                            }
                        ],
                        "text": "com, the largest online retailer in China, generates tens of Terabyte (TB) data every day [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "Facebook generates over 10 Petabyte (PB) log data per month [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3980412,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c8ce1460f584a6fe1197d03f1e71d6cd9d9147a8",
            "isKey": false,
            "numCitedBy": 134,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Big-data-related-technologies,-challenges-and-Li",
            "title": {
                "fragments": [],
                "text": "Big data related technologies, challenges and future prospects"
            },
            "venue": {
                "fragments": [],
                "text": "J. Inf. Technol. Tour."
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423230"
                        ],
                        "name": "L. Breiman",
                        "slug": "L.-Breiman",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Breiman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Breiman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69028931"
                        ],
                        "name": "J. Freidman",
                        "slug": "J.-Freidman",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Freidman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Freidman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2378652"
                        ],
                        "name": "R. Olshen",
                        "slug": "R.-Olshen",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Olshen",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Olshen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103556459"
                        ],
                        "name": "C. J. Stone",
                        "slug": "C.-J.-Stone",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Stone",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. J. Stone"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 40,
                                "start": 37
                            }
                        ],
                        "text": "For example, CART uses Gini impurity [3], ID3 uses information gain [33], and C4."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 59814698,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e8a7aee4637137fd24fd88fd4be4a95c172ec0d7",
            "isKey": false,
            "numCitedBy": 385,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "CART:-Classification-and-Regression-Trees-Breiman-Freidman",
            "title": {
                "fragments": [],
                "text": "CART: Classification and Regression Trees"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Induction of decision trees. Machine learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Overview of neural hardware. Neurocomputers for Brain-Style Processing. Design, Implementation and Application"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Luca Maria Gambardella , and J\u00fcrgen Schmidhuber. Flexible, high performance convolutional neural networks for image classification"
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI Proceedings-International Joint Conference on Artificial Intelligence"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 50
                            }
                        ],
                        "text": "In the machine learning community, an ML technique is conventionally characterized by its mathematical model (e.g., linear or non-linear), its learning style (e.g., supervised or unsupervised), its training algorithm (e.g., maximuma-posteriori or gradient descent) and so on."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "An introduction to kernel and nearestneighbor nonparametric regression. The American Statistician"
            },
            "venue": {
                "fragments": [],
                "text": "An introduction to kernel and nearestneighbor nonparametric regression. The American Statistician"
            },
            "year": 1992
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 8
                            }
                        ],
                        "text": "DianNao [7, 8] is one such example, which effectively accelerates representative neural network algorithms to benefit different ML scenarios (e."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 85
                            }
                        ],
                        "text": "In this trend, a number of successful neural network accelerators have been proposed [7, 15, 26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Diannao: a smallfootprint high-throughput accelerator for ubiquitous machinelearning"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of the 19th International Conference on Architectural support for programming languages and operating systems,"
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "Global training uses the Back Propagation (BP) algorithm [35] to globally tune synapses, and the most-time consuming step is still analogous to feedforward/backforward computation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 347,
                                "start": 343
                            }
                        ],
                        "text": "A DNN has three computation modes, feedforward computation which computes the network output for each given input under the current network setting, pre-training which locally tune the synapses (connection weights) between each pair of adjacent layers, and global training which globally tune synapses with the Back Propagation (BP) algorithm [35]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning representations by backpropagating"
            },
            "venue": {
                "fragments": [],
                "text": "errors. Nature,"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bagging, boosting, and c4"
            },
            "venue": {
                "fragments": [],
                "text": "In AAAI/IAAI,"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 117
                            }
                        ],
                        "text": "Recent debates on deep learning [24] even triggers the rebirth of hardware neural network [37], a hot topic in 1990s [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Overview of neural hardware. Neurocomputers for Brain-Style Processing"
            },
            "venue": {
                "fragments": [],
                "text": "Design, Implementation and Application,"
            },
            "year": 1995
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 25,
            "methodology": 11,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 49,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/PuDianNao:-A-Polyvalent-Machine-Learning-Liu-Chen/68837728232463651283edbb7ef0c93b2f502b2b?sort=total-citations"
}