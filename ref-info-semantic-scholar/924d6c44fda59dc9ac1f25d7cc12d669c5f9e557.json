{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144810556"
                        ],
                        "name": "Ying Wang",
                        "slug": "Ying-Wang",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ying Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111063139"
                        ],
                        "name": "Jie Xu",
                        "slug": "Jie-Xu",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276854"
                        ],
                        "name": "Yinhe Han",
                        "slug": "Yinhe-Han",
                        "structuredName": {
                            "firstName": "Yinhe",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yinhe Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47892692"
                        ],
                        "name": "Huawei Li",
                        "slug": "Huawei-Li",
                        "structuredName": {
                            "firstName": "Huawei",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huawei Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40613624"
                        ],
                        "name": "Xiaowei Li",
                        "slug": "Xiaowei-Li",
                        "structuredName": {
                            "firstName": "Xiaowei",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaowei Li"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[41] use a library of fixed-function blocks to accelerate DNNs on Xilinx Z7020 and Z7045 FPGAs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10103357,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb7ee710f96dfe999b2b047155fbba079e806b9d",
            "isKey": false,
            "numCitedBy": 169,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent advances in Neural Networks (NN) are enabling more and more innovative applications. As an energy-efficient hardware solution, machine learning accelerators for CNNs or traditional ANNs are also gaining popularity in the area of embedded vision, robotics and cyberphysics. However, the design parameters of NN models vary significantly from application to application. Hence, it's hard to provide one general and highly-efficient hardware solution to accommodate all of them, and it is also impractical for the domain-specific developers to customize their own hardware targeting on a specific NN model. To deal with this dilemma, this study proposes a design automation tool, DeepBurning, allowing the application developers to build from scratch learning accelerators that targets their specific NN models with custom configurations and optimized performance. DeepBurning includes a RTL-level accelerator generator and a coordinated compiler that generates the control flow and data layout under the user-specified constraints. The results can be used to implement FPGA-based NN accelerator or help generate chip design for early design stage. In general, DeepBurning supports a large family of NN models, and greatly simplifies the design flow of NN accelerators for the machine learning or AI application developers. The evaluation shows that the generated learning accelerators burnt to our FPGA board exhibit great power efficiency compared to state-of-the-art FPGA-based solutions."
            },
            "slug": "DeepBurning:-Automatic-generation-of-FPGA-based-for-Wang-Xu",
            "title": {
                "fragments": [],
                "text": "DeepBurning: Automatic generation of FPGA-based learning accelerators for the Neural Network family"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A design automation tool allowing the application developers to build from scratch learning accelerators that targets their specific NN models with custom configurations and optimized performance, and greatly simplifies the design flow of NN accelerators for the machine learning or AI application developers."
            },
            "venue": {
                "fragments": [],
                "text": "2016 53nd ACM/EDAC/IEEE Design Automation Conference (DAC)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40622167"
                        ],
                        "name": "Naveen Suda",
                        "slug": "Naveen-Suda",
                        "structuredName": {
                            "firstName": "Naveen",
                            "lastName": "Suda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naveen Suda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144137038"
                        ],
                        "name": "V. Chandra",
                        "slug": "V.-Chandra",
                        "structuredName": {
                            "firstName": "Vikas",
                            "lastName": "Chandra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Chandra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31613624"
                        ],
                        "name": "Ganesh S. Dasika",
                        "slug": "Ganesh-S.-Dasika",
                        "structuredName": {
                            "firstName": "Ganesh",
                            "lastName": "Dasika",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ganesh S. Dasika"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2942785"
                        ],
                        "name": "Abinash Mohanty",
                        "slug": "Abinash-Mohanty",
                        "structuredName": {
                            "firstName": "Abinash",
                            "lastName": "Mohanty",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abinash Mohanty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1557288829"
                        ],
                        "name": "Yufei Ma",
                        "slug": "Yufei-Ma",
                        "structuredName": {
                            "firstName": "Yufei",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yufei Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726608"
                        ],
                        "name": "S. Vrudhula",
                        "slug": "S.-Vrudhula",
                        "structuredName": {
                            "firstName": "Sarma",
                            "lastName": "Vrudhula",
                            "middleNames": [
                                "B.",
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Vrudhula"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706798"
                        ],
                        "name": "Jae-sun Seo",
                        "slug": "Jae-sun-Seo",
                        "structuredName": {
                            "firstName": "Jae-sun",
                            "lastName": "Seo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jae-sun Seo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1965873861"
                        ],
                        "name": "Yu Cao",
                        "slug": "Yu-Cao",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Cao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Cao"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "[39, 40] present implementations of accelerators for particular DNN models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207233292,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b4eac8295c90dbfb7d8d22ba560e025621287c58",
            "isKey": false,
            "numCitedBy": 411,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional Neural Networks (CNNs) have gained popularity in many computer vision applications such as image classification, face detection, and video analysis, because of their ability to train and classify with high accuracy. Due to multiple convolution and fully-connected layers that are compute-/memory-intensive, it is difficult to perform real-time classification with low power consumption on today?s computing systems. FPGAs have been widely explored as hardware accelerators for CNNs because of their reconfigurability and energy efficiency, as well as fast turn-around-time, especially with high-level synthesis methodologies. Previous FPGA-based CNN accelerators, however, typically implemented generic accelerators agnostic to the CNN configuration, where the reconfigurable capabilities of FPGAs are not fully leveraged to maximize the overall system throughput. In this work, we present a systematic design space exploration methodology to maximize the throughput of an OpenCL-based FPGA accelerator for a given CNN model, considering the FPGA resource constraints such as on-chip memory, registers, computational resources and external memory bandwidth. The proposed methodology is demonstrated by optimizing two representative large-scale CNNs, AlexNet and VGG, on two Altera Stratix-V FPGA platforms, DE5-Net and P395-D8 boards, which have different hardware resources. We achieve a peak performance of 136.5 GOPS for convolution operation, and 117.8 GOPS for the entire VGG network that performs ImageNet classification on P395-D8 board."
            },
            "slug": "Throughput-Optimized-OpenCL-based-FPGA-Accelerator-Suda-Chandra",
            "title": {
                "fragments": [],
                "text": "Throughput-Optimized OpenCL-based FPGA Accelerator for Large-Scale Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work presents a systematic design space exploration methodology to maximize the throughput of an OpenCL-based FPGA accelerator for a given CNN model, considering the FPGAs resource constraints such as on-chip memory, registers, computational resources and external memory bandwidth."
            },
            "venue": {
                "fragments": [],
                "text": "FPGA"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111573067"
                        ],
                        "name": "Chen Zhang",
                        "slug": "Chen-Zhang",
                        "structuredName": {
                            "firstName": "Chen",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chen Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50492686"
                        ],
                        "name": "Peng Li",
                        "slug": "Peng-Li",
                        "structuredName": {
                            "firstName": "Peng",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peng Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695860"
                        ],
                        "name": "Guangyu Sun",
                        "slug": "Guangyu-Sun",
                        "structuredName": {
                            "firstName": "Guangyu",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guangyu Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2238828"
                        ],
                        "name": "Yijin Guan",
                        "slug": "Yijin-Guan",
                        "structuredName": {
                            "firstName": "Yijin",
                            "lastName": "Guan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yijin Guan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37525788"
                        ],
                        "name": "Bingjun Xiao",
                        "slug": "Bingjun-Xiao",
                        "structuredName": {
                            "firstName": "Bingjun",
                            "lastName": "Xiao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bingjun Xiao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2259796"
                        ],
                        "name": "J. Cong",
                        "slug": "J.-Cong",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Cong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 85
                            }
                        ],
                        "text": "The benefits of the template approach is more evident when considering a recent work [14] that uses commercial HLS tool and yet spends significant effort to implement the convolution layers of just one DNN, AlexNet."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 32
                            }
                        ],
                        "text": "In fact, several research works [14, 15, 27, 28] have made extensive efforts to provide FPGA accelerators for specific DNN models, or parts of DNN computation, targeted for a particular FPGA platform."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 207220904,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c91eb0f9bbae8e2d3d007db73b8422b61ed1d68",
            "isKey": false,
            "numCitedBy": 1482,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional neural network (CNN) has been widely employed for image recognition because it can achieve high accuracy by emulating behavior of optic nerves in living creatures. Recently, rapid growth of modern applications based on deep learning algorithms has further improved research and implementations. Especially, various accelerators for deep CNN have been proposed based on FPGA platform because it has advantages of high performance, reconfigurability, and fast development round, etc. Although current FPGA accelerators have demonstrated better performance over generic processors, the accelerator design space has not been well exploited. One critical problem is that the computation throughput may not well match the memory bandwidth provided an FPGA platform. Consequently, existing approaches cannot achieve best performance due to under-utilization of either logic resource or memory bandwidth. At the same time, the increasing complexity and scalability of deep learning applications aggravate this problem. In order to overcome this problem, we propose an analytical design scheme using the roofline model. For any solution of a CNN design, we quantitatively analyze its computing throughput and required memory bandwidth using various optimization techniques, such as loop tiling and transformation. Then, with the help of rooine model, we can identify the solution with best performance and lowest FPGA resource requirement. As a case study, we implement a CNN accelerator on a VC707 FPGA board and compare it to previous approaches. Our implementation achieves a peak performance of 61.62 GFLOPS under 100MHz working frequency, which outperform previous approaches significantly."
            },
            "slug": "Optimizing-FPGA-based-Accelerator-Design-for-Deep-Zhang-Li",
            "title": {
                "fragments": [],
                "text": "Optimizing FPGA-based Accelerator Design for Deep Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This work implements a CNN accelerator on a VC707 FPGA board and compares it to previous approaches, achieving a peak performance of 61.62 GFLOPS under 100MHz working frequency, which outperform previous approaches significantly."
            },
            "venue": {
                "fragments": [],
                "text": "FPGA"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2732658"
                        ],
                        "name": "Brandon Reagen",
                        "slug": "Brandon-Reagen",
                        "structuredName": {
                            "firstName": "Brandon",
                            "lastName": "Reagen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brandon Reagen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3313708"
                        ],
                        "name": "P. Whatmough",
                        "slug": "P.-Whatmough",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Whatmough",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Whatmough"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3313828"
                        ],
                        "name": "Robert Adolf",
                        "slug": "Robert-Adolf",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Adolf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Adolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37408074"
                        ],
                        "name": "Saketh Rama",
                        "slug": "Saketh-Rama",
                        "structuredName": {
                            "firstName": "Saketh",
                            "lastName": "Rama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saketh Rama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3389887"
                        ],
                        "name": "Hyunkwang Lee",
                        "slug": "Hyunkwang-Lee",
                        "structuredName": {
                            "firstName": "Hyunkwang",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hyunkwang Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108166207"
                        ],
                        "name": "Sae Kyu Lee",
                        "slug": "Sae-Kyu-Lee",
                        "structuredName": {
                            "firstName": "Sae",
                            "lastName": "Lee",
                            "middleNames": [
                                "Kyu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sae Kyu Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388574431"
                        ],
                        "name": "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato",
                        "slug": "Jos\u00e9-Miguel-Hern\u00e1ndez-Lobato",
                        "structuredName": {
                            "firstName": "Jos\u00e9 Miguel",
                            "lastName": "Hern\u00e1ndez-Lobato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jos\u00e9 Miguel Hern\u00e1ndez-Lobato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2255803"
                        ],
                        "name": "Gu-Yeon Wei",
                        "slug": "Gu-Yeon-Wei",
                        "structuredName": {
                            "firstName": "Gu-Yeon",
                            "lastName": "Wei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gu-Yeon Wei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1896817"
                        ],
                        "name": "D. Brooks",
                        "slug": "D.-Brooks",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Brooks",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Brooks"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "EIE [45], Minerva [46], and Cnvlutin [47] propose ASIC accelerators that use operation pruning and quantization in DNNs for power and performance benefits."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 44529396,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "91d03e4bf98a03c827983457e6de43cbd4c6ccd7",
            "isKey": false,
            "numCitedBy": 312,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "The continued success of Deep Neural Networks (DNNs) in classification tasks has sparked a trend of accelerating their execution with specialized hardware. While published designs easily give an order of magnitude improvement over general-purpose hardware, few look beyond an initial implementation. This paper presents Minerva, a highly automated co-design approach across the algorithm, architecture, and circuit levels to optimize DNN hardware accelerators. Compared to an established fixed-point accelerator baseline, we show that fine-grained, heterogeneous datatype optimization reduces power by 1.5\u00d7; aggressive, inline predication and pruning of small activity values further reduces power by 2.0\u00d7; and active hardware fault detection coupled with domain-aware error mitigation eliminates an additional 2.7\u00d7 through lowering SRAM voltages. Across five datasets, these optimizations provide a collective average of 8.1\u00d7 power reduction over an accelerator baseline without compromising DNN model accuracy. Minerva enables highly accurate, ultra-low power DNN accelerators (in the range of tens of milliwatts), making it feasible to deploy DNNs in power-constrained IoT and mobile devices."
            },
            "slug": "Minerva:-Enabling-Low-Power,-Highly-Accurate-Deep-Reagen-Whatmough",
            "title": {
                "fragments": [],
                "text": "Minerva: Enabling Low-Power, Highly-Accurate Deep Neural Network Accelerators"
            },
            "venue": {
                "fragments": [],
                "text": "2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1848503"
                        ],
                        "name": "Jiantao Qiu",
                        "slug": "Jiantao-Qiu",
                        "structuredName": {
                            "firstName": "Jiantao",
                            "lastName": "Qiu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiantao Qiu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146044047"
                        ],
                        "name": "Jie Wang",
                        "slug": "Jie-Wang",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067824417"
                        ],
                        "name": "Song Yao",
                        "slug": "Song-Yao",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Yao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Yao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35493564"
                        ],
                        "name": "Kaiyuan Guo",
                        "slug": "Kaiyuan-Guo",
                        "structuredName": {
                            "firstName": "Kaiyuan",
                            "lastName": "Guo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiyuan Guo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2789329"
                        ],
                        "name": "Boxun Li",
                        "slug": "Boxun-Li",
                        "structuredName": {
                            "firstName": "Boxun",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Boxun Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1848243"
                        ],
                        "name": "Erjin Zhou",
                        "slug": "Erjin-Zhou",
                        "structuredName": {
                            "firstName": "Erjin",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Erjin Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1909938"
                        ],
                        "name": "Jincheng Yu",
                        "slug": "Jincheng-Yu",
                        "structuredName": {
                            "firstName": "Jincheng",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jincheng Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50149494"
                        ],
                        "name": "Tianqi Tang",
                        "slug": "Tianqi-Tang",
                        "structuredName": {
                            "firstName": "Tianqi",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianqi Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3977801"
                        ],
                        "name": "Ningyi Xu",
                        "slug": "Ningyi-Xu",
                        "structuredName": {
                            "firstName": "Ningyi",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ningyi Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "15168128"
                        ],
                        "name": "Sen Song",
                        "slug": "Sen-Song",
                        "structuredName": {
                            "firstName": "Sen",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sen Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40987227"
                        ],
                        "name": "Yu Wang",
                        "slug": "Yu-Wang",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39150998"
                        ],
                        "name": "Huazhong Yang",
                        "slug": "Huazhong-Yang",
                        "structuredName": {
                            "firstName": "Huazhong",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huazhong Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "[39, 40] present implementations of accelerators for particular DNN models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207233273,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c382406fd8db2744b2a609837395e5da05e1d2ed",
            "isKey": false,
            "numCitedBy": 897,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years, convolutional neural network (CNN) based methods have achieved great success in a large number of applications and have been among the most powerful and widely used techniques in computer vision. However, CNN-based methods are com-putational-intensive and resource-consuming, and thus are hard to be integrated into embedded systems such as smart phones, smart glasses, and robots. FPGA is one of the most promising platforms for accelerating CNN, but the limited bandwidth and on-chip memory size limit the performance of FPGA accelerator for CNN. In this paper, we go deeper with the embedded FPGA platform on accelerating CNNs and propose a CNN accelerator design on embedded FPGA for Image-Net large-scale image classification. We first present an in-depth analysis of state-of-the-art CNN models and show that Convolutional layers are computational-centric and Fully-Connected layers are memory-centric. Then the dynamic-precision data quantization method and a convolver design that is efficient for all layer types in CNN are proposed to improve the bandwidth and resource utilization. Results show that only 0.4% accuracy loss is introduced by our data quantization flow for the very deep VGG16 model when 8/4-bit quantization is used. A data arrangement method is proposed to further ensure a high utilization of the external memory bandwidth. Finally, a state-of-the-art CNN, VGG16-SVD, is implemented on an embedded FPGA platform as a case study. VGG16-SVD is the largest and most accurate network that has been implemented on FPGA end-to-end so far. The system on Xilinx Zynq ZC706 board achieves a frame rate at 4.45 fps with the top-5 accuracy of 86.66% using 16-bit quantization. The average performance of convolutional layers and the full CNN is 187.8 GOP/s and 137.0 GOP/s under 150MHz working frequency, which outperform previous approaches significantly."
            },
            "slug": "Going-Deeper-with-Embedded-FPGA-Platform-for-Neural-Qiu-Wang",
            "title": {
                "fragments": [],
                "text": "Going Deeper with Embedded FPGA Platform for Convolutional Neural Network"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents an in-depth analysis of state-of-the-art CNN models and shows that Convolutional layers are computational-centric and Fully-Connected layers are memory-centric, and proposes a CNN accelerator design on embedded FPGA for Image-Net large-scale image classification."
            },
            "venue": {
                "fragments": [],
                "text": "FPGA"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144049725"
                        ],
                        "name": "Tianshi Chen",
                        "slug": "Tianshi-Chen",
                        "structuredName": {
                            "firstName": "Tianshi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianshi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678776"
                        ],
                        "name": "Zidong Du",
                        "slug": "Zidong-Du",
                        "structuredName": {
                            "firstName": "Zidong",
                            "lastName": "Du",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zidong Du"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145550877"
                        ],
                        "name": "Ninghui Sun",
                        "slug": "Ninghui-Sun",
                        "structuredName": {
                            "firstName": "Ninghui",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ninghui Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110368816"
                        ],
                        "name": "Jia Wang",
                        "slug": "Jia-Wang",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7514065"
                        ],
                        "name": "Chengyong Wu",
                        "slug": "Chengyong-Wu",
                        "structuredName": {
                            "firstName": "Chengyong",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chengyong Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7377735"
                        ],
                        "name": "Yunji Chen",
                        "slug": "Yunji-Chen",
                        "structuredName": {
                            "firstName": "Yunji",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yunji Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731764"
                        ],
                        "name": "O. Temam",
                        "slug": "O.-Temam",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Temam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Temam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 25
                            }
                        ],
                        "text": "For example, (Da)Diannao [12, 13] provide DNN accelerators with a low-level fine-grained ISA, yet they do not define an ISA to unify DNN accelerators."
                    },
                    "intents": []
                }
            ],
            "corpusId": 207209696,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22e477a9fdde86ab1f8f4dafdb4d88ea37e31fbd",
            "isKey": false,
            "numCitedBy": 1235,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Machine-Learning tasks are becoming pervasive in a broad range of domains, and in a broad range of systems (from embedded systems to data centers). At the same time, a small set of machine-learning algorithms (especially Convolutional and Deep Neural Networks, i.e., CNNs and DNNs) are proving to be state-of-the-art across many applications. As architectures evolve towards heterogeneous multi-cores composed of a mix of cores and accelerators, a machine-learning accelerator can achieve the rare combination of efficiency (due to the small number of target algorithms) and broad application scope. Until now, most machine-learning accelerator designs have focused on efficiently implementing the computational part of the algorithms. However, recent state-of-the-art CNNs and DNNs are characterized by their large size. In this study, we design an accelerator for large-scale CNNs and DNNs, with a special emphasis on the impact of memory on accelerator design, performance and energy. We show that it is possible to design an accelerator with a high throughput, capable of performing 452 GOP/s (key NN operations such as synaptic weight multiplications and neurons outputs additions) in a small footprint of 3.02 mm2 and 485 mW; compared to a 128-bit 2GHz SIMD processor, the accelerator is 117.87x faster, and it can reduce the total energy by 21.08x. The accelerator characteristics are obtained after layout at 65 nm. Such a high throughput in a small footprint can open up the usage of state-of-the-art machine-learning algorithms in a broad set of systems and for a broad set of applications."
            },
            "slug": "DianNao:-a-small-footprint-high-throughput-for-Chen-Du",
            "title": {
                "fragments": [],
                "text": "DianNao: a small-footprint high-throughput accelerator for ubiquitous machine-learning"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This study designs an accelerator for large-scale CNNs and DNNs, with a special emphasis on the impact of memory on accelerator design, performance and energy, and shows that it is possible to design an accelerator with a high throughput, capable of performing 452 GOP/s in a small footprint."
            },
            "venue": {
                "fragments": [],
                "text": "ASPLOS"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2150598002"
                        ],
                        "name": "Lili Song",
                        "slug": "Lili-Song",
                        "structuredName": {
                            "firstName": "Lili",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lili Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144810556"
                        ],
                        "name": "Ying Wang",
                        "slug": "Ying-Wang",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ying Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276854"
                        ],
                        "name": "Yinhe Han",
                        "slug": "Yinhe-Han",
                        "structuredName": {
                            "firstName": "Yinhe",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yinhe Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145734386"
                        ],
                        "name": "Xin Zhao",
                        "slug": "Xin-Zhao",
                        "structuredName": {
                            "firstName": "Xin",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xin Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1913354"
                        ],
                        "name": "Bosheng Liu",
                        "slug": "Bosheng-Liu",
                        "structuredName": {
                            "firstName": "Bosheng",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bosheng Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40613624"
                        ],
                        "name": "Xiaowei Li",
                        "slug": "Xiaowei-Li",
                        "structuredName": {
                            "firstName": "Xiaowei",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaowei Li"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[44] propose an ASIC implementation with adaptive data-level parallelism for DNN accelerators."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5152110,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e11ca64a35299b612f92ee0782a6ad3c2878f18",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional neural networks (CNN) accelerators have been proposed as an efficient hardware solution for deep learning based applications, which are known to be both compute-and-memory intensive. Although the most advanced CNN accelerators can deliver high computational throughput, the performance is highly unstable. Once changed to accommodate a new network with different parameters like layers and kernel size, the fixed hardware structure, may no longer well match the data flows. Consequently, the accelerator will fail to deliver high performance due to the underutilization of either logic resource or memory bandwidth. To overcome this problem, we proposed a novel deep learning accelerator, which offers multiple types of data-level parallelism: inter-kernel, intra-kernel and hybrid. Our design can adaptively switch among the three types of parallelism and the corresponding data tiling schemes to dynamically match different networks or even different layers of a single network. No matter how we change the hardware configurations or network types, the proposed network mapping strategy ensures the optimal performance and energy-efficiency. Compared with previous state-of-the-art NN accelerators, it is possible to achieve a speedup of 4.0x-8.3x for some layers of the well-known large scale CNNs. For the whole phase of network forward-propagation, our design achieves 28.04% PE energy saving, 90.3% on-chip memory energy saving on average."
            },
            "slug": "C-Brain:-A-deep-learning-accelerator-that-tames-the-Song-Wang",
            "title": {
                "fragments": [],
                "text": "C-Brain: A deep learning accelerator that tames the diversity of CNNs through adaptive data-level parallelization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work has proposed a novel deep learning accelerator, which offers multiple types of data-level parallelism: inter-kernel, intra-kernel and hybrid, and can adaptively switch among the three types of parallelism and the corresponding data tiling schemes to dynamically match different networks or even different layers of a single network."
            },
            "venue": {
                "fragments": [],
                "text": "2016 53nd ACM/EDAC/IEEE Design Automation Conference (DAC)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143840275"
                        ],
                        "name": "Song Han",
                        "slug": "Song-Han",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49543200"
                        ],
                        "name": "Xingyu Liu",
                        "slug": "Xingyu-Liu",
                        "structuredName": {
                            "firstName": "Xingyu",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xingyu Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3123774"
                        ],
                        "name": "Huizi Mao",
                        "slug": "Huizi-Mao",
                        "structuredName": {
                            "firstName": "Huizi",
                            "lastName": "Mao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huizi Mao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1560397753"
                        ],
                        "name": "Jing Pu",
                        "slug": "Jing-Pu",
                        "structuredName": {
                            "firstName": "Jing",
                            "lastName": "Pu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jing Pu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9182159"
                        ],
                        "name": "A. Pedram",
                        "slug": "A.-Pedram",
                        "structuredName": {
                            "firstName": "Ardavan",
                            "lastName": "Pedram",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pedram"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144764327"
                        ],
                        "name": "M. Horowitz",
                        "slug": "M.-Horowitz",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Horowitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Horowitz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80724002"
                        ],
                        "name": "W. Dally",
                        "slug": "W.-Dally",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dally",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dally"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "EIE [45], Minerva [46], and Cnvlutin [47] propose ASIC accelerators that use operation pruning and quantization in DNNs for power and performance benefits."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1663491,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e2b189f668cf2c06ebc44dc9b166648256cf457",
            "isKey": false,
            "numCitedBy": 1816,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "State-of-the-art deep neural networks (DNNs) have hundreds of millions of connections and are both computationally and memory intensive, making them difficult to deploy on embedded systems with limited hardware resources and power budgets. While custom hardware helps the computation, fetching weights from DRAM is two orders of magnitude more expensive than ALU operations, and dominates the required power. Previously proposed 'Deep Compression' makes it possible to fit large DNNs (AlexNet and VGGNet) fully in on-chip SRAM. This compression is achieved by pruning the redundant connections and having multiple connections share the same weight. We propose an energy efficient inference engine (EIE) that performs inference on this compressed network model and accelerates the resulting sparse matrix-vector multiplication with weight sharing. Going from DRAM to SRAM gives EIE 120x energy saving, Exploiting sparsity saves 10x, Weight sharing gives 8x, Skipping zero activations from ReLU saves another 3x. Evaluated on nine DNN benchmarks, EIE is 189x and 13x faster when compared to CPU and GPU implementations of the same DNN without compression. EIE has a processing power of 102 GOPS working directly on a compressed network, corresponding to 3 TOPS on an uncompressed network, and processes FC layers of AlexNet at 1.88x104 frames/sec with a power dissipation of only 600mW. It is 24,000x and 3,400x more energy efficient than a CPU and GPU respectively. Compared with DaDianNao, EIE has 2.9x, 19x and 3x better throughput, energy efficiency and area efficiency."
            },
            "slug": "EIE:-Efficient-Inference-Engine-on-Compressed-Deep-Han-Liu",
            "title": {
                "fragments": [],
                "text": "EIE: Efficient Inference Engine on Compressed Deep Neural Network"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An energy efficient inference engine (EIE) that performs inference on this compressed network model and accelerates the resulting sparse matrix-vector multiplication with weight sharing and is 189x and 13x faster when compared to CPU and GPU implementations of the same DNN without compression."
            },
            "venue": {
                "fragments": [],
                "text": "2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33278013"
                        ],
                        "name": "Divya Mahajan",
                        "slug": "Divya-Mahajan",
                        "structuredName": {
                            "firstName": "Divya",
                            "lastName": "Mahajan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Divya Mahajan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3101741"
                        ],
                        "name": "Jongse Park",
                        "slug": "Jongse-Park",
                        "structuredName": {
                            "firstName": "Jongse",
                            "lastName": "Park",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jongse Park"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053398"
                        ],
                        "name": "Emmanuel Amaro",
                        "slug": "Emmanuel-Amaro",
                        "structuredName": {
                            "firstName": "Emmanuel",
                            "lastName": "Amaro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Emmanuel Amaro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32646274"
                        ],
                        "name": "Hardik Sharma",
                        "slug": "Hardik-Sharma",
                        "structuredName": {
                            "firstName": "Hardik",
                            "lastName": "Sharma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hardik Sharma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112229"
                        ],
                        "name": "A. Yazdanbakhsh",
                        "slug": "A.-Yazdanbakhsh",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Yazdanbakhsh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yazdanbakhsh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117059930"
                        ],
                        "name": "J. Kim",
                        "slug": "J.-Kim",
                        "structuredName": {
                            "firstName": "Joon",
                            "lastName": "Kim",
                            "middleNames": [
                                "Kyung"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696563"
                        ],
                        "name": "H. Esmaeilzadeh",
                        "slug": "H.-Esmaeilzadeh",
                        "structuredName": {
                            "firstName": "Hadi",
                            "lastName": "Esmaeilzadeh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Esmaeilzadeh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": "Tabla [22] provides an FPGA accelerator generator for the training phase of statistical machine learning algorithms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6016019,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "160bd7cc365e55c966fea5e4624a8f736a7d979d",
            "isKey": false,
            "numCitedBy": 133,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "A growing number of commercial and enterprise systems increasingly rely on compute-intensive Machine Learning (ML) algorithms. While the demand for these compute-intensive applications is growing, the performance benefits from general-purpose platforms are diminishing. Field Programmable Gate Arrays (FPGAs) provide a promising path forward to accommodate the needs of machine learning algorithms and represent an intermediate point between the efficiency of ASICs and the programmability of general-purpose processors. However, acceleration with FPGAs still requires long development cycles and extensive expertise in hardware design. To tackle this challenge, instead of designing an accelerator for a machine learning algorithm, we present TABLA, a framework that generates accelerators for a class of machine learning algorithms. The key is to identify the commonalities across a wide range of machine learning algorithms and utilize this commonality to provide a high-level abstraction for programmers. TABLA leverages the insight that many learning algorithms can be expressed as a stochastic optimization problem. Therefore, learning becomes solving an optimization problem using stochastic gradient descent that minimizes an objective function over the training data. The gradient descent solver is fixed while the objective function changes for different learning algorithms. TABLA provides a template-based framework to accelerate this class of learning algorithms. Therefore, a developer can specify the learning task by only expressing the gradient of the objective function using our high-level language. Tabla then automatically generates the synthesizable implementation of the accelerator for FPGA realization using a set of hand-optimized templates. We use Tabla to generate accelerators for ten different learning tasks targeted at a Xilinx Zynq FPGA platform. We rigorously compare the benefits of FPGA acceleration to multi-core CPUs (ARM Cortex A15 and Xeon E3) and many-core GPUs (Tegra K1, GTX 650 Ti, and Tesla K40) using real hardware measurements. TABLA-generated accelerators provide 19.4x and 2.9x average speedup over the ARM and Xeon processors, respectively. These accelerators provide 17.57x, 20.2x, and 33.4x higher Performance-per-Watt in comparison to Tegra, GTX 650 Ti and Tesla, respectively. These benefits are achieved while the programmers write less than 50 lines of code."
            },
            "slug": "TABLA:-A-unified-template-based-framework-for-Mahajan-Park",
            "title": {
                "fragments": [],
                "text": "TABLA: A unified template-based framework for accelerating statistical machine learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "TABLA provides a template-based framework that generates accelerators for a class of machine learning algorithms and rigorously compares the benefits of FPGA acceleration to multi-core CPUs and many-core GPUs using real hardware measurements."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE International Symposium on High Performance Computer Architecture (HPCA)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39419985"
                        ],
                        "name": "Shaoli Liu",
                        "slug": "Shaoli-Liu",
                        "structuredName": {
                            "firstName": "Shaoli",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoli Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678776"
                        ],
                        "name": "Zidong Du",
                        "slug": "Zidong-Du",
                        "structuredName": {
                            "firstName": "Zidong",
                            "lastName": "Du",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zidong Du"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117237898"
                        ],
                        "name": "Jinhua Tao",
                        "slug": "Jinhua-Tao",
                        "structuredName": {
                            "firstName": "Jinhua",
                            "lastName": "Tao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jinhua Tao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122023913"
                        ],
                        "name": "D. Han",
                        "slug": "D.-Han",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068286576"
                        ],
                        "name": "Tao Luo",
                        "slug": "Tao-Luo",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1410066063"
                        ],
                        "name": "Yuan Xie",
                        "slug": "Yuan-Xie",
                        "structuredName": {
                            "firstName": "Yuan",
                            "lastName": "Xie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuan Xie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7377735"
                        ],
                        "name": "Yunji Chen",
                        "slug": "Yunji-Chen",
                        "structuredName": {
                            "firstName": "Yunji",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yunji Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144049725"
                        ],
                        "name": "Tianshi Chen",
                        "slug": "Tianshi-Chen",
                        "structuredName": {
                            "firstName": "Tianshi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianshi Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[42] propose an ISA for neural networks optimized for high code density over vector and matrix operations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 520236,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "da6e8bcf1c92167553a5b383fe6fe5109a4c0321",
            "isKey": false,
            "numCitedBy": 197,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural Networks (NN) are a family of models for a broad range of emerging machine learning and pattern recondition applications. NN techniques are conventionally executed on general-purpose processors (such as CPU and GPGPU), which are usually not energy-efficient since they invest excessive hardware resources to flexibly support various workloads. Consequently, application-specific hardware accelerators for neural networks have been proposed recently to improve the energy-efficiency. However, such accelerators were designed for a small set of NN techniques sharing similar computational patterns, and they adopt complex and informative instructions (control signals) directly corresponding to high-level functional blocks of an NN (such as layers), or even an NN as a whole. Although straightforward and easy-to-implement for a limited set of similar NN techniques, the lack of agility in the instruction set prevents such accelerator designs from supporting a variety of different NN techniques with sufficient flexibility and efficiency. In this paper, we propose a novel domain-specific Instruction Set Architecture (ISA) for NN accelerators, called Cambricon, which is a load-store architecture that integrates scalar, vector, matrix, logical, data transfer, and control instructions, based on a comprehensive analysis of existing NN techniques. Our evaluation over a total of ten representative yet distinct NN techniques have demonstrated that Cambricon exhibits strong descriptive capacity over a broad range of NN techniques, and provides higher code density than general-purpose ISAs such as \u00d786, MIPS, and GPGPU. Compared to the latest state-of-the-art NN accelerator design DaDianNao [5] (which can only accommodate 3 types of NN techniques), our Cambricon-based accelerator prototype implemented in TSMC 65nm technology incurs only negligible latency/power/area overheads, with a versatile coverage of 10 different NN benchmarks."
            },
            "slug": "Cambricon:-An-Instruction-Set-Architecture-for-Liu-Du",
            "title": {
                "fragments": [],
                "text": "Cambricon: An Instruction Set Architecture for Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper proposes a novel domain-specific Instruction Set Architecture (ISA) for NN accelerators, called Cambricon, which is a load-store architecture that integrates scalar, vector, matrix, logical, data transfer, and control instructions, based on a comprehensive analysis of existing NN techniques."
            },
            "venue": {
                "fragments": [],
                "text": "2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7377735"
                        ],
                        "name": "Yunji Chen",
                        "slug": "Yunji-Chen",
                        "structuredName": {
                            "firstName": "Yunji",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yunji Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068286576"
                        ],
                        "name": "Tao Luo",
                        "slug": "Tao-Luo",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39419985"
                        ],
                        "name": "Shaoli Liu",
                        "slug": "Shaoli-Liu",
                        "structuredName": {
                            "firstName": "Shaoli",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoli Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145407329"
                        ],
                        "name": "Shijin Zhang",
                        "slug": "Shijin-Zhang",
                        "structuredName": {
                            "firstName": "Shijin",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shijin Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37167270"
                        ],
                        "name": "Liqiang He",
                        "slug": "Liqiang-He",
                        "structuredName": {
                            "firstName": "Liqiang",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liqiang He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110368816"
                        ],
                        "name": "Jia Wang",
                        "slug": "Jia-Wang",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3353457"
                        ],
                        "name": "Ling Li",
                        "slug": "Ling-Li",
                        "structuredName": {
                            "firstName": "Ling",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ling Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144049725"
                        ],
                        "name": "Tianshi Chen",
                        "slug": "Tianshi-Chen",
                        "structuredName": {
                            "firstName": "Tianshi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianshi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719934"
                        ],
                        "name": "Zhiwei Xu",
                        "slug": "Zhiwei-Xu",
                        "structuredName": {
                            "firstName": "Zhiwei",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhiwei Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145550877"
                        ],
                        "name": "Ninghui Sun",
                        "slug": "Ninghui-Sun",
                        "structuredName": {
                            "firstName": "Ninghui",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ninghui Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731764"
                        ],
                        "name": "O. Temam",
                        "slug": "O.-Temam",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Temam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Temam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 25
                            }
                        ],
                        "text": "For example, (Da)Diannao [12, 13] provide DNN accelerators with a low-level fine-grained ISA, yet they do not define an ISA to unify DNN accelerators."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6838992,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4157ed3db4c656854e69931cb6089b64b08784b9",
            "isKey": false,
            "numCitedBy": 1065,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "Many companies are deploying services, either for consumers or industry, which are largely based on machine-learning algorithms for sophisticated processing of large amounts of data. The state-of-the-art and most popular such machine-learning algorithms are Convolutional and Deep Neural Networks (CNNs and DNNs), which are known to be both computationally and memory intensive. A number of neural network accelerators have been recently proposed which can offer high computational capacity/area ratio, but which remain hampered by memory accesses. However, unlike the memory wall faced by processors on general-purpose workloads, the CNNs and DNNs memory footprint, while large, is not beyond the capability of the on chip storage of a multi-chip system. This property, combined with the CNN/DNN algorithmic characteristics, can lead to high internal bandwidth and low external communications, which can in turn enable high-degree parallelism at a reasonable area cost. In this article, we introduce a custom multi-chip machine-learning architecture along those lines. We show that, on a subset of the largest known neural network layers, it is possible to achieve a speedup of 450.65x over a GPU, and reduce the energy by 150.31x on average for a 64-chip system. We implement the node down to the place and route at 28nm, containing a combination of custom storage and computational units, with industry-grade interconnects."
            },
            "slug": "DaDianNao:-A-Machine-Learning-Supercomputer-Chen-Luo",
            "title": {
                "fragments": [],
                "text": "DaDianNao: A Machine-Learning Supercomputer"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This article introduces a custom multi-chip machine-learning architecture, showing that, on a subset of the largest known neural network layers, it is possible to achieve a speedup of 450.65x over a GPU, and reduce the energy by 150.31x on average for a 64-chip system."
            },
            "venue": {
                "fragments": [],
                "text": "2014 47th Annual IEEE/ACM International Symposium on Microarchitecture"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6647160"
                        ],
                        "name": "Vinayak Gokhale",
                        "slug": "Vinayak-Gokhale",
                        "structuredName": {
                            "firstName": "Vinayak",
                            "lastName": "Gokhale",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vinayak Gokhale"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2592429"
                        ],
                        "name": "Jonghoon Jin",
                        "slug": "Jonghoon-Jin",
                        "structuredName": {
                            "firstName": "Jonghoon",
                            "lastName": "Jin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonghoon Jin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2130620"
                        ],
                        "name": "A. Dundar",
                        "slug": "A.-Dundar",
                        "structuredName": {
                            "firstName": "Aysegul",
                            "lastName": "Dundar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Dundar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1940285"
                        ],
                        "name": "B. Martini",
                        "slug": "B.-Martini",
                        "structuredName": {
                            "firstName": "Berin",
                            "lastName": "Martini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Martini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2889774"
                        ],
                        "name": "E. Culurciello",
                        "slug": "E.-Culurciello",
                        "structuredName": {
                            "firstName": "Eugenio",
                            "lastName": "Culurciello",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Culurciello"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[27] propose a mobile co-processor for DNNs and evaluate it on a Zynq board."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 32
                            }
                        ],
                        "text": "In fact, several research works [14, 15, 27, 28] have made extensive efforts to provide FPGA accelerators for specific DNN models, or parts of DNN computation, targeted for a particular FPGA platform."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7311716,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "233b1774f28c9972df2dfcf20dfbb0df45792bd0",
            "isKey": false,
            "numCitedBy": 253,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep networks are state-of-the-art models used for understanding the content of images, videos, audio and raw input data. Current computing systems are not able to run deep network models in real-time with low power consumption. In this paper we present nn-X: a scalable, low-power coprocessor for enabling real-time execution of deep neural networks. nn-X is implemented on programmable logic devices and comprises an array of configurable processing elements called collections. These collections perform the most common operations in deep networks: convolution, subsampling and non-linear functions. The nn-X system includes 4 high-speed direct memory access interfaces to DDR3 memory and two ARM Cortex-A9 processors. Each port is capable of a sustained throughput of 950 MB/s in full duplex. nn-X is able to achieve a peak performance of 227 G-ops/s, a measured performance in deep learning applications of up to 200 G-ops/s while consuming less than 4 watts of power. This translates to a performance per power improvement of 10 to 100 times that of conventional mobile and desktop processors."
            },
            "slug": "A-240-G-ops/s-Mobile-Coprocessor-for-Deep-Neural-Gokhale-Jin",
            "title": {
                "fragments": [],
                "text": "A 240 G-ops/s Mobile Coprocessor for Deep Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The nn-X system is presented, a scalable, low-power coprocessor for enabling real-time execution of deep neural networks, able to achieve a peak performance of 227 G-ops/s, which translates to a performance per power improvement of 10 to 100 times that of conventional mobile and desktop processors."
            },
            "venue": {
                "fragments": [],
                "text": "2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678776"
                        ],
                        "name": "Zidong Du",
                        "slug": "Zidong-Du",
                        "structuredName": {
                            "firstName": "Zidong",
                            "lastName": "Du",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zidong Du"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1785040"
                        ],
                        "name": "Robert Fasthuber",
                        "slug": "Robert-Fasthuber",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Fasthuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Fasthuber"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144049725"
                        ],
                        "name": "Tianshi Chen",
                        "slug": "Tianshi-Chen",
                        "structuredName": {
                            "firstName": "Tianshi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianshi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748620"
                        ],
                        "name": "P. Ienne",
                        "slug": "P.-Ienne",
                        "structuredName": {
                            "firstName": "Paolo",
                            "lastName": "Ienne",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Ienne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3353457"
                        ],
                        "name": "Ling Li",
                        "slug": "Ling-Li",
                        "structuredName": {
                            "firstName": "Ling",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ling Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068286576"
                        ],
                        "name": "Tao Luo",
                        "slug": "Tao-Luo",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Luo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Luo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32215073"
                        ],
                        "name": "Xiaobing Feng",
                        "slug": "Xiaobing-Feng",
                        "structuredName": {
                            "firstName": "Xiaobing",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaobing Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7377735"
                        ],
                        "name": "Yunji Chen",
                        "slug": "Yunji-Chen",
                        "structuredName": {
                            "firstName": "Yunji",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yunji Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731764"
                        ],
                        "name": "O. Temam",
                        "slug": "O.-Temam",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Temam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Temam"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In comparison, the generated accelerators deliver superior performance and efficiency without requiring the programmers to participate in the arduous task of hardware design."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 11504619,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bd6507b5c9deaf87bda81e59ce15b2309df0bf37",
            "isKey": false,
            "numCitedBy": 743,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years, neural network accelerators have been shown to achieve both high energy efficiency and high performance for a broad application scope within the important category of recognition and mining applications. Still, both the energy efficiency and peiformance of such accelerators remain limited by memory accesses. In this paper, we focus on image applications, arguably the most important category among recognition and mining applications. The neural networks which are state-of-the-art for these applications are Convolutional Neural Networks (CNN), and they have an important property: weights are shared among many neurons, considerably reducing the neural network memory footprint. This property allows to entirely map a CNN within an SRAM, eliminating all DRAM accesses for weights. By further hoisting this accelerator next to the image sensor, it is possible to eliminate all remaining DRAM accesses, i.e., for inputs and outputs. In this paper, we propose such a CNN accelerator, placed next to a CMOS or CCD sensor. The absence of DRAM accesses combined with a careful exploitation of the specific data access patterns within CNNs allows us to design an accelerator which is 60x more energy efficient than the previous state-of-the-art neural network accelerator. We present a fult design down to the layout at 65 nm, with a modest footprint of 4.86 mm2 and consuming only 320 mW, but still about 30x faster than high-end GPUs."
            },
            "slug": "ShiDianNao:-Shifting-vision-processing-closer-to-Du-Fasthuber",
            "title": {
                "fragments": [],
                "text": "ShiDianNao: Shifting vision processing closer to the sensor"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper proposes an accelerator which is 60x more energy efficient than the previous state-of-the-art neural network accelerator, designed down to the layout at 65 nm, with a modest footprint and consuming only 320 mW, but still about 30x faster than high-end GPUs."
            },
            "venue": {
                "fragments": [],
                "text": "2015 ACM/IEEE 42nd Annual International Symposium on Computer Architecture (ISCA)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638694"
                        ],
                        "name": "Adam Coates",
                        "slug": "Adam-Coates",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Coates",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Coates"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2570381"
                        ],
                        "name": "Brody Huval",
                        "slug": "Brody-Huval",
                        "structuredName": {
                            "firstName": "Brody",
                            "lastName": "Huval",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brody Huval"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2156632012"
                        ],
                        "name": "Tao Wang",
                        "slug": "Tao-Wang",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "25629078"
                        ],
                        "name": "David J. Wu",
                        "slug": "David-J.-Wu",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Wu",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2301680"
                        ],
                        "name": "Bryan Catanzaro",
                        "slug": "Bryan-Catanzaro",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "Catanzaro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bryan Catanzaro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 85
                            }
                        ],
                        "text": "We use hardware measurements to compare the generated accelerators to both multicore CPUs (ARM Cortex A15 and Xeon E3) and many-core GPUs (Tegra K1, GTX 650Ti, and Tesla K40)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8604637,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d1208ac421cf8ff67b27d93cd19ae42b8d596f95",
            "isKey": false,
            "numCitedBy": 679,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Scaling up deep learning algorithms has been shown to lead to increased performance in benchmark tasks and to enable discovery of complex high-level features. Recent efforts to train extremely large networks (with over 1 billion parameters) have relied on cloudlike computing infrastructure and thousands of CPU cores. In this paper, we present technical details and results from our own system based on Commodity Off-The-Shelf High Performance Computing (COTS HPC) technology: a cluster of GPU servers with Infiniband interconnects and MPI. Our system is able to train 1 billion parameter networks on just 3 machines in a couple of days, and we show that it can scale to networks with over 11 billion parameters using just 16 machines. As this infrastructure is much more easily marshaled by others, the approach enables much wider-spread research with extremely large neural networks."
            },
            "slug": "Deep-learning-with-COTS-HPC-systems-Coates-Huval",
            "title": {
                "fragments": [],
                "text": "Deep learning with COTS HPC systems"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper presents technical details and results from their own system based on Commodity Off-The-Shelf High Performance Computing (COTS HPC) technology: a cluster of GPU servers with Infiniband interconnects and MPI, and shows that it can scale to networks with over 11 billion parameters using just 16 machines."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39978391"
                        ],
                        "name": "Yangqing Jia",
                        "slug": "Yangqing-Jia",
                        "structuredName": {
                            "firstName": "Yangqing",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yangqing Jia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782282"
                        ],
                        "name": "Evan Shelhamer",
                        "slug": "Evan-Shelhamer",
                        "structuredName": {
                            "firstName": "Evan",
                            "lastName": "Shelhamer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Evan Shelhamer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7408951"
                        ],
                        "name": "Jeff Donahue",
                        "slug": "Jeff-Donahue",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Donahue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeff Donahue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3049736"
                        ],
                        "name": "Sergey Karayev",
                        "slug": "Sergey-Karayev",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Karayev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sergey Karayev"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117314646"
                        ],
                        "name": "Jonathan Long",
                        "slug": "Jonathan-Long",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Long",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Long"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2983898"
                        ],
                        "name": "Ross B. Girshick",
                        "slug": "Ross-B.-Girshick",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Girshick",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross B. Girshick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687120"
                        ],
                        "name": "S. Guadarrama",
                        "slug": "S.-Guadarrama",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Guadarrama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Guadarrama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 70
                            }
                        ],
                        "text": "Figure 14 shows the runtime breakdown of the models computed from the Caffe framework using two baselines platforms, Xeon E3 and Tesla K40."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 58
                            }
                        ],
                        "text": "The performance of Xeon E3 for the eight DNN models using Caffe\u2019s framework is used as a baseline for comparison."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 109
                            }
                        ],
                        "text": "Recall that for none of the FPGA acceleration, DNNWEAVER requires anything beyond just expressing the DNN in Caffe format."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 56
                            }
                        ],
                        "text": "The programming interface is the same as Berkeley Caffe [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "Caffe is a widely used open-source deep learning framework that takes the DNN specification as input and computes the given model on CPUs and GPUs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 120
                            }
                        ],
                        "text": "We compare the execution time\nof DNNWEAVER generated accelerators to the execution time on CPUs and GPUs using Berkeley Caffe."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 62
                            }
                        ],
                        "text": "We obtain the baseline timings by using the timing feature of Caffe."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 89
                            }
                        ],
                        "text": "The input to DNNWEAVER is a high-level specification of the DNN in Berkeley Caffe format [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 49
                            }
                        ],
                        "text": "We use OpenBLAS for the BLAS backend required by Caffe to produce CPUspecific optimized binaries."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 17
                            }
                        ],
                        "text": "Translation from Caffe to this ISA is straightforward since the instructions match the DNN layers."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 200,
                                "start": 197
                            }
                        ],
                        "text": "This work tackles these challenges by devising DNNWEAVER, a framework that automatically generates a synthesizable accelerator for a given (DNN, FPGA) pair from a high-level specification in Caffe [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 111
                            }
                        ],
                        "text": "The code snippet in Figure 2 shows how two DNN layers, convolution and pooling, are described and connected in Caffe."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 27
                            }
                        ],
                        "text": "For fastest GPU execution, Caffe can be configured to use the NVIDIA cuDNN library."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1799558,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6bdb186ec4726e00a8051119636d4df3b94043b5",
            "isKey": true,
            "numCitedBy": 13814,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments. Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community of contributors on GitHub. It powers ongoing research projects, large-scale industrial applications, and startup prototypes in vision, speech, and multimedia."
            },
            "slug": "Caffe:-Convolutional-Architecture-for-Fast-Feature-Jia-Shelhamer",
            "title": {
                "fragments": [],
                "text": "Caffe: Convolutional Architecture for Fast Feature Embedding"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Multimedia"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2522763"
                        ],
                        "name": "Jorge Albericio",
                        "slug": "Jorge-Albericio",
                        "structuredName": {
                            "firstName": "Jorge",
                            "lastName": "Albericio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jorge Albericio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49226305"
                        ],
                        "name": "Patrick Judd",
                        "slug": "Patrick-Judd",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Judd",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick Judd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3278112"
                        ],
                        "name": "Tayler H. Hetherington",
                        "slug": "Tayler-H.-Hetherington",
                        "structuredName": {
                            "firstName": "Tayler",
                            "lastName": "Hetherington",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tayler H. Hetherington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742561"
                        ],
                        "name": "Tor M. Aamodt",
                        "slug": "Tor-M.-Aamodt",
                        "structuredName": {
                            "firstName": "Tor",
                            "lastName": "Aamodt",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tor M. Aamodt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727551"
                        ],
                        "name": "N. E. Jerger",
                        "slug": "N.-E.-Jerger",
                        "structuredName": {
                            "firstName": "Natalie",
                            "lastName": "Jerger",
                            "middleNames": [
                                "D.",
                                "Enright"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. E. Jerger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782536"
                        ],
                        "name": "Andreas Moshovos",
                        "slug": "Andreas-Moshovos",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Moshovos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Moshovos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "EIE [45], Minerva [46], and Cnvlutin [47] propose ASIC accelerators that use operation pruning and quantization in DNNs for power and performance benefits."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9841314,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49b4094f2c313a92da4461572c0bef80b0d7d649",
            "isKey": false,
            "numCitedBy": 444,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "This work observes that a large fraction of the computations performed by Deep Neural Networks (DNNs) are intrinsically ineffectual as they involve a multiplication where one of the inputs is zero. This observation motivates Cnvolutin (CNV), a value-based approach to hardware acceleration that eliminates most of these ineffectual operations, improving performance and energy over a state-of-the-art accelerator with no accuracy loss. CNV uses hierarchical data-parallel units, allowing groups of lanes to proceed mostly independently enabling them to skip over the ineffectual computations. A co-designed data storage format encodes the computation elimination decisions taking them off the critical path while avoiding control divergence in the data parallel units. Combined, the units and the data storage format result in a data-parallel architecture that maintains wide, aligned accesses to its memory hierarchy and that keeps its data lanes busy. By loosening the ineffectual computation identification criterion, CNV enables further performance and energy efficiency improvements, and more so if a loss in accuracy is acceptable. Experimental measurements over a set of state-of-the-art DNNs for image classification show that CNV improves performance over a state-of-the-art accelerator from 1.24\u00d7 to 1.55\u00d7 and by 1.37\u00d7 on average without any loss in accuracy by removing zero-valued operand multiplications alone. While CNV incurs an area overhead of 4.49%, it improves overall EDP (Energy Delay Product) and ED2P (Energy Delay Squared Product) on average by 1.47\u00d7 and 2.01\u00d7, respectively. The average performance improvements increase to 1.52\u00d7 without any loss in accuracy with a broader ineffectual identification policy. Further improvements are demonstrated with a loss in accuracy."
            },
            "slug": "Cnvlutin:-Ineffectual-Neuron-Free-Deep-Neural-Albericio-Judd",
            "title": {
                "fragments": [],
                "text": "Cnvlutin: Ineffectual-Neuron-Free Deep Neural Network Computing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Cnvolutin (CNV), a value-based approach to hardware acceleration that eliminates most of these ineffectual operations, improving performance and energy over a state-of-the-art accelerator with no accuracy loss."
            },
            "venue": {
                "fragments": [],
                "text": "2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721381"
                        ],
                        "name": "Francesco Conti",
                        "slug": "Francesco-Conti",
                        "structuredName": {
                            "firstName": "Francesco",
                            "lastName": "Conti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Francesco Conti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710649"
                        ],
                        "name": "L. Benini",
                        "slug": "L.-Benini",
                        "structuredName": {
                            "firstName": "Luca",
                            "lastName": "Benini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Benini"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[26] develop convolution cores designed to integrate with a shared-memory cluster of RISC processors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18185413,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee6fc98691d9a40e76d0f3e74e23cc1c94d1ed92",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "State-of-art brain-inspired computer vision algorithms such as Convolutional Neural Networks (CNNs) are reaching accuracy and performance rivaling that of humans; however, the gap in terms of energy consumption is still many degrees of magnitude wide. Many-core architectures using shared-memory clusters of power-optimized RISC processors have been proposed as a possible solution to help close this gap. In this work, we propose to augment these clusters with Hardware Convolution Engines (HWCEs): ultra-low energy coprocessors for accelerating convolutions, the main building block of many brain-inspired computer vision algorithms. Our synthesis results in ST 28nm FD-SOI technology show that the HWCE is capable of performing a convolution in the lowest-energy state spending as little as 35 pJ/pixel on average, with an optimum case of 6.5 pJ/pixel. Furthermore, we show that augmenting a cluster with a HWCE can lead to an average boost of 40x or more in energy efficiency in convolutional workloads."
            },
            "slug": "A-ultra-low-energy-convolution-engine-for-fast-in-Conti-Benini",
            "title": {
                "fragments": [],
                "text": "A ultra-low-energy convolution engine for fast brain-inspired vision in multicore clusters"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes to augment many-core architectures using shared-memory clusters of power-optimized RISC processors with Hardware Convolution Engines (HWCEs): ultra-low energy coprocessors for accelerating convolutions, the main building block of many brain-inspired computer vision algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "2015 Design, Automation & Test in Europe Conference & Exhibition (DATE)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50579876"
                        ],
                        "name": "Yu-hsin Chen",
                        "slug": "Yu-hsin-Chen",
                        "structuredName": {
                            "firstName": "Yu-hsin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu-hsin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775477"
                        ],
                        "name": "J. Emer",
                        "slug": "J.-Emer",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Emer",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Emer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691305"
                        ],
                        "name": "V. Sze",
                        "slug": "V.-Sze",
                        "structuredName": {
                            "firstName": "Vivienne",
                            "lastName": "Sze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Sze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3291270,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ec594e9f5ca4b629be28625cd78c882514ea3be",
            "isKey": false,
            "numCitedBy": 838,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep convolutional neural networks (CNNs) are widely used in modern AI systems for their superior accuracy but at the cost of high computational complexity. The complexity comes from the need to simultaneously process hundreds of filters and channels in the high-dimensional convolutions, which involve a significant amount of data movement. Although highly-parallel compute paradigms, such as SIMD/SIMT, effectively address the computation requirement to achieve high throughput, energy consumption still remains high as data movement can be more expensive than computation. Accordingly, finding a dataflow that supports parallel processing with minimal data movement cost is crucial to achieving energy-efficient CNN processing without compromising accuracy. In this paper, we present a novel dataflow, called row-stationary (RS), that minimizes data movement energy consumption on a spatial architecture. This is realized by exploiting local data reuse of filter weights and feature map pixels, i.e., activations, in the high-dimensional convolutions, and minimizing data movement of partial sum accumulations. Unlike dataflows used in existing designs, which only reduce certain types of data movement, the proposed RS dataflow can adapt to different CNN shape configurations and reduces all types of data movement through maximally utilizing the processing engine (PE) local storage, direct inter-PE communication and spatial parallelism. To evaluate the energy efficiency of the different dataflows, we propose an analysis framework that compares energy cost under the same hardware area and processing parallelism constraints. Experiments using the CNN configurations of AlexNet show that the proposed RS dataflow is more energy efficient than existing dataflows in both convolutional (1.4\u00d7 to 2.5\u00d7) and fully-connected layers (at least 1.3\u00d7 for batch size larger than 16). The RS dataflow has also been demonstrated on a fabricated chip, which verifies our energy analysis."
            },
            "slug": "Eyeriss:-A-Spatial-Architecture-for-Dataflow-for-Chen-Emer",
            "title": {
                "fragments": [],
                "text": "Eyeriss: A Spatial Architecture for Energy-Efficient Dataflow for Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel dataflow, called row-stationary (RS), is presented that minimizes data movement energy consumption on a spatial architecture and can adapt to different CNN shape configurations and reduces all types of data movement through maximally utilizing the processing engine local storage, direct inter-PE communication and spatial parallelism."
            },
            "venue": {
                "fragments": [],
                "text": "2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40565044"
                        ],
                        "name": "Shaoyi Cheng",
                        "slug": "Shaoyi-Cheng",
                        "structuredName": {
                            "firstName": "Shaoyi",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoyi Cheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762709"
                        ],
                        "name": "J. Wawrzynek",
                        "slug": "J.-Wawrzynek",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Wawrzynek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wawrzynek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "Moreover, another recent work [37] shows that using dataflow templates as an intermediate compilation target for high-level synthesis of C/C++ programs delivers 9\u00d7 higher performance than the state-of-the-art HLS tools."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1809757,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "20941b4ca2fb99512bdceeec3f038921b2dff293",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work, we present a new approach to high level synthesis (HLS), where high level functions are first mapped to an architectural template, before hardware synthesis is performed. As FPGA platforms are especially suitable for implementing streaming processing pipelines, we perform transformations on conventional high level programs where they are turned into multi-stage dataflow engines [1]. This target template naturally overlaps slow memory data accesses with computations and therefore has much better tolerance towards memory subsystem latency. Using a state-of-the-art HLS tool for the actual circuit generation, we observe up to 9x improvement in overall performance when the dataflow architectural template is used as an intermediate compilation target."
            },
            "slug": "High-Level-Synthesis-with-a-Dataflow-Architectural-Cheng-Wawrzynek",
            "title": {
                "fragments": [],
                "text": "High Level Synthesis with a Dataflow Architectural Template"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "This work presents a new approach to high level synthesis (HLS), where high level functions are first mapped to an architectural template, before hardware synthesis is performed, and observes up to 9x improvement in overall performance when the dataflow architectural template is used as an intermediate compilation target."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2045975"
                        ],
                        "name": "Jaehyeong Sim",
                        "slug": "Jaehyeong-Sim",
                        "structuredName": {
                            "firstName": "Jaehyeong",
                            "lastName": "Sim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jaehyeong Sim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109219957"
                        ],
                        "name": "Jun-Seok Park",
                        "slug": "Jun-Seok-Park",
                        "structuredName": {
                            "firstName": "Jun-Seok",
                            "lastName": "Park",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun-Seok Park"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110187596"
                        ],
                        "name": "Minhye Kim",
                        "slug": "Minhye-Kim",
                        "structuredName": {
                            "firstName": "Minhye",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minhye Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3367358"
                        ],
                        "name": "Dongmyung Bae",
                        "slug": "Dongmyung-Bae",
                        "structuredName": {
                            "firstName": "Dongmyung",
                            "lastName": "Bae",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dongmyung Bae"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3389760"
                        ],
                        "name": "Yeongjae Choi",
                        "slug": "Yeongjae-Choi",
                        "structuredName": {
                            "firstName": "Yeongjae",
                            "lastName": "Choi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yeongjae Choi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144843517"
                        ],
                        "name": "L. Kim",
                        "slug": "L.-Kim",
                        "structuredName": {
                            "firstName": "Lee-Sup",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Kim"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[24] showcase a DNN ASIC for IoT devices."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1373015,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "46494c6c0e2dd1dca8cd39d40a9681c7d5d6ba62",
            "isKey": false,
            "numCitedBy": 142,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present an energy-efficient CNN processor with 4 key features: (1) a CNN-optimized neuron processing engine (NPE), (2) a dual-range multiplyaccumulate (DRMAC) block for low-power convolution operations, (3) an on-chip memory architecture and a utilization scheme for reducing off-chip memory accesses, (4) kernel data compression for further reducing off-chip memory accesses."
            },
            "slug": "14.6-A-1.42TOPS/W-deep-convolutional-neural-network-Sim-Park",
            "title": {
                "fragments": [],
                "text": "14.6 A 1.42TOPS/W deep convolutional neural network recognition processor for intelligent IoE systems"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "This paper presents an energy-efficient CNN processor with a CNN-optimized neuron processing engine (NPE), a dual-range multiplyaccumulate (DRMAC) block for low-power convolution operations, an on-chip memory architecture and a utilization scheme for reducing off- chip memory accesses."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE International Solid-State Circuits Conference (ISSCC)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118927386"
                        ],
                        "name": "S. Gupta",
                        "slug": "S.-Gupta",
                        "structuredName": {
                            "firstName": "Shantanu",
                            "lastName": "Gupta",
                            "middleNames": [
                                "Sen"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2020641"
                        ],
                        "name": "Shuguang Feng",
                        "slug": "Shuguang-Feng",
                        "structuredName": {
                            "firstName": "Shuguang",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuguang Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2186447"
                        ],
                        "name": "Amin Ansari",
                        "slug": "Amin-Ansari",
                        "structuredName": {
                            "firstName": "Amin",
                            "lastName": "Ansari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amin Ansari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721289"
                        ],
                        "name": "S. Mahlke",
                        "slug": "S.-Mahlke",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Mahlke",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mahlke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722513"
                        ],
                        "name": "D. I. August",
                        "slug": "D.-I.-August",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "August",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. I. August"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In comparison, the generated accelerators deliver superior performance and efficiency without requiring the programmers to participate in the arduous task of hardware design."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 401953,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31f3e5c2f4b7c216fa8a50150b4f3944c24cb6b4",
            "isKey": false,
            "numCitedBy": 103,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Technology scaling has delivered on its promises of increasing device density on a single chip. However, the voltage scaling trend has failed to keep up, introducing tight power constraints on manufactured parts. In such a scenario, there is a need to incorporate energy-efficient processing resources that can enable more computation within the same power budget. Energy efficiency solutions in the past have typically relied on application specific hardware and accelerators. Unfortunately, these approaches do not extend to general purpose applications due to their irregular and diverse code base. Towards this end, we propose BERET, an energy-efficient co-processor that can be configured to benefit a wide range of applications. Our approach identifies recurring instruction sequences as phases of \u201ctemporal regularity\u201d in a program's execution, and maps suitable ones to the BERET hardware, a three-stage pipeline with a bundled execution model. This judicious off-loading of program execution to a reduced-complexity hardware demonstrates significant savings on instruction fetch, decode and register file accesses energy. On average, BERET reduces energy consumption by a factor of 3\u20134X for the program regions selected across a range of general-purpose and media applications. The average energy savings for the entire application run was 35% over a single-issue in-order processor."
            },
            "slug": "Bundled-execution-of-recurring-traces-for-general-Gupta-Feng",
            "title": {
                "fragments": [],
                "text": "Bundled execution of recurring traces for energy-efficient general purpose processing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This approach identifies recurring instruction sequences as phases of \u201ctemporal regularity\u201d in a program's execution, and maps suitable ones to the BERET hardware, a three-stage pipeline with a bundled execution model that demonstrates significant savings on instruction fetch, decode and register file accesses energy."
            },
            "venue": {
                "fragments": [],
                "text": "2011 44th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752242"
                        ],
                        "name": "S. Chakradhar",
                        "slug": "S.-Chakradhar",
                        "structuredName": {
                            "firstName": "Srimat",
                            "lastName": "Chakradhar",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chakradhar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2329060"
                        ],
                        "name": "M. Sankaradass",
                        "slug": "M.-Sankaradass",
                        "structuredName": {
                            "firstName": "Murugan",
                            "lastName": "Sankaradass",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sankaradass"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2101580"
                        ],
                        "name": "V. Jakkula",
                        "slug": "V.-Jakkula",
                        "structuredName": {
                            "firstName": "Venkata",
                            "lastName": "Jakkula",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Jakkula"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2468150"
                        ],
                        "name": "S. Cadambi",
                        "slug": "S.-Cadambi",
                        "structuredName": {
                            "firstName": "Srihari",
                            "lastName": "Cadambi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Cadambi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[38] present a VLIW co-processor for DNNs and emulate it on a Virtex 5 FPGA."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3350152,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e1c4e2fa071046569a05e9cfdf13496d094025dd",
            "isKey": false,
            "numCitedBy": 350,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional neural networks (CNN) applications range from recognition and reasoning (such as handwriting recognition, facial expression recognition and video surveillance) to intelligent text applications such as semantic text analysis and natural language processing applications. Two key observations drive the design of a new architecture for CNN. First, CNN workloads exhibit a widely varying mix of three types of parallelism: parallelism within a convolution operation, intra-output parallelism where multiple input sources (features) are combined to create a single output, and inter-output parallelism where multiple, independent outputs (features) are computed simultaneously. Workloads differ significantly across different CNN applications, and across different layers of a CNN. Second, the number of processing elements in an architecture continues to scale (as per Moore's law) much faster than off-chip memory bandwidth (or pin-count) of chips. Based on these two observations, we show that for a given number of processing elements and off-chip memory bandwidth, a new CNN hardware architecture that dynamically configures the hardware on-the-fly to match the specific mix of parallelism in a given workload gives the best throughput performance. Our CNN compiler automatically translates high abstraction network specification into a parallel microprogram (a sequence of low-level VLIW instructions) that is mapped, scheduled and executed by the coprocessor. Compared to a 2.3 GHz quad-core, dual socket Intel Xeon, 1.35 GHz C870 GPU, and a 200 MHz FPGA implementation, our 120 MHz dynamically configurable architecture is 4x to 8x faster. This is the first CNN architecture to achieve real-time video stream processing (25 to 30 frames per second) on a wide range of object detection and recognition tasks."
            },
            "slug": "A-dynamically-configurable-coprocessor-for-neural-Chakradhar-Sankaradass",
            "title": {
                "fragments": [],
                "text": "A dynamically configurable coprocessor for convolutional neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This is the first CNN architecture to achieve real-time video stream processing (25 to 30 frames per second) on a wide range of object detection and recognition tasks."
            },
            "venue": {
                "fragments": [],
                "text": "ISCA"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115490017"
                        ],
                        "name": "Dao-Fu Liu",
                        "slug": "Dao-Fu-Liu",
                        "structuredName": {
                            "firstName": "Dao-Fu",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dao-Fu Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144049725"
                        ],
                        "name": "Tianshi Chen",
                        "slug": "Tianshi-Chen",
                        "structuredName": {
                            "firstName": "Tianshi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianshi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39419985"
                        ],
                        "name": "Shaoli Liu",
                        "slug": "Shaoli-Liu",
                        "structuredName": {
                            "firstName": "Shaoli",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoli Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069662"
                        ],
                        "name": "Jinhong Zhou",
                        "slug": "Jinhong-Zhou",
                        "structuredName": {
                            "firstName": "Jinhong",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jinhong Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115867314"
                        ],
                        "name": "Shengyuan Zhou",
                        "slug": "Shengyuan-Zhou",
                        "structuredName": {
                            "firstName": "Shengyuan",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shengyuan Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731764"
                        ],
                        "name": "O. Temam",
                        "slug": "O.-Temam",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Temam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Temam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32215073"
                        ],
                        "name": "Xiaobing Feng",
                        "slug": "Xiaobing-Feng",
                        "structuredName": {
                            "firstName": "Xiaobing",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaobing Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8453780"
                        ],
                        "name": "Xuehai Zhou",
                        "slug": "Xuehai-Zhou",
                        "structuredName": {
                            "firstName": "Xuehai",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xuehai Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7377735"
                        ],
                        "name": "Yunji Chen",
                        "slug": "Yunji-Chen",
                        "structuredName": {
                            "firstName": "Yunji",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yunji Chen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "With diminishing benefits from technology scaling [10, 11], the research community is increasingly turning to specialized accelerators for deep networks [12\u201315] and other workloads [16\u201322]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "PuDianNao [20] is an ASIC accelerator for machine learning algorithms but lacks deep convolutional networks support."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8940335,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "68837728232463651283edbb7ef0c93b2f502b2b",
            "isKey": false,
            "numCitedBy": 266,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Machine Learning (ML) techniques are pervasive tools in various emerging commercial applications, but have to be accommodated by powerful computer systems to process very large data. Although general-purpose CPUs and GPUs have provided straightforward solutions, their energy-efficiencies are limited due to their excessive supports for flexibility. Hardware accelerators may achieve better energy-efficiencies, but each accelerator often accommodates only a single ML technique (family). According to the famous No-Free-Lunch theorem in the ML domain, however, an ML technique performs well on a dataset may perform poorly on another dataset, which implies that such accelerator may sometimes lead to poor learning accuracy. Even if regardless of the learning accuracy, such accelerator can still become inapplicable simply because the concrete ML task is altered, or the user chooses another ML technique. In this study, we present an ML accelerator called PuDianNao, which accommodates seven representative ML techniques, including k-means, k-nearest neighbors, naive bayes, support vector machine, linear regression, classification tree, and deep neural network. Benefited from our thorough analysis on computational primitives and locality properties of different ML techniques, PuDianNao can perform up to 1056 GOP/s (e.g., additions and multiplications) in an area of 3.51 mm^2, and consumes 596 mW only. Compared with the NVIDIA K20M GPU (28nm process), PuDianNao (65nm process) is 1.20x faster, and can reduce the energy by 128.41x."
            },
            "slug": "PuDianNao:-A-Polyvalent-Machine-Learning-Liu-Chen",
            "title": {
                "fragments": [],
                "text": "PuDianNao: A Polyvalent Machine Learning Accelerator"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "An ML accelerator called PuDianNao is presented, which accommodates seven representative ML techniques, including k-means, k-nearest neighbors, naive bayes, support vector machine, linear regression, classification tree, and deep neural network, and can perform up to 1056 GOP/s, and consumes 596 mW only."
            },
            "venue": {
                "fragments": [],
                "text": "ASPLOS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48930265"
                        ],
                        "name": "Venkatraman Govindaraju",
                        "slug": "Venkatraman-Govindaraju",
                        "structuredName": {
                            "firstName": "Venkatraman",
                            "lastName": "Govindaraju",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Venkatraman Govindaraju"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802116"
                        ],
                        "name": "C. Ho",
                        "slug": "C.-Ho",
                        "structuredName": {
                            "firstName": "Chen-Han",
                            "lastName": "Ho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Ho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720300"
                        ],
                        "name": "K. Sankaralingam",
                        "slug": "K.-Sankaralingam",
                        "structuredName": {
                            "firstName": "Karthikeyan",
                            "lastName": "Sankaralingam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sankaralingam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In comparison, the generated accelerators deliver superior performance and efficiency without requiring the programmers to participate in the arduous task of hardware design."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14408065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "319993de8b5ba6f42a416f6cb7f856268c348baa",
            "isKey": false,
            "numCitedBy": 208,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Due to limits in technology scaling, energy efficiency of logic devices is decreasing in successive generations. To provide continued performance improvements without increasing power, regardless of the sequential or parallel nature of the application, microarchitectural energy efficiency must improve. We propose Dynamically Specialized Datapaths to improve the energy efficiency of general purpose programmable processors. The key insights of this work are the following. First, applications execute in phases and these phases can be determined by creating a path-tree of basic-blocks rooted at the inner-most loop. Second, specialized datapaths corresponding to these path-trees, which we refer to as DySER blocks, can be constructed by interconnecting a set of heterogeneous computation units with a circuit-switched network. These blocks can be easily integrated with a processor pipeline. A synthesized RTL implementation using an industry 55nm technology library shows a 64-functional-unit DySER block occupies approximately the same area as a 64 KB single-ported SRAM and can execute at 2 GHz. We extend the GCC compiler to identify path-trees and code-mapping to DySER and evaluate the PAR-SEC, SPEC and Parboil benchmarks suites. Our results show that in most cases two DySER blocks can achieve the same performance (within 5%) as having a specialized hardware module for each path-tree. A 64-FU DySER block can cover 12% to 100% of the dynamically executed instruction stream. When integrated with a dual-issue out-of-order processor, two DySER blocks provide geometric mean speedup of 2.1X (1.15X to 10X), and geometric mean energy reduction of 40% (up to 70%), and 60% energy reduction if no performance improvement is required."
            },
            "slug": "Dynamically-Specialized-Datapaths-for-energy-Govindaraju-Ho",
            "title": {
                "fragments": [],
                "text": "Dynamically Specialized Datapaths for energy efficient computing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "D Dynamically Specialized Datapaths are proposed to improve the energy efficiency of general purpose programmable processors and show that in most cases two DySER blocks can achieve the same performance as having a specialized hardware module for each path-tree."
            },
            "venue": {
                "fragments": [],
                "text": "2011 IEEE 17th International Symposium on High Performance Computer Architecture"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 73
                            }
                        ],
                        "text": "We use hardware measurements to compare the generated accelerators to both multicore CPUs (ARM Cortex A15 and Xeon E3) and many-core GPUs (Tegra K1, GTX 650Ti, and Tesla K40)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 195908774,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "isKey": false,
            "numCitedBy": 82053,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry."
            },
            "slug": "ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever",
            "title": {
                "fragments": [],
                "text": "ImageNet classification with deep convolutional neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A large, deep convolutional neural network was trained to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes and employed a recently developed regularization method called \"dropout\" that proved to be very effective."
            },
            "venue": {
                "fragments": [],
                "text": "Commun. ACM"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2872576"
                        ],
                        "name": "W. Qadeer",
                        "slug": "W.-Qadeer",
                        "structuredName": {
                            "firstName": "Wajahat",
                            "lastName": "Qadeer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Qadeer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37116969"
                        ],
                        "name": "R. Hameed",
                        "slug": "R.-Hameed",
                        "structuredName": {
                            "firstName": "Rehan",
                            "lastName": "Hameed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hameed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1788630"
                        ],
                        "name": "O. Shacham",
                        "slug": "O.-Shacham",
                        "structuredName": {
                            "firstName": "Ofer",
                            "lastName": "Shacham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "O. Shacham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "72076105"
                        ],
                        "name": "P. Venkatesan",
                        "slug": "P.-Venkatesan",
                        "structuredName": {
                            "firstName": "Preethi",
                            "lastName": "Venkatesan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Venkatesan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700331"
                        ],
                        "name": "C. Kozyrakis",
                        "slug": "C.-Kozyrakis",
                        "structuredName": {
                            "firstName": "Christoforos",
                            "lastName": "Kozyrakis",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Kozyrakis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144764327"
                        ],
                        "name": "M. Horowitz",
                        "slug": "M.-Horowitz",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Horowitz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Horowitz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[25] propose Convolution Engine which reduces the number of operations required in convolution layers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3117823,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d50d7cd78126cd4df5dda62f1a75c89d095bc8a5",
            "isKey": false,
            "numCitedBy": 165,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper focuses on the trade-off between flexibility and efficiency in specialized computing. We observe that specialized units achieve most of their efficiency gains by tuning data storage and compute structures and their connectivity to the data-flow and data-locality patterns in the kernels. Hence, by identifying key data-flow patterns used in a domain, we can create efficient engines that can be programmed and reused across a wide range of applications. We present an example, the Convolution Engine (CE), specialized for the convolution-like data-flow that is common in computational photography, image processing, and video processing applications. CE achieves energy efficiency by capturing data reuse patterns, eliminating data transfer overheads, and enabling a large number of operations per memory access. We quantify the tradeoffs in efficiency and flexibility and demonstrate that CE is within a factor of 2-3x of the energy and area efficiency of custom units optimized for a single kernel. CE improves energy and area efficiency by 8-15x over a SIMD engine for most applications."
            },
            "slug": "Convolution-engine:-balancing-efficiency-&-in-Qadeer-Hameed",
            "title": {
                "fragments": [],
                "text": "Convolution engine: balancing efficiency & flexibility in specialized computing"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The Convolution Engine, specialized for the convolution-like data-flow that is common in computational photography, image processing, and video processing applications, is presented and it is demonstrated that CE is within a factor of 2-3x of the energy and area efficiency of custom units optimized for a single kernel."
            },
            "venue": {
                "fragments": [],
                "text": "ISCA"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256269"
                        ],
                        "name": "C. Farabet",
                        "slug": "C.-Farabet",
                        "structuredName": {
                            "firstName": "Cl\u00e9ment",
                            "lastName": "Farabet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Farabet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1940285"
                        ],
                        "name": "B. Martini",
                        "slug": "B.-Martini",
                        "structuredName": {
                            "firstName": "Berin",
                            "lastName": "Martini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Martini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2079955555"
                        ],
                        "name": "B. Corda",
                        "slug": "B.-Corda",
                        "structuredName": {
                            "firstName": "B.",
                            "lastName": "Corda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Corda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2447628"
                        ],
                        "name": "Polina Akselrod",
                        "slug": "Polina-Akselrod",
                        "structuredName": {
                            "firstName": "Polina",
                            "lastName": "Akselrod",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Polina Akselrod"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2889774"
                        ],
                        "name": "E. Culurciello",
                        "slug": "E.-Culurciello",
                        "structuredName": {
                            "firstName": "Eugenio",
                            "lastName": "Culurciello",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Culurciello"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "[15, 28] develops an FPGA accelerator for a specific DNN."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 32
                            }
                        ],
                        "text": "In fact, several research works [14, 15, 27, 28] have made extensive efforts to provide FPGA accelerators for specific DNN models, or parts of DNN computation, targeted for a particular FPGA platform."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 851574,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "204710a6a6d935150b5b16daf74493dea6d1b7a2",
            "isKey": false,
            "numCitedBy": 349,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a scalable dataflow hardware architecture optimized for the computation of general-purpose vision algorithms \u2014 neuFlow \u2014 and a dataflow compiler \u2014 luaFlow \u2014 that transforms high-level flow-graph representations of these algorithms into machine code for neuFlow. This system was designed with the goal of providing real-time detection, categorization and localization of objects in complex scenes, while consuming 10 Watts when implemented on a Xilinx Virtex 6 FPGA platform, or about ten times less than a laptop computer, and producing speedups of up to 100 times in real-world applications. We present an application of the system on street scene analysis, segmenting 20 categories on 500 \u00d7 375 frames at 12 frames per second on our custom hardware neuFlow."
            },
            "slug": "NeuFlow:-A-runtime-reconfigurable-dataflow-for-Farabet-Martini",
            "title": {
                "fragments": [],
                "text": "NeuFlow: A runtime reconfigurable dataflow processor for vision"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A scalable dataflow hardware architecture optimized for the computation of general-purpose vision algorithms \u2014 neuFlow \u2014 and a dataflow compiler \u2014 luaFlow \u2014 that transforms high-level flow-graph representations of these algorithms into machine code for neu Flow are presented."
            },
            "venue": {
                "fragments": [],
                "text": "CVPR 2011 WORKSHOPS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2546385"
                        ],
                        "name": "Johann Hauswald",
                        "slug": "Johann-Hauswald",
                        "structuredName": {
                            "firstName": "Johann",
                            "lastName": "Hauswald",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Johann Hauswald"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2672197"
                        ],
                        "name": "M. Laurenzano",
                        "slug": "M.-Laurenzano",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Laurenzano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Laurenzano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3216153"
                        ],
                        "name": "Yunqi Zhang",
                        "slug": "Yunqi-Zhang",
                        "structuredName": {
                            "firstName": "Yunqi",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yunqi Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2133092126"
                        ],
                        "name": "Cheng Li",
                        "slug": "Cheng-Li",
                        "structuredName": {
                            "firstName": "Cheng",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cheng Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1860422"
                        ],
                        "name": "A. Rovinski",
                        "slug": "A.-Rovinski",
                        "structuredName": {
                            "firstName": "Austin",
                            "lastName": "Rovinski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rovinski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2825947"
                        ],
                        "name": "Arjun Khurana",
                        "slug": "Arjun-Khurana",
                        "structuredName": {
                            "firstName": "Arjun",
                            "lastName": "Khurana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arjun Khurana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793651"
                        ],
                        "name": "R. Dreslinski",
                        "slug": "R.-Dreslinski",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Dreslinski",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dreslinski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751516"
                        ],
                        "name": "T. Mudge",
                        "slug": "T.-Mudge",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Mudge",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Mudge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771770"
                        ],
                        "name": "V. Petrucci",
                        "slug": "V.-Petrucci",
                        "structuredName": {
                            "firstName": "V.",
                            "lastName": "Petrucci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Petrucci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235128"
                        ],
                        "name": "Lingjia Tang",
                        "slug": "Lingjia-Tang",
                        "structuredName": {
                            "firstName": "Lingjia",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lingjia Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144603405"
                        ],
                        "name": "Jason Mars",
                        "slug": "Jason-Mars",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Mars",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason Mars"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 57
                            }
                        ],
                        "text": "We use hardware measurements to compare the generated accelerators to both multicore CPUs (ARM Cortex A15 and Xeon E3) and many-core GPUs (Tegra K1, GTX 650Ti, and Tesla K40)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13627618,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c80811585c37cb6e87f318194489fa6b7967879",
            "isKey": false,
            "numCitedBy": 209,
            "numCiting": 89,
            "paperAbstract": {
                "fragments": [],
                "text": "As user demand scales for intelligent personal assistants (IPAs) such as Apple's Siri, Google's Google Now, and Microsoft's Cortana, we are approaching the computational limits of current datacenter architectures. It is an open question how future server architectures should evolve to enable this emerging class of applications, and the lack of an open-source IPA workload is an obstacle in addressing this question. In this paper, we present the design of Sirius, an open end-to-end IPA web-service application that accepts queries in the form of voice and images, and responds with natural language. We then use this workload to investigate the implications of four points in the design space of future accelerator-based server architectures spanning traditional CPUs, GPUs, manycore throughput co-processors, and FPGAs. To investigate future server designs for Sirius, we decompose Sirius into a suite of 7 benchmarks (Sirius Suite) comprising the computationally intensive bottlenecks of Sirius. We port Sirius Suite to a spectrum of accelerator platforms and use the performance and power trade-offs across these platforms to perform a total cost of ownership (TCO) analysis of various server design points. In our study, we find that accelerators are critical for the future scalability of IPA services. Our results show that GPU- and FPGA-accelerated servers improve the query latency on average by 10x and 16x. For a given throughput, GPU- and FPGA-accelerated servers can reduce the TCO of datacenters by 2.6x and 1.4x, respectively."
            },
            "slug": "Sirius:-An-Open-End-to-End-Voice-and-Vision-and-Its-Hauswald-Laurenzano",
            "title": {
                "fragments": [],
                "text": "Sirius: An Open End-to-End Voice and Vision Personal Assistant and Its Implications for Future Warehouse Scale Computers"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The design of Sirius is presented, an open end-to-end IPA web-service application that accepts queries in the form of voice and images, and responds with natural language, and finds that accelerators are critical for the future scalability of IPA services."
            },
            "venue": {
                "fragments": [],
                "text": "ASPLOS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256269"
                        ],
                        "name": "C. Farabet",
                        "slug": "C.-Farabet",
                        "structuredName": {
                            "firstName": "Cl\u00e9ment",
                            "lastName": "Farabet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Farabet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1940285"
                        ],
                        "name": "B. Martini",
                        "slug": "B.-Martini",
                        "structuredName": {
                            "firstName": "Berin",
                            "lastName": "Martini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Martini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2447628"
                        ],
                        "name": "Polina Akselrod",
                        "slug": "Polina-Akselrod",
                        "structuredName": {
                            "firstName": "Polina",
                            "lastName": "Akselrod",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Polina Akselrod"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39576799"
                        ],
                        "name": "S. Talay",
                        "slug": "S.-Talay",
                        "structuredName": {
                            "firstName": "Sel\u00e7uk",
                            "lastName": "Talay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Talay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2889774"
                        ],
                        "name": "E. Culurciello",
                        "slug": "E.-Culurciello",
                        "structuredName": {
                            "firstName": "Eugenio",
                            "lastName": "Culurciello",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Culurciello"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "[15, 28] develops an FPGA accelerator for a specific DNN."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 32
                            }
                        ],
                        "text": "In fact, several research works [14, 15, 27, 28] have made extensive efforts to provide FPGA accelerators for specific DNN models, or parts of DNN computation, targeted for a particular FPGA platform."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6542026,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3c82b476162d2d006e02180530875a64af18154",
            "isKey": false,
            "numCitedBy": 223,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a scalable hardware architecture to implement large-scale convolutional neural networks and state-of-the-art multi-layered artificial vision systems. This system is fully digital and is a modular vision engine with the goal of performing real-time detection, recognition and segmentation of mega-pixel images. We present a performance comparison between a software, FPGA and ASIC implementation that shows a speed up in custom hardware implementations."
            },
            "slug": "Hardware-accelerated-convolutional-neural-networks-Farabet-Martini",
            "title": {
                "fragments": [],
                "text": "Hardware accelerated convolutional neural networks for synthetic vision systems"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This system is fully digital and is a modular vision engine with the goal of performing real-time detection, recognition and segmentation of mega-pixel images."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2010 IEEE International Symposium on Circuits and Systems"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145595812"
                        ],
                        "name": "Ganesh Venkatesh",
                        "slug": "Ganesh-Venkatesh",
                        "structuredName": {
                            "firstName": "Ganesh",
                            "lastName": "Venkatesh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ganesh Venkatesh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39862527"
                        ],
                        "name": "J. Sampson",
                        "slug": "J.-Sampson",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Sampson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sampson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39758083"
                        ],
                        "name": "Nathan Goulding",
                        "slug": "Nathan-Goulding",
                        "structuredName": {
                            "firstName": "Nathan",
                            "lastName": "Goulding",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nathan Goulding"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143811073"
                        ],
                        "name": "Saturnino Garcia",
                        "slug": "Saturnino-Garcia",
                        "structuredName": {
                            "firstName": "Saturnino",
                            "lastName": "Garcia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saturnino Garcia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2097611416"
                        ],
                        "name": "Vladyslav Bryksin",
                        "slug": "Vladyslav-Bryksin",
                        "structuredName": {
                            "firstName": "Vladyslav",
                            "lastName": "Bryksin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vladyslav Bryksin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409067558"
                        ],
                        "name": "Jose Lugo-Martinez",
                        "slug": "Jose-Lugo-Martinez",
                        "structuredName": {
                            "firstName": "Jose",
                            "lastName": "Lugo-Martinez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jose Lugo-Martinez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143846212"
                        ],
                        "name": "S. Swanson",
                        "slug": "S.-Swanson",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Swanson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Swanson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38303344"
                        ],
                        "name": "M. Taylor",
                        "slug": "M.-Taylor",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Taylor",
                            "middleNames": [
                                "Bedford"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In comparison, the generated accelerators deliver superior performance and efficiency without requiring the programmers to participate in the arduous task of hardware design."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7588214,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "135de4744217bec58b8ed5ffc7f9aea11afd0896",
            "isKey": false,
            "numCitedBy": 428,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Growing transistor counts, limited power budgets, and the breakdown of voltage scaling are currently conspiring to create a utilization wall that limits the fraction of a chip that can run at full speed at one time. In this regime, specialized, energy-efficient processors can increase parallelism by reducing the per-computation power requirements and allowing more computations to execute under the same power budget. To pursue this goal, this paper introduces conservation cores. Conservation cores, or c-cores, are specialized processors that focus on reducing energy and energy-delay instead of increasing performance. This focus on energy makes c-cores an excellent match for many applications that would be poor candidates for hardware acceleration (e.g., irregular integer codes). We present a toolchain for automatically synthesizing c-cores from application source code and demonstrate that they can significantly reduce energy and energy-delay for a wide range of applications. The c-cores support patching, a form of targeted reconfigurability, that allows them to adapt to new versions of the software they target. Our results show that conservation cores can reduce energy consumption by up to 16.0x for functions and by up to 2.1x for whole applications, while patching can extend the useful lifetime of individual c-cores to match that of conventional processors."
            },
            "slug": "Conservation-cores:-reducing-the-energy-of-mature-Venkatesh-Sampson",
            "title": {
                "fragments": [],
                "text": "Conservation cores: reducing the energy of mature computations"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A toolchain for automatically synthesizing c-cores from application source code is presented and it is demonstrated that they can significantly reduce energy and energy-delay for a wide range of applications, and patching can extend the useful lifetime of individual c-Cores to match that of conventional processors."
            },
            "venue": {
                "fragments": [],
                "text": "ASPLOS XV"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115913164"
                        ],
                        "name": "Min Lin",
                        "slug": "Min-Lin",
                        "structuredName": {
                            "firstName": "Min",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Min Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35370244"
                        ],
                        "name": "Qiang Chen",
                        "slug": "Qiang-Chen",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143653681"
                        ],
                        "name": "Shuicheng Yan",
                        "slug": "Shuicheng-Yan",
                        "structuredName": {
                            "firstName": "Shuicheng",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuicheng Yan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16636683,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e83ab70d0cbc003471e87ec306d27d9c80ecb16",
            "isKey": false,
            "numCitedBy": 4255,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel deep network structure called \"Network In Network\" (NIN) to enhance model discriminability for local patches within the receptive field. The conventional convolutional layer uses linear filters followed by a nonlinear activation function to scan the input. Instead, we build micro neural networks with more complex structures to abstract the data within the receptive field. We instantiate the micro neural network with a multilayer perceptron, which is a potent function approximator. The feature maps are obtained by sliding the micro networks over the input in a similar manner as CNN; they are then fed into the next layer. Deep NIN can be implemented by stacking mutiple of the above described structure. With enhanced local modeling via the micro network, we are able to utilize global average pooling over feature maps in the classification layer, which is easier to interpret and less prone to overfitting than traditional fully connected layers. We demonstrated the state-of-the-art classification performances with NIN on CIFAR-10 and CIFAR-100, and reasonable performances on SVHN and MNIST datasets."
            },
            "slug": "Network-In-Network-Lin-Chen",
            "title": {
                "fragments": [],
                "text": "Network In Network"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "With enhanced local modeling via the micro network, the proposed deep network structure NIN is able to utilize global average pooling over feature maps in the classification layer, which is easier to interpret and less prone to overfitting than traditional fully connected layers."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2546385"
                        ],
                        "name": "Johann Hauswald",
                        "slug": "Johann-Hauswald",
                        "structuredName": {
                            "firstName": "Johann",
                            "lastName": "Hauswald",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Johann Hauswald"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085723"
                        ],
                        "name": "Yiping Kang",
                        "slug": "Yiping-Kang",
                        "structuredName": {
                            "firstName": "Yiping",
                            "lastName": "Kang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiping Kang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2672197"
                        ],
                        "name": "M. Laurenzano",
                        "slug": "M.-Laurenzano",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Laurenzano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Laurenzano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1596812259"
                        ],
                        "name": "Quan Chen",
                        "slug": "Quan-Chen",
                        "structuredName": {
                            "firstName": "Quan",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quan Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2133092126"
                        ],
                        "name": "Cheng Li",
                        "slug": "Cheng-Li",
                        "structuredName": {
                            "firstName": "Cheng",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cheng Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751516"
                        ],
                        "name": "T. Mudge",
                        "slug": "T.-Mudge",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Mudge",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Mudge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793651"
                        ],
                        "name": "R. Dreslinski",
                        "slug": "R.-Dreslinski",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Dreslinski",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Dreslinski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144603405"
                        ],
                        "name": "Jason Mars",
                        "slug": "Jason-Mars",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Mars",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jason Mars"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2235128"
                        ],
                        "name": "Lingjia Tang",
                        "slug": "Lingjia-Tang",
                        "structuredName": {
                            "firstName": "Lingjia",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lingjia Tang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 77
                            }
                        ],
                        "text": "We use hardware measurements to compare the generated accelerators to both multicore CPUs (ARM Cortex A15 and Xeon E3) and many-core GPUs (Tegra K1, GTX 650Ti, and Tesla K40)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8022238,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c6c30e3052fcc01aa5ee38252d77f75322d7b3f",
            "isKey": false,
            "numCitedBy": 159,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "As applications such as Apple Siri, Google Now, Microsoft Cortana, and Amazon Echo continue to gain traction, webservice companies are adopting large deep neural networks (DNN) for machine learning challenges such as image processing, speech recognition, natural language processing, among others. A number of open questions arise as to the design of a server platform specialized for DNN and how modern warehouse scale computers (WSCs) should be outfitted to provide DNN as a service for these applications. In this paper, we present DjiNN, an open infrastructure for DNN as a service in WSCs, and Tonic Suite, a suite of 7 end-to-end applications that span image, speech, and language processing. We use DjiNN to design a high throughput DNN system based on massive GPU server designs and provide insights as to the varying characteristics across applications. After studying the throughput, bandwidth, and power properties of DjiNN and Tonic Suite, we investigate several design points for future WSC architectures. We investigate the total cost of ownership implications of having a WSC with a disaggregated GPU pool versus a WSC composed of homogeneous integrated GPU servers. We improve DNN throughput by over 120\u00d7 for all but one application (40\u00d7 for Facial Recognition) on an NVIDIA K40 GPU. On a GPU server composed of 8 NVIDIA K40s, we achieve near-linear scaling (around 1000\u00d7 throughput improvement) for 3 of the 7 applications. Through our analysis, we also find that GPU-enabled WSCs improve total cost of ownership over CPU-only designs by 4-20\u00d7, depending on the composition of the workload."
            },
            "slug": "DjiNN-and-Tonic:-DNN-as-a-service-and-its-for-scale-Hauswald-Kang",
            "title": {
                "fragments": [],
                "text": "DjiNN and Tonic: DNN as a service and its implications for future warehouse scale computers"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "DjiNN is used to design a high throughput DNN system based on massive GPU server designs and insights are provided as to the varying characteristics across applications and several design points for future WSC architectures are investigated."
            },
            "venue": {
                "fragments": [],
                "text": "2015 ACM/IEEE 42nd Annual International Symposium on Computer Architecture (ISCA)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764761"
                        ],
                        "name": "K. Chatfield",
                        "slug": "K.-Chatfield",
                        "structuredName": {
                            "firstName": "Ken",
                            "lastName": "Chatfield",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Chatfield"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34838386"
                        ],
                        "name": "K. Simonyan",
                        "slug": "K.-Simonyan",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Simonyan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Simonyan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687524"
                        ],
                        "name": "A. Vedaldi",
                        "slug": "A.-Vedaldi",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Vedaldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vedaldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "NiN [34], AlexNet [30], Overfeat [31], VGG-CNN-S [35], and VGG-16 [35] target the ILSVRC ImageNet dataset [36]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 11
                            }
                        ],
                        "text": "Benchmarks VGG-CNN-S, LeNet and Cifar10 Full observe a similar trend."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 66
                            }
                        ],
                        "text": "Norm is a significant portion of the runtime for Cifar10 Full and VGG-CNN-S, leading to a high speedup for these models."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 38
                            }
                        ],
                        "text": "The benchmarks AlexNet, Overfeat, and VGG-16 observe a 2.2\u00d7 increase in performance through batching."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 27
                            }
                        ],
                        "text": "Cifar10 Full, AlexNet, and VGG-CNN-S are the only networks that include a normalization layer, which is executed for 16% and 5% of the runtime on Xeon E3 and Tesla K40, respectively."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7204540,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "14d9be7962a4ec5a6e55755f4c7588ea00793652",
            "isKey": true,
            "numCitedBy": 3066,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "The latest generation of Convolutional Neural Networks (CNN) have achieved impressive results in challenging benchmarks on image recognition and object detection, significantly raising the interest of the community in these methods. Nevertheless, it is still unclear how different CNN methods compare with each other and with previous state-of-the-art shallow representations such as the Bag-of-Visual-Words and the Improved Fisher Vector. This paper conducts a rigorous evaluation of these new techniques, exploring different deep architectures and comparing them on a common ground, identifying and disclosing important implementation details. We identify several useful properties of CNN-based representations, including the fact that the dimensionality of the CNN output layer can be reduced significantly without having an adverse effect on performance. We also identify aspects of deep and shallow methods that can be successfully shared. In particular, we show that the data augmentation techniques commonly applied to CNN-based methods can also be applied to shallow methods, and result in an analogous performance boost. Source code and models to reproduce the experiments in the paper is made publicly available."
            },
            "slug": "Return-of-the-Devil-in-the-Details:-Delving-Deep-Chatfield-Simonyan",
            "title": {
                "fragments": [],
                "text": "Return of the Devil in the Details: Delving Deep into Convolutional Nets"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that the data augmentation techniques commonly applied to CNN-based methods can also be applied to shallow methods, and result in an analogous performance boost, and it is identified that the dimensionality of the CNN output layer can be reduced significantly without having an adverse effect on performance."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40360972"
                        ],
                        "name": "Abdel-rahman Mohamed",
                        "slug": "Abdel-rahman-Mohamed",
                        "structuredName": {
                            "firstName": "Abdel-rahman",
                            "lastName": "Mohamed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abdel-rahman Mohamed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 61
                            }
                        ],
                        "text": "We use hardware measurements to compare the generated accelerators to both multicore CPUs (ARM Cortex A15 and Xeon E3) and many-core GPUs (Tegra K1, GTX 650Ti, and Tesla K40)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206741496,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4177ec52d1b80ed57f2e72b0f9a42365f1a8598d",
            "isKey": false,
            "numCitedBy": 6960,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Recurrent neural networks (RNNs) are a powerful model for sequential data. End-to-end training methods such as Connectionist Temporal Classification make it possible to train RNNs for sequence labelling problems where the input-output alignment is unknown. The combination of these methods with the Long Short-term Memory RNN architecture has proved particularly fruitful, delivering state-of-the-art results in cursive handwriting recognition. However RNN performance in speech recognition has so far been disappointing, with better results returned by deep feedforward networks. This paper investigates deep recurrent neural networks, which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs. When trained end-to-end with suitable regularisation, we find that deep Long Short-term Memory RNNs achieve a test set error of 17.7% on the TIMIT phoneme recognition benchmark, which to our knowledge is the best recorded score."
            },
            "slug": "Speech-recognition-with-deep-recurrent-neural-Graves-Mohamed",
            "title": {
                "fragments": [],
                "text": "Speech recognition with deep recurrent neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper investigates deep recurrent neural networks, which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs."
            },
            "venue": {
                "fragments": [],
                "text": "2013 IEEE International Conference on Acoustics, Speech and Signal Processing"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "Among these, CIFAR-10 Full targets object detection in the CIFAR-10 thumbnail dataset [32]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18268744,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d90f06bb70a0a3dced62413346235c02b1aa086",
            "isKey": false,
            "numCitedBy": 17475,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Groups at MIT and NYU have collected a dataset of millions of tiny colour images from the web. It is, in principle, an excellent dataset for unsupervised training of deep generative models, but previous researchers who have tried this have found it dicult to learn a good set of lters from the images. We show how to train a multi-layer generative model that learns to extract meaningful features which resemble those found in the human visual cortex. Using a novel parallelization algorithm to distribute the work among multiple machines connected on a network, we show how training such a model can be done in reasonable time. A second problematic aspect of the tiny images dataset is that there are no reliable class labels which makes it hard to use for object recognition experiments. We created two sets of reliable labels. The CIFAR-10 set has 6000 examples of each of 10 classes and the CIFAR-100 set has 600 examples of each of 100 non-overlapping classes. Using these labels, we show that object recognition is signicantly improved by pre-training a layer of features on a large set of unlabeled tiny images."
            },
            "slug": "Learning-Multiple-Layers-of-Features-from-Tiny-Krizhevsky",
            "title": {
                "fragments": [],
                "text": "Learning Multiple Layers of Features from Tiny Images"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is shown how to train a multi-layer generative model that learns to extract meaningful features which resemble those found in the human visual cortex, using a novel parallelization algorithm to distribute the work among multiple machines connected on a network."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2217144"
                        ],
                        "name": "Simon Osindero",
                        "slug": "Simon-Osindero",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Osindero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Simon Osindero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725303"
                        ],
                        "name": "Y. Teh",
                        "slug": "Y.-Teh",
                        "structuredName": {
                            "firstName": "Yee",
                            "lastName": "Teh",
                            "middleNames": [
                                "Whye"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Teh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 69
                            }
                        ],
                        "text": "We use hardware measurements to compare the generated accelerators to both multicore CPUs (ARM Cortex A15 and Xeon E3) and many-core GPUs (Tegra K1, GTX 650Ti, and Tesla K40)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2309950,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8978cf7574ceb35f4c3096be768c7547b28a35d0",
            "isKey": false,
            "numCitedBy": 13502,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "We show how to use complementary priors to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind."
            },
            "slug": "A-Fast-Learning-Algorithm-for-Deep-Belief-Nets-Hinton-Osindero",
            "title": {
                "fragments": [],
                "text": "A Fast Learning Algorithm for Deep Belief Nets"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A fast, greedy algorithm is derived that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The advent of deep learning, or more precisely, deep structured learning, can be traced back to Convolutional Neural Networks [29]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": false,
            "numCitedBy": 35624,
            "numCiting": 246,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3651513"
                        ],
                        "name": "A. Putnam",
                        "slug": "A.-Putnam",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Putnam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Putnam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2986818"
                        ],
                        "name": "Adrian M. Caulfield",
                        "slug": "Adrian-M.-Caulfield",
                        "structuredName": {
                            "firstName": "Adrian",
                            "lastName": "Caulfield",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adrian M. Caulfield"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49842903"
                        ],
                        "name": "Eric S. Chung",
                        "slug": "Eric-S.-Chung",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Chung",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric S. Chung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2000338"
                        ],
                        "name": "Derek Chiou",
                        "slug": "Derek-Chiou",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Chiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Chiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2364885"
                        ],
                        "name": "Kypros Constantinides",
                        "slug": "Kypros-Constantinides",
                        "structuredName": {
                            "firstName": "Kypros",
                            "lastName": "Constantinides",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kypros Constantinides"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725238"
                        ],
                        "name": "J. Demme",
                        "slug": "J.-Demme",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Demme",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Demme"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696563"
                        ],
                        "name": "H. Esmaeilzadeh",
                        "slug": "H.-Esmaeilzadeh",
                        "structuredName": {
                            "firstName": "Hadi",
                            "lastName": "Esmaeilzadeh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Esmaeilzadeh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684785"
                        ],
                        "name": "J. Fowers",
                        "slug": "J.-Fowers",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Fowers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fowers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32107285"
                        ],
                        "name": "G. P. Gopal",
                        "slug": "G.-P.-Gopal",
                        "structuredName": {
                            "firstName": "Gopi",
                            "lastName": "Gopal",
                            "middleNames": [
                                "Prashanth"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. P. Gopal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46905933"
                        ],
                        "name": "J. Gray",
                        "slug": "J.-Gray",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Gray",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2589995"
                        ],
                        "name": "M. Haselman",
                        "slug": "M.-Haselman",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Haselman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Haselman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694228"
                        ],
                        "name": "S. Hauck",
                        "slug": "S.-Hauck",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Hauck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hauck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "14744223"
                        ],
                        "name": "S. Heil",
                        "slug": "S.-Heil",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Heil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Heil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691763"
                        ],
                        "name": "Amir Hormati",
                        "slug": "Amir-Hormati",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Hormati",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Amir Hormati"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145425761"
                        ],
                        "name": "Joo-Young Kim",
                        "slug": "Joo-Young-Kim",
                        "structuredName": {
                            "firstName": "Joo-Young",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joo-Young Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39577517"
                        ],
                        "name": "S. Lanka",
                        "slug": "S.-Lanka",
                        "structuredName": {
                            "firstName": "Sitaram",
                            "lastName": "Lanka",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lanka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752633"
                        ],
                        "name": "J. Larus",
                        "slug": "J.-Larus",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Larus",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Larus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059365345"
                        ],
                        "name": "Eric Peterson",
                        "slug": "Eric-Peterson",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Peterson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric Peterson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057924747"
                        ],
                        "name": "Simon Pope",
                        "slug": "Simon-Pope",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Pope",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Simon Pope"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48961931"
                        ],
                        "name": "Aaron Smith",
                        "slug": "Aaron-Smith",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1965761"
                        ],
                        "name": "J. Thong",
                        "slug": "J.-Thong",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Thong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Thong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48596928"
                        ],
                        "name": "Phillip Yi Xiao",
                        "slug": "Phillip-Yi-Xiao",
                        "structuredName": {
                            "firstName": "Phillip",
                            "lastName": "Xiao",
                            "middleNames": [
                                "Yi"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Phillip Yi Xiao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144859824"
                        ],
                        "name": "D. Burger",
                        "slug": "D.-Burger",
                        "structuredName": {
                            "firstName": "Doug",
                            "lastName": "Burger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Burger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In comparison, the generated accelerators deliver superior performance and efficiency without requiring the programmers to participate in the arduous task of hardware design."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3826382,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e25c39846d814f0eda33871c4b11c37855b9a70e",
            "isKey": false,
            "numCitedBy": 966,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "To advance datacenter capabilities beyond what commodity server designs can provide, the authors designed and built a composable, reconfigurable fabric to accelerate large-scale software services. Each instantiation of the fabric consists of a 6 x 8 2D torus of high-end field-programmable gate arrays (FPGAs) embedded into a half-rack of 48 servers. The authors deployed the reconfigurable fabric in a bed of 1,632 servers and FPGAs in a production datacenter and successfully used it to accelerate the ranking portion of the Bing Web search engine by nearly a factor of two."
            },
            "slug": "A-Reconfigurable-Fabric-for-Accelerating-Datacenter-Putnam-Caulfield",
            "title": {
                "fragments": [],
                "text": "A Reconfigurable Fabric for Accelerating Large-Scale Datacenter Services"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The authors deployed the reconfigurable fabric in a bed of 1,632 servers and FPGAs in a production datacenter and successfully used it to accelerate the ranking portion of the Bing Web search engine by nearly a factor of two."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Micro"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735300"
                        ],
                        "name": "S. Haykin",
                        "slug": "S.-Haykin",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Haykin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Haykin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713858"
                        ],
                        "name": "B. Kosko",
                        "slug": "B.-Kosko",
                        "structuredName": {
                            "firstName": "Bart",
                            "lastName": "Kosko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Kosko"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 126
                            }
                        ],
                        "text": "The advent of deep learning, or more precisely, deep structured learning, can be traced back to Convolutional Neural Networks [29]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 0
                            }
                        ],
                        "text": "Convolutional Neural Networks are commonly used deep learning models, and hence are the focus of our work."
                    },
                    "intents": []
                }
            ],
            "corpusId": 64294544,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f42b865e20e61a954239f421b42007236e671f19",
            "isKey": false,
            "numCitedBy": 3561,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer Neural Networks trained with the backpropagation algorithm constitute the best example of a successful Gradient-Based Learning technique. Given an appropriate network architecture, Gradient-Based Learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional Neural Networks, that are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation, recognition, and language modeling. A new learning paradigm, called Graph Transformer Networks (GTN), allows such multi-module systems to be trained globally using Gradient-Based methods so as to minimize an overall performance measure. Two systems for on-line handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of Graph Transformer Networks. A Graph Transformer Network for reading bank check is also described. It uses Convolutional Neural Network character recognizers combined with global training techniques to provides record accuracy on business and personal checks. It is deployed commercially and reads several million checks per day."
            },
            "slug": "GradientBased-Learning-Applied-to-Document-Haykin-Kosko",
            "title": {
                "fragments": [],
                "text": "GradientBased Learning Applied to Document Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Various methods applied to handwritten character recognition are reviewed and compared and Convolutional Neural Networks, that are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116926120"
                        ],
                        "name": "Ren Wu",
                        "slug": "Ren-Wu",
                        "structuredName": {
                            "firstName": "Ren",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ren Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2725514"
                        ],
                        "name": "Shengen Yan",
                        "slug": "Shengen-Yan",
                        "structuredName": {
                            "firstName": "Shengen",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shengen Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2143689293"
                        ],
                        "name": "Yi Shan",
                        "slug": "Yi-Shan",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Shan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Shan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066154565"
                        ],
                        "name": "Qingqing Dang",
                        "slug": "Qingqing-Dang",
                        "structuredName": {
                            "firstName": "Qingqing",
                            "lastName": "Dang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qingqing Dang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087137982"
                        ],
                        "name": "Gang Sun",
                        "slug": "Gang-Sun",
                        "structuredName": {
                            "firstName": "Gang",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gang Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 81
                            }
                        ],
                        "text": "We use hardware measurements to compare the generated accelerators to both multicore CPUs (ARM Cortex A15 and Xeon E3) and many-core GPUs (Tegra K1, GTX 650Ti, and Tesla K40)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7480530,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f5ce3abf942cdd685fb0f290f3e741f7b4749f0a",
            "isKey": false,
            "numCitedBy": 310,
            "numCiting": 71,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a state-of-the-art image recognition system, Deep Image, developed using end-to-end deep learning. The key components are a custom-built supercomputer dedicated to deep learning, a highly optimized parallel algorithm using new strategies for data partitioning and communication, larger deep neural network models, novel data augmentation approaches, and usage of multi-scale high-resolution images. Our method achieves excellent results on multiple challenging computer vision benchmarks."
            },
            "slug": "Deep-Image:-Scaling-up-Image-Recognition-Wu-Yan",
            "title": {
                "fragments": [],
                "text": "Deep Image: Scaling up Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A state-of-the-art image recognition system, Deep Image, developed using end-to-end deep learning, which achieves excellent results on multiple challenging computer vision benchmarks."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3142556"
                        ],
                        "name": "Pierre Sermanet",
                        "slug": "Pierre-Sermanet",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Sermanet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierre Sermanet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060028"
                        ],
                        "name": "D. Eigen",
                        "slug": "D.-Eigen",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Eigen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Eigen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46447747"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "Xiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143949035"
                        ],
                        "name": "Micha\u00ebl Mathieu",
                        "slug": "Micha\u00ebl-Mathieu",
                        "structuredName": {
                            "firstName": "Micha\u00ebl",
                            "lastName": "Mathieu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Micha\u00ebl Mathieu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4071727,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1109b663453e78a59e4f66446d71720ac58cec25",
            "isKey": false,
            "numCitedBy": 4388,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an integrated framework for using Convolutional Networks for classification, localization and detection. We show how a multiscale and sliding window approach can be efficiently implemented within a ConvNet. We also introduce a novel deep learning approach to localization by learning to predict object boundaries. Bounding boxes are then accumulated rather than suppressed in order to increase detection confidence. We show that different tasks can be learned simultaneously using a single shared network. This integrated framework is the winner of the localization task of the ImageNet Large Scale Visual Recognition Challenge 2013 (ILSVRC2013) and obtained very competitive results for the detection and classifications tasks. In post-competition work, we establish a new state of the art for the detection task. Finally, we release a feature extractor from our best model called OverFeat."
            },
            "slug": "OverFeat:-Integrated-Recognition,-Localization-and-Sermanet-Eigen",
            "title": {
                "fragments": [],
                "text": "OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This integrated framework for using Convolutional Networks for classification, localization and detection is the winner of the localization task of the ImageNet Large Scale Visual Recognition Challenge 2013 and obtained very competitive results for the detection and classifications tasks."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696563"
                        ],
                        "name": "H. Esmaeilzadeh",
                        "slug": "H.-Esmaeilzadeh",
                        "structuredName": {
                            "firstName": "Hadi",
                            "lastName": "Esmaeilzadeh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Esmaeilzadeh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2314690"
                        ],
                        "name": "E. Blem",
                        "slug": "E.-Blem",
                        "structuredName": {
                            "firstName": "Emily",
                            "lastName": "Blem",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Blem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2677903"
                        ],
                        "name": "R. S. Amant",
                        "slug": "R.-S.-Amant",
                        "structuredName": {
                            "firstName": "Ren\u00e9e",
                            "lastName": "Amant",
                            "middleNames": [
                                "St."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. S. Amant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720300"
                        ],
                        "name": "K. Sankaralingam",
                        "slug": "K.-Sankaralingam",
                        "structuredName": {
                            "firstName": "Karthikeyan",
                            "lastName": "Sankaralingam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sankaralingam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144859824"
                        ],
                        "name": "D. Burger",
                        "slug": "D.-Burger",
                        "structuredName": {
                            "firstName": "Doug",
                            "lastName": "Burger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Burger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 50
                            }
                        ],
                        "text": "With diminishing benefits from technology scaling [10, 11], the research community is increasingly turning to specialized accelerators for deep networks [12\u201315] and other workloads [16\u201322]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62736408,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ae04be7cd5430355ee380b283475e031b8dff4f",
            "isKey": false,
            "numCitedBy": 1714,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "A key question for the microprocessor research and design community is whether scaling multicores will provide the performance and value needed to scale down many more technology generations. To provide a quantitative answer to this question, a comprehensive study that projects the speedup potential of future multicores and examines the underutilization of integration capacity-dark silicon-is timely and crucial."
            },
            "slug": "Dark-Silicon-and-the-End-of-Multicore-Scaling-Esmaeilzadeh-Blem",
            "title": {
                "fragments": [],
                "text": "Dark Silicon and the End of Multicore Scaling"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A comprehensive study that projects the speedup potential of future multicores and examines the underutilization of integration capacity-dark silicon-is timely and crucial."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Micro"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 207
                            }
                        ],
                        "text": "The benefits of the template approach is more evident when considering a recent work [14] that uses commercial HLS tool and yet spends significant effort to implement the convolution layers of just one DNN, AlexNet."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "NiN [34], AlexNet [30], Overfeat [31], VGG-CNN-S [35], and VGG-16 [35] target the ILSVRC ImageNet dataset [36]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 137
                            }
                        ],
                        "text": "For the three FPGAs, (DW-Zynq, DW-Stratix, and DW-Arria), maximum speedup\nof (0.4\u00d7, 1.7\u00d7, and 3.8\u00d7) is observed from Cifar-10 Full, whereas AlexNet shows the minimum speedup of (0.1\u00d7, 0.4\u00d7, and 0.7\u00d7)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 81
                            }
                        ],
                        "text": "Figure 12 illustrates the result of search for Altera\u2019s Arria10 FPGA for AlexNet [30] and Overfeat [31]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 15
                            }
                        ],
                        "text": "The benchmarks AlexNet, Overfeat, and VGG-16 observe a 2.2\u00d7 increase in performance through batching."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 49
                            }
                        ],
                        "text": "The peak performance occurs at 14 PEs-per-PU for AlexNet and 12 PEs-per-PU for Overfeat."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 14
                            }
                        ],
                        "text": "Cifar10 Full, AlexNet, and VGG-CNN-S are the only networks that include a normalization layer, which is executed for 16% and 5% of the runtime on Xeon E3 and Tesla K40, respectively."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5556470,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "80d800dfadbe2e6c7b2367d9229cc82912d55889",
            "isKey": true,
            "numCitedBy": 889,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "I present a new way to parallelize the training of convolutional neural networks across multiple GPUs. The method scales significantly better than all alternatives when applied to modern convolutional neural networks."
            },
            "slug": "One-weird-trick-for-parallelizing-convolutional-Krizhevsky",
            "title": {
                "fragments": [],
                "text": "One weird trick for parallelizing convolutional neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A new way to parallelize the training of convolutional neural networks across multiple GPUs is presented, which scales significantly better than all alternatives when applied to modern convolutionAL neural networks."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2219581"
                        ],
                        "name": "B. Boser",
                        "slug": "B.-Boser",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Boser",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Boser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37274089"
                        ],
                        "name": "D. Henderson",
                        "slug": "D.-Henderson",
                        "structuredName": {
                            "firstName": "Donnie",
                            "lastName": "Henderson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Henderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2799635"
                        ],
                        "name": "R. Howard",
                        "slug": "R.-Howard",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Howard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34859193"
                        ],
                        "name": "W. Hubbard",
                        "slug": "W.-Hubbard",
                        "structuredName": {
                            "firstName": "Wayne",
                            "lastName": "Hubbard",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Hubbard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2041866"
                        ],
                        "name": "L. Jackel",
                        "slug": "L.-Jackel",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "Jackel",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Jackel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 65
                            }
                        ],
                        "text": "We use hardware measurements to compare the generated accelerators to both multicore CPUs (ARM Cortex A15 and Xeon E3) and many-core GPUs (Tegra K1, GTX 650Ti, and Tesla K40)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 41312633,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8e8f3c8d4418c8d62e306538c9c1292635e9d27",
            "isKey": false,
            "numCitedBy": 7922,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification."
            },
            "slug": "Backpropagation-Applied-to-Handwritten-Zip-Code-LeCun-Boser",
            "title": {
                "fragments": [],
                "text": "Backpropagation Applied to Handwritten Zip Code Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "This paper demonstrates how constraints from the task domain can be integrated into a backpropagation network through the architecture of the network, successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2192178"
                        ],
                        "name": "Olga Russakovsky",
                        "slug": "Olga-Russakovsky",
                        "structuredName": {
                            "firstName": "Olga",
                            "lastName": "Russakovsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Olga Russakovsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153302678"
                        ],
                        "name": "Jia Deng",
                        "slug": "Jia-Deng",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144914140"
                        ],
                        "name": "Hao Su",
                        "slug": "Hao-Su",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Su"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2285165"
                        ],
                        "name": "J. Krause",
                        "slug": "J.-Krause",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Krause",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Krause"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145031342"
                        ],
                        "name": "S. Satheesh",
                        "slug": "S.-Satheesh",
                        "structuredName": {
                            "firstName": "Sanjeev",
                            "lastName": "Satheesh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Satheesh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145423516"
                        ],
                        "name": "S. Ma",
                        "slug": "S.-Ma",
                        "structuredName": {
                            "firstName": "Sean",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3109481"
                        ],
                        "name": "Zhiheng Huang",
                        "slug": "Zhiheng-Huang",
                        "structuredName": {
                            "firstName": "Zhiheng",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhiheng Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2354728"
                        ],
                        "name": "A. Karpathy",
                        "slug": "A.-Karpathy",
                        "structuredName": {
                            "firstName": "Andrej",
                            "lastName": "Karpathy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Karpathy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2556428"
                        ],
                        "name": "A. Khosla",
                        "slug": "A.-Khosla",
                        "structuredName": {
                            "firstName": "Aditya",
                            "lastName": "Khosla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Khosla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145879842"
                        ],
                        "name": "Michael S. Bernstein",
                        "slug": "Michael-S.-Bernstein",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bernstein",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael S. Bernstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2930547,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e74f9b7f8eec6ba4704c206b93bc8079af3da4bd",
            "isKey": false,
            "numCitedBy": 25826,
            "numCiting": 138,
            "paperAbstract": {
                "fragments": [],
                "text": "The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the 5\u00a0years of the challenge, and propose future directions and improvements."
            },
            "slug": "ImageNet-Large-Scale-Visual-Recognition-Challenge-Russakovsky-Deng",
            "title": {
                "fragments": [],
                "text": "ImageNet Large Scale Visual Recognition Challenge"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The creation of this benchmark dataset and the advances in object recognition that have been possible as a result are described, and the state-of-the-art computer vision accuracy with human accuracy is compared."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50579876"
                        ],
                        "name": "Yu-hsin Chen",
                        "slug": "Yu-hsin-Chen",
                        "structuredName": {
                            "firstName": "Yu-hsin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu-hsin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145984583"
                        ],
                        "name": "T. Krishna",
                        "slug": "T.-Krishna",
                        "structuredName": {
                            "firstName": "Tushar",
                            "lastName": "Krishna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Krishna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775477"
                        ],
                        "name": "J. Emer",
                        "slug": "J.-Emer",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Emer",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Emer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691305"
                        ],
                        "name": "V. Sze",
                        "slug": "V.-Sze",
                        "structuredName": {
                            "firstName": "Vivienne",
                            "lastName": "Sze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Sze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Even though ASICs provide significant gains in performance and efficiency for DNNs [12, 13, 23\u201326], they may not cope with the ever-evolving DNN models."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "[23, 43] develop an ASIC design with a 2D spatial array of PEs for Convolutional Neural Networks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207882941,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3aada7d05f0478baaa3e92f51b66112171e4e53e",
            "isKey": false,
            "numCitedBy": 1227,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Eyeriss is an accelerator for state-of-the-art deep convolutional neural networks (CNNs). It optimizes for the energy efficiency of the entire system, including the accelerator chip and off-chip DRAM, for various CNN shapes by reconfiguring the architecture. CNNs are widely used in modern AI systems but also bring challenges on throughput and energy efficiency to the underlying hardware. This is because its computation requires a large amount of data, creating significant data movement from on-chip and off-chip that is more energy-consuming than computation. Minimizing data movement energy cost for any CNN shape, therefore, is the key to high throughput and energy efficiency. Eyeriss achieves these goals by using a proposed processing dataflow, called row stationary (RS), on a spatial architecture with 168 processing elements. RS dataflow reconfigures the computation mapping of a given shape, which optimizes energy efficiency by maximally reusing data locally to reduce expensive data movement, such as DRAM accesses. Compression and data gating are also applied to further improve energy efficiency. Eyeriss processes the convolutional layers at 35 frames/s and 0.0029 DRAM access/multiply and accumulation (MAC) for AlexNet at 278 mW (batch size  $N = 4$ ), and 0.7 frames/s and 0.0035 DRAM access/MAC for VGG-16 at 236 mW ( $N = 3$ )."
            },
            "slug": "Eyeriss:-An-Energy-Efficient-Reconfigurable-for-Chen-Krishna",
            "title": {
                "fragments": [],
                "text": "Eyeriss: An Energy-Efficient Reconfigurable Accelerator for Deep Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "Eyeriss is an accelerator for state-of-the-art deep convolutional neural networks (CNNs) that optimizes for the energy efficiency of the entire system, including the accelerator chip and off-chip DRAM, for various CNN shapes by reconfiguring the architecture."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Journal of Solid-State Circuits"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2088594"
                        ],
                        "name": "N. Hardavellas",
                        "slug": "N.-Hardavellas",
                        "structuredName": {
                            "firstName": "Nikolaos",
                            "lastName": "Hardavellas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Hardavellas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1843152"
                        ],
                        "name": "M. Ferdman",
                        "slug": "M.-Ferdman",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Ferdman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ferdman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701364"
                        ],
                        "name": "B. Falsafi",
                        "slug": "B.-Falsafi",
                        "structuredName": {
                            "firstName": "Babak",
                            "lastName": "Falsafi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Falsafi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1728318"
                        ],
                        "name": "A. Ailamaki",
                        "slug": "A.-Ailamaki",
                        "structuredName": {
                            "firstName": "Anastasia",
                            "lastName": "Ailamaki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ailamaki"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 50
                            }
                        ],
                        "text": "With diminishing benefits from technology scaling [10, 11], the research community is increasingly turning to specialized accelerators for deep networks [12\u201315] and other workloads [16\u201322]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2765349,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "40fb6da9c66d8e57b374d154f9a321560b425d9f",
            "isKey": false,
            "numCitedBy": 305,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "Server chips will not scale beyond a few tens to low hundreds of cores, and an increasing fraction of the chip in future technologies will be dark silicon that we cannot afford to power. Specialized multicore processors, however, can leverage the underutilized die area to overcome the initial power barrier, delivering significantly higher performance for the same bandwidth and power envelopes."
            },
            "slug": "Toward-Dark-Silicon-in-Servers-Hardavellas-Ferdman",
            "title": {
                "fragments": [],
                "text": "Toward Dark Silicon in Servers"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Server chips will not scale beyond a few tens to low hundreds of cores, and an increasing fraction of the chip in future technologies will be dark silicon that the authors cannot afford to power."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Micro"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "MNIST handwritten digit database"
            },
            "venue": {
                "fragments": [],
                "text": "MNIST handwritten digit database"
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "High level synthesis with a dataflow architectural template. CoRR, abs/1606"
            },
            "venue": {
                "fragments": [],
                "text": "High level synthesis with a dataflow architectural template. CoRR, abs/1606"
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Network in network. CoRR, abs/1312"
            },
            "venue": {
                "fragments": [],
                "text": "Network in network. CoRR, abs/1312"
            },
            "year": 2013
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "5 eyeriss: An energy-efficient reconfigurable accelerator for deep convolutional neural networks"
            },
            "venue": {
                "fragments": [],
                "text": "ISSCC"
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sen Song, et al. Going deeper with embedded fpga platform for convolutional neural network"
            },
            "venue": {
                "fragments": [],
                "text": "FPGA"
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In comparison, the generated accelerators deliver superior performance and efficiency without requiring the programmers to participate in the arduous task of hardware design."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Ninghui Sun, et al. Dadiannao: A machine-learning supercomputer"
            },
            "venue": {
                "fragments": [],
                "text": "MICRO"
            },
            "year": 2014
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 25,
            "methodology": 19
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 53,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/From-high-level-deep-neural-models-to-FPGAs-Sharma-Park/924d6c44fda59dc9ac1f25d7cc12d669c5f9e557?sort=total-citations"
}