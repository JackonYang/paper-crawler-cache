{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1870899"
                        ],
                        "name": "M. Dubois",
                        "slug": "M.-Dubois",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Dubois",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Dubois"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37849025"
                        ],
                        "name": "F. Briggs",
                        "slug": "F.-Briggs",
                        "structuredName": {
                            "firstName": "Faye",
                            "lastName": "Briggs",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Briggs"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 18361766,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f91ef92814dfb6af9f0f81732cff951191c3199",
            "isKey": false,
            "numCitedBy": 62,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "A general methodology for studying the degree of matching between an architecture and an algorithm is introduced and applied to the case of synchronized iterative algorithms in MIMD machines."
            },
            "slug": "Performance-of-Synchronized-Iterative-Processes-in-Dubois-Briggs",
            "title": {
                "fragments": [],
                "text": "Performance of Synchronized Iterative Processes in Multiprocessor Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "A general methodology for studying the degree of matching between an architecture and an algorithm is introduced and applied to the case of synchronized iterative algorithms in MIMD machines."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Software Engineering"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13956413"
                        ],
                        "name": "E. Boyd",
                        "slug": "E.-Boyd",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Boyd",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Boyd"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39660571"
                        ],
                        "name": "W. Azeem",
                        "slug": "W.-Azeem",
                        "structuredName": {
                            "firstName": "Waqar",
                            "lastName": "Azeem",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Azeem"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36012806"
                        ],
                        "name": "H. Lee",
                        "slug": "H.-Lee",
                        "structuredName": {
                            "firstName": "Hsien-Hsin",
                            "lastName": "Lee",
                            "middleNames": [
                                "Sean"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3061207"
                        ],
                        "name": "Tien-Pao Shih",
                        "slug": "Tien-Pao-Shih",
                        "structuredName": {
                            "firstName": "Tien-Pao",
                            "lastName": "Shih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tien-Pao Shih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40301874"
                        ],
                        "name": "Shih-Hao Hung",
                        "slug": "Shih-Hao-Hung",
                        "structuredName": {
                            "firstName": "Shih-Hao",
                            "lastName": "Hung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shih-Hao Hung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144274347"
                        ],
                        "name": "E. Davidson",
                        "slug": "E.-Davidson",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Davidson",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Davidson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9150719,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d56f8bf2781979e6c1ca10868a2cd18a6f29eede",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "We have developed a hierarchical performance bounding methodology that attempts to explain the performance of loop-dominated scientific applications on particular systems. The Kendall Square Research KSR1 is used as a running example. We model the throughput of key hardware units that arc common bottlenecks in concurrent machines. The four units currently used are: memory port, floating-point, instruction issue, and a loop-carried dependence pseudo-unit. We propose a workload characterization, and derive upper bounds on the performance of specific machine-workload pairs. Comparing delivered performance with bounds focuses attention on areas for improvement and indicates how much improvement might be attainable. We delineate a comprehensive approach to modeling and improving application performance on the KSR1. Application of this approach is being automated for the KSR1 with a series of tools including K-MA and K-MACSTAT (which enable the calculation of the MACS hierarchy of performance bounds), K-Trace (which allows parallel code to be instrumented to produce a memory reference trace), and K-Cache (which simulates inter-cache communications based on a memory reference trace)."
            },
            "slug": "A-Hierarchical-Approach-to-Modeling-and-Improving-Boyd-Azeem",
            "title": {
                "fragments": [],
                "text": "A Hierarchical Approach to Modeling and Improving the Performance of Scientific Applications on the KSR1"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work delineates a comprehensive approach to modeling and improving application performance on the KSR1, and proposes a workload characterization, and derive upper bounds on the performance of specific machine-workload pairs."
            },
            "venue": {
                "fragments": [],
                "text": "1994 International Conference on Parallel Processing Vol. 3"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143937132"
                        ],
                        "name": "Mark J. Harris",
                        "slug": "Mark-J.-Harris",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Harris",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark J. Harris"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 71
                            }
                        ],
                        "text": "We use operational intensity instead of the terms arithmetic intensity [16] or machine balance [8][11] for two reasons."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8212423,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc74b356b6d8c7ae793d4355301f64fde3c89a1d",
            "isKey": false,
            "numCitedBy": 222,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Recently, graphics processors have emerged as a powerful computational platform. A variety of encouraging results, mostly from researchers using GPUs to accelerate scientific computing and visualization applications, have shown that significant speedups can be achieved by applying GPUs to data-parallel computational problems. However, attaining these speedups requires knowledge of GPU programming and architecture.The preceding chapters have described the architecture of modern GPUs and the trends that govern their performance and design. Continuing from the concepts introduced in those chapters, in this chapter we present intuitive mappings of standard computational concepts onto the special-purpose features of GPUs. After presenting the basics, we introduce a simple GPU programming framework and demonstrate the use of the framework in a short sample program."
            },
            "slug": "Mapping-computational-concepts-to-GPUs-Harris",
            "title": {
                "fragments": [],
                "text": "Mapping computational concepts to GPUs"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This chapter presents intuitive mappings of standard computational concepts onto the special-purpose features of GPUs and introduces a simple GPU programming framework and demonstrates the use of the framework in a short sample program."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH Courses"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21112886"
                        ],
                        "name": "Richard Carl Demmel",
                        "slug": "Richard-Carl-Demmel",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Demmel",
                            "middleNames": [
                                "Carl"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richard Carl Demmel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708869"
                        ],
                        "name": "J. Dongarra",
                        "slug": "J.-Dongarra",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Dongarra",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dongarra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739274"
                        ],
                        "name": "V. Eijkhout",
                        "slug": "V.-Eijkhout",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Eijkhout",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Eijkhout"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144323704"
                        ],
                        "name": "E. Fuentes",
                        "slug": "E.-Fuentes",
                        "structuredName": {
                            "firstName": "Erika",
                            "lastName": "Fuentes",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Fuentes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719457"
                        ],
                        "name": "A. Petitet",
                        "slug": "A.-Petitet",
                        "structuredName": {
                            "firstName": "Antoine",
                            "lastName": "Petitet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Petitet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771649"
                        ],
                        "name": "R. Vuduc",
                        "slug": "R.-Vuduc",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Vuduc",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Vuduc"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11727255"
                        ],
                        "name": "R. C. Whaley",
                        "slug": "R.-C.-Whaley",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Whaley",
                            "middleNames": [
                                "Clint"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. C. Whaley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731111"
                        ],
                        "name": "K. Yelick",
                        "slug": "K.-Yelick",
                        "structuredName": {
                            "firstName": "Katherine",
                            "lastName": "Yelick",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Yelick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 230
                            }
                        ],
                        "text": "Another advantage of the restricted number is that we can create autotuners for each kernel that would search the space of alternatives to produce the best code for that multicore computer, including extensive cache optimizations [13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3065125,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5a3a535245d440f05047be8553b1466af9603408",
            "isKey": false,
            "numCitedBy": 231,
            "numCiting": 111,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the main obstacles to the efficient solution of scientific problems is the problem of tuning software, both to the available architecture and to the user problem at hand. We describe approaches for obtaining tuned high-performance kernels and for automatically choosing suitable algorithms. Specifically, we describe the generation of dense and sparse Basic Linear Algebra Subprograms (BLAS) kernels, and the selection of linear solver algorithms. However, the ideas presented here extend beyond these areas, which can be considered proof of concept."
            },
            "slug": "Self-Adapting-Linear-Algebra-Algorithms-and-Demmel-Dongarra",
            "title": {
                "fragments": [],
                "text": "Self-Adapting Linear Algebra Algorithms and Software"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "The generation of dense and sparse Basic Linear Algebra Subprograms (BLAS) kernels and the selection of linear solver algorithms are described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701130"
                        ],
                        "name": "D. Patterson",
                        "slug": "D.-Patterson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Patterson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Patterson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772133"
                        ],
                        "name": "J. Hennessy",
                        "slug": "J.-Hennessy",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hennessy",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hennessy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "Little's Law [21][20][17] dictates that to really push the limits of the memory system, considerable concurrency is necessary."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 60693966,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "890469e625fe728adfa690a3945ebca4c11a8998",
            "isKey": false,
            "numCitedBy": 11540,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This best-selling title, considered for over a decade to be essential reading for every serious student and practitioner of computer design, has been updated throughout to address the most important trends facing computer designers today. In this edition, the authors bring their trademark method of quantitative analysis not only to high-performance desktop machine design, but also to the design of embedded and server systems. They have illustrated their principles with designs from all three of these domains, including examples from consumer electronics, multimedia and Web technologies, and high-performance computing."
            },
            "slug": "Computer-Architecture:-A-Quantitative-Approach-Patterson-Hennessy",
            "title": {
                "fragments": [],
                "text": "Computer Architecture: A Quantitative Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This best-selling title, considered for over a decade to be essential reading for every serious student and practitioner of computer design, has been updated throughout to address the most important trends facing computer designers today."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "146767541"
                        ],
                        "name": "G. Amdhal",
                        "slug": "G.-Amdhal",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Amdhal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Amdhal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 195607370,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "0a5814c2b61aafdc9bafd14dba4ea6bd9536f236",
            "isKey": false,
            "numCitedBy": 4746,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "An instrument for facilitating the calculation of equivalent values includes a plate bearing symbols representing units and dimensions, the plate having a window in which a movable pointer is located. The pointer is movable from a first position representing a first set of units and dimensions to a second position representing an equivalent set of units and dimensions."
            },
            "slug": "Validity-of-the-Single-Processor-Approach-to-Large-Amdhal",
            "title": {
                "fragments": [],
                "text": "Validity of the Single Processor Approach to Achieving Large Scale Computing Capabilities"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "An instrument for facilitating the calculation of equivalent values includes a plate bearing symbols representing units and dimensions, the plate having a window in which a movable pointer is located."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1967
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3198208"
                        ],
                        "name": "S. Woo",
                        "slug": "S.-Woo",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Woo",
                            "middleNames": [
                                "Cameron"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Woo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145140637"
                        ],
                        "name": "M. Ohara",
                        "slug": "M.-Ohara",
                        "structuredName": {
                            "firstName": "Moriyoshi",
                            "lastName": "Ohara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ohara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123113859"
                        ],
                        "name": "E. Torrie",
                        "slug": "E.-Torrie",
                        "structuredName": {
                            "firstName": "Evan",
                            "lastName": "Torrie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Torrie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685479"
                        ],
                        "name": "J. Singh",
                        "slug": "J.-Singh",
                        "structuredName": {
                            "firstName": "Jaswinder",
                            "lastName": "Singh",
                            "middleNames": [
                                "Pal"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110759834"
                        ],
                        "name": "Anoop Gupta",
                        "slug": "Anoop-Gupta",
                        "structuredName": {
                            "firstName": "Anoop",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Anoop Gupta"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6178257,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16d06700b27881d3b3722408b220a653f6618691",
            "isKey": false,
            "numCitedBy": 4099,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The SPLASH-2 suite of parallel applications has recently been released to facilitate the study of centralized and distributed shared-address-space multiprocessors. In this context, the paper has two goals. One is to quantitatively characterize the SPLASH-2 programs in terms of fundamental properties and architectural interactions that are important to understand them well. The properties we study include the computational load balance, communication to computation ratio and traffic needs, important working set sizes, and issues related to spatial locality, as well as how these properties scale with problem size and the number of processors. The other, related goal is methodological: to assist people who will use the programs in architectural evaluations to prune the space of application and machine parameters in an informed and meaningful way. For example, by characterizing the working sets of the applications, we describe which operating points in terms of cache size and problem size are representative of realistic situations, which are not, and which re redundant. Using SPLASH-2 as an example, we hope to convey the importance of understanding the interplay of problem size, number of processors, and working sets in designing experiments and interpreting their results."
            },
            "slug": "The-SPLASH-2-programs:-characterization-and-Woo-Ohara",
            "title": {
                "fragments": [],
                "text": "The SPLASH-2 programs: characterization and methodological considerations"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper quantitatively characterize the SPLASH-2 programs in terms of fundamental properties and architectural interactions that are important to understand them well, including the computational load balance, communication to computation ratio and traffic needs, important working set sizes, and issues related to spatial locality."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 22nd Annual International Symposium on Computer Architecture"
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144888943"
                        ],
                        "name": "M. Hill",
                        "slug": "M.-Hill",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Hill",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6471065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3a02beb0ffb573c31a6be82565f62ba7abe98bc7",
            "isKey": false,
            "numCitedBy": 734,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Augmenting Amdahl's law with a corollary for multicore hardware makes it relevant to future generations of chips with multiple processor cores. Obtaining optimal multicore performance will require further research in both extracting more parallelism and making sequential cores faster."
            },
            "slug": "Amdahl's-Law-in-the-Multicore-Era-Hill",
            "title": {
                "fragments": [],
                "text": "Amdahl's Law in the Multicore Era"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Augmenting Amdahl's law with a corollary for multicore hardware makes it relevant to future generations of chips with multiple processor cores."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49589461"
                        ],
                        "name": "K. Datta",
                        "slug": "K.-Datta",
                        "structuredName": {
                            "firstName": "Kaushik",
                            "lastName": "Datta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Datta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144111356"
                        ],
                        "name": "M. Murphy",
                        "slug": "M.-Murphy",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Murphy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145687683"
                        ],
                        "name": "V. Volkov",
                        "slug": "V.-Volkov",
                        "structuredName": {
                            "firstName": "Vasily",
                            "lastName": "Volkov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Volkov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145117071"
                        ],
                        "name": "Samuel Williams",
                        "slug": "Samuel-Williams",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Williams",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuel Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152565684"
                        ],
                        "name": "J. Carter",
                        "slug": "J.-Carter",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Carter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Carter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757847"
                        ],
                        "name": "L. Oliker",
                        "slug": "L.-Oliker",
                        "structuredName": {
                            "firstName": "Leonid",
                            "lastName": "Oliker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Oliker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052996765"
                        ],
                        "name": "David A. Patterson",
                        "slug": "David-A.-Patterson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Patterson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David A. Patterson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746446"
                        ],
                        "name": "J. Shalf",
                        "slug": "J.-Shalf",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shalf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shalf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731111"
                        ],
                        "name": "K. Yelick",
                        "slug": "K.-Yelick",
                        "structuredName": {
                            "firstName": "Katherine",
                            "lastName": "Yelick",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Yelick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": "Indeed, three of the results were considered significant enough to be accepted for publication at major conferences [12][25][26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "The auto-tuning for this section is from [12], [25] and [26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 107
                            }
                        ],
                        "text": "For this work, we use the stencil derived from the explicit heat equation PDE on a uniform 256(3) 3-D grid [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7289478,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "695b6e055f199c91909550f57e8ee21444772801",
            "isKey": false,
            "numCitedBy": 443,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Understanding the most efficient design and utilization of emerging multicore systems is one of the most challenging questions faced by the mainstream and scientific computing industries in several decades. Our work explores multicore stencil (nearest-neighbor) computations - a class of algorithms at the heart of many structured grid codes, including PDE solvers. We develop a number of effective optimization strategies, and build an auto-tuning environment that searches over our optimizations and their parameters to minimize runtime, while maximizing performance portability. To evaluate the effectiveness of these strategies we explore the broadest set of multicore architectures in the current HPC literature, including the Intel Clovertown, AMD Barcelona, Sun Victoria Falls, IBM QS22 PowerXCell 8i, and NVIDIA GTX280. Overall, our auto-tuning optimization methodology results in the fastest multicore stencil performance to date. Finally, we present several key insights into the architectural tradeoffs of emerging multicore designs and their implications on scientific algorithm development."
            },
            "slug": "Stencil-computation-optimization-and-auto-tuning-on-Datta-Murphy",
            "title": {
                "fragments": [],
                "text": "Stencil computation optimization and auto-tuning on state-of-the-art multicore architectures"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work explores multicore stencil (nearest-neighbor) computations - a class of algorithms at the heart of many structured grid codes, including PDE solvers - and develops a number of effective optimization strategies, and builds an auto-tuning environment that searches over the optimizations and their parameters to minimize runtime, while maximizing performance portability."
            },
            "venue": {
                "fragments": [],
                "text": "2008 SC - International Conference for High Performance Computing, Networking, Storage and Analysis"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2275326"
                        ],
                        "name": "Christian Bienia",
                        "slug": "Christian-Bienia",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Bienia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Bienia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109967380"
                        ],
                        "name": "Sanjeev Kumar",
                        "slug": "Sanjeev-Kumar",
                        "structuredName": {
                            "firstName": "Sanjeev",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sanjeev Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685479"
                        ],
                        "name": "J. Singh",
                        "slug": "J.-Singh",
                        "structuredName": {
                            "firstName": "Jaswinder",
                            "lastName": "Singh",
                            "middleNames": [
                                "Pal"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49243317"
                        ],
                        "name": "Kai Li",
                        "slug": "Kai-Li",
                        "structuredName": {
                            "firstName": "Kai",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai Li"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 126,
                                "start": 123
                            }
                        ],
                        "text": "2 Four Diverse Floating-Point Kernels Rather than pick programs from some standard parallel benchmark suite such as Parsec [5] or Splash-2 [30], we were inspired by the work of Phil Colella [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 76
                            }
                        ],
                        "text": "Rather than pick programs from a standard parallel benchmark suite \n(such as Parsec5 and Splash-230), we were inspired by the work of Phil Colella,11 an expert in scientific \ncom\u00adputing at Lawrence Berkeley National Laboratory, who identified seven nu\u00admerical methods he believes \nwill be important for computational science and engineering for at least the next decade."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10043111,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "588dda88f15f1622ee7de7631f2824c23eea60df",
            "isKey": false,
            "numCitedBy": 3372,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents and characterizes the Princeton Application Repository for Shared-Memory Computers (PARSEC), a benchmark suite for studies of Chip-Multiprocessors (CMPs). Previous available benchmarks for multiprocessors have focused on high-performance computing applications and used a limited number of synchronization methods. PARSEC includes emerging applications in recognition, mining and synthesis (RMS) as well as systems applications which mimic large-scale multithreaded commercial programs. Our characterization shows that the benchmark suite covers a wide spectrum of working sets, locality, data sharing, synchronization and off-chip traffic. The benchmark suite has been made available to the public."
            },
            "slug": "The-PARSEC-benchmark-suite:-Characterization-and-Bienia-Kumar",
            "title": {
                "fragments": [],
                "text": "The PARSEC benchmark suite: Characterization and architectural implications"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "This paper presents and characterizes the Princeton Application Repository for Shared-Memory Computers (PARSEC), a benchmark suite for studies of Chip-Multiprocessors (CMPs), and shows that the benchmark suite covers a wide spectrum of working sets, locality, data sharing, synchronization and off-chip traffic."
            },
            "venue": {
                "fragments": [],
                "text": "2008 International Conference on Parallel Architectures and Compilation Techniques (PACT)"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066355407"
                        ],
                        "name": "Shang Zhi",
                        "slug": "Shang-Zhi",
                        "structuredName": {
                            "firstName": "Shang",
                            "lastName": "Zhi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shang Zhi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 186
                            }
                        ],
                        "text": "Rather than pick programs from a standard parallel benchmark suite \n(such as Parsec5 and Splash-230), we were inspired by the work of Phil Colella,11 an expert in scientific \ncom\u00adputing at Lawrence Berkeley National Laboratory, who identified seven nu\u00admerical methods he believes \nwill be important for computational science and engineering for at least the next decade."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "Little's Law [21][20][17] dictates that to really push the limits of the memory system, considerable concurrency is necessary."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 9
                            }
                        ],
                        "text": "Little s Law17, 20, 21 dic\u00adtates that considerable concurrency is necessary to really \npush the limits of the memory system."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 143,
                                "start": 140
                            }
                        ],
                        "text": "Manufac\u00adturers will likely offer multiple prod\u00aducts \nwith differing numbers of cores to cover multiple price-performance points, since Moore s Law will permit \nthe doubling of the number of cores per chip every two years.4 While di\u00adversity may be understandable \nin this time of uncertainty, it exacerbates the already difficult jobs of programmers, compiler writers, \nand even architects."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 102
                            }
                        ],
                        "text": "20 128 The \nbest-known example of a per\u00ad formance bound is surely Amdahl s 64 (b) opteron x4 opteron x2    Law,3 \nwhich says the performance gain of a parallel computer is limited by the serial portion of a parallel \nprogram and was recently applied to heteroge\u00ad neous multicore computers.4,18 32 16 8 4  Roofline model \n2 For the foreseeable future, off-chip 1 memory bandwidth will often be the constraining resource in \nsystem per-1/2 formance.23 Hence, we want a model 1/4 1/2 1 2 4 816 that relates processor performance \nto operational intensity (flops/Byte) off-chip memory traffic."
                    },
                    "intents": []
                }
            ],
            "corpusId": 64133274,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "fedc8961f829d8fc8dabef6e7f23ddddb69bb05f",
            "isKey": true,
            "numCitedBy": 586,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This article gives a proof.It is about the arrival rate multiplied by average waiting time equals average queue length."
            },
            "slug": "A-proof-of-the-queueing-formula:-L=\u03bbW-Zhi",
            "title": {
                "fragments": [],
                "text": "A proof of the queueing formula: L=\u03bbW"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "It is about the arrival rate multiplied by average waiting time equals average queue length, and the result is that the number of people queued up at the entrance to the terminal increases with the length of the queue."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145117071"
                        ],
                        "name": "Samuel Williams",
                        "slug": "Samuel-Williams",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Williams",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuel Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757847"
                        ],
                        "name": "L. Oliker",
                        "slug": "L.-Oliker",
                        "structuredName": {
                            "firstName": "Leonid",
                            "lastName": "Oliker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Oliker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771649"
                        ],
                        "name": "R. Vuduc",
                        "slug": "R.-Vuduc",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Vuduc",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Vuduc"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746446"
                        ],
                        "name": "J. Shalf",
                        "slug": "J.-Shalf",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shalf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shalf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731111"
                        ],
                        "name": "K. Yelick",
                        "slug": "K.-Yelick",
                        "structuredName": {
                            "firstName": "Katherine",
                            "lastName": "Yelick",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Yelick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700326"
                        ],
                        "name": "J. Demmel",
                        "slug": "J.-Demmel",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Demmel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Demmel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "Indeed, three of the results were considered significant enough to be accepted for publication at major conferences [12][25][26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 56
                            }
                        ],
                        "text": "The auto-tuning for this section is from [12], [25] and [26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1845814,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8138ab11231447708f13d1a593389ded2b845b1b",
            "isKey": false,
            "numCitedBy": 530,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "We are witnessing a dramatic change in computer architecture due to the multicore paradigm shift, as every electronic device from cell phones to supercomputers confronts parallelism of unprecedented scale. To fully unleash the potential of these systems, the HPC community must develop multicore specific optimization methodologies for important scientific computations. In this work, we examine sparse matrix-vector multiply (SpMV) - one of the most heavily used kernels in scientific computing - across a broad spectrum of multicore designs. Our experimental platform includes the homogeneous AMD dual-core and Intel quad-core designs, the heterogeneous STI Cell, as well as the first scientific study of the highly multithreaded Sun Niagara2. We present several optimization strategies especially effective for the multicore environment, and demonstrate significant performance improvements compared to existing state-of-the-art serial and parallel SpMV implementations. Additionally, we present key insights into the architectural tradeoffs of leading multicore design strategies, in the context of demanding memory-bound numerical algorithms."
            },
            "slug": "Optimization-of-sparse-matrix-vector-multiplication-Williams-Oliker",
            "title": {
                "fragments": [],
                "text": "Optimization of sparse matrix-vector multiplication on emerging multicore platforms"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work examines sparse matrix-vector multiply (SpMV) - one of the most heavily used kernels in scientific computing - across a broad spectrum of multicore designs, and presents several optimization strategies especially effective for the multicore environment."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2007 ACM/IEEE Conference on Supercomputing (SC '07)"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153281265"
                        ],
                        "name": "D. Callahan",
                        "slug": "D.-Callahan",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Callahan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Callahan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144716964"
                        ],
                        "name": "J. Cocke",
                        "slug": "J.-Cocke",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Cocke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Cocke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70455556"
                        ],
                        "name": "K. Kennedy",
                        "slug": "K.-Kennedy",
                        "structuredName": {
                            "firstName": "Ken",
                            "lastName": "Kennedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kennedy"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11477153,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eca1c7490c25d5201b38fb3552f62577eef88f3c",
            "isKey": false,
            "numCitedBy": 157,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Estimating-Interlock-and-Improving-Balance-for-Callahan-Cocke",
            "title": {
                "fragments": [],
                "text": "Estimating Interlock and Improving Balance for Pipelined Architectures"
            },
            "venue": {
                "fragments": [],
                "text": "J. Parallel Distributed Comput."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40770452"
                        ],
                        "name": "L. Goddard",
                        "slug": "L.-Goddard",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Goddard",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Goddard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4250374,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "60ec5ddae05190537c72974b8f93beb46b8db857",
            "isKey": false,
            "numCitedBy": 1111,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Introduction to Operations ResearchBy A. Kaufmann, and R. Faure. Translated by Henry C. Sneyd. (Mathematics in Science and Engineering, Vol. 47.) Pp. xi + 300. (Academic Press: New York and London, September 1968.) 135s 4d."
            },
            "slug": "Operations-Research-Goddard",
            "title": {
                "fragments": [],
                "text": "Operations Research"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2210176"
                        ],
                        "name": "M. Tikir",
                        "slug": "M.-Tikir",
                        "structuredName": {
                            "firstName": "Mustafa",
                            "lastName": "Tikir",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Tikir"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2928295"
                        ],
                        "name": "L. Carrington",
                        "slug": "L.-Carrington",
                        "structuredName": {
                            "firstName": "Laura",
                            "lastName": "Carrington",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Carrington"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749908"
                        ],
                        "name": "E. Strohmaier",
                        "slug": "E.-Strohmaier",
                        "structuredName": {
                            "firstName": "Erich",
                            "lastName": "Strohmaier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Strohmaier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2400472"
                        ],
                        "name": "A. Snavely",
                        "slug": "A.-Snavely",
                        "structuredName": {
                            "firstName": "Allan",
                            "lastName": "Snavely",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Snavely"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3057822,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0413bdb26f1aa03a70662ded96bbc1b528b5a20b",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Benchmarks that measure memory bandwidth, such as STREAM, Apex-MAPS and MultiMAPS, are increasingly popular due to the \"Von Neumann\" bottleneck of modern processors which causes many calculations to be memory-bound. We present a scheme for predicting the performance of HPC applications based on the results of such benchmarks. A Genetic Algorithm approach is used to \"learn\" bandwidth as a function of cache hit rates per machine with MultiMAPS as the fitness test. The specific results are 56 individual performance predictions including 3 full-scale parallel applications run on 5 different modern HPC architectures, with various CPU counts and inputs, predicted within 10% average difference with respect to independently verified runtimes."
            },
            "slug": "A-genetic-algorithms-approach-to-modeling-the-of-Tikir-Carrington",
            "title": {
                "fragments": [],
                "text": "A genetic algorithms approach to modeling the performance of memory-bound computations"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A Genetic Algorithm approach is used to \"learn\" bandwidth as a function of cache hit rates per machine with MultiMAPS as the fitness test and 56 individual performance predictions are made."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2007 ACM/IEEE Conference on Supercomputing (SC '07)"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701130"
                        ],
                        "name": "D. Patterson",
                        "slug": "D.-Patterson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Patterson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Patterson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "THE ROOFLINE MODEL We believe that for the recent past and foreseeable future, off-chip memory bandwidth will often be the constraining resource[23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 30274066,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "843a1567b056c8a1d0deddc8b699e1725194f85c",
            "isKey": false,
            "numCitedBy": 252,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "As I review performance trends, I am struck by a consistent theme across many technologies: bandwidth improves much more quickly than latency. Here, I list a half-dozen performance milestones to document this observation, many reasons why it happens, a few ways to cope with it, a rule of thumb to quantify it, plus an example of how to design systems differently based on this observation."
            },
            "slug": "Latency-lags-bandwith-Patterson",
            "title": {
                "fragments": [],
                "text": "Latency lags bandwith"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "As I review performance trends, I am struck by a consistent theme across many technologies: bandwidth improves much more quickly than latency."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760896"
                        ],
                        "name": "K. Asanovi\u0107",
                        "slug": "K.-Asanovi\u0107",
                        "structuredName": {
                            "firstName": "Krste",
                            "lastName": "Asanovi\u0107",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Asanovi\u0107"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1991345"
                        ],
                        "name": "R. Bod\u00edk",
                        "slug": "R.-Bod\u00edk",
                        "structuredName": {
                            "firstName": "Rastislav",
                            "lastName": "Bod\u00edk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bod\u00edk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2301680"
                        ],
                        "name": "Bryan Catanzaro",
                        "slug": "Bryan-Catanzaro",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "Catanzaro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bryan Catanzaro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053614"
                        ],
                        "name": "Joseph Gebis",
                        "slug": "Joseph-Gebis",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Gebis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph Gebis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38602469"
                        ],
                        "name": "P. Husbands",
                        "slug": "P.-Husbands",
                        "structuredName": {
                            "firstName": "Parry",
                            "lastName": "Husbands",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Husbands"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732330"
                        ],
                        "name": "K. Keutzer",
                        "slug": "K.-Keutzer",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Keutzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Keutzer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701130"
                        ],
                        "name": "D. Patterson",
                        "slug": "D.-Patterson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Patterson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Patterson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2160093"
                        ],
                        "name": "W. Plishker",
                        "slug": "W.-Plishker",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Plishker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Plishker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746446"
                        ],
                        "name": "J. Shalf",
                        "slug": "J.-Shalf",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shalf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shalf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145117071"
                        ],
                        "name": "Samuel Williams",
                        "slug": "Samuel-Williams",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Williams",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuel Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731111"
                        ],
                        "name": "K. Yelick",
                        "slug": "K.-Yelick",
                        "structuredName": {
                            "firstName": "Katherine",
                            "lastName": "Yelick",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Yelick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 62143065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ceb3fd01e1d5ece659654638e1c7cde2c4704a7a",
            "isKey": false,
            "numCitedBy": 2312,
            "numCiting": 141,
            "paperAbstract": {
                "fragments": [],
                "text": "Author(s): Asanovic, K; Bodik, R; Catanzaro, B; Gebis, J; Husbands, P; Keutzer, K; Patterson, D; Plishker, W; Shalf, J; Williams, SW | Abstract: The recent switch to parallel microprocessors is a milestone in the history of computing. Industry has laid out a roadmap for multicore designs that preserves the programming paradigm of the past via binary compatibility and cache coherence. Conventional wisdom is now to double the number of cores on a chip with each silicon generation. A multidisciplinary group of Berkeley researchers met nearly two years to discuss this change. Our view is that this evolutionary approach to parallel hardware and software may work from 2 or 8 processor systems, but is likely to face diminishing returns as 16 and 32 processor systems are realized, just as returns fell with greater instruction-level parallelism. We believe that much can be learned by examining the success of parallelism at the extremes of the computing spectrum, namely embedded computing and high performance computing. This led us to frame the parallel landscape with seven questions, and to recommend the following: \u2022 The overarching goal should be to make it easy to write programs that execute efficiently on highly parallel computing systems \u2022 The target should be 1000s of cores per chip, as these chips are built from processing elements that are the most efficient in MIPS (Million Instructions per Second) per watt, MIPS per area of silicon, and MIPS per development dollar. \u2022 Instead of traditional benchmarks, use 13 \u201cDwarfs\u201d to design and evaluate parallel programming models and architectures. (A dwarf is an algorithmic method that captures a pattern of computation and communication.) \u2022 \u201cAutotuners\u201d should play a larger role than conventional compilers in translating parallel programs. \u2022 To maximize programmer productivity, future programming models must be more human-centric than the conventional focus on hardware or applications. \u2022 To be successful, programming models should be independent of the number of processors. \u2022 To maximize application efficiency, programming models should support a wide range of data types and successful models of parallelism: task-level parallelism, word-level parallelism, and bit-level parallelism. 1 The Landscape of Parallel Computing Research: A View From Berkeley \u2022 Architects should not include features that significantly affect performance or energy if programmers cannot accurately measure their impact via performance counters and energy counters. \u2022 Traditional operating systems will be deconstructed and operating system functionality will be orchestrated using libraries and virtual machines. \u2022 To explore the design space rapidly, use system emulators based on Field Programmable Gate Arrays (FPGAs) that are highly scalable and low cost. Since real world applications are naturally parallel and hardware is naturally parallel, what we need is a programming model, system software, and a supporting architecture that are naturally parallel. Researchers have the rare opportunity to re-invent these cornerstones of computing, provided they simplify the efficient programming of highly parallel systems."
            },
            "slug": "The-Landscape-of-Parallel-Computing-Research:-A-Asanovi\u0107-Bod\u00edk",
            "title": {
                "fragments": [],
                "text": "The Landscape of Parallel Computing Research: A View from Berkeley"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The parallel landscape is frame with seven questions, and the following are recommended to explore the design space rapidly: \u2022 The overarching goal should be to make it easy to write programs that execute efficiently on highly parallel computing systems \u2022 The target should be 1000s of cores per chip, as these chips are built from processing elements that are the most efficient in MIPS (Million Instructions per Second) per watt, MIPS per area of silicon, and MIPS each development dollar."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771649"
                        ],
                        "name": "R. Vuduc",
                        "slug": "R.-Vuduc",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Vuduc",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Vuduc"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700326"
                        ],
                        "name": "J. Demmel",
                        "slug": "J.-Demmel",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Demmel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Demmel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731111"
                        ],
                        "name": "K. Yelick",
                        "slug": "K.-Yelick",
                        "structuredName": {
                            "firstName": "Katherine",
                            "lastName": "Yelick",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Yelick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145683292"
                        ],
                        "name": "S. Kamil",
                        "slug": "S.-Kamil",
                        "structuredName": {
                            "firstName": "Shoaib",
                            "lastName": "Kamil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kamil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2344807"
                        ],
                        "name": "R. Nishtala",
                        "slug": "R.-Nishtala",
                        "structuredName": {
                            "firstName": "Rajesh",
                            "lastName": "Nishtala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Nishtala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152840677"
                        ],
                        "name": "Benjamin C. Lee",
                        "slug": "Benjamin-C.-Lee",
                        "structuredName": {
                            "firstName": "Benjamin",
                            "lastName": "Lee",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benjamin C. Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "25 Flops per byte afterwards [29]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9960950,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "03b71d8f284b83c47d39e4d086253e09dc3f867f",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider performance tuning, by code and data structure reorganization, of sparse matrix-vector multiply (SpM\u00d7V), one of the most important computational kernels in scientific applications. This paper addresses the fundamental questions of what limits exist on such performance tuning, and how closely tuned code approaches these limits. Specifically, we develop upper and lower bounds on the performance (Mflop/s) of SpM\u00d7V when tuned using our previously proposed register blocking optimization. These bounds are based on the non-zero pattern in the matrix and the cost of basic memory operations, such as cache hits and misses. We evaluate our tuned implementations with respect to these bounds using hardware counter data on 4 different platforms and on test set of 44 sparse matrices. We find that we can often get within 20% of the upper bound, particularly on class of matrices from finite element modeling (FEM) problems; on non-FEM matrices, performance improvements of 2\u00d7 are still possible. Lastly, we present new heuristic that selects optimal or near-optimal register block sizes (the key tuning parameters) more accurately than our previous heuristic. Using the new heuristic, we show improvements in SpM\u00d7V performance (Mflop/s) by as much as 2.5\u00d7 over an untuned implementation. Collectively, our results suggest that future performance improvements, beyond those that we have already demonstrated for SpM\u00d7V, will come from two sources: (1) consideration of higher-level matrix structures (e.g. exploiting symmetry, matrix reordering, multiple register block sizes), and (2) optimizing kernels with more opportunity for data reuse (e.g. sparse matrix-multiple vector multiply, multiplication of AT A by a vector)."
            },
            "slug": "Performance-Optimizations-and-Bounds-for-Sparse-Vuduc-Demmel",
            "title": {
                "fragments": [],
                "text": "Performance Optimizations and Bounds for Sparse Matrix-Vector Multiply"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Upper and lower bounds on the performance (Mflop/s) of SpM\u00d7V when tuned using the previously proposed register blocking optimization are developed and a new heuristic is presented that selects optimal or near-optimal register block sizes more accurately than the previous heuristic."
            },
            "venue": {
                "fragments": [],
                "text": "ACM/IEEE SC 2002 Conference (SC'02)"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145117071"
                        ],
                        "name": "Samuel Williams",
                        "slug": "Samuel-Williams",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Williams",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuel Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152565684"
                        ],
                        "name": "J. Carter",
                        "slug": "J.-Carter",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Carter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Carter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757847"
                        ],
                        "name": "L. Oliker",
                        "slug": "L.-Oliker",
                        "structuredName": {
                            "firstName": "Leonid",
                            "lastName": "Oliker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Oliker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746446"
                        ],
                        "name": "J. Shalf",
                        "slug": "J.-Shalf",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shalf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shalf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1731111"
                        ],
                        "name": "K. Yelick",
                        "slug": "K.-Yelick",
                        "structuredName": {
                            "firstName": "Katherine",
                            "lastName": "Yelick",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Yelick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 120
                            }
                        ],
                        "text": "Indeed, three of the results were considered significant enough to be accepted for publication at major conferences [12][25][26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 47
                            }
                        ],
                        "text": "The auto-tuning for this section is from [12], [25] and [26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10666911,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4c651a5a3508e674781d36b91d18c97e47055b0",
            "isKey": false,
            "numCitedBy": 109,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an auto-tuning approach to optimize application performance on emerging multicore architectures. The methodology extends the idea of search-based performance optimizations, popular in linear algebra and FFT libraries, to application-specific computational kernels. Our work applies this strategy to a lattice Boltzmann application (LBMHD) that historically has made poor use of scalar microprocessors due to its complex data structures and memory access patterns. We explore one of the broadest sets of multicore architectures in the HPC literature, including the Intel Clovertown, AMD Opteron X2, Sun Niagara!, STI Cell, as well as the single core Intel Itanium.2. Rather than hand-tuning LBMHD for each system, we develop a code generator that allows us identify a highly optimized version for each platform, while amortizing the human programming effort. Results show that our auto- tuned LBMHD application achieves up to a 14times improvement compared with the original code. Additionally, we present detailed analysis of each optimization, which reveal surprising hardware bottlenecks and software challenges for future multicore systems and applications."
            },
            "slug": "Lattice-Boltzmann-simulation-optimization-on-Williams-Carter",
            "title": {
                "fragments": [],
                "text": "Lattice Boltzmann simulation optimization on leading multicore platforms"
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE International Symposium on Parallel and Distributed Processing"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683210"
                        ],
                        "name": "E. Lazowska",
                        "slug": "E.-Lazowska",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Lazowska",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Lazowska"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700666"
                        ],
                        "name": "J. Zahorjan",
                        "slug": "J.-Zahorjan",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Zahorjan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Zahorjan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145596540"
                        ],
                        "name": "G. S. Graham",
                        "slug": "G.-S.-Graham",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Graham",
                            "middleNames": [
                                "Scott"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. S. Graham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737874"
                        ],
                        "name": "K. Sevcik",
                        "slug": "K.-Sevcik",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Sevcik",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Sevcik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 112
                            }
                        ],
                        "text": "What optimizations should you perform, and in what order? Another advantage of bound and bottleneck analysis is [20]"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "Instead of trying to predict performance, it provides [20]"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "Little's Law [21][20][17] dictates that to really push the limits of the memory system, considerable concurrency is necessary."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1619603,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "02544882276ff1a35f4b6f1a8504a972b8df4087",
            "isKey": false,
            "numCitedBy": 1220,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Reading a book is also kind of better solution when you have no enough money or time to get your own adventure. This is one of the reasons we show the quantitative system performance computer system analysis using queuing network models as your friend in spending the time. For more representative collections, this book not only offers it's strategically book resource. It can be a good friend, really good friend with much knowledge."
            },
            "slug": "Quantitative-system-performance-computer-system-Lazowska-Zahorjan",
            "title": {
                "fragments": [],
                "text": "Quantitative system performance - computer system analysis using queueing network models"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This book shows the quantitative system performance computer system analysis using queuing network models as your friend in spending the time."
            },
            "venue": {
                "fragments": [],
                "text": "Int. CMG Conference"
            },
            "year": 1983
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720525"
                        ],
                        "name": "V. Adve",
                        "slug": "V.-Adve",
                        "structuredName": {
                            "firstName": "Vikram",
                            "lastName": "Adve",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Adve"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 7692340,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "be4024a238ebba9b7f650cb44b306881a6a4e152",
            "isKey": false,
            "numCitedBy": 58,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "An analytical performance model for parallel programs can provide qualitative insight as well as efficient quantitative evaluation and prediction of parallel program performance. While stochastic models for parallel programs can represent execution time variance due to communication and resource contention delays, a qualitative assessment of previous models shows that the stochastic assumption makes it extremely difficult to compute synchronization costs and overall execution times. \nThis thesis first re-evaluates the need for the stochastic assumption by examining the influence of non-deterministic communication and resource contention delays on execution times in parallel programs. An analytical model of program behavior, combined with detailed program measurements, provides compelling evidence that in shared-memory programs on current systems as well as programs with similar granularity on foreseeable future systems, such delays introduce extremely low variance into the execution time of each process between synchronization points, even with high communication costs and contention. \nMotivated by the above results, the thesis develops a conceptually simple deterministic model for parallel program performance prediction, using deterministic values to represent mean task times including communication, and (if necessary) shared-resource contention computed from a separate, stochastic model. Experiments applying the model to several shared-memory programs demonstrate the efficiency, accuracy and ability to model programs with large and complex task graphs. A quantitative assessment of previous stochastic models shows that they have inconsistent or poor accuracy, as well as prohibitive computational cost in models applicable to complex task graphs. Furthermore, in comparison with simple, insightful speedup bounds computed using parameters such as average parallelism, the deterministic model provides additional qualitative as well as quantitative information, for comparable effort. \nThe thesis then uses example programs to demonstrate the insight and predictive power provided by the deterministic model. The model can be used to quantify and understand nuances of program performance, and to quickly predict the impact of system changes as well as program design changes that affect load-balancing, such as changes in the partitioning and scheduling of tasks. This insight and predictive power is due to the particular task-graph-based representation of program parallelism and scheduling. \nIn summary, the analytical and experimental results in the thesis contribute towards understanding a fundamental principle of parallel program behavior, and towards evaluating, understanding, and predicting parallel program performance."
            },
            "slug": "Analyzing-the-behavior-and-performance-of-parallel-Adve",
            "title": {
                "fragments": [],
                "text": "Analyzing the behavior and performance of parallel programs"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A conceptually simple deterministic model for parallel program performance prediction, using deterministic values to represent mean task times including communication, and (if necessary) shared-resource contention computed from a separate, stochastic model is developed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714278"
                        ],
                        "name": "A. Thomasian",
                        "slug": "A.-Thomasian",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Thomasian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Thomasian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111422"
                        ],
                        "name": "Paul F. Bay",
                        "slug": "Paul-F.-Bay",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Bay",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Paul F. Bay"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "Stochastic analytical models [14][28] and statistical performance models [7][27] can predict program performance on multiprocessors accurately."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 730365,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ecf9e4feced6be08f3e88cf7543ada9da35646b5",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper is concerned with the performance evaluation of a realistic model of parallel computations. We present an efficient algorithm to determine the mean completion time and related performance measures for a task system: a set of tasks with precedence relationships in their execution sequence, such that the resulting graph is acyclic. A queueing network (QN) is used to model tasks executing on a single or multicomputer system. In the case of multicomputer systems, we take into account the delay due to interprocess communication. A straight- forward application of a QN solver to the problem is not possible due to variations in the state of the system (composition of tasks in execution). An accurate algorithm based on hierarchical decomposition is presented for solving task systems. At the higher level, the system behavior is specified by a Markov chain whose states correspond to the combination of tasks in execution. The state transition rate matrix for the Markov chain is triangular (since the task system graph was assumed to be acyclic), therefore it can be solved efficiently to compute the state probabilities and the task initiation/completion times. At the lower level, the transition rates among the states of the Markov chain are computed using a QN solver, which determines the throughput of the computer system for each system state. The model and the solution method can be used in performance evaluation of applications exhibiting concurrency in centralized/distributed systems where there are conflicting goals of load balancing and minimizing interprocess communication overhead."
            },
            "slug": "Analytic-Queueing-Network-Models-for-Parallel-of-Thomasian-Bay",
            "title": {
                "fragments": [],
                "text": "Analytic Queueing Network Models for Parallel Processing of Task Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "An efficient algorithm to determine the mean completion time and related performance measures for a task system: a set of tasks with precedence relationships in their execution sequence, such that the resulting graph is acyclic."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1879660"
                        ],
                        "name": "S. Carr",
                        "slug": "S.-Carr",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Carr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Carr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70455556"
                        ],
                        "name": "K. Kennedy",
                        "slug": "K.-Kennedy",
                        "structuredName": {
                            "firstName": "Ken",
                            "lastName": "Kennedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kennedy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8043398,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "199d33ed48a7bf2fceb389a9d144474e586dae96",
            "isKey": false,
            "numCitedBy": 157,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "Over the past decade, microprocessor design strategies have focused on increasing the computational power on a single chip. Because computations often require more data from cache per floating-point operation than a machine can deliver and because operations are pipelined, idle computational cycles are common when scientific applications are executed. To overcome these bottlenecks, programmers have learned to use a coding style that ensures a better balance between memory references and floating-point operations. In our view, this is a step in the wrong direction because it makes programs more machine-specific. A programmer should not be required to write a new program version for each new machine; instead, the task of specializing a program to a target machine should be left to the compiler.\nBut is our view practical? Can a sophisticated optimizing compiler obviate the need for the myriad of programming tricks that have found their way into practice to improve the performance of the memory hierarchy? In this paper we attempt to answer that question. To do so, we develop and evaluate techniques that automatically restructure program loops to achieve high performance on specific target architectures. These methods attempt to balance computation and memory accesses and seek to eliminate or reduce pipeline interlock. To do this, they estimate statically the balance between memory operations and floating-point operations for each loop in a particular program and use these estimates to determine whether to apply various loop transformations.\nExperiments with our automatic techniques show that integer-factor speedups are possible on kernels. Additionally, the estimate of the balance between memory operations and computation, and the application of the estimate are very accurate\u2014experiments reveal little difference between the balance achieved by our automatic system that is made possible by hand optimization."
            },
            "slug": "Improving-the-ratio-of-memory-operations-to-in-Carr-Kennedy",
            "title": {
                "fragments": [],
                "text": "Improving the ratio of memory operations to floating-point operations in loops"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper develops and evaluates techniques that automatically restructure program loops to achieve high performance on specific target architectures and attempts to balance computation and memory accesses and seek to eliminate or reduce pipeline interlock."
            },
            "venue": {
                "fragments": [],
                "text": "TOPL"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144888943"
                        ],
                        "name": "M. Hill",
                        "slug": "M.-Hill",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Hill",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116706896"
                        ],
                        "name": "A. Smith",
                        "slug": "A.-Smith",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Smith",
                            "middleNames": [
                                "Jay"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Smith"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 52
                            }
                        ],
                        "text": "For example, the 3Cs model for caches is an analogy [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5777300,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5de4150ba85d39130c69fbe59d48d6ae82f43ec8",
            "isKey": false,
            "numCitedBy": 622,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present new and efficient algorithms for simulating alternative direct-mapped and set-associative caches and use them to quantify the effect of limited associativity on the cache miss ratio. They introduce an algorithm, forest simulation, for simulating alternative direct-mapped caches and generalize one, which they call all-associativity simulation, for simulating alternative direct-mapped, set-associative, and fully-associative caches. The authors find that although all-associativity simulation is theoretically less efficient than forest simulation or stack simulation (a commonly used simulation algorithm), in practice it is not much slower and allows the simulation of many more caches with a single pass through an address trace. The authors also provide data and insight into how varying associatively affects the miss ratio. >"
            },
            "slug": "Evaluating-Associativity-in-CPU-Caches-Hill-Smith",
            "title": {
                "fragments": [],
                "text": "Evaluating Associativity in CPU Caches"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "All-associativity simulation is theoretically less efficient than forest simulation or stack simulation (a commonly used simulation algorithm), in practice it is not much slower and allows the simulation of many more caches with a single pass through an address trace."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Computers"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701130"
                        ],
                        "name": "D. Patterson",
                        "slug": "D.-Patterson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Patterson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Patterson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145117071"
                        ],
                        "name": "Samuel Williams",
                        "slug": "Samuel-Williams",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Williams",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuel Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 19382787,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa06894cdfcc5e2bfb8ecf8514edbc4fba77e710",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 120,
            "paperAbstract": {
                "fragments": [],
                "text": "For the last decade, the exponential potential of Moore's Law has been squandered in the effort to increase single thread performance, which is now limited by the memory, instruction, and power walls. In response, the computing industry has boldly placed its hopes on the multicore gambit. That is, abandon instruction-level parallelism and frequency-scaling in favor of the exponential scaling of the number of compute cores per microprocessor. The massive thread-level parallelism results in tremendous potential performance, but demands efficient parallel programming\u2014a task existing software tools are ill-equipped for. We desire performance portability\u2014the ability to write a program once and not only have it deliver good performance on the development computer, but on all multicore computers today and tomorrow. \nThis thesis accepts for fact that multicore is the basis for all future computers. Furthermore, we regiment our study by organizing it around the computational patterns and motifs as set forth in the Berkeley View. Although domain experts may be extremely knowledgeable on the mathematics and algorithms of their fields, they often lack the detailed computer architecture knowledge required to achieve high performance. Forthcoming heterogeneous architectures will exacerbate the problem for everyone. Thus, we extend the auto-tuning approach to program optimization and performance portability to the menagerie of multicore computers. In an automated fashion, an auto-tuner will explore the optimization space for a particular computational kernel of a motif on a particular computer. In doing so, it will determine the best combination of algorithm, implementation, and data structure for the combination of architecture and input data. \nWe implement and evaluate auto-tuners for two important kernels: Lattice Boltzmann Magnetohydrodynamics (LBMHD) and sparse matrix-vector multiplication (SpMV). They are representative of two of the computational motifs: structured grids and sparse linear algebra. To demonstrate the performance portability that our auto-tuners deliver, we selected an extremely wide range of architectures as an experimental test bed. These include conventional dual- and quad-core superscalar x86 processors both with and without integrated memory controllers. We also include the rather unconventional chip multithreaded (CMT) Sun Niagara2 (Victoria Falls) and the heterogeneous, local store-based IBM Cell Broadband Engine. In some experiments we sacrifice the performance portability of a common C representation, by creating ISA-specific auto-tuned versions of these kernels to gain architectural insight. To quantify our success, we created the Roofline model to perform a bound and bottleneck analysis for each kernel-architecture combination. \nDespite the common wisdom that LBMHD and SpMV are memory bandwidth-bound, and thus nothing can be done to improve performance, we show that auto-tuning consistently delivers speedups in excess of 3\u00d7 across all multicore computers except the memory-bound Intel Clovertown, where the benefit was as little as 1.5\u00d7. The Cell processor, with its explicitly managed memory hierarchy, showed far more dramatic speedups of between 20\u00d7 and 130\u00d7. The auto-tuners includes both architecture-independent optimizations based solely on source code transformations and high-level kernel knowledge, as well as architecture-specific optimizations like the explicit use of single instruction, multiple data (SIMD) extensions or the use Cell's DMA-based memory operations. We observe that the these ISA-specific optimizations are becoming increasingly important as architectures evolve."
            },
            "slug": "Auto-tuning-performance-on-multicore-computers-Patterson-Williams",
            "title": {
                "fragments": [],
                "text": "Auto-tuning performance on multicore computers"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is shown that auto-tuning consistently delivers speedups in excess of 3\u00d7 across all multicore computers except the memory-bound Intel Clovertown, where the benefit was as little as 1.5\u00d7."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52301815"
                        ],
                        "name": "N. S. Barnett",
                        "slug": "N.-S.-Barnett",
                        "structuredName": {
                            "firstName": "Norman",
                            "lastName": "Barnett",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. S. Barnett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1997442"
                        ],
                        "name": "S. Dragomir",
                        "slug": "S.-Dragomir",
                        "structuredName": {
                            "firstName": "Sever",
                            "lastName": "Dragomir",
                            "middleNames": [
                                "Silvestru"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dragomir"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 116073922,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "98e84e80e7126805de225b263813bfb2cf596a26",
            "isKey": false,
            "numCitedBy": 8318,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "vii"
            },
            "slug": "Private-communication-Barnett-Dragomir",
            "title": {
                "fragments": [],
                "text": "Private communication"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48230516"
                        ],
                        "name": "Matteo Frigo",
                        "slug": "Matteo-Frigo",
                        "structuredName": {
                            "firstName": "Matteo",
                            "lastName": "Frigo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matteo Frigo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2097716"
                        ],
                        "name": "Steven G. Johnson",
                        "slug": "Steven-G.-Johnson",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Johnson",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven G. Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 80
                            }
                        ],
                        "text": "We computed the 1-D FFTs on Xeon, X4, and T2+ using an autotuned library (FFTW) [15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "We computed the 1D FFTs on Xeon, X4, and T2+ \nusing an autotuned library (FFTW).15 For Cell, we implemented a radix-2 FFT. FFT differs from SpMV, LBMHD, \nand Stencil in that its operational in\u00adtensity is a function of problem size."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6644892,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f8e9b050c93af6dea582563f61b6460b590bc3af",
            "isKey": false,
            "numCitedBy": 4558,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "FFTW is an implementation of the discrete Fourier transform (DFT) that adapts to the hardware in order to maximize performance. This paper shows that such an approach can yield an implementation that is competitive with hand-optimized libraries, and describes the software structure that makes our current FFTW3 version flexible and adaptive. We further discuss a new algorithm for real-data DFTs of prime size, a new way of implementing DFTs by means of machine-specific single-instruction, multiple-data (SIMD) instructions, and how a special-purpose compiler can derive optimized implementations of the discrete cosine and sine transforms automatically from a DFT algorithm."
            },
            "slug": "The-Design-and-Implementation-of-FFTW3-Frigo-Johnson",
            "title": {
                "fragments": [],
                "text": "The Design and Implementation of FFTW3"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "It is shown that such an approach can yield an implementation of the discrete Fourier transform that is competitive with hand-optimized libraries, and the software structure that makes the current FFTW3 version flexible and adaptive is described."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701130"
                        ],
                        "name": "D. Patterson",
                        "slug": "D.-Patterson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Patterson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Patterson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 144
                            }
                        ],
                        "text": "THE ROOFLINE MODEL We believe that for the recent past and foreseeable future, off-chip memory bandwidth will often be the constraining resource[23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 31581407,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "bce75f78d340cac32dccd8631f59eedebf192abe",
            "isKey": false,
            "numCitedBy": 112,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Summary form only given. As I review performance trends, I am struck by a consistent theme across many technologies over many years: bandwidth improves much more quickly than latency for four different technologies: disks, networks, memories and processors. A rule of thumb to quantify the imbalance is: bandwidth improves by more than the square of the improvement in latency. This paper lists a half-dozen performance milestones to document this observation, many reasons why it happens, a few ways to cope with it, and two small examples of how you might design systems differently if you kept this simple rule of thumb in mind."
            },
            "slug": "Latency-Lags-Bandwidth-Patterson",
            "title": {
                "fragments": [],
                "text": "Latency Lags Bandwidth"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "This paper lists a half-dozen performance milestones to document this observation: bandwidth improves by more than the square of the improvement in latency for four different technologies: disks, networks, memories and processors."
            },
            "venue": {
                "fragments": [],
                "text": "ICCD"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772133"
                        ],
                        "name": "J. Hennessy",
                        "slug": "J.-Hennessy",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Hennessy",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hennessy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701130"
                        ],
                        "name": "D. Patterson",
                        "slug": "D.-Patterson",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Patterson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Patterson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 5284827,
            "fieldsOfStudy": [
                "Computer Science",
                "Art",
                "Physics"
            ],
            "id": "12db961cda6f5adaccb5731fcce0a0044752f3d1",
            "isKey": false,
            "numCitedBy": 1303,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "computer architecture: a quantitative approach, 3rd edition computer architecture a quantitative approach 3rd edition computer architecture a quantitative approach 3rd edition computer architecture introduction computer architecture a quantitative approach third edition computer architecture a quantitative approach 3rd edition computer architecture a quantitative approach third edition computer architecture a quantitative approach 3rd edition computer architecture a quantitative approach gbv computer architecture: a quantitative approach lsu fundamentals of computer design iuma ulpgc computer architecture a quantitative approach solution manual computer architecture a quantitative approach 3rd edition computer architecture a quantitative approach 3rd edition computer architecture a quantitative approach 3rd edition computer architecture a quantitative approach 2nd edition computer architecture, fifth edition: a quantitative computer architecture a quantitative approach 3rd edition computer architecture a quantitative approach 3rd edition computer architecture a quantitative approach 3rd edition computer architecture a quantitative approach (3rd edition a quantitative approach, fifth edition csu computer architecture a quantitative approach solution manual computer architecture a quantitative approach 4th edition computer architecture a quantitative approach 5th edition solution manual for computer architecture a quantitative computer architecture fifth edition a quantitative approach computer architecture a quantitative approach 4th edition computer architecture a quantitative approach (3rd or 4th computer architecture a quantitative approach 3rd edition computer architecture ----a quantitative approach computer architecture a quantitative approach 5th edition computer architecture quantitative approach solution manual computer architecture quantitative approach solutions manual computer architecture a quantitative approach 3rd edition computer architecture a quantitative approach 5th edition"
            },
            "slug": "Computer-Architecture-A-Quantitative-Approach,-5th-Hennessy-Patterson",
            "title": {
                "fragments": [],
                "text": "Computer Architecture - A Quantitative Approach, 5th Edition"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A quantitative approach to computer architecture a quantitative approach 5th edition computer architecture quantitative approach solution manual computer Architecture quantitative approach solutions manual computer architecture an quantitative approach 3rd editionComputer architecture, fifth edition."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34753526"
                        ],
                        "name": "J. Little",
                        "slug": "J.-Little",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Little",
                            "middleNames": [
                                "D.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Little"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 123314524,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "0953122463fe09928d0850d9e6d387db97b9d218",
            "isKey": false,
            "numCitedBy": 2301,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "In a queuing process, let 1/\u03bb be the mean time between the arrivals of two consecutive units, L be the mean number of units in the system, and W be the mean time spent by a unit in the system. It is shown that, if the three means are finite and the corresponding stochastic processes strictly stationary, and, if the arrival process is metrically transitive with nonzero mean, then L = \u03bbW."
            },
            "slug": "A-Proof-for-the-Queuing-Formula:-L-=-\u03bbW-Little",
            "title": {
                "fragments": [],
                "text": "A Proof for the Queuing Formula: L = \u03bbW"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1961
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Software Optimization Guide for AMD Family 10h Processors, Publication 40546"
            },
            "venue": {
                "fragments": [],
                "text": "AMD"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and kennedy, k. estimating interlock and improving balance for pipelined machines"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Parallel Distributed Computing"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Characterization and methodological considerations"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of the 22nd Annual International Symposium on Computer Architecture"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The SPLASH2 programs : Characterization and methodological considerations"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 22 nd Annual International Symposium on Computer Architecture"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Autotuning Performance on Multicore Computers. Ph.D. thesis. university of california, berkeley"
            },
            "venue": {
                "fragments": [],
                "text": "Autotuning Performance on Multicore Computers. Ph.D. thesis. university of california, berkeley"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "f., shalf, j., yelick, k., and Demmel, j. optimization of sparse matrix-vector multiplication on emerging multicore platforms. in Proceedings of the ACM/IEEE SC07 Conference (reno, nV, nov"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 212,
                                "start": 209
                            }
                        ],
                        "text": "The requirements for automatic creation of a Roofline model could guide the designer as to which metrics should be collected when faced with literally hundreds of candidates but only a limited hardware budget.(6) Roofline offers insights into other types of multicore systems (such as vector processors and graphical processing units); other kernels (such as sort and ray tracing); other computational metrics (such as pair-wise sorts per second and frames per second); and other traffic metrics (such as L3 cache bandwidth and I/O bandwidth)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A Case for Sensible Performance Counters"
            },
            "venue": {
                "fragments": [],
                "text": "submitted to the First USENIX Workshop on Hot Topics in Parallelism (HotPar \u201909), Berkeley CA, March 2009."
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "\u201c Estimating interlock and improving balance for pipelined machines , \u201d"
            },
            "venue": {
                "fragments": [],
                "text": "J . Parallel Distrb . Comput ."
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "Although you can find memory performance with the STREAM benchmark [22], for this work we wrote a series of progressively optimized microbenchmarks designed to determine sustainable DRAM bandwidth."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "STREAM: Sustainable Memory Bandwidth in High Performance Computers"
            },
            "venue": {
                "fragments": [],
                "text": "www.cs.virginia.edu/stream, 1995."
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Williams, s., and yelick, k. The Landscape of Parallel Computing Research: A View from Berkeley. technical report ucb/eecs-2006-183. eecs, university of california"
            },
            "venue": {
                "fragments": [],
                "text": "Williams, s., and yelick, k. The Landscape of Parallel Computing Research: A View from Berkeley. technical report ucb/eecs-2006-183. eecs, university of california"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Private communication on financial PDE solvers"
            },
            "venue": {
                "fragments": [],
                "text": "Private communication on financial PDE solvers"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "mapping computational concepts to gPus chapter 31 (los angeles, july 31-aug. 4) Computer Architecture: A Quantitative Approach, Fourth Edition"
            },
            "venue": {
                "fragments": [],
                "text": "ACM SIGGRAPH Courses"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Samuel Williams (SWWilliams@lbl.gov) is a research scientist at Lawrence Berkeley National Laboratory"
            },
            "venue": {
                "fragments": [],
                "text": "Samuel Williams (SWWilliams@lbl.gov) is a research scientist at Lawrence Berkeley National Laboratory"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Petitet, a., Vuduc, r., Whaley, r., and yelick, k. selfadapting linear algebra algorithms and software"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE: Special Issue on Program Generation, Optimization, and Adaptation 93"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Software Optimization Guide for AMD Family 10h Processors, Publication 40546"
            },
            "venue": {
                "fragments": [],
                "text": "Software Optimization Guide for AMD Family 10h Processors, Publication 40546"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Defining Software Requirements for"
            },
            "venue": {
                "fragments": [],
                "text": "Scientific Computing. Presentation,"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and gupta, a.the sPlash-2 programs: characterization and methodological considerations"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 22nd Annual International Symposium on Computer Architecture"
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Latency Lags Bandwidth , \u201d 47 : 10 , CACM , Oct . 2004 . [ 24 ] S . Williams , Autotuning Performance on Multicore Computers"
            },
            "venue": {
                "fragments": [],
                "text": ", Quantitative System Performance : Computer System Analysis Using Queueing Network Models"
            },
            "year": 1984
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 59
                            }
                        ],
                        "text": "We applied the model to four kernels from the seven dwarfs [10][4] to four recent multicore designs: the AMD Opteron X4, Intel Xeon, IBM Cell, and Sun T2+."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 190
                            }
                        ],
                        "text": "2 Four Diverse Floating-Point Kernels Rather than pick programs from some standard parallel benchmark suite such as Parsec [5] or Splash-2 [30], we were inspired by the work of Phil Colella [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 133
                            }
                        ],
                        "text": "Rather than pick programs from a standard parallel benchmark suite \n(such as Parsec5 and Splash-230), we were inspired by the work of Phil Colella,11 an expert in scientific \ncom\u00adputing at Lawrence Berkeley National Laboratory, who identified seven nu\u00admerical methods he believes \nwill be important for computational science and engineering for at least the next decade."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Defining Software Requirements for Scientific Computing"
            },
            "venue": {
                "fragments": [],
                "text": "presentation, 2004."
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 133
                            }
                        ],
                        "text": "For this work, we use the stencil derived from the explicit heat equation, a partial differential equation on a uniform 2563 3D grid.(12) The stencil\u2019s neighbors are the nearest six points along each axis, as well as the center point itself."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "shalf, j., and yelick, k. stencil computation optimization and autotuning on state-of-the-art multicore architectures"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2008 ACM/IEEE SC08  Conference (austin, tx, nov"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "David Patterson (pattrsn@eecs.berkeley.edu) is Director of the Parallel Computing Laboratory of the University of California, Berkeley, and a past president of ACM"
            },
            "venue": {
                "fragments": [],
                "text": "David Patterson (pattrsn@eecs.berkeley.edu) is Director of the Parallel Computing Laboratory of the University of California, Berkeley, and a past president of ACM"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Andrew Waterman (waterman@eecs.berkeley.edu) is a graduate student researcher in the Parallel Computing Laboratory of the University of California"
            },
            "venue": {
                "fragments": [],
                "text": "Andrew Waterman (waterman@eecs.berkeley.edu) is a graduate student researcher in the Parallel Computing Laboratory of the University of California"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 95
                            }
                        ],
                        "text": "We use operational intensity instead of the terms arithmetic intensity [16] or machine balance [8][11] for two reasons."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Estimating interlock and improving balance for pipelined machines"
            },
            "venue": {
                "fragments": [],
                "text": "J. Parallel Distrb. Comput. 5, 334-358. 1988."
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "STREAM: Sustainable Memory Bandwidth in High-Performance Computers, 1995; www.cs.virginia.edu/stream"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 95
                            }
                        ],
                        "text": "We use operational intensity instead of the terms arithmetic intensity [16] or machine balance [8][11] for two reasons."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Estimating interlock and improving balance for pipelined machines,\u201d J"
            },
            "venue": {
                "fragments": [],
                "text": "Parallel Distrb. Comput. 5, 334-358."
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The design and implementation of FFTW 3"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE : Special Issue on Program Generation , Optimization , and Platform Adaptation"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "cocke, j., and kennedy, k. estimating interlock and improving balance for pipelined machines"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Parallel Distributed Computing"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and smith, a. evaluating associativity in cPu caches"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1989
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 12,
            "methodology": 9
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 58,
        "totalPages": 6
    },
    "page_url": "https://www.semanticscholar.org/paper/Roofline:-an-insightful-visual-performance-model-Williams-Waterman/092217c2267f6e0673590aa151d811e579ff7760?sort=total-citations"
}