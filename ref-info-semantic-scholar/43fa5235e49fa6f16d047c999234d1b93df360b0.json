{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743758"
                        ],
                        "name": "M. Liwicki",
                        "slug": "M.-Liwicki",
                        "structuredName": {
                            "firstName": "Marcus",
                            "lastName": "Liwicki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Liwicki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "The recognizer of [10] was used as a reference system."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 78
                            }
                        ],
                        "text": "The preprocessing steps applied in the current system have been introduced in [10], but for the purpose of completeness, we give a short overview below."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 101
                            }
                        ],
                        "text": "These results are significantly higher then those from previous experiments with an HMM-based system [10]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 19004349,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3fef701a35e9c2012320a4deed65c9b9e0aeedb2",
            "isKey": false,
            "numCitedBy": 91,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present an on-line recognition system for handwritten texts acquired from a whiteboard. This input modality has received relatively little attention in the handwriting recognition community in the past. The system proposed in this paper uses state-of-the-art normalization and feature extraction strategies to transform a handwritten text line into a sequence of feature vectors. Additional preprocessing techniques are introduced, which significantly increase the word recognition rate. For classification, Hidden Markov Models are used together with a statistical language model. In writer independent experiments we achieved word recognition rates of 67.3% on the test set when no language model is used, and 70.8% by including a language model."
            },
            "slug": "HMM-Based-On-Line-Recognition-of-Handwritten-Notes-Liwicki-Bunke",
            "title": {
                "fragments": [],
                "text": "HMM-Based On-Line Recognition of Handwritten Whiteboard Notes"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "An on-line recognition system for handwritten texts acquired from a whiteboard that uses state-of-the-art normalization and feature extraction strategies to transform a handwritten text line into a sequence of feature vectors and significantly increases the word recognition rate."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40059859"
                        ],
                        "name": "Stefan J\u00e4ger",
                        "slug": "Stefan-J\u00e4ger",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "J\u00e4ger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefan J\u00e4ger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2561818"
                        ],
                        "name": "S. Manke",
                        "slug": "S.-Manke",
                        "structuredName": {
                            "firstName": "Stefan",
                            "lastName": "Manke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Manke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064936916"
                        ],
                        "name": "J\u00fcrgen Reichert",
                        "slug": "J\u00fcrgen-Reichert",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Reichert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J\u00fcrgen Reichert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 159
                            }
                        ],
                        "text": "For slant normalization, we compute the histogram over all angles between the lines connecting two successive points of the trajectory and the horizontal line [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13250446,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b48e0bca7bfe53158010a531b3ce06e72e8cfac3",
            "isKey": false,
            "numCitedBy": 269,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract. This paper presents the online handwriting recognition system NPen++ developed at the University of Karlsruhe and Carnegie Mellon University. The NPen++ recognition engine is based on a multi-state time delay neural network and yields recognition rates from 96% for a 5,000 word dictionary to 93.4% on a 20,000 word dictionary and 91.2% for a 50,000 word dictionary. The proposed tree search and pruning technique reduces the search space considerably without losing too much recognition performance compared to an exhaustive search. This enables the NPen++ recognizer to be run in real-time with large dictionaries. Initial recognition rates for whole sentences are promising and show that the MS-TDNN architecture is suited to recognizing handwritten data ranging from single characters to whole sentences."
            },
            "slug": "Online-handwriting-recognition:-the-NPen++-J\u00e4ger-Manke",
            "title": {
                "fragments": [],
                "text": "Online handwriting recognition: the NPen++ recognizer"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Initial recognition rates for whole sentences are promising and show that the MS-TDNN architecture is suited to recognizing handwritten data ranging from single characters to whole sentences."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal on Document Analysis and Recognition"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743758"
                        ],
                        "name": "M. Liwicki",
                        "slug": "M.-Liwicki",
                        "structuredName": {
                            "firstName": "Marcus",
                            "lastName": "Liwicki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Liwicki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 45
                            }
                        ],
                        "text": "In our writer independent experiments on the IAMOnDB [9]1, a word recognition rate of up to74."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 105
                            }
                        ],
                        "text": "For our experiments we used the IAM-OnDB, a large online handwriting database acquired from a whiteboard [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 53
                            }
                        ],
                        "text": "In our writer independent experiments on the IAMOnDB [9]1, a word recognition rate of up to 74."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1745101,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9eb7daa88879f283ae05e359d6c502a320b833c9",
            "isKey": false,
            "numCitedBy": 182,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present IAM-OnDB - a new large online handwritten sentences database. It is publicly available and consists of text acquired via an electronic interface from a whiteboard. The database contains about 86 K word instances from an 11 K dictionary written by more than 200 writers. We also describe a recognizer for unconstrained English text that was trained and tested using this database. This recognizer is based on hidden Markov models (HMMs). In our experiments we show that by using larger training sets we can significantly increase the word recognition rate. This recognizer may serve as a benchmark reference for future research."
            },
            "slug": "IAM-OnDB-an-on-line-English-sentence-database-from-Liwicki-Bunke",
            "title": {
                "fragments": [],
                "text": "IAM-OnDB - an on-line English sentence database acquired from handwritten text on a whiteboard"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "IAM-OnDB is a new large online handwritten sentences database that consists of text acquired via an electronic interface from a whiteboard and a recognizer for unconstrained English text that was trained and tested using this database."
            },
            "venue": {
                "fragments": [],
                "text": "Eighth International Conference on Document Analysis and Recognition (ICDAR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144586498"
                        ],
                        "name": "R. Plamondon",
                        "slug": "R.-Plamondon",
                        "structuredName": {
                            "firstName": "R\u00e9jean",
                            "lastName": "Plamondon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Plamondon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1696384"
                        ],
                        "name": "S. Srihari",
                        "slug": "S.-Srihari",
                        "structuredName": {
                            "firstName": "Sargur",
                            "lastName": "Srihari",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Srihari"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 91
                            }
                        ],
                        "text": "Although the problem of handwriting recognition has been considered for more than 30 years [1, 12, 16], there are still many open issues, especially in the task of unconstrained handwritten sentence recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15782139,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d12864a8acbab1830be755bfb9cb177e31ca5e20",
            "isKey": false,
            "numCitedBy": 2749,
            "numCiting": 719,
            "paperAbstract": {
                "fragments": [],
                "text": "Handwriting has continued to persist as a means of communication and recording information in day-to-day life even with the introduction of new technologies. Given its ubiquity in human transactions, machine recognition of handwriting has practical significance, as in reading handwritten notes in a PDA, in postal addresses on envelopes, in amounts in bank checks, in handwritten fields in forms, etc. This overview describes the nature of handwritten language, how it is transduced into electronic data, and the basic concepts behind written language recognition algorithms. Both the online case (which pertains to the availability of trajectory data during writing) and the off-line case (which pertains to scanned images) are considered. Algorithms for preprocessing, character and word recognition, and performance with practical systems are indicated. Other fields of application, like signature verification, writer authentification, handwriting learning tools are also considered."
            },
            "slug": "On-Line-and-Off-Line-Handwriting-Recognition:-A-Plamondon-Srihari",
            "title": {
                "fragments": [],
                "text": "On-Line and Off-Line Handwriting Recognition: A Comprehensive Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The nature of handwritten language, how it is transduced into electronic data, and the basic concepts behind written language recognition algorithms are described."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Pattern Anal. Mach. Intell."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1720945"
                        ],
                        "name": "H. Bunke",
                        "slug": "H.-Bunke",
                        "structuredName": {
                            "firstName": "Horst",
                            "lastName": "Bunke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Bunke"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 91
                            }
                        ],
                        "text": "Although the problem of handwriting recognition has been considered for more than 30 years [1, 12, 16], there are still many open issues, especially in the task of unconstrained handwritten sentence recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3155409,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7123bb66af97ea731990ed5ecffcc2c5fcfd81ab",
            "isKey": false,
            "numCitedBy": 188,
            "numCiting": 153,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reviews the state of the art in off-line Roman cursive handwriting recognition. The input provided to an off-line handwriting recognition system is an image of a digit, a word, or - more generally -some text, and the system produces, as output, an ASCII transcription of the input. This task involves a number of processing steps, some of which are quite difficult. Typically, preprocessing, normalization, feature extraction, classification, and postprocessing operations are required. We'll survey the state of the art, analyze recent trends, and try to identify challenges for future research in this field."
            },
            "slug": "Recognition-of-cursive-Roman-handwriting:-past,-and-Bunke",
            "title": {
                "fragments": [],
                "text": "Recognition of cursive Roman handwriting: past, present and future"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "The state of the art in off-line Roman cursive handwriting recognition is reviewed, recent trends are analyzed, and challenges for future research in this field are identified."
            },
            "venue": {
                "fragments": [],
                "text": "Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 28
                            }
                        ],
                        "text": "The CTC system used a BLSTM [6] network with 100 extended LSTM memory blocks in each of the forward and backward layers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 170
                            }
                        ],
                        "text": "Combining the above two concepts gives bidirectional LSTM (BLSTM), which has been shown to outperform other neural network architectures in framewise phoneme recognition [6]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 59
                            }
                        ],
                        "text": "Combining the above two concepts gives bidirectional\nLSTM (BLSTM), which has been shown to outperform other neural network architectures in framewise phoneme recognition [6]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 45
                            }
                        ],
                        "text": "In the experiments described below, we use a BLSTM network with a CTC output layer to transcribe samples of handwritten text."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1856462,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2f83f6e1afadf0963153974968af6b8342775d82",
            "isKey": false,
            "numCitedBy": 3324,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Framewise-phoneme-classification-with-bidirectional-Graves-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Framewise phoneme classification with bidirectional LSTM and other neural network architectures"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Networks"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143913738"
                        ],
                        "name": "Santiago Fern\u00e1ndez",
                        "slug": "Santiago-Fern\u00e1ndez",
                        "structuredName": {
                            "firstName": "Santiago",
                            "lastName": "Fern\u00e1ndez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Santiago Fern\u00e1ndez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145842938"
                        ],
                        "name": "Faustino J. Gomez",
                        "slug": "Faustino-J.-Gomez",
                        "structuredName": {
                            "firstName": "Faustino",
                            "lastName": "Gomez",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Faustino J. Gomez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 44
                            }
                        ],
                        "text": "Connectionist Temporal Classification (CTC) [5, 2] is an RNN objective function designed to overcome the above problem."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 120
                            }
                        ],
                        "text": "The key innovation is a recently introduced RNN objective function known as Connectionist Temporal Classification (CTC) [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9901844,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "96494e722f58705fa20302fe6179d483f52705b4",
            "isKey": false,
            "numCitedBy": 3534,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Many real-world sequence learning tasks require the prediction of sequences of labels from noisy, unsegmented input data. In speech recognition, for example, an acoustic signal is transcribed into words or sub-word units. Recurrent neural networks (RNNs) are powerful sequence learners that would seem well suited to such tasks. However, because they require pre-segmented training data, and post-processing to transform their outputs into label sequences, their applicability has so far been limited. This paper presents a novel method for training RNNs to label unsegmented sequences directly, thereby solving both problems. An experiment on the TIMIT speech corpus demonstrates its advantages over both a baseline HMM and a hybrid HMM-RNN."
            },
            "slug": "Connectionist-temporal-classification:-labelling-Graves-Fern\u00e1ndez",
            "title": {
                "fragments": [],
                "text": "Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents a novel method for training RNNs to label unsegmented sequences directly, thereby solving both problems of sequence learning and post-processing."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144927151"
                        ],
                        "name": "M. Schuster",
                        "slug": "M.-Schuster",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Schuster",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schuster"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48099761"
                        ],
                        "name": "K. Paliwal",
                        "slug": "K.-Paliwal",
                        "structuredName": {
                            "firstName": "Kuldip",
                            "lastName": "Paliwal",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Paliwal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "Whereas standard RNNs make use of previous context only, bidirectional RNNs (BRNNs) [14] are able to incorporate context on both sides of every position in the input sequence."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18375389,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e23c34414e66118ecd9b08cf0cd4d016f59b0b85",
            "isKey": false,
            "numCitedBy": 5446,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "In the first part of this paper, a regular recurrent neural network (RNN) is extended to a bidirectional recurrent neural network (BRNN). The BRNN can be trained without the limitation of using input information just up to a preset future frame. This is accomplished by training it simultaneously in positive and negative time direction. Structure and training procedure of the proposed network are explained. In regression and classification experiments on artificial data, the proposed structure gives better results than other approaches. For real data, classification experiments for phonemes from the TIMIT database show the same tendency. In the second part of this paper, it is shown how the proposed bidirectional structure can be easily modified to allow efficient estimation of the conditional posterior probability of complete symbol sequences without making any explicit assumption about the shape of the distribution. For this part, experiments on real data are reported."
            },
            "slug": "Bidirectional-recurrent-neural-networks-Schuster-Paliwal",
            "title": {
                "fragments": [],
                "text": "Bidirectional recurrent neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown how the proposed bidirectional structure can be easily modified to allow efficient estimation of the conditional posterior probability of complete symbol sequences without making any explicit assumption about the shape of the distribution."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Signal Process."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719436"
                        ],
                        "name": "A. Vinciarelli",
                        "slug": "A.-Vinciarelli",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Vinciarelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vinciarelli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Although the problem of handwriting recognition has been considered for more than 30 years [1, 12,  16 ], there are still many open issues, especially in the task of unconstrained handwritten sentence recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16082889,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "7f124251d5476213d0bbd95bcc4698458169cd51",
            "isKey": false,
            "numCitedBy": 258,
            "numCiting": 125,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-survey-on-off-line-Cursive-Word-Recognition-Vinciarelli",
            "title": {
                "fragments": [],
                "text": "A survey on off-line Cursive Word Recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Pattern Recognit."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308557"
                        ],
                        "name": "S. Hochreiter",
                        "slug": "S.-Hochreiter",
                        "structuredName": {
                            "firstName": "Sepp",
                            "lastName": "Hochreiter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hochreiter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "O n c e h a v i n g\nNetwork Outputs\n:\nAn LSTM layer consists of a set of recurrently connected blocks, known as memory blocks."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "Combining the above two concepts gives bidirectional\nLSTM (BLSTM), which has been shown to outperform other neural network architectures in framewise phoneme recognition [6]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 30
                            }
                        ],
                        "text": "Long Short-Term Memory (LSTM) [4, 7] is an RNN architecture specifically designed to bridge long time delays between relevant input and target events, making it suitable for problems (such as handwriting recognition) where long range context is required to disambiguate individual labels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "The CTC system used a BLSTM [6] network with 100 extended LSTM memory blocks in each of the forward and backward layers."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "In the experiments described below, we use a BLSTM network with a CTC output layer to transcribe samples of handwritten text."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1915014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44d2abe2175df8153f465f6c39b68b76a0d40ab9",
            "isKey": true,
            "numCitedBy": 52390,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms."
            },
            "slug": "Long-Short-Term-Memory-Hochreiter-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Long Short-Term Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel, efficient, gradient based method called long short-term memory (LSTM) is introduced, which can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145259603"
                        ],
                        "name": "S. Young",
                        "slug": "S.-Young",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Young",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Young"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145731155"
                        ],
                        "name": "N. Russell",
                        "slug": "N.-Russell",
                        "structuredName": {
                            "firstName": "N.",
                            "lastName": "Russell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145984105"
                        ],
                        "name": "J. Thornton",
                        "slug": "J.-Thornton",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Thornton",
                            "middleNames": [
                                "H.",
                                "Simon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Thornton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "In the recognition phase, an adapted version of the token passing algorithm [15] was used to find the most probable sequence of complete words, given the dictionary."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 59705956,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "963cf8f238745100ac6cc5cf730653a6e1849b62",
            "isKey": false,
            "numCitedBy": 364,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a simple but powerful abstract model in which connected word recognition is viewed as a process of passing tokens around a transition network The advantages of this unifying view are many The various apparently di erent connected word algorithms can be represented within the same conceptual framework simply by changing the network topology the application of grammatical constraints is straightforward and perhaps most importantly the entire structure is independent of the actual underlying pattern matching technology To illustrate the power of this conceptual model the paper concludes by describing some work done under the UK Alvey sponsored VODIS Project in which the Token Passing paradigm enabled the One Pass algorithm to be straightforwardly extended to include the generation of multiple alternatives and context free syntactic constraints"
            },
            "slug": "Token-passing:-a-simple-conceptual-model-for-speech-Young-Russell",
            "title": {
                "fragments": [],
                "text": "Token passing: a simple conceptual model for connected speech recognition systems"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "This paper describes a simple but powerful abstract model in which connected word recognition is viewed as a process of passing tokens around a transition network and some work done under the UK Alvey sponsored VODIS Project is described."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2088368"
                        ],
                        "name": "F. Gers",
                        "slug": "F.-Gers",
                        "structuredName": {
                            "firstName": "Felix",
                            "lastName": "Gers",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Gers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739396"
                        ],
                        "name": "N. Schraudolph",
                        "slug": "N.-Schraudolph",
                        "structuredName": {
                            "firstName": "Nicol",
                            "lastName": "Schraudolph",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Schraudolph"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "O n c e h a v i n g\nNetwork Outputs\n:\nAn LSTM layer consists of a set of recurrently connected blocks, known as memory blocks."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "Combining the above two concepts gives bidirectional\nLSTM (BLSTM), which has been shown to outperform other neural network architectures in framewise phoneme recognition [6]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 30
                            }
                        ],
                        "text": "Long Short-Term Memory (LSTM) [4, 7] is an RNN architecture specifically designed to bridge long time delays between relevant input and target events, making it suitable for problems (such as handwriting recognition) where long range context is required to disambiguate individual labels."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "The CTC system used a BLSTM [6] network with 100 extended LSTM memory blocks in each of the forward and backward layers."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 46
                            }
                        ],
                        "text": "In the experiments described below, we use a BLSTM network with a CTC output layer to transcribe samples of handwritten text."
                    },
                    "intents": []
                }
            ],
            "corpusId": 474078,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "047655e733a9eed9a500afd916efa566915b9110",
            "isKey": true,
            "numCitedBy": 1280,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The temporal distance between events conveys information essential for numerous sequential tasks such as motor control and rhythm detection. While Hidden Markov Models tend to ignore this information, recurrent neural networks (RNNs) can in principle learn to make use of it. We focus on Long Short-Term Memory (LSTM) because it has been shown to outperform other RNNs on tasks involving long time lags. We find that LSTM augmented by \"peephole connections\" from its internal cells to its multiplicative gates can learn the fine distinction between sequences of spikes spaced either 50 or 49 time steps apart without the help of any short training exemplars. Without external resets or teacher forcing, our LSTM variant also learns to generate stable streams of precisely timed spikes and other highly nonlinear periodic patterns. This makes LSTM a promising approach for tasks that require the accurate measurement or generation of time intervals."
            },
            "slug": "Learning-Precise-Timing-with-LSTM-Recurrent-Gers-Schraudolph",
            "title": {
                "fragments": [],
                "text": "Learning Precise Timing with LSTM Recurrent Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work finds that LSTM augmented by \"peephole connections\" from its internal cells to its multiplicative gates can learn the fine distinction between sequences of spikes spaced either 50 or 49 time steps apart without the help of any short training exemplars."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2088368"
                        ],
                        "name": "F. Gers",
                        "slug": "F.-Gers",
                        "structuredName": {
                            "firstName": "Felix",
                            "lastName": "Gers",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Gers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 47
                            }
                        ],
                        "text": "The cells are extended by peephole connections [3] that allow them to inspect their current internal states."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 36867983,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "545a4e23bf00ddbc1d3325324b4c61f57cf45081",
            "isKey": false,
            "numCitedBy": 513,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The size of the time intervals between events conveys information essential for numerous sequential tasks such as motor control and rhythm detection. While hidden Markov models tend to ignore this information, recurrent neural networks (RNN) can in principle learn to make use of it. We focus on long short-term memory (LSTM) because it usually outperforms other RNN. Surprisingly, LSTM augmented by \"peephole connections\" from its internal cells to its multiplicative gates can learn the fine distinction between sequences of spikes separated by either 50 or 49 discrete time steps, without the help of any short training exemplars. Without external resets or teacher forcing or loss of performance on tasks reported earlier, our LSTM variant also learns to generate very stable sequences of highly nonlinear, precisely timed spikes. This makes LSTM a promising approach for real-world tasks that require to time and count."
            },
            "slug": "Recurrent-nets-that-time-and-count-Gers-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Recurrent nets that time and count"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Surprisingly, LSTM augmented by \"peephole connections\" from its internal cells to its multiplicative gates can learn the fine distinction between sequences of spikes separated by either 50 or 49 discrete time steps, without the help of any short training exemplars."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks. IJCNN 2000. Neural Computing: New Challenges and Perspectives for the New Millennium"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143913738"
                        ],
                        "name": "Santiago Fern\u00e1ndez",
                        "slug": "Santiago-Fern\u00e1ndez",
                        "structuredName": {
                            "firstName": "Santiago",
                            "lastName": "Fern\u00e1ndez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Santiago Fern\u00e1ndez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 25
                            }
                        ],
                        "text": "Figure 6 illustrates how CTC transcribes an on-line handwriting sample."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 102
                            }
                        ],
                        "text": "Whereas previous objective functions only use RNNs to label individual data points within a sequence, CTC uses the network to label the entire input sequence at once."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "The CTC network was trained to identify individual characters."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 44
                            }
                        ],
                        "text": "Connectionist Temporal Classification (CTC) [5, 2] is an RNN objective function designed to overcome the above problem."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 39
                            }
                        ],
                        "text": "Connectionist Temporal Classification (CTC) [2, 5] is an RNN objective function designed to overcome the above problem."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 66
                            }
                        ],
                        "text": "The input layer was size 25 (one input for each feature), and the CTC output layer had one output for each character, plus one for \u2018blank\u2019."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "CTC uses the network to label the entire input sequence at once."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "The CTC system used a BLSTM [6] network with 100 extended LSTM memory blocks in each of the forward and backward layers."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 115
                            }
                        ],
                        "text": "The key innovation is a recently introduced RNN objective function known as Connectionist Temporal Classification (CTC)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 115
                            }
                        ],
                        "text": "The key innovation is a recently introduced RNN objective function known as Connectionist Temporal Classification (CTC) [5]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 66
                            }
                        ],
                        "text": "In the experiments described below, we use a BLSTM network with a CTC output layer to transcribe samples of handwritten text."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 33
                            }
                        ],
                        "text": "Table 1 shows the results of the CTC approach compared to the HMM-based system."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 97
                            }
                        ],
                        "text": "We use a recently introduced objective function, known as Connectionist Temporal Classification (CTC), that directly trains the network to label unsegmented sequence data."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1668634,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "12496bf48ebdb5ab3c92bc911d6ee42369fa70bc",
            "isKey": false,
            "numCitedBy": 85,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Modelling data in structured domains requires establishing the relations among patterns at multiple scales. When these patterns arise from sequential data, the multiscale structure also contains a dynamic component that must be modelled, particularly, as is often the case, if the data is unsegmented. Probabilistic graphical models are the predominant framework for labelling unsegmented sequential data in structured domains. Their use requires a certain degree of a priori knowledge about the relations among patterns and about the patterns themselves. This paper presents a hierarchical system, based on the connectionist temporal classification algorithm, for labelling unsegmented sequential data at multiple scales with recurrent neural networks only. Experiments on the recognition of sequences of spoken digits show that the system outperforms hidden Markov models, while making fewer assumptions about the domain."
            },
            "slug": "Sequence-Labelling-in-Structured-Domains-with-Fern\u00e1ndez-Graves",
            "title": {
                "fragments": [],
                "text": "Sequence Labelling in Structured Domains with Hierarchical Recurrent Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper presents a hierarchical system, based on the connectionist temporal classification algorithm, for labelling unsegmented sequential data at multiple scales with recurrent neural networks only and shows that the system outperforms hidden Markov models, while making fewer assumptions about the domain."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145903504"
                        ],
                        "name": "R. Rosenfeld",
                        "slug": "R.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rosenfeld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10959945,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6586e7c73cc1c9e9a251947425c54c5051be626",
            "isKey": false,
            "numCitedBy": 732,
            "numCiting": 205,
            "paperAbstract": {
                "fragments": [],
                "text": "Statistical language models estimate the distribution of various natural language phenomena for the purpose of speech recognition and other language technologies. Since the first significant model was proposed in 1980, many attempts have been made to improve the state of the art. We review them, point to a few promising directions, and argue for a Bayesian approach to integration of linguistic theories with data."
            },
            "slug": "Two-decades-of-statistical-language-modeling:-where-Rosenfeld",
            "title": {
                "fragments": [],
                "text": "Two decades of statistical language modeling: where do we go from here?"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A Bayesian approach to integration of linguistic theories with data is argued for inStatistical language models estimate the distribution of various natural language phenomena for the purpose of speech recognition and other language technologies."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "118672230"
                        ],
                        "name": "D. Moore",
                        "slug": "D.-Moore",
                        "structuredName": {
                            "firstName": "Darren",
                            "lastName": "Moore",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Moore"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 224,
                                "start": 220
                            }
                        ],
                        "text": "In the particular application underlying this paper we aim at developing a handwriting recognition system to be used in a smart meeting room scenario [17], in our case the smart meeting room developed in the IM2 project [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15406718,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "d4bdb678b5c4ba6f53e46915025ef4014c205868",
            "isKey": false,
            "numCitedBy": 121,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "The IDIAP Smart Meeting Room is a meeting room equipped with synchronised, multi-channel audio-visual recording facilities. This document presents a detailed description of the room with particular emphasis on the acquisition equipment and the components used to synchronise and accurately time-stamp each channel of audio and video. Brief descriptions of the current meeting recording configuration and recorded data processing procedures are also included."
            },
            "slug": "The-IDIAP-Smart-Meeting-Room-Moore",
            "title": {
                "fragments": [],
                "text": "The IDIAP Smart Meeting Room"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A detailed description of the IDIAP Smart Meeting Room is presented with particular emphasis on the acquisition equipment and the components used to synchronise and accurately time-stamp each channel of audio and video."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145618636"
                        ],
                        "name": "Tanja Schultz",
                        "slug": "Tanja-Schultz",
                        "structuredName": {
                            "firstName": "Tanja",
                            "lastName": "Schultz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tanja Schultz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145900786"
                        ],
                        "name": "M. Bett",
                        "slug": "M.-Bett",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35142518"
                        ],
                        "name": "Matthias Denecke",
                        "slug": "Matthias-Denecke",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Denecke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthias Denecke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46423430"
                        ],
                        "name": "Robert G. Malkin",
                        "slug": "Robert-G.-Malkin",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Malkin",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert G. Malkin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3281101"
                        ],
                        "name": "I. Rogina",
                        "slug": "I.-Rogina",
                        "structuredName": {
                            "firstName": "Ivica",
                            "lastName": "Rogina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Rogina"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742325"
                        ],
                        "name": "R. Stiefelhagen",
                        "slug": "R.-Stiefelhagen",
                        "structuredName": {
                            "firstName": "Rainer",
                            "lastName": "Stiefelhagen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Stiefelhagen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118579343"
                        ],
                        "name": "Jie Yang",
                        "slug": "Jie-Yang",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 150
                            }
                        ],
                        "text": "In the particular application underlying this paper we aim at developing a handwriting recognition system to be used in a smart meeting room scenario [17], in our case the smart meeting room developed in the IM2 project [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17465838,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "52ca6cf25246a20b399e1d3f166266b73b08efc1",
            "isKey": false,
            "numCitedBy": 99,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "As computational and communications systems become increasingly smaller, faster, more powerful, and more integrated, the goal of interactive, integrated meeting support rooms is slowly becoming reality. It is already possible, for instance, to rapidly locate task-related information during a meeting, filter it, and share it with remote users. Unfortunately, the technologies that provide such capabilities are as obstructive as they are useful - they force humans to focus on the tool rather than the task. Thus the veneer of utility often hides the true costs of use, which are longer, less focused human interactions. To address this issue, we present our current research efforts towards SMaRT: the Smart Meeting Room Task. The goal of SMaRT is to provide meeting support services that do not require explicit human-computer interaction. Instead, by monitoring the activities in the meeting room using both video and audio analysis, the room is able to react appropriately to users' needs and allow the users to focus on their own goals."
            },
            "slug": "SMaRT:-the-Smart-Meeting-Room-Task-at-ISL-Waibel-Schultz",
            "title": {
                "fragments": [],
                "text": "SMaRT: the Smart Meeting Room Task at ISL"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The goal of SMaRT is to provide meeting support services that do not require explicit human-computer interaction, and by monitoring the activities in the meeting room using both video and audio analysis, the room is able to react appropriately to users' needs and allow the users to focus on their own goals."
            },
            "venue": {
                "fragments": [],
                "text": "2003 IEEE International Conference on Acoustics, Speech, and Signal Processing, 2003. Proceedings. (ICASSP '03)."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2751729"
                        ],
                        "name": "P. Wellner",
                        "slug": "P.-Wellner",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Wellner",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Wellner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38059118"
                        ],
                        "name": "Mike Flynn",
                        "slug": "Mike-Flynn",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Flynn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mike Flynn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50157808"
                        ],
                        "name": "M. Guillemot",
                        "slug": "M.-Guillemot",
                        "structuredName": {
                            "firstName": "Ma\u00ebl",
                            "lastName": "Guillemot",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Guillemot"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 44
                            }
                        ],
                        "text": "In order to allow for indexing and browsing [18], automatic transcription of the recorded data is needed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10851666,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "357e7873ddb1a0a749724aeed9d9a44228a07364",
            "isKey": false,
            "numCitedBy": 101,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Browsing for elements of interest within a recorded meeting is time-consuming. We describe work in progress on a meeting browser, which aims to support this process by displaying many types of data. These include media, transcripts and processing results such as speaker segmentations. Users interact with these visualizations to observe and control synchronized playback of the recorded meeting."
            },
            "slug": "Browsing-Recorded-Meetings-with-Ferret-Wellner-Flynn",
            "title": {
                "fragments": [],
                "text": "Browsing Recorded Meetings with Ferret"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "Work in progress on a meeting browser, which aims to support this process by displaying many types of data, including media, transcripts and processing results such as speaker segmentations, is described."
            },
            "venue": {
                "fragments": [],
                "text": "MLMI"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719436"
                        ],
                        "name": "A. Vinciarelli",
                        "slug": "A.-Vinciarelli",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Vinciarelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vinciarelli"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 91
                            }
                        ],
                        "text": "Although the problem of handwriting recognition has been considered for more than 30 years [1, 12, 16], there are still many open issues, especially in the task of unconstrained handwritten sentence recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 18402360,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "87018bf66f29f29ea679b1fe1e99b3f5bb7e1fc4",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-Survey-On-Off-Line-Cursive-Script-Recognition-Vinciarelli",
            "title": {
                "fragments": [],
                "text": "A Survey On Off-Line Cursive Script Recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "Whereas standard RNNs make use of previous context only, bidirectional RNNs (BRNNs) [14] are able to incorporate context on both sides of every position in the input sequence."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Bidirectional recurrent neural networks.IEEE"
            },
            "venue": {
                "fragments": [],
                "text": "Transactions on Signal Processing  ,"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 44
                            }
                        ],
                        "text": "Connectionist Temporal Classification (CTC) [2, 5] is an RNN objective function designed to overcome the above problem."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 120
                            }
                        ],
                        "text": "The key innovation is a recently introduced RNN objective function known as Connectionist Temporal Classification (CTC) [5]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "S"
            },
            "venue": {
                "fragments": [],
                "text": "Fer\u0144 andez, F. Gomez, and J. Schmidhuber. Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks. In Proc. Int. Conf. on Machine Learning , pages 369\u2013376"
            },
            "year": 2006
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 12,
            "methodology": 9,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 21,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/A-novel-approach-to-on-line-handwriting-recognition-Liwicki-Graves/43fa5235e49fa6f16d047c999234d1b93df360b0?sort=total-citations"
}