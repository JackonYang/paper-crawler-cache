{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39838894"
                        ],
                        "name": "Yihui He",
                        "slug": "Yihui-He",
                        "structuredName": {
                            "firstName": "Yihui",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yihui He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46698300"
                        ],
                        "name": "Ji Lin",
                        "slug": "Ji-Lin",
                        "structuredName": {
                            "firstName": "Ji",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ji Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47781592"
                        ],
                        "name": "Zhijian Liu",
                        "slug": "Zhijian-Liu",
                        "structuredName": {
                            "firstName": "Zhijian",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhijian Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35446689"
                        ],
                        "name": "Hanrui Wang",
                        "slug": "Hanrui-Wang",
                        "structuredName": {
                            "firstName": "Hanrui",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanrui Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2040091191"
                        ],
                        "name": "Li-Jia Li",
                        "slug": "Li-Jia-Li",
                        "structuredName": {
                            "firstName": "Li-Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143840275"
                        ],
                        "name": "Song Han",
                        "slug": "Song-Han",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Han"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 52048008,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1717255b6aea01fe956cef998abbc3c399b5d7cf",
            "isKey": false,
            "numCitedBy": 843,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "Model compression is an effective technique to efficiently deploy neural network models on mobile devices which have limited computation resources and tight power budgets. Conventional model compression techniques rely on hand-crafted features and require domain experts to explore the large design space trading off among model size, speed, and accuracy, which is usually sub-optimal and time-consuming. In this paper, we propose AutoML for Model Compression (AMC) which leverages reinforcement learning to efficiently sample the design space and can improve the model compression quality. We achieved state-of-the-art model compression results in a fully automated way without any human efforts. Under 4\\(\\times \\) FLOPs reduction, we achieved 2.7% better accuracy than the hand-crafted model compression method for VGG-16 on ImageNet. We applied this automated, push-the-button compression pipeline to MobileNet-V1 and achieved a speedup of 1.53\\(\\times \\) on the GPU (Titan Xp) and 1.95\\(\\times \\) on an Android phone (Google Pixel 1), with negligible loss of accuracy."
            },
            "slug": "AMC:-AutoML-for-Model-Compression-and-Acceleration-He-Lin",
            "title": {
                "fragments": [],
                "text": "AMC: AutoML for Model Compression and Acceleration on Mobile Devices"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper proposes AutoML for Model Compression (AMC) which leverages reinforcement learning to efficiently sample the design space and can improve the model compression quality and achieves state-of-the-art model compression results in a fully automated way without any human efforts."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1950815"
                        ],
                        "name": "Tien-Ju Yang",
                        "slug": "Tien-Ju-Yang",
                        "structuredName": {
                            "firstName": "Tien-Ju",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tien-Ju Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50579876"
                        ],
                        "name": "Yu-hsin Chen",
                        "slug": "Yu-hsin-Chen",
                        "structuredName": {
                            "firstName": "Yu-hsin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu-hsin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775477"
                        ],
                        "name": "J. Emer",
                        "slug": "J.-Emer",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Emer",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Emer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691305"
                        ],
                        "name": "V. Sze",
                        "slug": "V.-Sze",
                        "structuredName": {
                            "firstName": "Vivienne",
                            "lastName": "Sze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Sze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 47
                            }
                        ],
                        "text": "Energy-aware pruning [25] uses an energy model [24] and incorporates the estimated energy numbers into the pruning algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206495670,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2fd67bc7d239b26d9e2453fecd29e88cc7a8627d",
            "isKey": false,
            "numCitedBy": 59,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep Neural Networks (DNNs) have enabled state-of-the-art accuracy on many challenging artificial intelligence tasks. While most of the computation currently resides in the cloud, it is desirable to embed DNN processing locally near the sensor due to privacy, security, and latency concerns or limitations in communication bandwidth. Accordingly, there has been increasing interest in the research community to design energy-efficient DNNs. However, estimating energy consumption from the DNN model is much more difficult than other metrics such as storage cost (model size) and throughput (number of operations). This is due to the fact that a significant portion of the energy is consumed by data movement, which is difficult to extract directly from the DNN model. This work proposes an energy estimation methodology that can estimate the energy consumption of a DNN based on its architecture, sparsity, and bitwidth. This methodology can be used to evaluate the various DNN architectures and energy-efficient techniques that are currently being proposed in the field and guide the design of energy-efficient DNNs. We have released an online version of the energy estimation tool at energyestimation.mit.edu. We believe that this method will play a critical role in bridging the gap between algorithm and hardware design and provide useful insights for the development of energy-efficient DNNs."
            },
            "slug": "A-method-to-estimate-the-energy-consumption-of-deep-Yang-Chen",
            "title": {
                "fragments": [],
                "text": "A method to estimate the energy consumption of deep neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work proposes an energy estimation methodology that can estimate the energy consumption of a DNN based on its architecture, sparsity, and bitwidth and believes that this method will play a critical role in bridging the gap between algorithm and hardware design and provide useful insights for the development of energy-efficient DNNs."
            },
            "venue": {
                "fragments": [],
                "text": "2017 51st Asilomar Conference on Signals, Systems, and Computers"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107911399"
                        ],
                        "name": "Yong-Deok Kim",
                        "slug": "Yong-Deok-Kim",
                        "structuredName": {
                            "firstName": "Yong-Deok",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yong-Deok Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2292315"
                        ],
                        "name": "Eunhyeok Park",
                        "slug": "Eunhyeok-Park",
                        "structuredName": {
                            "firstName": "Eunhyeok",
                            "lastName": "Park",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eunhyeok Park"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1808405"
                        ],
                        "name": "S. Yoo",
                        "slug": "S.-Yoo",
                        "structuredName": {
                            "firstName": "Sungjoo",
                            "lastName": "Yoo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Yoo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061466320"
                        ],
                        "name": "Taelim Choi",
                        "slug": "Taelim-Choi",
                        "structuredName": {
                            "firstName": "Taelim",
                            "lastName": "Choi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Taelim Choi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145445128"
                        ],
                        "name": "Lu Yang",
                        "slug": "Lu-Yang",
                        "structuredName": {
                            "firstName": "Lu",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lu Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149549040"
                        ],
                        "name": "Dongjun Shin",
                        "slug": "Dongjun-Shin",
                        "structuredName": {
                            "firstName": "Dongjun",
                            "lastName": "Shin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dongjun Shin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 37
                            }
                        ],
                        "text": "Layer-decomposition-based algorithms [13, 23] exploit matrix decomposition to reduce the number of operations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15602035,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4ca3b996d888d7178dbbf9855bb2ab253bdfa43d",
            "isKey": false,
            "numCitedBy": 672,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "Although the latest high-end smartphone has powerful CPU and GPU, running deeper convolutional neural networks (CNNs) for complex tasks such as ImageNet classification on mobile devices is challenging. To deploy deep CNNs on mobile devices, we present a simple and effective scheme to compress the entire CNN, which we call one-shot whole network compression. The proposed scheme consists of three steps: (1) rank selection with variational Bayesian matrix factorization, (2) Tucker decomposition on kernel tensor, and (3) fine-tuning to recover accumulated loss of accuracy, and each step can be easily implemented using publicly available tools. We demonstrate the effectiveness of the proposed scheme by testing the performance of various compressed CNNs (AlexNet, VGGS, GoogLeNet, and VGG-16) on the smartphone. Significant reductions in model size, runtime, and energy consumption are obtained, at the cost of small loss in accuracy. In addition, we address the important implementation level issue on 1?1 convolution, which is a key operation of inception module of GoogLeNet as well as CNNs compressed by our proposed scheme."
            },
            "slug": "Compression-of-Deep-Convolutional-Neural-Networks-Kim-Park",
            "title": {
                "fragments": [],
                "text": "Compression of Deep Convolutional Neural Networks for Fast and Low Power Mobile Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A simple and effective scheme to compress the entire CNN, called one-shot whole network compression, which addresses the important implementation level issue on 1?1 convolution, which is a key operation of inception module of GoogLeNet as well as CNNs compressed by the proposed scheme."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1950815"
                        ],
                        "name": "Tien-Ju Yang",
                        "slug": "Tien-Ju-Yang",
                        "structuredName": {
                            "firstName": "Tien-Ju",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tien-Ju Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50579876"
                        ],
                        "name": "Yu-hsin Chen",
                        "slug": "Yu-hsin-Chen",
                        "structuredName": {
                            "firstName": "Yu-hsin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu-hsin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691305"
                        ],
                        "name": "V. Sze",
                        "slug": "V.-Sze",
                        "structuredName": {
                            "firstName": "Vivienne",
                            "lastName": "Sze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Sze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 118
                            }
                        ],
                        "text": "and this strategy allows reducing both filters and feature maps, which play an important role in resource consumption [25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "Energy-aware pruning [25] uses an energy model [24] and incorporates the estimated energy numbers into the pruning algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 142
                            }
                        ],
                        "text": "More complex methods can be adopted to increase the accuracy, such as removing the filters based on their joint influence on the feature maps [25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 143
                            }
                        ],
                        "text": "The relationship between an indirect metric and the corresponding direct metric can be highly non-linear and platform-dependent as observed by [15, 25, 26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 219,
                                "start": 215
                            }
                        ],
                        "text": "Due to the limitation of the SNPE tool, the layerwise latency breakdown only considers the computation time and does not include the latency of other operations, such as feature map movement, which can be expensive [25]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2779809,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3ac1df952ffb63abb4231a4410f6f8375ccdfe79",
            "isKey": false,
            "numCitedBy": 478,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep convolutional neural networks (CNNs) are indispensable to state-of-the-art computer vision algorithms. However, they are still rarely deployed on battery-powered mobile devices, such as smartphones and wearable gadgets, where vision algorithms can enable many revolutionary real-world applications. The key limiting factor is the high energy consumption of CNN processing due to its high computational complexity. While there are many previous efforts that try to reduce the CNN model size or the amount of computation, we find that they do not necessarily result in lower energy consumption. Therefore, these targets do not serve as a good metric for energy cost estimation. To close the gap between CNN design and energy consumption optimization, we propose an energy-aware pruning algorithm for CNNs that directly uses the energy consumption of a CNN to guide the pruning process. The energy estimation methodology uses parameters extrapolated from actual hardware measurements. The proposed layer-by-layer pruning algorithm also prunes more aggressively than previously proposed pruning methods by minimizing the error in the output feature maps instead of the filter weights. For each layer, the weights are first pruned and then locally fine-tuned with a closed-form least-square solution to quickly restore the accuracy. After all layers are pruned, the entire network is globally fine-tuned using back-propagation. With the proposed pruning method, the energy consumption of AlexNet and GoogLeNet is reduced by 3.7x and 1.6x, respectively, with less than 1% top-5 accuracy loss. We also show that reducing the number of target classes in AlexNet greatly decreases the number of weights, but has a limited impact on energy consumption."
            },
            "slug": "Designing-Energy-Efficient-Convolutional-Neural-Yang-Chen",
            "title": {
                "fragments": [],
                "text": "Designing Energy-Efficient Convolutional Neural Networks Using Energy-Aware Pruning"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes an energy-aware pruning algorithm for CNNs that directly uses the energy consumption of a CNN to guide the pruning process, and shows that reducing the number of target classes in AlexNet greatly decreases thenumber of weights, but has a limited impact on energy consumption."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9099711"
                        ],
                        "name": "Jiecao Yu",
                        "slug": "Jiecao-Yu",
                        "structuredName": {
                            "firstName": "Jiecao",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiecao Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144096603"
                        ],
                        "name": "Andrew Lukefahr",
                        "slug": "Andrew-Lukefahr",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Lukefahr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Lukefahr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2587404"
                        ],
                        "name": "David J. Palframan",
                        "slug": "David-J.-Palframan",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Palframan",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David J. Palframan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31613624"
                        ],
                        "name": "Ganesh S. Dasika",
                        "slug": "Ganesh-S.-Dasika",
                        "structuredName": {
                            "firstName": "Ganesh",
                            "lastName": "Dasika",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ganesh S. Dasika"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40040123"
                        ],
                        "name": "R. Das",
                        "slug": "R.-Das",
                        "structuredName": {
                            "firstName": "Reetuparna",
                            "lastName": "Das",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Das"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721289"
                        ],
                        "name": "S. Mahlke",
                        "slug": "S.-Mahlke",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Mahlke",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mahlke"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4497748,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5fd26b0954a723f1fa22aa0a9fadcb4de498884b",
            "isKey": false,
            "numCitedBy": 282,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "As the size of Deep Neural Networks (DNNs) continues to grow to increase accuracy and solve more complex problems, their energy footprint also scales. Weight pruning reduces DNN model size and the computation by removing redundant weights. However, we implemented weight pruning for several popular networks on a variety of hardware platforms and observed surprising results. For many networks, the network sparsity caused by weight pruning will actually hurt the overall performance despite large reductions in the model size and required multiply-accumulate operations. Also, encoding the sparse format of pruned networks incurs additional storage space overhead. To overcome these challenges, we propose Scalpel that customizes DNN pruning to the underlying hardware by matching the pruned network structure to the data-parallel hardware organization. Scalpel consists of two techniques: SIMD-aware weight pruning and node pruning. For low-parallelism hardware (e.g., microcontroller), SIMD-aware weight pruning maintains weights in aligned fixed-size groups to fully utilize the SIMD units. For high-parallelism hardware (e.g., GPU), node pruning removes redundant nodes, not redundant weights, thereby reducing computation without sacrificing the dense matrix format. For hardware with moderate parallelism (e.g., desktop CPU), SIMD-aware weight pruning and node pruning are synergistically applied together. Across the microcontroller, CPU and GPU, Scalpel achieves mean speedups of 3.54x, 2.61x, and 1.25x while reducing the model sizes by 88%, 82%, and 53%. In comparison, traditional weight pruning achieves mean speedups of 1.90x, 1.06x, 0.41x across the three platforms."
            },
            "slug": "Scalpel:-Customizing-DNN-pruning-to-the-underlying-Yu-Lukefahr",
            "title": {
                "fragments": [],
                "text": "Scalpel: Customizing DNN pruning to the underlying hardware parallelism"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work implemented weight pruning for several popular networks on a variety of hardware platforms and observed surprising results, including mean speedups of 3.54x, 2.61x, and 1.25x while reducing the model sizes by 88, 82%, and 53%."
            },
            "venue": {
                "fragments": [],
                "text": "2017 ACM/IEEE 44th Annual International Symposium on Computer Architecture (ISCA)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50875121"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "Xiangyu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148927556"
                        ],
                        "name": "Xinyu Zhou",
                        "slug": "Xinyu-Zhou",
                        "structuredName": {
                            "firstName": "Xinyu",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinyu Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3287035"
                        ],
                        "name": "Mengxiao Lin",
                        "slug": "Mengxiao-Lin",
                        "structuredName": {
                            "firstName": "Mengxiao",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mengxiao Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "MobileNets [9, 18] and ShuffleNets [27] provide efficient layer operations and reference architecture design."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 24982157,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9da734397acd7ff7c557960c62fb1b400b27bd89",
            "isKey": false,
            "numCitedBy": 3251,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce an extremely computation-efficient CNN architecture named ShuffleNet, which is designed specially for mobile devices with very limited computing power (e.g., 10-150 MFLOPs). The new architecture utilizes two new operations, pointwise group convolution and channel shuffle, to greatly reduce computation cost while maintaining accuracy. Experiments on ImageNet classification and MS COCO object detection demonstrate the superior performance of ShuffleNet over other structures, e.g. lower top-1 error (absolute 7.8%) than recent MobileNet [12] on ImageNet classification task, under the computation budget of 40 MFLOPs. On an ARM-based mobile device, ShuffleNet achieves ~13\u00c3\u2014 actual speedup over AlexNet while maintaining comparable accuracy."
            },
            "slug": "ShuffleNet:-An-Extremely-Efficient-Convolutional-Zhang-Zhou",
            "title": {
                "fragments": [],
                "text": "ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "An extremely computation-efficient CNN architecture named ShuffleNet is introduced, which is designed specially for mobile devices with very limited computing power (e.g., 10-150 MFLOPs), to greatly reduce computation cost while maintaining accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1891108"
                        ],
                        "name": "Liangzhen Lai",
                        "slug": "Liangzhen-Lai",
                        "structuredName": {
                            "firstName": "Liangzhen",
                            "lastName": "Lai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liangzhen Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40622167"
                        ],
                        "name": "Naveen Suda",
                        "slug": "Naveen-Suda",
                        "structuredName": {
                            "firstName": "Naveen",
                            "lastName": "Suda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naveen Suda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144137038"
                        ],
                        "name": "V. Chandra",
                        "slug": "V.-Chandra",
                        "structuredName": {
                            "firstName": "Vikas",
                            "lastName": "Chandra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Chandra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 26843321,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74f7ef729d7d1d74012801a5533eacf75cf28ef7",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Efficient and compact neural network models are essential for enabling the deployment on mobile and embedded devices. In this work, we point out that typical design metrics for gauging the efficiency of neural network architectures -- total number of operations and parameters -- are not sufficient. These metrics may not accurately correlate with the actual deployment metrics such as energy and memory footprint. We show that throughput and energy varies by up to 5X across different neural network operation types on an off-the-shelf Arm Cortex-M7 microcontroller. Furthermore, we show that the memory required for activation data also need to be considered, apart from the model parameters, for network architecture exploration studies."
            },
            "slug": "Not-All-Ops-Are-Created-Equal!-Lai-Suda",
            "title": {
                "fragments": [],
                "text": "Not All Ops Are Created Equal!"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that throughput and energy varies by up to 5X across different neural network operation types on an off-the-shelf Arm Cortex-M7 microcontroller, and memory required for activation data also need to be considered, apart from the model parameters, for network architecture exploration studies."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11543879"
                        ],
                        "name": "Benoit Jacob",
                        "slug": "Benoit-Jacob",
                        "structuredName": {
                            "firstName": "Benoit",
                            "lastName": "Jacob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benoit Jacob"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "68988581"
                        ],
                        "name": "S. Kligys",
                        "slug": "S.-Kligys",
                        "structuredName": {
                            "firstName": "Skirmantas",
                            "lastName": "Kligys",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kligys"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Bo Chen",
                        "slug": "Bo-Chen",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2717876"
                        ],
                        "name": "Menglong Zhu",
                        "slug": "Menglong-Zhu",
                        "structuredName": {
                            "firstName": "Menglong",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Menglong Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113728429"
                        ],
                        "name": "Matthew Tang",
                        "slug": "Matthew-Tang",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144727050"
                        ],
                        "name": "Andrew G. Howard",
                        "slug": "Andrew-G.-Howard",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Howard",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew G. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2595180"
                        ],
                        "name": "Hartwig Adam",
                        "slug": "Hartwig-Adam",
                        "structuredName": {
                            "firstName": "Hartwig",
                            "lastName": "Adam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hartwig Adam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741985"
                        ],
                        "name": "Dmitry Kalenichenko",
                        "slug": "Dmitry-Kalenichenko",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Kalenichenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dmitry Kalenichenko"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 13
                            }
                        ],
                        "text": "Quantization [11, 12, 17] reduces the complexity by decreasing the computation accuracy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 39867659,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "59d0d7ccec2db66cad20cac5721ce54a8a058294",
            "isKey": false,
            "numCitedBy": 1284,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "The rising popularity of intelligent mobile devices and the daunting computational cost of deep learning-based models call for efficient and accurate on-device inference schemes. We propose a quantization scheme that allows inference to be carried out using integer-only arithmetic, which can be implemented more efficiently than floating point inference on commonly available integer-only hardware. We also co-design a training procedure to preserve end-to-end model accuracy post quantization. As a result, the proposed quantization scheme improves the tradeoff between accuracy and on-device latency. The improvements are significant even on MobileNets, a model family known for run-time efficiency, and are demonstrated in ImageNet classification and COCO detection on popular CPUs."
            },
            "slug": "Quantization-and-Training-of-Neural-Networks-for-Jacob-Kligys",
            "title": {
                "fragments": [],
                "text": "Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A quantization scheme is proposed that allows inference to be carried out using integer- only arithmetic, which can be implemented more efficiently than floating point inference on commonly available integer-only hardware."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143840275"
                        ],
                        "name": "Song Han",
                        "slug": "Song-Han",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47325862"
                        ],
                        "name": "Jeff Pool",
                        "slug": "Jeff-Pool",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Pool",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeff Pool"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066786849"
                        ],
                        "name": "J. Tran",
                        "slug": "J.-Tran",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Tran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80724002"
                        ],
                        "name": "W. Dally",
                        "slug": "W.-Dally",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dally",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dally"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 0
                            }
                        ],
                        "text": "[6, 14, 16] aim to remove individual redundant weights from DNNs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2238772,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1ff9a37d766e3a4f39757f5e1b235a42dacf18ff",
            "isKey": false,
            "numCitedBy": 4076,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural networks are both computationally intensive and memory intensive, making them difficult to deploy on embedded systems. Also, conventional networks fix the architecture before training starts; as a result, training cannot improve the architecture. To address these limitations, we describe a method to reduce the storage and computation required by neural networks by an order of magnitude without affecting their accuracy by learning only the important connections. Our method prunes redundant connections using a three-step method. First, we train the network to learn which connections are important. Next, we prune the unimportant connections. Finally, we retrain the network to fine tune the weights of the remaining connections. On the ImageNet dataset, our method reduced the number of parameters of AlexNet by a factor of 9x, from 61 million to 6.7 million, without incurring accuracy loss. Similar experiments with VGG-16 found that the number of parameters can be reduced by 13x, from 138 million to 10.3 million, again with no loss of accuracy."
            },
            "slug": "Learning-both-Weights-and-Connections-for-Efficient-Han-Pool",
            "title": {
                "fragments": [],
                "text": "Learning both Weights and Connections for Efficient Neural Network"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A method to reduce the storage and computation required by neural networks by an order of magnitude without affecting their accuracy by learning only the important connections, and prunes redundant connections using a three-step method."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3437504"
                        ],
                        "name": "Hengyuan Hu",
                        "slug": "Hengyuan-Hu",
                        "structuredName": {
                            "firstName": "Hengyuan",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hengyuan Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2128424546"
                        ],
                        "name": "Rui Peng",
                        "slug": "Rui-Peng",
                        "structuredName": {
                            "firstName": "Rui",
                            "lastName": "Peng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rui Peng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5068280"
                        ],
                        "name": "Yu-Wing Tai",
                        "slug": "Yu-Wing-Tai",
                        "structuredName": {
                            "firstName": "Yu-Wing",
                            "lastName": "Tai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu-Wing Tai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2088295"
                        ],
                        "name": "Chi-Keung Tang",
                        "slug": "Chi-Keung-Tang",
                        "structuredName": {
                            "firstName": "Chi-Keung",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chi-Keung Tang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2493219,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "60ae4f18cb53efff0174e3fea7064049737e1e67",
            "isKey": false,
            "numCitedBy": 564,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "State-of-the-art neural networks are getting deeper and wider. While their performance increases with the increasing number of layers and neurons, it is crucial to design an efficient deep architecture in order to reduce computational and memory costs. Designing an efficient neural network, however, is labor intensive requiring many experiments, and fine-tunings. In this paper, we introduce network trimming which iteratively optimizes the network by pruning unimportant neurons based on analysis of their outputs on a large dataset. Our algorithm is inspired by an observation that the outputs of a significant portion of neurons in a large network are mostly zero, regardless of what inputs the network received. These zero activation neurons are redundant, and can be removed without affecting the overall accuracy of the network. After pruning the zero activation neurons, we retrain the network using the weights before pruning as initialization. We alternate the pruning and retraining to further reduce zero activations in a network. Our experiments on the LeNet and VGG-16 show that we can achieve high compression ratio of parameters without losing or even achieving higher accuracy than the original network."
            },
            "slug": "Network-Trimming:-A-Data-Driven-Neuron-Pruning-Deep-Hu-Peng",
            "title": {
                "fragments": [],
                "text": "Network Trimming: A Data-Driven Neuron Pruning Approach towards Efficient Deep Architectures"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper introduces network trimming which iteratively optimizes the network by pruning unimportant neurons based on analysis of their outputs on a large dataset, inspired by an observation that the outputs of a significant portion of neurons in a large network are mostly zero."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39838894"
                        ],
                        "name": "Yihui He",
                        "slug": "Yihui-He",
                        "structuredName": {
                            "firstName": "Yihui",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yihui He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143840275"
                        ],
                        "name": "Song Han",
                        "slug": "Song-Han",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Han"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 68
                            }
                        ],
                        "text": "The results are shown and compared with the multipliers [9] and ADC [8] in Fig."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 9,
                                "start": 6
                            }
                        ],
                        "text": "\u2013 ADC [8] is an automatic network simplification algorithm based on reinforcement learning."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 95
                            }
                        ],
                        "text": "The figure compares NetAdapt (adapting the large MobileNetV1) with the multipliers [9] and ADC [8] on a mobile CPU of Google Pixel 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 96
                            }
                        ],
                        "text": "This figure compares NetAdapt (adapting the large MobileNetV1) with the multipliers [9] and ADC [8] on a mobile GPU of Samsung Galaxy S8."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 195346338,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "726df4f3f7a2ff193e626b49e37e2b3a7e494034",
            "isKey": true,
            "numCitedBy": 64,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "Model compression is an effective technique facilitating the deployment of neural network models on mobile devices that have limited computation resources and a tight power budget. However, conventional model compression techniques use hand-crafted features and require domain experts to explore the large design space trading off model size, speed, and accuracy, which is usually sub-optimal and time-consuming. In this paper, we propose Automated Deep Compression (ADC) that leverages reinforcement learning in order to efficiently sample the design space and greatly improve the model compression quality. We achieved state-of-the-art model compression results in a fully automated way without any human efforts. Under 4x FLOPs reduction, we achieved 2.7% better accuracy than hand-crafted model compression method for VGG-16 on ImageNet. We applied this automated, push-the-button compression pipeline to MobileNet and achieved a 2x reduction in FLOPs, and a speedup of 1.49x on Titan Xp and 1.65x on an Android phone (Samsung Galaxy S7), with negligible loss of accuracy."
            },
            "slug": "ADC:-Automated-Deep-Compression-and-Acceleration-He-Han",
            "title": {
                "fragments": [],
                "text": "ADC: Automated Deep Compression and Acceleration with Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This paper proposes Automated Deep Compression (ADC) that leverages reinforcement learning in order to efficiently sample the design space and greatly improve the model compression quality and achieves state-of-the-art model compression results in a fully automated way without any human efforts."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691305"
                        ],
                        "name": "V. Sze",
                        "slug": "V.-Sze",
                        "structuredName": {
                            "firstName": "Vivienne",
                            "lastName": "Sze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Sze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50579876"
                        ],
                        "name": "Yu-hsin Chen",
                        "slug": "Yu-hsin-Chen",
                        "structuredName": {
                            "firstName": "Yu-hsin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu-hsin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1950815"
                        ],
                        "name": "Tien-Ju Yang",
                        "slug": "Tien-Ju-Yang",
                        "structuredName": {
                            "firstName": "Tien-Ju",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tien-Ju Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775477"
                        ],
                        "name": "J. Emer",
                        "slug": "J.-Emer",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Emer",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Emer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 24
                            }
                        ],
                        "text": "We refer the readers to [21] for a comprehensive survey, and summarize the main approaches below."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3273340,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3f116042f50a499ab794bcc1255915bee507413c",
            "isKey": false,
            "numCitedBy": 1748,
            "numCiting": 193,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep neural networks (DNNs) are currently widely used for many artificial intelligence (AI) applications including computer vision, speech recognition, and robotics. While DNNs deliver state-of-the-art accuracy on many AI tasks, it comes at the cost of high computational complexity. Accordingly, techniques that enable efficient processing of DNNs to improve energy efficiency and throughput without sacrificing application accuracy or increasing hardware cost are critical to the wide deployment of DNNs in AI systems. This article aims to provide a comprehensive tutorial and survey about the recent advances toward the goal of enabling efficient processing of DNNs. Specifically, it will provide an overview of DNNs, discuss various hardware platforms and architectures that support DNNs, and highlight key trends in reducing the computation cost of DNNs either solely via hardware design changes or via joint hardware design and DNN algorithm changes. It will also summarize various development resources that enable researchers and practitioners to quickly get started in this field, and highlight important benchmarking metrics and design considerations that should be used for evaluating the rapidly growing number of DNN hardware designs, optionally including algorithmic codesigns, being proposed in academia and industry. The reader will take away the following concepts from this article: understand the key design considerations for DNNs; be able to evaluate different DNN hardware implementations with benchmarks and comparison metrics; understand the tradeoffs between various hardware architectures and platforms; be able to evaluate the utility of various DNN design techniques for efficient processing; and understand recent implementation trends and opportunities."
            },
            "slug": "Efficient-Processing-of-Deep-Neural-Networks:-A-and-Sze-Chen",
            "title": {
                "fragments": [],
                "text": "Efficient Processing of Deep Neural Networks: A Tutorial and Survey"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50579876"
                        ],
                        "name": "Yu-hsin Chen",
                        "slug": "Yu-hsin-Chen",
                        "structuredName": {
                            "firstName": "Yu-hsin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu-hsin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775477"
                        ],
                        "name": "J. Emer",
                        "slug": "J.-Emer",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Emer",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Emer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691305"
                        ],
                        "name": "V. Sze",
                        "slug": "V.-Sze",
                        "structuredName": {
                            "firstName": "Vivienne",
                            "lastName": "Sze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Sze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 245,
                                "start": 242
                            }
                        ],
                        "text": "However, this requires designing models to estimate the direct metrics of each target platform, which requires detailed knowledge of the platform including its hardware architecture [3], and the network-to-array mapping used in the toolchain [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3291270,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "399acab2bee6eccbfffe4a2ce688b6b1075e9c5e",
            "isKey": false,
            "numCitedBy": 838,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep convolutional neural networks (CNNs) are widely used in modern AI systems for their superior accuracy but at the cost of high computational complexity. The complexity comes from the need to simultaneously process hundreds of filters and channels in the high-dimensional convolutions, which involve a significant amount of data movement. Although highly-parallel compute paradigms, such as SIMD/SIMT, effectively address the computation requirement to achieve high throughput, energy consumption still remains high as data movement can be more expensive than computation. Accordingly, finding a dataflow that supports parallel processing with minimal data movement cost is crucial to achieving energy-efficient CNN processing without compromising accuracy. In this paper, we present a novel dataflow, called row-stationary (RS), that minimizes data movement energy consumption on a spatial architecture. This is realized by exploiting local data reuse of filter weights and feature map pixels, i.e., activations, in the high-dimensional convolutions, and minimizing data movement of partial sum accumulations. Unlike dataflows used in existing designs, which only reduce certain types of data movement, the proposed RS dataflow can adapt to different CNN shape configurations and reduces all types of data movement through maximally utilizing the processing engine (PE) local storage, direct inter-PE communication and spatial parallelism. To evaluate the energy efficiency of the different dataflows, we propose an analysis framework that compares energy cost under the same hardware area and processing parallelism constraints. Experiments using the CNN configurations of AlexNet show that the proposed RS dataflow is more energy efficient than existing dataflows in both convolutional (1.4\u00d7 to 2.5\u00d7) and fully-connected layers (at least 1.3\u00d7 for batch size larger than 16). The RS dataflow has also been demonstrated on a fabricated chip, which verifies our energy analysis."
            },
            "slug": "Eyeriss:-A-Spatial-Architecture-for-Dataflow-for-Chen-Emer",
            "title": {
                "fragments": [],
                "text": "Eyeriss: a spatial architecture for energy-efficient dataflow for convolutional neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel dataflow, called row-stationary (RS), is presented that minimizes data movement energy consumption on a spatial architecture and can adapt to different CNN shape configurations and reduces all types of data movement through maximally utilizing the processing engine local storage, direct inter-PE communication and spatial parallelism."
            },
            "venue": {
                "fragments": [],
                "text": "CARN"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143887493"
                        ],
                        "name": "Mohammad Rastegari",
                        "slug": "Mohammad-Rastegari",
                        "structuredName": {
                            "firstName": "Mohammad",
                            "lastName": "Rastegari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohammad Rastegari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2004053"
                        ],
                        "name": "Vicente Ordonez",
                        "slug": "Vicente-Ordonez",
                        "structuredName": {
                            "firstName": "Vicente",
                            "lastName": "Ordonez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vicente Ordonez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40497777"
                        ],
                        "name": "Joseph Redmon",
                        "slug": "Joseph-Redmon",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Redmon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph Redmon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143787583"
                        ],
                        "name": "Ali Farhadi",
                        "slug": "Ali-Farhadi",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Farhadi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ali Farhadi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 13
                            }
                        ],
                        "text": "Quantization [11, 12, 17] reduces the complexity by decreasing the computation accuracy."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14925907,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b649a98ce77ece8cd7638bb74ab77d22d9be77e7",
            "isKey": false,
            "numCitedBy": 2591,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose two efficient approximations to standard convolutional neural networks: Binary-Weight-Networks and XNOR-Networks. In Binary-Weight-Networks, the filters are approximated with binary values resulting in 32\\(\\times \\) memory saving. In XNOR-Networks, both the filters and the input to convolutional layers are binary. XNOR-Networks approximate convolutions using primarily binary operations. This results in 58\\(\\times \\) faster convolutional operations (in terms of number of the high precision operations) and 32\\(\\times \\) memory savings. XNOR-Nets offer the possibility of running state-of-the-art networks on CPUs (rather than GPUs) in real-time. Our binary networks are simple, accurate, efficient, and work on challenging visual tasks. We evaluate our approach on the ImageNet classification task. The classification accuracy with a Binary-Weight-Network version of AlexNet is the same as the full-precision AlexNet. We compare our method with recent network binarization methods, BinaryConnect and BinaryNets, and outperform these methods by large margins on ImageNet, more than \\(16\\,\\%\\) in top-1 accuracy. Our code is available at: http://allenai.org/plato/xnornet."
            },
            "slug": "XNOR-Net:-ImageNet-Classification-Using-Binary-Rastegari-Ordonez",
            "title": {
                "fragments": [],
                "text": "XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The Binary-Weight-Network version of AlexNet is compared with recent network binarization methods, BinaryConnect and BinaryNets, and outperform these methods by large margins on ImageNet, more than \\(16\\,\\%\\) in top-1 accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2824500"
                        ],
                        "name": "Pavlo Molchanov",
                        "slug": "Pavlo-Molchanov",
                        "structuredName": {
                            "firstName": "Pavlo",
                            "lastName": "Molchanov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pavlo Molchanov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2342481"
                        ],
                        "name": "Stephen Tyree",
                        "slug": "Stephen-Tyree",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Tyree",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen Tyree"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2976930"
                        ],
                        "name": "Tero Karras",
                        "slug": "Tero-Karras",
                        "structuredName": {
                            "firstName": "Tero",
                            "lastName": "Karras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tero Karras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761103"
                        ],
                        "name": "Timo Aila",
                        "slug": "Timo-Aila",
                        "structuredName": {
                            "firstName": "Timo",
                            "lastName": "Aila",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timo Aila"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690538"
                        ],
                        "name": "J. Kautz",
                        "slug": "J.-Kautz",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Kautz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kautz"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 17240902,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3db8730c203f88d7f08a6a99e8c02a077dc9b011",
            "isKey": false,
            "numCitedBy": 1045,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new formulation for pruning convolutional kernels in neural networks to enable efficient inference. We interleave greedy criteria-based pruning with fine-tuning by backpropagation - a computationally efficient procedure that maintains good generalization in the pruned network. We propose a new criterion based on Taylor expansion that approximates the change in the cost function induced by pruning network parameters. We focus on transfer learning, where large pretrained networks are adapted to specialized tasks. The proposed criterion demonstrates superior performance compared to other criteria, e.g. the norm of kernel weights or feature map activation, for pruning large CNNs after adaptation to fine-grained classification tasks (Birds-200 and Flowers-102) relaying only on the first order gradient information. We also show that pruning can lead to more than 10x theoretical (5x practical) reduction in adapted 3D-convolutional filters with a small drop in accuracy in a recurrent gesture classifier. Finally, we show results for the large-scale ImageNet dataset to emphasize the flexibility of our approach."
            },
            "slug": "Pruning-Convolutional-Neural-Networks-for-Resource-Molchanov-Tyree",
            "title": {
                "fragments": [],
                "text": "Pruning Convolutional Neural Networks for Resource Efficient Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that pruning can lead to more than 10x theoretical (5x practical) reduction in adapted 3D-convolutional filters with a small drop in accuracy in a recurrent gesture classifier."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144882893"
                        ],
                        "name": "M. Sandler",
                        "slug": "M.-Sandler",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Sandler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sandler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144727050"
                        ],
                        "name": "Andrew G. Howard",
                        "slug": "Andrew-G.-Howard",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Howard",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew G. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2717876"
                        ],
                        "name": "Menglong Zhu",
                        "slug": "Menglong-Zhu",
                        "structuredName": {
                            "firstName": "Menglong",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Menglong Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3422677"
                        ],
                        "name": "A. Zhmoginov",
                        "slug": "A.-Zhmoginov",
                        "structuredName": {
                            "firstName": "Andrey",
                            "lastName": "Zhmoginov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zhmoginov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34192119"
                        ],
                        "name": "Liang-Chieh Chen",
                        "slug": "Liang-Chieh-Chen",
                        "structuredName": {
                            "firstName": "Liang-Chieh",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liang-Chieh Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 4555207,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4",
            "isKey": false,
            "numCitedBy": 7406,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a new mobile architecture, MobileNetV2, that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes. We also describe efficient ways of applying these mobile models to object detection in a novel framework we call SSDLite. Additionally, we demonstrate how to build mobile semantic segmentation models through a reduced form of DeepLabv3 which we call Mobile DeepLabv3. is based on an inverted residual structure where the shortcut connections are between the thin bottleneck layers. The intermediate expansion layer uses lightweight depthwise convolutions to filter features as a source of non-linearity. Additionally, we find that it is important to remove non-linearities in the narrow layers in order to maintain representational power. We demonstrate that this improves performance and provide an intuition that led to this design. Finally, our approach allows decoupling of the input/output domains from the expressiveness of the transformation, which provides a convenient framework for further analysis. We measure our performance on ImageNet [1] classification, COCO object detection [2], VOC image segmentation [3]. We evaluate the trade-offs between accuracy, and number of operations measured by multiply-adds (MAdd), as well as actual latency, and the number of parameters."
            },
            "slug": "MobileNetV2:-Inverted-Residuals-and-Linear-Sandler-Howard",
            "title": {
                "fragments": [],
                "text": "MobileNetV2: Inverted Residuals and Linear Bottlenecks"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A new mobile architecture, MobileNetV2, is described that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes and allows decoupling of the input/output domains from the expressiveness of the transformation."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144727050"
                        ],
                        "name": "Andrew G. Howard",
                        "slug": "Andrew-G.-Howard",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Howard",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew G. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2717876"
                        ],
                        "name": "Menglong Zhu",
                        "slug": "Menglong-Zhu",
                        "structuredName": {
                            "firstName": "Menglong",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Menglong Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Bo Chen",
                        "slug": "Bo-Chen",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741985"
                        ],
                        "name": "Dmitry Kalenichenko",
                        "slug": "Dmitry-Kalenichenko",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Kalenichenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dmitry Kalenichenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108301072"
                        ],
                        "name": "Weijun Wang",
                        "slug": "Weijun-Wang",
                        "structuredName": {
                            "firstName": "Weijun",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weijun Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47447630"
                        ],
                        "name": "Tobias Weyand",
                        "slug": "Tobias-Weyand",
                        "structuredName": {
                            "firstName": "Tobias",
                            "lastName": "Weyand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tobias Weyand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2612392"
                        ],
                        "name": "M. Andreetto",
                        "slug": "M.-Andreetto",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Andreetto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Andreetto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2595180"
                        ],
                        "name": "Hartwig Adam",
                        "slug": "Hartwig-Adam",
                        "structuredName": {
                            "firstName": "Hartwig",
                            "lastName": "Adam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hartwig Adam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 14
                            }
                        ],
                        "text": "\u2013 Multipliers [9] are simple but effective methods for simplifying networks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 235
                            }
                        ],
                        "text": "4 compares the estimated latency (the sum of layer-wise latency from the layer-wise look-up tables) and the real latency on a single large core of Google Pixel 1 CPU while adapting the 100% MobileNetV1 with the input resolution of 224 [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 83
                            }
                        ],
                        "text": "The figure compares NetAdapt (adapting the small MobileNetV1) with the multipliers [9] and MorphNet [5] on a mobile CPU of Google Pixel 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 83
                            }
                        ],
                        "text": "The figure compares NetAdapt (adapting the large MobileNetV1) with the multipliers [9] and ADC [8] on a mobile CPU of Google Pixel 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 72
                            }
                        ],
                        "text": "In this section, we apply the proposed NetAdapt algorithm to MobileNets [9, 18], which are designed for mobile applications, and experiment on the ImageNet dataset [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 14
                            }
                        ],
                        "text": "4 even though MobileNets are more compact and much harder to simplify than the other larger networks, such as VGG [19]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 34
                            }
                        ],
                        "text": "NetAdapt ConfigurationMobileNetV1 [9] is based on depthwise separable convolutions, which factorize a m\u00d7m standard convolution layer into a m\u00d7m depthwise layer and a 1\u00d71 standard convolution layer called a pointwise layer."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 61
                            }
                        ],
                        "text": "The results are summarized and compared with the multipliers [9] and MorphNet [5] in Fig."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 214
                            }
                        ],
                        "text": "The comparison between the estimated latency (using layer-wise look-up tables) and the real latency on a single large core of Google Pixel 1 CPU while adapting the 100% MobileNetV1 with the input resolution of 224 [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 11
                            }
                        ],
                        "text": "MobileNets [9, 18] and ShuffleNets [27] provide efficient layer operations and reference architecture design."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 56
                            }
                        ],
                        "text": "The results are shown and compared with the multipliers [9] and ADC [8] in Fig."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 32
                            }
                        ],
                        "text": "For example, NetAdapt can adapt MobileNets to further push the frontier of efficient networks as shown in Sec."
                    },
                    "intents": []
                }
            ],
            "corpusId": 12670695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3647d6d0f151dc05626449ee09cc7bce55be497e",
            "isKey": false,
            "numCitedBy": 10323,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization."
            },
            "slug": "MobileNets:-Efficient-Convolutional-Neural-Networks-Howard-Zhu",
            "title": {
                "fragments": [],
                "text": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work introduces two simple global hyper-parameters that efficiently trade off between latency and accuracy and demonstrates the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477463"
                        ],
                        "name": "Itay Hubara",
                        "slug": "Itay-Hubara",
                        "structuredName": {
                            "firstName": "Itay",
                            "lastName": "Hubara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Itay Hubara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2388466"
                        ],
                        "name": "Matthieu Courbariaux",
                        "slug": "Matthieu-Courbariaux",
                        "structuredName": {
                            "firstName": "Matthieu",
                            "lastName": "Courbariaux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthieu Courbariaux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1912398"
                        ],
                        "name": "Daniel Soudry",
                        "slug": "Daniel-Soudry",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Soudry",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Soudry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1387872181"
                        ],
                        "name": "Ran El-Yaniv",
                        "slug": "Ran-El-Yaniv",
                        "structuredName": {
                            "firstName": "Ran",
                            "lastName": "El-Yaniv",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ran El-Yaniv"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6453539,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "28135fd3e80dda50a673cd556f10b9b972005d27",
            "isKey": false,
            "numCitedBy": 1282,
            "numCiting": 65,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a method to train Binarized Neural Networks (BNNs) - neural networks with binary weights and activations at run-time. At train-time the binary weights and activations are used for computing the parameter gradients. During the forward pass, BNNs drastically reduce memory size and accesses, and replace most arithmetic operations with bit-wise operations, which is expected to substantially improve power-efficiency. To validate the effectiveness of BNNs, we conducted two sets of experiments on the Torch7 and Theano frameworks. On both, BNNs achieved nearly state-of-the-art results over the MNIST, CIFAR-10 and SVHN datasets. We also report our preliminary results on the challenging ImageNet dataset. Last but not least, we wrote a binary matrix multiplication GPU kernel with which it is possible to run our MNIST BNN 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classification accuracy. The code for training and running our BNNs is available on-line."
            },
            "slug": "Binarized-Neural-Networks-Hubara-Courbariaux",
            "title": {
                "fragments": [],
                "text": "Binarized Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A binary matrix multiplication GPU kernel is written with which it is possible to run the MNIST BNN 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classification accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2824500"
                        ],
                        "name": "Pavlo Molchanov",
                        "slug": "Pavlo-Molchanov",
                        "structuredName": {
                            "firstName": "Pavlo",
                            "lastName": "Molchanov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pavlo Molchanov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2342481"
                        ],
                        "name": "Stephen Tyree",
                        "slug": "Stephen-Tyree",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Tyree",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen Tyree"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2976930"
                        ],
                        "name": "Tero Karras",
                        "slug": "Tero-Karras",
                        "structuredName": {
                            "firstName": "Tero",
                            "lastName": "Karras",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tero Karras"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761103"
                        ],
                        "name": "Timo Aila",
                        "slug": "Timo-Aila",
                        "structuredName": {
                            "firstName": "Timo",
                            "lastName": "Aila",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Timo Aila"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690538"
                        ],
                        "name": "J. Kautz",
                        "slug": "J.-Kautz",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Kautz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kautz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 0
                            }
                        ],
                        "text": "[6, 14, 16] aim to remove individual redundant weights from DNNs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16167970,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "026ecf916023e13191331a354271b7f9b86e50a1",
            "isKey": false,
            "numCitedBy": 347,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new framework for pruning convolutional kernels in neural networks to enable efficient inference, focusing on transfer learning where large and potentially unwieldy pretrained networks are adapted to specialized tasks. We interleave greedy criteria-based pruning with fine-tuning by backpropagation\u2014a computationally efficient procedure that maintains good generalization in the pruned network. We propose a new criterion based on an efficient first-order Taylor expansion to approximate the absolute change in training cost induced by pruning a network component. After normalization, the proposed criterion scales appropriately across all layers of a deep CNN, eliminating the need for per-layer sensitivity analysis. The proposed criterion demonstrates superior performance compared to other criteria, such as the norm of kernel weights or average feature map activation."
            },
            "slug": "Pruning-Convolutional-Neural-Networks-for-Resource-Molchanov-Tyree",
            "title": {
                "fragments": [],
                "text": "Pruning Convolutional Neural Networks for Resource Efficient Transfer Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A new criterion based on an efficient first-order Taylor expansion to approximate the absolute change in training cost induced by pruning a network component is proposed, demonstrating superior performance compared to other criteria, such as the norm of kernel weights or average feature map activation."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2151982940"
                        ],
                        "name": "Byungjo Kim",
                        "slug": "Byungjo-Kim",
                        "structuredName": {
                            "firstName": "Byungjo",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Byungjo Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108625122"
                        ],
                        "name": "Miyoung Lee",
                        "slug": "Miyoung-Lee",
                        "structuredName": {
                            "firstName": "Miyoung",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Miyoung Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109217809"
                        ],
                        "name": "Jinkyu Kim",
                        "slug": "Jinkyu-Kim",
                        "structuredName": {
                            "firstName": "Jinkyu",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jinkyu Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9642105"
                        ],
                        "name": "Juyeob Kim",
                        "slug": "Juyeob-Kim",
                        "structuredName": {
                            "firstName": "Juyeob",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Juyeob Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108413742"
                        ],
                        "name": "Joohyun Lee",
                        "slug": "Joohyun-Lee",
                        "structuredName": {
                            "firstName": "Joohyun",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joohyun Lee"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 44056228,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "08c3b964c7a6d09322bb070acc16d321f331ab93",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper present hierarchical compression scheme in deep convolutional neural networks (DCNN) on the ImageNet Large-Scale Visual Recognition Challenge (ILSVRC) for mobile devices. In hierarchical compression, we reduce the size of parameters and layers in VGG16 and GoogLeNet by using the iterative synapse pruning and grouping and quantization schemes hierarchically. We use the own simulation framework based on caffe to execute the hierarchical network compression and compare the test accuracy of reference model with compressed ones. The proposed scheme reduces the network parameter size to 91.61% and 67% in VGG and GoogLeNet, respectively. And with less 16bit fixed point parameters, we achieve good compression rates again, with only negligible loss of classification accuracy."
            },
            "slug": "Hierarchical-Compression-of-Deep-Convolutional-on-Kim-Lee",
            "title": {
                "fragments": [],
                "text": "Hierarchical Compression of Deep Convolutional Neural Networks on Large Scale Visual Recognition for Mobile Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 70,
                "text": "This paper present hierarchical compression scheme in deep convolutional neural networks (DCNN) on the ImageNet Large-Scale Visual Recognition Challenge (ILSVRC) for mobile devices by using the own simulation framework based on caffe to execute the hierarchical network compression and comparing the test accuracy of reference model with compressed ones."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2822290"
                        ],
                        "name": "Suraj Srinivas",
                        "slug": "Suraj-Srinivas",
                        "structuredName": {
                            "firstName": "Suraj",
                            "lastName": "Srinivas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Suraj Srinivas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144682140"
                        ],
                        "name": "R. Venkatesh Babu",
                        "slug": "R.-Venkatesh-Babu",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Babu",
                            "middleNames": [
                                "Venkatesh"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Venkatesh Babu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[20] focus on removing entire filters instead of individual weights."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15647317,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b0bd441a0cc04cdd0d0e469fe4c5184ee148a97d",
            "isKey": false,
            "numCitedBy": 388,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep Neural nets (NNs) with millions of parameters are at the heart of many state-of-the-art computer vision systems today. However, recent works have shown that much smaller models can achieve similar levels of performance. In this work, we address the problem of pruning parameters in a trained NN model. Instead of removing individual weights one at a time as done in previous works, we remove one neuron at a time. We show how similar neurons are redundant, and propose a systematic way to remove them. Our experiments in pruning the densely connected layers show that we can remove upto 85\\% of the total parameters in an MNIST-trained network, and about 35\\% for AlexNet without significantly affecting performance. Our method can be applied on top of most networks with a fully connected layer to give a smaller network."
            },
            "slug": "Data-free-Parameter-Pruning-for-Deep-Neural-Srinivas-Babu",
            "title": {
                "fragments": [],
                "text": "Data-free Parameter Pruning for Deep Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown how similar neurons are redundant, and a systematic way to remove them is proposed, which can be applied on top of most networks with a fully connected layer to give a smaller network."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771551"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3080683"
                        ],
                        "name": "Shaoqing Ren",
                        "slug": "Shaoqing-Ren",
                        "structuredName": {
                            "firstName": "Shaoqing",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoqing Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 16
                            }
                        ],
                        "text": "For example, in ResNet [7], we can treat a residual block as a single unit to speed up the adaptation process.\nof filters that can satisfy the current resource constraint will be chosen."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 23
                            }
                        ],
                        "text": "For example, in ResNet [7], we can treat a residual block as a single unit to speed up the adaptation process."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 57
                            }
                        ],
                        "text": "We did not apply NetAdapt on larger networks like ResNet [7] and VGG [19] because networks become more difficult to simplify as they become smaller; these networks are also seldom deployed on mobile platforms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206594692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "isKey": false,
            "numCitedBy": 97653,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation."
            },
            "slug": "Deep-Residual-Learning-for-Image-Recognition-He-Zhang",
            "title": {
                "fragments": [],
                "text": "Deep Residual Learning for Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work presents a residual learning framework to ease the training of networks that are substantially deeper than those used previously, and provides comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152894252"
                        ],
                        "name": "A. Gordon",
                        "slug": "A.-Gordon",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Gordon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gordon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2740527"
                        ],
                        "name": "Elad Eban",
                        "slug": "Elad-Eban",
                        "structuredName": {
                            "firstName": "Elad",
                            "lastName": "Eban",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elad Eban"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7624658"
                        ],
                        "name": "Ofir Nachum",
                        "slug": "Ofir-Nachum",
                        "structuredName": {
                            "firstName": "Ofir",
                            "lastName": "Nachum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ofir Nachum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152688442"
                        ],
                        "name": "Bo Chen",
                        "slug": "Bo-Chen",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1950815"
                        ],
                        "name": "Tien-Ju Yang",
                        "slug": "Tien-Ju-Yang",
                        "structuredName": {
                            "firstName": "Tien-Ju",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tien-Ju Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3242613"
                        ],
                        "name": "E. Choi",
                        "slug": "E.-Choi",
                        "structuredName": {
                            "firstName": "E.",
                            "lastName": "Choi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Choi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 100
                            }
                        ],
                        "text": "The figure compares NetAdapt (adapting the small MobileNetV1) with the multipliers [9] and MorphNet [5] on a mobile CPU of Google Pixel 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 53
                            }
                        ],
                        "text": "We adopt the same training configuration as MorphNet [5] (except that the batch size is 128 instead of 96)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 78
                            }
                        ],
                        "text": "The results are summarized and compared with the multipliers [9] and MorphNet [5] in Fig."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 11
                            }
                        ],
                        "text": "\u2013 MorphNet [5] is an automatic network simplification algorithm based on sparsifying regularization."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 9
                            }
                        ],
                        "text": "MorphNet [5] leverages the sparsifying regularizers to automatically determine the layerwise compression rate."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206596875,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e60f693cb12132c7fffc34dc141bcc3c9dfd4961",
            "isKey": false,
            "numCitedBy": 253,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We present MorphNet, an approach to automate the design of neural network structures. MorphNet iteratively shrinks and expands a network, shrinking via a resource-weighted sparsifying regularizer on activations and expanding via a uniform multiplicative factor on all layers. In contrast to previous approaches, our method is scalable to large networks, adaptable to specific resource constraints (e.g. the number of floating-point operations per inference), and capable of increasing the network's performance. When applied to standard network architectures on a wide variety of datasets, our approach discovers novel structures in each domain, obtaining higher performance while respecting the resource constraint."
            },
            "slug": "MorphNet:-Fast-&-Simple-Resource-Constrained-of-Gordon-Eban",
            "title": {
                "fragments": [],
                "text": "MorphNet: Fast & Simple Resource-Constrained Structure Learning of Deep Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "MorphNet iteratively shrinks and expands a network, shrinking via a resource-weighted sparsifying regularizer on activations and expanding via a uniform multiplicative factor on all layers, which is scalable to large networks, adaptable to specific resource constraints, and capable of increasing the network's performance."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8387085"
                        ],
                        "name": "Zichao Yang",
                        "slug": "Zichao-Yang",
                        "structuredName": {
                            "firstName": "Zichao",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zichao Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3009779"
                        ],
                        "name": "Marcin Moczulski",
                        "slug": "Marcin-Moczulski",
                        "structuredName": {
                            "firstName": "Marcin",
                            "lastName": "Moczulski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marcin Moczulski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715051"
                        ],
                        "name": "Misha Denil",
                        "slug": "Misha-Denil",
                        "structuredName": {
                            "firstName": "Misha",
                            "lastName": "Denil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Misha Denil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46234526"
                        ],
                        "name": "Alex Smola",
                        "slug": "Alex-Smola",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Smola",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Smola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779453"
                        ],
                        "name": "Le Song",
                        "slug": "Le-Song",
                        "structuredName": {
                            "firstName": "Le",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Le Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2124864085"
                        ],
                        "name": "Ziyu Wang",
                        "slug": "Ziyu-Wang",
                        "structuredName": {
                            "firstName": "Ziyu",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ziyu Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 37
                            }
                        ],
                        "text": "Layer-decomposition-based algorithms [13, 23] exploit matrix decomposition to reduce the number of operations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8132136,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "27a99c21a1324f087b2f144adc119f04137dfd87",
            "isKey": false,
            "numCitedBy": 232,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "The fully-connected layers of deep convolutional neural networks typically contain over 90% of the network parameters. Reducing the number of parameters while preserving predictive performance is critically important for training big models in distributed systems and for deployment in embedded devices. In this paper, we introduce a novel Adaptive Fastfood transform to reparameterize the matrix-vector multiplication of fully connected layers. Reparameterizing a fully connected layer with d inputs and n outputs with the Adaptive Fastfood transform reduces the storage and computational costs costs from O(nd) to O(n) and O(n log d) respectively. Using the Adaptive Fastfood transform in convolutional networks results in what we call a deep fried convnet. These convnets are end-to-end trainable, and enable us to attain substantial reductions in the number of parameters without affecting prediction accuracy on the MNIST and ImageNet datasets."
            },
            "slug": "Deep-Fried-Convnets-Yang-Moczulski",
            "title": {
                "fragments": [],
                "text": "Deep Fried Convnets"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A novel Adaptive Fastfood transform is introduced to reparameterize the matrix-vector multiplication of fully connected layers of deep convolutional neural networks, resulting in what is called a deep fried convnet."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE International Conference on Computer Vision (ICCV)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34838386"
                        ],
                        "name": "K. Simonyan",
                        "slug": "K.-Simonyan",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Simonyan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Simonyan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "4 even though MobileNets are more compact and much harder to simplify than the other larger networks, such as VGG [19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "We did not apply NetAdapt on larger networks like ResNet [7] and VGG [19] because networks become more difficult to simplify as they become smaller; these networks are also seldom deployed on mobile platforms."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14124313,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb42cf88027de515750f230b23b1a057dc782108",
            "isKey": false,
            "numCitedBy": 63195,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision."
            },
            "slug": "Very-Deep-Convolutional-Networks-for-Large-Scale-Simonyan-Zisserman",
            "title": {
                "fragments": [],
                "text": "Very Deep Convolutional Networks for Large-Scale Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This work investigates the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting using an architecture with very small convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153302678"
                        ],
                        "name": "Jia Deng",
                        "slug": "Jia-Deng",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144847596"
                        ],
                        "name": "Wei Dong",
                        "slug": "Wei-Dong",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Dong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Dong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2040091191"
                        ],
                        "name": "Li-Jia Li",
                        "slug": "Li-Jia-Li",
                        "structuredName": {
                            "firstName": "Li-Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "94451829"
                        ],
                        "name": "K. Li",
                        "slug": "K.-Li",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 164
                            }
                        ],
                        "text": "In this section, we apply the proposed NetAdapt algorithm to MobileNets [9, 18], which are designed for mobile applications, and experiment on the ImageNet dataset [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 57246310,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2c733e34d48784a37d717fe43d9e93277a8c53e",
            "isKey": false,
            "numCitedBy": 28266,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called \u201cImageNet\u201d, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond."
            },
            "slug": "ImageNet:-A-large-scale-hierarchical-image-database-Deng-Dong",
            "title": {
                "fragments": [],
                "text": "ImageNet: A large-scale hierarchical image database"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new database called \u201cImageNet\u201d is introduced, a large-scale ontology of images built upon the backbone of the WordNet structure, much larger in scale and diversity and much more accurate than the current image datasets."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3240893"
                        ],
                        "name": "Charles Audet",
                        "slug": "Charles-Audet",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Audet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles Audet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800149"
                        ],
                        "name": "J. Dennis",
                        "slug": "J.-Dennis",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Dennis",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dennis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 56
                            }
                        ],
                        "text": "Based on an idea similar to progressive barrier methods [1], NetAdapt breaks this problem into the following series of easier problems and solves it iteratively:"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14782397,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c002692649dcd1aa0df4f593b2312931ecc4e4e",
            "isKey": false,
            "numCitedBy": 188,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new constraint-handling approach for general constraints that is applicable to a widely used class of constrained derivative-free optimization methods. As in many methods that allow infeasible iterates, constraint violations are aggregated into a single constraint violation function. As in filter methods, a threshold, or barrier, is imposed on the constraint violation function, and any trial point whose constraint violation function value exceeds this threshold is discarded from consideration. In the new algorithm, unlike the filter method, the amount of constraint violation subject to the barrier is progressively decreased adaptively as the iteration evolves. We test this progressive barrier (PB) approach versus the extreme barrier (EB) with the generalized pattern search (Gps) and the lower triangular mesh adaptive direct search (LTMads) methods for nonlinear derivative-free optimization. Tests are also conducted using the Gps-filter, which uses a version of the Fletcher-Leyffer filter approach. We know that Gps cannot be shown to yield kkt points with this strategy or the filter, but we use the Clarke nonsmooth calculus to prove Clarke stationarity of the sequences of feasible and infeasible trial points for LTMads-PB. Numerical experiments are conducted on three academic test problems with up to 50 variables and on a chemical engineering problem. The new LTMads-PB method generally outperforms our LTMads-EB in the case where no feasible initial points are known, and it does as well when feasible points are known. which leads us to recommend LTMads-PB. Thus the LTMads-PB is a useful practical extension of our earlier LTMads-EB algorithm, particularly in the common case for real problems where no feasible point is known. The same conclusions hold for Gps-PB versus Gps-EB."
            },
            "slug": "A-Progressive-Barrier-for-Derivative-Free-Nonlinear-Audet-Dennis",
            "title": {
                "fragments": [],
                "text": "A Progressive Barrier for Derivative-Free Nonlinear Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The LTMads-PB is a useful practical extension of the earlier L TMads-EB algorithm, particularly in the common case for real problems where no feasible point is known, and it does as well when feasible points are known."
            },
            "venue": {
                "fragments": [],
                "text": "SIAM J. Optim."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759839"
                        ],
                        "name": "S. Solla",
                        "slug": "S.-Solla",
                        "structuredName": {
                            "firstName": "Sara",
                            "lastName": "Solla",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Solla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 0
                            }
                        ],
                        "text": "[6, 14, 16] aim to remove individual redundant weights from DNNs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7785881,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e7297db245c3feb1897720b173a59fe7e36babb7",
            "isKey": false,
            "numCitedBy": 3518,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We have used information-theoretic ideas to derive a class of practical and nearly optimal schemes for adapting the size of a neural network. By removing unimportant weights from a network, several improvements can be expected: better generalization, fewer training examples required, and improved speed of learning and/or classification. The basic idea is to use second-derivative information to make a tradeoff between network complexity and training set error. Experiments confirm the usefulness of the methods on a real-world application."
            },
            "slug": "Optimal-Brain-Damage-LeCun-Denker",
            "title": {
                "fragments": [],
                "text": "Optimal Brain Damage"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A class of practical and nearly optimal schemes for adapting the size of a neural network by using second-derivative information to make a tradeoff between network complexity and training set error is derived."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144882893"
                        ],
                        "name": "M. Sandler",
                        "slug": "M.-Sandler",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Sandler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sandler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144727050"
                        ],
                        "name": "Andrew G. Howard",
                        "slug": "Andrew-G.-Howard",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Howard",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew G. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2717876"
                        ],
                        "name": "Menglong Zhu",
                        "slug": "Menglong-Zhu",
                        "structuredName": {
                            "firstName": "Menglong",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Menglong Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3422677"
                        ],
                        "name": "A. Zhmoginov",
                        "slug": "A.-Zhmoginov",
                        "structuredName": {
                            "firstName": "Andrey",
                            "lastName": "Zhmoginov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zhmoginov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34192119"
                        ],
                        "name": "Liang-Chieh Chen",
                        "slug": "Liang-Chieh-Chen",
                        "structuredName": {
                            "firstName": "Liang-Chieh",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liang-Chieh Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 27
                            }
                        ],
                        "text": "Lastly, we adapt the large MobileNetV2 (100% MobileNetV2 (224)) to push the frontier of efficient networks."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 110
                            }
                        ],
                        "text": "The comparison between NetAdapt (adapting the large MobileNetV2 (100% MobileNetV2 (224))) and the multipliers [18] on a mobile CPU of Google Pixel 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 72
                            }
                        ],
                        "text": "In this section, we apply the proposed NetAdapt algorithm to MobileNets [9, 18], which are designed for mobile applications, and experiment on the ImageNet dataset [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 14
                            }
                        ],
                        "text": "4 even though MobileNets are more compact and much harder to simplify than the other larger networks, such as VGG [19]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 62
                            }
                        ],
                        "text": "Network Top-1 Accuracy (%) Latency (ms) 75% MobileNetV2 (224) [18] 69."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 11
                            }
                        ],
                        "text": "MobileNets [9, 18] and ShuffleNets [27] provide efficient layer operations and reference architecture design."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 49
                            }
                        ],
                        "text": "The main differences between the MobileNetV1 and MobileNetV2 experiment settings are that each network proposal is short-term fine-tuned with ten thousand iterations, the initial latency reduction is 1ms, the latency reduction decay is 0.995, the batch size is 96, and dropout and label smoothing are used."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 87
                            }
                        ],
                        "text": "In this section, we show encouraging early results of applying NetAdapt to MobileNetV2 [18]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 8
                            }
                        ],
                        "text": "Because MobileNetV2 utilizes residual connections, we only adapt individual inner (expansion) layers or reduce all bottleneck layers of the same resolution in lockstep."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 0
                            }
                        ],
                        "text": "MobileNetV2 introduces the inverted residual with linear bottleneck into MobileNetV1 and becomes more efficient."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 32
                            }
                        ],
                        "text": "For example, NetAdapt can adapt MobileNets to further push the frontier of efficient networks as shown in Sec."
                    },
                    "intents": []
                }
            ],
            "corpusId": 30879960,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "16b42f570873fc03d503090adb0a75a467c5f30c",
            "isKey": false,
            "numCitedBy": 609,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a new mobile architecture, MobileNetV2, that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes. We also describe efficient ways of applying these mobile models to object detection in a novel framework we call SSDLite. Additionally, we demonstrate how to build mobile semantic segmentation models through a reduced form of DeepLabv3 which we call Mobile DeepLabv3. \nThe MobileNetV2 architecture is based on an inverted residual structure where the input and output of the residual block are thin bottleneck layers opposite to traditional residual models which use expanded representations in the input an MobileNetV2 uses lightweight depthwise convolutions to filter features in the intermediate expansion layer. Additionally, we find that it is important to remove non-linearities in the narrow layers in order to maintain representational power. We demonstrate that this improves performance and provide an intuition that led to this design. Finally, our approach allows decoupling of the input/output domains from the expressiveness of the transformation, which provides a convenient framework for further analysis. We measure our performance on Imagenet classification, COCO object detection, VOC image segmentation. We evaluate the trade-offs between accuracy, and number of operations measured by multiply-adds (MAdd), as well as the number of parameters"
            },
            "slug": "Inverted-Residuals-and-Linear-Bottlenecks:-Mobile-Sandler-Howard",
            "title": {
                "fragments": [],
                "text": "Inverted Residuals and Linear Bottlenecks: Mobile Networks for Classification, Detection and Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "A new mobile architecture, MobileNetV2, that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes is described."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50579876"
                        ],
                        "name": "Yu-hsin Chen",
                        "slug": "Yu-hsin-Chen",
                        "structuredName": {
                            "firstName": "Yu-hsin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu-hsin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145984583"
                        ],
                        "name": "T. Krishna",
                        "slug": "T.-Krishna",
                        "structuredName": {
                            "firstName": "Tushar",
                            "lastName": "Krishna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Krishna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1775477"
                        ],
                        "name": "J. Emer",
                        "slug": "J.-Emer",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Emer",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Emer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691305"
                        ],
                        "name": "V. Sze",
                        "slug": "V.-Sze",
                        "structuredName": {
                            "firstName": "Vivienne",
                            "lastName": "Sze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Sze"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 185,
                                "start": 182
                            }
                        ],
                        "text": "However, this requires designing models to estimate the direct metrics of each target platform, which requires detailed knowledge of the platform including its hardware architecture [3], and the network-to-array mapping used in the toolchain [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207882941,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9d7c94996808770fa2ed9fbe2ab1cebea6866804",
            "isKey": false,
            "numCitedBy": 1227,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Eyeriss is an accelerator for state-of-the-art deep convolutional neural networks (CNNs). It optimizes for the energy efficiency of the entire system, including the accelerator chip and off-chip DRAM, for various CNN shapes by reconfiguring the architecture. CNNs are widely used in modern AI systems but also bring challenges on throughput and energy efficiency to the underlying hardware. This is because its computation requires a large amount of data, creating significant data movement from on-chip and off-chip that is more energy-consuming than computation. Minimizing data movement energy cost for any CNN shape, therefore, is the key to high throughput and energy efficiency. Eyeriss achieves these goals by using a proposed processing dataflow, called row stationary (RS), on a spatial architecture with 168 processing elements. RS dataflow reconfigures the computation mapping of a given shape, which optimizes energy efficiency by maximally reusing data locally to reduce expensive data movement, such as DRAM accesses. Compression and data gating are also applied to further improve energy efficiency. Eyeriss processes the convolutional layers at 35 frames/s and 0.0029 DRAM access/multiply and accumulation (MAC) for AlexNet at 278 mW (batch size  $N = 4$ ), and 0.7 frames/s and 0.0035 DRAM access/MAC for VGG-16 at 236 mW ( $N = 3$ )."
            },
            "slug": "Eyeriss:-An-Energy-Efficient-Reconfigurable-for-Chen-Krishna",
            "title": {
                "fragments": [],
                "text": "Eyeriss: An Energy-Efficient Reconfigurable Accelerator for Deep Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 99,
                "text": "Eyeriss is an accelerator for state-of-the-art deep convolutional neural networks (CNNs) that optimizes for the energy efficiency of the entire system, including the accelerator chip and off-chip DRAM, for various CNN shapes by reconfiguring the architecture."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Journal of Solid-State Circuits"
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": ", Vivienne : A Method to Estimate the Energy Consumption of Deep Neural Networks"
            },
            "venue": {
                "fragments": [],
                "text": "Asilomar Conference on Signals , Systems and Computers"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 14,
            "methodology": 12,
            "result": 4
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 31,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/NetAdapt:-Platform-Aware-Neural-Network-Adaptation-Yang-Howard/d16b21f3e99171c86365679435f9f03766750639?sort=total-citations"
}