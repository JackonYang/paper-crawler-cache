{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2582186"
                        ],
                        "name": "J. Azimi",
                        "slug": "J.-Azimi",
                        "structuredName": {
                            "firstName": "Javad",
                            "lastName": "Azimi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Azimi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145841336"
                        ],
                        "name": "Alan Fern",
                        "slug": "Alan-Fern",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Fern",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alan Fern"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694273"
                        ],
                        "name": "Xiaoli Z. Fern",
                        "slug": "Xiaoli-Z.-Fern",
                        "structuredName": {
                            "firstName": "Xiaoli",
                            "lastName": "Fern",
                            "middleNames": [
                                "Z."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoli Z. Fern"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 36
                            }
                        ],
                        "text": "Recent work [Garnett et al., 2010b, Azimi et al., 2011] has indicated very promising directions for this work to follow."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 481107,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5ab227a585ae98e168af4a01dbd00cf23849697b",
            "isKey": false,
            "numCitedBy": 97,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Bayesian optimization methods are often used to optimize unknown functions that are costly to evaluate. Typically, these methods sequentially select inputs to be evaluated one at a time based on a posterior over the unknown function that is updated after each evaluation. In many applications, however, it is desirable to perform multiple evaluations in parallel, which requires selecting batches of multiple inputs to evaluate at once. In this paper, we propose a novel approach to batch Bayesian optimization, providing a policy for selecting batches of inputs with the goal of optimizing the function as efficiently as possible. The key idea is to exploit the availability of high-quality and efficient sequential policies, by using Monte-Carlo simulation to select input batches that closely match their expected behavior. Our experimental results on six benchmarks show that the proposed approach significantly outperforms two baselines and can lead to large advantages over a top sequential approach in terms of performance per unit time."
            },
            "slug": "Batch-Bayesian-Optimization-via-Simulation-Matching-Azimi-Fern",
            "title": {
                "fragments": [],
                "text": "Batch Bayesian Optimization via Simulation Matching"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes a novel approach to batch Bayesian optimization, providing a policy for selecting batches of inputs with the goal of optimizing the function as efficiently as possible, by using Monte-Carlo simulation."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "28552618"
                        ],
                        "name": "M. Hoffman",
                        "slug": "M.-Hoffman",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hoffman",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hoffman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144180357"
                        ],
                        "name": "E. Brochu",
                        "slug": "E.-Brochu",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brochu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brochu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 174
                            }
                        ],
                        "text": "For convenience, we assume here that the prior mean is the zero func-\ntion m(x) = 0; alternative priors for the mean can be found in, for example [Martinez\u2013Cantin et al., 2009, Brochu et al., 2010a]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 116
                            }
                        ],
                        "text": "Methods of learning these values more efficiently is currently an active subfield of research (e.g. [Osborne, 2010, Brochu et al., 2010a])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 30
                            }
                        ],
                        "text": "The techniques introduced in [Brochu et al., 2010b] could also be applied to model selection, though that is outside the scope of this tutorial."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 4
                            }
                        ],
                        "text": "In [Brochu et al., 2010a], we discuss how model selection can be performed using models believed to be similar."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8053165,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa068e347fe8fcec0b5c6497a9d3c7790dc46f56",
            "isKey": false,
            "numCitedBy": 204,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "Bayesian optimization with Gaussian processes has become an increasingly popular tool in the machine learning community. It is efficient and can be used when very little is known about the objective function, making it popular in expensive black-box optimization scenarios. It uses Bayesian methods to sample the objective efficiently using an acquisition function which incorporates the model's estimate of the objective and the uncertainty at any given point. However, there are several different parameterized acquisition functions in the literature, and it is often unclear which one to use. Instead of using a single acquisition function, we adopt a portfolio of acquisition functions governed by an online multi-armed bandit strategy. We propose several portfolio strategies, the best of which we call GP-Hedge, and show that this method outperforms the best individual acquisition function. We also provide a theoretical bound on the algorithm's performance."
            },
            "slug": "Portfolio-Allocation-for-Bayesian-Optimization-Hoffman-Brochu",
            "title": {
                "fragments": [],
                "text": "Portfolio Allocation for Bayesian Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A portfolio of acquisition functions governed by an online multi-armed bandit strategy is proposed, the best of which is called GP-Hedge, and it is shown that this method outperforms the best individual acquisition function."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690162"
                        ],
                        "name": "D. Lizotte",
                        "slug": "D.-Lizotte",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lizotte",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lizotte"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 125,
                                "start": 110
                            }
                        ],
                        "text": "This is sometimes called \u201cone-step\u201d [Mo\u010dkus, 1994] \u201caverage-case\u201d [Streltsov and Vakili, 1999] or \u201cpractical\u201d [Lizotte, 2008] optimization."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 138
                            }
                        ],
                        "text": "Several researchers have studied the empirical impact of different values of \u03be in different domains [To\u0308rn and Z\u030cilinskas, 1989, Jones, 2001, Lizotte, 2008]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 105
                            }
                        ],
                        "text": "This is sometimes called \u201cone-step\u201d [Moc\u030ckus, 1994] \u201caverage-case\u201d [Streltsov and Vakili, 1999] or \u201cpractical\u201d [Lizotte, 2008] optimization."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 115
                            }
                        ],
                        "text": "Methods such as Monte Carlo and multistart have also been used, and seem to perform reasonably well [Moc\u030ckus, 1994, Lizotte, 2008]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 105
                            }
                        ],
                        "text": "This can often be aided with an informative hyperprior on the hyperparameters, often a log normal prior [Lizotte, 2008, Frean and Boyle, 2008]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 123325420,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "767256cacd1eeaaab0e1ecb158317389e0a9bf69",
            "isKey": true,
            "numCitedBy": 256,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Global optimization of non-convex functions over real vector spaces is a problem of widespread theoretical and practical interest. In the past fifty years, research in global optimization has produced many important approaches including Lipschitz optimization, simulated annealing, homotopy methods, genetic algorithms, and Bayesian response-surface methods. This work examines the last of these approaches. The Bayesian response-surface approach to global optimization maintains a posterior model of the function being optimized by combining a prior over functions with accumulating function evaluations. The model is then used to compute which point the method should acquire next in its search for the optimum of the function. Bayesian methods can be some of the most efficient approaches to optimization in terms of the number of function evaluations required, but they have significant drawbacks: Current approaches are needlessly data-inefficient, approximations to the Bayes-optimal acquisition criterion are poorly studied, and current approaches do not take advantage of the small-scale properties of differentiable functions near local optima. This work addresses each of these problems to make Bayesian methods more widely applicable."
            },
            "slug": "Practical-bayesian-optimization-Lizotte",
            "title": {
                "fragments": [],
                "text": "Practical bayesian optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work examines the last of the Bayesian response-surface approach to global optimization, which maintains a posterior model of the function being optimized by combining a prior over functions with accumulating function evaluations."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1405499515"
                        ],
                        "name": "Ruben Martinez-Cantin",
                        "slug": "Ruben-Martinez-Cantin",
                        "structuredName": {
                            "firstName": "Ruben",
                            "lastName": "Martinez-Cantin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruben Martinez-Cantin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144180357"
                        ],
                        "name": "E. Brochu",
                        "slug": "E.-Brochu",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brochu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brochu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145186838"
                        ],
                        "name": "J. A. Castellanos",
                        "slug": "J.-A.-Castellanos",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Castellanos",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. A. Castellanos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701800"
                        ],
                        "name": "A. Doucet",
                        "slug": "A.-Doucet",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Doucet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Doucet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15740223,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aa23b59a8dd663ee98af5fe18689022b05ba35a2",
            "isKey": false,
            "numCitedBy": 215,
            "numCiting": 67,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the problem of online path planning for optimal sensing with a mobile robot. The objective of the robot is to learn the most about its pose and the environment given time constraints. We use a POMDP with a utility function that depends on the belief state to model the finite horizon planning problem. We replan as the robot progresses throughout the environment. The POMDP is high-dimensional, continuous, non-differentiable, nonlinear, non-Gaussian and must be solved in real-time. Most existing techniques for stochastic planning and reinforcement learning are therefore inapplicable. To solve this extremely complex problem, we propose a Bayesian optimization method that dynamically trades off exploration (minimizing uncertainty in unknown parts of the policy space) and exploitation (capitalizing on the current best solution). We demonstrate our approach with a visually-guide mobile robot. The solution proposed here is also applicable to other closely-related domains, including active vision, sequential experimental design, dynamic sensing and calibration with mobile sensors."
            },
            "slug": "A-Bayesian-exploration-exploitation-approach-for-a-Martinez-Cantin-Freitas",
            "title": {
                "fragments": [],
                "text": "A Bayesian exploration-exploitation approach for optimal online sensing and planning with a visually guided mobile robot"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "A Bayesian optimization method that dynamically trades off exploration and exploitation for optimal sensing with a mobile robot and is applicable to other closely-related domains, including active vision, sequential experimental design, dynamic sensing and calibration with mobile sensors."
            },
            "venue": {
                "fragments": [],
                "text": "Auton. Robots"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49830188"
                        ],
                        "name": "S. Streltsov",
                        "slug": "S.-Streltsov",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Streltsov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Streltsov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2317992"
                        ],
                        "name": "P. Vakili",
                        "slug": "P.-Vakili",
                        "structuredName": {
                            "firstName": "Pirooz",
                            "lastName": "Vakili",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Vakili"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 203,
                                "start": 177
                            }
                        ],
                        "text": "Bayesian optimization techniques are some of the most efficient approaches in terms of the number of function evaluations required (see, e.g. [Moc\u030ckus, 1994, Jones et al., 1998, Streltsov and Vakili, 1999, Jones, 2001, Sasena, 2002])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 63
                            }
                        ],
                        "text": "This is sometimes called \u201cone-step\u201d [Moc\u030ckus, 1994] \u201caverage-case\u201d [Streltsov and Vakili, 1999] or \u201cpractical\u201d [Lizotte, 2008] optimization."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 94,
                                "start": 66
                            }
                        ],
                        "text": "This is sometimes called \u201cone-step\u201d [Mo\u010dkus, 1994] \u201caverage-case\u201d [Streltsov and Vakili, 1999] or \u201cpractical\u201d [Lizotte, 2008] optimization."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9975950,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6f61dc883ea944a2ebe70a90a4b1a980c10e8416",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "The high cost of providing \u201cworst-case\u201d solutions to global optimization problems has motivated the development of \u201daverage-case\u201c algorithms that rely on a statistical model of the objective function. The critical role of the statistical model is to guide the search for the optimum. The standard approach is to define a utility function u(x) that in a certain sense reflects the benefit of evaluating the function at x. A proper utility function needs to strike a balance between the immediate benefit of evaluating the function at x \u2013 a myopic consideration; and the overall effect of this choice on the performance of the algorithm \u2013 a global criterion. The utility functions currently used in this context are heuristically modified versions of some myopic utility functions. We propose using a new utility function that is provably a globally optimal utility function in a non-adaptive context (where the model of the function values remains unchanged). In the adaptive context, this utility function is not necessarily optimal, however, given its global nature, we expect that its use will lead to the improved performance of statistical global optimization algorithms. To illustrate the approach, and to test the above assertion, we apply this utility function to an existing adaptive multi-dimensional statistical global optimization algorithm and provide experimental comparisons with the original algorithm."
            },
            "slug": "A-Non-myopic-Utility-Function-for-Statistical-Streltsov-Vakili",
            "title": {
                "fragments": [],
                "text": "A Non-myopic Utility Function for Statistical Global Optimization Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work proposes using a new utility function that is provably a globally optimal utility function in a non-adaptive context (where the model of the function values remains unchanged) and expects that its use will lead to the improved performance of statistical global optimization algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "J. Glob. Optim."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144484861"
                        ],
                        "name": "Michael A. Osborne",
                        "slug": "Michael-A.-Osborne",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Osborne",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael A. Osborne"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 101
                            }
                        ],
                        "text": "Methods of learning these values more efficiently is currently an active subfield of research (e.g. [Osborne, 2010, Brochu et al., 2010a])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 38
                            }
                        ],
                        "text": "\u2022 The work of Osborne, Garnett et al. [Osborne, 2010, Osborne et al., 2010, Garnett et al., 2010b] uses Bayesian optimization to select the locations of a set of (possibly heterogenous) sensors in a dynamic system."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 119604728,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "74d6b7a3fda8ba7e9183ccbb8b697018b38864d7",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 109,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a family of Bayesian algorithms built around Gaussian processes for various problems posed by sensor networks. We firstly introduce an iterative Gaussian process for multi-sensor inference problems, and show how our algorithm is able to cope with data that may be noisy, missing, delayed and/or correlated. Our algorithm can also effectively manage data that features changepoints, such as sensor faults. Extensions to our algorithm allow us to tackle some of the decision problems faced in sensor networks, including observation scheduling. Along these lines, we also propose a general method of global optimisation, Gaussian process global optimisation (GPGO), and demonstrate how it may be used for sensor placement. Our algorithms operate within a complete Bayesian probabilistic framework. As such, we show how the hyperparameters of our system can be marginalised by use of Bayesian quadrature, a principled method of approximate integration. Similar techniques also allow us to produce full posterior distributions for any hyperparameters of interest, such as the location of changepoints. We frame the selection of the positions of the hyperparameter samples required by Bayesian quadrature as a decision problem, with the aim of minimising the uncertainty we possess about the values of the integrals we are approximating. Taking this approach, we have developed sampling for Bayesian quadrature (SBQ), a principled competitor to Monte Carlo methods. We conclude by testing our proposals on real weather sensor networks. We further benchmark GPGO on a wide range of canonical test problems, over which it achieves a significant improvement on its competitors. Finally, the efficacy of SBQ is demonstrated in the context of both prediction and optimisation."
            },
            "slug": "Bayesian-Gaussian-processes-for-sequential-and-Osborne",
            "title": {
                "fragments": [],
                "text": "Bayesian Gaussian processes for sequential prediction, optimisation and quadrature"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "A family of Bayesian algorithms built around Gaussian processes for various problems posed by sensor networks are developed, and sampling for Bayesian quadrature (SBQ) is developed, a principled competitor to Monte Carlo methods."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145974030"
                        ],
                        "name": "R. Garnett",
                        "slug": "R.-Garnett",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Garnett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Garnett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144484861"
                        ],
                        "name": "Michael A. Osborne",
                        "slug": "Michael-A.-Osborne",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Osborne",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael A. Osborne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145029236"
                        ],
                        "name": "S. Roberts",
                        "slug": "S.-Roberts",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Roberts",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roberts"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 169
                            }
                        ],
                        "text": "For example, it is possible to derive analytical expressions for the two-step ahead expected improvement [Ginsbourger et al., 2008] and multistep Bayesian optimization [Garnett et al., 2010b]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 75
                            }
                        ],
                        "text": "\u2022 The work of Osborne, Garnett et al. [Osborne, 2010, Osborne et al., 2010, Garnett et al., 2010b] uses Bayesian optimization to select the locations of a set of (possibly heterogenous) sensors in a dynamic system."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 13
                            }
                        ],
                        "text": "Recent work [Garnett et al., 2010b, Azimi et al., 2011] has indicated very promising directions for this work to follow."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 44
                            }
                        ],
                        "text": ", 2008] and multistep Bayesian optimization [Garnett et al., 2010b]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 251
                            }
                        ],
                        "text": "For example, the recent sequential sensor work of Osborne, Garnett and colleagues uses GP models with extensions to the covariance function to model the characteristics of changepoints [Osborne et al., 2010] and the locations of sensors in a network [Garnett et al., 2010a]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12351251,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "6fc4c7a500a90bb23dbd33d3020338ea3f707019",
            "isKey": true,
            "numCitedBy": 134,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of selecting an optimal set of sensors, as determined, for example, by the predictive accuracy of the resulting sensor network. Given an underlying metric between pairs of set elements, we introduce a natural metric between sets of sensors for this task. Using this metric, we can construct covariance functions over sets, and thereby perform Gaussian process inference over a function whose domain is a power set. If the function has additional inputs, our covariances can be readily extended to incorporate them---allowing us to consider, for example, functions over both sets and time. These functions can then be optimized using Gaussian process global optimization (GPGO). We use the root mean squared error (RMSE) of the predictions made using a set of sensors at a particular time as an example of such a function to be optimized; the optimal point specifies the best choice of sensor locations. We demonstrate the resulting method by dynamically selecting the best subset of a given set of weather sensors for the prediction of the air temperature across the United Kingdom."
            },
            "slug": "Bayesian-optimization-for-sensor-set-selection-Garnett-Osborne",
            "title": {
                "fragments": [],
                "text": "Bayesian optimization for sensor set selection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A natural metric is introduced between sets of sensors that can be used to construct covariance functions over sets, and thereby perform Gaussian process inference over a function whose domain is a power set."
            },
            "venue": {
                "fragments": [],
                "text": "IPSN '10"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145852650"
                        ],
                        "name": "D. Mackay",
                        "slug": "D.-Mackay",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Mackay",
                            "middleNames": [
                                "J.",
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Mackay"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 202
                            }
                        ],
                        "text": "Determining which of a set of possible kernel functions to use for a problem typically requires a combination of engineering and automatic model selection, either hierarchical Bayesian model selection [Mackay, 1992] or cross-validation."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16543854,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b959164d1efca4b73986ba5d21e664aadbbc0457",
            "isKey": false,
            "numCitedBy": 2608,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "A quantitative and practical Bayesian framework is described for learning of mappings in feedforward networks. The framework makes possible (1) objective comparisons between solutions using alternative network architectures, (2) objective stopping rules for network pruning or growing procedures, (3) objective choice of magnitude and type of weight decay terms or additive regularizers (for penalizing large weights, etc.), (4) a measure of the effective number of well-determined parameters in a model, (5) quantified estimates of the error bars on network parameters and on network output, and (6) objective comparisons with alternative learning and interpolation models such as splines and radial basis functions. The Bayesian \"evidence\" automatically embodies \"Occam's razor,\" penalizing overflexible and overcomplex models. The Bayesian approach helps detect poor underlying assumptions in learning models. For learning models well matched to a problem, a good correlation between generalization ability and the Bayesian evidence is obtained."
            },
            "slug": "A-Practical-Bayesian-Framework-for-Backpropagation-Mackay",
            "title": {
                "fragments": [],
                "text": "A Practical Bayesian Framework for Backpropagation Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A quantitative and practical Bayesian framework is described for learning of mappings in feedforward networks that automatically embodies \"Occam's razor,\" penalizing overflexible and overcomplex models."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1405499515"
                        ],
                        "name": "Ruben Martinez-Cantin",
                        "slug": "Ruben-Martinez-Cantin",
                        "structuredName": {
                            "firstName": "Ruben",
                            "lastName": "Martinez-Cantin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruben Martinez-Cantin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701800"
                        ],
                        "name": "A. Doucet",
                        "slug": "A.-Doucet",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Doucet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Doucet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145186838"
                        ],
                        "name": "J. A. Castellanos",
                        "slug": "J.-A.-Castellanos",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Castellanos",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. A. Castellanos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2077953,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45aa6a67ce508ccbe74b74f5d60acb626727e914",
            "isKey": false,
            "numCitedBy": 158,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a simulation-based active policy learning algorithm for finite-horizon, partially-observed sequential decision processes. The algorithm is tested in the domain of robot navigation and exploration under uncertainty. In such a setting, the expected cost, that must be minimized, is a function of the belief state (filtering distribution). This filtering distribution is in turn nonlinear and subject to discontinuities, which arise because constraints in the robot motion and control models. As a result, the expected cost is non-differentiable and very expensive to simulate. The new algorithm overcomes the first difficulty and reduces the number of required simulations as follows. First, it assumes that we have carried out previous simulations which returned values of the expected cost for different corresponding policy parameters. Second, it fits a Gaussian process (GP) regression model to these values, so as to approximate the expected cost as a function of the policy parameters. Third, it uses the GP predicted mean and variance to construct a statistical measure that determines which policy parameters should be used in the next simulation. The process is then repeated using the new parameters and the newly gathered expected cost observation. Since the objective is to find the policy parameters that minimize the expected cost, this iterative active learning approach effectively trades-off between exploration (in regions where the GP variance is large) and exploitation (where the GP mean is low). In our experiments, a robot uses the proposed algorithm to plan an optimal path for accomplishing a series of tasks, while maximizing the information about its pose and map estimates. These estimates are obtained with a standard filter for simultaneous localization and mapping. Upon gathering new observations, the robot updates the state estimates and is able to replan a new path in the spirit of open-loop feedback control."
            },
            "slug": "Active-Policy-Learning-for-Robot-Planning-and-under-Martinez-Cantin-Freitas",
            "title": {
                "fragments": [],
                "text": "Active Policy Learning for Robot Planning and Exploration under Uncertainty"
            },
            "tldr": {
                "abstractSimilarityScore": 81,
                "text": "A simulation-based active policy learning algorithm for finite-horizon, partially-observed sequential decision processes, tested in the domain of robot navigation and exploration under uncertainty, which effectively trades-off between exploration and exploitation."
            },
            "venue": {
                "fragments": [],
                "text": "Robotics: Science and Systems"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699645"
                        ],
                        "name": "R. Sutton",
                        "slug": "R.-Sutton",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Sutton",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sutton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730590"
                        ],
                        "name": "A. Barto",
                        "slug": "A.-Barto",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Barto",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barto"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 95
                            }
                        ],
                        "text": "It is the core idea in most reinforcement learning algorithms [Bertsekas and Tsitsiklis, 1996, Sutton and Barto, 1998], learning methods for Boltzmann machines and deep belief networks [Younes, 1989, Hinton and Salakhutdinov, 2006] and parameter estimation for nonlinear state space models\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9166388,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "97efafdb4a3942ab3efba53ded7413199f79c054",
            "isKey": false,
            "numCitedBy": 33129,
            "numCiting": 636,
            "paperAbstract": {
                "fragments": [],
                "text": "Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives when interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability. The book is divided into three parts. Part I defines the reinforcement learning problem in terms of Markov decision processes. Part II provides basic solution methods: dynamic programming, Monte Carlo methods, and temporal-difference learning. Part III presents a unified view of the solution methods and incorporates artificial neural networks, eligibility traces, and planning; the two final chapters present case studies and consider the future of reinforcement learning."
            },
            "slug": "Reinforcement-Learning:-An-Introduction-Sutton-Barto",
            "title": {
                "fragments": [],
                "text": "Reinforcement Learning: An Introduction"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This book provides a clear and simple account of the key ideas and algorithms of reinforcement learning, which ranges from the history of the field's intellectual foundations to the most recent developments and applications."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Neural Networks"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2221163"
                        ],
                        "name": "Vlad M. Cora",
                        "slug": "Vlad-M.-Cora",
                        "structuredName": {
                            "firstName": "Vlad",
                            "lastName": "Cora",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vlad M. Cora"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8896911,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc0fe8705f3cba3c44cfa022bb8cc65697afdf65",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Hierarchical task decompositions play an essential role in the design of complex simulation and decision systems, such as the ones that arise in video games. Game designers find it very natural to adopt a divide-and-conquer philosophy of specifying hierarchical policies, where decision modules can be constructed somewhat independently. The process of choosing the parameters of these modules manually is typically lengthy and tedious. The hierarchical reinforcement learning (HRL) field has produced elegant ways of decomposing policies and value functions using semi-Markov decision processes. However, there is still a lack of demonstrations in larger nonlinear systems with discrete and continuous variables. To narrow this gap between industrial practices and academic ideas, we address the problem of designing efficient algorithms to facilitate the deployment of HRL ideas in more realistic settings. In particular, we propose Bayesian active learning methods to learn the relevant aspects of either policies or value functions by focusing on the most relevant parts of the parameter and state spaces respectively. To demonstrate the scalability of our solution, we have applied it to The Open Racing Car Simulator (TORCS), a 3D game engine that implements complex vehicle dynamics. The environment is a large topological map roughly based on downtown Vancouver, British Columbia. Higher"
            },
            "slug": "Model-Based-Active-Learning-in-Hierarchical-Cora",
            "title": {
                "fragments": [],
                "text": "Model-Based Active Learning in Hierarchical Policies"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work addresses the problem of designing efficient algorithms to facilitate the deployment of HRL ideas in more realistic settings by proposing Bayesian active learning methods to learn the relevant aspects of either policies or value functions by focusing on the most relevant parts of the parameter and state spaces respectively."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144180357"
                        ],
                        "name": "E. Brochu",
                        "slug": "E.-Brochu",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brochu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brochu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2935553"
                        ],
                        "name": "Tyson Brochu",
                        "slug": "Tyson-Brochu",
                        "structuredName": {
                            "firstName": "Tyson",
                            "lastName": "Brochu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tyson Brochu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8788234,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "122c45495b725e1c999c4f2a65c3a380631262d5",
            "isKey": false,
            "numCitedBy": 129,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "The computer graphics and animation fields are filled with applications that require the setting of tricky parameters. In many cases, the models are complex and the parameters unintuitive for non-experts. In this paper, we present an optimization method for setting parameters of a procedural fluid animation system by showing the user examples of different parametrized animations and asking for feedback. Our method employs the Bayesian technique of bringing in \"prior\" belief based on previous runs of the system and/or expert knowledge, to assist users in finding good parameter settings in as few steps as possible. To do this, we introduce novel extensions to Bayesian optimization, which permit effective learning for parameter-based procedural animation applications. We show that even when users are trying to find a variety of different target animations, the system can learn and improve. We demonstrate the effectiveness of our method compared to related active learning methods. We also present a working application for assisting animators in the challenging task of designing curl-based velocity fields, even with minimal domain knowledge other than identifying when a simulation \"looks right\"."
            },
            "slug": "A-Bayesian-interactive-optimization-approach-to-Brochu-Brochu",
            "title": {
                "fragments": [],
                "text": "A Bayesian interactive optimization approach to procedural animation design"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This paper presents an optimization method for setting parameters of a procedural fluid animation system by showing the user examples of different parametrized animations and asking for feedback, and introduces novel extensions to Bayesian optimization, which permit effective learning for parameter-based procedural animation applications."
            },
            "venue": {
                "fragments": [],
                "text": "SCA '10"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144980509"
                        ],
                        "name": "D. Andre",
                        "slug": "D.-Andre",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Andre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Andre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145107462"
                        ],
                        "name": "Stuart J. Russell",
                        "slug": "Stuart-J.-Russell",
                        "structuredName": {
                            "firstName": "Stuart",
                            "lastName": "Russell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stuart J. Russell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 63
                            }
                        ],
                        "text": "Hierarchies of Abstract Machines (HAM) [Parr, 1998] and ALisp [Andre, 2003] are an exciting new development that has been recently applied to a Real-Time-Strategy (RTS) game [Marthi et al., 2005]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 82
                            }
                        ],
                        "text": "A hierarchically optimal policy (computed by the HAR [Ghavamzadeh, 2005] and HAM [Andre, 2003] three-part value decompositions) would pick the exit to minimize total travelling time, given the destination."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 62
                            }
                        ],
                        "text": "Hierarchies of Abstract Machines (HAM) [Parr, 1998] and ALisp [Andre, 2003] are an exciting new development that has been recently applied to a Real-Time-Strategy (RTS) game [Marthi et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 116
                            }
                        ],
                        "text": "Although\nthe formulation is very nice and would match game AI development processes, the underlying solver based on HAMs flattens the task hierarchy by including the program\u2019s memory and call-stack into a new joint-state space, and solves this new MDP instead."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 5,
                                "start": 0
                            }
                        ],
                        "text": "ALisp introduces programmable reinforcement learning policies that allows the programmer to specify choice points for the algorithm to optimize."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1115657,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b930f68e73fb06bd70d72e05781cf00d2781bd95",
            "isKey": true,
            "numCitedBy": 137,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This dissertation examines the use of partial programming as a means of designing agents for large Markov Decision Problems. In this approach, a programmer specifies only that which they know to be correct and the system then learns the rest from experience using reinforcement learning. \nIn contrast to previous low-level languages for partial programming, this dissertation presents ALisp, a Lisp-based high-level partial programming language. ALisp allows the programmer to constrain the policies considered by a learning process and to express his or her prior knowledge in a concise manner. Optimally completing a partial ALisp program is shown to be equivalent to solving a Semi-Markov Decision Problem (SMDP). Under a finite memory-use condition, online learning algorithms for ALisp are proved to converge to an optimal solution of the SMDP and thus to an optimal completion of the partial program. \nThis dissertation then presents methods for exploiting the modularity allows an agent to ignore aspects of its current state that are irrelevant to its current decision, and therefore speeds up reinforcement learning. By decomposing representations of the value of actions along subroutine boundaries, optimality, i.e., optimality among all policies consistent with the partial program. These methods are demonstrated on two simulated taxi tasks. \nFunction approximation, a method for representing the value of actions, allows reinforcement learning to be applied to problems where exact methods are intractable. Soft shaping is a method for guiding an agent toward a solution without constraining the search space. Both can be integrated with ALisp. ALisp with function approximation and reward shaping is successfully applied on a difficult continuous variant of the simulated taxi task. \nTogether, the methods presented in this work comprise a system for agent design that allows the programmer to specify what they know, hint at what they suspect using soft shaping, and leave unspecified that which they don't know; the system then optimally completes the program through experience and takes advantage of the hierarchical structure of the specified program to speed learning."
            },
            "slug": "Programmable-Reinforcement-Learning-Agents-Andre-Russell",
            "title": {
                "fragments": [],
                "text": "Programmable Reinforcement Learning Agents"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Together, the methods presented in this work comprise a system for agent design that allows the programmer to specify what they know, hint at what they suspect using soft shaping, and leave unspecified that which they don't know; the system then optimally completes the program through experience and takes advantage of the hierarchical structure of the specified program to speed learning."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2210196"
                        ],
                        "name": "J. Mockus",
                        "slug": "J.-Mockus",
                        "structuredName": {
                            "firstName": "Jonas",
                            "lastName": "Mockus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mockus"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 71
                            }
                        ],
                        "text": "This is a necessary condition for convergence under the assumptions of [Mo\u010dkus, 1994]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 72
                            }
                        ],
                        "text": "This is a necessary condition for convergence under the assumptions of [Moc\u030ckus, 1994]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 36
                            }
                        ],
                        "text": "This is sometimes called \u201cone-step\u201d [Mo\u010dkus, 1994] \u201caverage-case\u201d [Streltsov and Vakili, 1999] or \u201cpractical\u201d [Lizotte, 2008] optimization."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 44
                            }
                        ],
                        "text": "A more recent review of Mo\u010dkus\u2019 approach is [Mo\u010dkus, 1994]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 143
                            }
                        ],
                        "text": "Bayesian optimization techniques are some of the most efficient approaches in terms of the number of function evaluations required (see, e.g. [Moc\u030ckus, 1994, Jones et al., 1998, Streltsov and Vakili, 1999, Jones, 2001, Sasena, 2002])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 293,
                                "start": 281
                            }
                        ],
                        "text": "\u2026the risk (defined as the expected deviation from the global minimum at a fixed point x); and (ii) conditional variance converges to zero (or appropriate positive minimum value in the presence of noise) if and only if the distance to the nearest observation is zero [Moc\u030ckus, 1982, Moc\u030ckus, 1994]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 35
                            }
                        ],
                        "text": "This is sometimes called \u201cone-step\u201d [Moc\u030ckus, 1994] \u201caverage-case\u201d [Streltsov and Vakili, 1999] or \u201cpractical\u201d [Lizotte, 2008] optimization."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 101
                            }
                        ],
                        "text": "Methods such as Monte Carlo and multistart have also been used, and seem to perform reasonably well [Moc\u030ckus, 1994, Lizotte, 2008]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 44
                            }
                        ],
                        "text": "A more recent review of Moc\u030ckus\u2019 approach is [Moc\u030ckus, 1994]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 42695024,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82d51fac26b83f50ceb242b45fd6b1c88e94f867",
            "isKey": true,
            "numCitedBy": 277,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper a review of application of Bayesian approach to global and stochastic optimization of continuous multimodal functions is given. Advantages and disadvantages of Bayesian approach (average case analysis), comparing it with more usual minimax approach (worst case analysis) are discussed. New interactive version of software for global optimization is discussed. Practical multidimensional problems of global optimization are considered"
            },
            "slug": "Application-of-Bayesian-approach-to-numerical-of-Mockus",
            "title": {
                "fragments": [],
                "text": "Application of Bayesian approach to numerical methods of global and stochastic optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Advantages and disadvantages of Bayesian approach (average case analysis), comparing it with more usual minimax approach (worst case analysis) are discussed and new interactive version of software for global optimization is discussed."
            },
            "venue": {
                "fragments": [],
                "text": "J. Glob. Optim."
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678622"
                        ],
                        "name": "M. Ghavamzadeh",
                        "slug": "M.-Ghavamzadeh",
                        "structuredName": {
                            "firstName": "Mohammad",
                            "lastName": "Ghavamzadeh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ghavamzadeh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1850503"
                        ],
                        "name": "S. Mahadevan",
                        "slug": "S.-Mahadevan",
                        "structuredName": {
                            "firstName": "Sridhar",
                            "lastName": "Mahadevan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mahadevan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 54
                            }
                        ],
                        "text": "A hierarchically optimal policy (computed by the HAR [Ghavamzadeh, 2005] and HAM [Andre, 2003] three-part value decompositions) would pick the exit to minimize total travelling time, given the destination."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 44
                            }
                        ],
                        "text": "Recursive optimality, satisfied by MAXQ and RAR, means that each subtask is locally optimal, given the optimal policies of the descendants."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 54
                            }
                        ],
                        "text": "The other solutions investigated include HAR and RAR [Ghavamzadeh, 2005] which extend MAXQ to the case of average rewards (rather than discounted rewards)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 11
                            }
                        ],
                        "text": "Algorithms RAR and MAXQ are applied to all the tasks above and including Navigate, which also uses the Active Path learning algorithm from section 4.3.2."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 40
                            }
                        ],
                        "text": "We averaged the results from 10 runs of RAR, MAXQ, and the value learning Algorithm 3 applied only to the Navigate task (with the rest of the hierarchy using MAXQ)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 22
                            }
                        ],
                        "text": "The implementation of RAR is mostly the same as MAXQ, and in our experiments gave the same results."
                    },
                    "intents": []
                }
            ],
            "corpusId": 118121970,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "372e3e6ed730545b5760f8f9b072a3b1ffd9d0d6",
            "isKey": true,
            "numCitedBy": 10,
            "numCiting": 128,
            "paperAbstract": {
                "fragments": [],
                "text": "This dissertation investigates the use of hierarchy and abstraction as a means of solving complex sequential decision making problems such as those with continuous state and/or continuous action spaces, and domains with multiple cooperative agents. This thesis develops several novel extensions to hierarchical reinforcement learning (HRL), and designs algorithms that are appropriate for such problems. \nIt has been shown that the average reward optimality criterion is more natural than the more commonly used discounted criterion for continuing tasks. This thesis investigates two formulations of HRL based on the average reward semi-Markov decision process (SMDP) model, both for discrete-time and continuous-time. These formulations correspond to two notions of optimality that have been explored in previous work on HRL: hierarchical optimality and recursive optimality. Novel discrete-time and continuous-time algorithms, termed hierarchically optimal average reward RL (HAR) and recursively optimal average reward RL (RAR) are presented, which learn to find hierarchically and recursively optimal average reward policies. Two automated guided vehicle (AGV) scheduling problems are used as experimental testbeds to empirically study the performance of the proposed algorithms. \nPolicy gradient reinforcement learning (PGRL) methods have several advantages over the more traditional value function RL algorithms in solving problems with continuous state spaces. However, they suffer from slow convergence. This thesis defines a family of hierarchical policy gradient RL (HPGRL) algorithms for scaling PGRL methods to high-dimensional domains. \nThis thesis also examines the use of HRL to accelerate policy learning in cooperative multi-agent tasks. The use of hierarchy speeds up learning in multi-agent domains by making it possible to learn coordination skills at the level of subtasks instead of primitive actions. Subtask-level coordination allows for increased cooperation skills as agents do not get confused by low-level details. A framework for hierarchical multi-agent RL is developed and an algorithm called Cooperative HRL is presented that solves cooperative multi-agent problems more efficiently. (Abstract shortened by UMI.)"
            },
            "slug": "Hierarchical-reinforcement-learning-in-continuous-Ghavamzadeh-Mahadevan",
            "title": {
                "fragments": [],
                "text": "Hierarchical reinforcement learning in continuous state and multi-agent environments"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "This dissertation investigates the use of hierarchy and abstraction as a means of solving complex sequential decision making problems such as those with continuous state and/or continuous action spaces, and domains with multiple cooperative agents, and designs algorithms that are appropriate for such problems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144180357"
                        ],
                        "name": "E. Brochu",
                        "slug": "E.-Brochu",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brochu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brochu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32951485"
                        ],
                        "name": "A. Ghosh",
                        "slug": "A.-Ghosh",
                        "structuredName": {
                            "firstName": "Abhijeet",
                            "lastName": "Ghosh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ghosh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7062063,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "859d4b4b03cadff589164d71f97214a1c7b7b9b6",
            "isKey": false,
            "numCitedBy": 149,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an active learning algorithm that learns a continuous valuation model from discrete preferences. The algorithm automatically decides what items are best presented to an individual in order to find the item that they value highly in as few trials as possible, and exploits quirks of human psychology to minimize time and cognitive burden. To do this, our algorithm maximizes the expected improvement at each query without accurately modelling the entire valuation surface, which would be needlessly expensive. The problem is particularly difficult because the space of choices is infinite. We demonstrate the effectiveness of the new algorithm compared to related active learning methods. We also embed the algorithm within a decision making tool for assisting digital artists in rendering materials. The tool finds the best parameters while minimizing the number of queries."
            },
            "slug": "Active-Preference-Learning-with-Discrete-Choice-Brochu-Freitas",
            "title": {
                "fragments": [],
                "text": "Active Preference Learning with Discrete Choice Data"
            },
            "tldr": {
                "abstractSimilarityScore": 64,
                "text": "An active learning algorithm that learns a continuous valuation model from discrete preferences that maximizes the expected improvement at each query without accurately modelling the entire valuation surface, which would be needlessly expensive."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157110"
                        ],
                        "name": "Niranjan Srinivas",
                        "slug": "Niranjan-Srinivas",
                        "structuredName": {
                            "firstName": "Niranjan",
                            "lastName": "Srinivas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Niranjan Srinivas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145343838"
                        ],
                        "name": "Andreas Krause",
                        "slug": "Andreas-Krause",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Krause",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Krause"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144695232"
                        ],
                        "name": "S. Kakade",
                        "slug": "S.-Kakade",
                        "structuredName": {
                            "firstName": "Sham",
                            "lastName": "Kakade",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kakade"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1680574"
                        ],
                        "name": "M. Seeger",
                        "slug": "M.-Seeger",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Seeger",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Seeger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 54
                            }
                        ],
                        "text": "We refer the interested reader to the original paper [Srinivas et al., 2010]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 59031327,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c8413ab8de0c1b8f2e86402b8d737d94371610f",
            "isKey": false,
            "numCitedBy": 1656,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Many applications require optimizing an unknown, noisy function that is expensive to evaluate. We formalize this task as a multi-armed bandit problem, where the payoff function is either sampled from a Gaussian process (GP) or has low RKHS norm. We resolve the important open problem of deriving regret bounds for this setting, which imply novel convergence rates for GP optimization. We analyze GP-UCB, an intuitive upper-confidence based algorithm, and bound its cumulative regret in terms of maximal information gain, establishing a novel connection between GP optimization and experimental design. Moreover, by bounding the latter in terms of operator spectra, we obtain explicit sublinear regret bounds for many commonly used covariance functions. In some important cases, our bounds have surprisingly weak dependence on the dimensionality. In our experiments on real sensor data, GP-UCB compares favorably with other heuristical GP optimization approaches."
            },
            "slug": "Gaussian-Process-Optimization-in-the-Bandit-No-and-Srinivas-Krause",
            "title": {
                "fragments": [],
                "text": "Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work analyzes GP-UCB, an intuitive upper-confidence based algorithm, and bound its cumulative regret in terms of maximal information gain, establishing a novel connection between GP optimization and experimental design and obtaining explicit sublinear regret bounds for many commonly used covariance functions."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40073871"
                        ],
                        "name": "Marcus Frean",
                        "slug": "Marcus-Frean",
                        "structuredName": {
                            "firstName": "Marcus",
                            "lastName": "Frean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marcus Frean"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40132383"
                        ],
                        "name": "Phillip Boyle",
                        "slug": "Phillip-Boyle",
                        "structuredName": {
                            "firstName": "Phillip",
                            "lastName": "Boyle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Phillip Boyle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 120
                            }
                        ],
                        "text": "This can often be aided with an informative hyperprior on the hyperparameters, often a log normal prior [Lizotte, 2008, Frean and Boyle, 2008]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8265490,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1bb8263560f91b42fa19fc8383a74b74a049c028",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The task of finding the optimum of some function f (x) is commonly accomplished by generating and testing sample solutions iteratively, choosing each new sample x heuristically on the basis of results to date. We use Gaussian processes to represent predictions and uncertainty about the true function, and describe how to use these predictions to choose where to take each new sample in an optimal way. By doing this we were able to solve a difficult optimization problem - finding weights in a neural network controller to simultaneously balance two vertical poles - using an order of magnitude fewer samples than reported elsewhere."
            },
            "slug": "Using-Gaussian-Processes-to-Optimize-Expensive-Frean-Boyle",
            "title": {
                "fragments": [],
                "text": "Using Gaussian Processes to Optimize Expensive Functions"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Gaussian processes are used to represent predictions and uncertainty about the true function of a function to solve a difficult optimization problem - finding weights in a neural network controller to simultaneously balance two vertical poles - using an order of magnitude fewer samples than reported elsewhere."
            },
            "venue": {
                "fragments": [],
                "text": "Australasian Conference on Artificial Intelligence"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144299726"
                        ],
                        "name": "Thomas G. Dietterich",
                        "slug": "Thomas-G.-Dietterich",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Dietterich",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas G. Dietterich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 26
                            }
                        ],
                        "text": "The original taxi domain [Dietterich, 2000] is a 5x5 grid, with 4 possible pickup and dropoff destinations, and 6 actions (pickup, dropoff, and navigating North, South, East, West)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 39,
                                "start": 35
                            }
                        ],
                        "text": "Recursive optimality, satisfied by MAXQ and RAR, means that each subtask is locally optimal, given the optimal policies of the descendants."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 18
                            }
                        ],
                        "text": "A task i in MAXQ [Dietterich, 2000] is defined as a tuple: {Ai, Ti(s), Zi(s), \u03c0i(s)} where s is the current world state, Ai is a set of subtasks, Ti(s) \u2208 {true, false}\nis a termination predicate, Zi(s) is a state abstraction function that returns a subset of the state relevant to the current\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "The other solutions investigated include HAR and RAR [Ghavamzadeh, 2005] which extend MAXQ to the case of average rewards (rather than discounted rewards)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "Algorithms RAR and MAXQ are applied to all the tasks above and including Navigate, which also uses the Active Path learning algorithm from section 4.3.2."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 17
                            }
                        ],
                        "text": "A task i in MAXQ [Dietterich, 2000] is defined as a tuple: {Ai, Ti(s), Zi(s), \u03c0i(s)} where s is the current world state, Ai is a set of subtasks, Ti(s) \u2208 {true, false}"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "The MAXQ learning routine is a simple modification of the typical Q-learning algorithm."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "A task i in MAXQ [Dietterich, 2000] is defined as a tuple: {Ai, Ti(s), Zi(s), \u03c0i(s)} where s is the current world state, Ai is a set of subtasks, Ti(s) \u2208 {true, false}\nis a termination predicate, Zi(s) is a state abstraction function that returns a subset of the state relevant to the current subtask, and \u03c0i(s) \u2208 Ai is the policy learned by the agent (or used to explore during learning)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "We averaged the results from 10 runs of RAR, MAXQ, and the value learning Algorithm 3 applied only to the Navigate task (with the rest of the hierarchy using MAXQ)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 380,
                                "start": 376
                            }
                        ],
                        "text": "Although this task operates on a discrete set of waypoints, the underlying map coordinates are continuous, and we can again apply active exploration with GPs.\nUnlike the previous algorithm that searches for a set of optimal parameters, Algorithm 3 learns the value function at a finite set of states, by actively generating exploratory actions; it is designed to fit within a MAXQ task hierarchy."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "The implementation of RAR is mostly the same as MAXQ, and in our experiments gave the same results."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 41
                            }
                        ],
                        "text": "Out of the solutions investigated, MAXQ [Dietterich, 2000] met all our requirements, and was the easiest to understand and get positive results quickly."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "The MAXQ formulation gives a programmer or designer the ability to selectively enable hierarchical optimality by including the relevant state features as parameters to a task."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "We demonstrate an integration of the MAXQ hierarchical task learner with Bayesian active exploration that significantly speeds up the learning process, applied to hybrid discrete and continuous state and action spaces."
                    },
                    "intents": []
                }
            ],
            "corpusId": 57341,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c96ca25d889251e20e33d01f24eec175301ab94",
            "isKey": true,
            "numCitedBy": 1451,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new approach to hierarchical reinforcement learning based on decomposing the target Markov decision process (MDP) into a hierarchy of smaller MDPs and decomposing the value function of the target MDP into an additive combination of the value functions of the smaller MDPs. The decomposition, known as the MAXQ decomposition, has both a procedural semantics--as a subroutine hierarchy--and a declarative semantics--as a representation of the value function of a hierarchical policy. MAXQ unifies and extends previous work on hierarchical reinforcement learning by Singh, Kaelbling, and Dayan and Hinton. It is based on the assumption that the programmer can identify useful subgoals and define subtasks that achieve these subgoals. By defining such subgoals, the programmer constrains the set of policies that need to be considered during reinforcement learning. The MAXQ value function decomposition can represent the value function of any policy that is consistent with the given hierarchy. The decomposition also creates opportunities to exploit state abstractions, so that individual MDPs within the hierarchy can ignore large parts of the state space. This is important for the practical application of the method. This paper defines the MAXQ hierarchy, proves formal results on its representational power, and establishes five conditions for the safe use of state abstractions. The paper presents an online model-free learning algorithm, MAXQ-Q, and proves that it converges with probability 1 to a kind of locally-optimal policy known as a recursively optimal policy, even in the presence of the five kinds of state abstraction. The paper evaluates the MAXQ representation and MAXQ-Q through a series of experiments in three domains and shows experimentally that MAXQ-Q (with state abstractions) converges to a recursively optimal policy much faster than flat Q learning. The fact that MAXQ learns a representation of the value function has an important benefit: it makes it possible to compute and execute an improved, non-hierarchical policy via a procedure similar to the policy improvement step of policy iteration. The paper demonstrates the effectiveness of this nonhierarchical execution experimentally. Finally, the paper concludes with a comparison to related work and a discussion of the design tradeoffs in hierarchical reinforcement learning."
            },
            "slug": "Hierarchical-Reinforcement-Learning-with-the-MAXQ-Dietterich",
            "title": {
                "fragments": [],
                "text": "Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The paper presents an online model-free learning algorithm, MAXQ-Q, and proves that it converges with probability 1 to a kind of locally-optimal policy known as a recursively optimal policy, even in the presence of the five kinds of state abstraction."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145228938"
                        ],
                        "name": "W. Welch",
                        "slug": "W.-Welch",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Welch",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Welch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815604"
                        ],
                        "name": "M. Schonlau",
                        "slug": "M.-Schonlau",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Schonlau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schonlau"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 145
                            }
                        ],
                        "text": "It was published in a paper by Jones et al. [1998] as a refinement of the SPACE algorithm (Stochastic Process Analysis of Computer Experiments) [Schonlau, 1997]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 100
                            }
                        ],
                        "text": "[1998] as a refinement of the SPACE algorithm (Stochastic Process Analysis of Computer Experiments) [Schonlau, 1997]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 98
                            }
                        ],
                        "text": "Kriging has been applied to experimental design under the name DACE, after \u201cDesign and Analysis of Computer Experiments\u201d, the title of a paper by Sacks et al. [1989] (and more recently a book by Santner et al. [2003])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 60822138,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e89ecae12b44191809befa31404bbc91bec395df",
            "isKey": true,
            "numCitedBy": 410,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "A complex mathematical model that produces output values from input values is now commonly called a computer model. This thesis considers the problem of finding the global optimum of the response with few function evaluations. A small number of function evaluations is desirable since the computer model is often expensive (time consuming) to evaluate. \nThe function to be optimized is modeled as a stochastic process from initial function evaluations. Points are sampled sequentially according to a criterion that combines promising prediction values with prediction uncertainty. Some graphical tools are given that allow early assessment about whether the modeling strategy will work well. The approach is generalized by introducing a parameter that controls how global versus local the search strategy is. Strategies to conduct the optimization in stages and for optimization subject to constraints on additional response variables are presented. \nSpecial consideration is given to the stopping criterion of the global optimization algorithm. The problem of achieving a tolerance on the global minimum can be represented by determining whether the first order statistic of N dependent variables is greater than a certain value. An algorithm is developed that quickly determines bounds on the probability of this event. \nA strategy to explore high-dimensional data informally through effect plots is presented. The interpretation of the plots is guided by pointwise standard errors of the effects which are developed. When used in the context of global optimization, the graphical analysis sheds light on the number and location of local optima."
            },
            "slug": "Computer-experiments-and-global-optimization-Welch-Schonlau",
            "title": {
                "fragments": [],
                "text": "Computer experiments and global optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "This thesis considers the problem of finding the global optimum of the response with few function evaluations and presents strategies to conduct the optimization in stages and for optimization subject to constraints on additional response variables."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730590"
                        ],
                        "name": "A. Barto",
                        "slug": "A.-Barto",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Barto",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1850503"
                        ],
                        "name": "S. Mahadevan",
                        "slug": "S.-Mahadevan",
                        "structuredName": {
                            "firstName": "Sridhar",
                            "lastName": "Mahadevan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mahadevan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 39988136,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a28c4a55514bf6a8ddd536e2aeaa4fc6a31018c8",
            "isKey": false,
            "numCitedBy": 596,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Reinforcement learning is bedeviled by the curse of dimensionality: the number of parameters to be learned grows exponentially with the size of any compact encoding of a state. Recent attempts to combat the curse of dimensionality have turned to principled ways of exploiting temporal abstraction, where decisions are not required at each step, but rather invoke the execution of temporally-extended activities which follow their own policies until termination. This leads naturally to hierarchical control architectures and associated learning algorithms. We review several approaches to temporal abstraction and hierarchical organization that machine learning researchers have recently developed. Common to these approaches is a reliance on the theory of semi-Markov decision processes, which we emphasize in our review. We then discuss extensions of these ideas to concurrent activities, multiagent coordination, and hierarchical memory for addressing partial observability. Concluding remarks address open challenges facing the further development of reinforcement learning in a hierarchical setting."
            },
            "slug": "Recent-Advances-in-Hierarchical-Reinforcement-Barto-Mahadevan",
            "title": {
                "fragments": [],
                "text": "Recent Advances in Hierarchical Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work reviews several approaches to temporal abstraction and hierarchical organization that machine learning researchers have recently developed and discusses extensions of these ideas to concurrent activities, multiagent coordination, and hierarchical memory for addressing partial observability."
            },
            "venue": {
                "fragments": [],
                "text": "Discret. Event Dyn. Syst."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730590"
                        ],
                        "name": "A. Barto",
                        "slug": "A.-Barto",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Barto",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Barto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1850503"
                        ],
                        "name": "S. Mahadevan",
                        "slug": "S.-Mahadevan",
                        "structuredName": {
                            "firstName": "Sridhar",
                            "lastName": "Mahadevan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Mahadevan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 40
                            }
                        ],
                        "text": "The Hierarchical Reinforcement Learning [Barto and Mahadevan, 2003] field models repeated decision making by structuring the policy into tasks (actions) composed of subtasks that extend through time (temporal abstraction) and are specific to a subset of the total world state space (state abstraction)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 41
                            }
                        ],
                        "text": "The Hierarchical Reinforcement Learning [Barto and Mahadevan, 2003] field models repeated decision making by structuring the policy into tasks (actions) composed of subtasks that extend through time (temporal abstraction) and are specific to a subset of the total world state space (state\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 386824,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0a8149fb5aa8a5684e7d530c264451a5cb9250f5",
            "isKey": false,
            "numCitedBy": 918,
            "numCiting": 109,
            "paperAbstract": {
                "fragments": [],
                "text": "Reinforcement learning is bedeviled by the curse of dimensionality: the number of parameters to be learned grows exponentially with the size of any compact encoding of a state. Recent attempts to combat the curse of dimensionality have turned to principled ways of exploiting temporal abstraction, where decisions are not required at each step, but rather invoke the execution of temporally-extended activities which follow their own policies until termination. This leads naturally to hierarchical control architectures and associated learning algorithms. We review several approaches to temporal abstraction and hierarchical organization that machine learning researchers have recently developed. Common to these approaches is a reliance on the theory of semi-Markov decision processes, which we emphasize in our review. We then discuss extensions of these ideas to concurrent activities, multiagent coordination, and hierarchical memory for addressing partial observability. Concluding remarks address open challenges facing the further development of reinforcement learning in a hierarchical setting."
            },
            "slug": "Recent-Advances-in-Hierarchical-Reinforcement-Barto-Mahadevan",
            "title": {
                "fragments": [],
                "text": "Recent Advances in Hierarchical Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work reviews several approaches to temporal abstraction and hierarchical organization that machine learning researchers have recently developed and discusses extensions of these ideas to concurrent activities, multiagent coordination, and hierarchical memory for addressing partial observability."
            },
            "venue": {
                "fragments": [],
                "text": "Discret. Event Dyn. Syst."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1393588417"
                        ],
                        "name": "T. Bartz-Beielstein",
                        "slug": "T.-Bartz-Beielstein",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Bartz-Beielstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Bartz-Beielstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2278193"
                        ],
                        "name": "C. Lasarczyk",
                        "slug": "C.-Lasarczyk",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Lasarczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lasarczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1950379"
                        ],
                        "name": "M. Preuss",
                        "slug": "M.-Preuss",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Preuss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Preuss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 122
                            }
                        ],
                        "text": "It is also possible to resample potential incumbents to get more reliable estimates of the values in a noisy environment [Bartz-Beielstein et al., 2005, Huang et al., 2006, Hutter et al., 2009], a process sometimes called intensification."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 209
                            }
                        ],
                        "text": "\u2026has evolved a body of work devoted to extending the algorithm, particularly in adding constraints to the optimization problem [Audet et al., 2000, Sasena, 2002, Boyle, 2007], and in modelling noisy functions [Bartz-Beielstein et al., 2005, Huang et al., 2006, Hutter et al., 2009, Hutter, 2009]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6815175,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a99e54554731bda87e72024bb58da8c902d9800",
            "isKey": false,
            "numCitedBy": 325,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "Sequential parameter optimization is a heuristic that combines classical and modern statistical techniques to improve the performance of search algorithms. To demonstrate its flexibility, three scenarios are discussed: (1) no experience how to choose the parameter setting of an algorithm is available, (2) a comparison with other algorithms is needed, and (3) an optimization algorithm has to be applied effectively and efficiently to a complex real-world optimization problem. Although sequential parameter optimization relies on enhanced statistical techniques such as design and analysis of computer experiments, it can be performed algorithmically and requires basically the specification of the relevant algorithm's parameters"
            },
            "slug": "Sequential-parameter-optimization-Bartz-Beielstein-Lasarczyk",
            "title": {
                "fragments": [],
                "text": "Sequential parameter optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "Although sequential parameter optimization relies on enhanced statistical techniques such as design and analysis of computer experiments, it can be performed algorithmically and requires basically the specification of the relevant algorithm's parameters."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Congress on Evolutionary Computation"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49600153"
                        ],
                        "name": "M. Locatelli",
                        "slug": "M.-Locatelli",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Locatelli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Locatelli"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 89
                            }
                        ],
                        "text": "There exist several consistency proofs for this algorithm in the one-dimensional setting [Locatelli, 1997] and one for a simplification of the algorithm using simplicial partitioning in higher dimensions [\u017dilinskas and \u017dilinskas, 2002]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 90
                            }
                        ],
                        "text": "There exist several consistency proofs for this algorithm in the one-dimensional setting [Locatelli, 1997] and one for a simplification of the algorithm using simplicial partitioning in higher dimensions [Z\u030cilinskas and Z\u030cilinskas, 2002]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 35799038,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "b94597ae958ed215bf57035774759fa8e5d89156",
            "isKey": false,
            "numCitedBy": 122,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper Bayesian analysis and Wiener process are used in orderto build an algorithm to solve the problem of globaloptimization.The paper is divided in two main parts.In the first part an already known algorithm is considered: a new (Bayesian)stopping ruleis added to it and some results are given, such asan upper bound for the number of iterations under the new stopping rule.In the second part a new algorithm is introduced in which the Bayesianapproach is exploited not onlyin the choice of the Wiener model but also in the estimationof the parameter \u03c32 of the Wiener process, whose value appears to bequite crucial.Some results about this algorithm are also given."
            },
            "slug": "Bayesian-Algorithms-for-One-Dimensional-Global-Locatelli",
            "title": {
                "fragments": [],
                "text": "Bayesian Algorithms for One-Dimensional Global Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "In this paper Bayesian analysis and Wiener process are used in orderto build an algorithm to solve the problem of globaloptimization and the Bayesian approach is exploited not only in the choice of the Wiener model but also in the estimation of the parameter \u03c32 of theWiener process."
            },
            "venue": {
                "fragments": [],
                "text": "J. Glob. Optim."
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1707625"
                        ],
                        "name": "B. Sch\u00f6lkopf",
                        "slug": "B.-Sch\u00f6lkopf",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Sch\u00f6lkopf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Sch\u00f6lkopf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145039030"
                        ],
                        "name": "J. Platt",
                        "slug": "J.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Platt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153379696"
                        ],
                        "name": "T. Hofmann",
                        "slug": "T.-Hofmann",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Hofmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hofmann"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 126
                            }
                        ],
                        "text": "It has since been adopted to many other two-player games such as Go and Scrabble, and, more recently, online computer gaming [Herbrich and Graepel, 2006]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 63948832,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "52c1502bd99ae5112c36be6d097655c000600ce7",
            "isKey": false,
            "numCitedBy": 290,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new Bayesian skill rating system which can be viewed as a generalisation of the Elo system used in Chess. The new system tracks the uncertainty about player skills, explicitly models draws, can deal with any number of competing entities and can infer individual skills from team results. Inference is performed by approximate message passing on a factor graph representation of the model. We present experimental evidence on the increased accuracy and convergence speed of the system compared to Elo and report on our experience with the new rating system running in a large-scale commercial online gaming service under the name of TrueSkill."
            },
            "slug": "TrueSkill\u2122:-A-Bayesian-Skill-Rating-System-Sch\u00f6lkopf-Platt",
            "title": {
                "fragments": [],
                "text": "TrueSkill\u2122: A Bayesian Skill Rating System"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A new Bayesian skill rating system which can be viewed as a generalisation of the Elo system used in Chess, which tracks the uncertainty about player skills, explicitly models draws, can deal with any number of competing entities and can infer individual skills from team results."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057046890"
                        ],
                        "name": "Wei Chu",
                        "slug": "Wei-Chu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Chu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Chu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744700"
                        ],
                        "name": "Zoubin Ghahramani",
                        "slug": "Zoubin-Ghahramani",
                        "structuredName": {
                            "firstName": "Zoubin",
                            "lastName": "Ghahramani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zoubin Ghahramani"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 15
                            }
                        ],
                        "text": "1 are based on [Chu and Ghahramani, 2005b], which presents a preference learning method using probit models and Gaussian processes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 11
                            }
                        ],
                        "text": "Following [Chu and Ghahramani, 2005b], we assign a nonparametric Gaussian process prior to the unknown mean valuation: f(\u00b7) \u223c GP(0,K(\u00b7, \u00b7))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 27
                            }
                        ],
                        "text": "Parts of \u00a73.1 are based on [Chu and Ghahramani, 2005b], which presents a preference learning method using probit models and Gaussian processes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1115534,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "146e33f6ac7ee643af0a6a10f78a5273e6dfad86",
            "isKey": true,
            "numCitedBy": 308,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a probabilistic kernel approach to preference learning based on Gaussian processes. A new likelihood function is proposed to capture the preference relations in the Bayesian framework. The generalized formulation is also applicable to tackle many multiclass problems. The overall approach has the advantages of Bayesian methods for model selection and probabilistic prediction. Experimental results compared against the constraint classification approach on several benchmark datasets verify the usefulness of this algorithm."
            },
            "slug": "Preference-learning-with-Gaussian-processes-Chu-Ghahramani",
            "title": {
                "fragments": [],
                "text": "Preference learning with Gaussian processes"
            },
            "tldr": {
                "abstractSimilarityScore": 88,
                "text": "A probabilistic kernel approach to preference learning based on Gaussian processes and a new likelihood function is proposed to capture the preference relations in the Bayesian framework."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2424124"
                        ],
                        "name": "B. Stuckman",
                        "slug": "B.-Stuckman",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Stuckman",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Stuckman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 216
                            }
                        ],
                        "text": "Later work extended Kushner\u2019s technique to multidimensional optimization, using, for example, interpolation in a Delauney triangulation of the space [Elder, 1992] or projecting Wiener processes between sample points [Stuckman, 1988]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 31720281,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5b2c742a51e7d06ede251a2e7e82e37df1ecd59a",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "The theory and implementation of a global search method of optimization in n dimensions, inspired by Kushner's method in one dimension, are presented. This method is meant to address optimization problems where the function has many extrema, where it may or may not be differentiable, and where it is important to reduce the number of evaluations of the function at the expense of increased computation. Comparisons are made to the performance of other global optimization techniques on a set of standard differentiable test functions. A new class of discrete-valued test functions is introduced, and the performance of the method is determined on a randomly generated set of these functions. Overall, this method has the power of other Bayesian/sampling techniques without the need for a separate local optimization technique for improved convergence. This makes it possible for the search to operate on unknown functions that may contain one or more discrete components. >"
            },
            "slug": "A-global-search-method-for-optimizing-nonlinear-Stuckman",
            "title": {
                "fragments": [],
                "text": "A global search method for optimizing nonlinear systems"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "The theory and implementation of a global search method of optimization in n dimensions, inspired by Kushner's method in one dimension, are presented, which has the power of other Bayesian/sampling techniques without the need for a separate local optimization technique for improved convergence."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Syst. Man Cybern."
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3343244"
                        ],
                        "name": "D. Ginsbourger",
                        "slug": "D.-Ginsbourger",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ginsbourger",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ginsbourger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2480706"
                        ],
                        "name": "R. L. Riche",
                        "slug": "R.-L.-Riche",
                        "structuredName": {
                            "firstName": "Rodolphe",
                            "lastName": "Riche",
                            "middleNames": [
                                "Le"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. L. Riche"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153321911"
                        ],
                        "name": "L. Carraro",
                        "slug": "L.-Carraro",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Carraro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Carraro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 119691542,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c303bd0e5db703412511b7e423933384c373626e",
            "isKey": false,
            "numCitedBy": 83,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "The optimization of expensive-to-evaluate functions generally relies on metamodel-based exploration strategies. Many deterministic global optimization algorithms used in the field of computer experiments are based on Kriging (Gaussian process regression). Starting with a spatial predictor including a measure of uncertainty, they proceed by iteratively choosing the point maximizing a criterion which is a compromise between predicted performance and uncertainty. Distributing the evaluation of such numerically expensive objective functions on many processors is an appealing idea. Here we investigate a multi-points optimization criterion, the multipoints expected improvement (q-EI), aimed at choosing several points at the same time. An analytical expression of the q-EI is given when q = 2, and a consistent statistical estimate is given for the general case. We then propose two classes of heuristic strategies meant to approximately optimize the q-EI, and apply them to Gaussian Processes and to the classical Branin-Hoo test-case function. It is finally demonstrated within the covered example that the latter strategies perform as good as the best Latin Hypercubes and Uniform Designs ever found by simulation (2000 designs drawn at random for every q in [1, 10])."
            },
            "slug": "A-Multi-points-Criterion-for-Deterministic-Parallel-Ginsbourger-Riche",
            "title": {
                "fragments": [],
                "text": "A Multi-points Criterion for Deterministic Parallel Global Optimization based on Gaussian Processes"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work investigates a multi-points optimization criterion, the multipoints expected improvement (q-EI), aimed at choosing several points at the same time, and proposes two classes of heuristic strategies meant to approximately optimize the q- EI."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145726861"
                        ],
                        "name": "Ronald E. Parr",
                        "slug": "Ronald-E.-Parr",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Parr",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald E. Parr"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 116
                            }
                        ],
                        "text": "Although\nthe formulation is very nice and would match game AI development processes, the underlying solver based on HAMs flattens the task hierarchy by including the program\u2019s memory and call-stack into a new joint-state space, and solves this new MDP instead."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 40
                            }
                        ],
                        "text": "Hierarchies of Abstract Machines (HAM) [Parr, 1998] and ALisp [Andre, 2003] are an exciting new development that has been recently applied to a Real-Time-Strategy (RTS) game [Marthi et al., 2005]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 39
                            }
                        ],
                        "text": "Hierarchies of Abstract Machines (HAM) [Parr, 1998] and ALisp [Andre, 2003] are an exciting new development that has been recently applied to a Real-Time-Strategy (RTS) game [Marthi et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 77
                            }
                        ],
                        "text": "A hierarchically optimal policy (computed by the HAR [Ghavamzadeh, 2005] and HAM [Andre, 2003] three-part value decompositions) would pick the exit to minimize total travelling time, given the destination."
                    },
                    "intents": []
                }
            ],
            "corpusId": 53939299,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2966ae949d1bc255bad11045fd0ff8eb5848cf5a",
            "isKey": true,
            "numCitedBy": 269,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "This dissertation investigates the use of hierarchy and problem decomposition as a means of solving large, stochastic, sequential decision problems. These problems are framed as Markov decision problems (MDPs). The new technical content of this dissertation begins with a discussion of the concept of temporal abstraction. Temporal abstraction is shown to be equivalent to the transformation of a policy defined over a region of an MDP to an action in a semi-Markov decision problem (SMDP). Several algorithms are presented for performing this transformation efficiently. \nThis dissertation introduces the HAM for generating hierarchical, temporally abstract actions. This method permits the partial specification of abstract actions in a way that corresponds to an abstract plan or strategy. Abstract actions specified as HAMs can be optimally refined for new tasks by solving a reduced SMDP. The formal results show that traditional MDP algorithms can be used to optimally refine HAMs for new tasks. This can be achieved in much less time than it would take to learn a new policy for the task from scratch. \nHAMs complement some novel decomposition algorithms that are presented in this dissertation. These algorithms work by constructing a cache of policies for different regions of the MDP and then optimally combining the cached solution to produce a global solution that is within provable bounds of the optimal solution. \nTogether, the methods developed in this dissertation provide important tools for producing good policies for large MDPs. Unlike some ad-hoc methods, these methods provide strong formal guarantees. They use prior knowledge in a principled way, and they reduce larger MDPs into smaller ones while maintaining a well-defined relationship between the smaller problem and the larger problem."
            },
            "slug": "Hierarchical-control-and-learning-for-markov-Parr",
            "title": {
                "fragments": [],
                "text": "Hierarchical control and learning for markov decision processes"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This dissertation introduces the HAM for generating hierarchical, temporally abstract actions and shows that traditional MDP algorithms can be used to optimally refine HAMs for new tasks."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143732395"
                        ],
                        "name": "C. Holmes",
                        "slug": "C.-Holmes",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Holmes",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Holmes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144433364"
                        ],
                        "name": "L. Held",
                        "slug": "L.-Held",
                        "structuredName": {
                            "firstName": "Leonhard",
                            "lastName": "Held",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Held"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 88
                            }
                        ],
                        "text": "If the user had more than two choices one could adopt a polychotomous regression model [Holmes and Held, 2006]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8209006,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "bb0d201fa63d73cb19ce413b1a9a563bcae351c3",
            "isKey": false,
            "numCitedBy": 441,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we discuss auxiliary variable approaches to Bayesian binary and multinomial regression. These approaches are ideally suited to automated Markov chain Monte Carlo simulation. In the first part we describe a simple technique using joint updating that improves the performance of the conventional probit regression algorithm. In the second part we discuss auxiliary variable methods for inference in Bayesian logistic regression, including covariate set uncertainty. Finally, we show how the logistic method is easily extended to multinomial regression models. All of the algorithms are fully automatic with no user set parameters and no necessary Metropolis-Hastings accept/reject steps."
            },
            "slug": "Bayesian-auxiliary-variable-models-for-binary-and-Holmes-Held",
            "title": {
                "fragments": [],
                "text": "Bayesian auxiliary variable models for binary and multinomial regression"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A simple technique using joint updating that improves the performance of the conventional probit regression algorithm and is shown how the logistic method is easily extended to multinomial regression models."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690162"
                        ],
                        "name": "D. Lizotte",
                        "slug": "D.-Lizotte",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Lizotte",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lizotte"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2155450432"
                        ],
                        "name": "Tao Wang",
                        "slug": "Tao-Wang",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687780"
                        ],
                        "name": "Michael Bowling",
                        "slug": "Michael-Bowling",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bowling",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Bowling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714772"
                        ],
                        "name": "Dale Schuurmans",
                        "slug": "Dale-Schuurmans",
                        "structuredName": {
                            "firstName": "Dale",
                            "lastName": "Schuurmans",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dale Schuurmans"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10441616,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d89e23d3267c75db75e2055951facc2d74f2908b",
            "isKey": false,
            "numCitedBy": 274,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Gait optimization is a basic yet challenging problem for both quadrupedal and bipedal robots. Although techniques for automating the process exist, most involve local function optimization procedures that suffer from three key drawbacks. Local optimization techniques are naturally plagued by local optima, make no use of the expensive gait evaluations once a local step is taken, and do not explicitly model noise in gait evaluation. These drawbacks increase the need for a large number of gait evaluations, making optimization slow, data inefficient, and manually intensive. We present a Bayesian approach based on Gaussian process regression that addresses all three drawbacks. It uses a global search strategy based on a posterior model inferred from all of the individual noisy evaluations. We demonstrate the technique on a quadruped robot, using it to optimize two different criteria: speed and smoothness. We show in both cases our technique requires dramatically fewer gait evaluations than state-of-the-art local gradient approaches."
            },
            "slug": "Automatic-Gait-Optimization-with-Gaussian-Process-Lizotte-Wang",
            "title": {
                "fragments": [],
                "text": "Automatic Gait Optimization with Gaussian Process Regression"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A Bayesian approach based on Gaussian process regression that addresses all three drawbacks of local optimization procedures, using a global search strategy based on a posterior model inferred from all of the individual noisy evaluations."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118096690"
                        ],
                        "name": "Donald R. Jones",
                        "slug": "Donald-R.-Jones",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Jones",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donald R. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815604"
                        ],
                        "name": "M. Schonlau",
                        "slug": "M.-Schonlau",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Schonlau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schonlau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145228938"
                        ],
                        "name": "W. Welch",
                        "slug": "W.-Welch",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Welch",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Welch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 157
                            }
                        ],
                        "text": "Bayesian optimization techniques are some of the most efficient approaches in terms of the number of function evaluations required (see, e.g. [Moc\u030ckus, 1994, Jones et al., 1998, Streltsov and Vakili, 1999, Jones, 2001, Sasena, 2002])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 148
                            }
                        ],
                        "text": "\u2026+)\u2212 I)2 2\u03c32(x) ) d I\n= \u03c3(x)\n[ \u00b5(x)\u2212 f(x+)\n\u03c3(x) \u03a6\n( \u00b5(x)\u2212 f(x+)\n\u03c3(x)\n) + \u03c6 ( \u00b5(x)\u2212 f(x+)\n\u03c3(x) )] The expected improvement can be evaluated analytically [Moc\u030ckus et al., 1978,\nJones et al., 1998], yielding:\nEI(x) = { (\u00b5(x)\u2212 f(x+))\u03a6(Z) + \u03c3(x)\u03c6(Z) if \u03c3(x) > 0 0 if \u03c3(x) = 0\n(3)\nZ = \u00b5(x)\u2212\u2026"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 143
                            }
                        ],
                        "text": "Typically, the hyperparameter values are learned by \u201cseeding\u201d with a few random samples and maximizing the log-likelihood of the evidence given \u03b8 [Jones et al., 1998, Sasena, 2002, Santner et al., 2003, Rasmussen and Williams, 2006]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13068209,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "daa63f57c3fbe994c4356f8d986a22e696e776d2",
            "isKey": false,
            "numCitedBy": 5764,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "In many engineering optimization problems, the number of function evaluations is severely limited by time or cost. These problems pose a special challenge to the field of global optimization, since existing methods often require more function evaluations than can be comfortably afforded. One way to address this challenge is to fit response surfaces to data collected by evaluating the objective and constraint functions at a few points. These surfaces can then be used for visualization, tradeoff analysis, and optimization. In this paper, we introduce the reader to a response surface methodology that is especially good at modeling the nonlinear, multimodal functions that often occur in engineering. We then show how these approximating functions can be used to construct an efficient global optimization algorithm with a credible stopping rule. The key to using response surfaces for global optimization lies in balancing the need to exploit the approximating surface (by sampling where it is minimized) with the need to improve the approximation (by sampling where prediction error may be high). Striking this balance requires solving certain auxiliary problems which have previously been considered intractable, but we show how these computational obstacles can be overcome."
            },
            "slug": "Efficient-Global-Optimization-of-Expensive-Jones-Schonlau",
            "title": {
                "fragments": [],
                "text": "Efficient Global Optimization of Expensive Black-Box Functions"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper introduces the reader to a response surface methodology that is especially good at modeling the nonlinear, multimodal functions that often occur in engineering and shows how these approximating functions can be used to construct an efficient global optimization algorithm with a credible stopping rule."
            },
            "venue": {
                "fragments": [],
                "text": "J. Glob. Optim."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145974030"
                        ],
                        "name": "R. Garnett",
                        "slug": "R.-Garnett",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Garnett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Garnett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144484861"
                        ],
                        "name": "Michael A. Osborne",
                        "slug": "Michael-A.-Osborne",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Osborne",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael A. Osborne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145236972"
                        ],
                        "name": "S. Reece",
                        "slug": "S.-Reece",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Reece",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Reece"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145732981"
                        ],
                        "name": "A. Rogers",
                        "slug": "A.-Rogers",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Rogers",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rogers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145029236"
                        ],
                        "name": "S. Roberts",
                        "slug": "S.-Roberts",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Roberts",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roberts"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 50
                            }
                        ],
                        "text": ", 2010] and the locations of sensors in a network [Garnett et al., 2010a]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 169
                            }
                        ],
                        "text": "For example, it is possible to derive analytical expressions for the two-step ahead expected improvement [Ginsbourger et al., 2008] and multistep Bayesian optimization [Garnett et al., 2010b]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 75
                            }
                        ],
                        "text": "\u2022 The work of Osborne, Garnett et al. [Osborne, 2010, Osborne et al., 2010, Garnett et al., 2010b] uses Bayesian optimization to select the locations of a set of (possibly heterogenous) sensors in a dynamic system."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 13
                            }
                        ],
                        "text": "Recent work [Garnett et al., 2010b, Azimi et al., 2011] has indicated very promising directions for this work to follow."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 251
                            }
                        ],
                        "text": "For example, the recent sequential sensor work of Osborne, Garnett and colleagues uses GP models with extensions to the covariance function to model the characteristics of changepoints [Osborne et al., 2010] and the locations of sensors in a network [Garnett et al., 2010a]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52863369,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "37abfe7b8363f266bfde852003f03e88a27340ef",
            "isKey": true,
            "numCitedBy": 69,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new sequential algorithm for making robust predictions in the presence of changepoints. Unlike previous approaches, which focus on the problem of detecting and locating changepoints, our algorithm focuses on the problem of making predictions even when such changes might be present. We introduce nonstationary covariance functions to be used in Gaussian process prediction that model such changes, and then proceed to demonstrate how to effectively manage the hyperparameters associated with those covariance functions. We further introduce covariance functions to be used in situations where our observation model undergoes changes, as is the case for sensor faults. By using Bayesian quadrature, we can integrate out the hyperparameters, allowing us to calculate the full marginal predictive distribution. Furthermore, if desired, the posterior distribution over putative changepoint locations can be calculated as a natural byproduct of our prediction algorithm."
            },
            "slug": "Sequential-Bayesian-Prediction-in-the-Presence-of-Garnett-Osborne",
            "title": {
                "fragments": [],
                "text": "Sequential Bayesian Prediction in the Presence of Changepoints and Faults"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A new sequential algorithm for making robust predictions in the presence of changepoints, which focuses on the problem of making predictions even when such changes might be present, and introduces nonstationary covariance functions to be used in Gaussian process prediction that model such changes, and demonstrates how to effectively manage the hyperparameters associated with those covariance function."
            },
            "venue": {
                "fragments": [],
                "text": "Comput. J."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144272396"
                        ],
                        "name": "E. V\u00e1zquez",
                        "slug": "E.-V\u00e1zquez",
                        "structuredName": {
                            "firstName": "Emmanuel",
                            "lastName": "V\u00e1zquez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. V\u00e1zquez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691181"
                        ],
                        "name": "J. Bect",
                        "slug": "J.-Bect",
                        "structuredName": {
                            "firstName": "Julien",
                            "lastName": "Bect",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bect"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 105
                            }
                        ],
                        "text": "The convergence of the algorithm using multivariate Gaussian processes has been recently established in [Vasquez and Bect, 2008]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 63194191,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "57be1db2ca7bbe70cd3bc7353fab18743d2365f4",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper has been withdrawn from the arXiv. It is now published by Elsevier in the Journal of Statistical Planning and Inference, under the modified title \"Convergence properties of the expected improvement algorithm with fixed mean and covariance functions\". See this http URL An author-generated post-print version is available from the HAL repository of SUPELEC at this http URL Abstract : \"This paper deals with the convergence of the expected improvement algorithm, a popular global optimization algorithm based on a Gaussian process model of the function to be optimized. The first result is that under some mild hypotheses on the covariance function k of the Gaussian process, the expected improvement algorithm produces a dense sequence of evaluation points in the search domain, when the function to be optimized is in the reproducing kernel Hilbert space generated by k. The second result states that the density property also holds for P-almost all continuous functions, where P is the (prior) probability distribution induced by the Gaussian process.\""
            },
            "slug": "On-the-convergence-of-the-expected-improvement-V\u00e1zquez-Bect",
            "title": {
                "fragments": [],
                "text": "On the convergence of the expected improvement algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is shown that under some mild hypotheses on the covariance function k of the Gaussian process, the expected improvement algorithm produces a dense sequence of evaluation points in the search domain, when the function to be optimized is in the reproducing kernel Hilbert space generated by k."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711416"
                        ],
                        "name": "B. Marthi",
                        "slug": "B.-Marthi",
                        "structuredName": {
                            "firstName": "Bhaskara",
                            "lastName": "Marthi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Marthi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 99
                            }
                        ],
                        "text": "Even if this difficulty is surmounted, as evidenced by the last line in the concluding remarks of [Marthi et al., 2005], there is an imperative need for designing faster algorithms in HRL."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 175
                            }
                        ],
                        "text": "Hierarchies of Abstract Machines (HAM) [Parr, 1998] and ALisp [Andre, 2003] are an exciting new development that has been recently applied to a Real-Time-Strategy (RTS) game [Marthi et al., 2005]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 962364,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "165c7cc7c36112bb4215631c0270b5a8a5241dcd",
            "isKey": false,
            "numCitedBy": 105,
            "numCiting": 101,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider applying hierarchical reinforcement learning techniques to problems in which an agent has several effectors to control simultaneously. We argue that the kind of prior knowledge one typically has about such problems is best expressed using a multithreaded partial program, and present concurrent ALisp, a language for specifying such partial programs. We describe algorithms for learning and acting with concurrent ALisp that can be efficient even when there are exponentially many joint choices at each decision point. Finally, we show results of applying these methods to a complex computer game domain."
            },
            "slug": "Concurrent-Hierarchical-Reinforcement-Learning-Marthi",
            "title": {
                "fragments": [],
                "text": "Concurrent Hierarchical Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "It is argued that the kind of prior knowledge one typically has about such problems is best expressed using a multithreaded partial program, and concurrent ALisp, a language for specifying such partial programs is presented."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144272396"
                        ],
                        "name": "E. V\u00e1zquez",
                        "slug": "E.-V\u00e1zquez",
                        "structuredName": {
                            "firstName": "Emmanuel",
                            "lastName": "V\u00e1zquez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. V\u00e1zquez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691181"
                        ],
                        "name": "J. Bect",
                        "slug": "J.-Bect",
                        "structuredName": {
                            "firstName": "Julien",
                            "lastName": "Bect",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bect"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 88511936,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c469d247c2845670a098c03f1a4edf66e27f96b",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper has been withdrawn from the arXiv. It is now published by Elsevier in the Journal of Statistical Planning and Inference, under the modified title \"Convergence properties of the expected improvement algorithm with fixed mean and covariance functions\". See this http URL \nAn author-generated post-print version is available from the HAL repository of SUPELEC at this http URL \nAbstract : \"This paper deals with the convergence of the expected improvement algorithm, a popular global optimization algorithm based on a Gaussian process model of the function to be optimized. The first result is that under some mild hypotheses on the covariance function k of the Gaussian process, the expected improvement algorithm produces a dense sequence of evaluation points in the search domain, when the function to be optimized is in the reproducing kernel Hilbert space generated by k. The second result states that the density property also holds for P-almost all continuous functions, where P is the (prior) probability distribution induced by the Gaussian process.\""
            },
            "slug": "Convergence-properties-of-the-expected-improvement-V\u00e1zquez-Bect",
            "title": {
                "fragments": [],
                "text": "Convergence properties of the expected improvement algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is shown that under some mild hypotheses on the covariance function k of the Gaussian process, the expected improvement algorithm produces a dense sequence of evaluation points in the search domain, when the function to be optimized is in the reproducing kernel Hilbert space generated by k."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1452854346"
                        ],
                        "name": "Roderick Murray-Smith",
                        "slug": "Roderick-Murray-Smith",
                        "structuredName": {
                            "firstName": "Roderick",
                            "lastName": "Murray-Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Roderick Murray-Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38387373"
                        ],
                        "name": "A. Girard",
                        "slug": "A.-Girard",
                        "structuredName": {
                            "firstName": "Agathe",
                            "lastName": "Girard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Girard"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13752731,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d87563c1ab5227451ca3225f705d7d1df04ef0f1",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We extend the standard covariance function used in the Gaussian Process prior nonparametric modelling approach to include correlated (ARMA) noise models. The improvement in performance is illustrated on some simulation examples of data generated by nonlinear static functions corrupted with additive ARMA noise. 1 Gaussian Process priors In recent years many flexible parametric and semi-parametric approaches to empirical identification of nonlinear systems have been used. In this paper we use nonparametric models which retain the available data and perform inference conditional on the current state and local data (called \u2018smoothing\u2019 in some frameworks). This direct use of the data has potential advantages in many control contexts. The uncertainty of model predictions can be made dependent on local data density, and the model complexity is automatically related to the amount of available data (more complex models need more evidence to make them likely). The nonparametric model used in this paper is a Gaussian Process prior, as developed by O\u2019Hagan [1] and reviewed in [2, 3]. An application to modelling a system within a control context is described in [4], and further developments relating to their use in gain scheduling are described in [5]. Most previous published work has focused on regression tasks with independent identically distributed noise characteristics. Input-dependent noise is described in [6], but we are not aware of previous work with coloured noise covariance functions in Gaussian Process priors. This paper shows how knowledge about correlation structure of additive unmeasured noise or disturbances can be incorporated into the model. This improves the performance of the model in finding optimal parameters for describing the deterministic aspects of the system, and can be used to make online prediction more accurately. We expect this will make the use of Gaussian Process priors more attractive for use in control and signal processing contexts. 2 Modelling with GPs We assume that we are modelling an unknown nonlinear system f(x), with known inputs x, using observed outputs y. These have been corrupted by an additive discrete-time process (t). Here we assume that f(xi) and i are independent. Let y = [y1; : : : ; yN \u2104T , a set of observed data or targets be such that yi = f(xi) + i ; i = 1; : : : n (1) 2.1 The Gaussian Process prior approach A prior is placed directly on the space of functions for modelling the above system. We assume that the values of the function f(x) at inputs x1; : : : ; xn, outputs y1; : : : ; yn, constitute a set of random variables which we assume will have a joint n-dimensional multivariate Normal distribution. The Gaussian Process is then fully specified by its mean and covariance function C(xi; xj). We note (y1; : : : ; yn)T N (0; ); (2) where is the covariance matrix whose entries ij are given by C(xi; xj). We now have a prior distribution for the target values which is a multivariate Normal: p(yjx) = (2 ) n2 j j 1 2 exp 12yT 1y ; (3) 1See a standard text such as [7] for a discussion of disturbance models in the linear system identification context. 2In what follows, we assume a zero mean process."
            },
            "slug": "Gaussian-process-priors-with-ARMA-noise-models-Murray-Smith-Girard",
            "title": {
                "fragments": [],
                "text": "Gaussian process priors with ARMA noise models"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 40
                            }
                        ],
                        "text": "When carrying out direct policy search [Ng and Jordan, 2000], the Bayesian optimization approach has several advantages over the policy gradients method [Baxter and Bartlett, 2001]: it is derivative free, it is less prone to be caught in\nthe first local minimum, and it is explicitly designed to\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 39
                            }
                        ],
                        "text": "When carrying out direct policy search [Ng and Jordan, 2000], the Bayesian optimization approach has several advantages over the policy gradients method [Baxter and Bartlett, 2001]: it is derivative free, it is less prone to be caught in"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11691568,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d51fe3976ab4f4dc60745433c8638a2ecc3bf123",
            "isKey": false,
            "numCitedBy": 485,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new approach to the problem of searching a space of policies for a Markov decision process (MDP) or a partially observable Markov decision process (POMDP), given a model. Our approach is based on the following observation: Any (PO)MDP can be transformed into an \"equivalent\" POMDP in which all state transitions (given the current state and action) are deterministic. This reduces the general problem of policy search to one in which we need only consider POMDPs with deterministic transitions. We give a natural way of estimating the value of all policies in these transformed POMDPs. Policy search is then simply performed by searching for a policy with high estimated value. We also establish conditions under which our value estimates will be good, recovering theoretical results similar to those of Kearns, Mansour and Ng [7], but with \"sample complexity\" bounds that have only a polynomial rather than exponential dependence on the horizon time. Our method applies to arbitrary POMDPs, including ones with infinite state and action spaces. We also present empirical results for our approach on a small discrete problem, and on a complex continuous state/continuous action problem involving learning to ride a bicycle."
            },
            "slug": "PEGASUS:-A-policy-search-method-for-large-MDPs-and-Ng-Jordan",
            "title": {
                "fragments": [],
                "text": "PEGASUS: A policy search method for large MDPs and POMDPs"
            },
            "tldr": {
                "abstractSimilarityScore": 92,
                "text": "This work proposes a new approach to the problem of searching a space of policies for a Markov decision process (MDP) or a partially observable Markov decisions process (POMDP), given a model, based on the following observation: Any (PO)MDP can be transformed into an \"equivalent\" POMDP in which all state transitions are deterministic."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107327555"
                        ],
                        "name": "D. Huang",
                        "slug": "D.-Huang",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "115429409"
                        ],
                        "name": "T. Allen",
                        "slug": "T.-Allen",
                        "structuredName": {
                            "firstName": "Theodore",
                            "lastName": "Allen",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Allen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50238440"
                        ],
                        "name": "W. Notz",
                        "slug": "W.-Notz",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Notz",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Notz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065868465"
                        ],
                        "name": "N. Zheng",
                        "slug": "N.-Zheng",
                        "structuredName": {
                            "firstName": "Ning",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Zheng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14688276,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c51104c58c3e05f487d87ee94ce2e3b2d11dce6",
            "isKey": false,
            "numCitedBy": 584,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new method that extends the efficient global optimization to address stochastic black-box systems. The method is based on a kriging meta-model that provides a global prediction of the objective values and a measure of prediction uncertainty at every point. The criterion for the infill sample selection is an augmented expected improvement function with desirable properties for stochastic responses. The method is empirically compared with the revised simplex search, the simultaneous perturbation stochastic approximation, and the DIRECT methods using six test problems from the literature. An application case study on an inventory system is also documented. The results suggest that the proposed method has excellent consistency and efficiency in finding global optimal solutions, and is particularly useful for expensive systems."
            },
            "slug": "Global-Optimization-of-Stochastic-Black-Box-Systems-Huang-Allen",
            "title": {
                "fragments": [],
                "text": "Global Optimization of Stochastic Black-Box Systems via Sequential Kriging Meta-Models"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "The proposed method is based on a kriging meta-model that provides a global prediction of the objective values and a measure of prediction uncertainty at every point and has excellent consistency and efficiency in finding global optimal solutions."
            },
            "venue": {
                "fragments": [],
                "text": "J. Glob. Optim."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3234984"
                        ],
                        "name": "R. Herbrich",
                        "slug": "R.-Herbrich",
                        "structuredName": {
                            "firstName": "Ralf",
                            "lastName": "Herbrich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Herbrich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52626911"
                        ],
                        "name": "T. Minka",
                        "slug": "T.-Minka",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Minka",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Minka"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686971"
                        ],
                        "name": "T. Graepel",
                        "slug": "T.-Graepel",
                        "structuredName": {
                            "firstName": "Thore",
                            "lastName": "Graepel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Graepel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9744799,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6a1decd5e8507a845e77a43969d11592d9aa496f",
            "isKey": false,
            "numCitedBy": 616,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new Bayesian skill rating system which can be viewed as a generalisation of the Elo system used in Chess. The new system tracks the uncertainty about player skills, explicitly models draws, can deal with any number of competing entities and can infer individual skills from team results. Inference is performed by approximate message passing on a factor graph representation of the model. We present experimental evidence on the increased accuracy and convergence speed of the system compared to Elo and report on our experience with the new rating system running in a large-scale commercial online gaming service under the name of TrueSkill."
            },
            "slug": "TrueSkillTM:-A-Bayesian-Skill-Rating-System-Herbrich-Minka",
            "title": {
                "fragments": [],
                "text": "TrueSkillTM: A Bayesian Skill Rating System"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A new Bayesian skill rating system which can be viewed as a generalisation of the Elo system used in Chess, which tracks the uncertainty about player skills, explicitly models draws, can deal with any number of competing entities and can infer individual skills from team results."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "25042677"
                        ],
                        "name": "A. Zhigljavsky",
                        "slug": "A.-Zhigljavsky",
                        "structuredName": {
                            "firstName": "Anatoly",
                            "lastName": "Zhigljavsky",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zhigljavsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 225,
                                "start": 194
                            }
                        ],
                        "text": "A number of approaches exist for this kind of global optimization and have been well-studied in the literature (e.g., [To\u0308rn and Z\u030cilinskas, 1989, Mongeau et al., 1998, Liberti and Maculan, 2006, Zhigljavsky and Z\u030cilinskas, 2008])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 38904001,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "ccd86f5f2ed408c6f7bd5f2e98e5a46bcd0b9050",
            "isKey": false,
            "numCitedBy": 196,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Stochastic global optimization methods are methods for solving a global optimization problem incorporating probabilistic (stochastic) elements, either in the problem data (the objective function, the constraints, etc.), or in the algorithm itself, or in both. Global optimization is a very important part of applied mathematics and computer science. The importance of global optimization is primarily related to the applied areas such as engineering, computational chemistry, finance and medicine amongst many other fields. For the state of the art in the theory and methodology of global optimization we refer to the \u2018Journal of Global Optimization\u2019 and two volumes of the \u2018Handbook of Global Optimization\u2019 [1,2]. If the objective function is given as a \u2018black box\u2019 computer code, the optimization problem is especially difficult. Stochastic approaches can often deal with problems of this kind much easier and more efficiently than the deterministic algorithms. The problem of global minimization. Consider a general minimization problem f(x)\u2192minx\u2208X with objective function f(\u00b7) and feasible region X. Let x\u2217 be a global minimizer of f(\u00b7); that is, x\u2217 is a point in X such that f(x\u2217) = f\u2217 where f\u2217 = minx\u2208Xf(x). Global optimization problems are usually formulated so that the structure of the feasible region X is relatively simple; this can be done on the expense of increased complexity of the objective function. A global minimization algorithm is a rule for constructing a sequence of points x1, x2, . . . in X such that the sequence of record values yon = mini=1...n f(xi) approaches the minimum f\u2217 as n increases. In addition to approximating the minimal value f\u2217, one often needs to approximate at least one of the minimizers x\u2217. Heuristics. Many stochastic optimization algorithms where randomness is involved have been proposed heuristically. Some of these algorithms are based on analogies with natural processes; the well-known examples are evolutionary algorithms [3] and simulated annealing [4]. Heuristic global optimization algorithms are very popular in applications, especially in discrete optimization problems. Unfortunately, there is a large gap between practical efficiency of stochastic global optimization algorithms and their theoretical rigor. Stochastic assumptions about the objective function. In deterministic global optimization, Lipschitz-type conditions on the objective function are heavily exploited. Much research have been done in stochastic global optimization where stochastic assumptions about the objective function are used in a manner similar to how the Lipschitz condition is used in deterministic algorithms. A typical example of a stochastic assumption of this kind is the postulation that f(\u00b7) is a realization of a certain stochastic process. This part of stochastic optimization is well described in [5], Chapter 4 and will not be pursued in this article. Global random search (GRS). The main research in stochastic global optimization deals with the so-called \u2018global random search\u2019 (GRS) algorithms which involve random decisions in the process of choosing the observation points. A general GRS algorithm assumes that a sequence of random points x1, x2, . . . , xn is generated where for each j > 1 the point xj has some probability distribution Pj. For each j > 2, the distribution Pj may depend on the previous points x1, . . . , xj\u22121 and on the results of the objective function evaluations at these points (the function evaluations may not be noise-free). The number of points n, 1 6 n \u2264 \u221e (the stopping rule) can be either deterministic or random and may depend on the results of function evaluation at the points x1, . . . , xn."
            },
            "slug": "Stochastic-Global-Optimization-Zhigljavsky",
            "title": {
                "fragments": [],
                "text": "Stochastic Global Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Stochastic global optimization methods are methods for solving a global optimization problem incorporating probabilistic (stochastic) elements, either in the problem data (the objective function, the constraints, etc.), or in the algorithm itself, or in both."
            },
            "venue": {
                "fragments": [],
                "text": "International Encyclopedia of Statistical Science"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3472959"
                        ],
                        "name": "C. Rasmussen",
                        "slug": "C.-Rasmussen",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Rasmussen",
                            "middleNames": [
                                "Edward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rasmussen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 93
                            }
                        ],
                        "text": "The simplest transformation arises when f(x) is corrupted with Gaussian noise \u223c N (0, \u03c32noise) [Rasmussen and Williams, 2006]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 174,
                                "start": 146
                            }
                        ],
                        "text": "\u2026ft+1\n] \u223c N ( 0, [ K k kT k(xt+1,xt+1) ]) ,\nwhere k = [ k(xt+1,x1) k(xt+1,x2) \u00b7 \u00b7 \u00b7 k(xt+1,xt) ] Using the Sherman-Morrison-Woodbury formula (see, e.g., [Rasmussen and Williams, 2006, Press et al., 2007]), one can easily arrive at an expression for the predictive distribution:\nP\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 179
                            }
                        ],
                        "text": "While the squared exponential and Mate\u0301rn are the most common kernels for GPs, numerous others have been examined in the machine learning literature (see, e.g., [Genton, 2001] or [Rasmussen and Williams, 2006, Chapter 4] for an overview)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 98
                            }
                        ],
                        "text": "The simplest transformation arises when f(x) is corrupted with Gaussian noise \u223c N (0, \u03c3(2) noise) [Rasmussen and Williams, 2006]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 199
                            }
                        ],
                        "text": "Typically, the hyperparameter values are learned by \u201cseeding\u201d with a few random samples and maximizing the log-likelihood of the evidence given \u03b8 [Jones et al., 1998, Sasena, 2002, Santner et al., 2003, Rasmussen and Williams, 2006]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 139
                            }
                        ],
                        "text": "\u2026models, a very popular choice is the squared exponential kernel with a vector of automatic relevance determination (ARD) hyperparameters \u03b8\n[Rasmussen and Williams, 2006, page 106]: k(xi,xj) = exp ( \u2212 12 (xi \u2212 xj) T diag(\u03b8)\u22122(x\u2212 x\u2032) ) ,\nwhere diag(\u03b8) is a diagonal matrix with d entries \u03b8\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1430472,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82266f6103bade9005ec555ed06ba20b5210ff22",
            "isKey": true,
            "numCitedBy": 18076,
            "numCiting": 231,
            "paperAbstract": {
                "fragments": [],
                "text": "Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received growing attention in the machine learning community over the past decade. The book provides a long-needed, systematic and unified treatment of theoretical and practical aspects of GPs in machine learning. The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics. The book deals with the supervised learning problem for both regression and classification, and includes detailed algorithms. A wide variety of covariance (kernel) functions are presented and their properties discussed. Model selection is discussed both from a Bayesian and classical perspective. Many connections to other well-known techniques from machine learning and statistics are discussed, including support vector machines, neural networks, splines, regularization networks, relevance vector machines and others. Theoretical issues including learning curves and the PAC-Bayesian framework are treated, and several approximation methods for learning with large datasets are discussed. The book contains illustrative examples and exercises. Code and datasets can be obtained on the web. Appendices provide mathematical background and a discussion of Gaussian Markov processes."
            },
            "slug": "Gaussian-Processes-for-Machine-Learning-Rasmussen-Williams",
            "title": {
                "fragments": [],
                "text": "Gaussian Processes for Machine Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics, and deals with the supervised learning problem for both regression and classification."
            },
            "venue": {
                "fragments": [],
                "text": "Adaptive computation and machine learning"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145343838"
                        ],
                        "name": "Andreas Krause",
                        "slug": "Andreas-Krause",
                        "structuredName": {
                            "firstName": "Andreas",
                            "lastName": "Krause",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andreas Krause"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117775861"
                        ],
                        "name": "A. Singh",
                        "slug": "A.-Singh",
                        "structuredName": {
                            "firstName": "Ajit",
                            "lastName": "Singh",
                            "middleNames": [
                                "Paul"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Singh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730156"
                        ],
                        "name": "Carlos Guestrin",
                        "slug": "Carlos-Guestrin",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Guestrin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlos Guestrin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 333449,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d6380aebd96a1a0fdd5734067db814b91e5179a8",
            "isKey": false,
            "numCitedBy": 1371,
            "numCiting": 115,
            "paperAbstract": {
                "fragments": [],
                "text": "When monitoring spatial phenomena, which can often be modeled as Gaussian processes (GPs), choosing sensor locations is a fundamental task. There are several common strategies to address this task, for example, geometry or disk models, placing sensors at the points of highest entropy (variance) in the GP model, and A-, D-, or E-optimal design. In this paper, we tackle the combinatorial optimization problem of maximizing the mutual information between the chosen locations and the locations which are not selected. We prove that the problem of finding the configuration that maximizes mutual information is NP-complete. To address this issue, we describe a polynomial-time approximation that is within (1-1/e) of the optimum by exploiting the submodularity of mutual information. We also show how submodularity can be used to obtain online bounds, and design branch and bound search procedures. We then extend our algorithm to exploit lazy evaluations and local structure in the GP, yielding significant speedups. We also extend our approach to find placements which are robust against node failures and uncertainties in the model. These extensions are again associated with rigorous theoretical approximation guarantees, exploiting the submodularity of the objective function. We demonstrate the advantages of our approach towards optimizing mutual information in a very extensive empirical study on two real-world data sets."
            },
            "slug": "Near-Optimal-Sensor-Placements-in-Gaussian-Theory,-Krause-Singh",
            "title": {
                "fragments": [],
                "text": "Near-Optimal Sensor Placements in Gaussian Processes: Theory, Efficient Algorithms and Empirical Studies"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is proved that the problem of finding the configuration that maximizes mutual information is NP-complete, and a polynomial-time approximation is described that is within (1-1/e) of the optimum by exploiting the submodularity of mutual information."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699645"
                        ],
                        "name": "R. Sutton",
                        "slug": "R.-Sutton",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Sutton",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sutton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144368601"
                        ],
                        "name": "Doina Precup",
                        "slug": "Doina-Precup",
                        "structuredName": {
                            "firstName": "Doina",
                            "lastName": "Precup",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Doina Precup"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699868"
                        ],
                        "name": "Satinder Singh",
                        "slug": "Satinder-Singh",
                        "structuredName": {
                            "firstName": "Satinder",
                            "lastName": "Singh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Satinder Singh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 65
                            }
                        ],
                        "text": "Each task in an HRL hierarchy is a semi-Markov Decision Process [Sutton et al., 1999], that models repeated decision making in a stochastic environment, where the actions can take more than one time step."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 76564,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0e7638dc16a5e5e9e46c91272bfb9c3dd242ef6d",
            "isKey": false,
            "numCitedBy": 2830,
            "numCiting": 125,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Between-MDPs-and-Semi-MDPs:-A-Framework-for-in-Sutton-Precup",
            "title": {
                "fragments": [],
                "text": "Between MDPs and Semi-MDPs: A Framework for Temporal Abstraction in Reinforcement Learning"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717452"
                        ],
                        "name": "Burr Settles",
                        "slug": "Burr-Settles",
                        "structuredName": {
                            "firstName": "Burr",
                            "lastName": "Settles",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Burr Settles"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 324600,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "818826f356444f3daa3447755bf63f171f39ec47",
            "isKey": false,
            "numCitedBy": 4689,
            "numCiting": 178,
            "paperAbstract": {
                "fragments": [],
                "text": "The key idea behind active learning is that a machine learning algorithm can achieve greater accuracy with fewer training labels if it is allowed to choose the data from which it learns. An active learner may pose queries, usually in the form of unlabeled data instances to be labeled by an oracle (e.g., a human annotator). Active learning is well-motivated in many modern machine learning problems, where unlabeled data may be abundant or easily obtained, but labels are difficult, time-consuming, or expensive to obtain. This report provides a general introduction to active learning and a survey of the literature. This includes a discussion of the scenarios in which queries can be formulated, and an overview of the query strategy frameworks proposed in the literature to date. An analysis of the empirical and theoretical evidence for successful active learning, a summary of problem setting variants and practical issues, and a discussion of related topics in machine learning research are also presented."
            },
            "slug": "Active-Learning-Literature-Survey-Settles",
            "title": {
                "fragments": [],
                "text": "Active Learning Literature Survey"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This report provides a general introduction to active learning and a survey of the literature, including a discussion of the scenarios in which queries can be formulated, and an overview of the query strategy frameworks proposed in the literature to date."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2189118"
                        ],
                        "name": "Ashish Kapoor",
                        "slug": "Ashish-Kapoor",
                        "structuredName": {
                            "firstName": "Ashish",
                            "lastName": "Kapoor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashish Kapoor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794409"
                        ],
                        "name": "K. Grauman",
                        "slug": "K.-Grauman",
                        "structuredName": {
                            "firstName": "Kristen",
                            "lastName": "Grauman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Grauman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2422559"
                        ],
                        "name": "R. Urtasun",
                        "slug": "R.-Urtasun",
                        "structuredName": {
                            "firstName": "Raquel",
                            "lastName": "Urtasun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Urtasun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 469536,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5afcd7a69ddffc7b7ecfb82aed69f2e1ec007004",
            "isKey": false,
            "numCitedBy": 343,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Discriminative methods for visual object category recognition are typically non-probabilistic, predicting class labels but not directly providing an estimate of uncertainty. Gaussian Processes (GPs) are powerful regression techniques with explicit uncertainty models; we show here how Gaussian Processes with covariance functions defined based on a Pyramid Match Kernel (PMK) can be used for probabilistic object category recognition. The uncertainty model provided by GPs offers confidence estimates at test points, and naturally allows for an active learning paradigm in which points are optimally selected for interactive labeling. We derive a novel active category learning method based on our probabilistic regression model, and show that a significant boost in classification performance is possible, especially when the amount of training data for a category is ultimately very small."
            },
            "slug": "Active-Learning-with-Gaussian-Processes-for-Object-Kapoor-Grauman",
            "title": {
                "fragments": [],
                "text": "Active Learning with Gaussian Processes for Object Categorization"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work derives a novel active category learning method based on the probabilistic regression model, and shows that a significant boost in classification performance is possible, especially when the amount of training data for a category is ultimately very small."
            },
            "venue": {
                "fragments": [],
                "text": "2007 IEEE 11th International Conference on Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102631067"
                        ],
                        "name": "D. D. Cox",
                        "slug": "D.-D.-Cox",
                        "structuredName": {
                            "firstName": "Denis",
                            "lastName": "Cox",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. D. Cox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149717463"
                        ],
                        "name": "S. John",
                        "slug": "S.-John",
                        "structuredName": {
                            "firstName": "Staddon",
                            "lastName": "John",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. John"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 122348801,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ea506a0a281eab154fa4d9c99b9c6e6ecb32974c",
            "isKey": false,
            "numCitedBy": 264,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm for finding global optima using statistical prediction is presented. Assuming a random function model, lower confidence bounds on predicted values are used for sequential selection of evaluation points and as a convergence criterion. Comparison with published results for several test functions indicates that the procedure is very efficient in finding the global optimum of a multimodal function, and in terminating with relatively few evaluations.<<ETX>>"
            },
            "slug": "A-statistical-method-for-global-optimization-Cox-John",
            "title": {
                "fragments": [],
                "text": "A statistical method for global optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Comparison with published results for several test functions indicates that the procedure is very efficient in finding the global optimum of a multimodal function, and in terminating with relatively few evaluations."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] 1992 IEEE International Conference on Systems, Man, and Cybernetics"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107603179"
                        ],
                        "name": "D. R. Jones",
                        "slug": "D.-R.-Jones",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Jones",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. R. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2563797"
                        ],
                        "name": "C. D. Perttunen",
                        "slug": "C.-D.-Perttunen",
                        "structuredName": {
                            "firstName": "Cary",
                            "lastName": "Perttunen",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. D. Perttunen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2424124"
                        ],
                        "name": "B. Stuckman",
                        "slug": "B.-Stuckman",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Stuckman",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Stuckman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 63
                            }
                        ],
                        "text": "A particular advantage in active learning applications is that DIRECT can be implemented as an \u201cany-time\u201d algorithm, so that as long as the user is doing something else, it continues to optimize, and when interrupted, the program can use the best results found to that point in time."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 51
                            }
                        ],
                        "text": "We optimize the acquisition function using DIRECT [Jones et al., 1993], a deterministic, derivative-free optimizer."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 123674634,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d7808f2ad77de7b71e83a2e79d27f2e3e12be8d5",
            "isKey": false,
            "numCitedBy": 1840,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new algorithm for finding the global minimum of a multivariate function subject to simple bounds. The algorithm is a modification of the standard Lipschitzian approach that eliminates the need to specify a Lipschitz constant. This is done by carrying out simultaneous searches using all possible constants from zero to infinity. On nine standard test functions, the new algorithm converges in fewer function evaluations than most competing methods.The motivation for the new algorithm stems from a different way of looking at the Lipschitz constant. In particular, the Lipschitz constant is viewed as a weighting parameter that indicates how much emphasis to place on global versus local search. In standard Lipschitzian methods, this constant is usually large because it must equal or exceed the maximum rate of change of the objective function. As a result, these methods place a high emphasis on global search and exhibit slow convergence. In contrast, the new algorithm carries out simultaneous searches using all possible constants, and therefore operates at both the global and local level. Once the global part of the algorithm finds the basin of convergence of the optimum, the local part of the algorithm quickly and automatically exploits it. This accounts for the fast convergence of the new algorithm on the test functions."
            },
            "slug": "Lipschitzian-optimization-without-the-Lipschitz-Jones-Perttunen",
            "title": {
                "fragments": [],
                "text": "Lipschitzian optimization without the Lipschitz constant"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2185407"
                        ],
                        "name": "G. Poyiadjis",
                        "slug": "G.-Poyiadjis",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Poyiadjis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Poyiadjis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701800"
                        ],
                        "name": "A. Doucet",
                        "slug": "A.-Doucet",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Doucet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Doucet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109037966"
                        ],
                        "name": "Sumeetpal S. Singh",
                        "slug": "Sumeetpal-S.-Singh",
                        "structuredName": {
                            "firstName": "Sumeetpal",
                            "lastName": "Singh",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sumeetpal S. Singh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 263,
                                "start": 241
                            }
                        ],
                        "text": "\u2026algorithms [Bertsekas and Tsitsiklis, 1996, Sutton and Barto, 1998], learning methods for Boltzmann machines and deep belief networks [Younes, 1989, Hinton and Salakhutdinov, 2006] and parameter estimation for nonlinear state space models [Poyiadjis et al., 2005, Martinez\u2013Cantin et al., 2006]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9070111,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7608781cdf308d2cdd71a18cfd16b0306b0c66ca",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Particle filtering techniques are a popular set of simulation-based methods to perform optimal state estimation in nonlinear nonGaussian dynamic models. However, in applications related to control and identification, it is often necessary to be able to compute the derivative of the optimal filter with respect to parameters of the dynamic model. Several methods have already been proposed in the literature. In experiments, the approximation errors increase with the dataset length. We propose here original particle methods to approximate numerically the filter derivative. In simulations, these methods do not suffer from the problem mentioned. Applications to batch and recursive parameter estimation are presented."
            },
            "slug": "Particle-methods-for-optimal-filter-derivative:-to-Poyiadjis-Doucet",
            "title": {
                "fragments": [],
                "text": "Particle methods for optimal filter derivative: application to parameter estimation"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. (ICASSP '05). IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3044529"
                        ],
                        "name": "Leo Liberti",
                        "slug": "Leo-Liberti",
                        "structuredName": {
                            "firstName": "Leo",
                            "lastName": "Liberti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Leo Liberti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725329"
                        ],
                        "name": "N. Maculan",
                        "slug": "N.-Maculan",
                        "structuredName": {
                            "firstName": "Nelson",
                            "lastName": "Maculan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Maculan"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 117870224,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45d31ca46d95bdf4ad04fe198f002b488ed6d5d1",
            "isKey": false,
            "numCitedBy": 185,
            "numCiting": 184,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface.- Optimization under Composite Monotonic Constraints and Constrained Optimization over the Efficient Set (H. Tuy, N.T. Hoai-Phuong).- On a Local Search for Reverse Convex Problems (A. Strekalovsky).- Some Transformation Techniques in Global Optimization (T. Westerlund).- Solving Nonlinear Mixed Integer Stochastic Problems: A Global Perspective (M.E. Bruni).- Application of Quasi Monte Carlo Methods in Global Optimization (S. Kucherenko).- GLOB-A New VNS-Based Software for Global Optimization (M. Drazic, V. Kovacevic-Vujcic, M. Cangalovic, N. Mladenovic).- Disciplined Convex Programming (M. Grant, S. Boyd, Y. Ye).- Writing Global Optimization Software (L. Liberti).- MathOptimizer Professional: Key Features and Illustrative Applications (J.D. Pinter, F.J. Kampas).- Variable Neighborhood Search for Extremal Graphs 14: The AutoGraphiX 2 System (M. Aouchiche, J.M. Bonnefoy, A. Fidahoussen, G. Caporossi, P. Hansen, L. Hiesse, J. Lachere, A. Monhait).- From Theory to Implementation: Applying Metaheuristics (I.J. Garcia del Amo, F. Garcia Lopez, M. Garcia Torres, B. Melian Batista, J.A. Moreno Perez, J.M. Moreno Vega).- ooMILP-A C++ Callable Object-Oriented Library and the Implementation of Its Parallel Version Using CORBA (P. Tsiakis, B. Keeping).- Global Order-Value Optimization by Means of a Multistart Harmonic Oscillator Tunneling Strategy (R. Andreani, J.M. Martinez, M. Salvatierra, F. Yano).- On Generating Instances for the Molecular Distance Geometry Problem (C. Lavor).- Index."
            },
            "slug": "Global-optimization-:-from-theory-to-implementation-Liberti-Maculan",
            "title": {
                "fragments": [],
                "text": "Global optimization : from theory to implementation"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Preface.- Optimization under Composite Monotonic Constraints and Constrained Optimization over the Efficient Set (H. Tuy, N.T. Hoai-Phuong)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388404060"
                        ],
                        "name": "Kevin Leyton-Brown",
                        "slug": "Kevin-Leyton-Brown",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Leyton-Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Leyton-Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 173
                            }
                        ],
                        "text": "It is also possible to resample potential incumbents to get more reliable estimates of the values in a noisy environment [Bartz-Beielstein et al., 2005, Huang et al., 2006, Hutter et al., 2009], a process sometimes called intensification."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 279,
                                "start": 260
                            }
                        ],
                        "text": "\u2026has evolved a body of work devoted to extending the algorithm, particularly in adding constraints to the optimization problem [Audet et al., 2000, Sasena, 2002, Boyle, 2007], and in modelling noisy functions [Bartz-Beielstein et al., 2005, Huang et al., 2006, Hutter et al., 2009, Hutter, 2009]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1863673,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "eaa44ec117af3e45ffedd0028b3cc208469ab50f",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This work experimentally investigates model-based approaches for optimising the performance of parameterised randomised algorithms. We restrict our attention to procedures based on Gaussian process models, the most widely-studied family of models for this problem. We evaluated two approaches from the literature, and found that sequential parameter optimisation (SPO) [4] offered the most robust performance. We then investigated key design decisions within the SPO paradigm, characterising the performance consequences of each. Based on these findings, we propose a new version of SPO, dubbed SPO+, which extends SPO with a novel intensification procedure and log-transformed response values. Finally, in a domain for which performance results for other (model-free) parameter optimisation approaches are available, we demonstrate that SPO+ achieves state-of-the-art performance."
            },
            "slug": "An-experimental-investigation-of-model-based-SPO-Hutter-Hoos",
            "title": {
                "fragments": [],
                "text": "An experimental investigation of model-based parameter optimisation: SPO and beyond"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new version of SPO is proposed, dubbed SPO+, which extends SPO with a novel intensification procedure and log-transformed response values, and it is demonstrated that SPO+ achieves state-of-the-art performance."
            },
            "venue": {
                "fragments": [],
                "text": "GECCO"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3240893"
                        ],
                        "name": "Charles Audet",
                        "slug": "Charles-Audet",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Audet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles Audet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "151380925"
                        ],
                        "name": "J. Denni",
                        "slug": "J.-Denni",
                        "structuredName": {
                            "firstName": "Julien",
                            "lastName": "Denni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2114877467"
                        ],
                        "name": "Douglas Moore",
                        "slug": "Douglas-Moore",
                        "structuredName": {
                            "firstName": "Douglas",
                            "lastName": "Moore",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Douglas Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40698158"
                        ],
                        "name": "A. Booker",
                        "slug": "A.-Booker",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Booker",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Booker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704765"
                        ],
                        "name": "P. Frank",
                        "slug": "P.-Frank",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Frank",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Frank"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62550311,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fa69c712a0c6e7213e8fed4e00ec99e727a782cf",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes an algorithm and provides test results for surrogate-model-based optimization. In this type of optimization, the objective and constraint functions are represented by global \"surrogates\", i.e. response models, of the \"true\" problem responses. In general, guarantees of global optimality are not possible. However, a robust surrogate-model-based optimization method is presented here that has good global search properties, and proven local convergence results. This paper describes methods for handling three key issues in surrogate-model-based optimization. These issues are maintaining a balance of effort between global design space exploration and local optimizer region refinement, maintaining good surrogate model conditioning as points \"pile up\" in local regions, and providing a provably convergent method for ensuring local optimality. Acknowledgments: Work of the first author was supported by NSERC (Natural Sciences and Engineering Research Council) fellowship PDF-2074321998, and the first three authors was supported by DOE DE-FG03-95ER25257, AFOSR F49620-98-10267, The Boeing Company, Sandia LG-4253, ExxonMobil and CRPC CCR-9120008. Copyright \u00a92000 by the American Institute of Aeronautics and Astronautics, Inc. All rights reserved."
            },
            "slug": "A-surrogate-model-based-method-for-constrained-Audet-Denni",
            "title": {
                "fragments": [],
                "text": "A surrogate-model-based method for constrained optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A robust surrogate-model-based optimization method is presented here that has good global search properties, and proven local convergence results, and providing a provably convergent method for ensuring local optimality."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40132383"
                        ],
                        "name": "Phillip Boyle",
                        "slug": "Phillip-Boyle",
                        "structuredName": {
                            "firstName": "Phillip",
                            "lastName": "Boyle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Phillip Boyle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 161
                            }
                        ],
                        "text": "\u2026has evolved a body of work devoted to extending the algorithm, particularly in adding constraints to the optimization problem [Audet et al., 2000, Sasena, 2002, Boyle, 2007], and in modelling noisy functions [Bartz-Beielstein et al., 2005, Huang et al., 2006, Hutter et al., 2009, Hutter, 2009]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 118429927,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb529f514ae4b5f2c61ecde551157e1dd2e9b3f1",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 115,
            "paperAbstract": {
                "fragments": [],
                "text": "Gaussian processes have proved to be useful and powerful constructs for the purposes of regression. The classical method proceeds by parameterising a covariance function, and then infers the parameters given the training data. In this thesis, the classical approach is augmented by interpreting Gaussian processes as the outputs of linear filters excited by white noise. This enables a straightforward definition of dependent Gaussian processes as the outputs of a multiple output linear filter excited by multiple noise sources. We show how dependent Gaussian processes defined in this way can also be used for the purposes of system identification. Onewell known problem with Gaussian process regression is that the computational complexity scales poorly with the amount of training data. We review one approximate solution that alleviates this problem, namely reduced rank Gaussian processes. We then show how the reduced rank approximation can be applied to allow for the efficient computation of dependent Gaussian processes. We then examine the application of Gaussian processes to the solution of other machine learning problems. To do so, we review methods for the parameterisation of full covariance matrices. Furthermore, we discuss how improvements can be made by marginalising over alternative models, and introduce methods to perform these computations efficiently. In particular, we introduce sequential annealed importance sampling as a method for calculating model evidence in an on-line fashion as new data arrives. Gaussian process regression can also be applied to optimisation. An algorithm is described that uses model comparison between multiple models to find the optimum of a function while taking as few samples as possible. This algorithm shows impressive performance on the standard control problem of double pole balancing. Finally, we describe how Gaussian processes can be used to efficiently estimate gradients of noisy functions, and numerically estimate integrals."
            },
            "slug": "Gaussian-Processes-for-Regression-and-Optimisation-Boyle",
            "title": {
                "fragments": [],
                "text": "Gaussian Processes for Regression and Optimisation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This thesis introduces sequential annealed importance sampling as a method for calculating model evidence in an on-line fashion as new data arrives and describes how Gaussian processes can be used to efficiently estimate gradients of noisy functions, and numerically estimate integrals."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065748442"
                        ],
                        "name": "P. Goldberg",
                        "slug": "P.-Goldberg",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Goldberg",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Goldberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1792884"
                        ],
                        "name": "Charles M. Bishop",
                        "slug": "Charles-M.-Bishop",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Bishop",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Charles M. Bishop"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 158
                            }
                        ],
                        "text": "Nonstationary noise models are also possible, such as autoregressive moving-average noise [Murray-Smith and Girard, 2001] and heteroskedastic Gaussian noise [Goldberg et al., 1998]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7482528,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "4d00277ee6bdbfc7cd3282d33897be5758d315fe",
            "isKey": false,
            "numCitedBy": 234,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Gaussian processes provide natural non-parametric prior distributions over regression functions. In this paper we consider regression problems where there is noise on the output, and the variance of the noise depends on the inputs. If we assume that the noise is a smooth function of the inputs, then it is natural to model the noise variance using a second Gaussian process, in addition to the Gaussian process governing the noise-free output value. We show that prior uncertainty about the parameters controlling both processes can be handled and that the posterior distribution of the noise rate can be sampled from using Markov chain Monte Carlo methods. Our results on a synthetic data set give a posterior noise variance that well-approximates the true variance."
            },
            "slug": "Regression-with-Input-dependent-Noise:-A-Gaussian-Goldberg-Williams",
            "title": {
                "fragments": [],
                "text": "Regression with Input-dependent Noise: A Gaussian Process Treatment"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper shows that prior uncertainty about the parameters controlling both processes can be handled and that the posterior distribution of the noise rate can be sampled from using Markov chain Monte Carlo methods and gives a posterior noise variance that well-approximates the true variance."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144484861"
                        ],
                        "name": "Michael A. Osborne",
                        "slug": "Michael-A.-Osborne",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Osborne",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael A. Osborne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145974030"
                        ],
                        "name": "R. Garnett",
                        "slug": "R.-Garnett",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Garnett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Garnett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145029236"
                        ],
                        "name": "S. Roberts",
                        "slug": "S.-Roberts",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Roberts",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Roberts"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 185
                            }
                        ],
                        "text": "For example, the recent sequential sensor work of Osborne, Garnett and colleagues uses GP models with extensions to the covariance function to model the characteristics of changepoints [Osborne et al., 2010] and the locations of sensors in a network [Garnett et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 206,
                                "start": 186
                            }
                        ],
                        "text": "For example, the recent sequential sensor work of Osborne, Garnett and colleagues uses GP models with extensions to the covariance function to model the characteristics of changepoints [Osborne et al., 2010] and the locations of sensors in a network [Garnett et al., 2010a]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 53
                            }
                        ],
                        "text": "\u2022 The work of Osborne, Garnett et al. [Osborne, 2010, Osborne et al., 2010, Garnett et al., 2010b] uses Bayesian optimization to select the locations of a set of (possibly heterogenous) sensors in a dynamic system."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2733553,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "929a751a6b4e22fcbafd22c1754c8f135751a813",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a Bayesian formalism for the intelligent selection of observations from sensor networks that may intermittently undergo faults or changepoints. Such active data selection is performed with the goal of taking as few observations as necessary in order to maintain a reasonable level of uncertainty about the variables of interest. The presence of faults/changepoints is not always obvious and therefore our algorithm must first detect their occurrence. Having done so, our selection of observations must be appropriately altered. Faults corrupt our observations, reducing their impact; changepoints (abrupt changes in the characteristics of data) may require the transition to an entirely different sampling schedule. Our solution is to employ a Gaussian process formalism that allows for sequential time-series prediction about variables of interest along with a decision theoretic approach to the problem of selecting observations."
            },
            "slug": "Active-Data-Selection-for-Sensor-Networks-with-and-Osborne-Garnett",
            "title": {
                "fragments": [],
                "text": "Active Data Selection for Sensor Networks with Faults and Changepoints"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The solution is to employ a Gaussian process formalism that allows for sequential time-series prediction about variables of interest along with a decision theoretic approach to the problem of selecting observations."
            },
            "venue": {
                "fragments": [],
                "text": "2010 24th IEEE International Conference on Advanced Information Networking and Applications"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2203148"
                        ],
                        "name": "M. Mongeau",
                        "slug": "M.-Mongeau",
                        "structuredName": {
                            "firstName": "Marcel",
                            "lastName": "Mongeau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mongeau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085143470"
                        ],
                        "name": "H. Karsenty",
                        "slug": "H.-Karsenty",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Karsenty",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Karsenty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2071708608"
                        ],
                        "name": "V. Rouz\u00e9",
                        "slug": "V.-Rouz\u00e9",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Rouz\u00e9",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Rouz\u00e9"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102835246"
                        ],
                        "name": "J. Hiriart-Urruty",
                        "slug": "J.-Hiriart-Urruty",
                        "structuredName": {
                            "firstName": "Jean-Baptiste",
                            "lastName": "Hiriart-Urruty",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Hiriart-Urruty"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 145
                            }
                        ],
                        "text": "A number of approaches exist for this kind of global optimization and have been well-studied in the literature (e.g., [To\u0308rn and Z\u030cilinskas, 1989, Mongeau et al., 1998, Liberti and Maculan, 2006, Zhigljavsky and Z\u030cilinskas, 2008])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2595508,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "345baa5dda60265932587bb73844ff4f56eaf5b3",
            "isKey": false,
            "numCitedBy": 55,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We instance our experience with six public-domain global optimization software products and report comparative computational results obtained on a set of eleven test problems. The techniques used by the software under study include integral global optimization, genetic algorithms, simulated annealing, clustering, random search, continuation, Bayesian, tunneling, and multi-level methods. The test set contains practical problems: least median of squares regression, protein folding, and multidimensional scaling. These include non-differentiable, and also discontinuous objective functions, some with an exponential number of local minima. The dimension of the search space ranges from 1 to 20. We evaluate the software in view of engineers addressing black box global optimization problems, i.e. problems with an objective function whose explicit form is unknown and whose evaluation is costly. Such an objective function is common in industry. It is for instance given under the form of computer programmes involving a simulation"
            },
            "slug": "Comparison-of-public-domain-software-for-black-box-Mongeau-Karsenty",
            "title": {
                "fragments": [],
                "text": "Comparison of public-domain software for black box global optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Evaluating the software in view of engineers addressing black box global optimization problems, i.e. problems with an objective function whose explicit form is unknown and whose evaluation is costly, with results obtained on a set of eleven test problems."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1402170019"
                        ],
                        "name": "R. Murray-Smith",
                        "slug": "R.-Murray-Smith",
                        "structuredName": {
                            "firstName": "Roderick",
                            "lastName": "Murray-Smith",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Murray-Smith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152561047"
                        ],
                        "name": "D. Sbarbaro",
                        "slug": "D.-Sbarbaro",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Sbarbaro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Sbarbaro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 10529134,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "049572be1a2ec7a2d3823905025b7ba6b827adf8",
            "isKey": false,
            "numCitedBy": 86,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Nonparametric Gaussian Process prior models, taken from Bayesian statistics methodology are used to implement a nonlinear adaptive control law. The expected value of a quadratic cost function is minimised, without ignoring the variance of the model predictions. This leads to implicit regularisation of the control signal (caution), and excitation of the system. The controller has dual features, since it is both tracking a reference signal and learning a model of the system from observed responses. The general method and its main features are illustrated on a simulation example."
            },
            "slug": "Nonlinear-adaptive-control-using-non-parametric-Murray-Smith-Sbarbaro",
            "title": {
                "fragments": [],
                "text": "Nonlinear adaptive control using non-parametric Gaussian Process prior models"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "Nonparametric Gaussian Process prior models, taken from Bayesian statistics methodology are used to implement a nonlinear adaptive control law, which leads to implicit regularisation of the control signal (caution), and excitation of the system."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075355113"
                        ],
                        "name": "D. Dennis",
                        "slug": "D.-Dennis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Dennis",
                            "middleNames": [
                                "Mack"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Dennis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2081260358"
                        ],
                        "name": "Coxy",
                        "slug": "Coxy",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Coxy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Coxy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054222936"
                        ],
                        "name": "Susan",
                        "slug": "Susan",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Susan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Susan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2098105830"
                        ],
                        "name": "JohnzAbstractAn",
                        "slug": "JohnzAbstractAn",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "JohnzAbstractAn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "JohnzAbstractAn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 9899433,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1825c07187eddd2a3dc26b16d525524730a4feb4",
            "isKey": false,
            "numCitedBy": 170,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "An algorithm for nding global optima using statistical prediction is presented. Assuming a random function model, lower conndence bounds on predicted values are used for sequential selection of evaluation points and as a convergence criterion. Performance comparision with published results on several test functions indicate that the procedure is very eecient in nding the global optimum of a multimodal function, and in terminating with relatively few evaluations. The statistical computations involve linear algebra operations which are readily vectorized and is easy to adapt to parallel processing environments."
            },
            "slug": "SDO-:-A-Statistical-Method-for-Global-Optimization-Dennis-Coxy",
            "title": {
                "fragments": [],
                "text": "SDO : A Statistical Method for Global Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Performance comparision with published results on several test functions indicate that the procedure is very eecient in nding the global optimum of a multimodal function, and in terminating with relatively few evaluations."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064181"
                        ],
                        "name": "A. Tversky",
                        "slug": "A.-Tversky",
                        "structuredName": {
                            "firstName": "Amos",
                            "lastName": "Tversky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tversky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3683465"
                        ],
                        "name": "D. Kahneman",
                        "slug": "D.-Kahneman",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Kahneman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kahneman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 269,
                                "start": 243
                            }
                        ],
                        "text": "Prospect theory, for example, employs utility models based on relation to a reference point, based on evidence that the human perceptual apparatus is attuned to evaluate differences rather than absolute magnitudes [Kahneman and Tversky, 1979, Tversky and Kahneman, 1992]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8456150,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "9b129513de0da471a204b953528c437e4a4c30ef",
            "isKey": false,
            "numCitedBy": 12321,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "We develop a new version of prospect theory that employs cumulative rather than separable decision weights and extends the theory in several respects. This version, called cumulative prospect theory, applies to uncertain as well as to risky prospects with any number of outcomes, and it allows different weighting functions for gains and for losses. Two principles, diminishing sensitivity and loss aversion, are invoked to explain the characteristic curvature of the value function and the weighting functions. A review of the experimental evidence and the results of a new experiment confirm a distinctive fourfold pattern of risk attitudes: risk aversion for gains and risk seeking for losses of high probability; risk seeking for gains and risk aversion for losses of low probability.This article has benefited from discussions with Colin Camerer, Chew Soo-Hong, David Freedman, and David H. Krantz. We are especially grateful to Peter P. Wakker for his invaluable input and contribution to the axiomatic analysis. We are indebted to Richard Gonzalez and Amy Hayes for running the experiment and analyzing the data. This work was supported by Grants 89-0064 and 88-0206 from the Air Force Office of Scientific Research, by Grant SES-9109535 from the National Science Foundation, and by the Sloan Foundation."
            },
            "slug": "Advances-in-prospect-theory:-Cumulative-of-Tversky-Kahneman",
            "title": {
                "fragments": [],
                "text": "Advances in prospect theory: Cumulative representation of uncertainty"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1405499515"
                        ],
                        "name": "Ruben Martinez-Cantin",
                        "slug": "Ruben-Martinez-Cantin",
                        "structuredName": {
                            "firstName": "Ruben",
                            "lastName": "Martinez-Cantin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruben Martinez-Cantin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145186838"
                        ],
                        "name": "J. A. Castellanos",
                        "slug": "J.-A.-Castellanos",
                        "structuredName": {
                            "firstName": "Jos\u00e9",
                            "lastName": "Castellanos",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. A. Castellanos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8643706,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "09044d41b871ed06bfad87214214e8fc4c39921a",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a new particle method, with stochastic parameter estimation, to solve the SLAM problem. The underlying algorithm is rooted on a solid probabilistic foundation and is guaranteed to converge asymptotically, unlike many existing popular approaches. Moreover, it is efficient in storage and computation. The new algorithm carries out filtering only in the marginal filtering space, thereby allowing for the recursive computation of low variance estimates of the map. The paper provides mathematical arguments and empirical evidence to substantiate the fact that the new method represents an improvement over the existing particle filtering approaches for SLAM, which work on the joint path state space."
            },
            "slug": "Analysis-of-Particle-Methods-for-Simultaneous-Robot-Martinez-Cantin-Freitas",
            "title": {
                "fragments": [],
                "text": "Analysis of Particle Methods for Simultaneous Robot Localization and Mapping and a New Algorithm: Marginal-SLAM"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "This paper presents a new particle method, with stochastic parameter estimation, to solve the SLAM problem, which carries out filtering only in the marginal filtering space, thereby allowing for the recursive computation of low variance estimates of the map."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings 2007 IEEE International Conference on Robotics and Automation"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057046890"
                        ],
                        "name": "Wei Chu",
                        "slug": "Wei-Chu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Chu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Chu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 11
                            }
                        ],
                        "text": "Following [Chu and Ghahramani, 2005b], we assign a nonparametric Gaussian process prior to the unknown mean valuation: f(\u00b7) \u223c GP(0,K(\u00b7, \u00b7))."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 27
                            }
                        ],
                        "text": "Parts of \u00a73.1 are based on [Chu and Ghahramani, 2005b], which presents a preference learning method using probit models and Gaussian processes."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15543200,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af2575ccaa688890a11f78a58c061ece7ca7399c",
            "isKey": true,
            "numCitedBy": 53,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Unlabelled examples in supervised learning tasks can be optimally exploited using semi-supervised methods and active learning. We focus on ranking learning from pairwise instance preference to discuss these important extensions, semi-supervised learning and active learning, in the probabilistic framework of Gaussian processes. Numerical experiments demonstrate the capacities of these techniques."
            },
            "slug": "Extensions-of-Gaussian-Processes-for-Ranking-:-and-Chu",
            "title": {
                "fragments": [],
                "text": "Extensions of Gaussian Processes for Ranking : Semi-supervised and Active Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This work focuses on ranking learning from pairwise instance preference to discuss these important extensions, semi-supervised learning and active learning, in the probabilistic framework of Gaussian processes."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6050918"
                        ],
                        "name": "J. Elder",
                        "slug": "J.-Elder",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Elder",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Elder"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15251414,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "55692d2bed5b98c89a3314bb0e0df89650d95f4e",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "A global optimization algorithm i s introduced which generalizes Kushner\u2019s univariate search [1]. It aims to minimize the number o f probes (function evaluations) required for a g i v e n confidence in the results. All known p r o b e s contribute to a stochastic model of the underly ing \u201cscore surface\u201d; this model is interrogated for the location most likely to exceed the current result goal. The surface is assumed to be fractal, l e a d i n g to a piecewise Gaussian model, where the local regions are defined by the Delaunay triangulation o f the probes. The algorithm balances the c o m p e t i n g aims of 1) sampling in the vicinity of known p e a k s , and 2) exploring new regions. Preliminary tests o n a standard 2-d search problem are very encouraging."
            },
            "slug": "Global-Rd-Optimization-when-Probes-are-Expensive-:-Elder",
            "title": {
                "fragments": [],
                "text": "Global Rd Optimization when Probes are Expensive : the GROPE Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "A global optimization algorithm introduced which generalizes Kushner\u2019s univariate search and aims to minimize the number of probes (function evaluations) required for confidence in the results."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114746099"
                        ],
                        "name": "D. Busby",
                        "slug": "D.-Busby",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Busby",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Busby"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11311226,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b10547c6ff093c24d30835389b86cfe778100554",
            "isKey": false,
            "numCitedBy": 74,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Hierarchical-adaptive-experimental-design-for-Busby",
            "title": {
                "fragments": [],
                "text": "Hierarchical adaptive experimental design for Gaussian process emulators"
            },
            "venue": {
                "fragments": [],
                "text": "Reliab. Eng. Syst. Saf."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50238440"
                        ],
                        "name": "W. Notz",
                        "slug": "W.-Notz",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Notz",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Notz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2011917"
                        ],
                        "name": "T. Santner",
                        "slug": "T.-Santner",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Santner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Santner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50475322"
                        ],
                        "name": "B. Williams",
                        "slug": "B.-Williams",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 70
                            }
                        ],
                        "text": "However, sequential design is an important and active subfield (e.g. [Williams et al., 2000, Busby, 2009]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10069227,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ef6e6f619e84ceb990fa62a3f57548b02c14c3a",
            "isKey": false,
            "numCitedBy": 184,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In the last ten to fifteen years many phenomena that could be studied only using physical experiments can now be studied by computer experiments. Advances in the mathematical modeling of many physical processes, in algorithms for solving mathematical systems, and in computer speeds, have combined to make it possible to augment or replace physical experiments with computer experiments. In a computer experiment, a response z( x), usually deterministic, is computed for each set of input variables, x, according to an experimental design strategy. This strategy is determined by the goal of the experiment and depends, for example, on whether response prediction at unsampled input sites or response optimization is of primary interest. \nWe are concerned with the commonly occuring situation in which there are two types of input variables: suppose x = ( xc, x e) where xc is a set of \u201ccontrol\u201d (manufacturing) variables and xe is a set of \u201cenvironmental\u201d (noise) variables. Manufacturing variables can be controlled while noise variables are not controllable but have values governed by some probability distribution. \nFor single response settings, we introduce a sequential experimental design for finding the optimum of e(x c) = E[z(x c, Xe)], where the expectation is taken over the distribution of the environmental variables. For bivariate response settings, we introduce a sequential experimental design for finding the constrained optimum of e1( xc)) = E[z( xc, X e)], subject to e2 (x c) = E[z2(x c, Xe)] \u2264 U. The approach is Bayesian; the prior information is that the responses are a draw from a stationary Gaussian stochastic process with correlation function belonging to a parametric family with unknown parameters. The idea of the methods is to compute the posterior expected \u201cimprovement\u201d over the current optimum for each untested site; the design selects the next site to maximize the expected improvement. Both procedures are illustrated by examples utilizing test functions from the numerical optimization literature."
            },
            "slug": "Sequential-design-of-computer-experiments-to-Notz-Santner",
            "title": {
                "fragments": [],
                "text": "Sequential design of computer experiments to minimize integrated response functions"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The idea of the methods is to compute the posterior expected \u201cimprovement\u201d over the current optimum for each untested site; the design selects the next site to maximize the expected improvement."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1774321"
                        ],
                        "name": "B. Betr\u00f2",
                        "slug": "B.-Betr\u00f2",
                        "structuredName": {
                            "firstName": "Bruno",
                            "lastName": "Betr\u00f2",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Betr\u00f2"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 209,
                                "start": 196
                            }
                        ],
                        "text": "Even in a noise-free domain, evaluating an objective function with Lipschitz continuity C on a d-dimensional unit hypercube, guaranteeing the best observation f(x) \u2265 f(x)\u2212 requires (C/2 ) samples [Betr\u00f2, 1991]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 27
                            }
                        ],
                        "text": "\u2212 requires (C/2 )d samples [Betro\u0300, 1991]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 19324834,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3cd93c773acfd220b6bcc496ba103deba1eaa294",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper reviews methods which have been proposed for solving global optimization problems in the framework of the Bayesian paradigm."
            },
            "slug": "Bayesian-methods-in-global-optimization-Betr\u00f2",
            "title": {
                "fragments": [],
                "text": "Bayesian methods in global optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "This paper reviews methods which have been proposed for solving global optimization problems in the framework of the Bayesian paradigm and concludes that these methods should be considered as stand-alone approaches to optimization."
            },
            "venue": {
                "fragments": [],
                "text": "J. Glob. Optim."
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70271984"
                        ],
                        "name": "A. ilinskas",
                        "slug": "A.-ilinskas",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "ilinskas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. ilinskas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 235,
                                "start": 204
                            }
                        ],
                        "text": "There exist several consistency proofs for this algorithm in the one-dimensional setting [Locatelli, 1997] and one for a simplification of the algorithm using simplicial partitioning in higher dimensions [\u017dilinskas and \u017dilinskas, 2002]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 205
                            }
                        ],
                        "text": "There exist several consistency proofs for this algorithm in the one-dimensional setting [Locatelli, 1997] and one for a simplification of the algorithm using simplicial partitioning in higher dimensions [Z\u030cilinskas and Z\u030cilinskas, 2002]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52043977,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4b8b2267600b0e1ab278a43b4488e6a934cf4b5a",
            "isKey": false,
            "numCitedBy": 15,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "A statistical model for global optimization is constructed generalizing some properties of the Wiener process to the multidimensional case. An approach to the construction of global optimization algorithms is developed using the proposed statistical model. The convergence of an algorithm based on the constructed statistical model and simplicial partitioning is proved. Several versions of the algorithm are implemented and investigated. @ 2002 Elsevier Science Ltd. All rights reserved. Keywords-Global optimization, Statistical models, Partitioning, Simplices, Convergence"
            },
            "slug": "Global-Optimization-Based-on-a-Statistical-Model-ilinskas",
            "title": {
                "fragments": [],
                "text": "Global Optimization Based on a Statistical Model and Simplicial Partitioning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The convergence of an algorithm based on the constructed statistical model and simplicial partitioning is proved and several versions of the algorithm are implemented and investigated."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31445029"
                        ],
                        "name": "D. McFadden",
                        "slug": "D.-McFadden",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "McFadden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. McFadden"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 123
                            }
                        ],
                        "text": "Probability models for learning from discrete choices have a long history in psychology and econometrics [Thurstone, 1927, McFadden, 1980, Stern, 1990]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 154246537,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "f05ddb6d736c7c8fedef2d5f7d824751e050381b",
            "isKey": false,
            "numCitedBy": 701,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "I understand the discipline of marketing exists to answer questions such as: \"Will housepersons buy more Brand A soap if its perfume content is increased?\" Traditional econometric demand analysis provides no answer. Its attention has been concentrated on consumption levels of broad commodity classes (e.g., housing services), examined using aggregate market data, with demand models constructed on the twin pillars of economic rationality and consumer sovereignty. The market researcher has understandably looked elsewhere-to psychology and survey research-for answers to his questions. Realities have forced econometric demand analysts to broaden their perspective. Public intervention in the supply of some commodities, notably in the areas of transportation, energy, and communications, have required economists to recognize the marketing considerations implicit in issues of policy. (The decision of whether to build and how to design a public This paper reviews several recent developments in econometric demand analysis which may be of interest in market research. Econometric models of probabilistic choice, suitable for forecasting choice among existing or new brands, or switching between brands, are surveyed. These models incorporate attribute descriptions of commodities, making them statistical counterparts of the Court-GrilichesLancaster theory of consumer behavior. Particular attention is given to models which yield tree structures of similarities between alternatives. Also reviewed are methods for estimating econometric models of probabilistic choice from \"point-ofsale\" sample surveys. * Prepared for presentation at the Conference on Interfaces between Marketing and Economics, Graduate School of Management, University of Rochester, April 7, 1978. Research was supported in part by the National Science Foundation through grant SOC75-22657 to the University of California, Berkeley. Portions of this paper were written while the author was an Irving Fisher Visiting Professor of Economics at the Cowles Foundation for Research in Economics, Yale University."
            },
            "slug": "Econometric-Models-for-Probabilistic-Choice-Among-McFadden",
            "title": {
                "fragments": [],
                "text": "Econometric Models for Probabilistic Choice Among Products"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1980
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786249"
                        ],
                        "name": "D. Bertsekas",
                        "slug": "D.-Bertsekas",
                        "structuredName": {
                            "firstName": "Dimitri",
                            "lastName": "Bertsekas",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bertsekas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 63
                            }
                        ],
                        "text": "It is the core idea in most reinforcement learning algorithms [Bertsekas and Tsitsiklis, 1996, Sutton and Barto, 1998], learning methods for Boltzmann machines and deep belief networks [Younes, 1989, Hinton and Salakhutdinov, 2006] and parameter estimation for nonlinear state space models\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7989664,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7ee42abcd6f8c3c16375aead3346d0c7f3a6f672",
            "isKey": false,
            "numCitedBy": 4617,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "From the Publisher: \nThis is the first textbook that fully explains the neuro-dynamic programming/reinforcement learning methodology, which is a recent breakthrough in the practical application of neural networks and dynamic programming to complex problems of planning, optimal decision making, and intelligent control."
            },
            "slug": "Neuro-Dynamic-Programming-Bertsekas",
            "title": {
                "fragments": [],
                "text": "Neuro-Dynamic Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "This is the first textbook that fully explains the neuro-dynamic programming/reinforcement learning methodology, which is a recent breakthrough in the practical application of neural networks and dynamic programming to complex problems of planning, optimal decision making, and intelligent control."
            },
            "venue": {
                "fragments": [],
                "text": "Encyclopedia of Optimization"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6050918"
                        ],
                        "name": "J. Elder",
                        "slug": "J.-Elder",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Elder",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Elder"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 149
                            }
                        ],
                        "text": "Later work extended Kushner\u2019s technique to multidimensional optimization, using, for example, interpolation in a Delauney triangulation of the space [Elder, 1992] or projecting Wiener processes between sample points [Stuckman, 1988]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 123629619,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "396e4c51c8a9344d70429777c6d1a7a5a7357a48",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "A global optimization algorithm is introduced which generalizes H.J. Kushner's (1964) univariate search. It aims to minimize the number of probes required for a given confidence in the results. All known probes contribute to a stochastic model of the underlying score surface, and this model is interrogated for the location most likely to exceed the current result goal. The surface is assumed to be fractal, leading to a piecewise Gaussian model, where the local regions are defined by the Delaunay triangulation of the probes. The algorithm balances the competing aims of (1) sampling in the vicinity of known peaks, and (2) exploring new regions. Preliminary tests on a standard 2-D search problem were very encouraging.<<ETX>>"
            },
            "slug": "Global-R/sup-d/-optimization-when-probes-are-the-Elder",
            "title": {
                "fragments": [],
                "text": "Global R/sup d/ optimization when probes are expensive: the GROPE algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "A global optimization algorithm is introduced which generalizes H.J. Kushner's (1964) univariate search and balances the competing aims of sampling in the vicinity of known peaks, and exploring new regions."
            },
            "venue": {
                "fragments": [],
                "text": "[Proceedings] 1992 IEEE International Conference on Systems, Man, and Cybernetics"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102382028"
                        ],
                        "name": "D. Krige",
                        "slug": "D.-Krige",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Krige",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Krige"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 194
                            }
                        ],
                        "text": "At the same time, a large, related body of work emerged under the name kriging (\u00a72.6), in honour of the South African student who developed this technique at the University of the Witwatersrand [Krige, 1951], though largely popularized by Matheron and colleagues (e.g. [Matheron, 1971])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 111
                            }
                        ],
                        "text": "6), in honour of the South African student who developed this technique at the University of the Witwatersrand [Krige, 1951], though largely popularized by Matheron and colleagues (e."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 117319434,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "b8a3d23444cd33f1d74c62d5013f04e6acf0f763",
            "isKey": true,
            "numCitedBy": 2233,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Certain fundamental concepts in the application of statistics to mine valuation on the Witwatersrand are discussed, and general conclusions are drawn regarding the application of the lognormal curve to the frequency distribution of gold values. An indication is given of the reliability of present valuation methods on the Rand. It is shown that the existing over- and under-valuation of blocks of ore listed as high-grade and low-grade, respectively, can be explained statistically. Suggestions are made for the elimination of such errors and for the improvement of the general standard of mine valuation by the use of statistical theory."
            },
            "slug": "A-statistical-approach-to-some-basic-mine-valuation-Krige",
            "title": {
                "fragments": [],
                "text": "A statistical approach to some basic mine valuation problems on the Witwatersrand, by D.G. Krige, published in the Journal, December 1951 : introduction by the author"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1951
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3269957"
                        ],
                        "name": "A. Zilinskas",
                        "slug": "A.-Zilinskas",
                        "structuredName": {
                            "firstName": "Antanas",
                            "lastName": "Zilinskas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zilinskas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2404676"
                        ],
                        "name": "J. Zilinskas",
                        "slug": "J.-Zilinskas",
                        "structuredName": {
                            "firstName": "Julius",
                            "lastName": "Zilinskas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Zilinskas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 234,
                                "start": 205
                            }
                        ],
                        "text": "There exist several consistency proofs for this algorithm in the one-dimensional setting [Locatelli, 1997] and one for a simplification of the algorithm using simplicial partitioning in higher dimensions [Z\u030cilinskas and Z\u030cilinskas, 2002]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 120339829,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "671dd47e4aadda5e3e7020c6854cd578d69d5d4b",
            "isKey": false,
            "numCitedBy": 29,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Global-optimization-based-on-a-statistical-model-Zilinskas-Zilinskas",
            "title": {
                "fragments": [],
                "text": "Global optimization based on a statistical model and simplicial partitioning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39886803"
                        ],
                        "name": "R. Woodard",
                        "slug": "R.-Woodard",
                        "structuredName": {
                            "firstName": "Roger",
                            "lastName": "Woodard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Woodard"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 58
                            }
                        ],
                        "text": "More detailed examinations can be found in, for example, [Stein, 1999, Sasena, 2002, Diggle and Ribeiro, 2007]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 87
                            }
                        ],
                        "text": "Another important kernel for Bayesian optimization is the Mate\u0301rn kernel [Mate\u0301rn, 1960, Stein, 1999], which incorporates a smoothness parameter \u03c2 to permit greater flexibility in modelling functions:\nk(xi,xj) = 1 2\u03c2\u22121\u0393(\u03c2) (2 \u221a \u03c2 \u2016xi \u2212 xj\u2016) \u03c2 H\u03c2 (2 \u221a \u03c2 \u2016xi \u2212 xj\u2016) ,\nwhere \u0393(\u00b7) and H\u03c2(\u00b7) are the\u2026"
                    },
                    "intents": []
                }
            ],
            "corpusId": 29921342,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "c1a6bc3e20f8d0a7244211e96fdeeb59dfc7b9b0",
            "isKey": false,
            "numCitedBy": 2866,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "1 Linear Prediction.- 1.1 Introduction.- 1.2 Best linear prediction.- Exercises.- 1.3 Hilbert spaces and prediction.- Exercises.- 1.4 An example of a poor BLP.- Exercises.- 1.5 Best linear unbiased prediction.- Exercises.- 1.6 Some recurring themes.- The Matern model.- BLPs and BLUPs.- Inference for differentiable random fields.- Nested models are not tenable.- 1.7 Summary of practical suggestions.- 2 Properties of Random Fields.- 2.1 Preliminaries.- Stationarity.- Isotropy.- Exercise.- 2.2 The turning bands method.- Exercise.- 2.3 Elementary properties of autocovariance functions.- Exercise.- 2.4 Mean square continuity and differentiability.- Exercises.- 2.5 Spectral methods.- Spectral representation of a random field.- Bochner's Theorem.- Exercises.- 2.6 Two corresponding Hilbert spaces.- An application to mean square differentiability.- Exercises.- 2.7 Examples of spectral densities on 112.- Rational spectral densities.- Principal irregular term.- Gaussian model.- Triangular autocovariance functions.- Matern class.- Exercises.- 2.8 Abelian and Tauberian theorems.- Exercises.- 2.9 Random fields with nonintegrable spectral densities.- Intrinsic random functions.- Semivariograms.- Generalized random fields.- Exercises.- 2.10 Isotropic autocovariance functions.- Characterization.- Lower bound on isotropic autocorrelation functions.- Inversion formula.- Smoothness properties.- Matern class.- Spherical model.- Exercises.- 2.11 Tensor product autocovariances.- Exercises.- 3 Asymptotic Properties of Linear Predictors.- 3.1 Introduction.- 3.2 Finite sample results.- Exercise.- 3.3 The role of asymptotics.- 3.4 Behavior of prediction errors in the frequency domain.- Some examples.- Relationship to filtering theory.- Exercises.- 3.5 Prediction with the wrong spectral density.- Examples of interpolation.- An example with a triangular autocovariance function.- More criticism of Gaussian autocovariance functions.- Examples of extrapolation.- Pseudo-BLPs with spectral densities misspecified at high frequencies.- Exercises.- 3.6 Theoretical comparison of extrapolation and ointerpolation.- An interpolation problem.- An extrapolation problem.- Asymptotics for BLPs.- Inefficiency of pseudo-BLPs with misspecified high frequency behavior.- Presumed mses for pseudo-BLPs with misspecified high frequency behavior.- Pseudo-BLPs with correctly specified high frequency behavior.- Exercises.- 3.7 Measurement errors.- Some asymptotic theory.- Exercises.- 3.8 Observations on an infinite lattice.- Characterizing the BLP.- Bound on fraction of mse of BLP attributable to a set of frequencies.- Asymptotic optimality of pseudo-BLPs.- Rates of convergence to optimality.- Pseudo-BLPs with a misspecified mean function.- Exercises.- 4 Equivalence of Gaussian Measures and Prediction.- 4.1 Introduction.- 4.2 Equivalence and orthogonality of Gaussian measures.- Conditions for orthogonality.- Gaussian measures are equivalent or orthogonal.- Determining equivalence or orthogonality for periodic random fields.- Determining equivalence or orthogonality for nonperiodic random fields.- Measurement errors and equivalence and orthogonality.- Proof of Theorem 1.- Exercises.- 4.3 Applications of equivalence of Gaussian measures to linear prediction.- Asymptotically optimal pseudo-BLPs.- Observations not part of a sequence.- A theorem of Blackwell and Dubins.- Weaker conditions for asymptotic optimality of pseudo-BLPs.- Rates of convergence to asymptotic optimality.- Asymptotic optimality of BLUPs.- Exercises.- 4.4 Jeffreys's law.- A Bayesian version.- Exercises.- 5 Integration of Random Fields.- 5.1 Introduction.- 5.2 Asymptotic properties of simple average.- Results for sufficiently smooth random fields.- Results for sufficiently rough random fields.- Exercises.- 5.3 Observations on an infinite lattice.- Asymptotic mse of BLP.- Asymptotic optimality of simple average.- Exercises.- 5.4 Improving on the sample mean.- Approximating $$\\int_0^1 {\\exp } (ivt)dt$$.- Approximating $$\\int_{{{[0,1]}^d}} {\\exp (i{\\omega ^T}x)} dx$$ in more than one dimension.- Asymptotic properties of modified predictors.- Are centered systematic samples good designs?.- Exercises.- 5.5 Numerical results.- Exercises.- 6 Predicting With Estimated Parameters.- 6.1 Introduction.- 6.2 Microergodicity and equivalence and orthogonality of Gaussian measures.- Observations with measurement error.- Exercises.- 6.3 Is statistical inference for differentiable processes possible?.- An example where it is possible.- Exercises.- 6.4 Likelihood Methods.- Restricted maximum likelihood estimation.- Gaussian assumption.- Computational issues.- Some asymptotic theory.- Exercises.- 6.5 Matern model.- Exercise.- 6.6 A numerical study of the Fisher information matrix under the Matern model.- No measurement error and?unknown.- No measurement error and?known.- Observations with measurement error.- Conclusions.- Exercises.- 6.7 Maximum likelihood estimation for a periodic version of the Matern model.- Discrete Fourier transforms.- Periodic case.- Asymptotic results.- Exercises.- 6.8 Predicting with estimated parameters.- Jeffreys's law revisited.- Numerical results.- Some issues regarding asymptotic optimality.- Exercises.- 6.9 An instructive example of plug-in prediction.- Behavior of plug-in predictions.- Cross-validation.- Application of Matern model.- Conclusions.- Exercises.- 6.10 Bayesian approach.- Application to simulated data.- Exercises.- A Multivariate Normal Distributions.- B Symbols.- References."
            },
            "slug": "Interpolation-of-Spatial-Data:-Some-Theory-for-Woodard",
            "title": {
                "fragments": [],
                "text": "Interpolation of Spatial Data: Some Theory for Kriging"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This chapter discusses the role of asymptotics for BLPs, and applications of equivalence and orthogonality of Gaussian measures to linear prediction, and the importance of Observations not part of a sequence."
            },
            "venue": {
                "fragments": [],
                "text": "Technometrics"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145785256"
                        ],
                        "name": "P. Diggle",
                        "slug": "P.-Diggle",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Diggle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Diggle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153469"
                        ],
                        "name": "J. Tawn",
                        "slug": "J.-Tawn",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Tawn",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tawn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2080793"
                        ],
                        "name": "R. Moyeed",
                        "slug": "R.-Moyeed",
                        "structuredName": {
                            "firstName": "Rana",
                            "lastName": "Moyeed",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Moyeed"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 85
                            }
                        ],
                        "text": "More detailed examinations can be found in, for example, [Stein, 1999, Sasena, 2002, Diggle and Ribeiro, 2007]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 134,
                                "start": 113
                            }
                        ],
                        "text": "Note that this approach is related to, but distinct from the binomial logisticlinear model used in geostatistics [Diggle et al., 1998], in which the responses y represent the outcomes of Bernoulli trials which are conditionally independent given the model (i."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10743131,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "a1780988f2821ec1d47886aa1fbf933b675878ad",
            "isKey": false,
            "numCitedBy": 2230,
            "numCiting": 295,
            "paperAbstract": {
                "fragments": [],
                "text": "Conventional geostatistical methodology solves the problem of predicting the realized value of a linear functional of a Gaussian spatial stochastic process S(x) based on observations Yi = S(xi) + Zi at sampling locations xi, where the Zi are mutually independent, zero\u2010mean Gaussian random variables. We describe two spatial applications for which Gaussian distributional assumptions are clearly inappropriate. The first concerns the assessment of residual contamination from nuclear weapons testing on a South Pacific island, in which the sampling method generates spatially indexed Poisson counts conditional on an unobserved spatially varying intensity of radioactivity; we conclude that a conventional geostatistical analysis oversmooths the data and underestimates the spatial extremes of the intensity. The second application provides a description of spatial variation in the risk of campylobacter infections relative to other enteric infections in part of north Lancashire and south Cumbria. For this application, we treat the data as binomial counts at unit postcode locations, conditionally on an unobserved relative risk surface which we estimate. The theoretical framework for our extension of geostatistical methods is that, conditionally on the unobserved process S(x), observations at sample locations xi form a generalized linear model with the corresponding values of S(xi) appearing as an offset term in the linear predictor. We use a Bayesian inferential framework, implemented via the Markov chain Monte Carlo method, to solve the prediction problem for non\u2010linear functionals of S(x), making a proper allowance for the uncertainty in the estimation of any model parameters."
            },
            "slug": "Model\u2010based-geostatistics-Diggle-Tawn",
            "title": {
                "fragments": [],
                "text": "Model\u2010based geostatistics"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144180357"
                        ],
                        "name": "E. Brochu",
                        "slug": "E.-Brochu",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brochu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brochu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32951485"
                        ],
                        "name": "A. Ghosh",
                        "slug": "A.-Ghosh",
                        "structuredName": {
                            "firstName": "Abhijeet",
                            "lastName": "Ghosh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ghosh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 28590804,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "7d13d6ba4b1754121aed7b0622aaa65d875645b2",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "Properly modeling the appearance of a material is very important for realistic image synthesis. The appearance of a material is formalized by the notion of the Bidirectional Reflectance Distribution Function (BRDF). In computer graphics, BRDFs are most often specified using various analytical models. Analytical models that are of interest to realistic image synthesis are the ones that observe the physical laws of reciprocity and energy conservation while typically also exhibiting shadowing, masking and Fresnel reflectance phenomenon. Realistic models are hence fairly complex with many parameters that need to be adjusted by the designer for the proper material appearance. Unfortunately these parameters can interact in non-intuitive ways, and small adjustments to certain settings may result in non-uniform changes in the appearance. This can make the material design process hard for an artist or a non-expert user. To alleviate this problem, Ngan et al. [2006] recently presented an interface for navigation in a perceptually uniform BRDF space based on a metric derived from user studies. However, this is still somewhat constraining as the user has to develop an understanding of the various aspects of material appearance such as varying degrees of diffuseness, glossiness, specularity, Fresnel effects and/or anisotropy in order to navigate such an interface. An artist or a user often knows the look that he or she desires for a particular application without necessarily being interested in understanding the various subtleties of reflection! This is what we seek to address in this work with a 'preference gallery' approach to material design."
            },
            "slug": "Preference-galleries-for-material-design-Brochu-Ghosh",
            "title": {
                "fragments": [],
                "text": "Preference galleries for material design"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work seeks to address material design with a 'preference gallery' approach to material design by developing an understanding of the various aspects of material appearance such as varying degrees of diffuseness, glossiness, specularity, Fresnel effects and/or anisotropy."
            },
            "venue": {
                "fragments": [],
                "text": "SIGGRAPH '07"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3683465"
                        ],
                        "name": "D. Kahneman",
                        "slug": "D.-Kahneman",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Kahneman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kahneman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064181"
                        ],
                        "name": "A. Tversky",
                        "slug": "A.-Tversky",
                        "structuredName": {
                            "firstName": "Amos",
                            "lastName": "Tversky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Tversky"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 241,
                                "start": 215
                            }
                        ],
                        "text": "Prospect theory, for example, employs utility models based on relation to a reference point, based on evidence that the human perceptual apparatus is attuned to evaluate differences rather than absolute magnitudes [Kahneman and Tversky, 1979, Tversky and Kahneman, 1992]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 143094930,
            "fieldsOfStudy": [
                "Economics",
                "Sociology"
            ],
            "id": "b0e560b17d89fe17aa8dfe60c0fd29dc7a4d7110",
            "isKey": false,
            "numCitedBy": 882,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : The theoretical basis of decision analysis is utility theory, which describes the principles upon which people wish to base their decisions. This article questions the validity of utility theory and offers an alternative, 'prospect theory.' In addition to providing evidence in support of prospect theory, this paper discusses its implications for the theory and practice of decision analysis. It suggests, for example, ways in which subtle changes in elicitation procedure can have marked effects on people's expressed values."
            },
            "slug": "Prospect-Theory.-An-Analysis-of-Decision-Making-Kahneman-Tversky",
            "title": {
                "fragments": [],
                "text": "Prospect Theory. An Analysis of Decision Making Under Risk"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1977
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35153517"
                        ],
                        "name": "D. Lewis",
                        "slug": "D.-Lewis",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lewis",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lewis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34938639"
                        ],
                        "name": "W. Gale",
                        "slug": "W.-Gale",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Gale",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Gale"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 37
                            }
                        ],
                        "text": "This is called uncertainty sampling\n[Lewis and Gale, 1994]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 915058,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5194b668c67aa83c037e71599a087f63c98eb713",
            "isKey": false,
            "numCitedBy": 2424,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "The ability to cheaply train text classifiers is critical to their use in information retrieval, content analysis, natural language processing, and other tasks involving data which is partly or fully textual. An algorithm for sequential sampling during machine learning of statistical classifiers was developed and tested on a newswire text categorization task. This method, which we call uncertainty sampling, reduced by as much as 500-fold the amount of training data that would have to be manually classified to achieve a given level of effectiveness."
            },
            "slug": "A-sequential-algorithm-for-training-text-Lewis-Gale",
            "title": {
                "fragments": [],
                "text": "A sequential algorithm for training text classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "An algorithm for sequential sampling during machine learning of statistical classifiers was developed and tested on a newswire text categorization task and reduced by as much as 500-fold the amount of training data that would have to be manually classified to achieve a given level of effectiveness."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR '94"
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1572307727"
                        ],
                        "name": "KrauseAndreas",
                        "slug": "KrauseAndreas",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "KrauseAndreas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "KrauseAndreas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1643911390"
                        ],
                        "name": "SinghAjit",
                        "slug": "SinghAjit",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "SinghAjit",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "SinghAjit"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644051296"
                        ],
                        "name": "GuestrinCarlos",
                        "slug": "GuestrinCarlos",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "GuestrinCarlos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "GuestrinCarlos"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 224110813,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a301edf25f11440569f6f81af5902a4532b1dcb8",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "When monitoring spatial phenomena, which can often be modeled as Gaussian processes (GPs), choosing sensor locations is a fundamental task. There are several common strategies to address this task,..."
            },
            "slug": "Near-Optimal-Sensor-Placements-in-Gaussian-Theory,-KrauseAndreas-SinghAjit",
            "title": {
                "fragments": [],
                "text": "Near-Optimal Sensor Placements in Gaussian Processes: Theory, Efficient Algorithms and Empirical Studies"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper presents a meta-modelling architecture suitable for discrete-time decision-making that automates the very labor-intensive and therefore time-heavy and therefore expensive process of manually selecting sensor locations for spatial phenomena monitoring."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 150
                            }
                        ],
                        "text": "\u2026algorithms [Bertsekas and Tsitsiklis, 1996, Sutton and Barto, 1998], learning methods for Boltzmann machines and deep belief networks [Younes, 1989, Hinton and Salakhutdinov, 2006] and parameter estimation for nonlinear state space models [Poyiadjis et al., 2005, Martinez\u2013Cantin et al., 2006]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1658773,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "46eb79e5eec8a4e2b2f5652b66441e8a4c921c3e",
            "isKey": false,
            "numCitedBy": 14754,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such \u201cautoencoder\u201d networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data."
            },
            "slug": "Reducing-the-Dimensionality-of-Data-with-Neural-Hinton-Salakhutdinov",
            "title": {
                "fragments": [],
                "text": "Reducing the Dimensionality of Data with Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work describes an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data."
            },
            "venue": {
                "fragments": [],
                "text": "Science"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35112676"
                        ],
                        "name": "S. Kuhnt",
                        "slug": "S.-Kuhnt",
                        "structuredName": {
                            "firstName": "Sonja",
                            "lastName": "Kuhnt",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kuhnt"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50676519"
                        ],
                        "name": "D. Steinberg",
                        "slug": "D.-Steinberg",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Steinberg",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Steinberg"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15210862,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b617b85b5add24d55bdbd952cb5bde52b01e4869",
            "isKey": false,
            "numCitedBy": 2858,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "The design and analysis of computer experiments as a relatively young research field is not only of high importance for many industrial areas but also presents new challenges and open questions for statisticians. This editorial introduces a special issue devoted to the topic. The included papers present an interesting mixture of recent developments in the field as they cover fundamental research on the design of experiments, models and analysis methods as well as more applied research connected to real-life applications."
            },
            "slug": "Design-and-analysis-of-computer-experiments-Kuhnt-Steinberg",
            "title": {
                "fragments": [],
                "text": "Design and analysis of computer experiments"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The included papers present an interesting mixture of recent developments in the field as they cover fundamental research on the design of experiments, models and analysis methods as well as more applied research connected to real-life applications."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1877479"
                        ],
                        "name": "M. Genton",
                        "slug": "M.-Genton",
                        "structuredName": {
                            "firstName": "Marc",
                            "lastName": "Genton",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Genton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 2
                            }
                        ],
                        "text": ", [Genton, 2001] or [Rasmussen and Williams, 2006, Chapter 4] for an overview)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 173,
                                "start": 161
                            }
                        ],
                        "text": "While the squared exponential and Mate\u0301rn are the most common kernels for GPs, numerous others have been examined in the machine learning literature (see, e.g., [Genton, 2001] or [Rasmussen and Williams, 2006, Chapter 4] for an overview)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16552240,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "fb829c5e6b406bb325fa5a02e05073df12b1772b",
            "isKey": false,
            "numCitedBy": 611,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we present classes of kernels for machine learning from a statistics perspective. Indeed, kernels are positive definite functions and thus also covariances. After discussing key properties of kernels, as well as a new formula to construct kernels, we present several important classes of kernels: anisotropic stationary kernels, isotropic stationary kernels, compactly supported kernels, locally stationary kernels, nonstationary kernels, and separable nonstationary kernels. Compactly supported kernels and separable nonstationary kernels are of prime interest because they provide a computational reduction for kernel-based methods. We describe the spectral representation of the various classes of kernels and conclude with a discussion on the characterization of nonlinear maps that reduce nonstationary kernels to either stationarity or local stationarity."
            },
            "slug": "Classes-of-Kernels-for-Machine-Learning:-A-Genton",
            "title": {
                "fragments": [],
                "text": "Classes of Kernels for Machine Learning: A Statistics Perspective"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The spectral representation of the various classes of kernels is described and a discussion on the characterization of nonlinear maps that reduce nonstationary kernels to either stationarity or local stationarity is discussed."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118096690"
                        ],
                        "name": "Donald R. Jones",
                        "slug": "Donald-R.-Jones",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Jones",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donald R. Jones"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 205
                            }
                        ],
                        "text": "Bayesian optimization techniques are some of the most efficient approaches in terms of the number of function evaluations required (see, e.g. [Moc\u030ckus, 1994, Jones et al., 1998, Streltsov and Vakili, 1999, Jones, 2001, Sasena, 2002])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 125
                            }
                        ],
                        "text": "Several researchers have studied the empirical impact of different values of \u03be in different domains [To\u0308rn and Z\u030cilinskas, 1989, Jones, 2001, Lizotte, 2008]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8723392,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "a3db48fdc9aaf6921f269817ba4ed16b9b198394",
            "isKey": false,
            "numCitedBy": 1873,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a taxonomy of existing approaches for using response surfaces for global optimization. Each method is illustrated with a simple numerical example that brings out its advantages and disadvantages. The central theme is that methods that seem quite reasonable often have non-obvious failure modes. Understanding these failure modes is essential for the development of practical algorithms that fulfill the intuitive promise of the response surface approach."
            },
            "slug": "A-Taxonomy-of-Global-Optimization-Methods-Based-on-Jones",
            "title": {
                "fragments": [],
                "text": "A Taxonomy of Global Optimization Methods Based on Response Surfaces"
            },
            "tldr": {
                "abstractSimilarityScore": 93,
                "text": "This paper presents a taxonomy of existing approaches for using response surfaces for global optimization, illustrating each method with a simple numerical example that brings out its advantages and disadvantages."
            },
            "venue": {
                "fragments": [],
                "text": "J. Glob. Optim."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2504392"
                        ],
                        "name": "C. Kubrusly",
                        "slug": "C.-Kubrusly",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Kubrusly",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Kubrusly"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103381634"
                        ],
                        "name": "J. Gravier",
                        "slug": "J.-Gravier",
                        "structuredName": {
                            "firstName": "Julie",
                            "lastName": "Gravier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gravier"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 116
                            }
                        ],
                        "text": "Stochastic approximation is a popular idea for optimizing unknown objective functions in machine learning contexts [Kushner and Yin, 1997]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121825892,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "771a09f35664dfc0f57c844e80816008cf3ecd71",
            "isKey": false,
            "numCitedBy": 549,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This study presents the conditions of applicability of stochastic approximation algorithms that minimize a mean-square error criterion for identification of a linear discrete-time stationary system without dynamical numerator. The acceleration of the convergence is discussed. Then a tentative is outlined to overcome the previous requirement of states accessibility."
            },
            "slug": "Stochastic-approximation-algorithms-and-Kubrusly-Gravier",
            "title": {
                "fragments": [],
                "text": "Stochastic approximation algorithms and applications"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "The conditions of applicability of stochastic approximation algorithms that minimize a mean-square error criterion for identification of a linear discrete-time stationary system without dynamical numerator are presented."
            },
            "venue": {
                "fragments": [],
                "text": "CDC 1973"
            },
            "year": 1973
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47976263"
                        ],
                        "name": "F. Mosteller",
                        "slug": "F.-Mosteller",
                        "structuredName": {
                            "firstName": "Frederick",
                            "lastName": "Mosteller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Mosteller"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 156
                            }
                        ],
                        "text": "This model, relating binary observations to a continuous latent function, is known as the ThurstoneMosteller law of comparative judgement [Thurstone, 1927, Mosteller, 1951]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 186234417,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "3fc81fd639098d2efb0533c7ff75910c751721bf",
            "isKey": false,
            "numCitedBy": 270,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "Thurstone's Case V of the method of paired comparisons assumes equal standard deviations of sensations corresponding to stimuli and zero correlations between pairs of stimuli sensations. It is shown that the assumption of zero correlations can be relaxed to an assumption of equal correlations between pairs with no change in method. Further the usual approach to the method of paired comparisons Case V is shown to lead to a least squares estimate of the stimulus positions on the sensation scale."
            },
            "slug": "Remarks-on-the-method-of-paired-comparisons:-I.-The-Mosteller",
            "title": {
                "fragments": [],
                "text": "Remarks on the method of paired comparisons: I. The least squares solution assuming equal standard deviations and equal correlations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1951
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1990795"
                        ],
                        "name": "J. Payne",
                        "slug": "J.-Payne",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Payne",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Payne"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38028485"
                        ],
                        "name": "J. Bettman",
                        "slug": "J.-Bettman",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bettman",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bettman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148773395"
                        ],
                        "name": "Eric J. Johnson",
                        "slug": "Eric-J.-Johnson",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Johnson",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric J. Johnson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 278
                            }
                        ],
                        "text": "\u2026animation on a numerical scale has built-in problems\u2014not only will scales vary from user to user, but human evaluation is subject to phenomena such as drift, where the scale varies over time, anchoring, in which early experiences dominate the scale [Siegel and Castellan, 1988, Payne et al., 1993]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 62541141,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "b6fe97fc23a8031510cce4af5f60e407d848b83d",
            "isKey": false,
            "numCitedBy": 4061,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Preface 1. Adaptive decision behaviour: an introduction 2. Contingencies in decision making 3. Deciding how to decide: an effort/accuracy framework 4. Studying contingent decisions: an integrated methodology 5. Constructive processes in decision making 6. Why may adaptivity fail? 7. Improving decisions and other practical matters 8. The adaptive decision maker: a look backward and a look forward Appendix Footnotes Bibliography."
            },
            "slug": "The-adaptive-decision-maker-Payne-Bettman",
            "title": {
                "fragments": [],
                "text": "The adaptive decision maker"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The adaptive decision maker: a look backward and a look forward Appendix Footnotes Bibliography."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "97301357"
                        ],
                        "name": "F. David",
                        "slug": "F.-David",
                        "structuredName": {
                            "firstName": "F.",
                            "lastName": "David",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. David"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "92448292"
                        ],
                        "name": "S. Siegel",
                        "slug": "S.-Siegel",
                        "structuredName": {
                            "firstName": "Sidney",
                            "lastName": "Siegel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Siegel"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 276,
                                "start": 250
                            }
                        ],
                        "text": "\u2026animation on a numerical scale has built-in problems\u2014not only will scales vary from user to user, but human evaluation is subject to phenomena such as drift, where the scale varies over time, anchoring, in which early experiences dominate the scale [Siegel and Castellan, 1988, Payne et al., 1993]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 124165178,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "53b9b242f8cb2007e8e3dd9db5cd11b88fa6c4a7",
            "isKey": false,
            "numCitedBy": 33744,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This is the revision of the classic text in the field, adding two new chapters and thoroughly updating all others. The original structure is retained, and the book continues to serve as a combined text/reference."
            },
            "slug": "Nonparametric-Statistics-for-the-Behavioral-David-Siegel",
            "title": {
                "fragments": [],
                "text": "Nonparametric Statistics for the Behavioral Sciences."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1956
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66297967"
                        ],
                        "name": "R. Forthofer",
                        "slug": "R.-Forthofer",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Forthofer",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Forthofer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37381182"
                        ],
                        "name": "R. Lehnen",
                        "slug": "R.-Lehnen",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Lehnen",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Lehnen"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 179
                            }
                        ],
                        "text": "By presenting two or more realizations to a user and requiring only that they indicate preference, we can get far more robust results with much less cognitive burden on the user [Kendall, 1975]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 120895672,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "6094f4c6ed65e2e46dc57e2bd7a3cb10e7ed2199",
            "isKey": false,
            "numCitedBy": 4564,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Rank correlation coefficients are statistical indices that measure the degree of association between two variables having ordered categories. Some well-known rank correlation coefficients are those proposed by Goodman and Kruskal (1954, 1959), Kendall (1955), and Somers (1962). Rank correlation methods share several common features. They are based on counts and are defined such that a coefficient of zero means \u201cno association\u201d between the variables and a value of +1.0 or -1.0 means \u201cperfect agreement\u201d or \u201cperfect inverse agreement,\u201d respectively."
            },
            "slug": "Rank-Correlation-Methods-Forthofer-Lehnen",
            "title": {
                "fragments": [],
                "text": "Rank Correlation Methods"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1981
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144500726"
                        ],
                        "name": "A. Karimi",
                        "slug": "A.-Karimi",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Karimi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Karimi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8591486,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "79c24e7d31afe659fd42f5a72f8547bc83c49501",
            "isKey": false,
            "numCitedBy": 4781,
            "numCiting": 411,
            "paperAbstract": {
                "fragments": [],
                "text": "Web mediated communications revolutionized traditional social interactions. It is designed to facilitate information exchange between individuals and to enable people to connect with friends, family, classmates etc. virtually. By the formation of virtual communities, \u201cweb mediated communication\u201d is defined as a wider concept known as \u201csocial media\u201d. Social media enhances the volume of communications and interpersonal interactions based on the power of web 2.0 technology. People join to the virtual communities of online social networks to procure information from everywhere, share ideas, experiences, photos, videos and memorable moments while extending friendships beyond the geographical and cultural borders. The emergence and fast growth of social media among people added value to the web activities and convinced web masters to integrate web services such as e-mail, chat, discussion rooms, forums and third party applications to the social media web sites. Many of social media web sites are hosting millions of members, equipping their web sites with communication tools, sharing options, dynamic content creation and collaborative authoring facilities which never experienced before. Facebook, Twitter and GooglePlus are examples of most known social media web sites which gained popularity among people so fast. Social media helps people to make new friends, find lost friends and old classmates while providing an opportunity to build new friendships. This new communication technology empowers people to collaborate in authoring of the web content and causes the information sharing synergy. Such positive aspects are enough for people to ignore the consequences of joining social media. Despite the rise of friendships in number, the physical encounters are substituted by virtual ones which causes weak friendship ties. In addition, social media platforms promise the security and privacy of users, but issues such as identity theft and worm attacks threaten users' privacy and security. Social media is in its infancy, adopted among people for less than a decade whereas a lack of research in this field is evident. The author of this thesis aimed at filling this gap by investigating the positive and negative effects of using social media through collecting the users' experiences and professionals' viewpoints. Theoretical study primarily illuminated the main positive and negative aspects while the findings of empirical research verified by theoretical study identified other practical effects and aspects of social media."
            },
            "slug": "MASTER\u2019S-THESIS-Karimi",
            "title": {
                "fragments": [],
                "text": "MASTER\u2019S THESIS"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The author of this thesis aimed at investigating the positive and negative effects of using social media through collecting the users' experiences and professionals' viewpoints, and identified other practical effects and aspects of social media."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056561346"
                        ],
                        "name": "Leonzio Rizzo",
                        "slug": "Leonzio-Rizzo",
                        "structuredName": {
                            "firstName": "Leonzio",
                            "lastName": "Rizzo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Leonzio Rizzo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2094744078"
                        ],
                        "name": "Stefano Bonnini",
                        "slug": "Stefano-Bonnini",
                        "structuredName": {
                            "firstName": "Stefano",
                            "lastName": "Bonnini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stefano Bonnini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2175070255"
                        ],
                        "name": "Prof.ssa Emidia Vagnoni",
                        "slug": "Prof.ssa-Emidia-Vagnoni",
                        "structuredName": {
                            "firstName": "Prof.ssa",
                            "lastName": "Vagnoni",
                            "middleNames": [
                                "Emidia"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Prof.ssa Emidia Vagnoni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2083292251"
                        ],
                        "name": "E. Vagnoni",
                        "slug": "E.-Vagnoni",
                        "structuredName": {
                            "firstName": "Emidia",
                            "lastName": "Vagnoni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Vagnoni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2080812501"
                        ],
                        "name": "Caterina Cavicchi",
                        "slug": "Caterina-Cavicchi",
                        "structuredName": {
                            "firstName": "Caterina",
                            "lastName": "Cavicchi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Caterina Cavicchi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 131
                            }
                        ],
                        "text": "3An empirical study of various methods on a variety of test functions, and a discussion of why these were selected can be found in [Brochu et al., 2007a]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 239070348,
            "fieldsOfStudy": [
                "Chemistry",
                "Engineering"
            ],
            "id": "333510ba64fc7bbc0c7f93f9a098299f882f0d13",
            "isKey": false,
            "numCitedBy": 5804,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "m LIK arreci of aiuminum powder i n d:unping solid propellant instability had been investigated in a vortex burner developed previously. was composed of a main chamber having a shallow center-perforated grain and a hot gas generator. The generator fed combustion gases tangentially into the main chamber causin& transverse mode com- bustion instability. Aluminum powder was added either t o the main propellant or t o the gas gener- ator charge. Measurement of the amplitude of the pressure oscillations indicated the effectiveness of the metal acting (1) as an ingredient a t the solid surface and i n the gas phase and (2) in t h e , gas phase only. In the absenre of aluminum the rombui-tor was unstable, exhihicing an oscillation frequency of 3800 cps with a peak-to-peak amplitude ci' 55 percent. The addition of fine aluminum powder t o the propellant i n the main chamber was sufficient t o damp out the high-frequency instabil- ity. Addition of aluminum t o the gas generator propellant only was also effective i n eliminating instability provided that an eqi'i.valent concentration of metal particles was addd. It was con- cluded that the addition of aluminum powder t o solid propellants suppresses instability by acting as an attenuator of sound i n the gas phase rather than altering the driving or response of the pro- pellants. Viscous damping is inferred t o be the principal damping mechanism. of the alu- produced a nonacoustic disturbance which ap-peared t o be eliminated a t hig sures ."
            },
            "slug": "[N]-Rizzo-Bonnini",
            "title": {
                "fragments": [],
                "text": "[N]"
            },
            "venue": {
                "fragments": [],
                "text": "Diccionario para opositores."
            },
            "year": 1857
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "123242656"
                        ],
                        "name": "A. Hanks",
                        "slug": "A.-Hanks",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Hanks",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hanks"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 216112094,
            "fieldsOfStudy": [
                "Political Science"
            ],
            "id": "90315d5929b1f147f565bc18e0a01d7fdfeb2e74",
            "isKey": false,
            "numCitedBy": 977,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract Canada allowed the cultivation and processing of industrial hemp in 1998. This decision was seen as a political dream: \u201cwin win\u201d for everyone. There was very little opposition to the idea of industrial hemp: the biggest obstacle was government foot-dragging on the issue. Great expectations were raised then. Now 5 years in, many of these expectations have not been met and the cautious have been vindicated. The growth of the hemp sector has been modest and hemp has proven not to be immune to the struggles typical of any new industry."
            },
            "slug": "Canada-Hanks",
            "title": {
                "fragments": [],
                "text": "Canada"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059901706"
                        ],
                        "name": "J. Glynn",
                        "slug": "J.-Glynn",
                        "structuredName": {
                            "firstName": "Jerry",
                            "lastName": "Glynn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Glynn"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 70
                            }
                        ],
                        "text": "However, sequential design is an important and active subfield (e.g. [Williams et al., 2000, Busby, 2009]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 107
                            }
                        ],
                        "text": "The simplest transformation arises when f(x) is corrupted with Gaussian noise \u223c N (0, \u03c32noise) [Rasmussen and Williams, 2006]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 201,
                                "start": 193
                            }
                        ],
                        "text": "While the squared exponential and Mate\u0301rn are the most common kernels for GPs, numerous others have been examined in the machine learning literature (see, e.g., [Genton, 2001] or [Rasmussen and Williams, 2006, Chapter 4] for an overview)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 167
                            }
                        ],
                        "text": ":[\nf1:t ft+1\n] \u223c N ( 0, [ K k kT k(xt+1,xt+1) ]) ,\nwhere k = [ k(xt+1,x1) k(xt+1,x2) \u00b7 \u00b7 \u00b7 k(xt+1,xt) ] Using the Sherman-Morrison-Woodbury formula (see, e.g., [Rasmussen and Williams, 2006, Press et al., 2007]), one can easily arrive at an expression for the predictive distribution:\nP (ft+1|D1:t,xt+1) = N ( \u00b5t(xt+1), \u03c3 2 t (xt+1) ) where\n\u00b5t(xt+1) = k TK\u22121f1:t \u03c32t (xt+1) = k(xt+1,xt+1)\u2212 kTK\u22121k."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 221,
                                "start": 213
                            }
                        ],
                        "text": "Typically, the hyperparameter values are learned by \u201cseeding\u201d with a few random samples and maximizing the log-likelihood of the evidence given \u03b8 [Jones et al., 1998, Sasena, 2002, Santner et al., 2003, Rasmussen and Williams, 2006]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 168
                            }
                        ],
                        "text": "For anisotropic models, a very popular choice is the squared exponential kernel with a vector of automatic relevance determination (ARD) hyperparameters \u03b8\n[Rasmussen and Williams, 2006, page 106]: k(xi,xj) = exp ( \u2212 12 (xi \u2212 xj) T diag(\u03b8)\u22122(x\u2212 x\u2032) ) ,\nwhere diag(\u03b8) is a diagonal matrix with d entries \u03b8 along the diagonal."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 138
                            }
                        ],
                        "text": "\u2026]) ,\nwhere k = [ k(xt+1,x1) k(xt+1,x2) \u00b7 \u00b7 \u00b7 k(xt+1,xt) ] Using the Sherman-Morrison-Woodbury formula (see, e.g., [Rasmussen and Williams, 2006, Press et al., 2007]), one can easily arrive at an expression for the predictive distribution:\nP (ft+1|D1:t,xt+1) = N ( \u00b5t(xt+1), \u03c3 2 t (xt+1)\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 61275972,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "16b4fd36ff5ca603fed13a326054cd0373ea442c",
            "isKey": true,
            "numCitedBy": 6115,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Numerical-Recipes:-The-Art-of-Scientific-Computing-Glynn",
            "title": {
                "fragments": [],
                "text": "Numerical Recipes: The Art of Scientific Computing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9421473"
                        ],
                        "name": "M. Sasena",
                        "slug": "M.-Sasena",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Sasena",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sasena"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 230,
                                "start": 218
                            }
                        ],
                        "text": "Bayesian optimization techniques are some of the most efficient approaches in terms of the number of function evaluations required (see, e.g. [Moc\u030ckus, 1994, Jones et al., 1998, Streltsov and Vakili, 1999, Jones, 2001, Sasena, 2002])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 71
                            }
                        ],
                        "text": "More detailed examinations can be found in, for example, [Stein, 1999, Sasena, 2002, Diggle and Ribeiro, 2007]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 163
                            }
                        ],
                        "text": "Typically, the hyperparameter values are learned by \u201cseeding\u201d with a few random samples and maximizing the log-likelihood of the evidence given \u03b8 [Jones et al., 1998, Sasena, 2002, Santner et al., 2003, Rasmussen and Williams, 2006]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 147
                            }
                        ],
                        "text": "\u2026has evolved a body of work devoted to extending the algorithm, particularly in adding constraints to the optimization problem [Audet et al., 2000, Sasena, 2002, Boyle, 2007], and in modelling noisy functions [Bartz-Beielstein et al., 2005, Huang et al., 2006, Hutter et al., 2009, Hutter, 2009]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 114321095,
            "fieldsOfStudy": [
                "Engineering"
            ],
            "id": "161f2209b23354b0f628de40c063f69511bdecb2",
            "isKey": true,
            "numCitedBy": 390,
            "numCiting": 96,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Flexibility-and-efficiency-enhancements-for-global-Sasena",
            "title": {
                "fragments": [],
                "text": "Flexibility and efficiency enhancements for constrained global design optimization with kriging approximations."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 102,
                                "start": 81
                            }
                        ],
                        "text": "2 describes an extended Taxi domain, running under The Open Racing Car Simulator [Wymann et al., 2009], a 3D game engine that implements complex vehicle dynamics complete with manual and automatic transmission, engine, clutch, tire, suspension and aerodynamic models."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 61
                            }
                        ],
                        "text": "Section 4.2 describes an extended Taxi domain, running under The Open Racing Car Simulator [Wymann et al., 2009], a 3D game engine that implements complex vehicle dynamics complete with manual and automatic transmission, engine, clutch, tire, suspension and aerodynamic models."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and C"
            },
            "venue": {
                "fragments": [],
                "text": "Alexopoulos. The open racing car simulator (http://torcs.sourceforge.net/)"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 283,
                                "start": 269
                            }
                        ],
                        "text": "At the same time, a large, related body of work emerged under the name kriging (\u00a72.6), in honour of the South African student who developed this technique at the University of the Witwatersrand [Krige, 1951], though largely popularized by Matheron and colleagues (e.g. [Matheron, 1971])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The theory of regionalized variables and its applications"
            },
            "venue": {
                "fragments": [],
                "text": "Cahier du Centre de Morphologie Mathematique, Ecoles des Mines"
            },
            "year": 1971
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 39
                            }
                        ],
                        "text": "This was first published in English as [Mo\u010dkus et al., 1978]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 40
                            }
                        ],
                        "text": "This was first published in English as [Moc\u030ckus et al., 1978]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 165,
                                "start": 146
                            }
                        ],
                        "text": "\u2026exp ( \u2212 (\u00b5(x)\u2212 f(x +)\u2212 I)2 2\u03c32(x) ) d I\n= \u03c3(x)\n[ \u00b5(x)\u2212 f(x+)\n\u03c3(x) \u03a6\n( \u00b5(x)\u2212 f(x+)\n\u03c3(x)\n) + \u03c6 ( \u00b5(x)\u2212 f(x+)\n\u03c3(x) )] The expected improvement can be evaluated analytically [Moc\u030ckus et al., 1978,\nJones et al., 1998], yielding:\nEI(x) = { (\u00b5(x)\u2212 f(x+))\u03a6(Z) + \u03c3(x)\u03c6(Z) if \u03c3(x) > 0 0 if \u03c3(x) = 0\n(3)\nZ\u2026"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Toward Global Optimization"
            },
            "venue": {
                "fragments": [],
                "text": "volume 2, chapter The Application of Bayesian Methods for Seeking the Extremum, pages 117\u2013128. Elsevier"
            },
            "year": 1978
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144180357"
                        ],
                        "name": "E. Brochu",
                        "slug": "E.-Brochu",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Brochu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Brochu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "28552618"
                        ],
                        "name": "M. Hoffman",
                        "slug": "M.-Hoffman",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hoffman",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hoffman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 194,
                                "start": 174
                            }
                        ],
                        "text": "For convenience, we assume here that the prior mean is the zero func-\ntion m(x) = 0; alternative priors for the mean can be found in, for example [Martinez\u2013Cantin et al., 2009, Brochu et al., 2010a]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 116
                            }
                        ],
                        "text": "Methods of learning these values more efficiently is currently an active subfield of research (e.g. [Osborne, 2010, Brochu et al., 2010a])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 50,
                                "start": 30
                            }
                        ],
                        "text": "The techniques introduced in [Brochu et al., 2010b] could also be applied to model selection, though that is outside the scope of this tutorial."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 4
                            }
                        ],
                        "text": "In [Brochu et al., 2010a], we discuss how model selection can be performed using models believed to be similar."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 20815100,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bc43fe43e026d98943c739dc841adbda08c66027",
            "isKey": false,
            "numCitedBy": 4,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Hedging-Strategies-for-Bayesian-Optimization-Brochu-Hoffman",
            "title": {
                "fragments": [],
                "text": "Hedging Strategies for Bayesian Optimization"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2210196"
                        ],
                        "name": "J. Mockus",
                        "slug": "J.-Mockus",
                        "structuredName": {
                            "firstName": "Jonas",
                            "lastName": "Mockus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Mockus"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 279,
                                "start": 267
                            }
                        ],
                        "text": "\u2026the risk (defined as the expected deviation from the global minimum at a fixed point x); and (ii) conditional variance converges to zero (or appropriate positive minimum value in the presence of noise) if and only if the distance to the nearest observation is zero [Moc\u030ckus, 1982, Moc\u030ckus, 1994]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 119855746,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "701d221508f65926edf214d07b43f7fc38131665",
            "isKey": false,
            "numCitedBy": 286,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Bayesian-approach-to-global-optimization-Mockus",
            "title": {
                "fragments": [],
                "text": "The Bayesian approach to global optimization"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2296285"
                        ],
                        "name": "J. Aplevich",
                        "slug": "J.-Aplevich",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Aplevich",
                            "middleNames": [
                                "Dwight"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Aplevich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 116
                            }
                        ],
                        "text": "However, Gaussian process (GP) priors for Bayesian optimization date back at least to the late 1970s [O\u2019Hagan, 1978, Z\u030cilinskas, 1980]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 64214591,
            "fieldsOfStudy": [
                "Sociology"
            ],
            "id": "3f2f124827155478bd8c760307ad8bf527f70e0a",
            "isKey": false,
            "numCitedBy": 434,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Lecture-notes-in-control-and-information-sciences-Aplevich",
            "title": {
                "fragments": [],
                "text": "Lecture notes in control and information sciences"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3085659"
                        ],
                        "name": "H. Kushner",
                        "slug": "H.-Kushner",
                        "structuredName": {
                            "firstName": "Harold",
                            "lastName": "Kushner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Kushner"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62599010,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "64c0650c3c559e540ad7fb73c4deadf340da474b",
            "isKey": false,
            "numCitedBy": 802,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-New-Method-of-Locating-the-Maximum-Point-of-an-in-Kushner",
            "title": {
                "fragments": [],
                "text": "A New Method of Locating the Maximum Point of an Arbitrary Multipeak Curve in the Presence of Noise"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1963
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 167
                            }
                        ],
                        "text": "A number of approaches exist for this kind of global optimization and have been well-studied in the literature (e.g., [To\u0308rn and Z\u030cilinskas, 1989, Mongeau et al., 1998, Liberti and Maculan, 2006, Zhigljavsky and Z\u030cilinskas, 2008])."
                    },
                    "intents": []
                }
            ],
            "corpusId": 217504299,
            "fieldsOfStudy": [],
            "id": "5ef87a84be5e94abfda2dc0c6480995f49b002b3",
            "isKey": false,
            "numCitedBy": 1693,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Editors",
            "title": {
                "fragments": [],
                "text": "Editors"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3833091"
                        ],
                        "name": "H. Aaron",
                        "slug": "H.-Aaron",
                        "structuredName": {
                            "firstName": "Henry",
                            "lastName": "Aaron",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Aaron"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "118934010"
                        ],
                        "name": "Harvey Galper",
                        "slug": "Harvey-Galper",
                        "structuredName": {
                            "firstName": "Harvey",
                            "lastName": "Galper",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Harvey Galper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98740523"
                        ],
                        "name": "J. Pechman",
                        "slug": "J.-Pechman",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Pechman",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Pechman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34607519"
                        ],
                        "name": "G. Perry",
                        "slug": "G.-Perry",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Perry",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Perry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11974074"
                        ],
                        "name": "A. Rivlin",
                        "slug": "A.-Rivlin",
                        "structuredName": {
                            "firstName": "Alice",
                            "lastName": "Rivlin",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Rivlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "100637059"
                        ],
                        "name": "C. Schultze",
                        "slug": "C.-Schultze",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Schultze",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schultze"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 37
                            }
                        ],
                        "text": "Daniel McFadden\u2019s Nobel Prize speech [McFadden, 2001] provides a glimpse of this history."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 236168383,
            "fieldsOfStudy": [
                "Economics"
            ],
            "id": "bf30b589f246b47151e7e8bd07a402edb84db91d",
            "isKey": false,
            "numCitedBy": 742,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Economic-Choices-Aaron-Galper",
            "title": {
                "fragments": [],
                "text": "Economic Choices"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 3
                            }
                        ],
                        "text": "In [Brochu et al., 2010a], we discuss how model selection can be performed using models believed to be similar."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and N"
            },
            "venue": {
                "fragments": [],
                "text": "de Freitas. Preference galleries for material design. In ACM SIGGRAPH 2007 Posters, page 105"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 93
                            }
                        ],
                        "text": "They have been studied extensively, for example, in rating chess players, and the Elo system [\u00c9l\u0151, 1978] was adopted by the World Chess Federation FIDE to model the probability of one player beating another."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 94
                            }
                        ],
                        "text": "They have been studied extensively, for example, in rating chess players, and the Elo system [E\u0301lo\u030b, 1978] was adopted by the World Chess Federation FIDE to model the probability of one player beating another."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Rating of Chess Players: Past and Present"
            },
            "venue": {
                "fragments": [],
                "text": "Arco Publishing, New York"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 145
                            }
                        ],
                        "text": "\u2026learning algorithms [Bertsekas and Tsitsiklis, 1996, Sutton and Barto, 1998], learning methods for Boltzmann machines and deep belief networks [Younes, 1989, Hinton and Salakhutdinov, 2006] and parameter estimation for nonlinear state space models [Poyiadjis et al., 2005, Martinez\u2013Cantin et\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Parameter estimation for imperfectly observed Gibbsian fields"
            },
            "venue": {
                "fragments": [],
                "text": "Prob. Theory and Rel. fields, 82:625\u2013645"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "T\u00f6rn and\u017dilinskas, 1989] A. T\u00f6rn and A.\u017dilinskas. Global Optimization"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Neuro-Dynamic Programming. Athena Scientific"
            },
            "venue": {
                "fragments": [],
                "text": "Neuro-Dynamic Programming. Athena Scientific"
            },
            "year": 1996
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Wymann, C. Dimitrakakis, and C. Alexopoulos. The open racing car simulator"
            },
            "venue": {
                "fragments": [],
                "text": "Wymann, C. Dimitrakakis, and C. Alexopoulos. The open racing car simulator"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Preference uncertainty, preference refinement and paired comparison choice experiments"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1975
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stochastic Global Optimization. Springer Optimization and Its Applications"
            },
            "venue": {
                "fragments": [],
                "text": "\u017dilinskas and J.\u017dilinskas. Global optimization based on a statistical model and simplical partitioning"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Parameter estimation for imperfectly observed Gibbsian fields. Prob. Theory and Rel. fields"
            },
            "venue": {
                "fragments": [],
                "text": "Parameter estimation for imperfectly observed Gibbsian fields. Prob. Theory and Rel. fields"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Toward Global Optimization , volume 2, chapter The Application of Bayesian Methods for Seeking the Extremum"
            },
            "venue": {
                "fragments": [],
                "text": "Toward Global Optimization , volume 2, chapter The Application of Bayesian Methods for Seeking the Extremum"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 106
                            }
                        ],
                        "text": "Probability models for learning from discrete choices have a long history in psychology and econometrics [Thurstone, 1927, McFadden, 1980, Stern, 1990]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 139
                            }
                        ],
                        "text": "This model, relating binary observations to a continuous latent function, is known as the ThurstoneMosteller law of comparative judgement [Thurstone, 1927, Mosteller, 1951]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A law of comparative judgement"
            },
            "venue": {
                "fragments": [],
                "text": "Psychological Review, 34:273\u2013286"
            },
            "year": 1927
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 105
                            }
                        ],
                        "text": "For example, it is possible to derive analytical expressions for the two-step ahead expected improvement [Ginsbourger et al., 2008] and multistep Bayesian optimization [Garnett et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and L"
            },
            "venue": {
                "fragments": [],
                "text": "Carraro. A Multipoints Criterion for Deterministic Parallel Global Optimization based on Gaussian Processes."
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 153
                            }
                        ],
                        "text": "When carrying out direct policy search [Ng and Jordan, 2000], the Bayesian optimization approach has several advantages over the policy gradients method [Baxter and Bartlett, 2001]: it is derivative free, it is less prone to be caught in"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 175,
                                "start": 150
                            }
                        ],
                        "text": "\u2026carrying out direct policy search [Ng and Jordan, 2000], the Bayesian optimization approach has several advantages over the policy gradients method [Baxter and Bartlett, 2001]: it is derivative free, it is less prone to be caught in\nthe first local minimum, and it is explicitly designed to\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Infinite-horizon policygradient estimation"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Artificial Intelligence Research, 15:319\u2013350"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On curve fitting and optimal design for regression"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of the Royal Statistical Society B"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Mat\u00e9rn, 1960] B. Mat\u00e9rn. Spatial Variation"
            },
            "venue": {
                "fragments": [],
                "text": "Mat\u00e9rn, 1960] B. Mat\u00e9rn. Spatial Variation"
            },
            "year": 1960
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Rating of Chess Players: Past and Present"
            },
            "venue": {
                "fragments": [],
                "text": "The Rating of Chess Players: Past and Present"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "T\u00f6rn andand\u02c7and\u017dilinskas T\u00f6rn and A. \u02c7 Zilinskas. Global Optimization"
            },
            "venue": {
                "fragments": [],
                "text": "T\u00f6rn andand\u02c7and\u017dilinskas T\u00f6rn and A. \u02c7 Zilinskas. Global Optimization"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A law of comparative judgement. Psychological Review"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1927
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 153
                            }
                        ],
                        "text": "It is also possible to resample potential incumbents to get more reliable estimates of the values in a noisy environment [Bartz-Beielstein et al., 2005, Huang et al., 2006, Hutter et al., 2009], a process sometimes called intensification."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 258,
                                "start": 240
                            }
                        ],
                        "text": "\u2026has evolved a body of work devoted to extending the algorithm, particularly in adding constraints to the optimization problem [Audet et al., 2000, Sasena, 2002, Boyle, 2007], and in modelling noisy functions [Bartz-Beielstein et al., 2005, Huang et al., 2006, Hutter et al., 2009, Hutter, 2009]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "34(3):441\u2013466"
            },
            "venue": {
                "fragments": [],
                "text": "March"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "94(7):1183\u20131193"
            },
            "venue": {
                "fragments": [],
                "text": "July"
            },
            "year": 2009
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Model-Based Geostatistics. Springer Series in Statistics"
            },
            "venue": {
                "fragments": [],
                "text": "Model-Based Geostatistics. Springer Series in Statistics"
            },
            "year": 2007
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 100
                            }
                        ],
                        "text": "However, human beings do excel at comparing options and expressing a preference for one over others [Kingsley, 2006]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "preference refinement and paired comparison choice experiments"
            },
            "venue": {
                "fragments": [],
                "text": "Working Paper 06-06, Center for Economic Analysis, University of Colorado at Boulder,"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 102
                            }
                        ],
                        "text": "However, Gaussian process (GP) priors for Bayesian optimization date back at least to the late 1970s [O\u2019Hagan, 1978, Z\u030cilinskas, 1980]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "On curve fitting and optimal design for regression"
            },
            "venue": {
                "fragments": [],
                "text": "[O\u2019Hagan,"
            },
            "year": 1978
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 51
                            }
                        ],
                        "text": "An excellent recent overview of active learning is [Settles, 2010]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Computer Science Technical Report 1648"
            },
            "venue": {
                "fragments": [],
                "text": "University of Wisconsin-Madison, January"
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 58
                            }
                        ],
                        "text": "In fact, such choice is known as the Bradley-Terry model [Stern, 1990]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 139
                            }
                        ],
                        "text": "Probability models for learning from discrete choices have a long history in psychology and econometrics [Thurstone, 1927, McFadden, 1980, Stern, 1990]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A continuum of paired comparison models"
            },
            "venue": {
                "fragments": [],
                "text": "Biometrika, 77:265\u2013273"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Automating the Configuration of Algorithms for Solving Hard Computational Problems"
            },
            "venue": {
                "fragments": [],
                "text": "Canada"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 3
                            }
                        ],
                        "text": "In [Brochu et al., 2010a], we discuss how model selection can be performed using models believed to be similar."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and N"
            },
            "venue": {
                "fragments": [],
                "text": "de Freitas. A Bayesian interactive optimization approach to procedural animation design. In Eurographics/ ACM SIGGRAPH Symposium on Computer Animation"
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stochastic Global Optimization. Springer Optimization and Its Applications Global optimization based on a statistical model and simplical partitioning"
            },
            "venue": {
                "fragments": [],
                "text": "Computers and Mathematics with Applications"
            },
            "year": 2002
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Preference uncertainty, preference refinement and paired comparison choice experiments. Working Paper 06-06"
            },
            "venue": {
                "fragments": [],
                "text": "Preference uncertainty, preference refinement and paired comparison choice experiments. Working Paper 06-06"
            },
            "year": 2006
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 45,
            "methodology": 50
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 129,
        "totalPages": 13
    },
    "page_url": "https://www.semanticscholar.org/paper/A-Tutorial-on-Bayesian-Optimization-of-Expensive-to-Brochu-Cora/cd5a26b89f0799db1cbc1dff5607cb6815739fe7?sort=total-citations"
}