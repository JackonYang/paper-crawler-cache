{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686527"
                        ],
                        "name": "Vincent Loechner",
                        "slug": "Vincent-Loechner",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Loechner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Loechner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143860773"
                        ],
                        "name": "D. Wilde",
                        "slug": "D.-Wilde",
                        "structuredName": {
                            "firstName": "Doran",
                            "lastName": "Wilde",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Wilde"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The algorithm for the actual vertex enumeration is essentially that of [19], but the corresponding chamber decomposition is implemented much more efficiently."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14186123,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29e11e1da9dc40b727ea481a8b225eb5a98d463d",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Algorithms specified for parametrically sized problems are more general purpose and more reusable than algorithms for fixed sized problems. For this reason, there is a need for representing and symbolically analyzing linearly parameterized algorithms. An important class of parallel algorithms can be described as systems of parameterized affine recurrence equations (PARE). In this representation, linearly parameterized polyhedra are used to describe the domains of variables. This paper describes an algorithm which computes the set of parameterized vertices of a polyhedron, given its representation as a system of parameterized inequalities. This provides an important tool for the symbolic analysis of the parameterized domains used to define variables and computation domains in PAREs. A library of operations on parameterized polyhedra based on the Polyhedral Library has been written in C and is freely distributed."
            },
            "slug": "Parameterized-Polyhedra-and-Their-Vertices-Loechner-Wilde",
            "title": {
                "fragments": [],
                "text": "Parameterized Polyhedra and Their Vertices"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper describes an algorithm which computes the set of parameterization vertices of a polyhedron, given its representation as a system of parameterized inequalities."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Parallel Programming"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769333"
                        ],
                        "name": "C. Bastoul",
                        "slug": "C.-Bastoul",
                        "structuredName": {
                            "firstName": "C\u00e9dric",
                            "lastName": "Bastoul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Bastoul"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "We have already achieved the shortterm objectives of replacing PolyLib in the loop generator CLooG [3], producing better code by eliminating constraints that are redundant over the integers but not over the rationals, and of forming the basis of an equivalence checker [22] of programs that can be represented in the polyhedral model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7971227,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2f48fb9fd31390c56609f00510accf5c56f9f9b",
            "isKey": false,
            "numCitedBy": 518,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Many advances in automatic parallelization and optimization have been achieved through the polyhedral model. It has been extensively shown that this computational model provides convenient abstractions to reason about and apply program transformations. Nevertheless, the complexity of code generation has long been a deterrent for using polyhedral representation in optimizing compilers. First, code generators have a hard time coping with generated code size and control overhead that may spoil theoretical benefits achieved by the transformations. Second, this step is usually time consuming, hampering the integration of the polyhedral framework in production compilers or feedback-directed, iterative optimization schemes. Moreover, current code generation algorithms only cover a restrictive set of possible transformation functions. This paper discusses a general transformation framework able to deal with nonunimodular, noninvertible, nonintegral or even nonuniform functions. It presents several improvements to a state-of-the-art code generation algorithm. Two directions are explored: generated code size and code generator efficiency. Experimental evidence proves the ability of the improved method to handle real-life problems."
            },
            "slug": "Code-generation-in-the-polyhedral-model-is-easier-Bastoul",
            "title": {
                "fragments": [],
                "text": "Code generation in the polyhedral model is easier than you think"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A general transformation framework able to deal with nonunimodular, noninvertible, nonintegral or even nonuniform functions is discussed and several improvements to a state-of-the-art code generation algorithm are presented."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. 13th International Conference on Parallel Architecture and Compilation Techniques, 2004. PACT 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144022269"
                        ],
                        "name": "W. Pugh",
                        "slug": "W.-Pugh",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Pugh",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Pugh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6756477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5097a13ef3ce1cbbf4947df044ed76635f8d0420",
            "isKey": false,
            "numCitedBy": 597,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "ndamental analis step in an ad',nced optimizing compiler (as well as many other software tools) is data dependence analysis f o r arrays. This means deciding i f two references to an array can refer to the same e lement and i f so, under what conditions. This information is used to determine allowable program transformations and optimizations. For example, we can determine that in the fo l lowing code fragment , no location o f the array is both read and written. Once we also verify that no location is writ ten more than once, we know that the writes can be done in any order. for i = 1 to 100 do f o r j -i to 100 do A[i, j + 11 = A[100,j]"
            },
            "slug": "A-practical-algorithm-for-exact-array-dependence-Pugh",
            "title": {
                "fragments": [],
                "text": "A practical algorithm for exact array dependence analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A fundamental analis step in an ad',nced optimizing compiler (as well as many other software tools) is data dependence analysis f o r arrays, which determines whether two references to an array can refer to the same e lement and under what conditions."
            },
            "venue": {
                "fragments": [],
                "text": "CACM"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749863"
                        ],
                        "name": "R. Bagnara",
                        "slug": "R.-Bagnara",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Bagnara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bagnara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723952"
                        ],
                        "name": "P. Hill",
                        "slug": "P.-Hill",
                        "structuredName": {
                            "firstName": "Patricia",
                            "lastName": "Hill",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733885"
                        ],
                        "name": "E. Zaffanella",
                        "slug": "E.-Zaffanella",
                        "structuredName": {
                            "firstName": "Enea",
                            "lastName": "Zaffanella",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Zaffanella"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "It is different from the algorithm of [2], which uses both constraints and vertices and considers only rational sets."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12347956,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "7ac334a53ae1b7554b85c49beabb4c8513d88172",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Exact-join-detection-for-convex-polyhedra-and-other-Bagnara-Hill",
            "title": {
                "fragments": [],
                "text": "Exact join detection for convex polyhedra and other numerical abstractions"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Geom."
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749863"
                        ],
                        "name": "R. Bagnara",
                        "slug": "R.-Bagnara",
                        "structuredName": {
                            "firstName": "Roberto",
                            "lastName": "Bagnara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bagnara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40811262"
                        ],
                        "name": "E. Ricci",
                        "slug": "E.-Ricci",
                        "structuredName": {
                            "firstName": "Elisa",
                            "lastName": "Ricci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Ricci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733885"
                        ],
                        "name": "E. Zaffanella",
                        "slug": "E.-Zaffanella",
                        "structuredName": {
                            "firstName": "Enea",
                            "lastName": "Zaffanella",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Zaffanella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723952"
                        ],
                        "name": "P. Hill",
                        "slug": "P.-Hill",
                        "structuredName": {
                            "firstName": "Patricia",
                            "lastName": "Hill",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Hill"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Many researchers therefore use polyhedral libraries such as PolyLib [18] and PPL [1] that exploit the double description of polytopes in terms of both facets and vertices."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5659759,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8b531c10e3b8618212b2a321cdf4ca3b65ff55e1",
            "isKey": false,
            "numCitedBy": 152,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "The domain of convex polyhedra is employed in several systems for the analysis and verification of hardware and software components. Current applications span imperative, functional and logic languages, synchronous languages and synchronization protocols, real-time and hybrid systems. Since the seminal work of P. Cousot and N. Halbwachs, convex polyhedra have thus played an important role in the formal methods community and several critical tasks rely on their software implementations. Despite this, existing libraries for the manipulation of convex polyhedra are still research prototypes and suffer from limitations that make their usage problematic, especially in critical applications. Furthermore, there is inadequate support for polyhedra that are not necessarily closed (NNC), i.e., polyhedra that are described by systems of constraints where strict inequalities are allowed to occur. This paper presents the Parma Polyhedra Library, a new, robust and complete implementation of NNC convex polyhedra, concentrating on the distinctive features of the library and on the novel theoretical underpinnings."
            },
            "slug": "Possibly-Not-Closed-Convex-Polyhedra-and-the-Parma-Bagnara-Ricci",
            "title": {
                "fragments": [],
                "text": "Possibly Not Closed Convex Polyhedra and the Parma Polyhedra Library"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The Parma Polyhedra Library is presented, a new, robust and complete implementation of NNC convex polyhedra, concentrating on the distinctive features of the library and on the novel theoretical underpinnings."
            },
            "venue": {
                "fragments": [],
                "text": "SAS"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1704229"
                        ],
                        "name": "W. Cook",
                        "slug": "W.-Cook",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Cook",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Cook"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2095451945"
                        ],
                        "name": "Thomas F. Rutherford",
                        "slug": "Thomas-F.-Rutherford",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Rutherford",
                            "middleNames": [
                                "F."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas F. Rutherford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1797671"
                        ],
                        "name": "H. Scarf",
                        "slug": "H.-Scarf",
                        "structuredName": {
                            "firstName": "Herbert",
                            "lastName": "Scarf",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Scarf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145423192"
                        ],
                        "name": "D. Shallcross",
                        "slug": "D.-Shallcross",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Shallcross",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Shallcross"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "In particular, it is used in an ILP feasibility solver based on generalized basis reduction [9], which is in turn used to check the emptiness of a set, producing a sample element if not."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 207225573,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6140e02f4be025d2003ae380dfa5a9cef57272d7",
            "isKey": false,
            "numCitedBy": 65,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years many advances have been made in solution techniques for specially structured 0-1 integer programming problems. In contrast, very little progress has been made on solving general (mixed integer) problems. This, of course, is not true when viewed from the theoretical side: Lenstra (1981) made a major breakthrough, obtaining a polynomial-time algorithm when the number of integer variables is fixed. We discuss a practical implementation of a Lenstra-like algorithm, based on the generalized basis reduction method of Lovasz and Scarf (1988).This method allows us to avoid the ellipsoidal approximations required in Lenstra's algorithm. We report on the solution of a number of small (but difficult) examples, up to 100 integer variables. Our computer code uses the linear programming optimizer CPlex as a subroutine to solve the linear programming problems that arise."
            },
            "slug": "An-Implementation-of-the-Generalized-Basis-for-Cook-Rutherford",
            "title": {
                "fragments": [],
                "text": "An Implementation of the Generalized Basis Reduction Algorithm for Integer Programming"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "A practical implementation of a Lenstra-like algorithm, based on the generalized basis reduction method of Lovasz and Scarf (1988), which allows us to avoid the ellipsoidal approximations required in Lenstra's algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "INFORMS J. Comput."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772079"
                        ],
                        "name": "Sven Verdoolaege",
                        "slug": "Sven-Verdoolaege",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Verdoolaege",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sven Verdoolaege"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3272876"
                        ],
                        "name": "Gerda Janssens",
                        "slug": "Gerda-Janssens",
                        "structuredName": {
                            "firstName": "Gerda",
                            "lastName": "Janssens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gerda Janssens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743332"
                        ],
                        "name": "M. Bruynooghe",
                        "slug": "M.-Bruynooghe",
                        "structuredName": {
                            "firstName": "Maurice",
                            "lastName": "Bruynooghe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Bruynooghe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2935604,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8ab99e4854c526dc80f4cced40748f1369f10fad",
            "isKey": false,
            "numCitedBy": 72,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Designers often apply manual or semi-automatic loop and data transformations on array- and loop-intensive programs to improve performance. It is crucial that such transformations preserve the functionality of the program. This article presents an automatic method for constructing equivalence proofs for the class of static affine programs. The equivalence checking is performed on a dependence graph abstraction and uses a new approach based on widening to find the proper induction hypotheses for reasoning about recurrences. Unlike transitive-closure-based approaches, this widening approach can also handle nonuniform recurrences. The implementation is publicly available and is the first of its kind to fully support commutative operations."
            },
            "slug": "Equivalence-checking-of-static-affine-programs-to-Verdoolaege-Janssens",
            "title": {
                "fragments": [],
                "text": "Equivalence checking of static affine programs using widening to handle recurrences"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This article presents an automatic method for constructing equivalence proofs for the class of static affine programs and uses a new approach based on widening to find the proper induction hypotheses for reasoning about recurrences."
            },
            "venue": {
                "fragments": [],
                "text": "TOPL"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1838186"
                        ],
                        "name": "P. Feautrier",
                        "slug": "P.-Feautrier",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Feautrier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Feautrier"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2013 dependence analysis [12] is a crucial operation for the polyhedral model."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5738544,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7cd685371e267a499ded869a934a4cffed591aec",
            "isKey": false,
            "numCitedBy": 454,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Given a program written in a simple imperative language (assignment statements,for loops, affine indices and loop limits), this paper presents an algorithm for analyzing the patterns along which values flow as the execution proceeds. For each array or scalar reference, the result is the name and iteration vector of the source statement as a function of the iteration vector of the referencing statement. The paper discusses several applications of the method: conversion of a program to a set of recurrence equations, array and scalar expansion, program verification and parallel program construction."
            },
            "slug": "Dataflow-analysis-of-array-and-scalar-references-Feautrier",
            "title": {
                "fragments": [],
                "text": "Dataflow analysis of array and scalar references"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "This paper presents an algorithm for analyzing the patterns along which values flow as the execution proceeds, and discusses several applications of the method: conversion of a program to a set of recurrence equations, array and scalar expansion, program verification and parallel program construction."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Parallel Programming"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144022269"
                        ],
                        "name": "W. Pugh",
                        "slug": "W.-Pugh",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Pugh",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Pugh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3174094,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "285024b15197b5face8bdef1d03f36949b8339c4",
            "isKey": false,
            "numCitedBy": 950,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "The Omega test is an integer programming algorithm that can determine whether a dependence exists between two array references, and if so, under what conditions. Conventional wisdom holds that integer programming techniques are far too expensive to be used for dependence analysis, except as a method of last resort for situations that cannot be decided by simpler methods. We present evidence that suggests this wisdom is wrong, and that the Omega test is competitive with approximate algorithms used in practice and suitable for use in production compilers. The Omega test is based on an extension of FourierMotzkin variable elimination to integer programming, and has worst-case exponential time complexity. However, we show that for many situations in which other (polynomial) methods are accurate, the Omega test has low order polynomial time complexity. The Omega test can be used to simplify integer programming problems, rather than just deciding them. This has many applications, including accurately and efficiently computing dependence direction and distance vectors."
            },
            "slug": "The-Omega-test:-A-fast-and-practical-integer-for-Pugh",
            "title": {
                "fragments": [],
                "text": "The Omega test: A fast and practical integer programming algorithm for dependence analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Evidence is presented that suggests conventional wisdom is wrong, and that the Omega test is competitive with approximate algorithms used in practice and suitable for use in production compilers, and has low order polynomial time complexity."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 1991 ACM/IEEE Conference on Supercomputing (Supercomputing '91)"
            },
            "year": 1991
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1683624"
                        ],
                        "name": "A. Beletska",
                        "slug": "A.-Beletska",
                        "structuredName": {
                            "firstName": "Anna",
                            "lastName": "Beletska",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Beletska"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718247"
                        ],
                        "name": "Denis Barthou",
                        "slug": "Denis-Barthou",
                        "structuredName": {
                            "firstName": "Denis",
                            "lastName": "Barthou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Denis Barthou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701583"
                        ],
                        "name": "W. Bielecki",
                        "slug": "W.-Bielecki",
                        "structuredName": {
                            "firstName": "W\u0142odzimierz",
                            "lastName": "Bielecki",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Bielecki"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145509576"
                        ],
                        "name": "Albert Cohen",
                        "slug": "Albert-Cohen",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Cohen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Albert Cohen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "It is computed approximatively using an algorithm that improves upon both [17] and [5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16503288,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "7cfa9d0ea9be6e36bd94488a2152caf1b693b1f9",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a method to compute the transitive closure of a union of affine relations on integer tuples. Within Presburger arithmetics, complete algorithms to compute the transitive closure exist for convex polyhedra only. In presence of non-convex relations, there exist little but special cases and incomplete heuristics. We introduce a novel sufficient and necessary condition defining a class of relations for which an exact computation is possible. Our method is immediately applicable to a wide area of symbolic computation problems. It is illustrated on representative examples and compared with state-of-the-art approaches."
            },
            "slug": "Computing-the-Transitive-Closure-of-a-Union-of-Beletska-Barthou",
            "title": {
                "fragments": [],
                "text": "Computing the Transitive Closure of a Union of Affine Integer Tuple Relations"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper proposes a method to compute the transitive closure of a union of affine relations on integer tuples by introducing a novel sufficient and necessary condition defining a class of relations for which an exact computation is possible."
            },
            "venue": {
                "fragments": [],
                "text": "COCOA"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145010587"
                        ],
                        "name": "M. Karr",
                        "slug": "M.-Karr",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Karr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Karr"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "computation of the integer affine hull using the algorithm of [15], which is very useful for reducing the dimension of a set by detecting implicit equalities and for eliminating redundant existentially quantified variables."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 376574,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "4fb49f5742b11c00d4a853b36a368b52ae7cbb7b",
            "isKey": false,
            "numCitedBy": 365,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "SummarySeveral optimizations of programs can be performed when in certain regions of a program equality relationships hold between a linear combination of the variables of the program and a constant. This paper presents a practical approach to detecting these relationships by considering the problem from the viewpoint of linear algebra. Key to the practicality of this approach is an algorithm for the calculation of the \u201csum\u201d of linear subspaces."
            },
            "slug": "Affine-relationships-among-variables-of-a-program-Karr",
            "title": {
                "fragments": [],
                "text": "Affine relationships among variables of a program"
            },
            "tldr": {
                "abstractSimilarityScore": 56,
                "text": "A practical approach to detecting relationships between a linear combination of the variables of the program and a constant by considering the problem from the viewpoint of linear algebra is presented."
            },
            "venue": {
                "fragments": [],
                "text": "Acta Informatica"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2082428835"
                        ],
                        "name": "Christian Bauer",
                        "slug": "Christian-Bauer",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Bauer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Bauer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2368757"
                        ],
                        "name": "A. Frink",
                        "slug": "A.-Frink",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Frink",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Frink"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2438498"
                        ],
                        "name": "R. Kreckel",
                        "slug": "R.-Kreckel",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Kreckel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Kreckel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "From inception, one of the primary long-term objectives has been to provide all set and polynomial manipulations required by the barvinok library, which, at that time, used a combination of PolyLib, PipLib, Omega and GiNaC [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14965771,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5b2f780c3ce63f1795bbfa6e3e7e22d8ae5e268b",
            "isKey": false,
            "numCitedBy": 388,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "The traditional split into a low level language and a high level language in the design of computer algebra systems may become obsolete with the advent of more versatile computer languages. We describe GiNaC, a special-purpose system that deliberately denies the need for such a distinction. It is entirely written in C++and the user can interact with it directly in that language. It was designed to provide efficient handling of multivariate polynomials, algebras and special functions that are needed for loop calculations in theoretical quantum field theory. It also bears some potential to become a more general purpose symbolic package."
            },
            "slug": "Introduction-to-the-GiNaC-Framework-for-Symbolic-Bauer-Frink",
            "title": {
                "fragments": [],
                "text": "Introduction to the GiNaC Framework for Symbolic Computation within the C++ Programming Language"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "GiNaC is described, a special-purpose system that deliberately denies the need for such a distinction, and is entirely written in C++ and the user can interact with it directly in that language."
            },
            "venue": {
                "fragments": [],
                "text": "J. Symb. Comput."
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759256"
                        ],
                        "name": "A. Bemporad",
                        "slug": "A.-Bemporad",
                        "structuredName": {
                            "firstName": "Alberto",
                            "lastName": "Bemporad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Bemporad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2324246"
                        ],
                        "name": "K. Fukuda",
                        "slug": "K.-Fukuda",
                        "structuredName": {
                            "firstName": "Komei",
                            "lastName": "Fukuda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukuda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48000674"
                        ],
                        "name": "F. D. Torrisi",
                        "slug": "F.-D.-Torrisi",
                        "structuredName": {
                            "firstName": "Fabio",
                            "lastName": "Torrisi",
                            "middleNames": [
                                "Danilo"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. D. Torrisi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The algorithm is based on a variation of the constraints based technique of [6], but extended to handle sets of integers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18959335,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "9dcc6c39f479f6ecf579d7b30fa092bd915121d1",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Convexity-recognition-of-the-union-of-polyhedra-Bemporad-Fukuda",
            "title": {
                "fragments": [],
                "text": "Convexity recognition of the union of polyhedra"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Geom."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1886895"
                        ],
                        "name": "P. Clauss",
                        "slug": "P.-Clauss",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Clauss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Clauss"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065109572"
                        ],
                        "name": "F. Fern\u00e1ndez",
                        "slug": "F.-Fern\u00e1ndez",
                        "structuredName": {
                            "firstName": "Federico",
                            "lastName": "Fern\u00e1ndez",
                            "middleNames": [
                                "Javier"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Fern\u00e1ndez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2700568"
                        ],
                        "name": "D. Garbervetsky",
                        "slug": "D.-Garbervetsky",
                        "structuredName": {
                            "firstName": "Diego",
                            "lastName": "Garbervetsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Garbervetsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1772079"
                        ],
                        "name": "Sven Verdoolaege",
                        "slug": "Sven-Verdoolaege",
                        "structuredName": {
                            "firstName": "Sven",
                            "lastName": "Verdoolaege",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sven Verdoolaege"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "\u2013 bounds on piecewise step-polynomials are computed in an approximative, but usually fairly accurate, way using the algorithm of [8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 637908,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ab317b0fffb530c70335371cb8daba57358d5dca",
            "isKey": false,
            "numCitedBy": 49,
            "numCiting": 106,
            "paperAbstract": {
                "fragments": [],
                "text": "Memory requirement estimation is an important issue in the development of embedded systems, since memory directly influences performance, cost and power consumption. It is therefore crucial to have tools that automatically compute accurate estimates of the memory requirements of programs to better control the development process and avoid some catastrophic execution exceptions. Many important memory issues can be expressed as the problem of maximizing a parametric polynomial defined over a parametric convex domain. Bernstein expansion is a technique that has been used to compute upper bounds on polynomials defined over intervals and parametric ldquoboxesrdquo. In this paper, we propose an extension of this theory to more general parametric convex domains and illustrate its applicability to the resolution of memory issues with several application examples."
            },
            "slug": "Symbolic-Polynomial-Maximization-Over-Convex-Sets-Clauss-Fern\u00e1ndez",
            "title": {
                "fragments": [],
                "text": "Symbolic Polynomial Maximization Over Convex Sets and Its Application to Memory Requirement Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper proposes an extension of Bernstein expansion theory to more general parametric convex domains and illustrates its applicability to the resolution of memory issues with several application examples."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Very Large Scale Integration (VLSI) Systems"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145339508"
                        ],
                        "name": "D. Detlefs",
                        "slug": "D.-Detlefs",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Detlefs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Detlefs"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145802352"
                        ],
                        "name": "Greg Nelson",
                        "slug": "Greg-Nelson",
                        "structuredName": {
                            "firstName": "Greg",
                            "lastName": "Nelson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Greg Nelson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1804564"
                        ],
                        "name": "J. Saxe",
                        "slug": "J.-Saxe",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Saxe",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Saxe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The core of the library is formed by an incremental LP solver modeled after that of Simplify [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9613854,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8c45e059a11b1c6398b45c92610804e1f28336d4",
            "isKey": false,
            "numCitedBy": 863,
            "numCiting": 87,
            "paperAbstract": {
                "fragments": [],
                "text": "This article provides a detailed description of the automatic theorem prover Simplify, which is the proof engine of the Extended Static Checkers ESC/Java and ESC/Modula-3. Simplify uses the Nelson--Oppen method to combine decision procedures for several important theories, and also employs a matcher to reason about quantifiers. Instead of conventional matching in a term DAG, Simplify matches up to equivalence in an E-graph, which detects many relevant pattern instances that would be missed by the conventional approach. The article describes two techniques, error context reporting and error localization, for helping the user to determine the reason that a false conjecture is false. The article includes detailed performance figures on conjectures derived from realistic program-checking problems."
            },
            "slug": "Simplify:-a-theorem-prover-for-program-checking-Detlefs-Nelson",
            "title": {
                "fragments": [],
                "text": "Simplify: a theorem prover for program checking"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The article describes two techniques, error context reporting and error localization, for helping the user to determine the reason that a false conjecture is false, and includes detailed performance figures on conjectures derived from realistic program-checking problems."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2324246"
                        ],
                        "name": "K. Fukuda",
                        "slug": "K.-Fukuda",
                        "structuredName": {
                            "firstName": "Komei",
                            "lastName": "Fukuda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukuda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2159430"
                        ],
                        "name": "T. Liebling",
                        "slug": "T.-Liebling",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Liebling",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Liebling"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2372977"
                        ],
                        "name": "Christine L\u00fctolf",
                        "slug": "Christine-L\u00fctolf",
                        "structuredName": {
                            "firstName": "Christine",
                            "lastName": "L\u00fctolf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christine L\u00fctolf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 6061279,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "895a9b9ec25a2b6211118402a9556e1615c9ac59",
            "isKey": false,
            "numCitedBy": 27,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Extended-convex-hull-Fukuda-Liebling",
            "title": {
                "fragments": [],
                "text": "Extended convex hull"
            },
            "venue": {
                "fragments": [],
                "text": "Comput. Geom."
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3137897"
                        ],
                        "name": "G\u00fcnther Blaschek",
                        "slug": "G\u00fcnther-Blaschek",
                        "structuredName": {
                            "firstName": "G\u00fcnther",
                            "lastName": "Blaschek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G\u00fcnther Blaschek"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 58486417,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "08336aa2e5761542f781009dc8cd592e81b45eb5",
            "isKey": false,
            "numCitedBy": 20,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This chapter discusses the most important aspects of the Omega library. It does not explain all elements, but just those that are most frequently used in the solution of a problem. The intention of this chapter is to give the reader an idea of what the library contains and how its parts can be reused. As the Omega library closely follows the design principles of other object-oriented libraries, this chapter should also give the reader some insight into object-oriented libraries in general."
            },
            "slug": "The-Omega-Library-Blaschek",
            "title": {
                "fragments": [],
                "text": "The Omega Library"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This chapter discusses the most important aspects of the Omega library and an idea of what the library contains and how its parts can be reused is given."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3157456"
                        ],
                        "name": "J\u00f6rg Rambau",
                        "slug": "J\u00f6rg-Rambau",
                        "structuredName": {
                            "firstName": "J\u00f6rg",
                            "lastName": "Rambau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J\u00f6rg Rambau"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Preliminary experiments on a couple of non-trivial cases show that the implementation is orders of magnitude faster than that of PolyLib and as fast as or slightly faster than TOPCOM [21] (version 0."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 10003502,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "884f1b07b87ada3ef5780c80ac839f28ada179d9",
            "isKey": false,
            "numCitedBy": 119,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "TOPCOM is a package for computing triangulations of point configurations and oriented matroids. For example, for a point configuration one can compute the chirotope, components of the flip graph of triangulations, enumerate all triangulations. The core algorithms implemented in TOPCOM are described, and implentation issues are discussed."
            },
            "slug": "TOPCOM:-Triangulations-of-Point-Configurations-and-Rambau",
            "title": {
                "fragments": [],
                "text": "TOPCOM: Triangulations of Point Configurations and Oriented Matroids"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The core algorithms implemented in TOPCOM are described, and implentation issues are discussed."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1838186"
                        ],
                        "name": "P. Feautrier",
                        "slug": "P.-Feautrier",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Feautrier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Feautrier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The internal representation is also different, with Omega transforming sets with existentially quantified variables to unions of intersections of polyhedra and lattices in order to be able to perform some set operations, while isl uses a representation in terms of integer divisions inspired by the output format of PipLib, a library for performing parametric integer programming [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Finally, parametric integer programming [11] is built on top of these LP and ILP solvers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 58913364,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "d6613b9ca5b21506b56b004be7593d9d40fb84da",
            "isKey": false,
            "numCitedBy": 472,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "L'analyse semantique des programmes informatiques conduit a la resolution de problemes de programmation parametrique entiere. L'article s'est ainsi consacre a la construction d'un algorithme de ce type"
            },
            "slug": "Parametric-integer-programming-Feautrier",
            "title": {
                "fragments": [],
                "text": "Parametric integer programming"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1988
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 2,
            "methodology": 10,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 19,
        "totalPages": 2
    },
    "page_url": "https://www.semanticscholar.org/paper/isl:-An-Integer-Set-Library-for-the-Polyhedral-Verdoolaege/1c5b15587e4034c97610b2017697ad1ea663a8fa?sort=total-citations"
}