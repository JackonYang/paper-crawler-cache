{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108309275"
                        ],
                        "name": "Weinan Zhang",
                        "slug": "Weinan-Zhang",
                        "structuredName": {
                            "firstName": "Weinan",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weinan Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50234122"
                        ],
                        "name": "Tianming Du",
                        "slug": "Tianming-Du",
                        "structuredName": {
                            "firstName": "Tianming",
                            "lastName": "Du",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianming Du"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39055225"
                        ],
                        "name": "Jun Wang",
                        "slug": "Jun-Wang",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3426064,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1bc072002d97808340b312b69427baf2dc9fcb8e",
            "isKey": false,
            "numCitedBy": 357,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Predicting user responses, such as click-through rate and conversion rate, are critical in many web applications including web search, personalised recommendation, and online advertising. Different from continuous raw features that we usually found in the image and audio domains, the input features in web space are always of multi-field and are mostly discrete and categorical while their dependencies are little known. Major user response prediction models have to either limit themselves to linear models or require manually building up high-order combination features. The former loses the ability of exploring feature interactions, while the latter results in a heavy computation in the large feature space. To tackle the issue, we propose two novel models using deep neural networks (DNNs) to automatically learn effective patterns from categorical feature interactions and make predictions of users' ad clicks. To get our DNNs efficiently work, we propose to leverage three feature transformation methods, i.e., factorisation machines (FMs), restricted Boltzmann machines (RBMs) and denoising auto-encoders (DAEs). This paper presents the structure of our models and their efficient training algorithms. The large-scale experiments with real-world data demonstrate that our methods work better than major state-of-the-art models."
            },
            "slug": "Deep-Learning-over-Multi-field-Categorical-Data-A-Zhang-Du",
            "title": {
                "fragments": [],
                "text": "Deep Learning over Multi-field Categorical Data - - A Case Study on User Response Prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper proposes two novel models using deep neural networks (DNNs) to automatically learn effective patterns from categorical feature interactions and make predictions of users' ad clicks and demonstrates that their methods work better than major state-of-the-art models."
            },
            "venue": {
                "fragments": [],
                "text": "ECIR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2061550"
                        ],
                        "name": "Heng-Tze Cheng",
                        "slug": "Heng-Tze-Cheng",
                        "structuredName": {
                            "firstName": "Heng-Tze",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Heng-Tze Cheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40338695"
                        ],
                        "name": "L. Koc",
                        "slug": "L.-Koc",
                        "structuredName": {
                            "firstName": "Levent",
                            "lastName": "Koc",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Koc"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066076307"
                        ],
                        "name": "Jeremiah Harmsen",
                        "slug": "Jeremiah-Harmsen",
                        "structuredName": {
                            "firstName": "Jeremiah",
                            "lastName": "Harmsen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeremiah Harmsen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3296031"
                        ],
                        "name": "Tal Shaked",
                        "slug": "Tal-Shaked",
                        "structuredName": {
                            "firstName": "Tal",
                            "lastName": "Shaked",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tal Shaked"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073806959"
                        ],
                        "name": "Tushar Chandra",
                        "slug": "Tushar-Chandra",
                        "structuredName": {
                            "firstName": "Tushar",
                            "lastName": "Chandra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tushar Chandra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3312922"
                        ],
                        "name": "H. Aradhye",
                        "slug": "H.-Aradhye",
                        "structuredName": {
                            "firstName": "Hrishikesh",
                            "lastName": "Aradhye",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Aradhye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064997996"
                        ],
                        "name": "Glen Anderson",
                        "slug": "Glen-Anderson",
                        "structuredName": {
                            "firstName": "Glen",
                            "lastName": "Anderson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Glen Anderson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32131713"
                        ],
                        "name": "G. Corrado",
                        "slug": "G.-Corrado",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Corrado",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Corrado"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2055400243"
                        ],
                        "name": "Wei Chai",
                        "slug": "Wei-Chai",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Chai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Chai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37413761"
                        ],
                        "name": "M. Ispir",
                        "slug": "M.-Ispir",
                        "structuredName": {
                            "firstName": "Mustafa",
                            "lastName": "Ispir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Ispir"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1508890387"
                        ],
                        "name": "Rohan Anil",
                        "slug": "Rohan-Anil",
                        "structuredName": {
                            "firstName": "Rohan",
                            "lastName": "Anil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rohan Anil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50730596"
                        ],
                        "name": "Zakaria Haque",
                        "slug": "Zakaria-Haque",
                        "structuredName": {
                            "firstName": "Zakaria",
                            "lastName": "Haque",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zakaria Haque"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2217278"
                        ],
                        "name": "Lichan Hong",
                        "slug": "Lichan-Hong",
                        "structuredName": {
                            "firstName": "Lichan",
                            "lastName": "Hong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lichan Hong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20048351"
                        ],
                        "name": "Vihan Jain",
                        "slug": "Vihan-Jain",
                        "structuredName": {
                            "firstName": "Vihan",
                            "lastName": "Jain",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vihan Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109059862"
                        ],
                        "name": "Xiaobing Liu",
                        "slug": "Xiaobing-Liu",
                        "structuredName": {
                            "firstName": "Xiaobing",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaobing Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068799083"
                        ],
                        "name": "Hemal Shah",
                        "slug": "Hemal-Shah",
                        "structuredName": {
                            "firstName": "Hemal",
                            "lastName": "Shah",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hemal Shah"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 31
                            }
                        ],
                        "text": "Until very recently, some work [6, 9, 16, 31, 44] started to explore DNNs for some scenarios of sparse predictive analytics."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[9] proposed Wide&Deep for App recommendation, where the deep part is a multi-layer perceptron (MLP) on the concatenation of feature embedding vectors to learn feature interactions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 96
                            }
                        ],
                        "text": "While it is claimed that multiple non-linear layers are able to learn feature interactions well [9, 31], such a deep architecture can be di\u0081cult to optimize in practice due to the notorious problems of vanishing/exploding gradients, over\u0080\u008aing, degradation, among others [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 37
                            }
                        ],
                        "text": "feature vector) via one-hot encoding [2, 9, 16, 30, 31]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 124
                            }
                        ],
                        "text": "In recent years, embedding-based methods become increasingly popular, which try to learn feature interactions from raw data [9, 18, 24, 30, 31, 44]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 79
                            }
                        ],
                        "text": "Compared to the state-of-the-art deep learning methods \u2014 the 3-layer Wide&Deep [9] and 10-layer DeepCross [31] \u2014 our 1-layer NFM shows consistent improvements with a much simpler structure and fewer model parameters."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 98
                            }
                        ],
                        "text": "NFM has a similar multi-layered neural architecture with several existing deep learning solutions [9, 16, 31]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 51
                            }
                        ],
                        "text": ", size of each layer), one can freely choose tower [9, 16], constant [31], and diamond [44], among others."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 73
                            }
                        ],
                        "text": "In contrast to traditional deep learning methods that simply concatenate [9, 31, 44] or average [16, 36] embedding vectors in the low level, our use of Bi-Interaction pooling encodes more informative feature interactions, greatly facilitating the following \u201cdeep\u201d layers to learn meaningful information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 112
                            }
                        ],
                        "text": "Many successful solutions in both industry and academia largely rely on manually cra\u0089ing combinatorial features [9], i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3352400,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "657fbf29ea0b4904a3e98d1556f9acf38dddae5f",
            "isKey": true,
            "numCitedBy": 2152,
            "numCiting": 8,
            "paperAbstract": {
                "fragments": [],
                "text": "Generalized linear models with nonlinear feature transformations are widely used for large-scale regression and classification problems with sparse inputs. Memorization of feature interactions through a wide set of cross-product feature transformations are effective and interpretable, while generalization requires more feature engineering effort. With less feature engineering, deep neural networks can generalize better to unseen feature combinations through low-dimensional dense embeddings learned for the sparse features. However, deep neural networks with embeddings can over-generalize and recommend less relevant items when the user-item interactions are sparse and high-rank. In this paper, we present Wide & Deep learning---jointly trained wide linear models and deep neural networks---to combine the benefits of memorization and generalization for recommender systems. We productionized and evaluated the system on Google Play, a commercial mobile app store with over one billion active users and over one million apps. Online experiment results show that Wide & Deep significantly increased app acquisitions compared with wide-only and deep-only models. We have also open-sourced our implementation in TensorFlow."
            },
            "slug": "Wide-&-Deep-Learning-for-Recommender-Systems-Cheng-Koc",
            "title": {
                "fragments": [],
                "text": "Wide & Deep Learning for Recommender Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Wide & Deep learning is presented---jointly trained wide linear models and deep neural networks---to combine the benefits of memorization and generalization for recommender systems and is open-sourced in TensorFlow."
            },
            "venue": {
                "fragments": [],
                "text": "DLRS@RecSys"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2050212830"
                        ],
                        "name": "Alexander Novikov",
                        "slug": "Alexander-Novikov",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Novikov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander Novikov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "103810919"
                        ],
                        "name": "Mikhail Trofimov",
                        "slug": "Mikhail-Trofimov",
                        "structuredName": {
                            "firstName": "Mikhail",
                            "lastName": "Trofimov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mikhail Trofimov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738205"
                        ],
                        "name": "I. Oseledets",
                        "slug": "I.-Oseledets",
                        "structuredName": {
                            "firstName": "I.",
                            "lastName": "Oseledets",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Oseledets"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "tor variables, the generated feature vector can be of very high dimension but sparse. To build e\u2021ective ML models with such sparse data, it is crucial to account for the interactions between features [4, 23, 31]. Many successful solutions in both industry and academia largelyrelyonmanuallycra\u203aingcombinatorialfeatures[9], i.e.,constructing new features by combining multiple predictor variables, also known as "
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "del to learn higher-order feature interactions in a non-linear way. \u201eis is advantageous to existing methods for higher-order interaction learning, such as higher-Order FM [3] and Exponential Machines [23], which only support the learning of higher-order interactions in a linear way. As for the structure of fully connected layers (i.e.,size of each layer), one can freely choose tower [9, 16], constant "
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16676712,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "46d19644912b36942c5193d3e239849281dd0319",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Modeling interactions between features improves the performance of machine learning solutions in many domains (e.g. recommender systems or sentiment analysis). In this paper, we introduce Exponential Machines (ExM), a predictor that models all interactions of every order. The key idea is to represent an exponentially large tensor of parameters in a factorized format called Tensor Train (TT). The Tensor Train format regularizes the model and lets you control the number of underlying parameters. To train the model, we develop a stochastic Riemannian optimization procedure, which allows us to fit tensors with 2^160 entries. We show that the model achieves state-of-the-art performance on synthetic data with high-order interactions and that it works on par with high-order factorization machines on a recommender system dataset MovieLens 100K."
            },
            "slug": "Exponential-Machines-Novikov-Trofimov",
            "title": {
                "fragments": [],
                "text": "Exponential Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper introduces Exponential Machines (ExM), a predictor that models all interactions of every order in a factorized format called Tensor Train (TT), and shows that the model achieves state-of-the-art performance on synthetic data with high-order interactions and works on par on a recommender system dataset MovieLens 100K."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2843982"
                        ],
                        "name": "Steffen Rendle",
                        "slug": "Steffen-Rendle",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Rendle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steffen Rendle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 142
                            }
                        ],
                        "text": "Although higher-order FMs have been proposed [27], they still belong to the family of linear models and are claimed to be di\u0081cult to estimate [28]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 132
                            }
                        ],
                        "text": "We compared with the following competitive embedding-based models that are speci\u0080cally designed for sparse data prediction: - LibFM [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 86,
                                "start": 82
                            }
                        ],
                        "text": "With one hidden layer only, our NFM signi\u0080cantly outperforms FM (the o\u0081cial LibFM [28] implementation) with a 7."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5499886,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e50f4d3316d13841c287dcdf5479d7820d593571",
            "isKey": false,
            "numCitedBy": 1084,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "Factorization approaches provide high accuracy in several important prediction problems, for example, recommender systems. However, applying factorization approaches to a new prediction problem is a nontrivial task and requires a lot of expert knowledge. Typically, a new model is developed, a learning algorithm is derived, and the approach has to be implemented.\n Factorization machines (FM) are a generic approach since they can mimic most factorization models just by feature engineering. This way, factorization machines combine the generality of feature engineering with the superiority of factorization models in estimating interactions between categorical variables of large domain. libFM is a software implementation for factorization machines that features stochastic gradient descent (SGD) and alternating least-squares (ALS) optimization, as well as Bayesian inference using Markov Chain Monto Carlo (MCMC). This article summarizes the recent research on factorization machines both in terms of modeling and learning, provides extensions for the ALS and MCMC algorithms, and describes the software tool libFM."
            },
            "slug": "Factorization-Machines-with-libFM-Rendle",
            "title": {
                "fragments": [],
                "text": "Factorization Machines with libFM"
            },
            "venue": {
                "fragments": [],
                "text": "TIST"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7792071"
                        ],
                        "name": "Xiangnan He",
                        "slug": "Xiangnan-He",
                        "structuredName": {
                            "firstName": "Xiangnan",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangnan He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32781973"
                        ],
                        "name": "Lizi Liao",
                        "slug": "Lizi-Liao",
                        "structuredName": {
                            "firstName": "Lizi",
                            "lastName": "Liao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lizi Liao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5462268"
                        ],
                        "name": "Hanwang Zhang",
                        "slug": "Hanwang-Zhang",
                        "structuredName": {
                            "firstName": "Hanwang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanwang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143982887"
                        ],
                        "name": "Liqiang Nie",
                        "slug": "Liqiang-Nie",
                        "structuredName": {
                            "firstName": "Liqiang",
                            "lastName": "Nie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liqiang Nie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48539382"
                        ],
                        "name": "Xia Hu",
                        "slug": "Xia-Hu",
                        "structuredName": {
                            "firstName": "Xia",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xia Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144078686"
                        ],
                        "name": "Tat-Seng Chua",
                        "slug": "Tat-Seng-Chua",
                        "structuredName": {
                            "firstName": "Tat-Seng",
                            "lastName": "Chua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tat-Seng Chua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13907106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ad42c33c299ef1c53dfd4697e3f7f98ed0ca31dd",
            "isKey": false,
            "numCitedBy": 3248,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years, deep neural networks have yielded immense success on speech recognition, computer vision and natural language processing. However, the exploration of deep neural networks on recommender systems has received relatively less scrutiny. In this work, we strive to develop techniques based on neural networks to tackle the key problem in recommendation --- collaborative filtering --- on the basis of implicit feedback. Although some recent work has employed deep learning for recommendation, they primarily used it to model auxiliary information, such as textual descriptions of items and acoustic features of musics. When it comes to model the key factor in collaborative filtering --- the interaction between user and item features, they still resorted to matrix factorization and applied an inner product on the latent features of users and items. By replacing the inner product with a neural architecture that can learn an arbitrary function from data, we present a general framework named NCF, short for Neural network-based Collaborative Filtering. NCF is generic and can express and generalize matrix factorization under its framework. To supercharge NCF modelling with non-linearities, we propose to leverage a multi-layer perceptron to learn the user-item interaction function. Extensive experiments on two real-world datasets show significant improvements of our proposed NCF framework over the state-of-the-art methods. Empirical evidence shows that using deeper layers of neural networks offers better recommendation performance."
            },
            "slug": "Neural-Collaborative-Filtering-He-Liao",
            "title": {
                "fragments": [],
                "text": "Neural Collaborative Filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work strives to develop techniques based on neural networks to tackle the key problem in recommendation --- collaborative filtering --- on the basis of implicit feedback, and presents a general framework named NCF, short for Neural network-based Collaborative Filtering."
            },
            "venue": {
                "fragments": [],
                "text": "WWW"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145019134"
                        ],
                        "name": "Yu-Chin Juan",
                        "slug": "Yu-Chin-Juan",
                        "structuredName": {
                            "firstName": "Yu-Chin",
                            "lastName": "Juan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu-Chin Juan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056431469"
                        ],
                        "name": "Yong Zhuang",
                        "slug": "Yong-Zhuang",
                        "structuredName": {
                            "firstName": "Yong",
                            "lastName": "Zhuang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yong Zhuang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40429042"
                        ],
                        "name": "Wei-Sheng Chin",
                        "slug": "Wei-Sheng-Chin",
                        "structuredName": {
                            "firstName": "Wei-Sheng",
                            "lastName": "Chin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei-Sheng Chin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1711460"
                        ],
                        "name": "Chih-Jen Lin",
                        "slug": "Chih-Jen-Lin",
                        "structuredName": {
                            "firstName": "Chih-Jen",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chih-Jen Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "It has been successfully applied to many predictive tasks, ranging from online advertising [21], microblog retrieval [26], to open relation extraction [25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 191
                            }
                        ],
                        "text": "Predictive analytics is one of the most important techniques for many information retrieval (IR) and data mining (DM) tasks, ranging from recommendation systems [2, 16], targeted advertising [21], to search ranking [19, 39], visual analysis [35], and event detection [40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[21] proposed \u0080eld-aware FM, which learned multiple embedding vectors for a feature to di\u0082erentiate its interaction with features of di\u0082erent \u0080elds."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 61
                            }
                        ],
                        "text": "While FM has yielded great promise1 in many prediction tasks [2, 8, 21, 24], we argue that its performance can be limited by its linearity, as well as the modelling of pairwise (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 39
                            }
                        ],
                        "text": "In terms of methodology, many variants [18, 21, 24, 38] of FM have been developed."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1472236,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a802eccf56ea69c65b14831335a484a69e5cd849",
            "isKey": true,
            "numCitedBy": 492,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Click-through rate (CTR) prediction plays an important role in computational advertising. Models based on degree-2 polynomial mappings and factorization machines (FMs) are widely used for this task. Recently, a variant of FMs, field-aware factorization machines (FFMs), outperforms existing models in some world-wide CTR-prediction competitions. Based on our experiences in winning two of them, in this paper we establish FFMs as an effective method for classifying large sparse data including those from CTR prediction. First, we propose efficient implementations for training FFMs. Then we comprehensively analyze FFMs and compare this approach with competing models. Experiments show that FFMs are very useful for certain classification problems. Finally, we have released a package of FFMs for public use."
            },
            "slug": "Field-aware-Factorization-Machines-for-CTR-Juan-Zhuang",
            "title": {
                "fragments": [],
                "text": "Field-aware Factorization Machines for CTR Prediction"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper establishes FFMs as an effective method for classifying large sparse data including those from CTR prediction, and proposes efficient implementations for training FFMs and comprehensively analyze FFMs."
            },
            "venue": {
                "fragments": [],
                "text": "RecSys"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2660470"
                        ],
                        "name": "R. J. Oentaryo",
                        "slug": "R.-J.-Oentaryo",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Oentaryo",
                            "middleNames": [
                                "Jayadi"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. J. Oentaryo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709901"
                        ],
                        "name": "Ee-Peng Lim",
                        "slug": "Ee-Peng-Lim",
                        "structuredName": {
                            "firstName": "Ee-Peng",
                            "lastName": "Lim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ee-Peng Lim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49767096"
                        ],
                        "name": "Jia-Wei Low",
                        "slug": "Jia-Wei-Low",
                        "structuredName": {
                            "firstName": "Jia-Wei",
                            "lastName": "Low",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia-Wei Low"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143960553"
                        ],
                        "name": "D. Lo",
                        "slug": "D.-Lo",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Lo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8123268"
                        ],
                        "name": "Michael Finegold",
                        "slug": "Michael-Finegold",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Finegold",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Finegold"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 124
                            }
                        ],
                        "text": "In recent years, embedding-based methods become increasingly popular, which try to learn feature interactions from raw data [9, 18, 24, 30, 31, 44]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 61
                            }
                        ],
                        "text": "While FM has yielded great promise1 in many prediction tasks [2, 8, 21, 24], we argue that its performance can be limited by its linearity, as well as the modelling of pairwise (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[24] encoded prior knowledge of features to FM by designing a hierarchical regularizer; and Lin et al."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 39
                            }
                        ],
                        "text": "In terms of methodology, many variants [18, 21, 24, 38] of FM have been developed."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 155
                            }
                        ],
                        "text": "Note that RMSE has been widely used for evaluating regression tasks such as recommendation with explicit ratings [5, 30] and click-through rate prediction [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5711444,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4165afe63b70f8d8d1d385959585fdc3b796d481",
            "isKey": true,
            "numCitedBy": 90,
            "numCiting": 23,
            "paperAbstract": {
                "fragments": [],
                "text": "Mobile advertising has recently seen dramatic growth, fueled by the global proliferation of mobile phones and devices. The task of predicting ad response is thus crucial for maximizing business revenue. However, ad response data change dynamically over time, and are subject to cold-start situations in which limited history hinders reliable prediction. There is also a need for a robust regression estimation for high prediction accuracy, and good ranking to distinguish the impacts of different ads. To this end, we develop a Hierarchical Importance-aware Factorization Machine (HIFM), which provides an effective generic latent factor framework that incorporates importance weights and hierarchical learning. Comprehensive empirical studies on a real-world mobile advertising dataset show that HIFM outperforms the contemporary temporal latent factor models. The results also demonstrate the efficacy of the HIFM's importance-aware and hierarchical learning in improving the overall prediction and prediction in cold-start scenarios, respectively."
            },
            "slug": "Predicting-response-in-mobile-advertising-with-Oentaryo-Lim",
            "title": {
                "fragments": [],
                "text": "Predicting response in mobile advertising with hierarchical importance-aware factorization machine"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A Hierarchical Importance-aware Factorization Machine (HIFM) is developed, which provides an effective generic latent factor framework that incorporates importance weights and hierarchical learning and outperforms the contemporary temporal latent factor models."
            },
            "venue": {
                "fragments": [],
                "text": "WSDM"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7792071"
                        ],
                        "name": "Xiangnan He",
                        "slug": "Xiangnan-He",
                        "structuredName": {
                            "firstName": "Xiangnan",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangnan He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5462268"
                        ],
                        "name": "Hanwang Zhang",
                        "slug": "Hanwang-Zhang",
                        "structuredName": {
                            "firstName": "Hanwang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanwang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37596605"
                        ],
                        "name": "Min-Yen Kan",
                        "slug": "Min-Yen-Kan",
                        "structuredName": {
                            "firstName": "Min-Yen",
                            "lastName": "Kan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Min-Yen Kan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144078686"
                        ],
                        "name": "Tat-Seng Chua",
                        "slug": "Tat-Seng-Chua",
                        "structuredName": {
                            "firstName": "Tat-Seng",
                            "lastName": "Chua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tat-Seng Chua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 140,
                                "start": 136
                            }
                        ],
                        "text": "One main power of FM stems from its generality \u2014 in contrast to matrix factorization (MF) that models the relation of two entities only [17], FM is a general predictor working with any real valued feature vector for supervised learning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2896685,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ab443bd7e732374caabb5785b8d37bbfc724c845",
            "isKey": false,
            "numCitedBy": 750,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper contributes improvements on both the effectiveness and efficiency of Matrix Factorization (MF) methods for implicit feedback. We highlight two critical issues of existing works. First, due to the large space of unobserved feedback, most existing works resort to assign a uniform weight to the missing data to reduce computational complexity. However, such a uniform assumption is invalid in real-world settings. Second, most methods are also designed in an offline setting and fail to keep up with the dynamic nature of online data. We address the above two issues in learning MF models from implicit feedback. We first propose to weight the missing data based on item popularity, which is more effective and flexible than the uniform-weight assumption. However, such a non-uniform weighting poses efficiency challenge in learning the model. To address this, we specifically design a new learning algorithm based on the element-wise Alternating Least Squares (eALS) technique, for efficiently optimizing a MF model with variably-weighted missing data. We exploit this efficiency to then seamlessly devise an incremental update strategy that instantly refreshes a MF model given new feedback. Through comprehensive experiments on two public datasets in both offline and online protocols, we show that our implemented, open-source (https://github.com/hexiangnan/sigir16-eals) eALS consistently outperforms state-of-the-art implicit MF methods."
            },
            "slug": "Fast-Matrix-Factorization-for-Online-Recommendation-He-Zhang",
            "title": {
                "fragments": [],
                "text": "Fast Matrix Factorization for Online Recommendation with Implicit Feedback"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A new learning algorithm based on the element-wise Alternating Least Squares (eALS) technique is designed, for efficiently optimizing a Matrix Factorization (MF) model with variably-weighted missing data and exploiting this efficiency to then seamlessly devise an incremental update strategy that instantly refreshes a MF model given new feedback."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2843982"
                        ],
                        "name": "Steffen Rendle",
                        "slug": "Steffen-Rendle",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Rendle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steffen Rendle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 30
                            }
                        ],
                        "text": "By specifying input features, Rendle [27] showed that FM can mimic many speci c factorization models such as the standard MF, parallel factor analysis, and SVD++ [22], Owing to such genericity, FM has been recognized as one of the most e ective embedding methods for sparse data prediction."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 195,
                                "start": 189
                            }
                        ],
                        "text": "We compared with the following competitive embedding-based models that are speci cally designed for sparse data prediction:\n- LibFM [28]. is is the o cial implementation6 of FM released by Rendle."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "A popular approach is factorization machines (FMs) [27], which embeds features into a latent space and models the interactions between features via inner product of their embedding vectors."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "Although higher-order FMs have been proposed [27], they still belong to the family of linear models and are claimed to be di\u0081cult to estimate [28]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "\u008cis is the TensorFlow implementation7 of higherorder FM, as described in [27]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "By specifying input features, Rendle [27] showed that FM can mimic many speci\u0080c factorization models such as the standard MF, parallel factor analysis, and SVD++ [22], Owing to such genericity, FM has been recognized as one of the most e\u0082ective embedding methods for sparse data prediction."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 171,
                                "start": 167
                            }
                        ],
                        "text": "Note that we have rescaled an embedding vector by its input feature value, rather than simply an embedding table lookup, so as to account for the real valued features [27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 80
                            }
                        ],
                        "text": "Factorization machines are originally proposed for collaborative recommendation [27, 30]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 17265929,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df93596d4ed71d2863532c063c4c693711216abf",
            "isKey": true,
            "numCitedBy": 1819,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we introduce Factorization Machines (FM) which are a new model class that combines the advantages of Support Vector Machines (SVM) with factorization models. Like SVMs, FMs are a general predictor working with any real valued feature vector. In contrast to SVMs, FMs model all interactions between variables using factorized parameters. Thus they are able to estimate interactions even in problems with huge sparsity (like recommender systems) where SVMs fail. We show that the model equation of FMs can be calculated in linear time and thus FMs can be optimized directly. So unlike nonlinear SVMs, a transformation in the dual form is not necessary and the model parameters can be estimated directly without the need of any support vector in the solution. We show the relationship to SVMs and the advantages of FMs for parameter estimation in sparse settings. On the other hand there are many different factorization models like matrix factorization, parallel factor analysis or specialized models like SVD++, PITF or FPMC. The drawback of these models is that they are not applicable for general prediction tasks but work only with special input data. Furthermore their model equations and optimization algorithms are derived individually for each task. We show that FMs can mimic these models just by specifying the input data (i.e. the feature vectors). This makes FMs easily applicable even for users without expert knowledge in factorization models."
            },
            "slug": "Factorization-Machines-Rendle",
            "title": {
                "fragments": [],
                "text": "Factorization Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "Factorization Machines (FM) are introduced which are a new model class that combines the advantages of Support Vector Machines (SVM) with factorization models and can mimic these models just by specifying the input data (i.e. the feature vectors)."
            },
            "venue": {
                "fragments": [],
                "text": "2010 IEEE International Conference on Data Mining"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36190235"
                        ],
                        "name": "Runwei Qiang",
                        "slug": "Runwei-Qiang",
                        "structuredName": {
                            "firstName": "Runwei",
                            "lastName": "Qiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Runwei Qiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053834581"
                        ],
                        "name": "Feng Liang",
                        "slug": "Feng-Liang",
                        "structuredName": {
                            "firstName": "Feng",
                            "lastName": "Liang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Feng Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1743923"
                        ],
                        "name": "Jianwu Yang",
                        "slug": "Jianwu-Yang",
                        "structuredName": {
                            "firstName": "Jianwu",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianwu Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 117
                            }
                        ],
                        "text": "It has been successfully applied to many predictive tasks, ranging from online advertising [21], microblog retrieval [26], to open relation extraction [25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7342439,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d6f10ce25b5ee88a29d965109d600855768f2a70",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning to rank method has been proposed for practical application in the field of information retrieval. When employing it in microblog retrieval, the significant interactions of various involved features are rarely considered. In this paper, we propose a Ranking Factorization Machine (Ranking FM) model, which applies Factorization Machine model to microblog ranking on basis of pairwise classification. In this way, our proposed model combines the generality of learning to rank framework with the advantages of factorization models in estimating interactions between features, leading to better retrieval performance. Moreover, three groups of features (content relevance features, semantic expansion features and quality features) and their interactions are utilized in the Ranking FM model with the methods of stochastic gradient descent and adaptive regularization for optimization. Experimental results demonstrate its superiority over several baseline systems on a real Twitter dataset in terms of P@30 and MAP metrics. Furthermore, it outperforms the best performing results in the TREC'12 Real-Time Search Task."
            },
            "slug": "Exploiting-ranking-factorization-machines-for-Qiang-Liang",
            "title": {
                "fragments": [],
                "text": "Exploiting ranking factorization machines for microblog retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A Ranking Factorization Machine (Ranking FM) model is proposed, which applies Factorization machine model to microblog ranking on basis of pairwise classification, and demonstrates its superiority over several baseline systems on a real Twitter dataset in terms of P@30 and MAP metrics."
            },
            "venue": {
                "fragments": [],
                "text": "CIKM"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33888728"
                        ],
                        "name": "Liangjie Hong",
                        "slug": "Liangjie-Hong",
                        "structuredName": {
                            "firstName": "Liangjie",
                            "lastName": "Hong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liangjie Hong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144608"
                        ],
                        "name": "A. Doumith",
                        "slug": "A.-Doumith",
                        "structuredName": {
                            "firstName": "Aziz",
                            "lastName": "Doumith",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Doumith"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1800527"
                        ],
                        "name": "Brian D. Davison",
                        "slug": "Brian-D.-Davison",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Davison",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian D. Davison"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12963161,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4bbacf177938c431405924b076f7e7be4bff797d",
            "isKey": false,
            "numCitedBy": 192,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Users of popular services like Twitter and Facebook are often simultaneously overwhelmed with the amount of information delivered via their social connections and miss out on much content that they might have liked to see, even though it was distributed outside of their social circle. Both issues serve as difficulties to the users and drawbacks to the services.\n Social media service providers can benefit from understanding user interests and how they interact with the service, potentially predicting their behaviors in the future. In this paper, we address the problem of simultaneously predicting user decisions and modeling users' interests in social media by analyzing rich information gathered from Twitter. The task differs from conventional recommender systems as the cold-start problem is ubiquitous, and rich features, including textual content, need to be considered. We build predictive models for user decisions in Twitter by proposing Co-Factorization Machines (CoFM), an extension of a state-of-the-art recommendation model, to handle multiple aspects of the dataset at the same time. Additionally, we discuss and compare ranking-based loss functions in the context of recommender systems, providing the first view of how they vary from each other and perform in real tasks. We explore an extensive set of features and conduct experiments on a real-world dataset, concluding that CoFM with ranking-based loss functions is superior to state-of-the-art methods and yields interpretable latent factors."
            },
            "slug": "Co-factorization-machines:-modeling-user-interests-Hong-Doumith",
            "title": {
                "fragments": [],
                "text": "Co-factorization machines: modeling user interests and predicting individual decisions in Twitter"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper builds predictive models for user decisions in Twitter by proposing Co-Factorization Machines (CoFM), an extension of a state-of-the-art recommendation model, to handle multiple aspects of the dataset at the same time, and concludes that CoFM with ranking-based loss functions is superior to state of theart methods and yields interpretable latent factors."
            },
            "venue": {
                "fragments": [],
                "text": "WSDM '13"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32689163"
                        ],
                        "name": "Immanuel Bayer",
                        "slug": "Immanuel-Bayer",
                        "structuredName": {
                            "firstName": "Immanuel",
                            "lastName": "Bayer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Immanuel Bayer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7792071"
                        ],
                        "name": "Xiangnan He",
                        "slug": "Xiangnan-He",
                        "structuredName": {
                            "firstName": "Xiangnan",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangnan He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3015985"
                        ],
                        "name": "Bhargav Kanagal",
                        "slug": "Bhargav-Kanagal",
                        "structuredName": {
                            "firstName": "Bhargav",
                            "lastName": "Kanagal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bhargav Kanagal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2843982"
                        ],
                        "name": "Steffen Rendle",
                        "slug": "Steffen-Rendle",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Rendle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steffen Rendle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 161
                            }
                        ],
                        "text": "Predictive analytics is one of the most important techniques for many information retrieval (IR) and data mining (DM) tasks, ranging from recommendation systems [2, 16], targeted advertising [21], to search ranking [19, 39], visual analysis [35], and event detection [40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 61
                            }
                        ],
                        "text": "While FM has yielded great promise1 in many prediction tasks [2, 8, 21, 24], we argue that its performance can be limited by its linearity, as well as the modelling of pairwise (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 37
                            }
                        ],
                        "text": "feature vector) via one-hot encoding [2, 9, 16, 30, 31]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 7953982,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5720a5015ca67400fadd0ff6863519f4b030e731",
            "isKey": false,
            "numCitedBy": 179,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years, interest in recommender research has shifted from explicit feedback towards implicit feedback data. A diversity of complex models has been proposed for a wide variety of applications. Despite this, learning from implicit feedback is still computationally challenging. So far, most work relies on stochastic gradient descent (SGD) solvers which are easy to derive, but in practice challenging to apply, especially for tasks with many items. For the simple matrix factorization model, an efficient coordinate descent (CD) solver has been previously proposed. However, efficient CD approaches have not been derived for more complex models. In this paper, we provide a new framework for deriving efficient CD algorithms for complex recommender models. We identify and introduce the property of k-separable models. We show that k-separability is a sufficient property to allow efficient optimization of implicit recommender problems with CD. We illustrate this framework on a variety of state-of-the-art models including factorization machines and Tucker decomposition. To summarize, our work provides the theory and building blocks to derive efficient implicit CD algorithms for complex recommender models."
            },
            "slug": "A-Generic-Coordinate-Descent-Framework-for-Learning-Bayer-He",
            "title": {
                "fragments": [],
                "text": "A Generic Coordinate Descent Framework for Learning from Implicit Feedback"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is shown that k-separability is a sufficient property to allow efficient optimization of implicit recommender problems with CD, and a new framework for deriving efficient CD algorithms for complex recommender models is provided."
            },
            "venue": {
                "fragments": [],
                "text": "WWW"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108237336"
                        ],
                        "name": "Pengfei Wang",
                        "slug": "Pengfei-Wang",
                        "structuredName": {
                            "firstName": "Pengfei",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pengfei Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777025"
                        ],
                        "name": "J. Guo",
                        "slug": "J.-Guo",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Guo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Guo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37510256"
                        ],
                        "name": "Yanyan Lan",
                        "slug": "Yanyan-Lan",
                        "structuredName": {
                            "firstName": "Yanyan",
                            "lastName": "Lan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yanyan Lan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39474114"
                        ],
                        "name": "Jun Xu",
                        "slug": "Jun-Xu",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2019211"
                        ],
                        "name": "Shengxian Wan",
                        "slug": "Shengxian-Wan",
                        "structuredName": {
                            "firstName": "Shengxian",
                            "lastName": "Wan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shengxian Wan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717004"
                        ],
                        "name": "Xueqi Cheng",
                        "slug": "Xueqi-Cheng",
                        "structuredName": {
                            "firstName": "Xueqi",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xueqi Cheng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 96
                            }
                        ],
                        "text": "In contrast to traditional deep learning methods that simply concatenate [9, 31, 44] or average [16, 36] embedding vectors in the low level, our use of Bi-Interaction pooling encodes more informative feature interactions, greatly facilitating the following \u201cdeep\u201d layers to learn meaningful information."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 138
                            }
                        ],
                        "text": "\u008cis property is the same with average/max pooling and concatenation that are rather simple but commonly used in neural network approaches [16, 31, 36]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 4002880,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "35e53252ddd38119379a894d5eec73c664d29455",
            "isKey": false,
            "numCitedBy": 315,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Next basket recommendation is a crucial task in market basket analysis. Given a user's purchase history, usually a sequence of transaction data, one attempts to build a recommender that can predict the next few items that the user most probably would like. Ideally, a good recommender should be able to explore the sequential behavior (i.e., buying one item leads to buying another next), as well as account for users' general taste (i.e., what items a user is typically interested in) for recommendation. Moreover, these two factors may interact with each other to influence users' next purchase. To tackle the above problems, in this paper, we introduce a novel recommendation approach, namely hierarchical representation model (HRM). HRM can well capture both sequential behavior and users' general taste by involving transaction and user representations in prediction. Meanwhile, the flexibility of applying different aggregation operations, especially nonlinear operations, on representations allows us to model complicated interactions among different factors. Theoretically, we show that our model subsumes several existing methods when choosing proper aggregation operations. Empirically, we demonstrate that our model can consistently outperform the state-of-the-art baselines under different evaluation metrics on real-world transaction data."
            },
            "slug": "Learning-Hierarchical-Representation-Model-for-Wang-Guo",
            "title": {
                "fragments": [],
                "text": "Learning Hierarchical Representation Model for NextBasket Recommendation"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper introduces a novel recommendation approach, namely hierarchical representation model (HRM), which can well capture both sequential behavior and users' general taste by involving transaction and user representations in prediction."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27257992"
                        ],
                        "name": "Mathieu Blondel",
                        "slug": "Mathieu-Blondel",
                        "structuredName": {
                            "firstName": "Mathieu",
                            "lastName": "Blondel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mathieu Blondel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784290"
                        ],
                        "name": "Masakazu Ishihata",
                        "slug": "Masakazu-Ishihata",
                        "structuredName": {
                            "firstName": "Masakazu",
                            "lastName": "Ishihata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Masakazu Ishihata"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34433830"
                        ],
                        "name": "Akinori Fujino",
                        "slug": "Akinori-Fujino",
                        "structuredName": {
                            "firstName": "Akinori",
                            "lastName": "Fujino",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Akinori Fujino"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735221"
                        ],
                        "name": "N. Ueda",
                        "slug": "N.-Ueda",
                        "structuredName": {
                            "firstName": "Naonori",
                            "lastName": "Ueda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ueda"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1529311,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6d791513a695aadf1271100d9bf12e3e05b04cc5",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Polynomial networks and factorization machines are two recently-proposed models that can efficiently use feature interactions in classification and regression tasks. In this paper, we revisit both models from a unified perspective. Based on this new view, we study the properties of both models and propose new efficient training algorithms. Key to our approach is to cast parameter learning as a low-rank symmetric tensor estimation problem, which we solve by multi-convex optimization. We demonstrate our approach on regression and recommender system tasks."
            },
            "slug": "Polynomial-Networks-and-Factorization-Machines:-New-Blondel-Ishihata",
            "title": {
                "fragments": [],
                "text": "Polynomial Networks and Factorization Machines: New Insights and Efficient Training Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This paper revisits polynomial networks and factorization machines from a unified perspective to cast parameter learning as a low-rank symmetric tensor estimation problem, which is solved by multi-convex optimization."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27257992"
                        ],
                        "name": "Mathieu Blondel",
                        "slug": "Mathieu-Blondel",
                        "structuredName": {
                            "firstName": "Mathieu",
                            "lastName": "Blondel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mathieu Blondel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34433830"
                        ],
                        "name": "Akinori Fujino",
                        "slug": "Akinori-Fujino",
                        "structuredName": {
                            "firstName": "Akinori",
                            "lastName": "Fujino",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Akinori Fujino"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735221"
                        ],
                        "name": "N. Ueda",
                        "slug": "N.-Ueda",
                        "structuredName": {
                            "firstName": "Naonori",
                            "lastName": "Ueda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Ueda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784290"
                        ],
                        "name": "Masakazu Ishihata",
                        "slug": "Masakazu-Ishihata",
                        "structuredName": {
                            "firstName": "Masakazu",
                            "lastName": "Ishihata",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Masakazu Ishihata"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 103
                            }
                        ],
                        "text": "\u008cis is advantageous to existing methods for higher-order interaction learning, such as higher-Order FM [3] and Exponential Machines [23], which only support the learning of higher-order interactions in a linear way."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2543489,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3f3b3dc86415ebda1043d2be55e75a29ffe2bd95",
            "isKey": false,
            "numCitedBy": 132,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Factorization machines (FMs) are a supervised learning approach that can use second-order feature combinations even when the data is very high-dimensional. Unfortunately, despite increasing interest in FMs, there exists to date no efficient training algorithm for higher-order FMs (HOFMs). In this paper, we present the first generic yet efficient algorithms for training arbitrary-order HOFMs. We also present new variants of HOFMs with shared parameters, which greatly reduce model size and prediction times while maintaining similar accuracy. We demonstrate the proposed approaches on four different link prediction tasks."
            },
            "slug": "Higher-Order-Factorization-Machines-Blondel-Fujino",
            "title": {
                "fragments": [],
                "text": "Higher-Order Factorization Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The first generic yet efficient algorithms for training arbitrary-order higher-orderFactorization machines (HOFMs) are presented and new variants of HOFMs with shared parameters are presented, which greatly reduce model size and prediction times while maintaining similar accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3114085"
                        ],
                        "name": "Junxuan Chen",
                        "slug": "Junxuan-Chen",
                        "structuredName": {
                            "firstName": "Junxuan",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Junxuan Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2033539"
                        ],
                        "name": "Baigui Sun",
                        "slug": "Baigui-Sun",
                        "structuredName": {
                            "firstName": "Baigui",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Baigui Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706574"
                        ],
                        "name": "Hao Li",
                        "slug": "Hao-Li",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46385957"
                        ],
                        "name": "Hongtao Lu",
                        "slug": "Hongtao-Lu",
                        "structuredName": {
                            "firstName": "Hongtao",
                            "lastName": "Lu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hongtao Lu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143863244"
                        ],
                        "name": "Xiansheng Hua",
                        "slug": "Xiansheng-Hua",
                        "structuredName": {
                            "firstName": "Xiansheng",
                            "lastName": "Hua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiansheng Hua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 31
                            }
                        ],
                        "text": "Until very recently, some work [6, 9, 16, 31, 44] started to explore DNNs for some scenarios of sparse predictive analytics."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14617126,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "75dd41322a55cfca831b47aef8b822ea4f093c3e",
            "isKey": false,
            "numCitedBy": 82,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Click through rate (CTR) prediction of image ads is the core task of online display advertising systems, and logistic regression (LR) has been frequently applied as the prediction model. However, LR model lacks the ability of extracting complex and intrinsic nonlinear features from handcrafted high-dimensional image features, which limits its effectiveness. To solve this issue, in this paper, we introduce a novel deep neural network (DNN) based model that directly predicts the CTR of an image ad based on raw image pixels and other basic features in one step. The DNN model employs convolution layers to automatically extract representative visual features from images, and nonlinear CTR features are then learned from visual features and other contextual features by using fully-connected layers. Empirical evaluations on a real world dataset with over 50 million records demonstrate the effectiveness and efficiency of this method."
            },
            "slug": "Deep-CTR-Prediction-in-Display-Advertising-Chen-Sun",
            "title": {
                "fragments": [],
                "text": "Deep CTR Prediction in Display Advertising"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel deep neural network (DNN) based model is introduced that directly predicts the CTR of an image ad based on raw image pixels and other basic features in one step."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Multimedia"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2843982"
                        ],
                        "name": "Steffen Rendle",
                        "slug": "Steffen-Rendle",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Rendle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steffen Rendle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1825333"
                        ],
                        "name": "C. Freudenthaler",
                        "slug": "C.-Freudenthaler",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Freudenthaler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Freudenthaler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2382247"
                        ],
                        "name": "Zeno Gantner",
                        "slug": "Zeno-Gantner",
                        "structuredName": {
                            "firstName": "Zeno",
                            "lastName": "Gantner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zeno Gantner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388781075"
                        ],
                        "name": "L. Schmidt-Thieme",
                        "slug": "L.-Schmidt-Thieme",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Schmidt-Thieme",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Schmidt-Thieme"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 69
                            }
                        ],
                        "text": "For ranking task, we can optimize pairwise personalized ranking loss [29, 37] or contrastive max-margin loss [43]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10795036,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "db16e908246f32b60a6e0a8e27093aa145fbb1ed",
            "isKey": false,
            "numCitedBy": 3865,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Item recommendation is the task of predicting a personalized ranking on a set of items (e.g. websites, movies, products). In this paper, we investigate the most common scenario with implicit feedback (e.g. clicks, purchases). There are many methods for item recommendation from implicit feedback like matrix factorization (MF) or adaptive k-nearest-neighbor (kNN). Even though these methods are designed for the item prediction task of personalized ranking, none of them is directly optimized for ranking. In this paper we present a generic optimization criterion BPR-Opt for personalized ranking that is the maximum posterior estimator derived from a Bayesian analysis of the problem. We also provide a generic learning algorithm for optimizing models with respect to BPR-Opt. The learning method is based on stochastic gradient descent with bootstrap sampling. We show how to apply our method to two state-of-the-art recommender models: matrix factorization and adaptive kNN. Our experiments indicate that for the task of personalized ranking our optimization method outperforms the standard learning techniques for MF and kNN. The results show the importance of optimizing models for the right criterion."
            },
            "slug": "BPR:-Bayesian-Personalized-Ranking-from-Implicit-Rendle-Freudenthaler",
            "title": {
                "fragments": [],
                "text": "BPR: Bayesian Personalized Ranking from Implicit Feedback"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper presents a generic optimization criterion BPR-Opt for personalized ranking that is the maximum posterior estimator derived from a Bayesian analysis of the problem and provides a generic learning algorithm for optimizing models with respect to B PR-Opt."
            },
            "venue": {
                "fragments": [],
                "text": "UAI"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2843982"
                        ],
                        "name": "Steffen Rendle",
                        "slug": "Steffen-Rendle",
                        "structuredName": {
                            "firstName": "Steffen",
                            "lastName": "Rendle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steffen Rendle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2382247"
                        ],
                        "name": "Zeno Gantner",
                        "slug": "Zeno-Gantner",
                        "structuredName": {
                            "firstName": "Zeno",
                            "lastName": "Gantner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zeno Gantner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1825333"
                        ],
                        "name": "C. Freudenthaler",
                        "slug": "C.-Freudenthaler",
                        "structuredName": {
                            "firstName": "Christoph",
                            "lastName": "Freudenthaler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Freudenthaler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388781075"
                        ],
                        "name": "L. Schmidt-Thieme",
                        "slug": "L.-Schmidt-Thieme",
                        "structuredName": {
                            "firstName": "Lars",
                            "lastName": "Schmidt-Thieme",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Schmidt-Thieme"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207189080,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1683ffc189d16b616131c300f45af87602d211f7",
            "isKey": false,
            "numCitedBy": 517,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The situation in which a choice is made is an important information for recommender systems. Context-aware recommenders take this information into account to make predictions. So far, the best performing method for context-aware rating prediction in terms of predictive accuracy is Multiverse Recommendation based on the Tucker tensor factorization model. However this method has two drawbacks: (1) its model complexity is exponential in the number of context variables and polynomial in the size of the factorization and (2) it only works for categorical context variables. On the other hand there is a large variety of fast but specialized recommender methods which lack the generality of context-aware methods. We propose to apply Factorization Machines (FMs) to model contextual information and to provide context-aware rating predictions. This approach results in fast context-aware recommendations because the model equation of FMs can be computed in linear time both in the number of context variables and the factorization size. For learning FMs, we develop an iterative optimization method that analytically finds the least-square solution for one parameter given the other ones. Finally, we show empirically that our approach outperforms Multiverse Recommendation in prediction quality and runtime."
            },
            "slug": "Fast-context-aware-recommendations-with-machines-Rendle-Gantner",
            "title": {
                "fragments": [],
                "text": "Fast context-aware recommendations with factorization machines"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This work proposes to apply Factorization Machines (FMs) to model contextual information and to provide context-aware rating predictions and shows empirically that this approach outperforms Multiverse Recommendation in prediction quality and runtime."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8775916"
                        ],
                        "name": "Da Cao",
                        "slug": "Da-Cao",
                        "structuredName": {
                            "firstName": "Da",
                            "lastName": "Cao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Da Cao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7792071"
                        ],
                        "name": "Xiangnan He",
                        "slug": "Xiangnan-He",
                        "structuredName": {
                            "firstName": "Xiangnan",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangnan He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143982887"
                        ],
                        "name": "Liqiang Nie",
                        "slug": "Liqiang-Nie",
                        "structuredName": {
                            "firstName": "Liqiang",
                            "lastName": "Nie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liqiang Nie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7621447"
                        ],
                        "name": "Xiaochi Wei",
                        "slug": "Xiaochi-Wei",
                        "structuredName": {
                            "firstName": "Xiaochi",
                            "lastName": "Wei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaochi Wei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48539382"
                        ],
                        "name": "Xia Hu",
                        "slug": "Xia-Hu",
                        "structuredName": {
                            "firstName": "Xia",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xia Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3241809"
                        ],
                        "name": "Shunxiang Wu",
                        "slug": "Shunxiang-Wu",
                        "structuredName": {
                            "firstName": "Shunxiang",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shunxiang Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144078686"
                        ],
                        "name": "Tat-Seng Chua",
                        "slug": "Tat-Seng-Chua",
                        "structuredName": {
                            "firstName": "Tat-Seng",
                            "lastName": "Chua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tat-Seng Chua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 113
                            }
                        ],
                        "text": "Note that RMSE has been widely used for evaluating regression tasks such as recommendation with explicit ratings [5, 30] and click-through rate prediction [24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 13925572,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82480125b4a2eeffa94b6428c7c6f269dc1bc364",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "Over the last decade, the renaissance of Web technologies has transformed the online world into an application (App) driven society. While the abundant Apps have provided great convenience, their sheer number also leads to severe information overload, making it difficult for users to identify desired Apps. To alleviate the information overloading issue, recommender systems have been proposed and deployed for the App domain. However, existing work on App recommendation has largely focused on one single platform (e.g., smartphones), while it ignores the rich data of other relevant platforms (e.g., tablets and computers). In this article, we tackle the problem of cross-platform App recommendation, aiming at leveraging users\u2019 and Apps\u2019 data on multiple platforms to enhance the recommendation accuracy. The key advantage of our proposal is that by leveraging multiplatform data, the perpetual issues in personalized recommender systems\u2014data sparsity and cold-start\u2014can be largely alleviated. To this end, we propose a hybrid solution, STAR (short for \u201ccroSs-plaTform App Recommendation\u201d) that integrates both numerical ratings and textual content from multiple platforms. In STAR, we innovatively represent an App as an aggregation of common features across platforms (e.g., App\u2019s functionalities) and specific features that are dependent on the resided platform. In light of this, STAR can discriminate a user\u2019s preference on an App by separating the user\u2019s interest into two parts (either in the App\u2019s inherent factors or platform-aware features). To evaluate our proposal, we construct two real-world datasets that are crawled from the App stores of iPhone, iPad, and iMac. Through extensive experiments, we show that our STAR method consistently outperforms highly competitive recommendation methods, justifying the rationality of our cross-platform App recommendation proposal and the effectiveness of our solution."
            },
            "slug": "Cross-Platform-App-Recommendation-by-Jointly-and-Cao-He",
            "title": {
                "fragments": [],
                "text": "Cross-Platform App Recommendation by Jointly Modeling Ratings and Texts"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This article proposes a hybrid solution, STAR (short for \u201ccroSs-plaTform App Recommendation\u201d) that integrates both numerical ratings and textual content from multiple platforms, and innovatively represents an App as an aggregation of common features across platforms and specific features that are dependent on the resided platform."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Trans. Inf. Syst."
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145089705"
                        ],
                        "name": "Y. Shan",
                        "slug": "Y.-Shan",
                        "structuredName": {
                            "firstName": "Ying",
                            "lastName": "Shan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Shan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755821"
                        ],
                        "name": "T. R. Hoens",
                        "slug": "T.-R.-Hoens",
                        "structuredName": {
                            "firstName": "T.",
                            "lastName": "Hoens",
                            "middleNames": [
                                "Ryan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. R. Hoens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49097406"
                        ],
                        "name": "Jian Jiao",
                        "slug": "Jian-Jiao",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Jiao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Jiao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145341507"
                        ],
                        "name": "Haijing Wang",
                        "slug": "Haijing-Wang",
                        "structuredName": {
                            "firstName": "Haijing",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haijing Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144580027"
                        ],
                        "name": "Dong Yu",
                        "slug": "Dong-Yu",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143877014"
                        ],
                        "name": "J. C. Mao",
                        "slug": "J.-C.-Mao",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Mao",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. C. Mao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9704646,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a83c778e918539941cba9dcaa6ec881b3ae7a29a",
            "isKey": false,
            "numCitedBy": 288,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Manually crafted combinatorial features have been the \"secret sauce\" behind many successful models. For web-scale applications, however, the variety and volume of features make these manually crafted features expensive to create, maintain, and deploy. This paper proposes the Deep Crossing model which is a deep neural network that automatically combines features to produce superior models. The input of Deep Crossing is a set of individual features that can be either dense or sparse. The important crossing features are discovered implicitly by the networks, which are comprised of an embedding and stacking layer, as well as a cascade of Residual Units. Deep Crossing is implemented with a modeling tool called the Computational Network Tool Kit (CNTK), powered by a multi-GPU platform. It was able to build, from scratch, two web-scale models for a major paid search engine, and achieve superior results with only a sub-set of the features used in the production models. This demonstrates the potential of using Deep Crossing as a general modeling paradigm to improve existing products, as well as to speed up the development of new models with a fraction of the investment in feature engineering and acquisition of deep domain knowledge."
            },
            "slug": "Deep-Crossing:-Web-Scale-Modeling-without-Manually-Shan-Hoens",
            "title": {
                "fragments": [],
                "text": "Deep Crossing: Web-Scale Modeling without Manually Crafted Combinatorial Features"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The Deep Crossing model is proposed which is a deep neural network that automatically combines features to produce superior models and was able to build, from scratch, two web-scale models for a major paid search engine, and achieve superior results with only a sub-set of the features used in the production models."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47446553"
                        ],
                        "name": "Meng Wang",
                        "slug": "Meng-Wang",
                        "structuredName": {
                            "firstName": "Meng",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Meng Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3076466"
                        ],
                        "name": "Xueliang Liu",
                        "slug": "Xueliang-Liu",
                        "structuredName": {
                            "firstName": "Xueliang",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xueliang Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145502658"
                        ],
                        "name": "Xindong Wu",
                        "slug": "Xindong-Wu",
                        "structuredName": {
                            "firstName": "Xindong",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xindong Wu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 43050484,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e0e1a359c0617be201d4e9ddfd021ed950dc0940",
            "isKey": false,
            "numCitedBy": 108,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "Visual classification has attracted considerable research interests in the past decades. In this paper, a novel $\\ell _1$ -hypergraph model for visual classification is proposed. Hypergraph learning, as a natural extension of graph model, has been widely used in many machine learning tasks. In previous work, hypergraph is usually constructed by attribute-based or neighborhood-based methods. That is, a hyperedge is generated by connecting a set of samples sharing a same feature attribute or in a neighborhood. However, these methods are unable to explore feature space globally or sensitive to noises. To address these problems, we propose a novel hypergraph construction approach that leverages sparse representation to generate hyperedges and learns the relationship among hyperedges and their vertices. First, for each sample, a hyperedge is generated by regarding it as the centroid and linking it as well as its nearest neighbors. Then, the sparse representation method is applied to represent the centroid vertex by other vertices within the same hyperedge. The vertices with zero coefficients are removed from the hyperedge. Finally, the representation coefficients are used to define the incidence relation between the hyperedge and the vertices. In our approach, we also optimize the hyperedge weights to modulate the effects of different hyperedges. We leverage the prior knowledge on the hyperedges so that the hyperedges sharing more vertices can have closer weights, where a graph Laplacian is used to regularize the optimization of the weights. Our approach is named $\\ell _1$ -hypergraph since the $\\ell _1$ sparse representation is employed in the hypergraph construction process. The method is evaluated on various visual classification tasks, and it demonstrates promising performance."
            },
            "slug": "Visual-Classification-by-\u21131-Hypergraph-Modeling-Wang-Liu",
            "title": {
                "fragments": [],
                "text": "Visual Classification by \u21131-Hypergraph Modeling"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "A novel hypergraph construction approach that leverages sparse representation to generate hyperedge and learns the relationship among hyperedges and their vertices is proposed and evaluated on various visual classification tasks."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Knowl. Data Eng."
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054165706"
                        ],
                        "name": "S. Ioffe",
                        "slug": "S.-Ioffe",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Ioffe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ioffe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2574060"
                        ],
                        "name": "Christian Szegedy",
                        "slug": "Christian-Szegedy",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Szegedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Szegedy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5808102,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d376d6978dad0374edfa6709c9556b42d3594d3",
            "isKey": false,
            "numCitedBy": 31492,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters."
            },
            "slug": "Batch-Normalization:-Accelerating-Deep-Network-by-Ioffe-Szegedy",
            "title": {
                "fragments": [],
                "text": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40052301"
                        ],
                        "name": "Fabio Petroni",
                        "slug": "Fabio-Petroni",
                        "structuredName": {
                            "firstName": "Fabio",
                            "lastName": "Petroni",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fabio Petroni"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1875906"
                        ],
                        "name": "Luciano Del Corro",
                        "slug": "Luciano-Del-Corro",
                        "structuredName": {
                            "firstName": "Luciano",
                            "lastName": "Corro",
                            "middleNames": [
                                "Del"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luciano Del Corro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777107"
                        ],
                        "name": "Rainer Gemulla",
                        "slug": "Rainer-Gemulla",
                        "structuredName": {
                            "firstName": "Rainer",
                            "lastName": "Gemulla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rainer Gemulla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 155,
                                "start": 151
                            }
                        ],
                        "text": "It has been successfully applied to many predictive tasks, ranging from online advertising [21], microblog retrieval [26], to open relation extraction [25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7236297,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b471a6c7e1d45c78e78ea7b06f6f798a905ae304",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose CORE, a novel matrix factorization model that leverages contextual information for open relation extraction. Our model is based on factorization machines and integrates facts from various sources, such as knowledge bases or open information extractors, as well as the context in which these facts have been observed. We argue that integrating contextual information\u2014such as metadata about extraction sources, lexical context, or type information\u2014significantly improves prediction performance. Open information extractors, for example, may produce extractions that are unspecific or ambiguous when taken out of context. Our experimental study on a large real-world dataset indicates that CORE has significantly better prediction performance than state-ofthe-art approaches when contextual information is available."
            },
            "slug": "CORE:-Context-Aware-Open-Relation-Extraction-with-Petroni-Corro",
            "title": {
                "fragments": [],
                "text": "CORE: Context-Aware Open Relation Extraction with Factorization Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This work argues that integrating contextual information\u2014such as metadata about extraction sources, lexical context, or type information\u2014significantly improves prediction performance and proposes CORE, a novel matrix factorization model that leverages contextual information for open relation extraction."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701121"
                        ],
                        "name": "Y. Koren",
                        "slug": "Y.-Koren",
                        "structuredName": {
                            "firstName": "Yehuda",
                            "lastName": "Koren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Koren"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 207168823,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cf6f83fcce274606bf0264c59d1c78a30c9c9d18",
            "isKey": false,
            "numCitedBy": 3612,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Recommender systems provide users with personalized suggestions for products or services. These systems often rely on Collaborating Filtering (CF), where past transactions are analyzed in order to establish connections between users and products. The two more successful approaches to CF are latent factor models, which directly profile both users and products, and neighborhood models, which analyze similarities between products or users. In this work we introduce some innovations to both approaches. The factor and neighborhood models can now be smoothly merged, thereby building a more accurate combined model. Further accuracy improvements are achieved by extending the models to exploit both explicit and implicit feedback by the users. The methods are tested on the Netflix data. Results are better than those previously published on that dataset. In addition, we suggest a new evaluation metric, which highlights the differences among methods, based on their performance at a top-K recommendation task."
            },
            "slug": "Factorization-meets-the-neighborhood:-a-filtering-Koren",
            "title": {
                "fragments": [],
                "text": "Factorization meets the neighborhood: a multifaceted collaborative filtering model"
            },
            "tldr": {
                "abstractSimilarityScore": 37,
                "text": "The factor and neighborhood models can now be smoothly merged, thereby building a more accurate combined model and a new evaluation metric is suggested, which highlights the differences among methods, based on their performance at a top-K recommendation task."
            },
            "venue": {
                "fragments": [],
                "text": "KDD"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2897313"
                        ],
                        "name": "Nitish Srivastava",
                        "slug": "Nitish-Srivastava",
                        "structuredName": {
                            "firstName": "Nitish",
                            "lastName": "Srivastava",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nitish Srivastava"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6844431,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34f25a8704614163c4095b3ee2fc969b60de4698",
            "isKey": false,
            "numCitedBy": 29832,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different \"thinned\" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets."
            },
            "slug": "Dropout:-a-simple-way-to-prevent-neural-networks-Srivastava-Hinton",
            "title": {
                "fragments": [],
                "text": "Dropout: a simple way to prevent neural networks from overfitting"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771551"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3080683"
                        ],
                        "name": "Shaoqing Ren",
                        "slug": "Shaoqing-Ren",
                        "structuredName": {
                            "firstName": "Shaoqing",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoqing Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "Speci\u0080cally, if we replace the Bi-Interaction pooling with concatenation and apply a tower-structure MLP (or residual units [14]) to hidden layers, we can recover the Wide&Deep (or DeepCross) model."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 141
                            }
                        ],
                        "text": "With recent developments on GPU platforms, it is not technically di\u0081cult to build very deep models with hundreds or even thousands of layers [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 109
                            }
                        ],
                        "text": "It has been shown that BN leads to faster convergence and be\u008aer performance in several computer vision tasks [14, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 160,
                                "start": 156
                            }
                        ],
                        "text": "[31] proposed DeepCross for ads prediction, which shares a similar framework with Wide&Deep by replacing the MLP with the state-of-the-art residual network [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 274,
                                "start": 270
                            }
                        ],
                        "text": "While it is claimed that multiple non-linear layers are able to learn feature interactions well [9, 31], such a deep architecture can be di\u0081cult to optimize in practice due to the notorious problems of vanishing/exploding gradients, over\u0080\u008aing, degradation, among others [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 105
                            }
                        ],
                        "text": "For Wide&Deep, the training error is relatively high, which is likely because of the degradation problem [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 77
                            }
                        ],
                        "text": "Although DNNs have exhibited strong ability to learn pa\u008aerns from dense data [14], the use of DNNs on sparse data has received less scrutiny, and it is unclear how to employ DNNs for e\u0082ectively learning feature interactions under sparse se\u008aings."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 293,
                                "start": 285
                            }
                        ],
                        "text": "Focusing on the training error, we can see that BN leads to a faster convergence; on Frappe, when BN is applied, the training error of epoch 20 is even lower than that of epoch 60 without BN; and the validation error indicates that the lower training error is not over\u0080\u008aing \u2014 in fact, [14, 20] showed that by addressing the internal covariate shi\u0089 with BN, the model\u2019s generalization ability can be improved."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206594692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "isKey": true,
            "numCitedBy": 106571,
            "numCiting": 54,
            "paperAbstract": {
                "fragments": [],
                "text": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation."
            },
            "slug": "Deep-Residual-Learning-for-Image-Recognition-He-Zhang",
            "title": {
                "fragments": [],
                "text": "Deep Residual Learning for Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work presents a residual learning framework to ease the training of networks that are substantially deeper than those used previously, and provides comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761978"
                        ],
                        "name": "D. Erhan",
                        "slug": "D.-Erhan",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Erhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Erhan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1760871"
                        ],
                        "name": "Aaron C. Courville",
                        "slug": "Aaron-C.-Courville",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Courville",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron C. Courville"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120247189"
                        ],
                        "name": "Pascal Vincent",
                        "slug": "Pascal-Vincent",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Vincent",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Vincent"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 99
                            }
                        ],
                        "text": "Inspired by FNN [44], we further explore the use of feature embeddings learned by FM to initialize DNNs, which can be seen as a pre-training step."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "Although DNNs have exhibited strong ability to learn pa erns from dense data [14], the use of DNNs on sparse data has received less scrutiny, and it is unclear how to employ DNNs for e ectively learning feature interactions under sparse se ings."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "Until very recently, some work [6, 9, 16, 31, 44] started to explore DNNs for some scenarios of sparse predictive analytics."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "To demonstrate optimization di culties of DNNs empirically, we plot the training and test error of each epoch of Wide&Deep and DeepCross on the Frappe data in Figure 1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 100
                            }
                        ],
                        "text": "It is known that parameter initialization can greatly a\u0082ect the convergence and performance of DNNs [11, 16], since gradient-based methods can only \u0080nd local optima for DNNs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "However, the use of DNNs is not as widespread among the IR and DM community."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 127
                            }
                        ],
                        "text": "Zhang et al. [44] developed a FM-supported Neural Network (FNN), which uses the feature embeddings learned by FM to initialize DNNs. Cheng et al. [9] proposed Wide&Deep for App recommendation, where the deep part is a multi-layer perceptron (MLP) on the concatenation of feature embedding vectors to learn feature interactions."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 174
                            }
                        ],
                        "text": "However for the 10-layer DeepCross, it still su ers from severe over ing and underperforms LibFM. ese relatively negative results reveal optimization di culties for training DNNs."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "In recent ve years, deep neural networks (DNNs) have achieved immense success and have been widely used on speech recognition, computer vision and natural language processing."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 95
                            }
                        ],
                        "text": "It is known that parameter initialization can greatly a ect the convergence and performance of DNNs [11, 16], since gradient-based methods can only nd local optima for DNNs."
                    },
                    "intents": []
                }
            ],
            "corpusId": 15796526,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0d2336389dff3031910bd21dd1c44d1b4cd51725",
            "isKey": true,
            "numCitedBy": 1929,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Much recent research has been devoted to learning algorithms for deep architectures such as Deep Belief Networks and stacks of auto-encoder variants, with impressive results obtained in several areas, mostly on vision and language data sets. The best results obtained on supervised learning tasks involve an unsupervised learning component, usually in an unsupervised pre-training phase. Even though these new algorithms have enabled training deep models, many questions remain as to the nature of this difficult learning problem. The main question investigated here is the following: how does unsupervised pre-training work? Answering this questions is important if learning in deep architectures is to be further improved. We propose several explanatory hypotheses and test them through extensive simulations. We empirically show the influence of pre-training with respect to architecture depth, model capacity, and number of training examples. The experiments confirm and clarify the advantage of unsupervised pre-training. The results suggest that unsupervised pre-training guides the learning towards basins of attraction of minima that support better generalization from the training data set; the evidence from these results supports a regularization explanation for the effect of pre-training."
            },
            "slug": "Why-Does-Unsupervised-Pre-training-Help-Deep-Erhan-Courville",
            "title": {
                "fragments": [],
                "text": "Why Does Unsupervised Pre-training Help Deep Learning?"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The results suggest that unsupervised pre-training guides the learning towards basins of attraction of minima that support better generalization from the training data set; the evidence from these results supports a regularization explanation for the effect of pre- training."
            },
            "venue": {
                "fragments": [],
                "text": "AISTATS"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47446553"
                        ],
                        "name": "Meng Wang",
                        "slug": "Meng-Wang",
                        "structuredName": {
                            "firstName": "Meng",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Meng Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50091230"
                        ],
                        "name": "Weijie Fu",
                        "slug": "Weijie-Fu",
                        "structuredName": {
                            "firstName": "Weijie",
                            "lastName": "Fu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weijie Fu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6175623"
                        ],
                        "name": "Shijie Hao",
                        "slug": "Shijie-Hao",
                        "structuredName": {
                            "firstName": "Shijie",
                            "lastName": "Hao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shijie Hao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143719920"
                        ],
                        "name": "D. Tao",
                        "slug": "D.-Tao",
                        "structuredName": {
                            "firstName": "Dacheng",
                            "lastName": "Tao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145502658"
                        ],
                        "name": "Xindong Wu",
                        "slug": "Xindong-Wu",
                        "structuredName": {
                            "firstName": "Xindong",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xindong Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18856812,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a4be6fa575bf7325514acfd38a7d1c19e42b37a9",
            "isKey": false,
            "numCitedBy": 138,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "Many graph-based semi-supervised learning methods for large datasets have been proposed to cope with the rapidly increasing size of data, such as Anchor Graph Regularization (AGR). This model builds a regularization framework by exploring the underlying structure of the whole dataset with both datapoints and anchors. Nevertheless, AGR still has limitations in its two components: (1) in anchor graph construction, the estimation of the local weights between each datapoint and its neighboring anchors could be biased and relatively slow; and (2) in anchor graph regularization, the adjacency matrix that estimates the relationship between datapoints, is not sufficiently effective. In this paper, we develop an Efficient Anchor Graph Regularization (EAGR) by tackling these issues. First, we propose a fast local anchor embedding method, which reformulates the optimization of local weights and obtains an analytical solution. We show that this method better reconstructs datapoints with anchors and speeds up the optimizing process. Second, we propose a new adjacency matrix among anchors by considering the commonly linked datapoints, which leads to a more effective normalized graph Laplacian over anchors. We show that, with the novel local weight estimation and normalized graph Laplacian, EAGR is able to achieve better classification accuracy with much less computational costs. Experimental results on several publicly available datasets demonstrate the effectiveness of our approach."
            },
            "slug": "Scalable-Semi-Supervised-Learning-by-Efficient-Wang-Fu",
            "title": {
                "fragments": [],
                "text": "Scalable Semi-Supervised Learning by Efficient Anchor Graph Regularization"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A fast local anchor embedding method, which reformulates the optimization of local weights and obtains an analytical solution, and a new adjacency matrix among anchors by considering the commonly linked datapoints, which leads to a more effective normalized graph Laplacian over anchors."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Knowledge and Data Engineering"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7792071"
                        ],
                        "name": "Xiangnan He",
                        "slug": "Xiangnan-He",
                        "structuredName": {
                            "firstName": "Xiangnan",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangnan He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46572901"
                        ],
                        "name": "Ming Gao",
                        "slug": "Ming-Gao",
                        "structuredName": {
                            "firstName": "Ming",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37596605"
                        ],
                        "name": "Min-Yen Kan",
                        "slug": "Min-Yen-Kan",
                        "structuredName": {
                            "firstName": "Min-Yen",
                            "lastName": "Kan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Min-Yen Kan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783406"
                        ],
                        "name": "Yiqun Liu",
                        "slug": "Yiqun-Liu",
                        "structuredName": {
                            "firstName": "Yiqun",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiqun Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3060386"
                        ],
                        "name": "Kazunari Sugiyama",
                        "slug": "Kazunari-Sugiyama",
                        "structuredName": {
                            "firstName": "Kazunari",
                            "lastName": "Sugiyama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kazunari Sugiyama"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 226,
                                "start": 218
                            }
                        ],
                        "text": "While this work endows FM with non-linearities from predictive model perspective, another viable solution for incorporating nonlinearities is to extend the objective function with regularizers like the graph Laplacian [15, 34]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 893103,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b1d4273d1c967c10680aca02deebb125243b713",
            "isKey": false,
            "numCitedBy": 97,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "In the current Web 2.0 era, the popularity of Web resources fluctuates ephemerally, based on trends and social interest. As a result, content-based relevance signals are insufficient to meet users' constantly evolving information needs in searching for Web 2.0 items. Incorporating future popularity into ranking is one way to counter this. However, predicting popularity as a third party (as in the case of general search engines) is difficult in practice, due to their limited access to item view histories. To enable popularity prediction externally without excessive crawling, we propose an alternative solution by leveraging user comments, which are more accessible than view counts. Due to the sparsity of comments, traditional solutions that are solely based on view histories do not perform well. To deal with this sparsity, we mine comments to recover additional signal, such as social influence. By modeling comments as a time-aware bipartite graph, we propose a regularization-based ranking algorithm that accounts for temporal, social influence and current popularity factors to predict the future popularity of items. Experimental results on three real-world datasets --- crawled from YouTube, Flickr and Last.fm --- show that our method consistently outperforms competitive baselines in several evaluation tasks."
            },
            "slug": "Predicting-the-popularity-of-web-2.0-items-based-on-He-Gao",
            "title": {
                "fragments": [],
                "text": "Predicting the popularity of web 2.0 items based on user comments"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "By modeling comments as a time-aware bipartite graph, this work proposes a regularization-based ranking algorithm that accounts for temporal, social influence and current popularity factors to predict the future popularity of items."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5462268"
                        ],
                        "name": "Hanwang Zhang",
                        "slug": "Hanwang-Zhang",
                        "structuredName": {
                            "firstName": "Hanwang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanwang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47446553"
                        ],
                        "name": "Meng Wang",
                        "slug": "Meng-Wang",
                        "structuredName": {
                            "firstName": "Meng",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Meng Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48043335"
                        ],
                        "name": "Richang Hong",
                        "slug": "Richang-Hong",
                        "structuredName": {
                            "firstName": "Richang",
                            "lastName": "Hong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richang Hong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144078686"
                        ],
                        "name": "Tat-Seng Chua",
                        "slug": "Tat-Seng-Chua",
                        "structuredName": {
                            "firstName": "Tat-Seng",
                            "lastName": "Chua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tat-Seng Chua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 109
                            }
                        ],
                        "text": "It has been shown that BN leads to faster convergence and be\u008aer performance in several computer vision tasks [14, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 755578,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7c3ab4a8947a0d1d1014d3e09dcba7485db5ea22",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "We focus on hashing videos into short binary codes for efficient Content-based Video Retrieval (CBVR), which is a fundamental technique that supports access to the ever-growing abundance of videos on the Web. Existing video hash functions are built on three isolated stages: frame pooling, relaxed learning, and binarization, which have not adequately explored the temporal order of video frames in a joint binary optimization model, resulting in severe information loss. In this paper, we propose a novel unsupervised video hashing framework called Self-Supervised Temporal Hashing (SSTH) that is able to capture the temporal nature of videos in an end-to-end learning-to-hash fashion. Specifically, the hash function of SSTH is an encoder RNN equipped with the proposed Binary LSTM (BLSTM) that generates binary codes for videos. The hash function is learned in a self-supervised fashion, where a decoder RNN is proposed to reconstruct the original video frames in both forward and reverse orders. For binary code optimization, we develop a backpropagation rule that tackles the non-differentiability of BLSTM. This rule allows efficient deep network training without suffering from the binarization loss. Through extensive CBVR experiments on two real-world consumer video datasets of Youtube and Flickr, we show that SSTH consistently outperforms state-of-the-art video hashing methods, eg., in terms of mAP@20, SSTH using only 128 bits can still outperform others using 256 bits by at least 9% to 15% on both datasets."
            },
            "slug": "Play-and-Rewind:-Optimizing-Binary-Representations-Zhang-Wang",
            "title": {
                "fragments": [],
                "text": "Play and Rewind: Optimizing Binary Representations of Videos by Self-Supervised Temporal Hashing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper proposes a novel unsupervised video hashing framework called Self-Supervised Temporal Hashing (SSTH) that is able to capture the temporal nature of videos in an end- to-end learning-to-hash fashion and develops a backpropagation rule that tackles the non-differentiability of BLSTM."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Multimedia"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48043335"
                        ],
                        "name": "Richang Hong",
                        "slug": "Richang-Hong",
                        "structuredName": {
                            "firstName": "Richang",
                            "lastName": "Hong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Richang Hong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6897666"
                        ],
                        "name": "Yang Yang",
                        "slug": "Yang-Yang",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47446553"
                        ],
                        "name": "Meng Wang",
                        "slug": "Meng-Wang",
                        "structuredName": {
                            "firstName": "Meng",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Meng Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143863244"
                        ],
                        "name": "Xiansheng Hua",
                        "slug": "Xiansheng-Hua",
                        "structuredName": {
                            "firstName": "Xiansheng",
                            "lastName": "Hua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiansheng Hua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14000804,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9a89bcb1a6122b2d17079b56f14e26edc8c6426b",
            "isKey": false,
            "numCitedBy": 98,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we investigate how to establish the relationship between semantic concepts based on the large-scale realworld click data from image commercial engine, which is a challenging topic because the click data suffers from the noise such as typos, the same concept with different queries, etc. We first define five specific relationships between concepts. We then extract some concept relationship features in textual and visual domain to train the concept relationship models. The relationship of each pair of concepts will thus be classified into one of the five special relationships. We study the efficacy of the conceptual relationships by applying them to augment imperfect image tags, i.e., improve representative power. We further employ a sophisticated hashing approach to transform augmented image tags into binary codes, which are subsequently used for content-based image retrieval task. Experimental results on NUS-WIDE dataset demonstrate the superiority of our proposed approach as compared to state-of-the-art methods."
            },
            "slug": "Learning-Visual-Semantic-Relationships-for-Visual-Hong-Yang",
            "title": {
                "fragments": [],
                "text": "Learning Visual Semantic Relationships for Efficient Visual Retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "This paper investigates how to establish the relationship between semantic concepts based on the large-scale realworld click data from image commercial engine, which is a challenging topic because the click data suffers from the noise such as typos."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Big Data"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5462268"
                        ],
                        "name": "Hanwang Zhang",
                        "slug": "Hanwang-Zhang",
                        "structuredName": {
                            "firstName": "Hanwang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanwang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144618699"
                        ],
                        "name": "Fumin Shen",
                        "slug": "Fumin-Shen",
                        "structuredName": {
                            "firstName": "Fumin",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fumin Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46641573"
                        ],
                        "name": "W. Liu",
                        "slug": "W.-Liu",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7792071"
                        ],
                        "name": "Xiangnan He",
                        "slug": "Xiangnan-He",
                        "structuredName": {
                            "firstName": "Xiangnan",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangnan He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3371599"
                        ],
                        "name": "Huanbo Luan",
                        "slug": "Huanbo-Luan",
                        "structuredName": {
                            "firstName": "Huanbo",
                            "lastName": "Luan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huanbo Luan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144078686"
                        ],
                        "name": "Tat-Seng Chua",
                        "slug": "Tat-Seng-Chua",
                        "structuredName": {
                            "firstName": "Tat-Seng",
                            "lastName": "Chua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tat-Seng Chua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13124023,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b526b9b39046d3661160256153a5b602166f316a",
            "isKey": false,
            "numCitedBy": 217,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We address the efficiency problem of Collaborative Filtering (CF) by hashing users and items as latent vectors in the form of binary codes, so that user-item affinity can be efficiently calculated in a Hamming space. However, existing hashing methods for CF employ binary code learning procedures that most suffer from the challenging discrete constraints. Hence, those methods generally adopt a two-stage learning scheme composed of relaxed optimization via discarding the discrete constraints, followed by binary quantization. We argue that such a scheme will result in a large quantization loss, which especially compromises the performance of large-scale CF that resorts to longer binary codes. In this paper, we propose a principled CF hashing framework called Discrete Collaborative Filtering (DCF), which directly tackles the challenging discrete optimization that should have been treated adequately in hashing. The formulation of DCF has two advantages: 1) the Hamming similarity induced loss that preserves the intrinsic user-item similarity, and 2) the balanced and uncorrelated code constraints that yield compact yet informative binary codes. We devise a computationally efficient algorithm with a rigorous convergence proof of DCF. Through extensive experiments on several real-world benchmarks, we show that DCF consistently outperforms state-of-the-art CF hashing techniques, e.g, though using only 8 bits, DCF is even significantly better than other methods using 128 bits."
            },
            "slug": "Discrete-Collaborative-Filtering-Zhang-Shen",
            "title": {
                "fragments": [],
                "text": "Discrete Collaborative Filtering"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes a principled CF hashing framework called Discrete Collaborative Filtering (DCF), which directly tackles the challenging discrete optimization that should have been treated adequately in hashing, and devise a computationally efficient algorithm with a rigorous convergence proof of DCF."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "98285513"
                        ],
                        "name": "Xiang Wang",
                        "slug": "Xiang-Wang",
                        "structuredName": {
                            "firstName": "Xiang",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiang Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7792071"
                        ],
                        "name": "Xiangnan He",
                        "slug": "Xiangnan-He",
                        "structuredName": {
                            "firstName": "Xiangnan",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangnan He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143982887"
                        ],
                        "name": "Liqiang Nie",
                        "slug": "Liqiang-Nie",
                        "structuredName": {
                            "firstName": "Liqiang",
                            "lastName": "Nie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liqiang Nie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144078686"
                        ],
                        "name": "Tat-Seng Chua",
                        "slug": "Tat-Seng-Chua",
                        "structuredName": {
                            "firstName": "Tat-Seng",
                            "lastName": "Chua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tat-Seng Chua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "Later, the NCF framework was extended to model a\u008aribute interactions for a\u008aribute-aware CF [37]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 69
                            }
                        ],
                        "text": "For ranking task, we can optimize pairwise personalized ranking loss [29, 37] or contrastive max-margin loss [43]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 25396851,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2941a495900c7b8cc46fcb357c0d2c5d7d086e1",
            "isKey": false,
            "numCitedBy": 200,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Online platforms can be divided into information-oriented and social-oriented domains. The former refers to forums or E-commerce sites that emphasize user-item interactions, like Trip.com and Amazon; whereas the latter refers to social networking services (SNSs) that have rich user-user connections, such as Facebook and Twitter. Despite their heterogeneity, these two domains can be bridged by a few overlapping users, dubbed as bridge users. In this work, we address the problem of cross-domain social recommendation, i.e., recommending relevant items of information domains to potential users of social networks. To our knowledge, this is a new problem that has rarely been studied before. Existing cross-domain recommender systems are unsuitable for this task since they have either focused on homogeneous information domains or assumed that users are fully overlapped. Towards this end, we present a novel Neural Social Collaborative Ranking (NSCR) approach, which seamlessly sews up the user-item interactions in information domains and user-user connections in SNSs. In the information domain part, the attributes of users and items are leveraged to strengthen the embedding learning of users and items. In the SNS part, the embeddings of bridge users are propagated to learn the embeddings of other non-bridge users. Extensive experiments on two real-world datasets demonstrate the effectiveness and rationality of our NSCR method."
            },
            "slug": "Item-Silk-Road:-Recommending-Items-from-Information-Wang-He",
            "title": {
                "fragments": [],
                "text": "Item Silk Road: Recommending Items from Information Domains to Social Users"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work presents a novel Neural Social Collaborative Ranking (NSCR) approach, which seamlessly sews up the user-item interactions in information domains and user-user connections in SNSs."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2907818"
                        ],
                        "name": "Martin Genzel",
                        "slug": "Martin-Genzel",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Genzel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Martin Genzel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3125779"
                        ],
                        "name": "G. Kutyniok",
                        "slug": "G.-Kutyniok",
                        "structuredName": {
                            "firstName": "Gitta",
                            "lastName": "Kutyniok",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Kutyniok"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 140
                            }
                        ],
                        "text": "Unfortunately, the underlying structure of real-world data is o\u0089en highly non-linear and cannot be accurately approximated by linear models [12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2006795,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "97fe4b0a2cf2395b6ad009cfa0ddf677ae783d73",
            "isKey": false,
            "numCitedBy": 11,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we study the challenge of feature selection based on a relatively small collection of sample pairs $\\{(x_i, y_i)\\}_{1 \\leq i \\leq m}$. The observations $y_i \\in \\mathbb{R}$ are thereby supposed to follow a noisy single-index model, depending on a certain set of signal variables. A major difficulty is that these variables usually cannot be observed directly, but rather arise as hidden factors in the actual data vectors $x_i \\in \\mathbb{R}^d$ (feature variables). We will prove that a successful variable selection is still possible in this setup, even when the applied estimator does not have any knowledge of the underlying model parameters and only takes the 'raw' samples $\\{(x_i, y_i)\\}_{1 \\leq i \\leq m}$ as input. The model assumptions of our results will be fairly general, allowing for non-linear observations, arbitrary convex signal structures as well as strictly convex loss functions. This is particularly appealing for practical purposes, since in many applications, already standard methods, e.g., the Lasso or logistic regression, yield surprisingly good outcomes. Apart from a general discussion of the practical scope of our theoretical findings, we will also derive a rigorous guarantee for a specific real-world problem, namely sparse feature extraction from (proteomics-based) mass spectrometry data."
            },
            "slug": "A-Mathematical-Framework-for-Feature-Selection-from-Genzel-Kutyniok",
            "title": {
                "fragments": [],
                "text": "A Mathematical Framework for Feature Selection from Real-World Data with Non-Linear Observations"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper will prove that a successful variable selection is still possible in this setup, even when the applied estimator does not have any knowledge of the underlying model parameters and only takes the 'raw' samples as input."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144618699"
                        ],
                        "name": "Fumin Shen",
                        "slug": "Fumin-Shen",
                        "structuredName": {
                            "firstName": "Fumin",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fumin Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145353089"
                        ],
                        "name": "Yadong Mu",
                        "slug": "Yadong-Mu",
                        "structuredName": {
                            "firstName": "Yadong",
                            "lastName": "Mu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yadong Mu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6897666"
                        ],
                        "name": "Yang Yang",
                        "slug": "Yang-Yang",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46641573"
                        ],
                        "name": "W. Liu",
                        "slug": "W.-Liu",
                        "structuredName": {
                            "firstName": "W.",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49480212"
                        ],
                        "name": "Li Liu",
                        "slug": "Li-Liu",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2346105"
                        ],
                        "name": "Jingkuan Song",
                        "slug": "Jingkuan-Song",
                        "structuredName": {
                            "firstName": "Jingkuan",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jingkuan Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724393"
                        ],
                        "name": "H. Shen",
                        "slug": "H.-Shen",
                        "structuredName": {
                            "firstName": "Heng",
                            "lastName": "Shen",
                            "middleNames": [
                                "Tao"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Shen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13496494,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b091a0bbe5f5fa612797ceb333cdfbc780185b56",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a generic formulation that significantly expedites the training and deployment of image classification models, particularly under the scenarios of many image categories and high feature dimensions. As the core idea, our method represents both the images and learned classifiers using binary hash codes, which are simultaneously learned from the training data. Classifying an image thereby reduces to retrieving its nearest class codes in the Hamming space. Specifically, we formulate multiclass image classification as an optimization problem over binary variables. The optimization alternatingly proceeds over the binary classifiers and image hash codes. Profiting from the special property of binary codes, we show that the sub-problems can be efficiently solved through either a binary quadratic program (BQP) or a linear program. In particular, for attacking the BQP problem, we propose a novel bit-flipping procedure which enjoys high efficacy and a local optimality guarantee. Our formulation supports a large family of empirical loss functions and is, in specific, instantiated by exponential and linear losses. Comprehensive evaluations are conducted on several representative image benchmarks. The experiments consistently exhibit reduced computational and memory complexities of model training and deployment, without sacrificing classification accuracy."
            },
            "slug": "Classification-by-Retrieval:-Binarizing-Data-and-Shen-Mu",
            "title": {
                "fragments": [],
                "text": "Classification by Retrieval: Binarizing Data and Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "A generic formulation that significantly expedites the training and deployment of image classification models, particularly under the scenarios of many image categories and high feature dimensions, and proposes a novel bit-flipping procedure which enjoys high efficacy and a local optimality guarantee."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1734693"
                        ],
                        "name": "John C. Duchi",
                        "slug": "John-C.-Duchi",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Duchi",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Duchi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34840427"
                        ],
                        "name": "Elad Hazan",
                        "slug": "Elad-Hazan",
                        "structuredName": {
                            "firstName": "Elad",
                            "lastName": "Hazan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elad Hazan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740765"
                        ],
                        "name": "Y. Singer",
                        "slug": "Y.-Singer",
                        "structuredName": {
                            "firstName": "Yoram",
                            "lastName": "Singer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Singer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 111
                            }
                        ],
                        "text": "Besides LibFM that optimized FM with the vanilla SGD, all other methods were optimized with mini-batch Adagrad [10], where the batch size was set to 128 for Frappe and 4096 for MovieLens."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 49
                            }
                        ],
                        "text": "In our implementation, we use mini-batch Adagrad [10] as the optimizer, rather than the vanilla SGD."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 538820,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "413c1142de9d91804d6d11c67ff3fed59c9fc279",
            "isKey": false,
            "numCitedBy": 8368,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to find needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efficient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms."
            },
            "slug": "Adaptive-Subgradient-Methods-for-Online-Learning-Duchi-Hazan",
            "title": {
                "fragments": [],
                "text": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work describes and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies setting a learning rate and results in regret guarantees that are provably as good as the best proximal functions that can be chosen in hindsight."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144799987"
                        ],
                        "name": "Tao Chen",
                        "slug": "Tao-Chen",
                        "structuredName": {
                            "firstName": "Tao",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tao Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7792071"
                        ],
                        "name": "Xiangnan He",
                        "slug": "Xiangnan-He",
                        "structuredName": {
                            "firstName": "Xiangnan",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangnan He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37596605"
                        ],
                        "name": "Min-Yen Kan",
                        "slug": "Min-Yen-Kan",
                        "structuredName": {
                            "firstName": "Min-Yen",
                            "lastName": "Kan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Min-Yen Kan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17224362,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bdadef4d3265d1f1e3f92155ca1896df0f8619d4",
            "isKey": false,
            "numCitedBy": 68,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "While efforts have been made on bridging the semantic gap in image understanding, the in situ understanding of social media images is arguably more important but has had less progress. In this work, we enrich the representation of images in image tweets by considering their social context. We argue that in the microblog context, traditional image features, e.g., low-level SIFT or high-level detected objects, are far from adequate in interpreting the necessary semantics latent in image tweets. To bridge this gap, we move from the images' pixels to their context and propose a context-aware image bf tweet modelling (CITING) framework to mine and fuse contextual text to model such social media images' semantics. We start with tweet's intrinsic contexts, namely, 1) text within the image itself and 2) its accompanying text; and then we turn to the extrinsic contexts: 3) the external web page linked to by the tweet's embedded URL, and 4) the Web as a whole. These contexts can be leveraged to benefit many fundamental applications. To demonstrate the effectiveness our framework, we focus on the task of personalized image tweet recommendation, developing a feature-aware matrix factorization framework that encodes the contexts as a part of user interest modelling. Extensive experiments on a large Twitter dataset show that our proposed method significantly improves performance. Finally, to spur future studies, we have released both the code of our recommendation model and our image tweet dataset."
            },
            "slug": "Context-aware-Image-Tweet-Modelling-and-Chen-He",
            "title": {
                "fragments": [],
                "text": "Context-aware Image Tweet Modelling and Recommendation"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work proposes a context-aware image bf tweet modelling (CITING) framework to mine and fuse contextual text to model such social media images' semantics and focuses on the task of personalized image tweet recommendation, developing a feature-aware matrix factorization framework that encodes the contexts as a part of user interest modelling."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Multimedia"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47740660"
                        ],
                        "name": "Jingyuan Chen",
                        "slug": "Jingyuan-Chen",
                        "structuredName": {
                            "firstName": "Jingyuan",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jingyuan Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5462268"
                        ],
                        "name": "Hanwang Zhang",
                        "slug": "Hanwang-Zhang",
                        "structuredName": {
                            "firstName": "Hanwang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanwang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7792071"
                        ],
                        "name": "Xiangnan He",
                        "slug": "Xiangnan-He",
                        "structuredName": {
                            "firstName": "Xiangnan",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangnan He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143982887"
                        ],
                        "name": "Liqiang Nie",
                        "slug": "Liqiang-Nie",
                        "structuredName": {
                            "firstName": "Liqiang",
                            "lastName": "Nie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liqiang Nie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1654091065"
                        ],
                        "name": "Wei Liu",
                        "slug": "Wei-Liu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144078686"
                        ],
                        "name": "Tat-Seng Chua",
                        "slug": "Tat-Seng-Chua",
                        "structuredName": {
                            "firstName": "Tat-Seng",
                            "lastName": "Chua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tat-Seng Chua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 20970043,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "43c0ff1070def3d98f548b7cbf523fdd4a83827a",
            "isKey": false,
            "numCitedBy": 589,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Multimedia content is dominating today's Web information. The nature of multimedia user-item interactions is 1/0 binary implicit feedback (e.g., photo likes, video views, song downloads, etc.), which can be collected at a larger scale with a much lower cost than explicit feedback (e.g., product ratings). However, the majority of existing collaborative filtering (CF) systems are not well-designed for multimedia recommendation, since they ignore the implicitness in users' interactions with multimedia content. We argue that, in multimedia recommendation, there exists item- and component-level implicitness which blurs the underlying users' preferences. The item-level implicitness means that users' preferences on items (e.g. photos, videos, songs, etc.) are unknown, while the component-level implicitness means that inside each item users' preferences on different components (e.g. regions in an image, frames of a video, etc.) are unknown. For example, a 'view'' on a video does not provide any specific information about how the user likes the video (i.e.item-level) and which parts of the video the user is interested in (i.e.component-level). In this paper, we introduce a novel attention mechanism in CF to address the challenging item- and component-level implicit feedback in multimedia recommendation, dubbed Attentive Collaborative Filtering (ACF). Specifically, our attention model is a neural network that consists of two attention modules: the component-level attention module, starting from any content feature extraction network (e.g. CNN for images/videos), which learns to select informative components of multimedia items, and the item-level attention module, which learns to score the item preferences. ACF can be seamlessly incorporated into classic CF models with implicit feedback, such as BPR and SVD++, and efficiently trained using SGD. Through extensive experiments on two real-world multimedia Web services: Vine and Pinterest, we show that ACF significantly outperforms state-of-the-art CF methods."
            },
            "slug": "Attentive-Collaborative-Filtering:-Multimedia-with-Chen-Zhang",
            "title": {
                "fragments": [],
                "text": "Attentive Collaborative Filtering: Multimedia Recommendation with Item- and Component-Level Attention"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A novel attention mechanism in CF is introduced to address the challenging item- and component-level implicit feedback in multimedia recommendation, dubbed Attentive Collaborative Filtering (ACF), which significantly outperforms state-of-the-art CF methods."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145192090"
                        ],
                        "name": "F. M. Harper",
                        "slug": "F.-M.-Harper",
                        "structuredName": {
                            "firstName": "F.",
                            "lastName": "Harper",
                            "middleNames": [
                                "Maxwell"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. M. Harper"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2478310"
                        ],
                        "name": "J. Konstan",
                        "slug": "J.-Konstan",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Konstan",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Konstan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16619709,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "276ebc620a8976026bd2d03582b9ecfa3738d43c",
            "isKey": false,
            "numCitedBy": 2909,
            "numCiting": 49,
            "paperAbstract": {
                "fragments": [],
                "text": "The MovieLens datasets are widely used in education, research, and industry. They are downloaded hundreds of thousands of times each year, reflecting their use in popular press programming books, traditional and online courses, and software. These datasets are a product of member activity in the MovieLens movie recommendation system, an active research platform that has hosted many experiments since its launch in 1997. This article documents the history of MovieLens and the MovieLens datasets. We include a discussion of lessons learned from running a long-standing, live research platform from the perspective of a research organization. We document best practices and limitations of using the MovieLens datasets in new research."
            },
            "slug": "The-MovieLens-Datasets:-History-and-Context-Harper-Konstan",
            "title": {
                "fragments": [],
                "text": "The MovieLens Datasets: History and Context"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "The history of MovieLens and the MovieLens datasets is documents, including a discussion of lessons learned from running a long-standing, live research platform from the perspective of a research organization, and best practices and limitations of using the Movie Lens datasets in new research are documented."
            },
            "venue": {
                "fragments": [],
                "text": "TIIS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145657503"
                        ],
                        "name": "Chao Zhang",
                        "slug": "Chao-Zhang",
                        "structuredName": {
                            "firstName": "Chao",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chao Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 198925319,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ada27246ae0bbd60717dda9fba7bcd6e9023088b",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "The real-time discovery of local events (e.g., protests, disasters) has been widely recognized as a fundamental socioeconomic task. Recent studies have demonstrated that the geo-tagged tweet stream serves as an unprecedentedly valuable source for local event detection. Nevertheless, how to e ectively extract local events from massive geo-tagged tweet streams in real time remains challenging. To bridge the gap, we propose a method for e ective and real-time local event detection from geo-tagged tweet streams. Our method, named GeoBurst+, rst leverages a novel cross-modal authority measure to identify several pivots in the query window. Such pivots reveal di erent geo-topical activities and naturally attract similar tweets to form candidate events. GeoBurst+ further summarizes the continuous stream and compares the candidates against the historical summaries to pinpoint truly interesting local events. Better still, as the query window shifts, GeoBurst+ is capable of updating the event list with little time cost, thus achieving continuous monitoring of the stream. We used crowdsourcing to evaluate GeoBurst+ on two million-scale data sets, and found it signi cantly more e ective than existing methods while being orders of magnitude faster."
            },
            "slug": "Real-Time-Local-Event-Detection-in-GeoTagged-Tweet-Zhang",
            "title": {
                "fragments": [],
                "text": "Real-Time Local Event Detection in GeoTagged Tweet Streams"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The method, named GeoBurst+, leverages a novel cross-modal authority measure to identify several pivots in the query window and is capable of updating the event list with little time cost, thus achieving continuous monitoring of the stream."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145657504"
                        ],
                        "name": "Chao Zhang",
                        "slug": "Chao-Zhang",
                        "structuredName": {
                            "firstName": "Chao",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chao Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110809372"
                        ],
                        "name": "Guangyu Zhou",
                        "slug": "Guangyu-Zhou",
                        "structuredName": {
                            "firstName": "Guangyu",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guangyu Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145001852"
                        ],
                        "name": "Quan Yuan",
                        "slug": "Quan-Yuan",
                        "structuredName": {
                            "firstName": "Quan",
                            "lastName": "Yuan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quan Yuan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39371343"
                        ],
                        "name": "Honglei Zhuang",
                        "slug": "Honglei-Zhuang",
                        "structuredName": {
                            "firstName": "Honglei",
                            "lastName": "Zhuang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Honglei Zhuang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153116509"
                        ],
                        "name": "Yu Zheng",
                        "slug": "Yu-Zheng",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1795727"
                        ],
                        "name": "Lance M. Kaplan",
                        "slug": "Lance-M.-Kaplan",
                        "structuredName": {
                            "firstName": "Lance",
                            "lastName": "Kaplan",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lance M. Kaplan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2989265"
                        ],
                        "name": "Shaowen Wang",
                        "slug": "Shaowen-Wang",
                        "structuredName": {
                            "firstName": "Shaowen",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaowen Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145325584"
                        ],
                        "name": "Jiawei Han",
                        "slug": "Jiawei-Han",
                        "structuredName": {
                            "firstName": "Jiawei",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiawei Han"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 271,
                                "start": 267
                            }
                        ],
                        "text": "Predictive analytics is one of the most important techniques for many information retrieval (IR) and data mining (DM) tasks, ranging from recommendation systems [2, 16], targeted advertising [21], to search ranking [19, 39], visual analysis [35], and event detection [40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15098872,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c27f7776d54f86da74cc40db08c02992e8df567a",
            "isKey": false,
            "numCitedBy": 143,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "The real-time discovery of local events (e.g., protests, crimes, disasters) is of great importance to various applications, such as crime monitoring, disaster alarming, and activity recommendation. While this task was nearly impossible years ago due to the lack of timely and reliable data sources, the recent explosive growth in geo-tagged tweet data brings new opportunities to it. That said, how to extract quality local events from geo-tagged tweet streams in real time remains largely unsolved so far. We propose GeoBurst, a method that enables effective and real-time local event detection from geo-tagged tweet streams. With a novel authority measure that captures the geo-topic correlations among tweets, GeoBurst first identifies several pivots in the query window. Such pivots serve as representative tweets for potential local events and naturally attract similar tweets to form candidate events. To select truly interesting local events from the candidate list, GeoBurst further summarizes continuous tweet streams and compares the candidates against historical activities to obtain spatiotemporally bursty ones. Finally, GeoBurst also features an updating module that finds new pivots with little time cost when the query window shifts. As such, GeoBurst is capable of monitoring continuous streams in real time. We used crowdsourcing to evaluate GeoBurst on two real-life data sets that contain millions of geo-tagged tweets. The results demonstrate that GeoBurst significantly outperforms state-of-the-art methods in precision, and is orders of magnitude faster."
            },
            "slug": "GeoBurst:-Real-Time-Local-Event-Detection-in-Tweet-Zhang-Zhou",
            "title": {
                "fragments": [],
                "text": "GeoBurst: Real-Time Local Event Detection in Geo-Tagged Tweet Streams"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "GeoBurst is a method that enables effective and real-time local event detection from geo-tagged tweet streams and significantly outperforms state-of-the-art methods in precision, and is orders of magnitude faster."
            },
            "venue": {
                "fragments": [],
                "text": "SIGIR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5462268"
                        ],
                        "name": "Hanwang Zhang",
                        "slug": "Hanwang-Zhang",
                        "structuredName": {
                            "firstName": "Hanwang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanwang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143962510"
                        ],
                        "name": "Zhengjun Zha",
                        "slug": "Zhengjun-Zha",
                        "structuredName": {
                            "firstName": "Zhengjun",
                            "lastName": "Zha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhengjun Zha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6897666"
                        ],
                        "name": "Yang Yang",
                        "slug": "Yang-Yang",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143653681"
                        ],
                        "name": "Shuicheng Yan",
                        "slug": "Shuicheng-Yan",
                        "structuredName": {
                            "firstName": "Shuicheng",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuicheng Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109218951"
                        ],
                        "name": "Yue Gao",
                        "slug": "Yue-Gao",
                        "structuredName": {
                            "firstName": "Yue",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yue Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144078686"
                        ],
                        "name": "Tat-Seng Chua",
                        "slug": "Tat-Seng-Chua",
                        "structuredName": {
                            "firstName": "Tat-Seng",
                            "lastName": "Chua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tat-Seng Chua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 17089940,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ef03b633a71cd74afa7c1a0090a9fcfa9c9c37bf",
            "isKey": false,
            "numCitedBy": 138,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a novel Attribute-augmented Semantic Hierarchy (A2 SH) and demonstrates its effectiveness in bridging both the semantic and intention gaps in Content-based Image Retrieval (CBIR). A2 SH organizes the semantic concepts into multiple semantic levels and augments each concept with a set of related attributes, which describe the multiple facets of the concept and act as the intermediate bridge connecting the concept and low-level visual content. A hierarchical semantic similarity function is learnt to characterize the semantic similarities among images for retrieval. To better capture user search intent, a hybrid feedback mechanism is developed, which collects hybrid feedbacks on attributes and images. These feedbacks are then used to refine the search results based on A2 SH. We develop a content-based image retrieval system based on the proposed A2 SH. We conduct extensive experiments on a large-scale data set of over one million Web images. Experimental results show that the proposed A2 SH can characterize the semantic affinities among images accurately and can shape user search intent precisely and quickly, leading to more accurate search results as compared to state-of-the-art CBIR solutions."
            },
            "slug": "Attribute-augmented-semantic-hierarchy:-towards-gap-Zhang-Zha",
            "title": {
                "fragments": [],
                "text": "Attribute-augmented semantic hierarchy: towards bridging semantic gap and intention gap in image retrieval"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Experimental results show that the proposed A2 SH can characterize the semantic affinities among images accurately and can shape user search intent precisely and quickly, leading to more accurate search results as compared to state-of-the-art CBIR solutions."
            },
            "venue": {
                "fragments": [],
                "text": "ACM Multimedia"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2666397"
                        ],
                        "name": "L. Baltrunas",
                        "slug": "L.-Baltrunas",
                        "structuredName": {
                            "firstName": "Linas",
                            "lastName": "Baltrunas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Baltrunas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145639750"
                        ],
                        "name": "K. Church",
                        "slug": "K.-Church",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Church",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Church"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713164"
                        ],
                        "name": "Alexandros Karatzoglou",
                        "slug": "Alexandros-Karatzoglou",
                        "structuredName": {
                            "firstName": "Alexandros",
                            "lastName": "Karatzoglou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexandros Karatzoglou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145709776"
                        ],
                        "name": "Nuria Oliver",
                        "slug": "Nuria-Oliver",
                        "structuredName": {
                            "firstName": "Nuria",
                            "lastName": "Oliver",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nuria Oliver"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "4.1.1 Datasets. We experimented with two publicly accessible datasets: Frappe3 and MovieLens4: 1. Frappe. Frappe is a context-aware app discovery tool. \u201eis\u00b4 dataset is constructed by Baltrunas et al. [1]. It contains 96;203 app usage logs of users under di\u2021erent contexts. Besides user ID and app ID, each log contains 8 context variables, including weather, city and daytime (e.g., morning or a\u203aernoon)"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1791006,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "00f4df1d155cc9bdf412e1d5d17c9193799e6e9f",
            "isKey": true,
            "numCitedBy": 67,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a real world deployment of a contextaware mobile app recommender system (RS) called Frapp e. Utilizing a hybrid-approach, we conducted a large-scale app market deployment with 1000 Android users combined with a small-scale local user study involving 33 users. The resulting usage logs and subjective feedback enabled us to gather key insights into (1) context-dependent app usage and (2) the perceptions and experiences of end-users while interacting with context-aware mobile app recommendations. While Frapp e performs very well based on usage-centric evaluation metrics insights from the small-scale study reveal some negative user experiences. Our results point to a number of actionable lessons learned specically related to designing, deploying and evaluating mobile context-aware RS in-thewild with real users."
            },
            "slug": "Frappe:-Understanding-the-Usage-and-Perception-of-Baltrunas-Church",
            "title": {
                "fragments": [],
                "text": "Frappe: Understanding the Usage and Perception of Mobile App Recommendations In-The-Wild"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "While Frapp e performs very well based on usage-centric evaluation metrics insights from the small-scale study reveal some negative user experiences, these results point to a number of actionable lessons learned specically related to designing, deploying and evaluating mobile context-aware RS in-thewild with real users."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145974111"
                        ],
                        "name": "Jun Xiao",
                        "slug": "Jun-Xiao",
                        "structuredName": {
                            "firstName": "Jun",
                            "lastName": "Xiao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jun Xiao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111972888"
                        ],
                        "name": "Hao Ye",
                        "slug": "Hao-Ye",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Ye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Ye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7792071"
                        ],
                        "name": "Xiangnan He",
                        "slug": "Xiangnan-He",
                        "structuredName": {
                            "firstName": "Xiangnan",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangnan He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5462268"
                        ],
                        "name": "Hanwang Zhang",
                        "slug": "Hanwang-Zhang",
                        "structuredName": {
                            "firstName": "Hanwang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanwang Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144894849"
                        ],
                        "name": "Fei Wu",
                        "slug": "Fei-Wu",
                        "structuredName": {
                            "firstName": "Fei",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fei Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144078686"
                        ],
                        "name": "Tat-Seng Chua",
                        "slug": "Tat-Seng-Chua",
                        "structuredName": {
                            "firstName": "Tat-Seng",
                            "lastName": "Chua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tat-Seng Chua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3836251,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f0af0029293dc8f242894f113baf15d68228ec4d",
            "isKey": false,
            "numCitedBy": 552,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Factorization Machines (FMs) are a supervised learning approach that enhances the linear regression model by incorporating the second-order feature interactions. Despite effectiveness, FM can be hindered by its modelling of all feature interactions with the same weight, as not all feature interactions are equally useful and predictive. For example, the interactions with useless features may even introduce noises and adversely degrade the performance. In this work, we improve FM by discriminating the importance of different feature interactions. We propose a novel model named Attentional Factorization Machine (AFM), which learns the importance of each feature interaction from data via a neural attention network. Extensive experiments on two real-world datasets demonstrate the effectiveness of AFM. Empirically, it is shown on regression task AFM betters FM with a $8.6\\%$ relative improvement, and consistently outperforms the state-of-the-art deep learning methods Wide&Deep and DeepCross with a much simpler structure and fewer model parameters. Our implementation of AFM is publicly available at: this https URL"
            },
            "slug": "Attentional-Factorization-Machines:-Learning-the-of-Xiao-Ye",
            "title": {
                "fragments": [],
                "text": "Attentional Factorization Machines: Learning the Weight of Feature Interactions via Attention Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A novel model named Attentional Factorization Machine (AFM), which learns the importance of each feature interaction from data via a neural attention network, which consistently outperforms the state-of-the-art deep learning methods Wide&Deep and DeepCross with a much simpler structure and fewer model parameters."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 223,
                                "start": 215
                            }
                        ],
                        "text": "Predictive analytics is one of the most important techniques for many information retrieval (IR) and data mining (DM) tasks, ranging from recommendation systems [2, 16], targeted advertising [21], to search ranking [19, 39], visual analysis [35], and event detection [40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 55
                            }
                        ],
                        "text": "[38] proposed a\u008aentional FM, using an a\u008aention network [7, 39] to learn the importance of each feature interaction."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning to a\u008aend and to rank with word-entity duets"
            },
            "venue": {
                "fragments": [],
                "text": "In SIGIR,"
            },
            "year": 2017
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 18,
            "methodology": 14
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 45,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Neural-Factorization-Machines-for-Sparse-Predictive-He-Chua/3d1f9a530e710fdd4e2313bda4c8a1f574e60ab6?sort=total-citations"
}