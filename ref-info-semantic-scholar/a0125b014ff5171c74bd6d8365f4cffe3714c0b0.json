{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109474526"
                        ],
                        "name": "Jeremy Morris",
                        "slug": "Jeremy-Morris",
                        "structuredName": {
                            "firstName": "Jeremy",
                            "lastName": "Morris",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeremy Morris"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398481836"
                        ],
                        "name": "E. Fosler-Lussier",
                        "slug": "E.-Fosler-Lussier",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Fosler-Lussier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Fosler-Lussier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18184555,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "388fbc02ee1e8a7dcd10eda9b5d6856ddb3552ee",
            "isKey": false,
            "numCitedBy": 16,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "A Conditional Random Field is a mathematical model for sequences that is similar in many ways to a Hidden Markov Model, but is discriminative rather than generative in nature. In this paper, we explore the application of the CRF model to ASR processing of discriminative phonetic features by building a system that performs first-pass phonetic recognition using discriminatively trained phonetic features. With this system, we show that this CRF model trained on only monophone labels achieves an accuracy level in a phone recognition task that is close to that of an HMM model that has been trained on triphone labels."
            },
            "slug": "Discriminative-Phonetic-Recognition-with-Random-Morris-Fosler-Lussier",
            "title": {
                "fragments": [],
                "text": "Discriminative Phonetic Recognition with Conditional Random Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper builds a system that performs first-pass phonetic recognition using discriminatively trained phonetic features and shows that this CRF model trained on only monophone labels achieves an accuracy level in a phone recognition task that is close to that of an HMM model that has been trained on triphone labels."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1794100"
                        ],
                        "name": "Brian Roark",
                        "slug": "Brian-Roark",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Roark",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brian Roark"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2535627"
                        ],
                        "name": "M. Sara\u00e7lar",
                        "slug": "M.-Sara\u00e7lar",
                        "structuredName": {
                            "firstName": "Murat",
                            "lastName": "Sara\u00e7lar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sara\u00e7lar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143707112"
                        ],
                        "name": "M. Collins",
                        "slug": "M.-Collins",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Collins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Collins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145177220"
                        ],
                        "name": "Mark Johnson",
                        "slug": "Mark-Johnson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Johnson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Johnson"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "In addition, CRFs have been explored for building language models for ASR [10] and for phone classification [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14001621,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "567dc4e26ece98e96c2e798ae8acafa5883945a9",
            "isKey": false,
            "numCitedBy": 184,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes discriminative language modeling for a large vocabulary speech recognition task. We contrast two parameter estimation methods: the perceptron algorithm, and a method based on conditional random fields (CRFs). The models are encoded as deterministic weighted finite state automata, and are applied by intersecting the automata with word-lattices that are the output from a baseline recognizer. The perceptron algorithm has the benefit of automatically selecting a relatively small feature set in just a couple of passes over the training data. However, using the feature set output from the perceptron algorithm (initialized with their weights), CRF training provides an additional 0.5% reduction in word error rate, for a total 1.8% absolute reduction from the baseline of 39.2%."
            },
            "slug": "Discriminative-Language-Modeling-with-Conditional-Roark-Sara\u00e7lar",
            "title": {
                "fragments": [],
                "text": "Discriminative Language Modeling with Conditional Random Fields and the Perceptron Algorithm"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "This paper compares two parameter estimation methods: the perceptron algorithm, and a method based on conditional random fields (CRFs), which have the benefit of automatically selecting a relatively small feature set in just a couple of passes over the training data."
            },
            "venue": {
                "fragments": [],
                "text": "ACL"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1738798"
                        ],
                        "name": "H. Hermansky",
                        "slug": "H.-Hermansky",
                        "structuredName": {
                            "firstName": "Hynek",
                            "lastName": "Hermansky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hermansky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745455"
                        ],
                        "name": "D. Ellis",
                        "slug": "D.-Ellis",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Ellis",
                            "middleNames": [
                                "P.",
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ellis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109947002"
                        ],
                        "name": "Sangita Sharma",
                        "slug": "Sangita-Sharma",
                        "structuredName": {
                            "firstName": "Sangita",
                            "lastName": "Sharma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sangita Sharma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5807992,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e9082caea65c76bfd23b8763872804473ee7872",
            "isKey": false,
            "numCitedBy": 805,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov model speech recognition systems typically use Gaussian mixture models to estimate the distributions of decorrelated acoustic feature vectors that correspond to individual subword units. By contrast, hybrid connectionist-HMM systems use discriminatively-trained neural networks to estimate the probability distribution among subword units given the acoustic observations. In this work we show a large improvement in word recognition performance by combining neural-net discriminative feature processing with Gaussian-mixture distribution modeling. By training the network to generate the subword probability posteriors, then using transformations of these estimates as the base features for a conventionally-trained Gaussian-mixture based system, we achieve relative error rate reductions of 35% or more on the multicondition Aurora noisy continuous digits task."
            },
            "slug": "Tandem-connectionist-feature-extraction-for-HMM-Hermansky-Ellis",
            "title": {
                "fragments": [],
                "text": "Tandem connectionist feature extraction for conventional HMM systems"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A large improvement in word recognition performance is shown by combining neural-net discriminative feature processing with Gaussian-mixture distribution modeling."
            },
            "venue": {
                "fragments": [],
                "text": "2000 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.00CH37100)"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2801698"
                        ],
                        "name": "A. Gunawardana",
                        "slug": "A.-Gunawardana",
                        "structuredName": {
                            "firstName": "Asela",
                            "lastName": "Gunawardana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gunawardana"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143817088"
                        ],
                        "name": "M. Mahajan",
                        "slug": "M.-Mahajan",
                        "structuredName": {
                            "firstName": "Milind",
                            "lastName": "Mahajan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mahajan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723644"
                        ],
                        "name": "A. Acero",
                        "slug": "A.-Acero",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Acero",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Acero"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189092"
                        ],
                        "name": "John C. Platt",
                        "slug": "John-C.-Platt",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Platt",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John C. Platt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1744924,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ad4cfdb0c0bb62bf1fa99cb3d0519cadd9cbc160",
            "isKey": false,
            "numCitedBy": 360,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we show the novel application of hidden conditional random fields (HCRFs) \u2013 conditional random fields with hidden state sequences \u2013 for modeling speech. Hidden state sequences are critical for modeling the non-stationarity of speech signals. We show that HCRFs can easily be trained using the simple direct optimization technique of stochastic gradient descent. We present the results on the TIMIT phone classification task and show that HCRFs outperforms comparable ML and CML/MMI trained HMMs. In fact, HCRF results on this task are the best single classifier results known to us. We note that the HCRF framework is easily extensible to recognition since it is a state and label sequence modeling technique. We also note that HCRFs have the ability to handle complex features without any change in training procedure."
            },
            "slug": "Hidden-conditional-random-fields-for-phone-Gunawardana-Mahajan",
            "title": {
                "fragments": [],
                "text": "Hidden conditional random fields for phone classification"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents the results on the TIMIT phone classification task and shows that HCRFs outperforms comparable ML and CML/MMI trained HMMs and has the ability to handle complex features without any change in training procedure."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739581"
                        ],
                        "name": "J. Lafferty",
                        "slug": "J.-Lafferty",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Lafferty",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Lafferty"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "113414328"
                        ],
                        "name": "Fernando Pereira",
                        "slug": "Fernando-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 219683473,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4ba954b0412773d047dc41231c733de0c1f4926",
            "isKey": false,
            "numCitedBy": 13472,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "We present conditional random fields , a framework for building probabilistic models to segment and label sequence data. Conditional random fields offer several advantages over hidden Markov models and stochastic grammars for such tasks, including the ability to relax strong independence assumptions made in those models. Conditional random fields also avoid a fundamental limitation of maximum entropy Markov models (MEMMs) and other discriminative Markov models based on directed graphical models, which can be biased towards states with few successor states. We present iterative parameter estimation algorithms for conditional random fields and compare the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data."
            },
            "slug": "Conditional-Random-Fields:-Probabilistic-Models-for-Lafferty-McCallum",
            "title": {
                "fragments": [],
                "text": "Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work presents iterative parameter estimation algorithms for conditional random fields and compares the performance of the resulting models to HMMs and MEMMs on synthetic and natural-language data."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143753639"
                        ],
                        "name": "A. McCallum",
                        "slug": "A.-McCallum",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "McCallum",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. McCallum"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1758106"
                        ],
                        "name": "Dayne Freitag",
                        "slug": "Dayne-Freitag",
                        "structuredName": {
                            "firstName": "Dayne",
                            "lastName": "Freitag",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dayne Freitag"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 176,
                                "start": 173
                            }
                        ],
                        "text": "Models based around the framework of maximum entropy have shown successful results in various areas of discriminative modeling, including part of speech tagging [2], information extraction [3], and statistical language modeling [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 775373,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bece46ed303f8eaef2affae2cba4e0aef51fe636",
            "isKey": false,
            "numCitedBy": 1557,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov models (HMMs) are a powerful probabilistic tool for modeling sequential data, and have been applied with success to many text-related tasks, such as part-of-speech tagging, text segmentation and information extraction. In these cases, the observations are usually modeled as multinomial distributions over a discrete vocabulary, and the HMM parameters are set to maximize the likelihood of the observations. This paper presents a new Markovian sequence model, closely related to HMMs, that allows observations to be represented as arbitrary overlapping features (such as word, capitalization, formatting, part-of-speech), and defines the conditional probability of state sequences given observation sequences. It does this by using the maximum entropy framework to fit a set of exponential models that represent the probability of a state given an observation and the previous state. We present positive experimental results on the segmentation of FAQ\u2019s."
            },
            "slug": "Maximum-Entropy-Markov-Models-for-Information-and-McCallum-Freitag",
            "title": {
                "fragments": [],
                "text": "Maximum Entropy Markov Models for Information Extraction and Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "A new Markovian sequence model is presented that allows observations to be represented as arbitrary overlapping features (such as word, capitalization, formatting, part-of-speech), and defines the conditional probability of state sequences given observation sequences."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3153147"
                        ],
                        "name": "Wolfgang Macherey",
                        "slug": "Wolfgang-Macherey",
                        "structuredName": {
                            "firstName": "Wolfgang",
                            "lastName": "Macherey",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wolfgang Macherey"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145322333"
                        ],
                        "name": "H. Ney",
                        "slug": "H.-Ney",
                        "structuredName": {
                            "firstName": "Hermann",
                            "lastName": "Ney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Ney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 231
                            }
                        ],
                        "text": "As a baseline for comparison purposes, we compared phonelevel accuracies of the system to the results given by a system built using the Tandem model described in [1]: the output of the MLP attribute detectors is used as input to a Gaussian-based HMM."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 85
                            }
                        ],
                        "text": "In ASR, the maximum entropy principle has been used to discriminatively train Gaussian-based systems [5], combining phonetic landmark estimates in lattice rescoring [6], and for performing score combination on the acoustic, segmental and word levels [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7179365,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0feeec2feaaf832516a16cce2cf5a034564ca8fa",
            "isKey": false,
            "numCitedBy": 25,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "While Maximum Entropy (ME) based learning procedures have been successfully applied to text based natural language processing, there are only little investigations on using ME for acoustic modeling in automatic speech recognition. In this paper we show that the well known Generalized Iterative Scaling (GIS) algorithm can be used as an alternative method to discriminatively train the parameters of a speech recognizer that is based on Gaussian densities. The approach is compared with both a conventional maximum likelihood training and a discriminative training based on the Extended Baum algorithm. Experimental results are reported on a connected digit string recognition task."
            },
            "slug": "A-comparative-study-on-maximum-entropy-and-training-Macherey-Ney",
            "title": {
                "fragments": [],
                "text": "A comparative study on maximum entropy and discriminative training for acoustic modeling in automatic speech recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The well known Generalized Iterative Scaling (GIS) algorithm can be used as an alternative method to discriminatively train the parameters of a speech recognizer that is based on Gaussian densities."
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145757665"
                        ],
                        "name": "Fei Sha",
                        "slug": "Fei-Sha",
                        "structuredName": {
                            "firstName": "Fei",
                            "lastName": "Sha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fei Sha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145366908"
                        ],
                        "name": "Fernando C Pereira",
                        "slug": "Fernando-C-Pereira",
                        "structuredName": {
                            "firstName": "Fernando",
                            "lastName": "Pereira",
                            "middleNames": [
                                "C"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fernando C Pereira"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 13936575,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "897249c93f55ef1c0d2aa1e799eb67b414c6d4a6",
            "isKey": false,
            "numCitedBy": 1546,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Conditional random fields for sequence labeling offer advantages over both generative models like HMMs and classifiers applied at each sequence position. Among sequence labeling tasks in language processing, shallow parsing has received much attention, with the development of standard evaluation datasets and extensive comparison among methods. We show here how to train a conditional random field to achieve performance as good as any reported base noun-phrase chunking method on the CoNLL task, and better than any reported single model. Improved training methods based on modern optimization algorithms were critical in achieving these results. We present extensive comparisons between models and training methods that confirm and strengthen previous results on shallow parsing and training methods for maximum-entropy models."
            },
            "slug": "Shallow-Parsing-with-Conditional-Random-Fields-Sha-Pereira",
            "title": {
                "fragments": [],
                "text": "Shallow Parsing with Conditional Random Fields"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work shows how to train a conditional random field to achieve performance as good as any reported base noun-phrase chunking method on the CoNLL task, and better than any reported single model."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399115926"
                        ],
                        "name": "M. Hasegawa-Johnson",
                        "slug": "M.-Hasegawa-Johnson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Hasegawa-Johnson",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Hasegawa-Johnson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117189428"
                        ],
                        "name": "J. Baker",
                        "slug": "J.-Baker",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Baker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Baker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2759962"
                        ],
                        "name": "S. Borys",
                        "slug": "S.-Borys",
                        "structuredName": {
                            "firstName": "Sarah",
                            "lastName": "Borys",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Borys"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1390874357"
                        ],
                        "name": "Ken Chen",
                        "slug": "Ken-Chen",
                        "structuredName": {
                            "firstName": "Ken",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ken Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1407961242"
                        ],
                        "name": "Emily Coogan",
                        "slug": "Emily-Coogan",
                        "structuredName": {
                            "firstName": "Emily",
                            "lastName": "Coogan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Emily Coogan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145086537"
                        ],
                        "name": "S. Greenberg",
                        "slug": "S.-Greenberg",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Greenberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Greenberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35039757"
                        ],
                        "name": "A. Juneja",
                        "slug": "A.-Juneja",
                        "structuredName": {
                            "firstName": "Amit",
                            "lastName": "Juneja",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Juneja"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1783839"
                        ],
                        "name": "Katrin Kirchhoff",
                        "slug": "Katrin-Kirchhoff",
                        "structuredName": {
                            "firstName": "Katrin",
                            "lastName": "Kirchhoff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Katrin Kirchhoff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2924113"
                        ],
                        "name": "Karen Livescu",
                        "slug": "Karen-Livescu",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Livescu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Karen Livescu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33147398"
                        ],
                        "name": "Srividya Mohan",
                        "slug": "Srividya-Mohan",
                        "structuredName": {
                            "firstName": "Srividya",
                            "lastName": "Mohan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Srividya Mohan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057008599"
                        ],
                        "name": "Jennifer Muller",
                        "slug": "Jennifer-Muller",
                        "structuredName": {
                            "firstName": "Jennifer",
                            "lastName": "Muller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jennifer Muller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145468185"
                        ],
                        "name": "M. S\u00f6nmez",
                        "slug": "M.-S\u00f6nmez",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "S\u00f6nmez",
                            "middleNames": [
                                "Kemal"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. S\u00f6nmez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152987973"
                        ],
                        "name": "Tianyu T. Wang",
                        "slug": "Tianyu-T.-Wang",
                        "structuredName": {
                            "firstName": "Tianyu",
                            "lastName": "Wang",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianyu T. Wang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 149
                            }
                        ],
                        "text": "In ASR, the maximum entropy principle has been used to discriminatively train Gaussian-based systems [5], combining phonetic landmark estimates in lattice rescoring [6], and for performing score combination on the acoustic, segmental and word levels [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8297837,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d298f76f604e46970e87c5c3a01d4f008791a233",
            "isKey": false,
            "numCitedBy": 135,
            "numCiting": 194,
            "paperAbstract": {
                "fragments": [],
                "text": "Three research prototype speech recognition systems are described, all of which use recently developed methods from artificial intelligence (specifically support vector machines (SVM); dynamic Bayesian networks, and maximum entropy classification) in order to implement, in the form of an ASR, current theories of human speech perception and phonology. All systems begin with a high-D multiframe acoustic-to-distinctive feature transformation, implemented using SVMs trained to detect and classify acoustic phonetic landmarks. Distinctive feature probabilities estimated by the SVMs are then integrated using one of 3 pronunciation models: a dynamic programming algorithm that assumes canonical pronunciation of each word, a dynamic Bayesian network implementation of articulatory phonology, or a discriminative pronunciation model trained using the methods of maximum entropy classification. Log probability scores computed by these models are then combined, using log-linear combination, with other word scores available in the lattice output of a 1st pass recognizer, and the resulting combination score is used to compute a 2nd-pass speech recognition output."
            },
            "slug": "Landmark-based-speech-recognition:-report-of-the-Hasegawa-Johnson-Baker",
            "title": {
                "fragments": [],
                "text": "Landmark-based speech recognition: report of the 2004 Johns Hopkins summer workshop"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "Three research prototype speech recognition systems are described, all of which use recently developed methods from artificial intelligence (specifically support vector machines (SVM); dynamic Bayesian networks, and maximum entropy classification) in order to implement, in the form of an ASR, current theories of human speech perception and phonology."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings. (ICASSP '05). IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "102429215"
                        ],
                        "name": "Kai-Fu Lee",
                        "slug": "Kai-Fu-Lee",
                        "structuredName": {
                            "firstName": "Kai-Fu",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kai-Fu Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145058181"
                        ],
                        "name": "H. Hon",
                        "slug": "H.-Hon",
                        "structuredName": {
                            "firstName": "Hsiao-Wuen",
                            "lastName": "Hon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 37373402,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3034afcd45fc190ed71982828b77f6e4154bdc5c",
            "isKey": false,
            "numCitedBy": 1044,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Hidden Markov modeling is extended to speaker-independent phone recognition. Using multiple codebooks of various linear-predictive-coding (LPC) parameters and discrete hidden Markov models (HMMs) the authors obtain a speaker-independent phone recognition accuracy of 58.8-73.8% on the TIMIT database, depending on the type of acoustic and language models used. In comparison, the performance of expert spectrogram readers is only 69% without use of higher level knowledge. The authors introduce the co-occurrence smoothing algorithm, which enables accurate recognition even with very limited training data. Since the results were evaluated on a standard database, they can be used as benchmarks to evaluate future systems. >"
            },
            "slug": "Speaker-independent-phone-recognition-using-hidden-Lee-Hon",
            "title": {
                "fragments": [],
                "text": "Speaker-independent phone recognition using hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The authors introduce the co-occurrence smoothing algorithm, which enables accurate recognition even with very limited training data, and can be used as benchmarks to evaluate future systems."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153195961"
                        ],
                        "name": "Hua Yu",
                        "slug": "Hua-Yu",
                        "structuredName": {
                            "firstName": "Hua",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hua Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 234
                            }
                        ],
                        "text": "In ASR, the maximum entropy principle has been used to discriminatively train Gaussian-based systems [5], combining phonetic landmark estimates in lattice rescoring [6], and for performing score combination on the acoustic, segmental and word levels [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12693060,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3257ea3dddafbd8ed193f3cc34f278f40353b176",
            "isKey": false,
            "numCitedBy": 5,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a novel approach for modeling segmental information in speech recognition, through the use of thumbnail features. By taking into account dependencies at the segmental level, thumbnail features are more resistant to changes in speaking rates and other factors. While the traditional acoustic features are fixed for every utterance, one set of thumbnail features is computed for each hypothesis, which may violate the traditional scoring paradigm. To this end, we introduce a conditional exponential modeling framework. It allows better integration of various knowledge sources in a discriminative fashion. We present preliminary experiments on the Switchboard task."
            },
            "slug": "Integrating-thumbnail-features-for-speech-using-Yu-Waibel",
            "title": {
                "fragments": [],
                "text": "Integrating thumbnail features for speech recognition using conditional exponential models"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A conditional exponential modeling framework is introduced that allows better integration of various knowledge sources in a discriminative fashion and is presented on the Switchboard task."
            },
            "venue": {
                "fragments": [],
                "text": "2004 IEEE International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1793475"
                        ],
                        "name": "A. Ratnaparkhi",
                        "slug": "A.-Ratnaparkhi",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ratnaparkhi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ratnaparkhi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 145
                            }
                        ],
                        "text": "Models based around the framework of maximum entropy have shown successful results in various areas of discriminative modeling, including part of speech tagging [2], information extraction [3], and statistical language modeling [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5914287,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a574e320d899e7e82e341eb64baef7dfe8a24642",
            "isKey": false,
            "numCitedBy": 1550,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a statistical model which trains from a corpus annotated with Part Of Speech tags and assigns them to previously unseen text with state of the art accuracy The model can be classi ed as a Maximum Entropy model and simultaneously uses many contextual features to predict the POS tag Furthermore this paper demonstrates the use of specialized fea tures to model di cult tagging decisions discusses the corpus consistency problems discovered during the implementation of these features and proposes a training strategy that mitigates these problems"
            },
            "slug": "A-Maximum-Entropy-Model-for-Part-Of-Speech-Tagging-Ratnaparkhi",
            "title": {
                "fragments": [],
                "text": "A Maximum Entropy Model for Part-Of-Speech Tagging"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A statistical model which trains from a corpus annotated with Part Of Speech tags and assigns them to previously unseen text with state of the art accuracy and discusses the corpus consistency problems discovered during the implementation of these features."
            },
            "venue": {
                "fragments": [],
                "text": "EMNLP"
            },
            "year": 1996
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145903504"
                        ],
                        "name": "R. Rosenfeld",
                        "slug": "R.-Rosenfeld",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Rosenfeld",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rosenfeld"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 212
                            }
                        ],
                        "text": "Models based around the framework of maximum entropy have shown successful results in various areas of discriminative modeling, including part of speech tagging [2], information extraction [3], and statistical language modeling [4]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1735632,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b26fa1b848ed808a0511db34bce2426888f0b68",
            "isKey": false,
            "numCitedBy": 419,
            "numCiting": 120,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract : Language modeling is the attempt to characterize, capture and exploit regularities in natural language. In statistical language modeling, large amounts of text are used to automatically determine the model's parameters. Language modeling is useful in automatic speech recognition, machine translation, and any other application that processes natural language with incomplete knowledge. In this thesis, I view language as an information source which emits a stream of symbols from a finite alphabet (the vocabulary). The goal of language modeling is then to identify and exploit sources of information in the language stream, so as to minimize its perceived entropy. Most existing statistical language models exploit the immediate past only. To extract information from further back in the document's history, I use trigger pairs as the basic information bearing elements. This allows the model to adapt its expectations to the topic of discourse. Next, statistical evidence from many sources must be combined. Traditionally, linear interpolation and its variants have been used, but these are shown here to be seriously deficient. Instead, I apply the principle of Maximum Entropy (ME). Each information source gives rise to a set of constraints, to be imposed on the combined estimate. The intersection of these constraints is the set of probability functions which are consistent with all the information sources. The function with the highest entropy within that set is the NE solution. Language modeling, Adaptive language modeling, Statistical language modeling, Maximum entropy, Speech recognition."
            },
            "slug": "Adaptive-Statistical-Language-Modeling;-A-Maximum-Rosenfeld",
            "title": {
                "fragments": [],
                "text": "Adaptive Statistical Language Modeling; A Maximum Entropy Approach"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This thesis views language as an information source which emits a stream of symbols from a finite alphabet (the vocabulary), and applies the principle of Maximum Entropy to identify and exploit sources of information in the language stream, so as to minimize its perceived entropy."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1994
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145804005"
                        ],
                        "name": "Robert Malouf",
                        "slug": "Robert-Malouf",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Malouf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Robert Malouf"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6249194,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "878783964ab23c97052ea82685368099d85c500d",
            "isKey": false,
            "numCitedBy": 744,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Conditional maximum entropy (ME) models provide a general purpose machine learning technique which has been successfully applied to fields as diverse as computer vision and econometrics, and which is used for a wide variety of classification problems in natural language processing. However, the flexibility of ME models is not without cost. While parameter estimation for ME models is conceptually straightforward, in practice ME models for typical natural language tasks are very large, and may well contain many thousands of free parameters. In this paper, we consider a number of algorithms for estimating the parameters of ME models, including iterative scaling, gradient ascent, conjugate gradient, and variable metric methods. Sur-prisingly, the standardly used iterative scaling algorithms perform quite poorly in comparison to the others, and for all of the test problems, a limited-memory variable metric algorithm outperformed the other choices."
            },
            "slug": "A-Comparison-of-Algorithms-for-Maximum-Entropy-Malouf",
            "title": {
                "fragments": [],
                "text": "A Comparison of Algorithms for Maximum Entropy Parameter Estimation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A number of algorithms for estimating the parameters of ME models are considered, including iterative scaling, gradient ascent, conjugate gradient, and variable metric methods."
            },
            "venue": {
                "fragments": [],
                "text": "CoNLL"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409075359"
                        ],
                        "name": "M. Rajamanohar",
                        "slug": "M.-Rajamanohar",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Rajamanohar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Rajamanohar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398481836"
                        ],
                        "name": "E. Fosler-Lussier",
                        "slug": "E.-Fosler-Lussier",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Fosler-Lussier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Fosler-Lussier"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 31017147,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "94f1ac79a8103aa8c8637b274fad170a6370ae69",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "Articulatory feature modeling in automatic speech recognition (ASR), while not (yet) mainstream, has received a significant amount of attention in recent research ((S. Chang, et al., 2001), (K. Kirchhoff, May 2000), (S. Stuker, et al., 2003), (F. Metze and A. Waibel, 2002) inter alia). One study in particular (S. Chang, et al., 2001) has provided evidence that hierarchical articulatory feature models can potentially significantly outperform their non-hierarchical counterparts. In such a system, the probability of an articulatory feature is conditional upon some other feature - for example, the classifier for place of articulation may depend on the manner of articulation. In this work, we seek to further the studies in (S. Chang, et al., 2001) by changing the assumption of perfect recognition of the conditioning class made in that study. The gains shown over non-hierarchical classification are minimized; our analysis shows that this is in part because the errors in different acoustic feature streams are in fact correlated. We conclude the study by observing that joint acoustic feature modeling, rather than conditional modeling, may provide better gains"
            },
            "slug": "An-evaluation-of-hierarchical-articulatory-feature-Rajamanohar-Fosler-Lussier",
            "title": {
                "fragments": [],
                "text": "An evaluation of hierarchical articulatory feature detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This study concludes the study by observing that joint acoustic feature modeling, rather than conditional modeling, may provide better gains."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Workshop on Automatic Speech Recognition and Understanding, 2005."
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145259603"
                        ],
                        "name": "S. Young",
                        "slug": "S.-Young",
                        "structuredName": {
                            "firstName": "Steve",
                            "lastName": "Young",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Young"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056933609"
                        ],
                        "name": "J. Jansen",
                        "slug": "J.-Jansen",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Jansen",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Jansen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144687429"
                        ],
                        "name": "J. Odell",
                        "slug": "J.-Odell",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Odell",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Odell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "116518564"
                        ],
                        "name": "Dg Ollason",
                        "slug": "Dg-Ollason",
                        "structuredName": {
                            "firstName": "Dg",
                            "lastName": "Ollason",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dg Ollason"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1716393"
                        ],
                        "name": "P. Woodland",
                        "slug": "P.-Woodland",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Woodland",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Woodland"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16197350,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a98e481ce418a437cdfae107d85f009a5da6a790",
            "isKey": false,
            "numCitedBy": 2090,
            "numCiting": 2,
            "paperAbstract": {
                "fragments": [],
                "text": "1 The Fundamentals of HTK 2 1.1 General Principles of HMMs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.2 Isolated Word Recognition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 1.3 Output Probability Specification . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 1.4 Baum-Welch Re-Estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 1.5 Recognition and Viterbi Decoding . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 1.6 Continuous Speech Recognition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 1.7 Speaker Adaptation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13"
            },
            "slug": "The-HTK-book-Young-Jansen",
            "title": {
                "fragments": [],
                "text": "The HTK book"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "The Fundamentals of HTK: General Principles of HMMs, Recognition and Viterbi Decoding, and Continuous Speech Recognition."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1995
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2467151"
                        ],
                        "name": "John S. Garofolo",
                        "slug": "John-S.-Garofolo",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Garofolo",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "John S. Garofolo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145204681"
                        ],
                        "name": "L. Lamel",
                        "slug": "L.-Lamel",
                        "structuredName": {
                            "firstName": "Lori",
                            "lastName": "Lamel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Lamel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144982775"
                        ],
                        "name": "W. Fisher",
                        "slug": "W.-Fisher",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Fisher",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Fisher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3241934"
                        ],
                        "name": "J. Fiscus",
                        "slug": "J.-Fiscus",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Fiscus",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Fiscus"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1786370"
                        ],
                        "name": "D. Pallett",
                        "slug": "D.-Pallett",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Pallett",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pallett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35669756"
                        ],
                        "name": "Nancy L. Dahlgren",
                        "slug": "Nancy-L.-Dahlgren",
                        "structuredName": {
                            "firstName": "Nancy",
                            "lastName": "Dahlgren",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nancy L. Dahlgren"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 65148724,
            "fieldsOfStudy": [
                "Physics"
            ],
            "id": "47128bb3ce4ed00691c0d7d58c02791c3e963ab7",
            "isKey": false,
            "numCitedBy": 2187,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Darpa-Timit-Acoustic-Phonetic-Continuous-Speech-|-Garofolo-Lamel",
            "title": {
                "fragments": [],
                "text": "Darpa Timit Acoustic-Phonetic Continuous Speech Corpus CD-ROM {TIMIT} | NIST"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153609862"
                        ],
                        "name": "Yu Wang",
                        "slug": "Yu-Wang",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398481836"
                        ],
                        "name": "E. Fosler-Lussier",
                        "slug": "E.-Fosler-Lussier",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Fosler-Lussier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Fosler-Lussier"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 11809102,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7dad01eb07e1044fedcca20f7ef6fec66e77692d",
            "isKey": false,
            "numCitedBy": 9,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Integrating-phonetic-boundary-discrimination-into-Wang-Fosler-Lussier",
            "title": {
                "fragments": [],
                "text": "Integrating phonetic boundary discrimination explicitly into HMM systems"
            },
            "venue": {
                "fragments": [],
                "text": "INTERSPEECH"
            },
            "year": 2006
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "DARPA TIMIT acoustic phonetic continuous speech corpus cdrom"
            },
            "venue": {
                "fragments": [],
                "text": "DARPA TIMIT acoustic phonetic continuous speech corpus cdrom"
            },
            "year": 1993
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tandem connectionist feature stream extraction for conventional HMM systems \u201d"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE Intl . Conf . on Acoustics , Speech , and Signal Processing"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Conditional Random Fields: Probabilistic Models for Segmenting and Labelling Sequence Data"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 18 th International Conference on Machine Learning"
            },
            "year": 2001
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "ICSI quicknet software package"
            },
            "venue": {
                "fragments": [],
                "text": "ICSI quicknet software package"
            },
            "year": 2004
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tandem connectionist feature stream extraction for conventional HMM systems \u201d"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the IEEE Intl . Conf . on Acoustics , Speech , and Signal Processing"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tandem connectionist feature stream extraction for conventional HMM systems"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. of the ICASSP"
            },
            "year": 2000
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "CRF package for Java ICSI QuickNet software"
            },
            "venue": {
                "fragments": [],
                "text": "CRF package for Java ICSI QuickNet software"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "CRF package for java"
            },
            "venue": {
                "fragments": [],
                "text": "CRF package for java"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "AT&T finite-state machine library"
            },
            "venue": {
                "fragments": [],
                "text": "AT&T finite-state machine library"
            }
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "methodology": 7
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 27,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Combining-phonetic-attributes-using-conditional-Morris-Fosler-Lussier/a0125b014ff5171c74bd6d8365f4cffe3714c0b0?sort=total-citations"
}