{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072782550"
                        ],
                        "name": "Zhihao Jia",
                        "slug": "Zhihao-Jia",
                        "structuredName": {
                            "firstName": "Zhihao",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhihao Jia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110226192"
                        ],
                        "name": "James J. Thomas",
                        "slug": "James-J.-Thomas",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Thomas",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James J. Thomas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2155642"
                        ],
                        "name": "Todd Warszawski",
                        "slug": "Todd-Warszawski",
                        "structuredName": {
                            "firstName": "Todd",
                            "lastName": "Warszawski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Todd Warszawski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2092402029"
                        ],
                        "name": "Mingyu Gao",
                        "slug": "Mingyu-Gao",
                        "structuredName": {
                            "firstName": "Mingyu",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mingyu Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143834867"
                        ],
                        "name": "M. Zaharia",
                        "slug": "M.-Zaharia",
                        "structuredName": {
                            "firstName": "Matei",
                            "lastName": "Zaharia",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Zaharia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653825"
                        ],
                        "name": "A. Aiken",
                        "slug": "A.-Aiken",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Aiken",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Aiken"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "TASO uses the cost-based backtracking search algorithm of MetaFlow [21] and extends its cost model to also capture performance differences that arise from different data layouts."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "MetaFlow [21] allows users to define performance-decreasing substitutions to obtain a larger space of potential graphs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 32
                            }
                        ],
                        "text": "The optimizer uses the MetaFlow [21] cost-based backtracking search algorithm to search for an optimized computation graph by applying verified substitutions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "05, which is identical to the value used in MetaFlow [21]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 127
                            }
                        ],
                        "text": "Wefirst compare the end-to-end inference performance among TensorFlow [6], TensorFlowXLA [3], TensorRT [36], TVM [8], MetaFlow [21], and TASO on a V100 GPU."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "MetaFlow [21] allows substitutions that may either increase or decrease performance to enable a larger search space of equivalent computation graphs and uses back-tracking search to explore this space, but it still requires manually specified substitutions."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "Similar to MetaFlow [21], TASOmeasures the execution time of a DNN operator once for each configuration and data layout, and estimates the performance of a graph by summing up the measured execution time of its operators."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 146
                            }
                        ],
                        "text": "The enlarge operator increases the size of a tensor by padding it with zeros, which is useful for fusing convolutions with different kernel sizes [21]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 95
                            }
                        ],
                        "text": "TASO is implemented on top of MetaFlow, and reuses the MetaFlow cost-based backtracking search [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 102345141,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a226e7dc70c9902fa57b987f8fee78b04052c954",
            "isKey": false,
            "numCitedBy": 39,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Existing deep learning frameworks optimize the computation graph of a DNN model by performing greedy rule-based graph transformations, which generally only consider transformations that strictly improve runtime performance. We propose relaxed graph substitutions that enable the exploration of complex graph optimizations by relaxing the strict performance improvement constraint, which greatly increases the space of semantically equivalent computation graphs that can be discovered by repeated application of a suitable set of graph transformations. We introduce a backtracking search algorithm over a set of relaxed graph substitutions to find optimized networks and use a flow-based graph split algorithm to recursively split a computation graph into smaller subgraphs to allow efficient search. We implement relaxed graph substitutions in a system called MetaFlow and show that MetaFlow improves the inference and training performance by 1.1-1.6\u00d7 and 1.1-1.2\u00d7 respectively over existing deep learning frameworks."
            },
            "slug": "Optimizing-DNN-Computation-with-Relaxed-Graph-Jia-Thomas",
            "title": {
                "fragments": [],
                "text": "Optimizing DNN Computation with Relaxed Graph Substitutions"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A backtracking search algorithm is introduced over a set of relaxed graph substitutions to find optimized networks and a flow-based graph split algorithm is used to recursively split a computation graph into smaller subgraphs to allow efficient search."
            },
            "venue": {
                "fragments": [],
                "text": "MLSys"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1913774"
                        ],
                        "name": "Tianqi Chen",
                        "slug": "Tianqi-Chen",
                        "structuredName": {
                            "firstName": "Tianqi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianqi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149970173"
                        ],
                        "name": "Lianmin Zheng",
                        "slug": "Lianmin-Zheng",
                        "structuredName": {
                            "firstName": "Lianmin",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lianmin Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2621619"
                        ],
                        "name": "Eddie Q. Yan",
                        "slug": "Eddie-Q.-Yan",
                        "structuredName": {
                            "firstName": "Eddie",
                            "lastName": "Yan",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eddie Q. Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732910"
                        ],
                        "name": "Ziheng Jiang",
                        "slug": "Ziheng-Jiang",
                        "structuredName": {
                            "firstName": "Ziheng",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ziheng Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47108160"
                        ],
                        "name": "T. Moreau",
                        "slug": "T.-Moreau",
                        "structuredName": {
                            "firstName": "Thierry",
                            "lastName": "Moreau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Moreau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717411"
                        ],
                        "name": "L. Ceze",
                        "slug": "L.-Ceze",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Ceze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ceze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730156"
                        ],
                        "name": "Carlos Guestrin",
                        "slug": "Carlos-Guestrin",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Guestrin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlos Guestrin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144695691"
                        ],
                        "name": "A. Krishnamurthy",
                        "slug": "A.-Krishnamurthy",
                        "structuredName": {
                            "firstName": "Arvind",
                            "lastName": "Krishnamurthy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krishnamurthy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 153
                            }
                        ],
                        "text": "TensorFlow, TensorFlow XLA, TensorRT, and MetaFlow use the highly-engineered cuDNN and cuBLAS libraries [10, 12] to perform DNN operators on GPUs, while TVM generates customized GPU kernels for the DNN operators."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 39
                            }
                        ],
                        "text": "For example, TensorFlow, TensorRT, and TVM use a rule-based strategy and directly perform all applicable substitutions on an input graph [6, 8, 36]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 97
                            }
                        ],
                        "text": "TASO is framework-agnostic and can be plugged in to existing DNN frameworks such as TensorRT and TVM by simply emitting the optimized graph in the target framework\u2019s input format."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 56
                            }
                        ],
                        "text": "To generate GPU kernels in TVM, we allow the auto tuner [9] to run 2000 trials and use the best discovered configuration for each DNN operator."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 127
                            }
                        ],
                        "text": "The TASO graph optimizer needs to query the execution time of hundreds of DNN operators for its cost model, therefore, for the TVM backend, we reuse the best discovered computation graph for the cuDNN backend, assuming the cost of an operator in cuDNN is a reasonable estimate for its cost in TVM."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 109
                            }
                        ],
                        "text": "Wefirst compare the end-to-end inference performance among TensorFlow [6], TensorFlowXLA [3], TensorRT [36], TVM [8], MetaFlow [21], and TASO on a V100 GPU."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 67
                            }
                        ],
                        "text": "In the evaluation, we demonstrate this portability on TensorRT and TVM, and show that they can directly use TASO\u2019s optimizations to improve performance."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 48
                            }
                        ],
                        "text": "For example, TensorFlow, PyTorch, TensorRT, and TVM use a greedy rule-based optimization strategy and directly perform all applicable substitutions (i.e., rules) on an input computation graph [6, 8, 31, 36]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 17
                            }
                        ],
                        "text": "For example, TVM [8, 9] uses a learning-based approach and automatically generates lowlevel optimized code for a diverse set of hardware backends."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 207,
                                "start": 204
                            }
                        ],
                        "text": "For the remaining four DNN architectures with new operators and graph structures, TASO outperforms existing DNN frameworks with speedups ranging from 1.3\u00d7 to 2.8\u00d7 on the cuDNN backend and 1.1\u00d7 to 1.8\u00d7 on the TVM backend."
                    },
                    "intents": []
                }
            ],
            "corpusId": 29160233,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb91c2f8d3cac0b655a39be318b603334eb18987",
            "isKey": true,
            "numCitedBy": 181,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a learning-based framework to optimize tensor programs for deep learning workloads. Efficient implementations of tensor operators, such as matrix multiplication and high dimensional convolution, are key enablers of effective deep learning systems. However, existing systems rely on manually optimized libraries such as cuDNN where only a narrow range of server class GPUs are well-supported. The reliance on hardware-specific operator libraries limits the applicability of high-level graph optimizations and incurs significant engineering costs when deploying to new hardware targets. We use learning to remove this engineering burden. We learn domain-specific statistical cost models to guide the search of tensor operator implementations over billions of possible program variants. We further accelerate the search by effective model transfer across workloads. Experimental results show that our framework delivers performance competitive with state-of-the-art hand-tuned libraries for low-power CPU, mobile GPU, and server-class GPU."
            },
            "slug": "Learning-to-Optimize-Tensor-Programs-Chen-Zheng",
            "title": {
                "fragments": [],
                "text": "Learning to Optimize Tensor Programs"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A learning-based framework to optimize tensor programs for deep learning workloads that learns domain-specific statistical cost models to guide the search of tensor operator implementations over billions of possible program variants and accelerates the search by effective model transfer across workloads."
            },
            "venue": {
                "fragments": [],
                "text": "NeurIPS"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39172707"
                        ],
                        "name": "Jacob Devlin",
                        "slug": "Jacob-Devlin",
                        "structuredName": {
                            "firstName": "Jacob",
                            "lastName": "Devlin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jacob Devlin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744179"
                        ],
                        "name": "Ming-Wei Chang",
                        "slug": "Ming-Wei-Chang",
                        "structuredName": {
                            "firstName": "Ming-Wei",
                            "lastName": "Chang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming-Wei Chang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2544107"
                        ],
                        "name": "Kenton Lee",
                        "slug": "Kenton-Lee",
                        "structuredName": {
                            "firstName": "Kenton",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenton Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3259253"
                        ],
                        "name": "Kristina Toutanova",
                        "slug": "Kristina-Toutanova",
                        "structuredName": {
                            "firstName": "Kristina",
                            "lastName": "Toutanova",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kristina Toutanova"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "The most time consuming operation in BERT is matrix multiplicationA\u00d7B, whereA is 64 by 1024 and B is 1024 by 4096."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "ResNeXt-50 and BERT do not obtain additional speedups by using substitutions with 4 operators, while NasNet-A achieves 1.2\u00d7 by considering larger substitutions."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "For new DNN architectures such as ResNeXt-50 [38], NasRNN [39], NasNet-A [40], and BERT [15], TASO is up to 2.8\u00d7 faster than state-of-the-art frameworks, by automatically discovering novel graph substitutions to optimize these architectures."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "Finally, BERT [15] is a new language representation architecture that obtained the state-of-the-art model accuracy on a spectrum of language tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "Figure 12 shows the comparison results among the four strategies on BERT."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 88
                            }
                        ],
                        "text": "For new DNN architectures such as ResNeXt-50 [38], NasRNN [39], NasNet-A [40], and BERT [15], TASO is up to 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52967399,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df2b0e26d0599ce3e70df8a9da02e51594e0e992",
            "isKey": true,
            "numCitedBy": 35052,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement)."
            },
            "slug": "BERT:-Pre-training-of-Deep-Bidirectional-for-Devlin-Chang",
            "title": {
                "fragments": [],
                "text": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A new language representation model, BERT, designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers, which can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks."
            },
            "venue": {
                "fragments": [],
                "text": "NAACL"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1861312"
                        ],
                        "name": "Azalia Mirhoseini",
                        "slug": "Azalia-Mirhoseini",
                        "structuredName": {
                            "firstName": "Azalia",
                            "lastName": "Mirhoseini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Azalia Mirhoseini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143950636"
                        ],
                        "name": "Hieu Pham",
                        "slug": "Hieu-Pham",
                        "structuredName": {
                            "firstName": "Hieu",
                            "lastName": "Pham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hieu Pham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32163737"
                        ],
                        "name": "Benoit Steiner",
                        "slug": "Benoit-Steiner",
                        "structuredName": {
                            "firstName": "Benoit",
                            "lastName": "Steiner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benoit Steiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47223513"
                        ],
                        "name": "Rasmus Larsen",
                        "slug": "Rasmus-Larsen",
                        "structuredName": {
                            "firstName": "Rasmus",
                            "lastName": "Larsen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rasmus Larsen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116451595"
                        ],
                        "name": "Yuefeng Zhou",
                        "slug": "Yuefeng-Zhou",
                        "structuredName": {
                            "firstName": "Yuefeng",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuefeng Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116960562"
                        ],
                        "name": "Naveen Kumar",
                        "slug": "Naveen-Kumar",
                        "structuredName": {
                            "firstName": "Naveen",
                            "lastName": "Kumar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naveen Kumar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144739074"
                        ],
                        "name": "Mohammad Norouzi",
                        "slug": "Mohammad-Norouzi",
                        "structuredName": {
                            "firstName": "Mohammad",
                            "lastName": "Norouzi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohammad Norouzi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48448318"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "ColocRL [26] uses reinforcement learning to automatically discover an efficient device placement for parallelizing DNN training across multiple GPUs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3635282,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "bfbd10ebffc9494423770a5bd30ebd0f9cbce66d",
            "isKey": false,
            "numCitedBy": 312,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "The past few years have witnessed a growth in size and computational requirements for training and inference with neural networks. Currently, a common approach to address these requirements is to use a heterogeneous distributed environment with a mixture of hardware devices such as CPUs and GPUs. Importantly, the decision of placing parts of the neural models on devices is often made by human experts based on simple heuristics and intuitions. In this paper, we propose a method which learns to optimize device placement for TensorFlow computational graphs. Key to our method is the use of a sequence-to-sequence model to predict which subsets of operations in a TensorFlow graph should run on which of the available devices. The execution time of the predicted placements is then used as the reward signal to optimize the parameters of the sequence-to-sequence model. Our main result is that on Inception-V3 for ImageNet classification, and on RNN LSTM, for language modeling and neural machine translation, our model finds non-trivial device placements that outperform hand-crafted heuristics and traditional algorithmic methods."
            },
            "slug": "Device-Placement-Optimization-with-Reinforcement-Mirhoseini-Pham",
            "title": {
                "fragments": [],
                "text": "Device Placement Optimization with Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A method which learns to optimize device placement for TensorFlow computational graphs using a sequence-to-sequence model, which finds non-trivial device placements that outperform hand-crafted heuristics and traditional algorithmic methods."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768816"
                        ],
                        "name": "Muthian Sivathanu",
                        "slug": "Muthian-Sivathanu",
                        "structuredName": {
                            "firstName": "Muthian",
                            "lastName": "Sivathanu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Muthian Sivathanu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2122946534"
                        ],
                        "name": "Tapan Chugh",
                        "slug": "Tapan-Chugh",
                        "structuredName": {
                            "firstName": "Tapan",
                            "lastName": "Chugh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tapan Chugh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3376683"
                        ],
                        "name": "Sanjay S. Singapuram",
                        "slug": "Sanjay-S.-Singapuram",
                        "structuredName": {
                            "firstName": "Sanjay",
                            "lastName": "Singapuram",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sanjay S. Singapuram"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "93317102"
                        ],
                        "name": "Lidong Zhou",
                        "slug": "Lidong-Zhou",
                        "structuredName": {
                            "firstName": "Lidong",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lidong Zhou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 6
                            }
                        ],
                        "text": "Astra [34] optimizes DNN computation by exploring the optimization space of multi-version complication during training."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 88497672,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f12557da0cff05914ed4a28d11c8a561e08fbd18",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "We present Astra, a compilation and execution framework that optimizes execution of a deep learning training job. Instead of treating the computation as a generic data flow graph, Astra exploits domain knowledge about deep learning to adopt a custom approach to compiler optimization. The key insight in Astra is to exploit the unique repetitiveness and predictability of a deep learning job, to perform online exploration of the optimization state space in a work-conserving manner while making progress on the training job. This dynamic state space exploration in Astra uses lightweight profiling and indexing of profile data, coupled with several techniques to prune the exploration state space. Effectively, the execution layer custom-wires the infrastructure end-to-end for each job and hardware, while keeping the compiler simple and maintainable. We have implemented Astra in two popular deep learning frameworks, PyTorch and Tensorflow. On state-of-the-art deep learning models, we show that Astra improves end-to-end performance of deep learning training by up to 3x, while approaching the performance of hand-optimized implementations such as cuDNN where available. Astra also significantly outperforms static compilation frameworks such as Tensorflow XLA both in performance and robustness."
            },
            "slug": "Astra:-Exploiting-Predictability-to-Optimize-Deep-Sivathanu-Chugh",
            "title": {
                "fragments": [],
                "text": "Astra: Exploiting Predictability to Optimize Deep Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "It is shown that Astra improves end-to-end performance of deep learning training by up to 3x, while approaching the performance of hand-optimized implementations such as cuDNN where available and significantly outperforms static compilation frameworks such as Tensorflow XLA both in performance and robustness."
            },
            "venue": {
                "fragments": [],
                "text": "ASPLOS"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072782550"
                        ],
                        "name": "Zhihao Jia",
                        "slug": "Zhihao-Jia",
                        "structuredName": {
                            "firstName": "Zhihao",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhihao Jia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143834867"
                        ],
                        "name": "M. Zaharia",
                        "slug": "M.-Zaharia",
                        "structuredName": {
                            "firstName": "Matei",
                            "lastName": "Zaharia",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Zaharia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653825"
                        ],
                        "name": "A. Aiken",
                        "slug": "A.-Aiken",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Aiken",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Aiken"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 9
                            }
                        ],
                        "text": "FlexFlow [20, 22] introduces a comprehensive search space of parallelization strategies for DNN training, and uses a randomized search algorithm to find efficient strategies in the search space."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 49868726,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f971658ab845d7573c4bbb760d5e7e5332025254",
            "isKey": false,
            "numCitedBy": 233,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "The computational requirements for training deep neural networks (DNNs) have grown to the point that it is now standard practice to parallelize training. Existing deep learning systems commonly use data or model parallelism, but unfortunately, these strategies often result in suboptimal parallelization performance. \nIn this paper, we define a more comprehensive search space of parallelization strategies for DNNs called SOAP, which includes strategies to parallelize a DNN in the Sample, Operation, Attribute, and Parameter dimensions. We also propose FlexFlow, a deep learning framework that uses guided randomized search of the SOAP space to find a fast parallelization strategy for a specific parallel machine. To accelerate this search, FlexFlow introduces a novel execution simulator that can accurately predict a parallelization strategy's performance and is three orders of magnitude faster than prior approaches that have to execute each strategy. We evaluate FlexFlow with six real-world DNN benchmarks on two GPU clusters and show that FlexFlow can increase training throughput by up to 3.8x over state-of-the-art approaches, even when including its search time, and also improves scalability."
            },
            "slug": "Beyond-Data-and-Model-Parallelism-for-Deep-Neural-Jia-Zaharia",
            "title": {
                "fragments": [],
                "text": "Beyond Data and Model Parallelism for Deep Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "A more comprehensive search space of parallelization strategies for DNNs called SOAP, which includes strategies to parallelize a DNN in the Sample, Operation, Attribute, and Parameter dimensions is defined and FlexFlow, a deep learning framework that uses guided randomized search of the SOAP space to find a fast parallelization strategy for a specific parallel machine is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "MLSys"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2057642721"
                        ],
                        "name": "Mart\u00edn Abadi",
                        "slug": "Mart\u00edn-Abadi",
                        "structuredName": {
                            "firstName": "Mart\u00edn",
                            "lastName": "Abadi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mart\u00edn Abadi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144758007"
                        ],
                        "name": "P. Barham",
                        "slug": "P.-Barham",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Barham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Barham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108406634"
                        ],
                        "name": "Jianmin Chen",
                        "slug": "Jianmin-Chen",
                        "structuredName": {
                            "firstName": "Jianmin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianmin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2545358"
                        ],
                        "name": "Z. Chen",
                        "slug": "Z.-Chen",
                        "structuredName": {
                            "firstName": "Z.",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36347083"
                        ],
                        "name": "Andy Davis",
                        "slug": "Andy-Davis",
                        "structuredName": {
                            "firstName": "Andy",
                            "lastName": "Davis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andy Davis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49959210"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145139947"
                        ],
                        "name": "Matthieu Devin",
                        "slug": "Matthieu-Devin",
                        "structuredName": {
                            "firstName": "Matthieu",
                            "lastName": "Devin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthieu Devin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1780892"
                        ],
                        "name": "S. Ghemawat",
                        "slug": "S.-Ghemawat",
                        "structuredName": {
                            "firstName": "Sanjay",
                            "lastName": "Ghemawat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ghemawat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060655766"
                        ],
                        "name": "Geoffrey Irving",
                        "slug": "Geoffrey-Irving",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Irving",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey Irving"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2090818"
                        ],
                        "name": "M. Isard",
                        "slug": "M.-Isard",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Isard",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Isard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1942300"
                        ],
                        "name": "M. Kudlur",
                        "slug": "M.-Kudlur",
                        "structuredName": {
                            "firstName": "Manjunath",
                            "lastName": "Kudlur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kudlur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3369421"
                        ],
                        "name": "J. Levenberg",
                        "slug": "J.-Levenberg",
                        "structuredName": {
                            "firstName": "Josh",
                            "lastName": "Levenberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Levenberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3089272"
                        ],
                        "name": "R. Monga",
                        "slug": "R.-Monga",
                        "structuredName": {
                            "firstName": "Rajat",
                            "lastName": "Monga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Monga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144375552"
                        ],
                        "name": "Sherry Moore",
                        "slug": "Sherry-Moore",
                        "structuredName": {
                            "firstName": "Sherry",
                            "lastName": "Moore",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sherry Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20154699"
                        ],
                        "name": "D. Murray",
                        "slug": "D.-Murray",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Murray",
                            "middleNames": [
                                "Gordon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Murray"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32163737"
                        ],
                        "name": "Benoit Steiner",
                        "slug": "Benoit-Steiner",
                        "structuredName": {
                            "firstName": "Benoit",
                            "lastName": "Steiner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benoit Steiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2080690"
                        ],
                        "name": "P. Tucker",
                        "slug": "P.-Tucker",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Tucker",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Tucker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053781980"
                        ],
                        "name": "Vijay Vasudevan",
                        "slug": "Vijay-Vasudevan",
                        "structuredName": {
                            "firstName": "Vijay",
                            "lastName": "Vasudevan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vijay Vasudevan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47941411"
                        ],
                        "name": "P. Warden",
                        "slug": "P.-Warden",
                        "structuredName": {
                            "firstName": "Pete",
                            "lastName": "Warden",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Warden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35078078"
                        ],
                        "name": "M. Wicke",
                        "slug": "M.-Wicke",
                        "structuredName": {
                            "firstName": "Martin",
                            "lastName": "Wicke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Wicke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117163698"
                        ],
                        "name": "Yuan Yu",
                        "slug": "Yuan-Yu",
                        "structuredName": {
                            "firstName": "Yuan",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuan Yu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144533795"
                        ],
                        "name": "Xiaoqiang Zhang",
                        "slug": "Xiaoqiang-Zhang",
                        "structuredName": {
                            "firstName": "Xiaoqiang",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoqiang Zhang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "TensorFlow, TensorFlow XLA, TensorRT, and MetaFlow use the highly-engineered cuDNN and cuBLAS libraries [10, 12] to perform DNN operators on GPUs, while TVM generates customized GPU kernels for the DNN operators."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 13
                            }
                        ],
                        "text": "For example, TensorFlow currently contains approximately 53,000 lines of manual optimization rules, while the operator specifications needed by TASO are only 1,400 lines of code."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 35
                            }
                        ],
                        "text": "Similar to existing DNN frameworks [6, 31], pooling and convolution operators support different strides and padding modes (i."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 39
                            }
                        ],
                        "text": ", rules) on an input computation graph [6, 8, 31, 36]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 137
                            }
                        ],
                        "text": "For example, TensorFlow, TensorRT, and TVM use a rule-based strategy and directly perform all applicable substitutions on an input graph [6, 8, 36]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "TensorFlow r1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "TensorFlow and TensorFlow XLA (r1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 13
                            }
                        ],
                        "text": "For example, TensorFlow r1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 122
                            }
                        ],
                        "text": "14 as of August 2019) currently do not support grouped convolution, so the fastest available ResNeXt-50 implementation in TensorFlow launches convolutions in multiple branches separately with the resulting high kernel launch overhead."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 70
                            }
                        ],
                        "text": "Wefirst compare the end-to-end inference performance among TensorFlow [6], TensorFlowXLA [3], TensorRT [36], TVM [8], MetaFlow [21], and TASO on a V100 GPU."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 13
                            }
                        ],
                        "text": "For example, TensorFlow, PyTorch, TensorRT, and TVM use a greedy rule-based optimization strategy and directly perform all applicable substitutions (i.e., rules) on an input computation graph [6, 8, 31, 36]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6287870,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "46200b99c40e8586c8a0f588488ab6414119fb28",
            "isKey": true,
            "numCitedBy": 12805,
            "numCiting": 111,
            "paperAbstract": {
                "fragments": [],
                "text": "TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. Tensor-Flow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, general-purpose GPUs, and custom-designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer: whereas in previous \"parameter server\" designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with a focus on training and inference on deep neural networks. Several Google services use TensorFlow in production, we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model and demonstrate the compelling performance that TensorFlow achieves for several real-world applications."
            },
            "slug": "TensorFlow:-A-system-for-large-scale-machine-Abadi-Barham",
            "title": {
                "fragments": [],
                "text": "TensorFlow: A system for large-scale machine learning"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The TensorFlow dataflow model is described and the compelling performance that Tensor Flow achieves for several real-world applications is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "OSDI"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2368067"
                        ],
                        "name": "Barret Zoph",
                        "slug": "Barret-Zoph",
                        "structuredName": {
                            "firstName": "Barret",
                            "lastName": "Zoph",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barret Zoph"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 51
                            }
                        ],
                        "text": "For new DNN architectures such as ResNeXt-50 [38], NasRNN [39], NasNet-A [40], and BERT [15], TASO is up to 2.8\u00d7 faster than state-of-the-art frameworks, by automatically discovering novel graph substitutions to optimize these architectures."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 13
                            }
                        ],
                        "text": "NasNet-A and NasRNN exceed the best human-designed DNN architectures for image classification and language modeling tasks, respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 25
                            }
                        ],
                        "text": "NasNet-A [40] and NasRNN [39] are two DNN architectures automatically discovered by machines through neural architecture search."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "For new DNN architectures such as ResNeXt-50 [38], NasRNN [39], NasNet-A [40], and BERT [15], TASO is up to 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12713052,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "67d968c7450878190e45ac7886746de867bf673d",
            "isKey": true,
            "numCitedBy": 3482,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural networks are powerful and flexible models that work well for many difficult learning tasks in image, speech and natural language understanding. Despite their success, neural networks are still hard to design. In this paper, we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set. On the CIFAR-10 dataset, our method, starting from scratch, can design a novel network architecture that rivals the best human-invented architecture in terms of test set accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is 0.09 percent better and 1.05x faster than the previous state-of-the-art model that used a similar architectural scheme. On the Penn Treebank dataset, our model can compose a novel recurrent cell that outperforms the widely-used LSTM cell, and other state-of-the-art baselines. Our cell achieves a test set perplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than the previous state-of-the-art model. The cell can also be transferred to the character language modeling task on PTB and achieves a state-of-the-art perplexity of 1.214."
            },
            "slug": "Neural-Architecture-Search-with-Reinforcement-Zoph-Le",
            "title": {
                "fragments": [],
                "text": "Neural Architecture Search with Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper uses a recurrent network to generate the model descriptions of neural networks and trains this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1913774"
                        ],
                        "name": "Tianqi Chen",
                        "slug": "Tianqi-Chen",
                        "structuredName": {
                            "firstName": "Tianqi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianqi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47108160"
                        ],
                        "name": "T. Moreau",
                        "slug": "T.-Moreau",
                        "structuredName": {
                            "firstName": "Thierry",
                            "lastName": "Moreau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Moreau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732910"
                        ],
                        "name": "Ziheng Jiang",
                        "slug": "Ziheng-Jiang",
                        "structuredName": {
                            "firstName": "Ziheng",
                            "lastName": "Jiang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ziheng Jiang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3050154"
                        ],
                        "name": "Haichen Shen",
                        "slug": "Haichen-Shen",
                        "structuredName": {
                            "firstName": "Haichen",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haichen Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2621619"
                        ],
                        "name": "Eddie Q. Yan",
                        "slug": "Eddie-Q.-Yan",
                        "structuredName": {
                            "firstName": "Eddie",
                            "lastName": "Yan",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eddie Q. Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2185540"
                        ],
                        "name": "Leyuan Wang",
                        "slug": "Leyuan-Wang",
                        "structuredName": {
                            "firstName": "Leyuan",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Leyuan Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49994783"
                        ],
                        "name": "Yuwei Hu",
                        "slug": "Yuwei-Hu",
                        "structuredName": {
                            "firstName": "Yuwei",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuwei Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717411"
                        ],
                        "name": "L. Ceze",
                        "slug": "L.-Ceze",
                        "structuredName": {
                            "firstName": "Luis",
                            "lastName": "Ceze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Ceze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730156"
                        ],
                        "name": "Carlos Guestrin",
                        "slug": "Carlos-Guestrin",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Guestrin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlos Guestrin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144695691"
                        ],
                        "name": "A. Krishnamurthy",
                        "slug": "A.-Krishnamurthy",
                        "structuredName": {
                            "firstName": "Arvind",
                            "lastName": "Krishnamurthy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krishnamurthy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 39
                            }
                        ],
                        "text": ", rules) on an input computation graph [6, 8, 31, 36]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 137
                            }
                        ],
                        "text": "For example, TensorFlow, TensorRT, and TVM use a rule-based strategy and directly perform all applicable substitutions on an input graph [6, 8, 36]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 142
                            }
                        ],
                        "text": "Existing DNN frameworks that support data layout optimizations treat data layouts and graph transformations as separate optimization problems [8, 24, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 113
                            }
                        ],
                        "text": "Wefirst compare the end-to-end inference performance among TensorFlow [6], TensorFlowXLA [3], TensorRT [36], TVM [8], MetaFlow [21], and TASO on a V100 GPU."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 157,
                                "start": 150
                            }
                        ],
                        "text": "Current frameworks avoid this complexity by treating data layout and graph substitution as separate optimization problems and solve them sequentially [8, 27], as shown in Figure 1a, but this separation misses many possible optimization opportunities."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 17
                            }
                        ],
                        "text": "For example, TVM [8, 9] uses a learning-based approach and automatically generates lowlevel optimized code for a diverse set of hardware backends."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3296374,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ec3071fb918ad69ec80df1ca9cf1fdeb386a9603",
            "isKey": true,
            "numCitedBy": 140,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Scalable frameworks, such as TensorFlow, MXNet, Caffe, and PyTorch drive the current popularity and utility of deep learning. However, these frameworks are optimized for a narrow range of server-class GPUs and deploying workloads to other platforms such as mobile phones, embedded devices, and specialized accelerators (e.g., FPGAs, ASICs) requires laborious manual effort. We propose TVM, an end-to-end optimization stack that exposes graph-level and operator-level optimizations to provide performance portability to deep learning workloads across diverse hardware back-ends. We discuss the optimization challenges specific to deep learning that TVM solves: high-level operator fusion, low-level memory reuse across threads, mapping to arbitrary hardware primitives, and memory latency hiding. Experimental results demonstrate that TVM delivers performance across hardware back-ends that are competitive with state-of-the-art libraries for low-power CPU and server-class GPUs. We also demonstrate TVM's ability to target new hardware accelerator back-ends by targeting an FPGA-based generic deep learning accelerator. The compiler infrastructure is open sourced."
            },
            "slug": "TVM:-End-to-End-Optimization-Stack-for-Deep-Chen-Moreau",
            "title": {
                "fragments": [],
                "text": "TVM: End-to-End Optimization Stack for Deep Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "TVM is proposed, an end-to-end optimization stack that exposes graph-level and operator-level optimizations to provide performance portability to deep learning workloads across diverse hardware back-ends and discusses the optimization challenges specific toDeep learning that TVM solves."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1817030"
                        ],
                        "name": "Saining Xie",
                        "slug": "Saining-Xie",
                        "structuredName": {
                            "firstName": "Saining",
                            "lastName": "Xie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saining Xie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2983898"
                        ],
                        "name": "Ross B. Girshick",
                        "slug": "Ross-B.-Girshick",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Girshick",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross B. Girshick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127283"
                        ],
                        "name": "Piotr Doll\u00e1r",
                        "slug": "Piotr-Doll\u00e1r",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Doll\u00e1r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piotr Doll\u00e1r"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 4
                            }
                        ],
                        "text": "For ResNeXt-50, TASO uses a mixture of previous approaches and launches multiple grouped convolutions, as shown in Figure 9c. TASO discovered this mixture automatically, resulting in a speedup of 2.8\u00d7 compared to the best existing approach."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "ResNeXt-50 and BERT do not obtain additional speedups by using substitutions with 4 operators, while NasNet-A achieves 1.2\u00d7 by considering larger substitutions."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "ResNeXt-50 [38] improves the model accuracy and runtime efficiency of ResNet-50 by introducing a new grouped convolution operator."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 34
                            }
                        ],
                        "text": "For new DNN architectures such as ResNeXt-50 [38], NasRNN [39], NasNet-A [40], and BERT [15], TASO is up to 2.8\u00d7 faster than state-of-the-art frameworks, by automatically discovering novel graph substitutions to optimize these architectures."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 103,
                                "start": 93
                            }
                        ],
                        "text": "14 as of August 2019) currently do not support grouped convolution, so the fastest available ResNeXt-50 implementation in TensorFlow launches convolutions in multiple branches separately with the resulting high kernel launch overhead."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 0
                            }
                        ],
                        "text": "ResNeXt-50 replaces large convolutions in ResNet-50 with multiple branches of much smaller convolutions to improve both model accuracy and runtime efficiency, as shown\nin Figure 9a."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 160
                            }
                        ],
                        "text": "The maintenance problem is aggravated by the fact that new operators are continuously introduced; for example, recent work has proposed depthwise [19], grouped [38], and transposed convolutions [16] for different image classification tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "For new DNN architectures such as ResNeXt-50 [38], NasRNN [39], NasNet-A [40], and BERT [15], TASO is up to 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8485068,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6e0856b4a9199fa968ac00da612a9407b5cb85c",
            "isKey": true,
            "numCitedBy": 5619,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a simple, highly modularized network architecture for image classification. Our network is constructed by repeating a building block that aggregates a set of transformations with the same topology. Our simple design results in a homogeneous, multi-branch architecture that has only a few hyper-parameters to set. This strategy exposes a new dimension, which we call cardinality (the size of the set of transformations), as an essential factor in addition to the dimensions of depth and width. On the ImageNet-1K dataset, we empirically show that even under the restricted condition of maintaining complexity, increasing cardinality is able to improve classification accuracy. Moreover, increasing cardinality is more effective than going deeper or wider when we increase the capacity. Our models, named ResNeXt, are the foundations of our entry to the ILSVRC 2016 classification task in which we secured 2nd place. We further investigate ResNeXt on an ImageNet-5K set and the COCO detection set, also showing better results than its ResNet counterpart. The code and models are publicly available online."
            },
            "slug": "Aggregated-Residual-Transformations-for-Deep-Neural-Xie-Girshick",
            "title": {
                "fragments": [],
                "text": "Aggregated Residual Transformations for Deep Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "On the ImageNet-1K dataset, it is empirically show that even under the restricted condition of maintaining complexity, increasing cardinality is able to improve classification accuracy and is more effective than going deeper or wider when the authors increase the capacity."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3003738"
                        ],
                        "name": "Sharan Chetlur",
                        "slug": "Sharan-Chetlur",
                        "structuredName": {
                            "firstName": "Sharan",
                            "lastName": "Chetlur",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sharan Chetlur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2266717"
                        ],
                        "name": "Cliff Woolley",
                        "slug": "Cliff-Woolley",
                        "structuredName": {
                            "firstName": "Cliff",
                            "lastName": "Woolley",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cliff Woolley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2101730"
                        ],
                        "name": "Philippe Vandermersch",
                        "slug": "Philippe-Vandermersch",
                        "structuredName": {
                            "firstName": "Philippe",
                            "lastName": "Vandermersch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philippe Vandermersch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145611200"
                        ],
                        "name": "Jonathan M. Cohen",
                        "slug": "Jonathan-M.-Cohen",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Cohen",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan M. Cohen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066786849"
                        ],
                        "name": "J. Tran",
                        "slug": "J.-Tran",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Tran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2301680"
                        ],
                        "name": "Bryan Catanzaro",
                        "slug": "Bryan-Catanzaro",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "Catanzaro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bryan Catanzaro"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782282"
                        ],
                        "name": "Evan Shelhamer",
                        "slug": "Evan-Shelhamer",
                        "structuredName": {
                            "firstName": "Evan",
                            "lastName": "Shelhamer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Evan Shelhamer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 104
                            }
                        ],
                        "text": "TensorFlow, TensorFlow XLA, TensorRT, and MetaFlow use the highly-engineered cuDNN and cuBLAS libraries [10, 12] to perform DNN operators on GPUs, while TVM generates customized GPU kernels for the DNN operators."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": ", the cuDNN kernels [10]) up to a fixed size, and executes them on a set of random input tensors."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 144
                            }
                        ],
                        "text": "The cuDNN library has recently introduced grouped convolution kernels that perform multiple convolutions in parallel using a single CUDA kernel [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12330432,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "31c36d445367ba204244bb74893c5654e31c3869",
            "isKey": false,
            "numCitedBy": 1419,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a library that provides optimized implementations for deep learning primitives. Deep learning workloads are computationally intensive, and optimizing the kernels of deep learning workloads is difficult and time-consuming. As parallel architectures evolve, kernels must be reoptimized for new processors, which makes maintaining codebases difficult over time. Similar issues have long been addressed in the HPC community by libraries such as the Basic Linear Algebra Subroutines (BLAS) [2]. However, there is no analogous library for deep learning. Without such a library, researchers implementing deep learning workloads on parallel processors must create and optimize their own implementations of the main computational kernels, and this work must be repeated as new parallel processors emerge. To address this problem, we have created a library similar in intent to BLAS, with optimized routines for deep learning workloads. Our implementation contains routines for GPUs, and similarly to the BLAS library, could be implemented for other platforms. The library is easy to integrate into existing frameworks, and provides optimized performance and memory usage. For example, integrating cuDNN into Caffe, a popular framework for convolutional networks, improves performance by 36% on a standard model while also reducing memory consumption."
            },
            "slug": "cuDNN:-Efficient-Primitives-for-Deep-Learning-Chetlur-Woolley",
            "title": {
                "fragments": [],
                "text": "cuDNN: Efficient Primitives for Deep Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "A library similar in intent to BLAS, with optimized routines for deep learning workloads, that contains routines for GPUs, and similarly to the BLAS library, could be implemented for other platforms."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "101473711"
                        ],
                        "name": "Shuang Wu",
                        "slug": "Shuang-Wu",
                        "structuredName": {
                            "firstName": "Shuang",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuang Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1730243"
                        ],
                        "name": "Guoqi Li",
                        "slug": "Guoqi-Li",
                        "structuredName": {
                            "firstName": "Guoqi",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Guoqi Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144180429"
                        ],
                        "name": "F. Chen",
                        "slug": "F.-Chen",
                        "structuredName": {
                            "firstName": "F.",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29889772"
                        ],
                        "name": "Luping Shi",
                        "slug": "Luping-Shi",
                        "structuredName": {
                            "firstName": "Luping",
                            "lastName": "Shi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luping Shi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 137
                            }
                        ],
                        "text": "To avoid floating-point errors in computing a fingerprint, all tensors are represented with integers, following the method introduced in [37]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3603886,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "acdf151b8efc2c6b05662d69f27531afc557dc85",
            "isKey": false,
            "numCitedBy": 262,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Researches on deep neural networks with discrete parameters and their deployment in embedded systems have been active and promising topics. Although previous works have successfully reduced precision in inference, transferring both training and inference processes to low-bitwidth integers has not been demonstrated simultaneously. In this work, we develop a new method termed as \"WAGE\" to discretize both training and inference, where weights (W), activations (A), gradients (G) and errors (E) among layers are shifted and linearly constrained to low-bitwidth integers. To perform pure discrete dataflow for fixed-point devices, we further replace batch normalization by a constant scaling layer and simplify other components that are arduous for integer implementation. Improved accuracies can be obtained on multiple datasets, which indicates that WAGE somehow acts as a type of regularization. Empirically, we demonstrate the potential to deploy training in hardware systems such as integer-based deep learning accelerators and neuromorphic chips with comparable accuracy and higher energy efficiency, which is crucial to future AI applications in variable scenarios with transfer and continual learning demands."
            },
            "slug": "Training-and-Inference-with-Integers-in-Deep-Neural-Wu-Li",
            "title": {
                "fragments": [],
                "text": "Training and Inference with Integers in Deep Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Empirically, this work demonstrates the potential to deploy training in hardware systems such as integer-based deep learning accelerators and neuromorphic chips with comparable accuracy and higher energy efficiency, which is crucial to future AI applications in variable scenarios with transfer and continual learning demands."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46651287"
                        ],
                        "name": "C. Li",
                        "slug": "C.-Li",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2143686020"
                        ],
                        "name": "Yi Yang",
                        "slug": "Yi-Yang",
                        "structuredName": {
                            "firstName": "Yi",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yi Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067623080"
                        ],
                        "name": "Min Feng",
                        "slug": "Min-Feng",
                        "structuredName": {
                            "firstName": "Min",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Min Feng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752242"
                        ],
                        "name": "S. Chakradhar",
                        "slug": "S.-Chakradhar",
                        "structuredName": {
                            "firstName": "Srimat",
                            "lastName": "Chakradhar",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chakradhar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38067595"
                        ],
                        "name": "Huiyang Zhou",
                        "slug": "Huiyang-Zhou",
                        "structuredName": {
                            "firstName": "Huiyang",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huiyang Zhou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 153,
                                "start": 142
                            }
                        ],
                        "text": "Existing DNN frameworks that support data layout optimizations treat data layouts and graph transformations as separate optimization problems [8, 24, 27]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 758535,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d6a4ec00379fbe4206ea91b20ee8d40b1a38de1",
            "isKey": false,
            "numCitedBy": 61,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Leveraging large data sets, deep Convolutional Neural Networks (CNNs) achieve state-of-the-art recognition accuracy. Due to the substantial compute and memory operations, however, they require significant execution time. The massive parallel computing capability of GPUs make them as one of the ideal platforms to accelerate CNNs and a number of GPU-based CNN libraries have been developed. While existing works mainly focus on the computational efficiency of CNNs, the memory efficiency of CNNs have been largely overlooked. Yet CNNs have intricate data structures and their memory behavior can have significant impact on the performance. In this work, we study the memory efficiency of various CNN layers and reveal the performance implication from both data layouts and memory access patterns. Experiments show the universal effect of our proposed optimizations on both single layers and various networks, with up to 27.9\u00d7 for a single layer and up to 5.6\u00d7 on the whole networks."
            },
            "slug": "Optimizing-Memory-Efficiency-for-Deep-Convolutional-Li-Yang",
            "title": {
                "fragments": [],
                "text": "Optimizing Memory Efficiency for Deep Convolutional Neural Networks on GPUs"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work studies the memory efficiency of various CNN layers and reveals the performance implication from both data layouts and memory access patterns, which shows the universal effect of the proposed optimizations on both single layers and various networks."
            },
            "venue": {
                "fragments": [],
                "text": "SC16: International Conference for High Performance Computing, Networking, Storage and Analysis"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771551"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3080683"
                        ],
                        "name": "Shaoqing Ren",
                        "slug": "Shaoqing-Ren",
                        "structuredName": {
                            "firstName": "Shaoqing",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoqing Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "For widely used DNNs optimized by existing frameworks, such as ResNet-50 [18], TASO matches the performance of these frameworks with hand-written rules by using operator definitions and specifications 1,400 lines long."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 123
                            }
                        ],
                        "text": "TASO matches the performance of existing frameworks on DNNs for which these frameworks have been heavily optimized such as ResNet-50, and outperforms existing frameworks by up to 2.8\u00d7 on other DNNs, finding novel optimizations not present in the hundreds of optimization rules in existing frameworks."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 79,
                                "start": 70
                            }
                        ],
                        "text": "ResNeXt-50 [38] improves the model accuracy and runtime efficiency of ResNet-50 by introducing a new grouped convolution operator."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "ResNet-50 [18] is a widely used convolutional neural network for image classification and achieved the best classification performance in the ILSVRC [32] competition."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 42
                            }
                        ],
                        "text": "ResNeXt-50 replaces large convolutions in ResNet-50 with multiple branches of much smaller convolutions to improve both model accuracy and runtime efficiency, as shown\nin Figure 9a."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 34
                            }
                        ],
                        "text": "Among the five DNN architectures, ResNet-50 has been commonly used and heavily optimized by existing DNN frameworks."
                    },
                    "intents": []
                }
            ],
            "corpusId": 206594692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "isKey": true,
            "numCitedBy": 97653,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation."
            },
            "slug": "Deep-Residual-Learning-for-Image-Recognition-He-Zhang",
            "title": {
                "fragments": [],
                "text": "Deep Residual Learning for Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work presents a residual learning framework to ease the training of networks that are substantially deeper than those used previously, and provides comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2368067"
                        ],
                        "name": "Barret Zoph",
                        "slug": "Barret-Zoph",
                        "structuredName": {
                            "firstName": "Barret",
                            "lastName": "Zoph",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barret Zoph"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053781980"
                        ],
                        "name": "Vijay Vasudevan",
                        "slug": "Vijay-Vasudevan",
                        "structuredName": {
                            "firstName": "Vijay",
                            "lastName": "Vasudevan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vijay Vasudevan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789737"
                        ],
                        "name": "Jonathon Shlens",
                        "slug": "Jonathon-Shlens",
                        "structuredName": {
                            "firstName": "Jonathon",
                            "lastName": "Shlens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathon Shlens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1397917613"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc V.",
                            "lastName": "Le",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 40
                            }
                        ],
                        "text": "Figure 8a shows a convolutional cell in NasNet-A."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 101
                            }
                        ],
                        "text": "ResNeXt-50 and BERT do not obtain additional speedups by using substitutions with 4 operators, while NasNet-A achieves 1.2\u00d7 by considering larger substitutions."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "NasNet-A and NasRNN exceed the best human-designed DNN architectures for image classification and language modeling tasks, respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 0
                            }
                        ],
                        "text": "NasNet-A is the best discovered CNN architecture for the CIFAR-10 dataset, obtained by neural architecture search."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "The NasNet-A architecture [40] and substitutions discovered by TASO to optimize NasNet-A."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 37
                            }
                        ],
                        "text": "Unlike human-designed architectures, NasNet-A contains unconventional graph structures, making it hard to optimize with manual substitutions designed for more standard DNN architectures."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 64
                            }
                        ],
                        "text": "For new DNN architectures such as ResNeXt-50 [38], NasRNN [39], NasNet-A [40], and BERT [15], TASO is up to 2.8\u00d7 faster than state-of-the-art frameworks, by automatically discovering novel graph substitutions to optimize these architectures."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 43
                            }
                        ],
                        "text": "A second new sequence of substitutions for NasNet-A is shown in Figure 8c, which fuses two depth-wise convolutions and two convolutions followed by addition to a depth-wise convolution followed by a standard convolution."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "For new DNN architectures such as ResNeXt-50 [38], NasRNN [39], NasNet-A [40], and BERT [15], TASO is up to 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 9
                            }
                        ],
                        "text": "NasNet-A [40] and NasRNN [39] are two DNN architectures automatically discovered by machines through neural architecture search."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12227989,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0611891b9e8a7c5731146097b6f201578f47b2f",
            "isKey": true,
            "numCitedBy": 3538,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "Developing neural network image classification models often requires significant architecture engineering. In this paper, we study a method to learn the model architectures directly on the dataset of interest. As this approach is expensive when the dataset is large, we propose to search for an architectural building block on a small dataset and then transfer the block to a larger dataset. The key contribution of this work is the design of a new search space (which we call the \"NASNet search space\") which enables transferability. In our experiments, we search for the best convolutional layer (or \"cell\") on the CIFAR-10 dataset and then apply this cell to the ImageNet dataset by stacking together more copies of this cell, each with their own parameters to design a convolutional architecture, which we name a \"NASNet architecture\". We also introduce a new regularization technique called ScheduledDropPath that significantly improves generalization in the NASNet models. On CIFAR-10 itself, a NASNet found by our method achieves 2.4% error rate, which is state-of-the-art. Although the cell is not searched for directly on ImageNet, a NASNet constructed from the best cell achieves, among the published works, state-of-the-art accuracy of 82.7% top-1 and 96.2% top-5 on ImageNet. Our model is 1.2% better in top-1 accuracy than the best human-invented architectures while having 9 billion fewer FLOPS - a reduction of 28% in computational demand from the previous state-of-the-art model. When evaluated at different levels of computational cost, accuracies of NASNets exceed those of the state-of-the-art human-designed models. For instance, a small version of NASNet also achieves 74% top-1 accuracy, which is 3.1% better than equivalently-sized, state-of-the-art models for mobile platforms. Finally, the image features learned from image classification are generically useful and can be transferred to other computer vision problems. On the task of object detection, the learned features by NASNet used with the Faster-RCNN framework surpass state-of-the-art by 4.0% achieving 43.1% mAP on the COCO dataset."
            },
            "slug": "Learning-Transferable-Architectures-for-Scalable-Zoph-Vasudevan",
            "title": {
                "fragments": [],
                "text": "Learning Transferable Architectures for Scalable Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper proposes to search for an architectural building block on a small dataset and then transfer the block to a larger dataset and introduces a new regularization technique called ScheduledDropPath that significantly improves generalization in the NASNet models."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145083365"
                        ],
                        "name": "Sorav Bansal",
                        "slug": "Sorav-Bansal",
                        "structuredName": {
                            "firstName": "Sorav",
                            "lastName": "Bansal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sorav Bansal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653825"
                        ],
                        "name": "A. Aiken",
                        "slug": "A.-Aiken",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Aiken",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Aiken"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 35
                            }
                        ],
                        "text": "It is worth noting that prior work [7] reported false positives in using random testing to examine code transformations in compiler superoptimization."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 49
                            }
                        ],
                        "text": "We adopt an idea from compiler superoptimization [7] and compute a fingerprint for each graph, which is a hash of the graph outputs on some specific inputs."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 100
                            }
                        ],
                        "text": "In the compiler literature, significant effort has been devoted to formally verifying optimizations [7, 11, 13, 23, 29, 30, 33, 35]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 202
                            }
                        ],
                        "text": "TASO\u2019s approach to identifying potential substitutions via enumeration of graphs and fingerprinting is similar to work in automatically generating peephole optimizers using superoptimization techniques [7]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 990671,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "25a77652204ae3e524a1ca25cca7a44c72d37d6d",
            "isKey": false,
            "numCitedBy": 151,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Peephole optimizers are typically constructed using human-written pattern matching rules, an approach that requires expertise and time, as well as being less than systematic at exploiting all opportunities for optimization. We explore fully automatic construction of peephole optimizers using brute force superoptimization. While the optimizations discovered by our automatic system may be less general than human-written counterparts, our approach has the potential to automatically learn a database of thousands to millions of optimizations, in contrast to the hundreds found in current peephole optimizers. We show experimentally that our optimizer is able to exploit performance opportunities not found by existing compilers; in particular, we show speedups from 1.7 to a factor of 10 on some compute intensive kernels over a conventional optimizing compiler."
            },
            "slug": "Automatic-generation-of-peephole-superoptimizers-Bansal-Aiken",
            "title": {
                "fragments": [],
                "text": "Automatic generation of peephole superoptimizers"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown experimentally that the fully automatic construction of peephole optimizers using brute force superoptimization is able to exploit performance opportunities not found by existing compilers, and speedups from 1.7 to a factor of 10 on some compute intensive kernels over a conventional optimizing compiler are shown."
            },
            "venue": {
                "fragments": [],
                "text": "ASPLOS XII"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108314"
                        ],
                        "name": "Sumit Gulwani",
                        "slug": "Sumit-Gulwani",
                        "structuredName": {
                            "firstName": "Sumit",
                            "lastName": "Gulwani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sumit Gulwani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790411"
                        ],
                        "name": "G. Necula",
                        "slug": "G.-Necula",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Necula",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Necula"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 16
                            }
                        ],
                        "text": "As a reference, [17] shows that for programs with only linear operators, the probability that two nonequivalent programs produce identical output on a random input is at most 1 d , where d is the number of possible values for a variable (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15381034,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "1cfb4d6ae9f3617f14f91ae1d939dd9e0e47fb30",
            "isKey": false,
            "numCitedBy": 43,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new polynomial-time randomized algorithm for discovering affine equalities involving variables in a program. The key idea of the algorithm is to execute a code fragment on a few random inputs, but in such a way that all paths are covered on each run. This makes it possible to rule out invalid relationships even with very few runs.The algorithm is based on two main techniques. First, both branches of a conditional are executed on each run and at joint points we perform an affine combination of the joining states. Secondly, in the branches of an equality conditional we adjust the data values on the fly to reflect the truth value of the guarding boolean expression. This increases the number of affine equalities that the analysis discovers.The algorithm is simpler to implement than alternative deterministic versions, has better computational complexity, and has an extremely small probability of error for even a small number of runs. This algorithm is an example of how randomization can provide a trade-off between the cost and complexity of program analysis, and a small probability of unsoundness."
            },
            "slug": "Discovering-affine-equalities-using-random-Gulwani-Necula",
            "title": {
                "fragments": [],
                "text": "Discovering affine equalities using random interpretation"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "A new polynomial-time randomized algorithm for discovering affine equalities involving variables in a program that is simpler to implement than alternative deterministic versions, has better computational complexity, and has an extremely small probability of error for even a small number of runs."
            },
            "venue": {
                "fragments": [],
                "text": "POPL '03"
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072782550"
                        ],
                        "name": "Zhihao Jia",
                        "slug": "Zhihao-Jia",
                        "structuredName": {
                            "firstName": "Zhihao",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhihao Jia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3349220"
                        ],
                        "name": "Sina Lin",
                        "slug": "Sina-Lin",
                        "structuredName": {
                            "firstName": "Sina",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sina Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144329939"
                        ],
                        "name": "C. Qi",
                        "slug": "C.-Qi",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Qi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Qi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653825"
                        ],
                        "name": "A. Aiken",
                        "slug": "A.-Aiken",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Aiken",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Aiken"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 64548220,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f1c5dacd324d5d764432d7d331f1d0091ce35ddb",
            "isKey": false,
            "numCitedBy": 10,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Exploring-the-Hidden-Dimension-in-Accelerating-Jia-Lin",
            "title": {
                "fragments": [],
                "text": "Exploring the Hidden Dimension in Accelerating Convolutional Neural Networks"
            },
            "venue": {
                "fragments": [],
                "text": "ICML 2018"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143914877"
                        ],
                        "name": "Vu Le",
                        "slug": "Vu-Le",
                        "structuredName": {
                            "firstName": "Vu",
                            "lastName": "Le",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vu Le"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "36889034"
                        ],
                        "name": "M. Afshari",
                        "slug": "M.-Afshari",
                        "structuredName": {
                            "firstName": "Mehrdad",
                            "lastName": "Afshari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Afshari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38319925"
                        ],
                        "name": "Z. Su",
                        "slug": "Z.-Su",
                        "structuredName": {
                            "firstName": "Zhendong",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Su"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 100
                            }
                        ],
                        "text": "In the compiler literature, significant effort has been devoted to formally verifying optimizations [7, 11, 13, 23, 29, 30, 33, 35]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3027731,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "79bbd54d5bdfd20980e5f9a65480f5e127fc1221",
            "isKey": false,
            "numCitedBy": 274,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce equivalence modulo inputs (EMI), a simple, widely applicable methodology for validating optimizing compilers. Our key insight is to exploit the close interplay between (1) dynamically executing a program on some test inputs and (2) statically compiling the program to work on all possible inputs. Indeed, the test inputs induce a natural collection of the original program's EMI variants, which can help differentially test any compiler and specifically target the difficult-to-find miscompilations. To create a practical implementation of EMI for validating C compilers, we profile a program's test executions and stochastically prune its unexecuted code. Our extensive testing in eleven months has led to 147 confirmed, unique bug reports for GCC and LLVM alone. The majority of those bugs are miscompilations, and more than 100 have already been fixed. Beyond testing compilers, EMI can be adapted to validate program transformation and analysis systems in general. This work opens up this exciting, new direction."
            },
            "slug": "Compiler-validation-via-equivalence-modulo-inputs-Le-Afshari",
            "title": {
                "fragments": [],
                "text": "Compiler validation via equivalence modulo inputs"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This work introduces equivalence modulo inputs (EMI), a simple, widely applicable methodology for validating optimizing compilers, and profiles a program's test executions and stochastically prune its unexecuted code to create a practical implementation."
            },
            "venue": {
                "fragments": [],
                "text": "PLDI 2014"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790411"
                        ],
                        "name": "G. Necula",
                        "slug": "G.-Necula",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Necula",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Necula"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 100
                            }
                        ],
                        "text": "In the compiler literature, significant effort has been devoted to formally verifying optimizations [7, 11, 13, 23, 29, 30, 33, 35]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2448939,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "011f7da0095ac8c0d4477eeda2728e5f80a35767",
            "isKey": false,
            "numCitedBy": 486,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a translation validation infrastructure for the GNU C compiler. During the compilation the infrastructure compares the intermediate form of the program before and after each compiler pass and verifies the preservation of semantics. We discuss a general framework that the optimizer can use to communicate to the validator what transformations were performed. Our implementation however does not rely on help from the optimizer and it is quite successful by using instead a few heuristics to detect the transformations that take place.\nThe main message of this paper is that a practical translation validation infrastructure, able to check the correctness of many of the transformations performed by a realistic compiler, can be implemented with about the effort typically required to implement one compiler pass. We demonstrate this in the context of the GNU C compiler for a number of its optimizations while compiling realistic programs such as the compiler itself or the Linux kernel. We believe that the price of such an infrastructure is small considering the qualitative increase in the ability to isolate compilation errors during compiler testing and maintenance."
            },
            "slug": "Translation-validation-for-an-optimizing-compiler-Necula",
            "title": {
                "fragments": [],
                "text": "Translation validation for an optimizing compiler"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "A practical translation validation infrastructure, able to check the correctness of many of the transformations performed by a realistic compiler, can be implemented with about the effort typically required to implement one compiler pass."
            },
            "venue": {
                "fragments": [],
                "text": "PLDI '00"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2445900"
                        ],
                        "name": "Berkeley R. Churchill",
                        "slug": "Berkeley-R.-Churchill",
                        "structuredName": {
                            "firstName": "Berkeley",
                            "lastName": "Churchill",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Berkeley R. Churchill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2381030"
                        ],
                        "name": "Oded Padon",
                        "slug": "Oded-Padon",
                        "structuredName": {
                            "firstName": "Oded",
                            "lastName": "Padon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oded Padon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111333766"
                        ],
                        "name": "Rahul Sharma",
                        "slug": "Rahul-Sharma",
                        "structuredName": {
                            "firstName": "Rahul",
                            "lastName": "Sharma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rahul Sharma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653825"
                        ],
                        "name": "A. Aiken",
                        "slug": "A.-Aiken",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Aiken",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Aiken"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 100
                            }
                        ],
                        "text": "In the compiler literature, significant effort has been devoted to formally verifying optimizations [7, 11, 13, 23, 29, 30, 33, 35]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 121159330,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fc6e36c9df6521aa805bc622d066e2964d2e471d",
            "isKey": false,
            "numCitedBy": 44,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a robust semantics-driven technique for program equivalence checking. Given two functions we find a trace alignment over a set of concrete executions of both programs and construct a product program particularly amenable to checking equivalence. We demonstrate that our algorithm is applicable to challenging equivalence problems beyond the scope of existing techniques. For example, we verify the correctness of the hand-optimized vector implementation of strlen that ships as part of the GNU C Library, as well as the correctness of vectorization optimizations for 56 benchmarks derived from the Test Suite for Vectorizing Compilers."
            },
            "slug": "Semantic-program-alignment-for-equivalence-checking-Churchill-Padon",
            "title": {
                "fragments": [],
                "text": "Semantic program alignment for equivalence checking"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "A robust semantics-driven technique for program equivalence checking is introduced and it is demonstrated that the algorithm is applicable to challenging equivalence problems beyond the scope of existing techniques."
            },
            "venue": {
                "fragments": [],
                "text": "PLDI"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3074927"
                        ],
                        "name": "Vincent Dumoulin",
                        "slug": "Vincent-Dumoulin",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Dumoulin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Dumoulin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2077146"
                        ],
                        "name": "Francesco Visin",
                        "slug": "Francesco-Visin",
                        "structuredName": {
                            "firstName": "Francesco",
                            "lastName": "Visin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Francesco Visin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 198,
                                "start": 194
                            }
                        ],
                        "text": "The maintenance problem is aggravated by the fact that new operators are continuously introduced; for example, recent work has proposed depthwise [19], grouped [38], and transposed convolutions [16] for different image classification tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6662846,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f19284f6ab802c8a1fcde076fcb3fba195a71723",
            "isKey": false,
            "numCitedBy": 1083,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a guide to help deep learning practitioners understand and manipulate convolutional neural network architectures. The guide clarifies the relationship between various properties (input shape, kernel shape, zero padding, strides and output shape) of convolutional, pooling and transposed convolutional layers, as well as the relationship between convolutional and transposed convolutional layers. Relationships are derived for various cases, and are illustrated in order to make them intuitive."
            },
            "slug": "A-guide-to-convolution-arithmetic-for-deep-learning-Dumoulin-Visin",
            "title": {
                "fragments": [],
                "text": "A guide to convolution arithmetic for deep learning"
            },
            "tldr": {
                "abstractSimilarityScore": 80,
                "text": "A guide to help deep learning practitioners understand and manipulate convolutional neural network architectures and clarifies the relationship between various properties of Convolutional, pooling and transposedconvolutional layers."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113938930"
                        ],
                        "name": "B. Steffen",
                        "slug": "B.-Steffen",
                        "structuredName": {
                            "firstName": "Bernhard",
                            "lastName": "Steffen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Steffen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 33423279,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9d03ef15547375713c8b57524435656296a3ef5",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Formal verification of pipelined processors.- Fully local and efficient evaluation of alternating fixed points.- Modular model checking of software.- Verification based on local states.- Exploiting symmetry in linear time temporal logic model checking: One step beyond.- OPEN/CAeSAR: An open software architecture for verification, simulation, and testing.- Practical model-checking using games.- Combining finite automata, parallel programs and SDL using Petri nets.- Mesa: Support for scenario-based design of concurrent systems.- Efficient modeling of memory arrays in symbolic ternary simulation.- Translation validation.- A verified model checker for the modal ?-calculus in Coq.- Detecting races in relay ladder logic programs.- Verification of large state/event systems using compositionality and dependency analysis.- Tamagotchis need not die - Verification of statemate designs.- Modeling and verification of sC++ applications.- Factotum: Automatic and systematic sharing support for systems analyzers.- Model checking via reachability testing for timed automata.- Formal design and analysis of a gear controller.- Verifying networks of timed processes.- Model checking of real-time reachability properties using abstractions.- Symbolic exploration of transition hierarchies.- Static partial order reduction.- Set-based analysis of reactive infinite-state systems.- Deciding fixed and non-fixed size bit-vectors.- Experience with literate programming in the modelling and validation of systems.- A proof of burns N-process mutual exclusion algorithm using abstraction.- Automated verification of Szymanski's algorithm.- Formal verification of SDL systems at the siemens mobile phone department."
            },
            "slug": "Tools-and-Algorithms-for-the-Construction-and-of-Steffen",
            "title": {
                "fragments": [],
                "text": "Tools and Algorithms for the Construction and Analysis of Systems"
            },
            "tldr": {
                "abstractSimilarityScore": 54,
                "text": "This work presents formal verification of pipelined processors, a proof of burns N-process mutual exclusion algorithm using abstraction, and automated verification of Szymanski's algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "Lecture Notes in Computer Science"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1698938"
                        ],
                        "name": "A. Pnueli",
                        "slug": "A.-Pnueli",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Pnueli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Pnueli"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "119614910"
                        ],
                        "name": "M. Siegel",
                        "slug": "M.-Siegel",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Siegel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Siegel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1774977"
                        ],
                        "name": "Eli Singerman",
                        "slug": "Eli-Singerman",
                        "structuredName": {
                            "firstName": "Eli",
                            "lastName": "Singerman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eli Singerman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14822655,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d8b4164fef65ffc7082a3c95b0a706e5c3aa38f9",
            "isKey": false,
            "numCitedBy": 515,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We present the notion of translation validation as a new approach to the veriication of translators (compilers, code generators). Rather than proving in advance that the compiler always produces a target code which correctly implements the source code (compiler verii-cation), each individual translation (i.e. a run of the compiler) is followed by a validation phase which veriies that the target code produced on this run correctly implements the submitted source program. Several ingredients are necessary to set up the { fully automatic { translation validation process, among which are: 1. A common semantic framework for the representation of the source code and the generated target code. 2. A formalization of the notion of \"correct implementation\" as a re-nement relation. 3. A syntactic simulation-based proof method which allows to automatically verify that one model of the semantic framework, representing the produced target code, correctly implements another model which represents the source. These, and other ingredients are elaborated in this paper, in which we illustrate the new approach in a most challenging case. We consider a translation (compilation) from the synchronous multi-clock data-ow language Signal to asynchronous (sequential) C-code."
            },
            "slug": "Translation-Validation-Pnueli-Siegel",
            "title": {
                "fragments": [],
                "text": "Translation Validation"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper considers a translation (compilation) from the synchronous multi-clock data-ow language Signal to asynchronous (sequential) C-code and presents the notion of translation validation as a new approach to the veriication of translators (compilers, code generators)."
            },
            "venue": {
                "fragments": [],
                "text": "TACAS"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1597383891"
                        ],
                        "name": "Manjeet Dahiya",
                        "slug": "Manjeet-Dahiya",
                        "structuredName": {
                            "firstName": "Manjeet",
                            "lastName": "Dahiya",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manjeet Dahiya"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145083365"
                        ],
                        "name": "Sorav Bansal",
                        "slug": "Sorav-Bansal",
                        "structuredName": {
                            "firstName": "Sorav",
                            "lastName": "Bansal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sorav Bansal"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 100
                            }
                        ],
                        "text": "In the compiler literature, significant effort has been devoted to formally verifying optimizations [7, 11, 13, 23, 29, 30, 33, 35]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 28654424,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5da199a2b340da3bec5aced418d7e52ccabda182",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Equivalence checking is an important building block for program synthesis and verification. For a synthesis tool to compete with modern compilers, its equivalence checker should be able to verify the transformations produced by these compilers. We find that the transformations produced by compilers are much varied and the presence of undefined behaviour allows them to produce even more aggressive optimizations. Previous work on equivalence checking has been done in the context of translation validation, where either a pass-by-pass based approach was employed or a set of handpicked optimizations were proven. These settings are not suitable for a synthesis tool where a black-box approach is required."
            },
            "slug": "Black-Box-Equivalence-Checking-Across-Compiler-Dahiya-Bansal",
            "title": {
                "fragments": [],
                "text": "Black-Box Equivalence Checking Across Compiler Optimizations"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is found that the transformations produced by compilers are much varied and the presence of undefined behaviour allows them to produce even more aggressive optimizations."
            },
            "venue": {
                "fragments": [],
                "text": "APLAS"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144727050"
                        ],
                        "name": "Andrew G. Howard",
                        "slug": "Andrew-G.-Howard",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Howard",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew G. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2717876"
                        ],
                        "name": "Menglong Zhu",
                        "slug": "Menglong-Zhu",
                        "structuredName": {
                            "firstName": "Menglong",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Menglong Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Bo Chen",
                        "slug": "Bo-Chen",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741985"
                        ],
                        "name": "Dmitry Kalenichenko",
                        "slug": "Dmitry-Kalenichenko",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Kalenichenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dmitry Kalenichenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108301072"
                        ],
                        "name": "Weijun Wang",
                        "slug": "Weijun-Wang",
                        "structuredName": {
                            "firstName": "Weijun",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weijun Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47447630"
                        ],
                        "name": "Tobias Weyand",
                        "slug": "Tobias-Weyand",
                        "structuredName": {
                            "firstName": "Tobias",
                            "lastName": "Weyand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tobias Weyand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2612392"
                        ],
                        "name": "M. Andreetto",
                        "slug": "M.-Andreetto",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Andreetto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Andreetto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2595180"
                        ],
                        "name": "Hartwig Adam",
                        "slug": "Hartwig-Adam",
                        "structuredName": {
                            "firstName": "Hartwig",
                            "lastName": "Adam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hartwig Adam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 146
                            }
                        ],
                        "text": "The maintenance problem is aggravated by the fact that new operators are continuously introduced; for example, recent work has proposed depthwise [19], grouped [38], and transposed convolutions [16] for different image classification tasks."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12670695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3647d6d0f151dc05626449ee09cc7bce55be497e",
            "isKey": false,
            "numCitedBy": 10323,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization."
            },
            "slug": "MobileNets:-Efficient-Convolutional-Neural-Networks-Howard-Zhu",
            "title": {
                "fragments": [],
                "text": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work introduces two simple global hyper-parameters that efficiently trade off between latency and accuracy and demonstrates the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144996001"
                        ],
                        "name": "L. D. Moura",
                        "slug": "L.-D.-Moura",
                        "structuredName": {
                            "firstName": "Leonardo",
                            "lastName": "Moura",
                            "middleNames": [
                                "Mendon\u00e7a",
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. D. Moura"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3714351"
                        ],
                        "name": "N. Bj\u00f8rner",
                        "slug": "N.-Bj\u00f8rner",
                        "structuredName": {
                            "firstName": "Nikolaj",
                            "lastName": "Bj\u00f8rner",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Bj\u00f8rner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15912959,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3960dda299e0f8615a7db675b8e6905b375ecf8a",
            "isKey": false,
            "numCitedBy": 6280,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Satisfiability Modulo Theories (SMT) problem is a decision problem for logical first order formulas with respect to combinations of background theories such as: arithmetic, bit-vectors, arrays, and uninterpreted functions. Z3 is a new and efficient SMT Solver freely available from Microsoft Research. It is used in various software verification and analysis applications."
            },
            "slug": "Z3:-An-Efficient-SMT-Solver-Moura-Bj\u00f8rner",
            "title": {
                "fragments": [],
                "text": "Z3: An Efficient SMT Solver"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "Z3 is a new and efficient SMT Solver freely available from Microsoft Research that is used in various software verification and analysis applications."
            },
            "venue": {
                "fragments": [],
                "text": "TACAS"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2073603971"
                        ],
                        "name": "Vinod Nair",
                        "slug": "Vinod-Nair",
                        "structuredName": {
                            "firstName": "Vinod",
                            "lastName": "Nair",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vinod Nair"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "The relu operator [28], which is commonly used in DNN applications, returns 0 for all negative inputs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 29
                            }
                        ],
                        "text": ", applying the relu function [28] as part of convolution); and the parameters of split or concatenation determine the axis along which to apply the operator."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15539264,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a538b05ebb01a40323997629e171c91aa28b8e2f",
            "isKey": false,
            "numCitedBy": 12985,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Restricted Boltzmann machines were developed using binary stochastic hidden units. These can be generalized by replacing each binary unit by an infinite number of copies that all have the same weights but have progressively more negative biases. The learning and inference rules for these \"Stepped Sigmoid Units\" are unchanged. They can be approximated efficiently by noisy, rectified linear units. Compared with binary units, these units learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset. Unlike binary units, rectified linear units preserve information about relative intensities as information travels through multiple layers of feature detectors."
            },
            "slug": "Rectified-Linear-Units-Improve-Restricted-Boltzmann-Nair-Hinton",
            "title": {
                "fragments": [],
                "text": "Rectified Linear Units Improve Restricted Boltzmann Machines"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "Restricted Boltzmann machines were developed using binary stochastic hidden units that learn features that are better for object recognition on the NORB dataset and face verification on the Labeled Faces in the Wild dataset."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111333766"
                        ],
                        "name": "Rahul Sharma",
                        "slug": "Rahul-Sharma",
                        "structuredName": {
                            "firstName": "Rahul",
                            "lastName": "Sharma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rahul Sharma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1945094"
                        ],
                        "name": "Eric Schkufza",
                        "slug": "Eric-Schkufza",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Schkufza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric Schkufza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2445900"
                        ],
                        "name": "Berkeley R. Churchill",
                        "slug": "Berkeley-R.-Churchill",
                        "structuredName": {
                            "firstName": "Berkeley",
                            "lastName": "Churchill",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Berkeley R. Churchill"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144653825"
                        ],
                        "name": "A. Aiken",
                        "slug": "A.-Aiken",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Aiken",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Aiken"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 100
                            }
                        ],
                        "text": "In the compiler literature, significant effort has been devoted to formally verifying optimizations [7, 11, 13, 23, 29, 30, 33, 35]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 995430,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1e52a2e8535509ab0111c0c5d89a88d3bb10b34c",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a data driven algorithm for equivalence checking of two loops. The algorithm infers simulation relations using data from test runs. Once a candidate simulation relation has been obtained, off-the-shelf SMT solvers are used to check whether the simulation relation actually holds. The algorithm is sound: insufficient data will cause the proof to fail. We demonstrate a prototype implementation, called DDEC, of our algorithm, which is the first sound equivalence checker for loops written in x86 assembly."
            },
            "slug": "Data-driven-equivalence-checking-Sharma-Schkufza",
            "title": {
                "fragments": [],
                "text": "Data-driven equivalence checking"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "A data driven algorithm for equivalence checking of two loops, which is the first sound equivalence checker for loops written in x86 assembly and demonstrates a prototype implementation of the algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "OOPSLA 2013"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2192178"
                        ],
                        "name": "Olga Russakovsky",
                        "slug": "Olga-Russakovsky",
                        "structuredName": {
                            "firstName": "Olga",
                            "lastName": "Russakovsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Olga Russakovsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153302678"
                        ],
                        "name": "Jia Deng",
                        "slug": "Jia-Deng",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144914140"
                        ],
                        "name": "Hao Su",
                        "slug": "Hao-Su",
                        "structuredName": {
                            "firstName": "Hao",
                            "lastName": "Su",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hao Su"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2285165"
                        ],
                        "name": "J. Krause",
                        "slug": "J.-Krause",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Krause",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Krause"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145031342"
                        ],
                        "name": "S. Satheesh",
                        "slug": "S.-Satheesh",
                        "structuredName": {
                            "firstName": "Sanjeev",
                            "lastName": "Satheesh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Satheesh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145423516"
                        ],
                        "name": "S. Ma",
                        "slug": "S.-Ma",
                        "structuredName": {
                            "firstName": "Sean",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3109481"
                        ],
                        "name": "Zhiheng Huang",
                        "slug": "Zhiheng-Huang",
                        "structuredName": {
                            "firstName": "Zhiheng",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhiheng Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2354728"
                        ],
                        "name": "A. Karpathy",
                        "slug": "A.-Karpathy",
                        "structuredName": {
                            "firstName": "Andrej",
                            "lastName": "Karpathy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Karpathy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2556428"
                        ],
                        "name": "A. Khosla",
                        "slug": "A.-Khosla",
                        "structuredName": {
                            "firstName": "Aditya",
                            "lastName": "Khosla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Khosla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145879842"
                        ],
                        "name": "Michael S. Bernstein",
                        "slug": "Michael-S.-Bernstein",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Bernstein",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael S. Bernstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39668247"
                        ],
                        "name": "A. Berg",
                        "slug": "A.-Berg",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Berg",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Berg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2930547,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e74f9b7f8eec6ba4704c206b93bc8079af3da4bd",
            "isKey": false,
            "numCitedBy": 25826,
            "numCiting": 138,
            "paperAbstract": {
                "fragments": [],
                "text": "The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the 5\u00a0years of the challenge, and propose future directions and improvements."
            },
            "slug": "ImageNet-Large-Scale-Visual-Recognition-Challenge-Russakovsky-Deng",
            "title": {
                "fragments": [],
                "text": "ImageNet Large Scale Visual Recognition Challenge"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The creation of this benchmark dataset and the advances in object recognition that have been possible as a result are described, and the state-of-the-art computer vision accuracy with human accuracy is compared."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 247,
                                "start": 244
                            }
                        ],
                        "text": "TASO Cost Function \u2022 TASO improves the cost function to include data layout \u2022 Cost(Operator, Layout) measured on-device \u2022 Data Layout = Column-Major or Row-Major \u2022 Consider each permutation of data layouts \u2022 Cost(G) = \u2211Cost(oi, li) Fig 12 from [1]"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 246,
                                "start": 243
                            }
                        ],
                        "text": "TASO Cost Function \u2022 TASO improves the cost function to include data layout \u2022 Cost(Operator, Layout) measured on-device \u2022 Data Layout = Column-Major or Row-Major \u2022 Consider each permutation of data layouts \u2022 Cost(G) = \u2211Cost(oi, li) Fig 5 from [1]"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 42
                            }
                        ],
                        "text": "05 chosen for evaluation Algorithm 1 from [1], based on [2]"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "TASO: Optimizing Deep Learning Computation with Automatic Generation of Graph Substitutions"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 27th ACM Symposium on Operating Systems Principles. SOSP \u201919"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152486626"
                        ],
                        "name": "R. Larsen",
                        "slug": "R.-Larsen",
                        "structuredName": {
                            "firstName": "Rasmus",
                            "lastName": "Larsen",
                            "middleNames": [
                                "Munk"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Larsen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1774432"
                        ],
                        "name": "T. Shpeisman",
                        "slug": "T.-Shpeisman",
                        "structuredName": {
                            "firstName": "Tatiana",
                            "lastName": "Shpeisman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Shpeisman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 165108961,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e37b58bb5c056fa972a0a502d46b5abcfd7da5e1",
            "isKey": false,
            "numCitedBy": 18,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "TensorFlow-Graph-Optimizations-Larsen-Shpeisman",
            "title": {
                "fragments": [],
                "text": "TensorFlow Graph Optimizations"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2019
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tensor Cores in NVIDIA Volta Architecture"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2018
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "NVIDIA TensorRT: Programmable Inference Accelerator"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Dense Linear Algebra on GPUs"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tensorflow graph transform creates corrupted graph"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "XLA: Optimizing Compiler for TensorFlow"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 9
                            }
                        ],
                        "text": "FlexFlow [20, 22] introduces a comprehensive search space of parallelization strategies for DNN training, and uses a randomized search algorithm to find efficient strategies in the search space."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Exploring Hidden Dimensions in Accelerating Convolutional Neural Networks"
            },
            "venue": {
                "fragments": [],
                "text": "In Proceedings of the 35th International Conference on Machine Learning (Proceedings of Machine Learning Research),"
            },
            "year": 2018
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Graph transform: fold constant with invalid graph"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2018
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 100
                            }
                        ],
                        "text": "In the compiler literature, significant effort has been devoted to formally verifying optimizations [7, 11, 13, 23, 29, 30, 33, 35]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Equality Saturation: ANewApproach toOptimization"
            },
            "venue": {
                "fragments": [],
                "text": "LogicalMethods in Computer Science 7,"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Tensors and Dynamic neural networks in Python with strong GPU acceleration"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2017
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 19,
            "methodology": 17,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 41,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/TASO%3A-optimizing-deep-learning-computation-with-of-Jia-Padon/80b362efee95c1759c6dab9219eb77ca3ee44475"
}