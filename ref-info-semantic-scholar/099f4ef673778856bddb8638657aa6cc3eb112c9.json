{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2119044211"
                        ],
                        "name": "Kuan Wang",
                        "slug": "Kuan-Wang",
                        "structuredName": {
                            "firstName": "Kuan",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kuan Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47781592"
                        ],
                        "name": "Zhijian Liu",
                        "slug": "Zhijian-Liu",
                        "structuredName": {
                            "firstName": "Zhijian",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhijian Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49417466"
                        ],
                        "name": "Yujun Lin",
                        "slug": "Yujun-Lin",
                        "structuredName": {
                            "firstName": "Yujun",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yujun Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46698300"
                        ],
                        "name": "Ji Lin",
                        "slug": "Ji-Lin",
                        "structuredName": {
                            "firstName": "Ji",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ji Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143840275"
                        ],
                        "name": "Song Han",
                        "slug": "Song-Han",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Han"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 147
                            }
                        ],
                        "text": "It is also worth to mention as non-uniform quantizers have resulted as the best approximators when reducing the bit precision (Zhang et al., 2018; Wang et al., 2018; Han et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 30
                            }
                        ],
                        "text": "Both (Dong et al., 2019) and (Wang et al., 2018) reports superior accuracy than ours when compressing networks to a 1MB of memory footprint, but they rely on a non-uniform clustering quantization of floating-point parameters, therefore not fully-comparable with our work in terms of microcontroller\u2026"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 65
                            }
                        ],
                        "text": "Our best models feature up to 7% lower accuracy with respect to (Wang et al., 2018), but, in contrast with this and similar works, we remark that we only use integer operations also\nthanks to the exploited uniform quantization."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 28
                            }
                        ],
                        "text": "On the same direction, HAQ (Wang et al., 2018) dynamically explores multiple low-bitwidth precision at training time by means of reinforcement learning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 102350477,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "54c4642d017830e1faddbb49f0377228d2b01493",
            "isKey": true,
            "numCitedBy": 394,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Model quantization is a widely used technique to compress and accelerate deep neural network (DNN) inference. Emergent DNN hardware accelerators begin to support mixed precision (1-8 bits) to further improve the computation efficiency, which raises a great challenge to find the optimal bitwidth for each layer: it requires domain experts to explore the vast design space trading off among accuracy, latency, energy, and model size, which is both time-consuming and sub-optimal. There are plenty of specialized hardware for neural networks, but little research has been done for specialized neural network optimization for a particular hardware architecture. Conventional quantization algorithm ignores the different hardware architectures and quantizes all the layers in a uniform way. In this paper, we introduce the Hardware-Aware Automated Quantization (HAQ) framework which leverages the reinforcement learning to automatically determine the quantization policy, and we take the hardware accelerator's feedback in the design loop. Rather than relying on proxy signals such as FLOPs and model size, we employ a hardware simulator to generate direct feedback signals (latency and energy) to the RL agent. Compared with conventional methods, our framework is fully automated and can specialize the quantization policy for different neural network architectures and hardware architectures. Our framework effectively reduced the latency by 1.4-1.95x and the energy consumption by 1.9x with negligible loss of accuracy compared with the fixed bitwidth (8 bits) quantization. Our framework reveals that the optimal policies on different hardware architectures (i.e., edge and cloud architectures) under different resource constraints (i.e., latency, energy and model size) are drastically different. We interpreted the implication of different quantization policies, which offer insights for both neural network architecture design and hardware architecture design."
            },
            "slug": "HAQ:-Hardware-Aware-Automated-Quantization-With-Wang-Liu",
            "title": {
                "fragments": [],
                "text": "HAQ: Hardware-Aware Automated Quantization With Mixed Precision"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "The Hardware-Aware Automated Quantization (HAQ) framework is introduced which leverages the reinforcement learning to automatically determine the quantization policy, and takes the hardware accelerator's feedback in the design loop to generate direct feedback signals to the RL agent."
            },
            "venue": {
                "fragments": [],
                "text": "2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3468810"
                        ],
                        "name": "Yoni Choukroun",
                        "slug": "Yoni-Choukroun",
                        "structuredName": {
                            "firstName": "Yoni",
                            "lastName": "Choukroun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoni Choukroun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71729077"
                        ],
                        "name": "Eli Kravchik",
                        "slug": "Eli-Kravchik",
                        "structuredName": {
                            "firstName": "Eli",
                            "lastName": "Kravchik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eli Kravchik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771779"
                        ],
                        "name": "P. Kisilev",
                        "slug": "P.-Kisilev",
                        "structuredName": {
                            "firstName": "Pavel",
                            "lastName": "Kisilev",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Kisilev"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 41
                            }
                        ],
                        "text": "less than 8 bit, are under investigation (Choukroun et al., 2019; Jain et al., 2019; Esser et al., 2019; Krishnamoorthi, 2018; Liu & Mattina, 2019)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 177,
                                "start": 155
                            }
                        ],
                        "text": "Recently, to fit stringent memory requirements, more aggressive sub-byte precision quantization approaches, i.e. less than 8 bit, are under investigation (Choukroun et al., 2019; Jain et al., 2019; Esser et al., 2019; Krishnamoorthi, 2018; Liu & Mattina, 2019)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 67750088,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47a1edfb88f5b4a7ba1e9f6aed327f67f942f6d6",
            "isKey": false,
            "numCitedBy": 126,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent machine learning methods use increasingly large deep neural networks to achieve state of the art results in various tasks. The gains in performance come at the cost of a substantial increase in computation and storage requirements. This makes real-time implementations on limited resources hardware a challenging task. One popular approach to address this challenge is to perform low-bit precision computations via neural network quantization. However, aggressive quantization generally entails a severe penalty in terms of accuracy, and often requires retraining of the network, or resorting to higher bit precision quantization. In this paper, we formalize the linear quantization task as a Minimum Mean Squared Error (MMSE) problem for both weights and activations, allowing low-bit precision inference without the need for full network retraining. We propose the analysis and the optimization of constrained MSE problems for performant hardware aware quantization. The proposed approach allows 4 bits integer (INT4) quantization for deployment of pretrained models on limited hardware resources. Multiple experiments on various network architectures show that the suggested method yields state of the art results with minimal loss of tasks accuracy."
            },
            "slug": "Low-bit-Quantization-of-Neural-Networks-for-Choukroun-Kravchik",
            "title": {
                "fragments": [],
                "text": "Low-bit Quantization of Neural Networks for Efficient Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper formalizes the linear quantization task as a Minimum Mean Squared Error (MMSE) problem for both weights and activations, allowing low-bit precision inference without the need for full network retraining."
            },
            "venue": {
                "fragments": [],
                "text": "2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2119045079"
                        ],
                        "name": "Kuan Wang",
                        "slug": "Kuan-Wang",
                        "structuredName": {
                            "firstName": "Kuan",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kuan Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47781592"
                        ],
                        "name": "Zhijian Liu",
                        "slug": "Zhijian-Liu",
                        "structuredName": {
                            "firstName": "Zhijian",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhijian Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49417466"
                        ],
                        "name": "Yujun Lin",
                        "slug": "Yujun-Lin",
                        "structuredName": {
                            "firstName": "Yujun",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yujun Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46698300"
                        ],
                        "name": "Ji Lin",
                        "slug": "Ji-Lin",
                        "structuredName": {
                            "firstName": "Ji",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ji Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143840275"
                        ],
                        "name": "Song Han",
                        "slug": "Song-Han",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Han"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 164,
                                "start": 147
                            }
                        ],
                        "text": "It is also worth to mention as non-uniform quantizers have resulted as the best approximators when reducing the bit precision (Zhang et al., 2018; Wang et al., 2018; Han et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "On the same direction, HAQ [22] dynamically explores multiple low-bitwidth precision at training time by means of reinforcement learning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 30
                            }
                        ],
                        "text": "Both (Dong et al., 2019) and (Wang et al., 2018) reports superior accuracy than ours when compressing networks to a 1MB of memory footprint, but they rely on a non-uniform clustering quantization of floating-point parameters, therefore not fully-comparable with our work in terms of microcontroller\u2026"
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "It is also worth to mention as non-uniform quantizers have resulted as the best approximators when reducing the bit precision [24, 22, 9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 28
                            }
                        ],
                        "text": "On the same direction, HAQ (Wang et al., 2018) dynamically explores multiple low-bitwidth precision at training time by means of reinforcement learning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "MobilenetV1 [22] MIX not-uniform 57."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Both [5] and [22] reports superior accuracy than ours when compressing networks to a 1MB of memory footprint, but they include non-uniform clustering quantization of floating-point parameters, therefore not fully-comparable with our work in terms of microcontroller readiness, as current MCUs are not equipped with the hardware needed for manipulation and computation on these data formats."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "58 MB MobileNetV2 [22] MIX not-uniform 66."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Our best models feature up to 7% lower accuracy with respect to [22], but we remark the integer-only nature of our solution."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 65
                            }
                        ],
                        "text": "Our best models feature up to 7% lower accuracy with respect to (Wang et al., 2018), but, in contrast with this and similar works, we remark that we only use integer operations also\nthanks to the exploited uniform quantization."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 53746082,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df71a17df5350b0dbf8e5e084ae56a65cee9aaf8",
            "isKey": true,
            "numCitedBy": 73,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "Model quantization is a widely used technique to compress and accelerate deep neural network (DNN) inference. Emergent DNN hardware accelerators begin to support flexible bitwidth (1-8 bits) to further improve the computation efficiency, which raises a great challenge to find the optimal bitwidth for each layer: it requires domain experts to explore the vast design space trading off among accuracy, latency, energy, and model size, which is both time-consuming and sub-optimal. Conventional quantization algorithm ignores the different hardware architectures and quantizes all the layers in a uniform way. In this paper, we introduce the Hardware-Aware Automated Quantization (HAQ) framework which leverages the reinforcement learning to automatically determine the quantization policy, and we take the hardware accelerator's feedback in the design loop. Rather than relying on proxy signals such as FLOPs and model size, we employ a hardware simulator to generate direct feedback signals to the RL agent. Compared with conventional methods, our framework is fully automated and can specialize the quantization policy for different neural network architectures and hardware architectures. Our framework effectively reduced the latency by 1.4-1.95x and the energy consumption by 1.9x with negligible loss of accuracy compared with the fixed bitwidth (8 bits) quantization. Our framework reveals that the optimal policies on different hardware architectures (i.e., edge and cloud architectures) under different resource constraints (i.e., latency, energy and model size) are drastically different. We interpreted the implication of different quantization policies, which offer insights for both neural network architecture design and hardware architecture design."
            },
            "slug": "HAQ:-Hardware-Aware-Automated-Quantization-Wang-Liu",
            "title": {
                "fragments": [],
                "text": "HAQ: Hardware-Aware Automated Quantization"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper introduces the Hardware-Aware Automated Quantization (HAQ) framework, which leverages the reinforcement learning to automatically determine the quantization policy, and takes the hardware accelerator's feedback in the design loop to reduce the latency and energy consumption."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "11543879"
                        ],
                        "name": "Benoit Jacob",
                        "slug": "Benoit-Jacob",
                        "structuredName": {
                            "firstName": "Benoit",
                            "lastName": "Jacob",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Benoit Jacob"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "68988581"
                        ],
                        "name": "S. Kligys",
                        "slug": "S.-Kligys",
                        "structuredName": {
                            "firstName": "Skirmantas",
                            "lastName": "Kligys",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Kligys"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Bo Chen",
                        "slug": "Bo-Chen",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2717876"
                        ],
                        "name": "Menglong Zhu",
                        "slug": "Menglong-Zhu",
                        "structuredName": {
                            "firstName": "Menglong",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Menglong Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2113728429"
                        ],
                        "name": "Matthew Tang",
                        "slug": "Matthew-Tang",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Tang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew Tang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144727050"
                        ],
                        "name": "Andrew G. Howard",
                        "slug": "Andrew-G.-Howard",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Howard",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew G. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2595180"
                        ],
                        "name": "Hartwig Adam",
                        "slug": "Hartwig-Adam",
                        "structuredName": {
                            "firstName": "Hartwig",
                            "lastName": "Adam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hartwig Adam"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741985"
                        ],
                        "name": "Dmitry Kalenichenko",
                        "slug": "Dmitry-Kalenichenko",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Kalenichenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dmitry Kalenichenko"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 161,
                                "start": 143
                            }
                        ],
                        "text": "A quantizationaware retraining of a fake-quantized model is essential to recover accuracy, especially when low-bitwidth precision is employed (Jacob et al., 2018)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 12
                            }
                        ],
                        "text": "As done by (Jacob et al., 2018), each element mi of M can be decomposed as mi = m0i \u00b7 2n0i , where m0i is a signed fractionary fixed-point number with 0.5 \u2264 abs(m0i)   1.0."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 15
                            }
                        ],
                        "text": "Previous work (Jacob et al., 2018) discussed the training and integer-only deployment of a fake-quantized network with 8 bit per-layer quantization."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Our methodology demonstrates an integer-only deployment of a MobilenetV1 network on a STM32H7 microcontroller with 68% Top1 accuracy, which is 8% higher than previous reported 8 bit integer-only implementations [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 45
                            }
                        ],
                        "text": "In contrast, the integer-only deployment in (Jacob et al., 2018) presented a compact fixed-point 8 bit quantization strategy, which performs the folding of batch-normalization and scaling factors into weights before applying a uniform quantizer."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 102
                            }
                        ],
                        "text": "In the case of weights, the parameters a and b can be computed as the min and max values of a tensor (Jacob et al., 2018) or by means of more sophisticated statistic analysis (Migacz, 2017) or via backpropagation (Choi et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 149
                            }
                        ],
                        "text": "\u2026t \u2208 RN ,\neither representing weights or activations or only a subset of them, can be quantized across the range [a, b] with a given number of Q bits (Jacob et al., 2018) as:\nT \u00b7 St = quant(t) = round( clamp(t, a, b)\nSt )St (1)\nwhere St = b\u2212a2Q\u22121 is a real scaling parameter and T is an integer\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 130,
                                "start": 112
                            }
                        ],
                        "text": "Hence, under the configuration MixQ-PL, these points corresponds to the 8 bit integer-only models described in (Jacob et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Previous work [11] discussed the training and integer-only deployment of a fake-quantized network with 8 bit per-layer quantization."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In the case of weights, the parameters a and b can be computed as the min and max values of a tensor [11] or by means of more sophisticated statistic analysis [18] or via backpropagation [2]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 18
                            }
                        ],
                        "text": "On the contrary, (Jacob et al., 2018) quantizes values within a range defined by the tensor min and max values."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 256,
                                "start": 238
                            }
                        ],
                        "text": "Several studies demonstrated that 8 bit quantization\nof weights and activations results in a good trade-off between latency, compression and a near-zero accuracy degradation, also if applied to efficient Imagenet classification networks (Jacob et al., 2018; Migacz, 2017; Jain et al., 2019)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "A quantization-aware retraining of a fake-quantized model is essential to recover accuracy, especially when low-bitwidth precision is employed [11]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Moreover, we improve the methodology [11] for integeronly inference networks to support sub-byte per-channel quantization."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Several studies demonstrated that 8 bit quantization of weights and activations results in a good trade-off between latency, compression and a near-zero accuracy degradation, also if applied to efficient Imagenet classification networks [11, 18, 12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In contrast, the integer-only deployment in [11] presented a compact fixed-point 8 bit quantization strategy, which performs the folding of batch-normalization and scaling factors into weights before applying a uniform quantizer."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 55
                            }
                        ],
                        "text": "With the aim of an integer-only deployment, we extend (Jacob et al., 2018) to a) prevent the folding of batch normalization parameters into convolutional weights and b) support per-channel low-bitwidth weight quantization."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 296,
                                "start": 278
                            }
                        ],
                        "text": "\u2026an integer-only deployment of a MobilenetV1 network on a STM32H7 microcontroller, featuring only 2MB of FLASH memory and 512kB of RAM, with 68% Top1 accuracy, which is 8% higher than previous reported 8 bit integeronly implementations fitting into the same memory constraints (Jacob et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Hence, without loosing generalities, any tensor t \u2208 R , either representing weights or activations or only a subset of them, can be quantized across the range [a, b] with a given number of Q bits [11] as:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 148,
                                "start": 130
                            }
                        ],
                        "text": "State-of-the-art quantization approaches lead to almost-zero accuracy loss if approximating a deep models with 8 bits arithmetic (Jacob et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The state-of-the-art methodology for training a quantized integer-only model is currently integrated within the Tensorflow framework, which shows a low accuracy degradation when targeting 8 bit implementations [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 38
                            }
                        ],
                        "text": "Moreover, we improve the methodology (Jacob et al., 2018) for integer-only inference networks by supporting sub-byte per-channel quantization."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "On the contrary, [11] quantizes values within a range defined by the tensor min and max values."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 39867659,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "59d0d7ccec2db66cad20cac5721ce54a8a058294",
            "isKey": true,
            "numCitedBy": 1284,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "The rising popularity of intelligent mobile devices and the daunting computational cost of deep learning-based models call for efficient and accurate on-device inference schemes. We propose a quantization scheme that allows inference to be carried out using integer-only arithmetic, which can be implemented more efficiently than floating point inference on commonly available integer-only hardware. We also co-design a training procedure to preserve end-to-end model accuracy post quantization. As a result, the proposed quantization scheme improves the tradeoff between accuracy and on-device latency. The improvements are significant even on MobileNets, a model family known for run-time efficiency, and are demonstrated in ImageNet classification and COCO detection on popular CPUs."
            },
            "slug": "Quantization-and-Training-of-Neural-Networks-for-Jacob-Kligys",
            "title": {
                "fragments": [],
                "text": "Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A quantization scheme is proposed that allows inference to be carried out using integer- only arithmetic, which can be implemented more efficiently than floating point inference on commonly available integer-only hardware."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065915235"
                        ],
                        "name": "Raghuraman Krishnamoorthi",
                        "slug": "Raghuraman-Krishnamoorthi",
                        "structuredName": {
                            "firstName": "Raghuraman",
                            "lastName": "Krishnamoorthi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raghuraman Krishnamoorthi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 125
                            }
                        ],
                        "text": "A Per-Channel (PC) procedure results more effective by independently approximating a given tensor along the outer dimension (Krishnamoorthi, 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 150,
                                "start": 130
                            }
                        ],
                        "text": "If homogeneously lowering the number of bits below 8 bits on a per-network base, the accuracy degradation becomes not negligible (Krishnamoorthi, 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 138,
                                "start": 118
                            }
                        ],
                        "text": "Moreover, by means of PC quantization, the accuracy of our 4 bit model is higher than other reported implementations (Krishnamoorthi, 2018; Liu & Mattina, 2019)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 238,
                                "start": 218
                            }
                        ],
                        "text": "Recently, to fit stringent memory requirements, more aggressive sub-byte precision quantization approaches, i.e. less than 8 bit, are under investigation (Choukroun et al., 2019; Jain et al., 2019; Esser et al., 2019; Krishnamoorthi, 2018; Liu & Mattina, 2019)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 41
                            }
                        ],
                        "text": "less than 8 bit, are under investigation (Choukroun et al., 2019; Jain et al., 2019; Esser et al., 2019; Krishnamoorthi, 2018; Liu & Mattina, 2019)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 89
                            }
                        ],
                        "text": "State-of-the-art accuracy level on the efficient MobilenetV1 model has been reported by (Krishnamoorthi, 2018; Liu & Mattina, 2019), by making use of per-channel quantization when moving to 4 bits precision."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 49356451,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3d8b62c060f8444907e7c975c6ae590373b51ed4",
            "isKey": true,
            "numCitedBy": 450,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an overview of techniques for quantizing convolutional neural networks for inference with integer weights and activations. Per-channel quantization of weights and per-layer quantization of activations to 8-bits of precision post-training produces classification accuracies within 2% of floating point networks for a wide variety of CNN architectures. Model sizes can be reduced by a factor of 4 by quantizing weights to 8-bits, even when 8-bit arithmetic is not supported. This can be achieved with simple, post training quantization of weights.We benchmark latencies of quantized networks on CPUs and DSPs and observe a speedup of 2x-3x for quantized implementations compared to floating point on CPUs. Speedups of up to 10x are observed on specialized processors with fixed point SIMD capabilities, like the Qualcomm QDSPs with HVX. \nQuantization-aware training can provide further improvements, reducing the gap to floating point to 1% at 8-bit precision. Quantization-aware training also allows for reducing the precision of weights to four bits with accuracy losses ranging from 2% to 10%, with higher accuracy drop for smaller networks.We introduce tools in TensorFlow and TensorFlowLite for quantizing convolutional networks and review best practices for quantization-aware training to obtain high accuracy with quantized weights and activations. We recommend that per-channel quantization of weights and per-layer quantization of activations be the preferred quantization scheme for hardware acceleration and kernel optimization. We also propose that future processors and hardware accelerators for optimized inference support precisions of 4, 8 and 16 bits."
            },
            "slug": "Quantizing-deep-convolutional-networks-for-A-Krishnamoorthi",
            "title": {
                "fragments": [],
                "text": "Quantizing deep convolutional networks for efficient inference: A whitepaper"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "An overview of techniques for quantizing convolutional neural networks for inference with integer weights and activations is presented and it is recommended that per-channel quantization of weights and per-layer quantized of activations be the preferred quantization scheme for hardware acceleration and kernel optimization."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3493948"
                        ],
                        "name": "Manuele Rusci",
                        "slug": "Manuele-Rusci",
                        "structuredName": {
                            "firstName": "Manuele",
                            "lastName": "Rusci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Manuele Rusci"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2780990"
                        ],
                        "name": "Alessandro Capotondi",
                        "slug": "Alessandro-Capotondi",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Capotondi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alessandro Capotondi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721381"
                        ],
                        "name": "Francesco Conti",
                        "slug": "Francesco-Conti",
                        "structuredName": {
                            "firstName": "Francesco",
                            "lastName": "Conti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Francesco Conti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710649"
                        ],
                        "name": "L. Benini",
                        "slug": "L.-Benini",
                        "structuredName": {
                            "firstName": "Luca",
                            "lastName": "Benini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Benini"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Their quantization approach makes use of integer thresholds [21, 8, 20] for data compression."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 103
                            }
                        ],
                        "text": "Their quantization approach makes use of integer thresholds (Umuroglu & Jahre, 2017; Gao et al., 2018; Rusci et al., 2018) for data compression."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 53281535,
            "fieldsOfStudy": [
                "Computer Science",
                "Engineering"
            ],
            "id": "cfeef5655de414f615520ec615e941366ada938a",
            "isKey": false,
            "numCitedBy": 17,
            "numCiting": 6,
            "paperAbstract": {
                "fragments": [],
                "text": "High energy efficiency and low memory footprint are the key requirements for the deployment of deep learning based analytics on low-power microcontrollers. Here we present work-in-progress results with <tex>$Q$</tex>-bit Quantized Neural Networks (QNNs) deployed on a commercial Cortex-M7 class microcontroller by means of an extension to the ARM CMSIS-NN library. We show that i) for <tex>$Q=4$</tex> and <tex>$Q=2$</tex> low memory footprint QNNs can be deployed with an energy overhead of 30% and 36% respectively against the 8-bit CMSIS-NN due to the lack of quantization support in the ISA; ii) for <tex>$Q=1$</tex> native instructions can be used, yielding an energy and latency reduction of \u223c3.8\u00d7 with respect to CMSIS-NN. Our initial results suggest that a small set of QNN-related specialized instructions could improve performance by as much as 7.5\u00d7 for <tex>$Q=4$</tex>, 13.6\u00d7 for <tex>$Q=2$</tex> and 6.5\u00d7 for binary NNs."
            },
            "slug": "Work-in-Progress:-Quantized-NNs-as-the-Definitive-Rusci-Capotondi",
            "title": {
                "fragments": [],
                "text": "Work-in-Progress: Quantized NNs as the Definitive Solution for Inference on Low-Power ARM MCUs?"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "The initial results suggest that a small set of QNN-related specialized instructions could improve performance by as much as 7.5\u00d7 for binary NNs and up to 6.8\u00d7 with respect to CMSIS-NN."
            },
            "venue": {
                "fragments": [],
                "text": "2018 International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS)"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112666139"
                        ],
                        "name": "Hongxing Gao",
                        "slug": "Hongxing-Gao",
                        "structuredName": {
                            "firstName": "Hongxing",
                            "lastName": "Gao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hongxing Gao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2112528277"
                        ],
                        "name": "Wei Tao",
                        "slug": "Wei-Tao",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Tao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Tao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "115712451"
                        ],
                        "name": "Dongchao Wen",
                        "slug": "Dongchao-Wen",
                        "structuredName": {
                            "firstName": "Dongchao",
                            "lastName": "Wen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dongchao Wen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2145223699"
                        ],
                        "name": "Tse-Wei Chen",
                        "slug": "Tse-Wei-Chen",
                        "structuredName": {
                            "firstName": "Tse-Wei",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tse-Wei Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47373253"
                        ],
                        "name": "Kinya Osa",
                        "slug": "Kinya-Osa",
                        "structuredName": {
                            "firstName": "Kinya",
                            "lastName": "Osa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kinya Osa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1845879900"
                        ],
                        "name": "Masami Kato",
                        "slug": "Masami-Kato",
                        "structuredName": {
                            "firstName": "Masami",
                            "lastName": "Kato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Masami Kato"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Their quantization approach makes use of integer thresholds [21, 8, 20] for data compression."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "For comparison purpose, Table 1 reports also the higher memory requirement of a quantized convolutional layer if using the thresholding method proposed by [21, 8], which exponentially increases with Q."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Label Zx Weights Zw Bq M0 N0 Zy Thr PL+FB [11] 1 cO \u00b7 kw \u00b7 kh \u00b7 cI 1 cO 1 1 1 PL+ICN (our) 1 cO \u00b7 kw \u00b7 kh \u00b7 cI 1 cO cO cO 1 PC+ICN (our) 1 cO \u00b7 kw \u00b7 kh \u00b7 cI cO cO cO cO 1 PC+Thresholds [21, 8] 1 cO \u00b7 kw \u00b7 kh \u00b7 cI cO - - - 1 cO \u00b7 2"
                    },
                    "intents": []
                }
            ],
            "corpusId": 53400337,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9a90ce38c5ad0fdfd18463a5ad8ff76ff625229e",
            "isKey": false,
            "numCitedBy": 8,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Deploying deep models on embedded devices has been a challenging problem since the great success of deep learning based networks. Fixed-point networks, which represent their data with low bits fixed-point and thus give remarkable savings on memory usage, are generally preferred. Even though current fixed-point networks employ relative low bits (e.g. 8-bits), the memory saving is far from enough for the embedded devices. On the other hand, quantization deep networks, for example XNOR-Net and HWGQ-Net, quantize the data into 1 or 2 bits resulting in more significant memory savings but still contain lots of floating-point data. In this paper, we propose a fixed-point network for embedded vision tasks through converting the floating-point data in a quantization network into fixed-point. Furthermore, to overcome the data loss caused by the conversion, we propose to compose floating-point data operations across multiple layers (e.g. convolution, batch normalization and quantization layers) and convert them into fixed-point. We name the fixed-point network obtained through such integrated conversion as Integrated Fixed-point Quantization Networks (IFQ-Net). We demonstrate that our IFQ-Net gives 2.16\u00d7 and 18\u00d7 more savings on model size and runtime feature map memory respectively with similar accuracy on ImageNet. Furthermore, based on YOLOv2, we design IFQ-Tinier-YOLO face detector which is a fixed-point network with 256\u00d7 reduction in model size (246k Bytes) than Tiny-YOLO. We illustrate the promising performance of our face detector in terms of detection rate on Face Detection Data Set and Bencmark (FDDB) and qualitative results of detecting small faces of Wider Face dataset."
            },
            "slug": "IFQ-Net:-Integrated-Fixed-Point-Quantization-for-Gao-Tao",
            "title": {
                "fragments": [],
                "text": "IFQ-Net: Integrated Fixed-Point Quantization Networks for Embedded Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A fixed-point network for embedded vision tasks is proposed through converting the floating-point data in a quantization network intoFixed-point through an integrated conversion of convolution, batch normalization and quantization layers to overcome the data loss caused by the conversion."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791399"
                        ],
                        "name": "Michaela Blott",
                        "slug": "Michaela-Blott",
                        "structuredName": {
                            "firstName": "Michaela",
                            "lastName": "Blott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michaela Blott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2125768"
                        ],
                        "name": "Thomas B. Preu\u00dfer",
                        "slug": "Thomas-B.-Preu\u00dfer",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Preu\u00dfer",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas B. Preu\u00dfer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1809409"
                        ],
                        "name": "Nicholas J. Fraser",
                        "slug": "Nicholas-J.-Fraser",
                        "structuredName": {
                            "firstName": "Nicholas",
                            "lastName": "Fraser",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nicholas J. Fraser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779727"
                        ],
                        "name": "G. Gambardella",
                        "slug": "G.-Gambardella",
                        "structuredName": {
                            "firstName": "Giulio",
                            "lastName": "Gambardella",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gambardella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1409617957"
                        ],
                        "name": "Kenneth O'Brien",
                        "slug": "Kenneth-O'Brien",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "O'Brien",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth O'Brien"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067445"
                        ],
                        "name": "Yaman Umuroglu",
                        "slug": "Yaman-Umuroglu",
                        "structuredName": {
                            "firstName": "Yaman",
                            "lastName": "Umuroglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yaman Umuroglu"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 10
                            }
                        ],
                        "text": "The work (Blott et al., 2018) introduced FINN-R to quantize and deploy a generic model into constrained FPGA architectures."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 9
                            }
                        ],
                        "text": "The work [1] introduced FINN-R to quantize and deploy a generic model into constrained FPGA architectures."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 219886219,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8daa392b62968206885f3e84c3d96cf04d48a5b4",
            "isKey": false,
            "numCitedBy": 102,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional Neural Networks have rapidly become the most successful machine learning algorithm, enabling ubiquitous machine vision and intelligent decisions on even embedded computing-systems. While the underlying arithmetic is structurally simple, compute and memory requirements are challenging. One of the promising opportunities is leveraging reduced-precision representations for inputs, activations and model parameters. The resulting scalability in performance, power efficiency and storage footprint provides interesting design compromises in exchange for a small reduction in accuracy. FPGAs are ideal for exploiting low-precision inference engines leveraging custom precisions to achieve the required numerical accuracy for a given application. In this article, we describe the second generation of the FINN framework, an end-to-end tool which enables design space exploration and automates the creation of fully customized inference engines on FPGAs. Given a neural network description, the tool optimizes for given platforms, design targets and a specific precision. We introduce formalizations of resource cost functions and performance predictions, and elaborate on the optimization algorithms. Finally, we evaluate a selection of reduced precision neural networks ranging from CIFAR-10 classifiers to YOLO-based object detection on a range of platforms including PYNQ and AWS\\,F1, demonstrating new unprecedented measured throughput at 50TOp/s on AWS-F1 and 5TOp/s on embedded devices."
            },
            "slug": "FINN-R:-An-End-to-End-Deep-Learning-Framework-for-Blott-Preu\u00dfer",
            "title": {
                "fragments": [],
                "text": "FINN-R: An End-to-End Deep-Learning Framework for Fast Exploration of Quantized Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The second generation of the FINN framework is described, an end-to-end tool which enables design space exploration and automates the creation of fully customized inference engines on FPGAs that optimizes for given platforms, design targets and a specific precision."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067445"
                        ],
                        "name": "Yaman Umuroglu",
                        "slug": "Yaman-Umuroglu",
                        "structuredName": {
                            "firstName": "Yaman",
                            "lastName": "Umuroglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yaman Umuroglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054413"
                        ],
                        "name": "Magnus Jahre",
                        "slug": "Magnus-Jahre",
                        "structuredName": {
                            "firstName": "Magnus",
                            "lastName": "Jahre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Magnus Jahre"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 192,
                                "start": 185
                            }
                        ],
                        "text": "Label Zx Weights Zw Bq M0 N0 Zy Thr PL+FB [11] 1 cO \u00b7 kw \u00b7 kh \u00b7 cI 1 cO 1 1 1 PL+ICN (our) 1 cO \u00b7 kw \u00b7 kh \u00b7 cI 1 cO cO cO 1 PC+ICN (our) 1 cO \u00b7 kw \u00b7 kh \u00b7 cI cO cO cO cO 1 PC+Thresholds [21, 8] 1 cO \u00b7 kw \u00b7 kh \u00b7 cI cO - - - 1 cO \u00b7 2"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 61
                            }
                        ],
                        "text": "Their quantization approach makes use of integer thresholds (Umuroglu & Jahre, 2017; Gao et al., 2018; Rusci et al., 2018) for data compression."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 60
                            }
                        ],
                        "text": "Their quantization approach makes use of integer thresholds [21, 8, 20] for data compression."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 156
                            }
                        ],
                        "text": "For comparison purpose, Table 1 reports also the higher memory requirement of a quantized convolutional layer if using the thresholding method pro-\nposed by (Umuroglu & Jahre, 2017; Gao et al., 2018), which exponentially increases with Q."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 162,
                                "start": 155
                            }
                        ],
                        "text": "For comparison purpose, Table 1 reports also the higher memory requirement of a quantized convolutional layer if using the thresholding method proposed by [21, 8], which exponentially increases with Q."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 26223295,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a42b9a97d0458dda4bbc0863eca0143d7505c3c",
            "isKey": true,
            "numCitedBy": 23,
            "numCiting": 9,
            "paperAbstract": {
                "fragments": [],
                "text": "Running Deep Neural Network (DNN) models on devices with limited computational capability is a challenge due to large compute and memory requirements. Quantized Neural Networks (QNNs) have emerged as a potential solution to this problem, promising to offer most of the DNN accuracy benefits with much lower computational cost. However, harvesting these benefits on existing mobile CPUs is a challenge since operations on highly quantized datatypes are not natively supported in most instruction set architectures (ISAs). In this work, we first describe a streamlining flow to convert all QNN inference operations to integer ones. Afterwards, we provide techniques based on processing one bit position at a time (bit-serial) to show how QNNs can be efficiently deployed using common bitwise operations. We demonstrate the potential of QNNs on mobile CPUs with microbenchmarks and on a quantized AlexNet, which is 3.5x faster than an optimized 8-bit baseline."
            },
            "slug": "Streamlined-Deployment-for-Quantized-Neural-Umuroglu-Jahre",
            "title": {
                "fragments": [],
                "text": "Streamlined Deployment for Quantized Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This work describes a streamlining flow to convert all QNN inference operations to integer ones and provides techniques based on processing one bit position at a time (bit-serial) to show how QNNs can be efficiently deployed using common bitwise operations."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143879884"
                        ],
                        "name": "Zhen Dong",
                        "slug": "Zhen-Dong",
                        "structuredName": {
                            "firstName": "Zhen",
                            "lastName": "Dong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhen Dong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9088433"
                        ],
                        "name": "Z. Yao",
                        "slug": "Z.-Yao",
                        "structuredName": {
                            "firstName": "Zhewei",
                            "lastName": "Yao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Yao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10419477"
                        ],
                        "name": "A. Gholami",
                        "slug": "A.-Gholami",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Gholami",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gholami"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717098"
                        ],
                        "name": "M. Mahoney",
                        "slug": "M.-Mahoney",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Mahoney",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Mahoney"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732330"
                        ],
                        "name": "K. Keutzer",
                        "slug": "K.-Keutzer",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Keutzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Keutzer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 9
                            }
                        ],
                        "text": "The HAWQ [5] method relies on a second order Hessian metric to define prioritization of tensor\u2019s bit precision to reduce, but without choosing the optimal per-tensor quantization level."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 5
                            }
                        ],
                        "text": "Both [5] and [22] reports superior accuracy than ours when compressing networks to a 1MB of memory footprint, but they include non-uniform clustering quantization of floating-point parameters, therefore not fully-comparable with our work in terms of microcontroller readiness, as current MCUs are not equipped with the hardware needed for manipulation and computation on these data formats."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "The HAWQ (Dong et al., 2019) method relies on a second order Hessian metric to define prioritization of tensor\u2019s bit precision to reduce, but without choosing the optimal per-tensor quantization level."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 18
                            }
                        ],
                        "text": "38 MB SqueezeNext [5] MIX not-uniform 68."
                    },
                    "intents": []
                }
            ],
            "corpusId": 148571720,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a858b96d2fdfeadf8c0f7126cbd55825223fb9d",
            "isKey": true,
            "numCitedBy": 180,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Model size and inference speed/power have become a major challenge in the deployment of neural networks for many applications. A promising approach to address these problems is quantization. However, uniformly quantizing a model to ultra-low precision leads to significant accuracy degradation. A novel solution for this is to use mixed-precision quantization, as some parts of the network may allow lower precision as compared to other layers. However, there is no systematic way to determine the precision of different layers. A brute force approach is not feasible for deep networks, as the search space for mixed-precision is exponential in the number of layers. Another challenge is a similar factorial complexity for determining block-wise fine-tuning order when quantizing the model to a target precision. Here, we introduce Hessian AWare Quantization (HAWQ), a novel second-order quantization method to address these problems. HAWQ allows for the automatic selection of the relative quantization precision of each layer, based on the layer's Hessian spectrum. Moreover, HAWQ provides a deterministic fine-tuning order for quantizing layers. We show the results of our method on Cifar-10 using ResNet20, and on ImageNet using Inception-V3, ResNet50 and SqueezeNext models. Comparing HAWQ with state-of-the-art shows that we can achieve similar/better accuracy with 8\u00d7 activation compression ratio on ResNet20, as compared to DNAS, and up to 1% higher accuracy with up to 14% smaller models on ResNet50 and Inception-V3, compared to recently proposed methods of RVQuant and HAQ. Furthermore, we show that we can quantize SqueezeNext to just 1MB model size while achieving above 68% top1 accuracy on ImageNet."
            },
            "slug": "HAWQ:-Hessian-AWare-Quantization-of-Neural-Networks-Dong-Yao",
            "title": {
                "fragments": [],
                "text": "HAWQ: Hessian AWare Quantization of Neural Networks With Mixed-Precision"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "Hessian AWare Quantization (HAWQ), a novel second-order quantization method that allows for the automatic selection of the relative quantization precision of each layer, based on the layer's Hessian spectrum, is introduced."
            },
            "venue": {
                "fragments": [],
                "text": "2019 IEEE/CVF International Conference on Computer Vision (ICCV)"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109552037"
                        ],
                        "name": "Dongqing Zhang",
                        "slug": "Dongqing-Zhang",
                        "structuredName": {
                            "firstName": "Dongqing",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dongqing Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109732576"
                        ],
                        "name": "Jiaolong Yang",
                        "slug": "Jiaolong-Yang",
                        "structuredName": {
                            "firstName": "Jiaolong",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiaolong Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51150243"
                        ],
                        "name": "Dongqiangzi Ye",
                        "slug": "Dongqiangzi-Ye",
                        "structuredName": {
                            "firstName": "Dongqiangzi",
                            "lastName": "Ye",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dongqiangzi Ye"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144988571"
                        ],
                        "name": "G. Hua",
                        "slug": "G.-Hua",
                        "structuredName": {
                            "firstName": "Gang",
                            "lastName": "Hua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Hua"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 145,
                                "start": 127
                            }
                        ],
                        "text": "It is also worth to mention as non-uniform quantizers have resulted as the best approximators when reducing the bit precision (Zhang et al., 2018; Wang et al., 2018; Han et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 50784025,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a8e1b91b0940a539aca302fb4e5c1f098e4e3860",
            "isKey": false,
            "numCitedBy": 393,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Although weight and activation quantization is an effective approach for Deep Neural Network (DNN) compression and has a lot of potentials to increase inference speed leveraging bit-operations, there is still a noticeable gap in terms of prediction accuracy between the quantized model and the full-precision model. To address this gap, we propose to jointly train a quantized, bit-operation-compatible DNN and its associated quantizers, as opposed to using fixed, handcrafted quantization schemes such as uniform or logarithmic quantization. Our method for learning the quantizers applies to both network weights and activations with arbitrary-bit precision, and our quantizers are easy to train. The comprehensive experiments on CIFAR-10 and ImageNet datasets show that our method works consistently well for various network structures such as AlexNet, VGG-Net, GoogLeNet, ResNet, and DenseNet, surpassing previous quantization methods in terms of accuracy by an appreciable margin. Code available at https://github.com/Microsoft/LQ-Nets."
            },
            "slug": "LQ-Nets:-Learned-Quantization-for-Highly-Accurate-Zhang-Yang",
            "title": {
                "fragments": [],
                "text": "LQ-Nets: Learned Quantization for Highly Accurate and Compact Deep Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 57,
                "text": "This work proposes to jointly train a quantized, bit-operation-compatible DNN and its associated quantizers, as opposed to using fixed, handcrafted quantization schemes such as uniform or logarithmic quantization, to address the gap in prediction accuracy between the quantized model and the full-precision model."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2357931"
                        ],
                        "name": "Steven K. Esser",
                        "slug": "Steven-K.-Esser",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Esser",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven K. Esser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46571359"
                        ],
                        "name": "J. McKinstry",
                        "slug": "J.-McKinstry",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "McKinstry",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. McKinstry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064431971"
                        ],
                        "name": "D. Bablani",
                        "slug": "D.-Bablani",
                        "structuredName": {
                            "firstName": "Deepika",
                            "lastName": "Bablani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Bablani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2730753"
                        ],
                        "name": "R. Appuswamy",
                        "slug": "R.-Appuswamy",
                        "structuredName": {
                            "firstName": "Rathinakumar",
                            "lastName": "Appuswamy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Appuswamy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1944330"
                        ],
                        "name": "D. Modha",
                        "slug": "D.-Modha",
                        "structuredName": {
                            "firstName": "Dharmendra",
                            "lastName": "Modha",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Modha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 10
                            }
                        ],
                        "text": "The works [12, 6] exploits learning-based approaches for determining the quantization ranges of activation and weights at low-bitwidth precision."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 41
                            }
                        ],
                        "text": "less than 8 bit, are under investigation [3, 12, 6, 13, 16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 67788003,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dc160709bbe528b506a37ead334f60d258413357",
            "isKey": false,
            "numCitedBy": 203,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep networks run with low precision operations at inference time offer power and space advantages over high precision alternatives, but need to overcome the challenge of maintaining high accuracy as precision decreases. Here, we present a method for training such networks, Learned Step Size Quantization, that achieves the highest accuracy to date on the ImageNet dataset when using models, from a variety of architectures, with weights and activations quantized to 2-, 3- or 4-bits of precision, and that can train 3-bit models that reach full precision baseline accuracy. Our approach builds upon existing methods for learning weights in quantized networks by improving how the quantizer itself is configured. Specifically, we introduce a novel means to estimate and scale the task loss gradient at each weight and activation layer's quantizer step size, such that it can be learned in conjunction with other network parameters. This approach works using different levels of precision as needed for a given system and requires only a simple modification of existing training code."
            },
            "slug": "Learned-Step-Size-Quantization-Esser-McKinstry",
            "title": {
                "fragments": [],
                "text": "Learned Step Size Quantization"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work introduces a novel means to estimate and scale the task loss gradient at each weight and activation layer's quantizer step size, such that it can be learned in conjunction with other network parameters."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2020
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2506452"
                        ],
                        "name": "Jungwook Choi",
                        "slug": "Jungwook-Choi",
                        "structuredName": {
                            "firstName": "Jungwook",
                            "lastName": "Choi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jungwook Choi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108370425"
                        ],
                        "name": "Zhuo Wang",
                        "slug": "Zhuo-Wang",
                        "structuredName": {
                            "firstName": "Zhuo",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhuo Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1778215"
                        ],
                        "name": "Swagath Venkataramani",
                        "slug": "Swagath-Venkataramani",
                        "structuredName": {
                            "firstName": "Swagath",
                            "lastName": "Venkataramani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Swagath Venkataramani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40060585"
                        ],
                        "name": "P. Chuang",
                        "slug": "P.-Chuang",
                        "structuredName": {
                            "firstName": "Pierce",
                            "lastName": "Chuang",
                            "middleNames": [
                                "I-Jen"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Chuang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145941003"
                        ],
                        "name": "V. Srinivasan",
                        "slug": "V.-Srinivasan",
                        "structuredName": {
                            "firstName": "Vijayalakshmi",
                            "lastName": "Srinivasan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Srinivasan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33678523"
                        ],
                        "name": "K. Gopalakrishnan",
                        "slug": "K.-Gopalakrishnan",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Gopalakrishnan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Gopalakrishnan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 60,
                                "start": 43
                            }
                        ],
                        "text": "Concerning activations, the PACT approach (Choi et al., 2018) demonstrated the highest efficiency by leveraging backpropagation to learn the quantization ranges."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 231,
                                "start": 214
                            }
                        ],
                        "text": "In the case of weights, the parameters a and b can be computed as the min and max values of a tensor (Jacob et al., 2018) or by means of more sophisticated statistic analysis (Migacz, 2017) or via backpropagation (Choi et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 99
                            }
                        ],
                        "text": ", 2018) or by means of more sophisticated statistic analysis (Migacz, 2017) or via backpropagation (Choi et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 69
                            }
                        ],
                        "text": ", 2019), and much harder than quantizing over-parameterized networks (Choi et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 119
                            }
                        ],
                        "text": "These additional layers are responsible for recording the activation range statistics, optionally via backpropagation (Choi et al., 2018), and apply quantization during the forward pass depending on the collected statistics."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 169
                            }
                        ],
                        "text": "We argue that this is a representative problem for tiny microntrollers, not yet solved (Jain et al., 2019), and much harder than quantizing over-parameterized networks (Choi\net al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 21721698,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "49e60f82d6ae835c56473464f67ca5c11d3e95ec",
            "isKey": true,
            "numCitedBy": 435,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep learning algorithms achieve high classification accuracy at the expense of significant computation cost. To address this cost, a number of quantization schemeshave been proposed - but most of these techniques focused on quantizing weights, which are relatively smaller in size compared to activations. This paper proposes a novel quantization scheme for activations during training - that enables neural networks to work well with ultra low precision weights and activations without any significant accuracy degradation. This technique, PArameterized Clipping acTi-vation (PACT), uses an activation clipping parameter \u03b1 that is optimized duringtraining to find the right quantization scale. PACT allows quantizing activations toarbitrary bit precisions, while achieving much better accuracy relative to publishedstate-of-the-art quantization schemes. We show, for the first time, that both weights and activations can be quantized to 4-bits of precision while still achieving accuracy comparable to full precision networks across a range of popular models and datasets. We also show that exploiting these reduced-precision computational units in hardware can enable a super-linear improvement in inferencing performance dueto a significant reduction in the area of accelerator compute engines coupled with the ability to retain the quantized model and activation data in on-chip memories."
            },
            "slug": "PACT:-Parameterized-Clipping-Activation-for-Neural-Choi-Wang",
            "title": {
                "fragments": [],
                "text": "PACT: Parameterized Clipping Activation for Quantized Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is shown, for the first time, that both weights and activations can be quantized to 4-bits of precision while still achieving accuracy comparable to full precision networks across a range of popular models and datasets."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116997936"
                        ],
                        "name": "Sambhav R. Jain",
                        "slug": "Sambhav-R.-Jain",
                        "structuredName": {
                            "firstName": "Sambhav",
                            "lastName": "Jain",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sambhav R. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31056113"
                        ],
                        "name": "Albert Gural",
                        "slug": "Albert-Gural",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Gural",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Albert Gural"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110542026"
                        ],
                        "name": "Michael Wu",
                        "slug": "Michael-Wu",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145990102"
                        ],
                        "name": "C. Dick",
                        "slug": "C.-Dick",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Dick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Dick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 28,
                                "start": 11
                            }
                        ],
                        "text": "The works (Jain et al., 2019; Esser et al., 2019) exploits learning-based approaches for determining the quantization ranges of activation and weights at low-bitwidth precision."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 105,
                                "start": 88
                            }
                        ],
                        "text": "We argue that this is a representative problem for tiny microntrollers, not yet solved (Jain et al., 2019), and much harder than quantizing over-parameterized networks (Choi\net al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 289,
                                "start": 272
                            }
                        ],
                        "text": "Several studies demonstrated that 8 bit quantization\nof weights and activations results in a good trade-off between latency, compression and a near-zero accuracy degradation, also if applied to efficient Imagenet classification networks (Jacob et al., 2018; Migacz, 2017; Jain et al., 2019)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 179
                            }
                        ],
                        "text": "Recently, to fit stringent memory requirements, more aggressive sub-byte precision quantization approaches, i.e. less than 8 bit, are under investigation (Choukroun et al., 2019; Jain et al., 2019; Esser et al., 2019; Krishnamoorthi, 2018; Liu & Mattina, 2019)."
                    },
                    "intents": []
                }
            ],
            "corpusId": 202542905,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d7efe244661f6171116fa8e6cf91e554dd29535",
            "isKey": true,
            "numCitedBy": 74,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a method of training quantization thresholds (TQT) for uniform symmetric quantizers using standard backpropagation and gradient descent. Contrary to prior work, we show that a careful analysis of the straight-through estimator for threshold gradients allows for a natural range-precision trade-off leading to better optima. Our quantizers are constrained to use power-of-2 scale-factors and per-tensor scaling of weights and activations to make it amenable for hardware implementations. We present analytical support for the general robustness of our methods and empirically validate them on various CNNs for ImageNet classification. We are able to achieve near-floating-point accuracy on traditionally difficult networks such as MobileNets with less than 5 epochs of quantized (8-bit) retraining. Finally, we present Graffitist, a framework that enables automatic quantization of TensorFlow graphs for TQT (available at this https URL )."
            },
            "slug": "Trained-Quantization-Thresholds-for-Accurate-and-of-Jain-Gural",
            "title": {
                "fragments": [],
                "text": "Trained Quantization Thresholds for Accurate and Efficient Fixed-Point Inference of Deep Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "The proposed method of training quantization thresholds (TQT) for uniform symmetric quantizers using standard backpropagation and gradient descent is able to achieve near-floating-point accuracy on traditionally difficult networks such as MobileNets with less than 5 epochs of quantized (8-bit) retraining."
            },
            "venue": {
                "fragments": [],
                "text": "MLSys"
            },
            "year": 2020
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1933900"
                        ],
                        "name": "D. Lin",
                        "slug": "D.-Lin",
                        "structuredName": {
                            "firstName": "Darryl",
                            "lastName": "Lin",
                            "middleNames": [
                                "Dexu"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2390504"
                        ],
                        "name": "S. Talathi",
                        "slug": "S.-Talathi",
                        "structuredName": {
                            "firstName": "Sachin",
                            "lastName": "Talathi",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Talathi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145712235"
                        ],
                        "name": "V. Annapureddy",
                        "slug": "V.-Annapureddy",
                        "structuredName": {
                            "firstName": "V.",
                            "lastName": "Annapureddy",
                            "middleNames": [
                                "Sreekanth"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Annapureddy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 107,
                                "start": 91
                            }
                        ],
                        "text": "Early works on quantization of deep networks targeted 16 bits fixed-point implementations (Lin et al., 2016), which result in an almost lossless approximation of full-precision trained networks, or extreme binarized networks, which, despite the fascinating low-computational and memory requirements,\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 108,
                                "start": 90
                            }
                        ],
                        "text": "Early works on quantization of deep networks targeted 16 bits fixed-point implementations (Lin et al., 2016), which result in an almost lossless approximation of full-precision trained networks, or extreme binarized networks, which, despite the fascinating low-computational and memory requirements, showed major accuracy losses when applied on image classification benchmarks (Courbariaux et al."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 649645,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33da17e0070dfceed05aec1602a7d1e3284cf715",
            "isKey": false,
            "numCitedBy": 609,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years increasingly complex architectures for deep convolution networks (DCNs) have been proposed to boost the performance on image recognition tasks. However, the gains in performance have come at a cost of substantial increase in computation and model storage resources. Fixed point implementation of DCNs has the potential to alleviate some of these complexities and facilitate potential deployment on embedded hardware. In this paper, we propose a quantizer design for fixed point implementation of DCNs. We formulate and solve an optimization problem to identify optimal fixed point bit-width allocation across DCN layers. Our experiments show that in comparison to equal bitwidth settings, the fixed point DCNs with optimized bit width allocation offer > 20%reduction in the model size without any loss in accuracy on CIFAR-10 benchmark. We also demonstrate that fine-tuning can further enhance the accuracy of fixed point DCNs beyond that of the original floating point model. In doing so, we report a new state-of-the-art fixed point performance of 6.78% error-rate on CIFAR-10 benchmark."
            },
            "slug": "Fixed-Point-Quantization-of-Deep-Convolutional-Lin-Talathi",
            "title": {
                "fragments": [],
                "text": "Fixed Point Quantization of Deep Convolutional Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper proposes a quantizer design for fixed point implementation of DCNs, formulate and solve an optimization problem to identify optimal fixed point bit-width allocation across DCN layers, and demonstrates that fine-tuning can further enhance the accuracy of fixed point DCNs beyond that of the original floating point model."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143840275"
                        ],
                        "name": "Song Han",
                        "slug": "Song-Han",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3123774"
                        ],
                        "name": "Huizi Mao",
                        "slug": "Huizi-Mao",
                        "structuredName": {
                            "firstName": "Huizi",
                            "lastName": "Mao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huizi Mao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80724002"
                        ],
                        "name": "W. Dally",
                        "slug": "W.-Dally",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dally",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dally"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 166
                            }
                        ],
                        "text": "It is also worth to mention as non-uniform quantizers have resulted as the best approximators when reducing the bit precision (Zhang et al., 2018; Wang et al., 2018; Han et al., 2015)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2134321,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "642d0f49b7826adcf986616f4af77e736229990f",
            "isKey": false,
            "numCitedBy": 5732,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural networks are both computationally intensive and memory intensive, making them difficult to deploy on embedded systems with limited hardware resources. To address this limitation, we introduce \"deep compression\", a three stage pipeline: pruning, trained quantization and Huffman coding, that work together to reduce the storage requirement of neural networks by 35x to 49x without affecting their accuracy. Our method first prunes the network by learning only the important connections. Next, we quantize the weights to enforce weight sharing, finally, we apply Huffman coding. After the first two steps we retrain the network to fine tune the remaining connections and the quantized centroids. Pruning, reduces the number of connections by 9x to 13x; Quantization then reduces the number of bits that represent each connection from 32 to 5. On the ImageNet dataset, our method reduced the storage required by AlexNet by 35x, from 240MB to 6.9MB, without loss of accuracy. Our method reduced the size of VGG-16 by 49x from 552MB to 11.3MB, again with no loss of accuracy. This allows fitting the model into on-chip SRAM cache rather than off-chip DRAM memory. Our compression method also facilitates the use of complex neural networks in mobile applications where application size and download bandwidth are constrained. Benchmarked on CPU, GPU and mobile GPU, compressed network has 3x to 4x layerwise speedup and 3x to 7x better energy efficiency."
            },
            "slug": "Deep-Compression:-Compressing-Deep-Neural-Network-Han-Mao",
            "title": {
                "fragments": [],
                "text": "Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work introduces \"deep compression\", a three stage pipeline: pruning, trained quantization and Huffman coding, that work together to reduce the storage requirement of neural networks by 35x to 49x without affecting their accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109015543"
                        ],
                        "name": "Zhi-Gang Liu",
                        "slug": "Zhi-Gang-Liu",
                        "structuredName": {
                            "firstName": "Zhi-Gang",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhi-Gang Liu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 210182726,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b021755bd3c77a7b558fd831d1c68dc293b77e57",
            "isKey": false,
            "numCitedBy": 1,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "The Straight-Through Estimator (STE) [Hinton, 2012][Bengio et al., 2013] is widely used for back-propagating gradients through the quantization function, but the STE technique lacks a complete theoretical understanding. We propose an alternative methodology called alpha-blending (AB), which quantizes neural networks to low precision using stochastic gradient descent (SGD). Our (AB) method avoids STE approximation by replacing the quantized weight in the loss function by an affine combination of the quantized weight wq and the corresponding full-precision weight w with non-trainable scalar coefficient \u03b1 and (1\u2212\u03b1). During training, \u03b1 is gradually increased from 0 to 1; the gradient updates to the weights are through the full precision term, (1\u2212\u03b1)w, of the affine combination; the model is converted from full-precision to low precision progressively. To evaluate the (AB) method, a 1-bit BinaryNet [Hubara et al., 2016a] on CIFAR10 dataset and 8-bits, 4-bits MobileNet v1, ResNet 50 v1/2 on ImageNet are trained using the alpha-blending approach, and the evaluation indicates that AB improves top-1 accuracy by 0.9%, 0.82% and 2.93% respectively compared to the results of STE based quantization [Hubara et al., 2016a] 1 [Krishnamoorthi, 2018] 2 ."
            },
            "slug": "Learning-Low-precision-Neural-Networks-without-Liu",
            "title": {
                "fragments": [],
                "text": "Learning Low-precision Neural Networks without Straight-Through Estimator (STE)"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work proposes an alternative methodology called alpha-blending (AB), which quantizes neural networks to low precision using stochastic gradient descent (SGD) and improves top-1 accuracy by 0.9%, 0.82% and 2.93% compared to the results of STE based quantization."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "71908954"
                        ],
                        "name": "Josh Fromm",
                        "slug": "Josh-Fromm",
                        "structuredName": {
                            "firstName": "Josh",
                            "lastName": "Fromm",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Josh Fromm"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701358"
                        ],
                        "name": "Shwetak N. Patel",
                        "slug": "Shwetak-N.-Patel",
                        "structuredName": {
                            "firstName": "Shwetak",
                            "lastName": "Patel",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shwetak N. Patel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3041721"
                        ],
                        "name": "Matthai Philipose",
                        "slug": "Matthai-Philipose",
                        "structuredName": {
                            "firstName": "Matthai",
                            "lastName": "Philipose",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthai Philipose"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 12
                            }
                        ],
                        "text": "The method (Fromm et al., 2018) targeted perpixel binarization based on a defined tensor mask."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 44128338,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6509ffd1fe0eeaf92f2e3ac201b33fdaa83c31d",
            "isKey": false,
            "numCitedBy": 26,
            "numCiting": 17,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work has shown that fast, compact low-bitwidth neural networks can be surprisingly accurate. These networks use homogeneous binarization: all parameters in each layer or (more commonly) the whole model have the same low bitwidth (e.g., 2 bits). However, modern hardware allows efficient designs where each arithmetic instruction can have a custom bitwidth, motivating heterogeneous binarization, where every parameter in the network may have a different bitwidth. In this paper, we show that it is feasible and useful to select bitwidths at the parameter granularity during training. For instance a heterogeneously quantized version of modern networks such as AlexNet and MobileNet, with the right mix of 1-, 2- and 3-bit parameters that average to just 1.4 bits can equal the accuracy of homogeneous 2-bit versions of these networks. Further, we provide analyses to show that the heterogeneously binarized systems yield FPGA- and ASIC-based implementations that are correspondingly more efficient in both circuit area and energy efficiency than their homogeneous counterparts."
            },
            "slug": "Heterogeneous-Bitwidth-Binarization-in-Neural-Fromm-Patel",
            "title": {
                "fragments": [],
                "text": "Heterogeneous Bitwidth Binarization in Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper shows that it is feasible and useful to select bitwidths at the parameter granularity during training, and provides analyses to show that the heterogeneously binarized systems yield FPGA- and ASIC-based implementations that are correspondingly more efficient in both circuit area and energy efficiency than their homogeneous counterparts."
            },
            "venue": {
                "fragments": [],
                "text": "NeurIPS"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2388466"
                        ],
                        "name": "Matthieu Courbariaux",
                        "slug": "Matthieu-Courbariaux",
                        "structuredName": {
                            "firstName": "Matthieu",
                            "lastName": "Courbariaux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthieu Courbariaux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477463"
                        ],
                        "name": "Itay Hubara",
                        "slug": "Itay-Hubara",
                        "structuredName": {
                            "firstName": "Itay",
                            "lastName": "Hubara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Itay Hubara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1912398"
                        ],
                        "name": "Daniel Soudry",
                        "slug": "Daniel-Soudry",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Soudry",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Soudry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1387872181"
                        ],
                        "name": "Ran El-Yaniv",
                        "slug": "Ran-El-Yaniv",
                        "structuredName": {
                            "firstName": "Ran",
                            "lastName": "El-Yaniv",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ran El-Yaniv"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 274,
                                "start": 250
                            }
                        ],
                        "text": "\u2026almost lossless approximation of full-precision trained networks, or extreme binarized networks, which, despite the fascinating low-computational and memory requirements, showed major accuracy losses when applied on image classification benchmarks (Courbariaux et al., 2016; Rastegari et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14796162,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6eecc808d4c74e7d0d7ef6b8a4112c985ced104d",
            "isKey": false,
            "numCitedBy": 1753,
            "numCiting": 78,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a method to train Binarized Neural Networks (BNNs) - neural networks with binary weights and activations at run-time. At training-time the binary weights and activations are used for computing the parameters gradients. During the forward pass, BNNs drastically reduce memory size and accesses, and replace most arithmetic operations with bit-wise operations, which is expected to substantially improve power-efficiency. To validate the effectiveness of BNNs we conduct two sets of experiments on the Torch7 and Theano frameworks. On both, BNNs achieved nearly state-of-the-art results over the MNIST, CIFAR-10 and SVHN datasets. Last but not least, we wrote a binary matrix multiplication GPU kernel with which it is possible to run our MNIST BNN 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classification accuracy. The code for training and running our BNNs is available on-line."
            },
            "slug": "Binarized-Neural-Networks:-Training-Deep-Neural-and-Courbariaux-Hubara",
            "title": {
                "fragments": [],
                "text": "Binarized Neural Networks: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A binary matrix multiplication GPU kernel is written with which it is possible to run the MNIST BNN 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classification accuracy."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3130257"
                        ],
                        "name": "Bichen Wu",
                        "slug": "Bichen-Wu",
                        "structuredName": {
                            "firstName": "Bichen",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bichen Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "4527324"
                        ],
                        "name": "Xiaoliang Dai",
                        "slug": "Xiaoliang-Dai",
                        "structuredName": {
                            "firstName": "Xiaoliang",
                            "lastName": "Dai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaoliang Dai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2918780"
                        ],
                        "name": "Peizhao Zhang",
                        "slug": "Peizhao-Zhang",
                        "structuredName": {
                            "firstName": "Peizhao",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peizhao Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146020227"
                        ],
                        "name": "Yanghan Wang",
                        "slug": "Yanghan-Wang",
                        "structuredName": {
                            "firstName": "Yanghan",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yanghan Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2075373634"
                        ],
                        "name": "Fei Sun",
                        "slug": "Fei-Sun",
                        "structuredName": {
                            "firstName": "Fei",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fei Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115877352"
                        ],
                        "name": "Yiming Wu",
                        "slug": "Yiming-Wu",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39402399"
                        ],
                        "name": "Yuandong Tian",
                        "slug": "Yuandong-Tian",
                        "structuredName": {
                            "firstName": "Yuandong",
                            "lastName": "Tian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuandong Tian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48682997"
                        ],
                        "name": "P\u00e9ter Vajda",
                        "slug": "P\u00e9ter-Vajda",
                        "structuredName": {
                            "firstName": "P\u00e9ter",
                            "lastName": "Vajda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P\u00e9ter Vajda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39978391"
                        ],
                        "name": "Yangqing Jia",
                        "slug": "Yangqing-Jia",
                        "structuredName": {
                            "firstName": "Yangqing",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yangqing Jia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732330"
                        ],
                        "name": "K. Keutzer",
                        "slug": "K.-Keutzer",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Keutzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Keutzer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 216,
                                "start": 204
                            }
                        ],
                        "text": "To address this problem, a crucial contribution comes from the recent work aiming at designing novel network topologies optimized not only in terms of accuracy but also for computational and memory costs [10, 17, 23]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 199
                            }
                        ],
                        "text": "To address this, recent works focused on designing novel network topologies optimized not only in terms of accuracy but also for computational and memory costs (Howard et al., 2017; Ma et al., 2018; Wu et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 54461508,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "45532bffbfbb5553da0b2d0844e95a1b37e59147",
            "isKey": false,
            "numCitedBy": 731,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Designing accurate and efficient ConvNets for mobile devices is challenging because the design space is combinatorially large. Due to this, previous neural architecture search (NAS) methods are computationally expensive. ConvNet architecture optimality depends on factors such as input resolution and target devices. However, existing approaches are too resource demanding for case-by-case redesigns. Also, previous work focuses primarily on reducing FLOPs, but FLOP count does not always reflect actual latency. To address these, we propose a differentiable neural architecture search (DNAS) framework that uses gradient-based methods to optimize ConvNet architectures, avoiding enumerating and training individual architectures separately as in previous methods. FBNets (Facebook-Berkeley-Nets), a family of models discovered by DNAS surpass state-of-the-art models both designed manually and generated automatically. FBNet-B achieves 74.1% top-1 accuracy on ImageNet with 295M FLOPs and 23.1 ms latency on a Samsung S8 phone, 2.4x smaller and 1.5x faster than MobileNetV2-1.3 with similar accuracy. Despite higher accuracy and lower latency than MnasNet, we estimate FBNet-B's search cost is 420x smaller than MnasNet's, at only 216 GPU-hours. Searched for different resolutions and channel sizes, FBNets achieve 1.5% to 6.4% higher accuracy than MobileNetV2. The smallest FBNet achieves 50.2% accuracy and 2.9 ms latency (345 frames per second) on a Samsung S8. Over a Samsung-optimized FBNet, the iPhone-X-optimized model achieves a 1.4x speedup on an iPhone X. FBNet models are open-sourced at https://github. com/facebookresearch/mobile-vision."
            },
            "slug": "FBNet:-Hardware-Aware-Efficient-ConvNet-Design-via-Wu-Dai",
            "title": {
                "fragments": [],
                "text": "FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes a differentiable neural architecture search (DNAS) framework that uses gradient-based methods to optimize ConvNet architectures, avoiding enumerating and training individual architectures separately as in previous methods."
            },
            "venue": {
                "fragments": [],
                "text": "2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49890233"
                        ],
                        "name": "Yundong Zhang",
                        "slug": "Yundong-Zhang",
                        "structuredName": {
                            "firstName": "Yundong",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yundong Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40622167"
                        ],
                        "name": "Naveen Suda",
                        "slug": "Naveen-Suda",
                        "structuredName": {
                            "firstName": "Naveen",
                            "lastName": "Suda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naveen Suda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1891108"
                        ],
                        "name": "Liangzhen Lai",
                        "slug": "Liangzhen-Lai",
                        "structuredName": {
                            "firstName": "Liangzhen",
                            "lastName": "Lai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liangzhen Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144137038"
                        ],
                        "name": "V. Chandra",
                        "slug": "V.-Chandra",
                        "structuredName": {
                            "firstName": "Vikas",
                            "lastName": "Chandra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Chandra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 44
                            }
                        ],
                        "text": "Given common microcontroller architectures (Zhang et al., 2017), we distinguish:\n\u2022 Read-Only (RO) Memory, to store frozen inference parameters, i.e. parameters that will not change during the lifetime of a smart device."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 141
                            }
                        ],
                        "text": "Unfortunately, due to memory constraints, only a small set of relatively complex networks has been ported to the microcontroller domain yet (Zhang et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1125974,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a3d4dbd03355d6b4972d7cb9257ccccdd6d33923",
            "isKey": false,
            "numCitedBy": 227,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Keyword spotting (KWS) is a critical component for enabling speech based user interactions on smart devices. It requires real-time response and high accuracy for good user experience. Recently, neural networks have become an attractive choice for KWS architecture because of their superior accuracy compared to traditional speech processing algorithms. Due to its always-on nature, KWS application has highly constrained power budget and typically runs on tiny microcontrollers with limited memory and compute capability. The design of neural network architecture for KWS must consider these constraints. In this work, we perform neural network architecture evaluation and exploration for running KWS on resource-constrained microcontrollers. We train various neural network architectures for keyword spotting published in literature to compare their accuracy and memory/compute requirements. We show that it is possible to optimize these neural network architectures to fit within the memory and compute constraints of microcontrollers without sacrificing accuracy. We further explore the depthwise separable convolutional neural network (DS-CNN) and compare it against other neural network architectures. DS-CNN achieves an accuracy of 95.4%, which is ~10% higher than the DNN model with similar number of parameters."
            },
            "slug": "Hello-Edge:-Keyword-Spotting-on-Microcontrollers-Zhang-Suda",
            "title": {
                "fragments": [],
                "text": "Hello Edge: Keyword Spotting on Microcontrollers"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "It is shown that it is possible to optimize these neural network architectures to fit within the memory and compute constraints of microcontrollers without sacrificing accuracy, and the depthwise separable convolutional neural network (DS-CNN) is explored and compared against other neural network architecture."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143887493"
                        ],
                        "name": "Mohammad Rastegari",
                        "slug": "Mohammad-Rastegari",
                        "structuredName": {
                            "firstName": "Mohammad",
                            "lastName": "Rastegari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mohammad Rastegari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2004053"
                        ],
                        "name": "Vicente Ordonez",
                        "slug": "Vicente-Ordonez",
                        "structuredName": {
                            "firstName": "Vicente",
                            "lastName": "Ordonez",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vicente Ordonez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40497777"
                        ],
                        "name": "Joseph Redmon",
                        "slug": "Joseph-Redmon",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Redmon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph Redmon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143787583"
                        ],
                        "name": "Ali Farhadi",
                        "slug": "Ali-Farhadi",
                        "structuredName": {
                            "firstName": "Ali",
                            "lastName": "Farhadi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ali Farhadi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 298,
                                "start": 276
                            }
                        ],
                        "text": "\u2026almost lossless approximation of full-precision trained networks, or extreme binarized networks, which, despite the fascinating low-computational and memory requirements, showed major accuracy losses when applied on image classification benchmarks (Courbariaux et al., 2016; Rastegari et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 326,
                                "start": 276
                            }
                        ],
                        "text": ", 2016), which result in an almost lossless approximation of full-precision trained networks, or extreme binarized networks, which, despite the fascinating low-computational and memory requirements, showed major accuracy losses when applied on image classification benchmarks (Courbariaux et al., 2016; Rastegari et al., 2016)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14925907,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b649a98ce77ece8cd7638bb74ab77d22d9be77e7",
            "isKey": false,
            "numCitedBy": 2591,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose two efficient approximations to standard convolutional neural networks: Binary-Weight-Networks and XNOR-Networks. In Binary-Weight-Networks, the filters are approximated with binary values resulting in 32\\(\\times \\) memory saving. In XNOR-Networks, both the filters and the input to convolutional layers are binary. XNOR-Networks approximate convolutions using primarily binary operations. This results in 58\\(\\times \\) faster convolutional operations (in terms of number of the high precision operations) and 32\\(\\times \\) memory savings. XNOR-Nets offer the possibility of running state-of-the-art networks on CPUs (rather than GPUs) in real-time. Our binary networks are simple, accurate, efficient, and work on challenging visual tasks. We evaluate our approach on the ImageNet classification task. The classification accuracy with a Binary-Weight-Network version of AlexNet is the same as the full-precision AlexNet. We compare our method with recent network binarization methods, BinaryConnect and BinaryNets, and outperform these methods by large margins on ImageNet, more than \\(16\\,\\%\\) in top-1 accuracy. Our code is available at: http://allenai.org/plato/xnornet."
            },
            "slug": "XNOR-Net:-ImageNet-Classification-Using-Binary-Rastegari-Ordonez",
            "title": {
                "fragments": [],
                "text": "XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The Binary-Weight-Network version of AlexNet is compared with recent network binarization methods, BinaryConnect and BinaryNets, and outperform these methods by large margins on ImageNet, more than \\(16\\,\\%\\) in top-1 accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1891108"
                        ],
                        "name": "Liangzhen Lai",
                        "slug": "Liangzhen-Lai",
                        "structuredName": {
                            "firstName": "Liangzhen",
                            "lastName": "Lai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liangzhen Lai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40622167"
                        ],
                        "name": "Naveen Suda",
                        "slug": "Naveen-Suda",
                        "structuredName": {
                            "firstName": "Naveen",
                            "lastName": "Suda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Naveen Suda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144137038"
                        ],
                        "name": "V. Chandra",
                        "slug": "V.-Chandra",
                        "structuredName": {
                            "firstName": "Vikas",
                            "lastName": "Chandra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Chandra"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 83,
                                "start": 67
                            }
                        ],
                        "text": "To this aim, we leverages an extended version of the ARM CMSIS-NN (Lai et al., 2018)\nlibrary, featuring an output stationary dataflow, and we measure latency in terms of clock cycles."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 72
                            }
                        ],
                        "text": "Copyright 2020 by the author(s).\nreleased a software library, CMSIS-NN (Lai et al., 2018), which enabled the efficient computation of deep networks on tiny microcontrollers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 66
                            }
                        ],
                        "text": "To this aim, we leverages an extended version of the ARM CMSIS-NN (Lai et al., 2018)"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 38
                            }
                        ],
                        "text": "released a software library, CMSIS-NN (Lai et al., 2018), which enabled the efficient computation of deep networks on tiny microcontrollers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 691340,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ca24492a46856221086e77ffe29e8a69e1be0595",
            "isKey": true,
            "numCitedBy": 183,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep Neural Networks are becoming increasingly popular in always-on IoT edge devices performing data analytics right at the source, reducing latency as well as energy consumption for data communication. This paper presents CMSIS-NN, efficient kernels developed to maximize the performance and minimize the memory footprint of neural network (NN) applications on Arm Cortex-M processors targeted for intelligent IoT edge devices. Neural network inference based on CMSIS-NN kernels achieves 4.6X improvement in runtime/throughput and 4.9X improvement in energy efficiency."
            },
            "slug": "CMSIS-NN:-Efficient-Neural-Network-Kernels-for-Arm-Lai-Suda",
            "title": {
                "fragments": [],
                "text": "CMSIS-NN: Efficient Neural Network Kernels for Arm Cortex-M CPUs"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "CMSIS-NN, efficient kernels developed to maximize the performance and minimize the memory footprint of neural network (NN) applications on Arm Cortex-M processors targeted for intelligent IoT edge devices are presented."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068605434"
                        ],
                        "name": "Ningning Ma",
                        "slug": "Ningning-Ma",
                        "structuredName": {
                            "firstName": "Ningning",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ningning Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50875121"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "Xiangyu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16215052"
                        ],
                        "name": "Haitao Zheng",
                        "slug": "Haitao-Zheng",
                        "structuredName": {
                            "firstName": "Haitao",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haitao Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 182
                            }
                        ],
                        "text": "To address this, recent works focused on designing novel network topologies optimized not only in terms of accuracy but also for computational and memory costs (Howard et al., 2017; Ma et al., 2018; Wu et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 51880435,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c02b909a514af6b9255315e2d50112845ca5ed0e",
            "isKey": false,
            "numCitedBy": 1910,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Currently, the neural network architecture design is mostly guided by the indirect metric of computation complexity, i.e., FLOPs. However, the direct metric, e.g., speed, also depends on the other factors such as memory access cost and platform characterics. Thus, this work proposes to evaluate the direct metric on the target platform, beyond only considering FLOPs. Based on a series of controlled experiments, this work derives several practical guidelines for efficient network design. Accordingly, a new architecture is presented, called ShuffleNet V2. Comprehensive ablation experiments verify that our model is the state-of-the-art in terms of speed and accuracy tradeoff."
            },
            "slug": "ShuffleNet-V2:-Practical-Guidelines-for-Efficient-Ma-Zhang",
            "title": {
                "fragments": [],
                "text": "ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes to evaluate the direct metric on the target platform, beyond only considering FLOPs, and derives several practical guidelines for efficient network design, called ShuffleNet V2."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144727050"
                        ],
                        "name": "Andrew G. Howard",
                        "slug": "Andrew-G.-Howard",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Howard",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew G. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2717876"
                        ],
                        "name": "Menglong Zhu",
                        "slug": "Menglong-Zhu",
                        "structuredName": {
                            "firstName": "Menglong",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Menglong Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Bo Chen",
                        "slug": "Bo-Chen",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741985"
                        ],
                        "name": "Dmitry Kalenichenko",
                        "slug": "Dmitry-Kalenichenko",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Kalenichenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dmitry Kalenichenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108301072"
                        ],
                        "name": "Weijun Wang",
                        "slug": "Weijun-Wang",
                        "structuredName": {
                            "firstName": "Weijun",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weijun Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47447630"
                        ],
                        "name": "Tobias Weyand",
                        "slug": "Tobias-Weyand",
                        "structuredName": {
                            "firstName": "Tobias",
                            "lastName": "Weyand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tobias Weyand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2612392"
                        ],
                        "name": "M. Andreetto",
                        "slug": "M.-Andreetto",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Andreetto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Andreetto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2595180"
                        ],
                        "name": "Hartwig Adam",
                        "slug": "Hartwig-Adam",
                        "structuredName": {
                            "firstName": "Hartwig",
                            "lastName": "Adam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hartwig Adam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 74,
                                "start": 55
                            }
                        ],
                        "text": "We run experiments on the MobilenetV1 family networks (Howard et al., 2017) on Imagenet using the PyTorch framework."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 117,
                                "start": 96
                            }
                        ],
                        "text": "conducted over the MobilenetV1 family networks on the 1000 classes Imagenet classification task (Howard et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 161
                            }
                        ],
                        "text": "To address this, recent works focused on designing novel network topologies optimized not only in terms of accuracy but also for computational and memory costs (Howard et al., 2017; Ma et al., 2018; Wu et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 128
                            }
                        ],
                        "text": "Our experimental evaluation is conducted over the MobilenetV1 family networks on the 1000 classes Imagenet classification task (Howard et al., 2017)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 36
                            }
                        ],
                        "text": "As an example, a 8 bit MobilenetV1 (Howard et al., 2017) with the highest accuracy requires more than 4 MB of embedded memory, which is prohibitive for the majority of microcontroller devices available today."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12670695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3647d6d0f151dc05626449ee09cc7bce55be497e",
            "isKey": true,
            "numCitedBy": 10323,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization."
            },
            "slug": "MobileNets:-Efficient-Convolutional-Neural-Networks-Howard-Zhu",
            "title": {
                "fragments": [],
                "text": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work introduces two simple global hyper-parameters that efficiently trade off between latency and accuracy and demonstrates the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 176
                            }
                        ],
                        "text": "In the case of weights, the parameters a and b can be computed as the min and max values of a tensor (Jacob et al., 2018) or by means of more sophisticated statistic analysis (Migacz, 2017) or via backpropagation (Choi et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 80
                            }
                        ],
                        "text": "While the parameters can be quantized just before the inference (forward) pass (Migacz, 2017), the quantization of the activations requires the insertion of fake-quantized activation layers within the network graph."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 61
                            }
                        ],
                        "text": ", 2018) or by means of more sophisticated statistic analysis (Migacz, 2017) or via backpropagation (Choi et al."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 270,
                                "start": 258
                            }
                        ],
                        "text": "Several studies demonstrated that 8 bit quantization\nof weights and activations results in a good trade-off between latency, compression and a near-zero accuracy degradation, also if applied to efficient Imagenet classification networks (Jacob et al., 2018; Migacz, 2017; Jain et al., 2019)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 237,
                                "start": 184
                            }
                        ],
                        "text": "of weights and activations results in a good trade-off between latency, compression and a near-zero accuracy degradation, also if applied to efficient Imagenet classification networks (Jacob et al., 2018; Migacz, 2017; Jain et al., 2019)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 56,
                                "start": 44
                            }
                        ],
                        "text": "Among the employed methodologies, TensorRT (Migacz, 2017) approximates the parameters tensor by the minimization of the KL divergence metric between quantized and full-precision values."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "8-bit inference with tensorrt"
            },
            "venue": {
                "fragments": [],
                "text": "In GPU Technology Conference,"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116997936"
                        ],
                        "name": "Sambhav R. Jain",
                        "slug": "Sambhav-R.-Jain",
                        "structuredName": {
                            "firstName": "Sambhav",
                            "lastName": "Jain",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sambhav R. Jain"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "31056113"
                        ],
                        "name": "Albert Gural",
                        "slug": "Albert-Gural",
                        "structuredName": {
                            "firstName": "Albert",
                            "lastName": "Gural",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Albert Gural"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110542026"
                        ],
                        "name": "Michael Wu",
                        "slug": "Michael-Wu",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145990102"
                        ],
                        "name": "C. Dick",
                        "slug": "C.-Dick",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Dick",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Dick"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 249,
                                "start": 237
                            }
                        ],
                        "text": "Several studies demonstrated that 8 bit quantization of weights and activations results in a good trade-off between latency, compression and a near-zero accuracy degradation, also if applied to efficient Imagenet classification networks [11, 18, 12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 91,
                                "start": 87
                            }
                        ],
                        "text": "We argue that this is a representative problem for tiny microntrollers, not yet solved [12] and much harder than quantizing over-parameterized networks [2]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 10
                            }
                        ],
                        "text": "The works [12, 6] exploits learning-based approaches for determining the quantization ranges of activation and weights at low-bitwidth precision."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 41
                            }
                        ],
                        "text": "less than 8 bit, are under investigation [3, 12, 6, 13, 16]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 83458578,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e0f7dcefc67294c81d1f3cecea976a289572828",
            "isKey": true,
            "numCitedBy": 39,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a method of training quantization clipping thresholds for uniform symmetric quantizers using standard backpropagation and gradient descent. Our quantizers are constrained to use power-of-2 scale-factors and per-tensor scaling for weights and activations. These constraints make our methods better suited for hardware implementations. Training with these difficult constraints is enabled by a combination of three techniques: using accurate threshold gradients to achieve range-precision trade-off, training thresholds in log-domain, and training with an adaptive gradient optimizer. We refer to this collection of techniques as Adaptive-Gradient Log-domain Threshold Training (ALT). We present analytical support for the general robustness of our methods and empirically validate them on various CNNs for ImageNet classification. We are able to achieve floating-point or near-floating-point accuracy on traditionally difficult networks such as MobileNets in less than 5 epochs of quantized (8-bit) retraining. Finally, we present Graffitist, a framework that enables immediate quantization of TensorFlow graphs using our methods. Code available at this https URL ."
            },
            "slug": "Trained-Uniform-Quantization-for-Accurate-and-on-Jain-Gural",
            "title": {
                "fragments": [],
                "text": "Trained Uniform Quantization for Accurate and Efficient Neural Network Inference on Fixed-Point Hardware"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "A method of training quantization clipping thresholds for uniform symmetric quantizers using standard backpropagation and gradient descent that is able to achieve floating-point or near-floating-point accuracy on traditionally difficult networks such as MobileNets in less than 5 epochs of quantized (8-bit) retraining."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2019
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 214,
                                "start": 199
                            }
                        ],
                        "text": "To address this, recent works focused on designing novel network topologies optimized not only in terms of accuracy but also for computational and memory costs (Howard et al., 2017; Ma et al., 2018; Wu et al., 2018)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fbnet: Hardwareaware efficient convnet design via differentiable neural architecture search"
            },
            "venue": {
                "fragments": [],
                "text": "arXiv preprint arXiv:1812.03443,"
            },
            "year": 2018
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 21,
            "methodology": 15,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 28,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/Memory-Driven-Mixed-Low-Precision-Quantization-For-Rusci-Capotondi/099f4ef673778856bddb8638657aa6cc3eb112c9?sort=total-citations"
}