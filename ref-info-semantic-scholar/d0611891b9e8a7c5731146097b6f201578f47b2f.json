{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1817030"
                        ],
                        "name": "Saining Xie",
                        "slug": "Saining-Xie",
                        "structuredName": {
                            "firstName": "Saining",
                            "lastName": "Xie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saining Xie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2983898"
                        ],
                        "name": "Ross B. Girshick",
                        "slug": "Ross-B.-Girshick",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Girshick",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross B. Girshick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127283"
                        ],
                        "name": "Piotr Doll\u00e1r",
                        "slug": "Piotr-Doll\u00e1r",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Doll\u00e1r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piotr Doll\u00e1r"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144035504"
                        ],
                        "name": "Z. Tu",
                        "slug": "Z.-Tu",
                        "structuredName": {
                            "firstName": "Zhuowen",
                            "lastName": "Tu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Tu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 166
                            }
                        ],
                        "text": "Successive advancements on this benchmark based on convolutional neural networks (CNNs) have achieved impressive results through significant architecture engineering [32, 35, 11, 36, 34, 41]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8485068,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f6e0856b4a9199fa968ac00da612a9407b5cb85c",
            "isKey": false,
            "numCitedBy": 5619,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a simple, highly modularized network architecture for image classification. Our network is constructed by repeating a building block that aggregates a set of transformations with the same topology. Our simple design results in a homogeneous, multi-branch architecture that has only a few hyper-parameters to set. This strategy exposes a new dimension, which we call cardinality (the size of the set of transformations), as an essential factor in addition to the dimensions of depth and width. On the ImageNet-1K dataset, we empirically show that even under the restricted condition of maintaining complexity, increasing cardinality is able to improve classification accuracy. Moreover, increasing cardinality is more effective than going deeper or wider when we increase the capacity. Our models, named ResNeXt, are the foundations of our entry to the ILSVRC 2016 classification task in which we secured 2nd place. We further investigate ResNeXt on an ImageNet-5K set and the COCO detection set, also showing better results than its ResNet counterpart. The code and models are publicly available online."
            },
            "slug": "Aggregated-Residual-Transformations-for-Deep-Neural-Xie-Girshick",
            "title": {
                "fragments": [],
                "text": "Aggregated Residual Transformations for Deep Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "On the ImageNet-1K dataset, it is empirically show that even under the restricted condition of maintaining complexity, increasing cardinality is able to improve classification accuracy and is more effective than going deeper or wider when the authors increase the capacity."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34838386"
                        ],
                        "name": "K. Simonyan",
                        "slug": "K.-Simonyan",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Simonyan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Simonyan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 111
                            }
                        ],
                        "text": "Note the prevalence of separable convolutions and the number of branches compared with competing architectures [32, 35, 11, 36, 34]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 181
                            }
                        ],
                        "text": "We use a common heuristic to double the number of filters in the output whenever the spatial activation size is reduced in order to maintain roughly constant hidden state dimension [22, 32]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 166
                            }
                        ],
                        "text": "Successive advancements on this benchmark based on convolutional neural networks (CNNs) have achieved impressive results through significant architecture engineering [32, 35, 11, 36, 34, 41]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14124313,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb42cf88027de515750f230b23b1a057dc782108",
            "isKey": false,
            "numCitedBy": 63195,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision."
            },
            "slug": "Very-Deep-Convolutional-Networks-for-Large-Scale-Simonyan-Zisserman",
            "title": {
                "fragments": [],
                "text": "Very Deep Convolutional Networks for Large-Scale Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This work investigates the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting using an architecture with very small convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 24,
                                "start": 20
                            }
                        ],
                        "text": "The seminal work of [22] on using convolutional architectures [9, 23] for ImageNet classification represents one of the most important breakthroughs in deep learning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 181
                            }
                        ],
                        "text": "We use a common heuristic to double the number of filters in the output whenever the spatial activation size is reduced in order to maintain roughly constant hidden state dimension [22, 32]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 195908774,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "isKey": false,
            "numCitedBy": 82046,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry."
            },
            "slug": "ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever",
            "title": {
                "fragments": [],
                "text": "ImageNet classification with deep convolutional neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A large, deep convolutional neural network was trained to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes and employed a recently developed regularization method called \"dropout\" that proved to be very effective."
            },
            "venue": {
                "fragments": [],
                "text": "Commun. ACM"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2574060"
                        ],
                        "name": "Christian Szegedy",
                        "slug": "Christian-Szegedy",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Szegedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Szegedy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157222093"
                        ],
                        "name": "Wei Liu",
                        "slug": "Wei-Liu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39978391"
                        ],
                        "name": "Yangqing Jia",
                        "slug": "Yangqing-Jia",
                        "structuredName": {
                            "firstName": "Yangqing",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yangqing Jia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3142556"
                        ],
                        "name": "Pierre Sermanet",
                        "slug": "Pierre-Sermanet",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Sermanet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierre Sermanet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144828948"
                        ],
                        "name": "Scott E. Reed",
                        "slug": "Scott-E.-Reed",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Reed",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott E. Reed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1838674"
                        ],
                        "name": "Dragomir Anguelov",
                        "slug": "Dragomir-Anguelov",
                        "structuredName": {
                            "firstName": "Dragomir",
                            "lastName": "Anguelov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dragomir Anguelov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761978"
                        ],
                        "name": "D. Erhan",
                        "slug": "D.-Erhan",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Erhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Erhan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2657155"
                        ],
                        "name": "Vincent Vanhoucke",
                        "slug": "Vincent-Vanhoucke",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Vanhoucke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Vanhoucke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39863668"
                        ],
                        "name": "Andrew Rabinovich",
                        "slug": "Andrew-Rabinovich",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Rabinovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Rabinovich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 367,
                                "start": 351
                            }
                        ],
                        "text": "One inspiration for this search space is the recognition that architecture engineering with CNNs often identifies repeated motifs consisting of combinations of convolutional filter banks, nonlinearities and a prudent selection of connections to achieve state-of-the-art results (such as the repeated modules present in the Inception and ResNet models [35, 11, 36, 34])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 111
                            }
                        ],
                        "text": "Note the prevalence of separable convolutions and the number of branches compared with competing architectures [32, 35, 11, 36, 34]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 51
                            }
                        ],
                        "text": "Importantly, much like Inception and ResNet models [35, 11, 36, 34], we consider the number of motif repetitions N and the number of initial convolutional filters as free parameters that we tailor to the scale of an image classification problem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 166
                            }
                        ],
                        "text": "Successive advancements on this benchmark based on convolutional neural networks (CNNs) have achieved impressive results through significant architecture engineering [32, 35, 11, 36, 34, 41]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206592484,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e15cf50aa89fee8535703b9f9512fca5bfc43327",
            "isKey": true,
            "numCitedBy": 29917,
            "numCiting": 278,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection."
            },
            "slug": "Going-deeper-with-convolutions-Szegedy-Liu",
            "title": {
                "fragments": [],
                "text": "Going deeper with convolutions"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "A deep convolutional neural network architecture codenamed Inception is proposed that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14)."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33493200"
                        ],
                        "name": "Tsung-Yi Lin",
                        "slug": "Tsung-Yi-Lin",
                        "structuredName": {
                            "firstName": "Tsung-Yi",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tsung-Yi Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127283"
                        ],
                        "name": "Piotr Doll\u00e1r",
                        "slug": "Piotr-Doll\u00e1r",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Doll\u00e1r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piotr Doll\u00e1r"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2983898"
                        ],
                        "name": "Ross B. Girshick",
                        "slug": "Ross-B.-Girshick",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Girshick",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross B. Girshick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1790580"
                        ],
                        "name": "Bharath Hariharan",
                        "slug": "Bharath-Hariharan",
                        "structuredName": {
                            "firstName": "Bharath",
                            "lastName": "Hariharan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bharath Hariharan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "ResNet-101-FPN [24] 800 (short side) 36."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10716717,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b9b4e05faa194e5022edd9eb9dd07e3d675c2b36",
            "isKey": false,
            "numCitedBy": 9631,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "Feature pyramids are a basic component in recognition systems for detecting objects at different scales. But pyramid representations have been avoided in recent object detectors that are based on deep convolutional networks, partially because they are slow to compute and memory intensive. In this paper, we exploit the inherent multi-scale, pyramidal hierarchy of deep convolutional networks to construct feature pyramids with marginal extra cost. A top-down architecture with lateral connections is developed for building high-level semantic feature maps at all scales. This architecture, called a Feature Pyramid Network (FPN), shows significant improvement as a generic feature extractor in several applications. Using a basic Faster R-CNN system, our method achieves state-of-the-art single-model results on the COCO detection benchmark without bells and whistles, surpassing all existing single-model entries including those from the COCO 2016 challenge winners. In addition, our method can run at 5 FPS on a GPU and thus is a practical and accurate solution to multi-scale object detection. Code will be made publicly available."
            },
            "slug": "Feature-Pyramid-Networks-for-Object-Detection-Lin-Doll\u00e1r",
            "title": {
                "fragments": [],
                "text": "Feature Pyramid Networks for Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper exploits the inherent multi-scale, pyramidal hierarchy of deep convolutional networks to construct feature pyramids with marginal extra cost and achieves state-of-the-art single-model results on the COCO detection benchmark without bells and whistles."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771551"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3080683"
                        ],
                        "name": "Shaoqing Ren",
                        "slug": "Shaoqing-Ren",
                        "structuredName": {
                            "firstName": "Shaoqing",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoqing Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 367,
                                "start": 351
                            }
                        ],
                        "text": "One inspiration for this search space is the recognition that architecture engineering with CNNs often identifies repeated motifs consisting of combinations of convolutional filter banks, nonlinearities and a prudent selection of connections to achieve state-of-the-art results (such as the repeated modules present in the Inception and ResNet models [35, 11, 36, 34])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 111
                            }
                        ],
                        "text": "Note the prevalence of separable convolutions and the number of branches compared with competing architectures [32, 35, 11, 36, 34]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 51
                            }
                        ],
                        "text": "Importantly, much like Inception and ResNet models [35, 11, 36, 34], we consider the number of motif repetitions N and the number of initial convolutional filters as free parameters that we tailor to the scale of an image classification problem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 166
                            }
                        ],
                        "text": "Successive advancements on this benchmark based on convolutional neural networks (CNNs) have achieved impressive results through significant architecture engineering [32, 35, 11, 36, 34, 41]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206594692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "isKey": true,
            "numCitedBy": 97653,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation."
            },
            "slug": "Deep-Residual-Learning-for-Image-Recognition-He-Zhang",
            "title": {
                "fragments": [],
                "text": "Deep Residual Learning for Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work presents a residual learning framework to ease the training of networks that are substantially deeper than those used previously, and provides comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7408951"
                        ],
                        "name": "Jeff Donahue",
                        "slug": "Jeff-Donahue",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Donahue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeff Donahue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39978391"
                        ],
                        "name": "Yangqing Jia",
                        "slug": "Yangqing-Jia",
                        "structuredName": {
                            "firstName": "Yangqing",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yangqing Jia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50196944"
                        ],
                        "name": "Judy Hoffman",
                        "slug": "Judy-Hoffman",
                        "structuredName": {
                            "firstName": "Judy",
                            "lastName": "Hoffman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Judy Hoffman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152329702"
                        ],
                        "name": "Ning Zhang",
                        "slug": "Ning-Zhang",
                        "structuredName": {
                            "firstName": "Ning",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ning Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2368132"
                        ],
                        "name": "Eric Tzeng",
                        "slug": "Eric-Tzeng",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Tzeng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric Tzeng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 122,
                                "start": 119
                            }
                        ],
                        "text": "Image classification networks provide generic image features that may be transferred to other computer vision problems [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 199,
                                "start": 196
                            }
                        ],
                        "text": "For example, features from networks that perform well on ImageNet classification provide state-of-the-art performance when transferred to other computer vision tasks where labeled data is limited [8]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6161478,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b8de958fead0d8a9619b55c7299df3257c624a96",
            "isKey": false,
            "numCitedBy": 4275,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be repurposed to novel generic tasks. Our generic tasks may differ significantly from the originally trained tasks and there may be insufficient labeled or unlabeled data to conventionally train or adapt a deep architecture to the new tasks. We investigate and visualize the semantic clustering of deep convolutional features with respect to a variety of such tasks, including scene recognition, domain adaptation, and fine-grained recognition challenges. We compare the efficacy of relying on various network levels to define a fixed feature, and report novel results that significantly outperform the state-of-the-art on several important vision challenges. We are releasing DeCAF, an open-source implementation of these deep convolutional activation features, along with all associated network parameters to enable vision researchers to be able to conduct experimentation with deep representations across a range of visual concept learning paradigms."
            },
            "slug": "DeCAF:-A-Deep-Convolutional-Activation-Feature-for-Donahue-Jia",
            "title": {
                "fragments": [],
                "text": "DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "DeCAF, an open-source implementation of deep convolutional activation features, along with all associated network parameters, are released to enable vision researchers to be able to conduct experimentation with deep representations across a range of visual concept learning paradigms."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32097919"
                        ],
                        "name": "Terrance Devries",
                        "slug": "Terrance-Devries",
                        "structuredName": {
                            "firstName": "Terrance",
                            "lastName": "Devries",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Terrance Devries"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144639556"
                        ],
                        "name": "Graham W. Taylor",
                        "slug": "Graham-W.-Taylor",
                        "structuredName": {
                            "firstName": "Graham",
                            "lastName": "Taylor",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Graham W. Taylor"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 88,
                                "start": 84
                            }
                        ],
                        "text": "As can be seen from the Table, a large NASNet-A model with cutout data augmentation [12] achieves a state-of-the-art error rate of 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "86 Shake-Shake 26 2x96d + cutout [12] 26 26."
                    },
                    "intents": []
                }
            ],
            "corpusId": 23714201,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb35fdc11a325f21a8ce0ca65058f7480a2fc91f",
            "isKey": false,
            "numCitedBy": 1727,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional neural networks are capable of learning powerful representational spaces, which are necessary for tackling complex learning tasks. However, due to the model capacity required to capture such representations, they are often susceptible to overfitting and therefore require proper regularization in order to generalize well. In this paper, we show that the simple regularization technique of randomly masking out square regions of input during training, which we call cutout, can be used to improve the robustness and overall performance of convolutional neural networks. Not only is this method extremely easy to implement, but we also demonstrate that it can be used in conjunction with existing forms of data augmentation and other regularizers to further improve model performance. We evaluate this method by applying it to current state-of-the-art architectures on the CIFAR-10, CIFAR-100, and SVHN datasets, yielding new state-of-the-art results of 2.56%, 15.20%, and 1.30% test error respectively. Code is available at this https URL"
            },
            "slug": "Improved-Regularization-of-Convolutional-Neural-Devries-Taylor",
            "title": {
                "fragments": [],
                "text": "Improved Regularization of Convolutional Neural Networks with Cutout"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper shows that the simple regularization technique of randomly masking out square regions of input during training, which is called cutout, can be used to improve the robustness and overall performance of convolutional neural networks."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3041937"
                        ],
                        "name": "Lingxi Xie",
                        "slug": "Lingxi-Xie",
                        "structuredName": {
                            "firstName": "Lingxi",
                            "lastName": "Xie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lingxi Xie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A more flexible class of methods for designing architecture is evolutionary algorithms [65, 16, 57, 30, 46, 42, 67], yet they have not had as much success at large scale."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Xie and Yuille [67] also transferred learned architectures from CIFAR-10 to ImageNet but performance of these models (top-1 accuracy 72."
                    },
                    "intents": []
                }
            ],
            "corpusId": 206770867,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4f46dba09e075b2e7dfae1ba2a71e8e21b46e88d",
            "isKey": false,
            "numCitedBy": 512,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "The deep convolutional neural network (CNN) is the state-of-the-art solution for large-scale visual recognition. Following some basic principles such as increasing network depth and constructing highway connections, researchers have manually designed a lot of fixed network architectures and verified their effectiveness.,,In this paper, we discuss the possibility of learning deep network structures automatically. Note that the number of possible network structures increases exponentially with the number of layers in the network, which motivates us to adopt the genetic algorithm to efficiently explore this large search space. The core idea is to propose an encoding method to represent each network structure in a fixed-length binary string. The genetic algorithm is initialized by generating a set of randomized individuals. In each generation, we define standard genetic operations, e.g., selection, mutation and crossover, to generate competitive individuals and eliminate weak ones. The competitiveness of each individual is defined as its recognition accuracy, which is obtained via a standalone training process on a reference dataset. We run the genetic process on CIFAR10, a small-scale dataset, demonstrating its ability to find high-quality structures which are little studied before. The learned powerful structures are also transferrable to the ILSVRC2012 dataset for large-scale visual recognition."
            },
            "slug": "Genetic-CNN-Xie-Yuille",
            "title": {
                "fragments": [],
                "text": "Genetic CNN"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The core idea is to propose an encoding method to represent each network structure in a fixed-length binary string to efficiently explore this large search space."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE International Conference on Computer Vision (ICCV)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46708564"
                        ],
                        "name": "S. Saxena",
                        "slug": "S.-Saxena",
                        "structuredName": {
                            "firstName": "Shreya",
                            "lastName": "Saxena",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Saxena"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34602236"
                        ],
                        "name": "Jakob Verbeek",
                        "slug": "Jakob-Verbeek",
                        "structuredName": {
                            "firstName": "Jakob",
                            "lastName": "Verbeek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jakob Verbeek"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": " Related Work The proposed method is related to previous work in hyperparameter optimization [44, 4, 5, 54, 55, 6, 40] \u2013 especially recent approaches in designing architectures such as Neural Fabrics [48], DiffRNN [41], MetaQNN [3] and DeepArchitect [43]. A more \ufb02exible class of methods for designing architecture is evolutionary algorithms [65, 16, 57, 30, 46, 42, 67], yet they have not had as much su"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 438087,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "197c8988ef21d0b58d363c21bafe1900c3089e3e",
            "isKey": false,
            "numCitedBy": 193,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Despite the success of CNNs, selecting the optimal architecture for a given task remains an open problem. Instead of aiming to select a single optimal architecture, we propose a \"fabric\" that embeds an exponentially large number of architectures. The fabric consists of a 3D trellis that connects response maps at different layers, scales, and channels with a sparse homogeneous local connectivity pattern. The only hyper-parameters of a fabric are the number of channels and layers. While individual architectures can be recovered as paths, the fabric can in addition ensemble all embedded architectures together, sharing their weights where their paths overlap. Parameters can be learned using standard methods based on back-propagation, at a cost that scales linearly in the fabric size. We present benchmark results competitive with the state of the art for image classification on MNIST and CIFAR10, and for semantic segmentation on the Part Labels dataset."
            },
            "slug": "Convolutional-Neural-Fabrics-Saxena-Verbeek",
            "title": {
                "fragments": [],
                "text": "Convolutional Neural Fabrics"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A \"fabric\" that embeds an exponentially large number of architectures that is competitive with the state of the art for image classification on MNIST and CIFAR10, and for semantic segmentation on the Part Labels dataset."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2892780"
                        ],
                        "name": "Esteban Real",
                        "slug": "Esteban-Real",
                        "structuredName": {
                            "firstName": "Esteban",
                            "lastName": "Real",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Esteban Real"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144375552"
                        ],
                        "name": "Sherry Moore",
                        "slug": "Sherry-Moore",
                        "structuredName": {
                            "firstName": "Sherry",
                            "lastName": "Moore",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sherry Moore"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714992"
                        ],
                        "name": "Andrew Selle",
                        "slug": "Andrew-Selle",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Selle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Selle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054003577"
                        ],
                        "name": "Saurabh Saxena",
                        "slug": "Saurabh-Saxena",
                        "structuredName": {
                            "firstName": "Saurabh",
                            "lastName": "Saxena",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Saurabh Saxena"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46901409"
                        ],
                        "name": "Y. Suematsu",
                        "slug": "Y.-Suematsu",
                        "structuredName": {
                            "firstName": "Yutaka",
                            "lastName": "Suematsu",
                            "middleNames": [
                                "Leon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Suematsu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1739176520"
                        ],
                        "name": "Jie Tan",
                        "slug": "Jie-Tan",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Tan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Tan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145714153"
                        ],
                        "name": "A. Kurakin",
                        "slug": "A.-Kurakin",
                        "structuredName": {
                            "firstName": "Alexey",
                            "lastName": "Kurakin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Kurakin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "A more flexible class of methods for designing architecture is evolutionary algorithms [65, 16, 57, 30, 46, 42, 67], yet they have not had as much success at large scale."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 743641,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f108b65fe0003e387e1cd7e50f537af0531818e4",
            "isKey": false,
            "numCitedBy": 1118,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural networks have proven effective at solving difficult problems but designing their architectures can be challenging, even for image classification problems alone. Our goal is to minimize human participation, so we employ evolutionary algorithms to discover such networks automatically. Despite significant computational requirements, we show that it is now possible to evolve models with accuracies within the range of those published in the last year. Specifically, we employ simple evolutionary techniques at unprecedented scales to discover models for the CIFAR-10 and CIFAR-100 datasets, starting from trivial initial conditions and reaching accuracies of 94.6% (95.6% for ensemble) and 77.0%, respectively. To do this, we use novel and intuitive mutation operators that navigate large search spaces; we stress that no human participation is required once evolution starts and that the output is a fully-trained model. Throughout this work, we place special emphasis on the repeatability of results, the variability in the outcomes and the computational requirements."
            },
            "slug": "Large-Scale-Evolution-of-Image-Classifiers-Real-Moore",
            "title": {
                "fragments": [],
                "text": "Large-Scale Evolution of Image Classifiers"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is shown that it is now possible to evolve models with accuracies within the range of those published in the last year, starting from trivial initial conditions and reaching accuracies of 94.6% and 77.0%, respectively."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145815850"
                        ],
                        "name": "Jie Hu",
                        "slug": "Jie-Hu",
                        "structuredName": {
                            "firstName": "Jie",
                            "lastName": "Hu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jie Hu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152148573"
                        ],
                        "name": "Li Shen",
                        "slug": "Li-Shen",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Shen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Shen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7641268"
                        ],
                        "name": "Samuel Albanie",
                        "slug": "Samuel-Albanie",
                        "structuredName": {
                            "firstName": "Samuel",
                            "lastName": "Albanie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samuel Albanie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2087137982"
                        ],
                        "name": "Gang Sun",
                        "slug": "Gang-Sun",
                        "structuredName": {
                            "firstName": "Gang",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gang Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145344139"
                        ],
                        "name": "E. Wu",
                        "slug": "E.-Wu",
                        "structuredName": {
                            "firstName": "Enhua",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Wu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "Model size for [15] calculated from open-source implementation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 3
                            }
                        ],
                        "text": "7% [15], while having significantly fewer floating point operations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 140309863,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df67d46e78aae0d2fccfb6212d101a342259c01b",
            "isKey": false,
            "numCitedBy": 7692,
            "numCiting": 90,
            "paperAbstract": {
                "fragments": [],
                "text": "The central building block of convolutional neural networks (CNNs) is the convolution operator, which enables networks to construct informative features by fusing both spatial and channel-wise information within local receptive fields at each layer. A broad range of prior research has investigated the spatial component of this relationship, seeking to strengthen the representational power of a CNN by enhancing the quality of spatial encodings throughout its feature hierarchy. In this work, we focus instead on the channel relationship and propose a novel architectural unit, which we term the \u201cSqueeze-and-Excitation\u201d (SE) block, that adaptively recalibrates channel-wise feature responses by explicitly modelling interdependencies between channels. We show that these blocks can be stacked together to form SENet architectures that generalise extremely effectively across different datasets. We further demonstrate that SE blocks bring significant improvements in performance for existing state-of-the-art CNNs at slight additional computational cost. Squeeze-and-Excitation Networks formed the foundation of our ILSVRC 2017 classification submission which won first place and reduced the top-5 error to 2.251 percent, surpassing the winning entry of 2016 by a relative improvement of <inline-formula><tex-math notation=\"LaTeX\">${\\sim }$</tex-math><alternatives><mml:math><mml:mo>\u223c</mml:mo></mml:math><inline-graphic xlink:href=\"shen-ieq1-2913372.gif\"/></alternatives></inline-formula>25 percent. Models and code are available at <uri>https://github.com/hujie-frank/SENet</uri>."
            },
            "slug": "Squeeze-and-Excitation-Networks-Hu-Shen",
            "title": {
                "fragments": [],
                "text": "Squeeze-and-Excitation Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes a novel architectural unit, which is term the \u201cSqueeze-and-Excitation\u201d (SE) block, that adaptively recalibrates channel-wise feature responses by explicitly modelling interdependencies between channels and shows that these blocks can be stacked together to form SENet architectures that generalise extremely effectively across different datasets."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2020
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "In summary, all architecture searches are performed using the CIFAR-10 classification task [21]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18268744,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5d90f06bb70a0a3dced62413346235c02b1aa086",
            "isKey": false,
            "numCitedBy": 17474,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Groups at MIT and NYU have collected a dataset of millions of tiny colour images from the web. It is, in principle, an excellent dataset for unsupervised training of deep generative models, but previous researchers who have tried this have found it dicult to learn a good set of lters from the images. We show how to train a multi-layer generative model that learns to extract meaningful features which resemble those found in the human visual cortex. Using a novel parallelization algorithm to distribute the work among multiple machines connected on a network, we show how training such a model can be done in reasonable time. A second problematic aspect of the tiny images dataset is that there are no reliable class labels which makes it hard to use for object recognition experiments. We created two sets of reliable labels. The CIFAR-10 set has 6000 examples of each of 10 classes and the CIFAR-100 set has 600 examples of each of 100 non-overlapping classes. Using these labels, we show that object recognition is signicantly improved by pre-training a layer of features on a large set of unlabeled tiny images."
            },
            "slug": "Learning-Multiple-Layers-of-Features-from-Tiny-Krizhevsky",
            "title": {
                "fragments": [],
                "text": "Learning Multiple Layers of Features from Tiny Images"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "It is shown how to train a multi-layer generative model that learns to extract meaningful features which resemble those found in the human visual cortex, using a novel parallelization algorithm to distribute the work among multiple machines connected on a network."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2368067"
                        ],
                        "name": "Barret Zoph",
                        "slug": "Barret-Zoph",
                        "structuredName": {
                            "firstName": "Barret",
                            "lastName": "Zoph",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barret Zoph"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 39
                            }
                        ],
                        "text": "Overview of Neural Architecture Search [44]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "Our approach makes use of the recently proposed Neural Architecture Search (NAS) framework [44], which uses a policy gradient algorithm to optimize architecture configurations."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 80
                            }
                        ],
                        "text": "We note that this search procedure is almost 7\u00d7 faster than previous approaches [44]"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "2In particular, we note that previous architecture search [44] employed 800 GPUs for 28 days resulting in 22,400 GPU-hours."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 106
                            }
                        ],
                        "text": "However, if the search space is properly constructed, architectural elements can transfer across datasets [44]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 85,
                                "start": 81
                            }
                        ],
                        "text": "Our work makes use of the Neural Architecture Search (NAS) framework proposed by [44]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 135
                            }
                        ],
                        "text": "First, note that the resulting network architectures are comparable to or surpass architectures identified through earlier NAS methods [44]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                }
            ],
            "corpusId": 12713052,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "67d968c7450878190e45ac7886746de867bf673d",
            "isKey": false,
            "numCitedBy": 3482,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural networks are powerful and flexible models that work well for many difficult learning tasks in image, speech and natural language understanding. Despite their success, neural networks are still hard to design. In this paper, we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set. On the CIFAR-10 dataset, our method, starting from scratch, can design a novel network architecture that rivals the best human-invented architecture in terms of test set accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is 0.09 percent better and 1.05x faster than the previous state-of-the-art model that used a similar architectural scheme. On the Penn Treebank dataset, our model can compose a novel recurrent cell that outperforms the widely-used LSTM cell, and other state-of-the-art baselines. Our cell achieves a test set perplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than the previous state-of-the-art model. The cell can also be transferred to the character language modeling task on PTB and achieves a state-of-the-art perplexity of 1.214."
            },
            "slug": "Neural-Architecture-Search-with-Reinforcement-Zoph-Le",
            "title": {
                "fragments": [],
                "text": "Neural Architecture Search with Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper uses a recurrent network to generate the model descriptions of neural networks and trains this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143983679"
                        ],
                        "name": "Gao Huang",
                        "slug": "Gao-Huang",
                        "structuredName": {
                            "firstName": "Gao",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gao Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109168016"
                        ],
                        "name": "Zhuang Liu",
                        "slug": "Zhuang-Liu",
                        "structuredName": {
                            "firstName": "Zhuang",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhuang Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7446832"
                        ],
                        "name": "Kilian Q. Weinberger",
                        "slug": "Kilian-Q.-Weinberger",
                        "structuredName": {
                            "firstName": "Kilian",
                            "lastName": "Weinberger",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kilian Q. Weinberger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 29
                            }
                        ],
                        "text": "24 DenseNet(L = 100, k = 12) [16] 100 7."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 33
                            }
                        ],
                        "text": "74 DenseNet-BC (L = 100, k = 40) [16] 190 25."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "10 DenseNet (L = 100, k = 24) [16] 100 27."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9433631,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5694e46284460a648fe29117cbc55f6c9be3fa3c",
            "isKey": true,
            "numCitedBy": 19204,
            "numCiting": 58,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections&#x2014;one between each layer and its subsequent layer&#x2014;our network has L(L+1)/2 direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less memory and computation to achieve high performance. Code and pre-trained models are available at https://github.com/liuzhuang13/DenseNet."
            },
            "slug": "Densely-Connected-Convolutional-Networks-Huang-Liu",
            "title": {
                "fragments": [],
                "text": "Densely Connected Convolutional Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion, and has several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3080683"
                        ],
                        "name": "Shaoqing Ren",
                        "slug": "Shaoqing-Ren",
                        "structuredName": {
                            "firstName": "Shaoqing",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoqing Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2983898"
                        ],
                        "name": "Ross B. Girshick",
                        "slug": "Ross-B.-Girshick",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Girshick",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross B. Girshick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2032184078"
                        ],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "All results employ Faster-RCNN object detection framework [28] from a single crop of an image."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 117
                            }
                        ],
                        "text": "In our experiments, the features learned from ImageNet classification can be combined with the Faster-RCNN framework [28] to achieve state-of-the-art on COCO object detection task for both the largest as well as mobile-optimized models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 92,
                                "start": 88
                            }
                        ],
                        "text": "NASNet-A networks pretrained on ImageNet into the Faster-RCNN object detection pipeline [28] using an opensource software platform [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10328909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270",
            "isKey": false,
            "numCitedBy": 33308,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features---using the recently popular terminology of neural networks with 'attention' mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model, our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available"
            },
            "slug": "Faster-R-CNN:-Towards-Real-Time-Object-Detection-Ren-He",
            "title": {
                "fragments": [],
                "text": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work introduces a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals and further merge RPN and Fast R-CNN into a single network by sharing their convolutionAL features."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1565641737"
                        ],
                        "name": "Fran\u00e7ois Chollet",
                        "slug": "Fran\u00e7ois-Chollet",
                        "structuredName": {
                            "firstName": "Fran\u00e7ois",
                            "lastName": "Chollet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Fran\u00e7ois Chollet"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 193,
                                "start": 186
                            }
                        ],
                        "text": "The modular structure of the convolutional cell is also related to previous methods on ImageNet such as VGG [53], Inception [59, 60, 58], ResNet/ResNext [20, 68], and Xception/MobileNet [9, 24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2375110,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5b6ec746d309b165f9f9def873a2375b6fb40f3d",
            "isKey": false,
            "numCitedBy": 6758,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "We present an interpretation of Inception modules in convolutional neural networks as being an intermediate step in-between regular convolution and the depthwise separable convolution operation (a depthwise convolution followed by a pointwise convolution). In this light, a depthwise separable convolution can be understood as an Inception module with a maximally large number of towers. This observation leads us to propose a novel deep convolutional neural network architecture inspired by Inception, where Inception modules have been replaced with depthwise separable convolutions. We show that this architecture, dubbed Xception, slightly outperforms Inception V3 on the ImageNet dataset (which Inception V3 was designed for), and significantly outperforms Inception V3 on a larger image classification dataset comprising 350 million images and 17,000 classes. Since the Xception architecture has the same number of parameters as Inception V3, the performance gains are not due to increased capacity but rather to a more efficient use of model parameters."
            },
            "slug": "Xception:-Deep-Learning-with-Depthwise-Separable-Chollet",
            "title": {
                "fragments": [],
                "text": "Xception: Deep Learning with Depthwise Separable Convolutions"
            },
            "tldr": {
                "abstractSimilarityScore": 50,
                "text": "This work proposes a novel deep convolutional neural network architecture inspired by Inception, where Inception modules have been replaced with depthwise separable convolutions, and shows that this architecture, dubbed Xception, slightly outperforms Inception V3 on the ImageNet dataset, and significantly outperforms it on a larger image classification dataset."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2574060"
                        ],
                        "name": "Christian Szegedy",
                        "slug": "Christian-Szegedy",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Szegedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Szegedy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2657155"
                        ],
                        "name": "Vincent Vanhoucke",
                        "slug": "Vincent-Vanhoucke",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Vanhoucke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Vanhoucke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054165706"
                        ],
                        "name": "S. Ioffe",
                        "slug": "S.-Ioffe",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Ioffe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ioffe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789737"
                        ],
                        "name": "Jonathon Shlens",
                        "slug": "Jonathon-Shlens",
                        "structuredName": {
                            "firstName": "Jonathon",
                            "lastName": "Shlens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathon Shlens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3282833"
                        ],
                        "name": "Z. Wojna",
                        "slug": "Z.-Wojna",
                        "structuredName": {
                            "firstName": "Zbigniew",
                            "lastName": "Wojna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Wojna"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 367,
                                "start": 351
                            }
                        ],
                        "text": "One inspiration for this search space is the recognition that architecture engineering with CNNs often identifies repeated motifs consisting of combinations of convolutional filter banks, nonlinearities and a prudent selection of connections to achieve state-of-the-art results (such as the repeated modules present in the Inception and ResNet models [35, 11, 36, 34])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 291,
                                "start": 287
                            }
                        ],
                        "text": "In the first set of experiments, we train several image classification systems operating on 299x299 or 331x331 resolution images with different experiments scaled in computational demand to create models that are roughly on par in computational cost with Inception-v2 [19], Inception-v3 [36] and PolyNet [42]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 45
                            }
                        ],
                        "text": "Our training setup on ImageNet is similar to [36], but please see Appendix A for details."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 51
                            }
                        ],
                        "text": "Importantly, much like Inception and ResNet models [35, 11, 36, 34], we consider the number of motif repetitions N and the number of initial convolutional filters as free parameters that we tailor to the scale of an image classification problem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 166
                            }
                        ],
                        "text": "Successive advancements on this benchmark based on convolutional neural networks (CNNs) have achieved impressive results through significant architecture engineering [32, 35, 11, 36, 34, 41]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 178
                            }
                        ],
                        "text": "The resulting architectures approach or exceed stateof-the-art performance in both CIFAR-10 and ImageNet datasets with less computational demand than humandesigned architectures [36, 19, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 182
                            }
                        ],
                        "text": "Thanks to this property of the cells, we can generate a family of models that achieve accuracies superior to all human-invented models at equivalent or smaller computational budgets [36, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 111
                            }
                        ],
                        "text": "Note the prevalence of separable convolutions and the number of branches compared with competing architectures [32, 35, 11, 36, 34]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206593880,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23ffaa0fe06eae05817f527a47ac3291077f9e58",
            "isKey": false,
            "numCitedBy": 15857,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional networks are at the core of most state of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21:2% top-1 and 5:6% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3:5% top-5 error and 17:3% top-1 error on the validation set and 3:6% top-5 error on the official test set."
            },
            "slug": "Rethinking-the-Inception-Architecture-for-Computer-Szegedy-Vanhoucke",
            "title": {
                "fragments": [],
                "text": "Rethinking the Inception Architecture for Computer Vision"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work is exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3302320"
                        ],
                        "name": "Florian Schroff",
                        "slug": "Florian-Schroff",
                        "structuredName": {
                            "firstName": "Florian",
                            "lastName": "Schroff",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Florian Schroff"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741985"
                        ],
                        "name": "Dmitry Kalenichenko",
                        "slug": "Dmitry-Kalenichenko",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Kalenichenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dmitry Kalenichenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066819269"
                        ],
                        "name": "James Philbin",
                        "slug": "James-Philbin",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Philbin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Philbin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": ", object detection [18], face detection [29], image localization [39]) derive image features or architectures from ImageNet classification models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206592766,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5aa26299435bdf7db874ef1640a6c3b5a4a2c394",
            "isKey": false,
            "numCitedBy": 8302,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "Despite significant recent advances in the field of face recognition [10, 14, 15, 17], implementing face verification and recognition efficiently at scale presents serious challenges to current approaches. In this paper we present a system, called FaceNet, that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure offace similarity. Once this space has been produced, tasks such as face recognition, verification and clustering can be easily implemented using standard techniques with FaceNet embeddings asfeature vectors. Our method uses a deep convolutional network trained to directly optimize the embedding itself, rather than an intermediate bottleneck layer as in previous deep learning approaches. To train, we use triplets of roughly aligned matching / non-matching face patches generated using a novel online triplet mining method. The benefit of our approach is much greater representational efficiency: we achieve state-of-the-artface recognition performance using only 128-bytes perface. On the widely used Labeled Faces in the Wild (LFW) dataset, our system achieves a new record accuracy of 99.63%. On YouTube Faces DB it achieves 95.12%. Our system cuts the error rate in comparison to the best published result [15] by 30% on both datasets."
            },
            "slug": "FaceNet:-A-unified-embedding-for-face-recognition-Schroff-Kalenichenko",
            "title": {
                "fragments": [],
                "text": "FaceNet: A unified embedding for face recognition and clustering"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A system that directly learns a mapping from face images to a compact Euclidean space where distances directly correspond to a measure offace similarity, and achieves state-of-the-art face recognition performance using only 128-bytes perface."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52495223"
                        ],
                        "name": "Olga Wichrowska",
                        "slug": "Olga-Wichrowska",
                        "structuredName": {
                            "firstName": "Olga",
                            "lastName": "Wichrowska",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Olga Wichrowska"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2333223"
                        ],
                        "name": "Niru Maheswaranathan",
                        "slug": "Niru-Maheswaranathan",
                        "structuredName": {
                            "firstName": "Niru",
                            "lastName": "Maheswaranathan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Niru Maheswaranathan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3243579"
                        ],
                        "name": "Matthew W. Hoffman",
                        "slug": "Matthew-W.-Hoffman",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hoffman",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew W. Hoffman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2016840"
                        ],
                        "name": "Sergio Gomez Colmenarejo",
                        "slug": "Sergio-Gomez-Colmenarejo",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Colmenarejo",
                            "middleNames": [
                                "Gomez"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sergio Gomez Colmenarejo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715051"
                        ],
                        "name": "Misha Denil",
                        "slug": "Misha-Denil",
                        "structuredName": {
                            "firstName": "Misha",
                            "lastName": "Denil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Misha Denil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1407546424"
                        ],
                        "name": "Jascha Narain Sohl-Dickstein",
                        "slug": "Jascha-Narain-Sohl-Dickstein",
                        "structuredName": {
                            "firstName": "Jascha",
                            "lastName": "Sohl-Dickstein",
                            "middleNames": [
                                "Narain"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jascha Narain Sohl-Dickstein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 128
                            }
                        ],
                        "text": "An exception is the recent work focused on learning an optimizer for ImageNet classification that achieved notable improvements [64]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12885891,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b8ff7e02ffa1577d125acd3e998e8ce76a9059dc",
            "isKey": false,
            "numCitedBy": 180,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning to learn has emerged as an important direction for achieving artificial intelligence. Two of the primary barriers to its adoption are an inability to scale to larger problems and a limited ability to generalize to new tasks. We introduce a learned gradient descent optimizer that generalizes well to new tasks, and which has significantly reduced memory and computation overhead. We achieve this by introducing a novel hierarchical RNN architecture, with minimal per-parameter overhead, augmented with additional architectural features that mirror the known structure of optimization tasks. We also develop a meta-training ensemble of small, diverse, optimization tasks capturing common properties of loss landscapes. The optimizer learns to outperform RMSProp/ADAM on problems in this corpus. More importantly, it performs comparably or better when applied to small convolutional neural networks, despite seeing no neural networks in its meta-training set. Finally, it generalizes to train Inception V3 and ResNet V2 architectures on the ImageNet dataset for thousands of steps, optimization problems that are of a vastly different scale than those it was trained on."
            },
            "slug": "Learned-Optimizers-that-Scale-and-Generalize-Wichrowska-Maheswaranathan",
            "title": {
                "fragments": [],
                "text": "Learned Optimizers that Scale and Generalize"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work introduces a learned gradient descent optimizer that generalizes well to new tasks, and which has significantly reduced memory and computation overhead, by introducing a novel hierarchical RNN architecture with minimal per-parameter overhead."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2136435893"
                        ],
                        "name": "Jonathan Huang",
                        "slug": "Jonathan-Huang",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1382126732"
                        ],
                        "name": "V. Rathod",
                        "slug": "V.-Rathod",
                        "structuredName": {
                            "firstName": "Vivek",
                            "lastName": "Rathod",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Rathod"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1491624845"
                        ],
                        "name": "Chen Sun",
                        "slug": "Chen-Sun",
                        "structuredName": {
                            "firstName": "Chen",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chen Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2717876"
                        ],
                        "name": "Menglong Zhu",
                        "slug": "Menglong-Zhu",
                        "structuredName": {
                            "firstName": "Menglong",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Menglong Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34786378"
                        ],
                        "name": "A. Balan",
                        "slug": "A.-Balan",
                        "structuredName": {
                            "firstName": "Anoop",
                            "lastName": "Balan",
                            "middleNames": [
                                "Korattikara"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Balan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50706340"
                        ],
                        "name": "A. Fathi",
                        "slug": "A.-Fathi",
                        "structuredName": {
                            "firstName": "Alireza",
                            "lastName": "Fathi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Fathi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33091759"
                        ],
                        "name": "Ian S. Fischer",
                        "slug": "Ian-S.-Fischer",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Fischer",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian S. Fischer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3282833"
                        ],
                        "name": "Z. Wojna",
                        "slug": "Z.-Wojna",
                        "structuredName": {
                            "firstName": "Zbigniew",
                            "lastName": "Wojna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Wojna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157997231"
                        ],
                        "name": "Yang Song",
                        "slug": "Yang-Song",
                        "structuredName": {
                            "firstName": "Yang",
                            "lastName": "Song",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yang Song"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687120"
                        ],
                        "name": "S. Guadarrama",
                        "slug": "S.-Guadarrama",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Guadarrama",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Guadarrama"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702318"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": ", [28])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "To further validate the performance of the family of NASNet-A networks, we test whether object detection systems derived from NASNet-A lead to improvements in object detection [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "0% [28, 52] (see Appendix for example detections on images and sideby-side comparisons)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": ", object detection [28], face detection [50], image localization [63]) derive image features or architectures from ImageNet classification models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "2% Inception-ResNet-v2 (G-RMI) [28] 600\u00d7 600 35."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "All mini-val results employ the same 8K subset of validation images in [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "We evaluate the model on the COCO mini-val [28] and test-dev dataset and report the mean average precision (mAP) as computed with the standard COCO metric library [38]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "To address this question, we plug in the family of NASNet-A networks pretrained on ImageNet into the Faster-RCNN object detection pipeline [47] using an opensource software platform [28]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206595627,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a312a573ef81793d56401e932ef6c9498791a3d1",
            "isKey": true,
            "numCitedBy": 2017,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "The goal of this paper is to serve as a guide for selecting a detection architecture that achieves the right speed/memory/accuracy balance for a given application and platform. To this end, we investigate various ways to trade accuracy for speed and memory usage in modern convolutional object detection systems. A number of successful systems have been proposed in recent years, but apples-toapples comparisons are difficult due to different base feature extractors (e.g., VGG, Residual Networks), different default image resolutions, as well as different hardware and software platforms. We present a unified implementation of the Faster R-CNN [30], R-FCN [6] and SSD [25] systems, which we view as meta-architectures and trace out the speed/accuracy trade-off curve created by using alternative feature extractors and varying other critical parameters such as image size within each of these meta-architectures. On one extreme end of this spectrum where speed and memory are critical, we present a detector that achieves real time speeds and can be deployed on a mobile device. On the opposite end in which accuracy is critical, we present a detector that achieves state-of-the-art performance measured on the COCO detection task."
            },
            "slug": "Speed/Accuracy-Trade-Offs-for-Modern-Convolutional-Huang-Rathod",
            "title": {
                "fragments": [],
                "text": "Speed/Accuracy Trade-Offs for Modern Convolutional Object Detectors"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A unified implementation of the Faster R-CNN, R-FCN and SSD systems is presented and the speed/accuracy trade-off curve created by using alternative feature extractors and varying other critical parameters such as image size within each of these meta-architectures is traced out."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2144861793"
                        ],
                        "name": "Yunpeng Chen",
                        "slug": "Yunpeng-Chen",
                        "structuredName": {
                            "firstName": "Yunpeng",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yunpeng Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46276098"
                        ],
                        "name": "Jianan Li",
                        "slug": "Jianan-Li",
                        "structuredName": {
                            "firstName": "Jianan",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianan Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755210"
                        ],
                        "name": "Huaxin Xiao",
                        "slug": "Huaxin-Xiao",
                        "structuredName": {
                            "firstName": "Huaxin",
                            "lastName": "Xiao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huaxin Xiao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2103483"
                        ],
                        "name": "Xiaojie Jin",
                        "slug": "Xiaojie-Jin",
                        "structuredName": {
                            "firstName": "Xiaojie",
                            "lastName": "Jin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiaojie Jin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143653681"
                        ],
                        "name": "Shuicheng Yan",
                        "slug": "Shuicheng-Yan",
                        "structuredName": {
                            "firstName": "Shuicheng",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuicheng Yan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33221685"
                        ],
                        "name": "Jiashi Feng",
                        "slug": "Jiashi-Feng",
                        "structuredName": {
                            "firstName": "Jiashi",
                            "lastName": "Feng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jiashi Feng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 35602767,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d7ddad7bbda29de7676c21bfeac6be2ce0a07d6f",
            "isKey": false,
            "numCitedBy": 566,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work, we present a simple, highly efficient and modularized Dual Path Network (DPN) for image classification which presents a new topology of connection paths internally. By revealing the equivalence of the state-of-the-art Residual Network (ResNet) and Densely Convolutional Network (DenseNet) within the HORNN framework, we find that ResNet enables feature re-usage while DenseNet enables new features exploration which are both important for learning good representations. To enjoy the benefits from both path topologies, our proposed Dual Path Network shares common features while maintaining the flexibility to explore new features through dual path architectures. Extensive experiments on three benchmark datasets, ImagNet-1k, Places365 and PASCAL VOC, clearly demonstrate superior performance of the proposed DPN over state-of-the-arts. In particular, on the ImagNet-1k dataset, a shallow DPN surpasses the best ResNeXt-101(64x4d) with 26% smaller model size, 25% less computational cost and 8% lower memory consumption, and a deeper DPN (DPN-131) further pushes the state-of-the-art single model performance with about 2 times faster training speed. Experiments on the Places365 large-scale scene dataset, PASCAL VOC detection dataset, and PASCAL VOC segmentation dataset also demonstrate its consistently better performance than DenseNet, ResNet and the latest ResNeXt model over various applications."
            },
            "slug": "Dual-Path-Networks-Chen-Li",
            "title": {
                "fragments": [],
                "text": "Dual Path Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work reveals the equivalence of the state-of-the-art Residual Network (ResNet) and Densely Convolutional Network (DenseNet) within the HORNN framework, and finds that ResNet enables feature re-usage while DenseNet enables new features exploration which are both important for learning good representations."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33493200"
                        ],
                        "name": "Tsung-Yi Lin",
                        "slug": "Tsung-Yi-Lin",
                        "structuredName": {
                            "firstName": "Tsung-Yi",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tsung-Yi Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47316088"
                        ],
                        "name": "Priya Goyal",
                        "slug": "Priya-Goyal",
                        "structuredName": {
                            "firstName": "Priya",
                            "lastName": "Goyal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Priya Goyal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2983898"
                        ],
                        "name": "Ross B. Girshick",
                        "slug": "Ross-B.-Girshick",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Girshick",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross B. Girshick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127283"
                        ],
                        "name": "Piotr Doll\u00e1r",
                        "slug": "Piotr-Doll\u00e1r",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Doll\u00e1r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piotr Doll\u00e1r"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 27
                            }
                        ],
                        "text": "ResNet-101-FPN (RetinaNet) [25] 800 (short side) 39."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 100
                            }
                        ],
                        "text": "3A primary advance in the best reported object detection system is the introduction of a novel loss [25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 47252984,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72564a69bf339ff1d16a639c86a764db2321caab",
            "isKey": false,
            "numCitedBy": 8549,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "The highest accuracy object detectors to date are based on a two-stage approach popularized by R-CNN, where a classifier is applied to a sparse set of candidate object locations. In contrast, one-stage detectors that are applied over a regular, dense sampling of possible object locations have the potential to be faster and simpler, but have trailed the accuracy of two-stage detectors thus far. In this paper, we investigate why this is the case. We discover that the extreme foreground-background class imbalance encountered during training of dense detectors is the central cause. We propose to address this class imbalance by reshaping the standard cross entropy loss such that it down-weights the loss assigned to well-classified examples. Our novel Focal Loss focuses training on a sparse set of hard examples and prevents the vast number of easy negatives from overwhelming the detector during training. To evaluate the effectiveness of our loss, we design and train a simple dense detector we call RetinaNet. Our results show that when trained with the focal loss, RetinaNet is able to match the speed of previous one-stage detectors while surpassing the accuracy of all existing state-of-the-art two-stage detectors. Code is at: https://github.com/facebookresearch/Detectron."
            },
            "slug": "Focal-Loss-for-Dense-Object-Detection-Lin-Goyal",
            "title": {
                "fragments": [],
                "text": "Focal Loss for Dense Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes to address the extreme foreground-background class imbalance encountered during training of dense detectors by reshaping the standard cross entropy loss such that it down-weights the loss assigned to well-classified examples, and develops a novel Focal Loss, which focuses training on a sparse set of hard examples and prevents the vast number of easy negatives from overwhelming the detector during training."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2020
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2574060"
                        ],
                        "name": "Christian Szegedy",
                        "slug": "Christian-Szegedy",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Szegedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Szegedy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054165706"
                        ],
                        "name": "S. Ioffe",
                        "slug": "S.-Ioffe",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Ioffe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ioffe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2657155"
                        ],
                        "name": "Vincent Vanhoucke",
                        "slug": "Vincent-Vanhoucke",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Vanhoucke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Vanhoucke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122113652"
                        ],
                        "name": "Alexander A. Alemi",
                        "slug": "Alexander-A.-Alemi",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Alemi",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander A. Alemi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 367,
                                "start": 351
                            }
                        ],
                        "text": "One inspiration for this search space is the recognition that architecture engineering with CNNs often identifies repeated motifs consisting of combinations of convolutional filter banks, nonlinearities and a prudent selection of connections to achieve state-of-the-art results (such as the repeated modules present in the Inception and ResNet models [58, 20, 59, 57])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 124
                            }
                        ],
                        "text": "The modular structure of the convolutional cell is also related to previous methods on ImageNet such as VGG [52], Inception [58, 59, 57], ResNet/ResNext [20, 67], and Xception/MobileNet [9, 24]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 332,
                                "start": 323
                            }
                        ],
                        "text": "One inspiration for this search space is the recognition that architecture engineering with CNNs often identifies repeated motifs consisting of combinations of convolutional filter banks, nonlinearities and a prudent selection of connections to achieve state-of-the-art results (such as the repeated modules present in the Inception and ResNet models [35, 11, 36, 34])."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 166
                            }
                        ],
                        "text": "Successive advancements on this benchmark based on convolutional neural networks (CNNs) have achieved impressive results through significant architecture engineering [52, 58, 20, 59, 57, 67]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 264,
                                "start": 255
                            }
                        ],
                        "text": "In the first set of experiments, we train several image classification systems operating on 299x299 or 331x331 resolution images with different experiments scaled in computational demand to create models that are roughly on par in computational cost with Inception-v2 [19], Inception-v3 [36] and PolyNet [42]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 111
                            }
                        ],
                        "text": "Note the prevalence of separable convolutions and the number of branches compared with competing architectures [52, 58, 20, 59, 57]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 243,
                                "start": 234
                            }
                        ],
                        "text": "For the best NASNet network, our resulting network operating on images of the same spatial resolution (800 \u00d7 800) achieves mAP = 40.7%, exceeding equivalent object detection systems based off lesser performing image featurization (i.e. Inception-ResNet-v2) by 4.0% [18, 31] (see Figure 6 and Appendix)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 23
                            }
                        ],
                        "text": "Importantly, much like Inception and ResNet models [35, 11, 36, 34], we consider the number of motif repetitions N and the number of initial convolutional filters as free parameters that we tailor to the scale of an image classification problem."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 51
                            }
                        ],
                        "text": "Importantly, much like Inception and ResNet models [58, 20, 59, 57], we consider the number of motif repetitions N and the number of initial convolutional filters as free parameters that we tailor to the scale of an image classification problem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1023605,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5c26ab8767d046cb6e32d959fdf726aee89bb62",
            "isKey": true,
            "numCitedBy": 8225,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "\n \n Very deep convolutional networks have been central to the largest advances in image recognition performance in recent years. One example is the Inception architecture that has been shown to achieve very good performance at relatively low computational cost. Recently, the introduction of residual connections in conjunction with a more traditional architecture has yielded state-of-the-art performance in the 2015 ILSVRC challenge; its performance was similar to the latest generation Inception-v3 network. This raises the question: Are there any benefits to combining Inception architectures with residual connections? Here we give clear empirical evidence that training with residual connections accelerates the training of Inception networks significantly. There is also some evidence of residual Inception networks outperforming similarly expensive Inception networks without residual connections by a thin margin. We also present several new streamlined architectures for both residual and non-residual Inception networks. These variations improve the single-frame recognition performance on the ILSVRC 2012 classification task significantly. We further demonstrate how proper activation scaling stabilizes the training of very wide residual Inception networks. With an ensemble of three residual and one Inception-v4 networks, we achieve 3.08% top-5 error on the test set of the ImageNet classification (CLS) challenge.\n \n"
            },
            "slug": "Inception-v4,-Inception-ResNet-and-the-Impact-of-on-Szegedy-Ioffe",
            "title": {
                "fragments": [],
                "text": "Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Clear empirical evidence that training with residual connections accelerates the training of Inception networks significantly is given and several new streamlined architectures for both residual and non-residual Inception Networks are presented."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2153649520"
                        ],
                        "name": "Xingcheng Zhang",
                        "slug": "Xingcheng-Zhang",
                        "structuredName": {
                            "firstName": "Xingcheng",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xingcheng Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109714662"
                        ],
                        "name": "Zhizhong Li",
                        "slug": "Zhizhong-Li",
                        "structuredName": {
                            "firstName": "Zhizhong",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhizhong Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1717179"
                        ],
                        "name": "Chen Change Loy",
                        "slug": "Chen-Change-Loy",
                        "structuredName": {
                            "firstName": "Chen",
                            "lastName": "Loy",
                            "middleNames": [
                                "Change"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chen Change Loy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1807606"
                        ],
                        "name": "Dahua Lin",
                        "slug": "Dahua-Lin",
                        "structuredName": {
                            "firstName": "Dahua",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dahua Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 178
                            }
                        ],
                        "text": "The resulting architectures approach or exceed stateof-the-art performance in both CIFAR-10 and ImageNet datasets with less computational demand than humandesigned architectures [36, 19, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 308,
                                "start": 304
                            }
                        ],
                        "text": "In the first set of experiments, we train several image classification systems operating on 299x299 or 331x331 resolution images with different experiments scaled in computational demand to create models that are roughly on par in computational cost with Inception-v2 [19], Inception-v3 [36] and PolyNet [42]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17265670,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "aad34665649953fa4bbacdc6eff4edb5408df6b3",
            "isKey": false,
            "numCitedBy": 198,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "A number of studies have shown that increasing the depth or width of convolutional networks is a rewarding approach to improve the performance of image recognition. In our study, however, we observed difficulties along both directions. On one hand, the pursuit for very deep networks is met with a diminishing return and increased training difficulty, on the other hand, widening a network would result in a quadratic growth in both computational cost and memory demand. These difficulties motivate us to explore structural diversity in designing deep networks, a new dimension beyond just depth and width. Specifically, we present a new family of modules, namely the PolyInception, which can be flexibly inserted in isolation or in a composition as replacements of different parts of a network. Choosing PolyInception modules with the guidance of architectural efficiency can improve the expressive power while preserving comparable computational cost. The Very Deep PolyNet, designed following this direction, demonstrates substantial improvements over the state-of-the-art on the ILSVRC 2012 benchmark. Compared to Inception-ResNet-v2, it reduces the top-5 validation error on single crops from 4.9% to 4.25%, and that on multi-crops from 3.7% to 3.45%."
            },
            "slug": "PolyNet:-A-Pursuit-of-Structural-Diversity-in-Very-Zhang-Li",
            "title": {
                "fragments": [],
                "text": "PolyNet: A Pursuit of Structural Diversity in Very Deep Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work presents a new family of modules, namely the PolyInception, which can be flexibly inserted in isolation or in a composition as replacements of different parts of a network, and demonstrates substantial improvements over the state-of-the-art on the ILSVRC 2012 benchmark."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054165706"
                        ],
                        "name": "S. Ioffe",
                        "slug": "S.-Ioffe",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Ioffe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ioffe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2574060"
                        ],
                        "name": "Christian Szegedy",
                        "slug": "Christian-Szegedy",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Szegedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Szegedy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 178
                            }
                        ],
                        "text": "The resulting architectures approach or exceed stateof-the-art performance in both CIFAR-10 and ImageNet datasets with less computational demand than humandesigned architectures [36, 19, 42]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 272,
                                "start": 268
                            }
                        ],
                        "text": "In the first set of experiments, we train several image classification systems operating on 299x299 or 331x331 resolution images with different experiments scaled in computational demand to create models that are roughly on par in computational cost with Inception-v2 [19], Inception-v3 [36] and PolyNet [42]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 182
                            }
                        ],
                        "text": "Thanks to this property of the cells, we can generate a family of models that achieve accuracies superior to all human-invented models at equivalent or smaller computational budgets [36, 19]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5808102,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d376d6978dad0374edfa6709c9556b42d3594d3",
            "isKey": false,
            "numCitedBy": 29648,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters."
            },
            "slug": "Batch-Normalization:-Accelerating-Deep-Network-by-Ioffe-Szegedy",
            "title": {
                "fragments": [],
                "text": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40566201"
                        ],
                        "name": "Bowen Baker",
                        "slug": "Bowen-Baker",
                        "structuredName": {
                            "firstName": "Bowen",
                            "lastName": "Baker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bowen Baker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145418561"
                        ],
                        "name": "Otkrist Gupta",
                        "slug": "Otkrist-Gupta",
                        "structuredName": {
                            "firstName": "Otkrist",
                            "lastName": "Gupta",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Otkrist Gupta"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48685423"
                        ],
                        "name": "Nikhil Naik",
                        "slug": "Nikhil-Naik",
                        "structuredName": {
                            "firstName": "Nikhil",
                            "lastName": "Naik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nikhil Naik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145711633"
                        ],
                        "name": "R. Raskar",
                        "slug": "R.-Raskar",
                        "structuredName": {
                            "firstName": "Ramesh",
                            "lastName": "Raskar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Raskar"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "ethod is related to previous work in hyperparameter optimization [44, 4, 5, 54, 55, 6, 40] \u2013 especially recent approaches in designing architectures such as Neural Fabrics [48], DiffRNN [41], MetaQNN [3] and DeepArchitect [43]. A more \ufb02exible class of methods for designing architecture is evolutionary algorithms [65, 16, 57, 30, 46, 42, 67], yet they have not had as much success at large scale. Xie a"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1740355,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6cd5dfccd9f52538b19a415e00031d0ee4e5b181",
            "isKey": false,
            "numCitedBy": 1064,
            "numCiting": 47,
            "paperAbstract": {
                "fragments": [],
                "text": "At present, designing convolutional neural network (CNN) architectures requires both human expertise and labor. New architectures are handcrafted by careful experimentation or modified from a handful of existing networks. We introduce MetaQNN, a meta-modeling algorithm based on reinforcement learning to automatically generate high-performing CNN architectures for a given learning task. The learning agent is trained to sequentially choose CNN layers using $Q$-learning with an $\\epsilon$-greedy exploration strategy and experience replay. The agent explores a large but finite space of possible architectures and iteratively discovers designs with improved performance on the learning task. On image classification benchmarks, the agent-designed networks (consisting of only standard convolution, pooling, and fully-connected layers) beat existing networks designed with the same layer types and are competitive against the state-of-the-art methods that use more complex layer types. We also outperform existing meta-modeling approaches for network design on image classification tasks."
            },
            "slug": "Designing-Neural-Network-Architectures-using-Baker-Gupta",
            "title": {
                "fragments": [],
                "text": "Designing Neural Network Architectures using Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "MetaQNN is introduced, a meta-modeling algorithm based on reinforcement learning to automatically generate high-performing CNN architectures for a given learning task that beat existing networks designed with the same layer types and are competitive against the state-of-the-art methods that use more complex layer types."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3013941"
                        ],
                        "name": "Renato Negrinho",
                        "slug": "Renato-Negrinho",
                        "structuredName": {
                            "firstName": "Renato",
                            "lastName": "Negrinho",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Renato Negrinho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21889436"
                        ],
                        "name": "Geoffrey J. Gordon",
                        "slug": "Geoffrey-J.-Gordon",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Gordon",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey J. Gordon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 240,
                                "start": 236
                            }
                        ],
                        "text": "The proposed method is related to previous work in hyperparameter optimization [44, 4, 5, 54, 55, 6, 40] \u2013 especially recent approaches in designing architectures such as Neural Fabrics [48], DiffRNN [41], MetaQNN [3] and DeepArchitect [43]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7044373,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "71a80e7342e56f33fd120246e907151a0cf1b4d0",
            "isKey": false,
            "numCitedBy": 153,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "In deep learning, performance is strongly affected by the choice of architecture and hyperparameters. While there has been extensive work on automatic hyperpa- rameter optimization for simple spaces, complex spaces such as the space of deep architectures remain largely unexplored. As a result, the choice of architecture is done manually by the human expert through a slow trial and error process guided mainly by intuition. In this paper we describe a framework for automatically designing and training deep models. We propose an extensible and modular lan- guage that allows the human expert to compactly represent complex search spaces over architectures and their hyperparameters. The resulting search spaces are tree- structured and therefore easy to traverse. Models can be automatically compiled to computational graphs once values for all hyperparameters have been chosen. We can leverage the structure of the search space to introduce different model search algorithms, such as random search, Monte Carlo tree search (MCTS), and sequen- tial model-based optimization (SMBO). We present experiments comparing the different algorithms on CIFAR-10 and show that MCTS and SMBO outperform random search. We also present experiments on MNIST, showing that the same search space achieves near state-of-the-art performance with a few samples. These experiments show that our framework can be used effectively for model discov- ery, as it is possible to describe expressive search spaces and discover competitive models without much effort from the human expert. Code for our framework and experiments has been made publicly available"
            },
            "slug": "DeepArchitect:-Automatically-Designing-and-Training-Negrinho-Gordon",
            "title": {
                "fragments": [],
                "text": "DeepArchitect: Automatically Designing and Training Deep Architectures"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This paper proposes an extensible and modular framework that allows the human expert to compactly represent complex search spaces over architectures and their hyperparameters and shows that the same search space achieves near state-of-the-art performance with a few samples."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32837403"
                        ],
                        "name": "J. Bergstra",
                        "slug": "J.-Bergstra",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bergstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bergstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2103302"
                        ],
                        "name": "R. Bardenet",
                        "slug": "R.-Bardenet",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Bardenet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Bardenet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143674326"
                        ],
                        "name": "B. K\u00e9gl",
                        "slug": "B.-K\u00e9gl",
                        "structuredName": {
                            "firstName": "Bal\u00e1zs",
                            "lastName": "K\u00e9gl",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. K\u00e9gl"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The proposed method is related to previous work in hyperparameter optimization [44, 4, 5, 54, 55, 6, 40] \u2013 especially recent approaches in designing architectures such as Neural Fabrics [48], DiffRNN [41], MetaQNN [3] and DeepArchitect [43]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11688126,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "03911c85305d42aa2eeb02be82ef6fb7da644dd0",
            "isKey": false,
            "numCitedBy": 2516,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Several recent advances to the state of the art in image classification benchmarks have come from better configurations of existing techniques rather than novel approaches to feature learning. Traditionally, hyper-parameter optimization has been the job of humans because they can be very efficient in regimes where only a few trials are possible. Presently, computer clusters and GPU processors make it possible to run more trials and we show that algorithmic approaches can find better results. We present hyper-parameter optimization results on tasks of training neural networks and deep belief networks (DBNs). We optimize hyper-parameters using random search and two new greedy sequential methods based on the expected improvement criterion. Random search has been shown to be sufficiently efficient for learning neural networks for several datasets, but we show it is unreliable for training DBNs. The sequential algorithms are applied to the most difficult DBN learning problems from [1] and find significantly better results than the best previously reported. This work contributes novel techniques for making response surface models P(y|x) in which many elements of hyper-parameter assignment (x) are known to be irrelevant given particular values of other elements."
            },
            "slug": "Algorithms-for-Hyper-Parameter-Optimization-Bergstra-Bardenet",
            "title": {
                "fragments": [],
                "text": "Algorithms for Hyper-Parameter Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work contributes novel techniques for making response surface models P(y|x) in which many elements of hyper-parameter assignment (x) are known to be irrelevant given particular values of other elements."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1686788"
                        ],
                        "name": "R. Miikkulainen",
                        "slug": "R.-Miikkulainen",
                        "structuredName": {
                            "firstName": "Risto",
                            "lastName": "Miikkulainen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Miikkulainen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2111834930"
                        ],
                        "name": "J. Liang",
                        "slug": "J.-Liang",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Liang",
                            "middleNames": [
                                "Zhi"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Liang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2978740"
                        ],
                        "name": "Elliot Meyerson",
                        "slug": "Elliot-Meyerson",
                        "structuredName": {
                            "firstName": "Elliot",
                            "lastName": "Meyerson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Elliot Meyerson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064309559"
                        ],
                        "name": "Aditya Rawal",
                        "slug": "Aditya-Rawal",
                        "structuredName": {
                            "firstName": "Aditya",
                            "lastName": "Rawal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aditya Rawal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2156494244"
                        ],
                        "name": "E. FinkDaniel",
                        "slug": "E.-FinkDaniel",
                        "structuredName": {
                            "firstName": "E",
                            "lastName": "FinkDaniel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. FinkDaniel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9965138"
                        ],
                        "name": "Olivier Francon",
                        "slug": "Olivier-Francon",
                        "structuredName": {
                            "firstName": "Olivier",
                            "lastName": "Francon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Olivier Francon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39806498"
                        ],
                        "name": "Bala Raju",
                        "slug": "Bala-Raju",
                        "structuredName": {
                            "firstName": "Bala",
                            "lastName": "Raju",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bala Raju"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2481407"
                        ],
                        "name": "H. Shahrzad",
                        "slug": "H.-Shahrzad",
                        "structuredName": {
                            "firstName": "Hormoz",
                            "lastName": "Shahrzad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Shahrzad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1632432987"
                        ],
                        "name": "Arshak Navruzyan",
                        "slug": "Arshak-Navruzyan",
                        "structuredName": {
                            "firstName": "Arshak",
                            "lastName": "Navruzyan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arshak Navruzyan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143857271"
                        ],
                        "name": "Nigel P. Duffy",
                        "slug": "Nigel-P.-Duffy",
                        "structuredName": {
                            "firstName": "Nigel",
                            "lastName": "Duffy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nigel P. Duffy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3024670"
                        ],
                        "name": "B. Hodjat",
                        "slug": "B.-Hodjat",
                        "structuredName": {
                            "firstName": "Babak",
                            "lastName": "Hodjat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Hodjat"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 87
                            }
                        ],
                        "text": "A more flexible class of methods for designing architecture is evolutionary algorithms [65, 16, 57, 30, 46, 42, 67], yet they have not had as much success at large scale."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 215763844,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd7c02cab3ec4e59150657bd6660eab97def9a3a",
            "isKey": false,
            "numCitedBy": 610,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Evolving-Deep-Neural-Networks-Miikkulainen-Liang",
            "title": {
                "fragments": [],
                "text": "Evolving Deep Neural Networks"
            },
            "venue": {
                "fragments": [],
                "text": "Artificial Intelligence in the Age of Neural Networks and Brain Computing"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143983679"
                        ],
                        "name": "Gao Huang",
                        "slug": "Gao-Huang",
                        "structuredName": {
                            "firstName": "Gao",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gao Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117103358"
                        ],
                        "name": "Yu Sun",
                        "slug": "Yu-Sun",
                        "structuredName": {
                            "firstName": "Yu",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yu Sun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109168016"
                        ],
                        "name": "Zhuang Liu",
                        "slug": "Zhuang-Liu",
                        "structuredName": {
                            "firstName": "Zhuang",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhuang Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3371029"
                        ],
                        "name": "Daniel Sedra",
                        "slug": "Daniel-Sedra",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Sedra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Sedra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7446832"
                        ],
                        "name": "Kilian Q. Weinberger",
                        "slug": "Kilian-Q.-Weinberger",
                        "structuredName": {
                            "firstName": "Kilian",
                            "lastName": "Weinberger",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kilian Q. Weinberger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": "This is similar to [25] and [60] where they dropout full parts of their model during training and then at test time scale the path by the probability of keeping that path during training."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6773885,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "51db1f3c8dfc7d4077da39c96bb90a6358128111",
            "isKey": false,
            "numCitedBy": 1458,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Very deep convolutional networks with hundreds of layers have led to significant reductions in error on competitive benchmarks. Although the unmatched expressiveness of the many layers can be highly desirable at test time, training very deep networks comes with its own set of challenges. The gradients can vanish, the forward flow often diminishes, and the training time can be painfully slow. To address these problems, we propose stochastic depth, a training procedure that enables the seemingly contradictory setup to train short networks and use deep networks at test time. We start with very deep networks but during training, for each mini-batch, randomly drop a subset of layers and bypass them with the identity function. This simple approach complements the recent success of residual networks. It reduces training time substantially and improves the test error significantly on almost all data sets that we used for evaluation. With stochastic depth we can increase the depth of residual networks even beyond 1200 layers and still yield meaningful improvements in test error (4.91 % on CIFAR-10)."
            },
            "slug": "Deep-Networks-with-Stochastic-Depth-Huang-Sun",
            "title": {
                "fragments": [],
                "text": "Deep Networks with Stochastic Depth"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Stochastic depth is proposed, a training procedure that enables the seemingly contradictory setup to train short networks and use deep networks at test time and reduces training time substantially and improves the test error significantly on almost all data sets that were used for evaluation."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49517463"
                        ],
                        "name": "S. Ravi",
                        "slug": "S.-Ravi",
                        "structuredName": {
                            "firstName": "Sachin",
                            "lastName": "Ravi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ravi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777528"
                        ],
                        "name": "H. Larochelle",
                        "slug": "H.-Larochelle",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Larochelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Larochelle"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The concept of having one neural network interact with a second neural network to aid the learning process, or learning to learn or meta-learning [21, 41] has attracted much attention in recent years [1, 13, 14, 18, 32, 38, 52]. Most of these approaches have not been scaled to large problems like ImageNet. A notable exception is recent work focused on learning an optimizer for ImageNet classi\ufb01cation that achieved notable im"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 67413369,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29c887794eed2ca9462638ff853e6fe1ab91d5d8",
            "isKey": false,
            "numCitedBy": 2175,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Optimization-as-a-Model-for-Few-Shot-Learning-Ravi-Larochelle",
            "title": {
                "fragments": [],
                "text": "Optimization as a Model for Few-Shot Learning"
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46881670"
                        ],
                        "name": "Chelsea Finn",
                        "slug": "Chelsea-Finn",
                        "structuredName": {
                            "firstName": "Chelsea",
                            "lastName": "Finn",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chelsea Finn"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689992"
                        ],
                        "name": "P. Abbeel",
                        "slug": "P.-Abbeel",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Abbeel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Abbeel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736651"
                        ],
                        "name": "S. Levine",
                        "slug": "S.-Levine",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Levine",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levine"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 200
                            }
                        ],
                        "text": "The concept of having one neural network interact with a second neural network to aid the learning process, or learning to learn or meta-learning [23, 48] has attracted much attention in recent years [1, 61, 14, 19, 34, 44, 15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6719686,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c889d6f98e6d79b89c3a6adf8a921f88fa6ba518",
            "isKey": false,
            "numCitedBy": 5497,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies."
            },
            "slug": "Model-Agnostic-Meta-Learning-for-Fast-Adaptation-of-Finn-Abbeel",
            "title": {
                "fragments": [],
                "text": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "An algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771551"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3080683"
                        ],
                        "name": "Shaoqing Ren",
                        "slug": "Shaoqing-Ren",
                        "structuredName": {
                            "firstName": "Shaoqing",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoqing Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6447277,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "77f0a39b8e02686fd85b01971f8feb7f60971f80",
            "isKey": false,
            "numCitedBy": 6555,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep residual networks have emerged as a family of extremely deep architectures showing compelling accuracy and nice convergence behaviors. In this paper, we analyze the propagation formulations behind the residual building blocks, which suggest that the forward and backward signals can be directly propagated from one block to any other block, when using identity mappings as the skip connections and after-addition activation. A series of ablation experiments support the importance of these identity mappings. This motivates us to propose a new residual unit, which makes training easier and improves generalization. We report improved results using a 1001-layer ResNet on CIFAR-10 (4.62 % error) and CIFAR-100, and a 200-layer ResNet on ImageNet. Code is available at: https://github.com/KaimingHe/resnet-1k-layers."
            },
            "slug": "Identity-Mappings-in-Deep-Residual-Networks-He-Zhang",
            "title": {
                "fragments": [],
                "text": "Identity Mappings in Deep Residual Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The propagation formulations behind the residual building blocks suggest that the forward and backward signals can be directly propagated from one block to any other block, when using identity mappings as the skip connections and after-addition activation."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47447630"
                        ],
                        "name": "Tobias Weyand",
                        "slug": "Tobias-Weyand",
                        "structuredName": {
                            "firstName": "Tobias",
                            "lastName": "Weyand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tobias Weyand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2000906"
                        ],
                        "name": "Ilya Kostrikov",
                        "slug": "Ilya-Kostrikov",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Kostrikov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Kostrikov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066819269"
                        ],
                        "name": "James Philbin",
                        "slug": "James-Philbin",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Philbin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Philbin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": ", object detection [18], face detection [29], image localization [39]) derive image features or architectures from ImageNet classification models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 171846,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1b93a123d352ea09b4c8aaac933f1d4c8bd42009",
            "isKey": false,
            "numCitedBy": 323,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "Is it possible to determine the location of a photo from just its pixels? While the general problem seems exceptionally difficult, photos often contain cues such as landmarks, weather patterns, vegetation, road markings, or architectural details, which in combination allow to infer where the photo was taken. Previously, this problem has been approached using image retrieval methods. In contrast, we pose the problem as one of classification by subdividing the surface of the earth into thousands of multi-scale geographic cells, and train a deep network using millions of geotagged images. We show that the resulting model, called PlaNet, outperforms previous approaches and even attains superhuman accuracy in some cases. Moreover, we extend our model to photo albums by combining it with a long short-term memory (LSTM) architecture. By learning to exploit temporal coherence to geolocate uncertain photos, this model achieves a 50 % performance improvement over the single-image model."
            },
            "slug": "PlaNet-Photo-Geolocation-with-Convolutional-Neural-Weyand-Kostrikov",
            "title": {
                "fragments": [],
                "text": "PlaNet - Photo Geolocation with Convolutional Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work subdividing the surface of the earth into thousands of multi-scale geographic cells, and train a deep network using millions of geotagged images, and shows that the resulting model, called PlaNet, outperforms previous approaches and even attains superhuman accuracy in some cases."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144727050"
                        ],
                        "name": "Andrew G. Howard",
                        "slug": "Andrew-G.-Howard",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Howard",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew G. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2717876"
                        ],
                        "name": "Menglong Zhu",
                        "slug": "Menglong-Zhu",
                        "structuredName": {
                            "firstName": "Menglong",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Menglong Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Bo Chen",
                        "slug": "Bo-Chen",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741985"
                        ],
                        "name": "Dmitry Kalenichenko",
                        "slug": "Dmitry-Kalenichenko",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Kalenichenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dmitry Kalenichenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108301072"
                        ],
                        "name": "Weijun Wang",
                        "slug": "Weijun-Wang",
                        "structuredName": {
                            "firstName": "Weijun",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weijun Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47447630"
                        ],
                        "name": "Tobias Weyand",
                        "slug": "Tobias-Weyand",
                        "structuredName": {
                            "firstName": "Tobias",
                            "lastName": "Weyand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tobias Weyand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2612392"
                        ],
                        "name": "M. Andreetto",
                        "slug": "M.-Andreetto",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Andreetto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Andreetto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2595180"
                        ],
                        "name": "Hartwig Adam",
                        "slug": "Hartwig-Adam",
                        "structuredName": {
                            "firstName": "Hartwig",
                            "lastName": "Adam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hartwig Adam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 101
                            }
                        ],
                        "text": "1% better than previously engineered architectures targeted towards mobile and embedded vision tasks [14, 43]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "MobileNet [14] and ShuffleNet [43] provide state-of-the-art results obtaining 70."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 240,
                                "start": 232
                            }
                        ],
                        "text": "Finally, we demonstrate that we can employ the resulting learned architecture to perform ImageNet classification with reduced computational budgets that outperform streamlined architectures targeted to mobile and embedded platforms [14, 43]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 209
                            }
                        ],
                        "text": "Second, we demonstrate that by adjusting the scale of the model we can achieve state-of-the-art performance at smaller computational budgets, exceeding streamlined CNNs hand-designed for this operating regime [14, 43]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12670695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3647d6d0f151dc05626449ee09cc7bce55be497e",
            "isKey": true,
            "numCitedBy": 10323,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization."
            },
            "slug": "MobileNets:-Efficient-Convolutional-Neural-Networks-Howard-Zhu",
            "title": {
                "fragments": [],
                "text": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work introduces two simple global hyper-parameters that efficiently trade off between latency and accuracy and demonstrates the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735300"
                        ],
                        "name": "S. Haykin",
                        "slug": "S.-Haykin",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Haykin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Haykin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713858"
                        ],
                        "name": "B. Kosko",
                        "slug": "B.-Kosko",
                        "structuredName": {
                            "firstName": "Bart",
                            "lastName": "Kosko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Kosko"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 62
                            }
                        ],
                        "text": "The seminal work of [22] on using convolutional architectures [9, 23] for ImageNet classification represents one of the most important breakthroughs in deep learning."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 64294544,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f42b865e20e61a954239f421b42007236e671f19",
            "isKey": false,
            "numCitedBy": 3561,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer Neural Networks trained with the backpropagation algorithm constitute the best example of a successful Gradient-Based Learning technique. Given an appropriate network architecture, Gradient-Based Learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional Neural Networks, that are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation, recognition, and language modeling. A new learning paradigm, called Graph Transformer Networks (GTN), allows such multi-module systems to be trained globally using Gradient-Based methods so as to minimize an overall performance measure. Two systems for on-line handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of Graph Transformer Networks. A Graph Transformer Network for reading bank check is also described. It uses Convolutional Neural Network character recognizers combined with global training techniques to provides record accuracy on business and personal checks. It is deployed commercially and reads several million checks per day."
            },
            "slug": "GradientBased-Learning-Applied-to-Document-Haykin-Kosko",
            "title": {
                "fragments": [],
                "text": "GradientBased Learning Applied to Document Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Various methods applied to handwritten character recognition are reviewed and compared and Convolutional Neural Networks, that are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "y 4.0% achieving 43.1% mAP on the COCO dataset. 1. Introduction ImageNet classi\ufb01cation [11] is an important benchmark in computer vision. The seminal work of [32] on using convolutional architectures [17, 33] for ImageNet classi\ufb01- cation represents one of the most important breakthroughs in deep learning. Successive advancements on this benchmark based on convolutional neural networks (CNNs) have achieved"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": true,
            "numCitedBy": 35623,
            "numCiting": 246,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "51131802"
                        ],
                        "name": "J. Kiros",
                        "slug": "J.-Kiros",
                        "structuredName": {
                            "firstName": "Jamie",
                            "lastName": "Kiros",
                            "middleNames": [
                                "Ryan"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Kiros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8236317,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "97fb4e3d45bb098e27e0071448b6152217bd35a5",
            "isKey": false,
            "numCitedBy": 3130,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Training state-of-the-art, deep neural networks is computationally expensive. One way to reduce the training time is to normalize the activities of the neurons. A recently introduced technique called batch normalization uses the distribution of the summed input to a neuron over a mini-batch of training cases to compute a mean and variance which are then used to normalize the summed input to that neuron on each training case. This significantly reduces the training time in feedforward neural networks. However, the effect of batch normalization is dependent on the mini-batch size and it is not obvious how to apply it to recurrent neural networks. In this paper, we transpose batch normalization into layer normalization by computing the mean and variance used for normalization from all of the summed inputs to the neurons in a layer on a single training case. Like batch normalization, we also give each neuron its own adaptive bias and gain which are applied after the normalization but before the non-linearity. Unlike batch normalization, layer normalization performs exactly the same computation at training and test times. It is also straightforward to apply to recurrent neural networks by computing the normalization statistics separately at each time step. Layer normalization is very effective at stabilizing the hidden state dynamics in recurrent networks. Empirically, we show that layer normalization can substantially reduce the training time compared with previously published techniques."
            },
            "slug": "Layer-Normalization-Ba-Kiros",
            "title": {
                "fragments": [],
                "text": "Layer Normalization"
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30017846"
                        ],
                        "name": "N. Pinto",
                        "slug": "N.-Pinto",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Pinto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Pinto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3250342"
                        ],
                        "name": "D. Doukhan",
                        "slug": "D.-Doukhan",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Doukhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Doukhan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1865831"
                        ],
                        "name": "J. DiCarlo",
                        "slug": "J.-DiCarlo",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "DiCarlo",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. DiCarlo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2042941"
                        ],
                        "name": "D. Cox",
                        "slug": "D.-Cox",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cox",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cox"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 79
                            }
                        ],
                        "text": "The proposed method is related to previous work in hyperparameter optimization [43, 4, 5, 53, 54, 6, 39] \u2013 especially recent approaches in designing architectures such as Neural Fabrics [47], DiffRNN [40], MetaQNN [3] and DeepArchitect [42]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 215779860,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "d46fd54609e09bcd135fd28750003185a5ee4125",
            "isKey": false,
            "numCitedBy": 254,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "While many models of biological object recognition share a common set of \u201cbroad-stroke\u201d properties, the performance of any one model depends strongly on the choice of parameters in a particular instantiation of that model\u2014e.g., the number of units per layer, the size of pooling kernels, exponents in normalization operations, etc. Since the number of such parameters (explicit or implicit) is typically large and the computational cost of evaluating one particular parameter set is high, the space of possible model instantiations goes largely unexplored. Thus, when a model fails to approach the abilities of biological visual systems, we are left uncertain whether this failure is because we are missing a fundamental idea or because the correct \u201cparts\u201d have not been tuned correctly, assembled at sufficient scale, or provided with enough training. Here, we present a high-throughput approach to the exploration of such parameter sets, leveraging recent advances in stream processing hardware (high-end NVIDIA graphic cards and the PlayStation 3's IBM Cell Processor). In analogy to high-throughput screening approaches in molecular biology and genetics, we explored thousands of potential network architectures and parameter instantiations, screening those that show promising object recognition performance for further analysis. We show that this approach can yield significant, reproducible gains in performance across an array of basic object recognition tasks, consistently outperforming a variety of state-of-the-art purpose-built vision systems from the literature. As the scale of available computational power continues to expand, we argue that this approach has the potential to greatly accelerate progress in both artificial vision and our understanding of the computational underpinning of biological vision."
            },
            "slug": "A-High-Throughput-Screening-Approach-to-Discovering-Pinto-Doukhan",
            "title": {
                "fragments": [],
                "text": "A High-Throughput Screening Approach to Discovering Good Forms of Biologically Inspired Visual Representation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This approach can yield significant, reproducible gains in performance across an array of basic object recognition tasks, consistently outperforming a variety of state-of-the-art purpose-built vision systems from the literature."
            },
            "venue": {
                "fragments": [],
                "text": "PLoS Comput. Biol."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2897313"
                        ],
                        "name": "Nitish Srivastava",
                        "slug": "Nitish-Srivastava",
                        "structuredName": {
                            "firstName": "Nitish",
                            "lastName": "Srivastava",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nitish Srivastava"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145124475"
                        ],
                        "name": "R. Salakhutdinov",
                        "slug": "R.-Salakhutdinov",
                        "structuredName": {
                            "firstName": "Ruslan",
                            "lastName": "Salakhutdinov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Salakhutdinov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6844431,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "34f25a8704614163c4095b3ee2fc969b60de4698",
            "isKey": false,
            "numCitedBy": 28464,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different \"thinned\" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets."
            },
            "slug": "Dropout:-a-simple-way-to-prevent-neural-networks-Srivastava-Hinton",
            "title": {
                "fragments": [],
                "text": "Dropout: a simple way to prevent neural networks from overfitting"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153302678"
                        ],
                        "name": "Jia Deng",
                        "slug": "Jia-Deng",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144847596"
                        ],
                        "name": "Wei Dong",
                        "slug": "Wei-Dong",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Dong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Dong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2040091191"
                        ],
                        "name": "Li-Jia Li",
                        "slug": "Li-Jia-Li",
                        "structuredName": {
                            "firstName": "Li-Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "94451829"
                        ],
                        "name": "K. Li",
                        "slug": "K.-Li",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 24
                            }
                        ],
                        "text": "ImageNet classification [7] is an important benchmark in computer vision."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 57246310,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2c733e34d48784a37d717fe43d9e93277a8c53e",
            "isKey": false,
            "numCitedBy": 28266,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called \u201cImageNet\u201d, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond."
            },
            "slug": "ImageNet:-A-large-scale-hierarchical-image-database-Deng-Dong",
            "title": {
                "fragments": [],
                "text": "ImageNet: A large-scale hierarchical image database"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new database called \u201cImageNet\u201d is introduced, a large-scale ontology of images built upon the backbone of the WordNet structure, much larger in scale and diversity and much more accurate than the current image datasets."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50875121"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "Xiangyu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148927556"
                        ],
                        "name": "Xinyu Zhou",
                        "slug": "Xinyu-Zhou",
                        "structuredName": {
                            "firstName": "Xinyu",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinyu Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3287035"
                        ],
                        "name": "Mengxiao Lin",
                        "slug": "Mengxiao-Lin",
                        "structuredName": {
                            "firstName": "Mengxiao",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mengxiao Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 101
                            }
                        ],
                        "text": "1% better than previously engineered architectures targeted towards mobile and embedded vision tasks [14, 43]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 29,
                                "start": 19
                            }
                        ],
                        "text": "MobileNet [14] and ShuffleNet [43] provide state-of-the-art results obtaining 70.6% and 70.9% accuracy, respectively on 224x224 images using \u223c550M multliply-add operations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "MobileNet [14] and ShuffleNet [43] provide state-of-the-art results obtaining 70."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 240,
                                "start": 232
                            }
                        ],
                        "text": "Finally, we demonstrate that we can employ the resulting learned architecture to perform ImageNet classification with reduced computational budgets that outperform streamlined architectures targeted to mobile and embedded platforms [14, 43]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 217,
                                "start": 209
                            }
                        ],
                        "text": "Second, we demonstrate that by adjusting the scale of the model we can achieve state-of-the-art performance at smaller computational budgets, exceeding streamlined CNNs hand-designed for this operating regime [14, 43]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 24982157,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9da734397acd7ff7c557960c62fb1b400b27bd89",
            "isKey": true,
            "numCitedBy": 3251,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce an extremely computation-efficient CNN architecture named ShuffleNet, which is designed specially for mobile devices with very limited computing power (e.g., 10-150 MFLOPs). The new architecture utilizes two new operations, pointwise group convolution and channel shuffle, to greatly reduce computation cost while maintaining accuracy. Experiments on ImageNet classification and MS COCO object detection demonstrate the superior performance of ShuffleNet over other structures, e.g. lower top-1 error (absolute 7.8%) than recent MobileNet [12] on ImageNet classification task, under the computation budget of 40 MFLOPs. On an ARM-based mobile device, ShuffleNet achieves ~13\u00c3\u2014 actual speedup over AlexNet while maintaining comparable accuracy."
            },
            "slug": "ShuffleNet:-An-Extremely-Efficient-Convolutional-Zhang-Zhou",
            "title": {
                "fragments": [],
                "text": "ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "An extremely computation-efficient CNN architecture named ShuffleNet is introduced, which is designed specially for mobile devices with very limited computing power (e.g., 10-150 MFLOPs), to greatly reduce computation cost while maintaining accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1781242"
                        ],
                        "name": "Abhinav Shrivastava",
                        "slug": "Abhinav-Shrivastava",
                        "structuredName": {
                            "firstName": "Abhinav",
                            "lastName": "Shrivastava",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Abhinav Shrivastava"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694199"
                        ],
                        "name": "R. Sukthankar",
                        "slug": "R.-Sukthankar",
                        "structuredName": {
                            "firstName": "Rahul",
                            "lastName": "Sukthankar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Sukthankar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726095131"
                        ],
                        "name": "A. Gupta",
                        "slug": "A.-Gupta",
                        "structuredName": {
                            "firstName": "Abhinav",
                            "lastName": "Gupta",
                            "middleNames": [
                                "Kumar"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gupta"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 33,
                                "start": 29
                            }
                        ],
                        "text": "6% Inception-ResNet-v2 (TDM) [31] 600\u00d7 1000 37."
                    },
                    "intents": []
                }
            ],
            "corpusId": 13123786,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "47a1fa91816f50266aef3c31b6bd38895df63b00",
            "isKey": false,
            "numCitedBy": 269,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years, we have seen tremendous progress in the field of object detection. Most of the recent improvements have been achieved by targeting deeper feedforward networks. However, many hard object categories such as bottle, remote, etc. require representation of fine details and not just coarse, semantic representations. But most of these fine details are lost in the early convolutional layers. What we need is a way to incorporate finer details from lower layers into the detection architecture. Skip connections have been proposed to combine high-level and low-level features, but we argue that selecting the right features from low-level requires top-down contextual information. Inspired by the human visual pathway, in this paper we propose top-down modulations as a way to incorporate fine details into the detection framework. Our approach supplements the standard bottom-up, feedforward ConvNet with a top-down modulation (TDM) network, connected using lateral connections. These connections are responsible for the modulation of lower layer filters, and the top-down network handles the selection and integration of contextual information and low-level features. The proposed TDM architecture provides a significant boost on the COCO testdev benchmark, achieving 28.6 AP for VGG16, 35.2 AP for ResNet101, and 37.3 for InceptionResNetv2 network, without any bells and whistles (e.g., multi-scale, iterative box refinement, etc.)."
            },
            "slug": "Beyond-Skip-Connections:-Top-Down-Modulation-for-Shrivastava-Sukthankar",
            "title": {
                "fragments": [],
                "text": "Beyond Skip Connections: Top-Down Modulation for Object Detection"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "Inspired by the human visual pathway, this paper proposes top-down modulations as a way to incorporate fine details into the detection framework, and supplements the standard bottom-up, feedforward ConvNet with a top- down modulation (TDM) network, connected using lateral connections."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144108062"
                        ],
                        "name": "Jasper Snoek",
                        "slug": "Jasper-Snoek",
                        "structuredName": {
                            "firstName": "Jasper",
                            "lastName": "Snoek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jasper Snoek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1757324"
                        ],
                        "name": "Oren Rippel",
                        "slug": "Oren-Rippel",
                        "structuredName": {
                            "firstName": "Oren",
                            "lastName": "Rippel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oren Rippel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1754860"
                        ],
                        "name": "Kevin Swersky",
                        "slug": "Kevin-Swersky",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Swersky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Swersky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3450996"
                        ],
                        "name": "Ryan Kiros",
                        "slug": "Ryan-Kiros",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Kiros",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan Kiros"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143758120"
                        ],
                        "name": "N. Satish",
                        "slug": "N.-Satish",
                        "structuredName": {
                            "firstName": "Nadathur",
                            "lastName": "Satish",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Satish"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789372"
                        ],
                        "name": "N. Sundaram",
                        "slug": "N.-Sundaram",
                        "structuredName": {
                            "firstName": "Narayanan",
                            "lastName": "Sundaram",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Sundaram"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8176660"
                        ],
                        "name": "Md. Mostofa Ali Patwary",
                        "slug": "Md.-Mostofa-Ali-Patwary",
                        "structuredName": {
                            "firstName": "Md.",
                            "lastName": "Patwary",
                            "middleNames": [
                                "Mostofa",
                                "Ali"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Md. Mostofa Ali Patwary"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1764912"
                        ],
                        "name": "Prabhat",
                        "slug": "Prabhat",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Prabhat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Prabhat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722180"
                        ],
                        "name": "Ryan P. Adams",
                        "slug": "Ryan-P.-Adams",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Adams",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan P. Adams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "rovide a viable search strategy, RL does signi\ufb01cantly improve our ability to learn neural architectures. 4. Related Work The proposed method is related to previous work in hyperparameter optimization [43, 4, 5, 53, 54, 6, 39] \u2013 especially recent approaches in designing architectures such as Neural Fabrics [47], DiffRNN [40], MetaQNN [3] and DeepArchitect [42]. A more \ufb02exible class of methods for designing architecture is "
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12604141,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "93bc65d2842b8cc5f3cf72ebc5b8f75daeacea35",
            "isKey": false,
            "numCitedBy": 711,
            "numCiting": 73,
            "paperAbstract": {
                "fragments": [],
                "text": "Bayesian optimization is an effective methodology for the global optimization of functions with expensive evaluations. It relies on querying a distribution over functions defined by a relatively cheap surrogate model. An accurate model for this distribution over functions is critical to the effectiveness of the approach, and is typically fit using Gaussian processes (GPs). However, since GPs scale cubically with the number of observations, it has been challenging to handle objectives whose optimization requires many evaluations, and as such, massively parallelizing the optimization. \n \nIn this work, we explore the use of neural networks as an alternative to GPs to model distributions over functions. We show that performing adaptive basis function regression with a neural network as the parametric form performs competitively with state-of-the-art GP-based approaches, but scales linearly with the number of data rather than cubically. This allows us to achieve a previously intractable degree of parallelism, which we apply to large scale hyperparameter optimization, rapidly finding competitive models on benchmark object recognition tasks using convolutional networks, and image caption generation using neural language models."
            },
            "slug": "Scalable-Bayesian-Optimization-Using-Deep-Neural-Snoek-Rippel",
            "title": {
                "fragments": [],
                "text": "Scalable Bayesian Optimization Using Deep Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work shows that performing adaptive basis function regression with a neural network as the parametric form performs competitively with state-of-the-art GP-based approaches, but scales linearly with the number of data rather than cubically, which allows for a previously intractable degree of parallelism."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33493200"
                        ],
                        "name": "Tsung-Yi Lin",
                        "slug": "Tsung-Yi-Lin",
                        "structuredName": {
                            "firstName": "Tsung-Yi",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tsung-Yi Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145854440"
                        ],
                        "name": "M. Maire",
                        "slug": "M.-Maire",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Maire",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50172592"
                        ],
                        "name": "Serge J. Belongie",
                        "slug": "Serge-J.-Belongie",
                        "structuredName": {
                            "firstName": "Serge",
                            "lastName": "Belongie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Serge J. Belongie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48966748"
                        ],
                        "name": "James Hays",
                        "slug": "James-Hays",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Hays",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James Hays"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690922"
                        ],
                        "name": "P. Perona",
                        "slug": "P.-Perona",
                        "structuredName": {
                            "firstName": "Pietro",
                            "lastName": "Perona",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Perona"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1770537"
                        ],
                        "name": "D. Ramanan",
                        "slug": "D.-Ramanan",
                        "structuredName": {
                            "firstName": "Deva",
                            "lastName": "Ramanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Ramanan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3127283"
                        ],
                        "name": "Piotr Doll\u00e1r",
                        "slug": "Piotr-Doll\u00e1r",
                        "structuredName": {
                            "firstName": "Piotr",
                            "lastName": "Doll\u00e1r",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Piotr Doll\u00e1r"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699161"
                        ],
                        "name": "C. L. Zitnick",
                        "slug": "C.-L.-Zitnick",
                        "structuredName": {
                            "firstName": "C.",
                            "lastName": "Zitnick",
                            "middleNames": [
                                "Lawrence"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. L. Zitnick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 163
                            }
                        ],
                        "text": "We evaluate the model on the COCO mini-val [18] and test-dev dataset and report the mean average precision (mAP) as computed with the standard COCO metric library [26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14113767,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "71b7178df5d2b112d07e45038cb5637208659ff7",
            "isKey": false,
            "numCitedBy": 20273,
            "numCiting": 59,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model."
            },
            "slug": "Microsoft-COCO:-Common-Objects-in-Context-Lin-Maire",
            "title": {
                "fragments": [],
                "text": "Microsoft COCO: Common Objects in Context"
            },
            "tldr": {
                "abstractSimilarityScore": 91,
                "text": "A new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding by gathering images of complex everyday scenes containing common objects in their natural context."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1944541"
                        ],
                        "name": "R. J\u00f3zefowicz",
                        "slug": "R.-J\u00f3zefowicz",
                        "structuredName": {
                            "firstName": "Rafal",
                            "lastName": "J\u00f3zefowicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. J\u00f3zefowicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2563432"
                        ],
                        "name": "Wojciech Zaremba",
                        "slug": "Wojciech-Zaremba",
                        "structuredName": {
                            "firstName": "Wojciech",
                            "lastName": "Zaremba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wojciech Zaremba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "roaches in designing architectures such as Neural Fabrics [48], DiffRNN [41], MetaQNN [3] and DeepArchitect [43]. A more \ufb02exible class of methods for designing architecture is evolutionary algorithms [65, 16, 57, 30, 46, 42, 67], yet they have not had as much success at large scale. Xie and Yuille [67] also transferred learned architectures from CIFAR-10 to ImageNet but performance of these models (top-1 accuracy 72.1%) are "
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9668607,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5b8364c21155d3d2cd38ea4c8b8580beba9a3250",
            "isKey": true,
            "numCitedBy": 1395,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The Recurrent Neural Network (RNN) is an extremely powerful sequence model that is often difficult to train. The Long Short-Term Memory (LSTM) is a specific RNN architecture whose design makes it much easier to train. While wildly successful in practice, the LSTM's architecture appears to be ad-hoc so it is not clear if it is optimal, and the significance of its individual components is unclear. \n \nIn this work, we aim to determine whether the LSTM architecture is optimal or whether much better architectures exist. We conducted a thorough architecture search where we evaluated over ten thousand different RNN architectures, and identified an architecture that outperforms both the LSTM and the recently-introduced Gated Recurrent Unit (GRU) on some but not all tasks. We found that adding a bias of 1 to the LSTM's forget gate closes the gap between the LSTM and the GRU."
            },
            "slug": "An-Empirical-Exploration-of-Recurrent-Network-J\u00f3zefowicz-Zaremba",
            "title": {
                "fragments": [],
                "text": "An Empirical Exploration of Recurrent Network Architectures"
            },
            "tldr": {
                "abstractSimilarityScore": 36,
                "text": "It is found that adding a bias of 1 to the LSTM's forget gate closes the gap between the L STM and the recently-introduced Gated Recurrent Unit (GRU) on some but not all tasks."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32837403"
                        ],
                        "name": "J. Bergstra",
                        "slug": "J.-Bergstra",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bergstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bergstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2292273"
                        ],
                        "name": "Daniel Yamins",
                        "slug": "Daniel-Yamins",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Yamins",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Yamins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2042941"
                        ],
                        "name": "D. Cox",
                        "slug": "D.-Cox",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cox",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cox"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "rovide a viable search strategy, RL does signi\ufb01cantly improve our ability to learn neural architectures. 4. Related Work The proposed method is related to previous work in hyperparameter optimization [43, 4, 5, 53, 54, 6, 39] \u2013 especially recent approaches in designing architectures such as Neural Fabrics [47], DiffRNN [40], MetaQNN [3] and DeepArchitect [42]. A more \ufb02exible class of methods for designing architecture is "
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3356163,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "29935173af73aef20336db72d608e0ef5b0e0c16",
            "isKey": false,
            "numCitedBy": 1286,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Many computer vision algorithms depend on configuration settings that are typically hand-tuned in the course of evaluating the algorithm for a particular data set. While such parameter tuning is often presented as being incidental to the algorithm, correctly setting these parameter choices is frequently critical to realizing a method's full potential. Compounding matters, these parameters often must be re-tuned when the algorithm is applied to a new problem domain, and the tuning process itself often depends on personal experience and intuition in ways that are hard to quantify or describe. Since the performance of a given technique depends on both the fundamental quality of the algorithm and the details of its tuning, it is sometimes difficult to know whether a given technique is genuinely better, or simply better tuned. \n \nIn this work, we propose a meta-modeling approach to support automated hyperparameter optimization, with the goal of providing practical tools that replace hand-tuning with a reproducible and unbiased optimization process. Our approach is to expose the underlying expression graph of how a performance metric (e.g. classification accuracy on validation examples) is computed from hyperparameters that govern not only how individual processing steps are applied, but even which processing steps are included. A hyperparameter optimization algorithm transforms this graph into a program for optimizing that performance metric. Our approach yields state of the art results on three disparate computer vision problems: a face-matching verification task (LFW), a face identification task (PubFig83) and an object recognition task (CIFAR-10), using a single broad class of feed-forward vision architectures."
            },
            "slug": "Making-a-Science-of-Model-Search:-Hyperparameter-in-Bergstra-Yamins",
            "title": {
                "fragments": [],
                "text": "Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work proposes a meta-modeling approach to support automated hyperparameter optimization, with the goal of providing practical tools that replace hand-tuning with a reproducible and unbiased optimization process."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34917892"
                        ],
                        "name": "Djork-Arn\u00e9 Clevert",
                        "slug": "Djork-Arn\u00e9-Clevert",
                        "structuredName": {
                            "firstName": "Djork-Arn\u00e9",
                            "lastName": "Clevert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Djork-Arn\u00e9 Clevert"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2465270"
                        ],
                        "name": "Thomas Unterthiner",
                        "slug": "Thomas-Unterthiner",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Unterthiner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Unterthiner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308557"
                        ],
                        "name": "S. Hochreiter",
                        "slug": "S.-Hochreiter",
                        "structuredName": {
                            "firstName": "Sepp",
                            "lastName": "Hochreiter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hochreiter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 17
                            }
                        ],
                        "text": "Experiments with ELU nonlinearity [6] showed minimal benefit."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 22,
                                "start": 18
                            }
                        ],
                        "text": "We also tried ELU [10] instead of ReLUs and found that performance was about the same."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5273326,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f63e917638553414526a0cc8550de4ad2d83fe7a",
            "isKey": false,
            "numCitedBy": 3703,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce the \"exponential linear unit\" (ELU) which speeds up learning in deep neural networks and leads to higher classification accuracies. Like rectified linear units (ReLUs), leaky ReLUs (LReLUs) and parametrized ReLUs (PReLUs), ELUs alleviate the vanishing gradient problem via the identity for positive values. However, ELUs have improved learning characteristics compared to the units with other activation functions. In contrast to ReLUs, ELUs have negative values which allows them to push mean unit activations closer to zero like batch normalization but with lower computational complexity. Mean shifts toward zero speed up learning by bringing the normal gradient closer to the unit natural gradient because of a reduced bias shift effect. While LReLUs and PReLUs have negative values, too, they do not ensure a noise-robust deactivation state. ELUs saturate to a negative value with smaller inputs and thereby decrease the forward propagated variation and information. Therefore, ELUs code the degree of presence of particular phenomena in the input, while they do not quantitatively model the degree of their absence. In experiments, ELUs lead not only to faster learning, but also to significantly better generalization performance than ReLUs and LReLUs on networks with more than 5 layers. On CIFAR-100 ELUs networks significantly outperform ReLU networks with batch normalization while batch normalization does not improve ELU networks. ELU networks are among the top 10 reported CIFAR-10 results and yield the best published result on CIFAR-100, without resorting to multi-view evaluation or model averaging. On ImageNet, ELU networks considerably speed up learning compared to a ReLU network with the same architecture, obtaining less than 10% classification error for a single crop, single model network."
            },
            "slug": "Fast-and-Accurate-Deep-Network-Learning-by-Linear-Clevert-Unterthiner",
            "title": {
                "fragments": [],
                "text": "Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "The \"exponential linear unit\" (ELU) which speeds up learning in deep neural networks and leads to higher classification accuracies and significantly better generalization performance than ReLUs and LReLUs on networks with more than 5 layers."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2149140383"
                        ],
                        "name": "Ke Li",
                        "slug": "Ke-Li",
                        "structuredName": {
                            "firstName": "Ke",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ke Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143751119"
                        ],
                        "name": "Jitendra Malik",
                        "slug": "Jitendra-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jitendra Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 200
                            }
                        ],
                        "text": "The concept of having one neural network interact with a second neural network to aid the learning process, or learning to learn or meta-learning [23, 49] has attracted much attention in recent years [1, 62, 14, 19, 35, 45, 15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3083502,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5b8e5804c3adeb4a4e60f8f7d8d76aab0e02cfbe",
            "isKey": false,
            "numCitedBy": 94,
            "numCiting": 43,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning to Optimize is a recently proposed framework for learning optimization algorithms using reinforcement learning. In this paper, we explore learning an optimization algorithm for training shallow neural nets. Such high-dimensional stochastic optimization problems present interesting challenges for existing reinforcement learning algorithms. We develop an extension that is suited to learning optimization algorithms in this setting and demonstrate that the learned optimization algorithm consistently outperforms other known optimization algorithms even on unseen tasks and is robust to changes in stochasticity of gradients and the neural net architecture. More specifically, we show that an optimization algorithm trained with the proposed method on the problem of training a neural net on MNIST generalizes to the problems of training neural nets on the Toronto Faces Dataset, CIFAR-10 and CIFAR-100."
            },
            "slug": "Learning-to-Optimize-Neural-Nets-Li-Malik",
            "title": {
                "fragments": [],
                "text": "Learning to Optimize Neural Nets"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "An extension to Learning to Optimize is developed that is suited to learning optimization algorithms in this setting and it is demonstrated that the learned optimization algorithm consistently outperforms other known optimization algorithms even on unseen tasks and is robust to changes in stochasticity of gradients and the neural net architecture."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145276680"
                        ],
                        "name": "Dmitry Ulyanov",
                        "slug": "Dmitry-Ulyanov",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Ulyanov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dmitry Ulyanov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687524"
                        ],
                        "name": "A. Vedaldi",
                        "slug": "A.-Vedaldi",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Vedaldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vedaldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1740145"
                        ],
                        "name": "V. Lempitsky",
                        "slug": "V.-Lempitsky",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Lempitsky",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Lempitsky"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16516553,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "63de0ad39d807f0c256f851428f211e8d5fcd3bb",
            "isKey": false,
            "numCitedBy": 2223,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "It this paper we revisit the fast stylization method introduced in Ulyanov et. al. (2016). We show how a small change in the stylization architecture results in a significant qualitative improvement in the generated images. The change is limited to swapping batch normalization with instance normalization, and to apply the latter both at training and testing times. The resulting method can be used to train high-performance architectures for real-time image generation. The code will is made available on github at this https URL. Full paper can be found at arXiv:1701.02096."
            },
            "slug": "Instance-Normalization:-The-Missing-Ingredient-for-Ulyanov-Vedaldi",
            "title": {
                "fragments": [],
                "text": "Instance Normalization: The Missing Ingredient for Fast Stylization"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A small change in the stylization architecture results in a significant qualitative improvement in the generated images, and can be used to train high-performance architectures for real-time image generation."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3422336"
                        ],
                        "name": "A\u00e4ron van den Oord",
                        "slug": "A\u00e4ron-van-den-Oord",
                        "structuredName": {
                            "firstName": "A\u00e4ron",
                            "lastName": "Oord",
                            "middleNames": [
                                "van",
                                "den"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A\u00e4ron van den Oord"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48373216"
                        ],
                        "name": "S. Dieleman",
                        "slug": "S.-Dieleman",
                        "structuredName": {
                            "firstName": "Sander",
                            "lastName": "Dieleman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Dieleman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691713"
                        ],
                        "name": "H. Zen",
                        "slug": "H.-Zen",
                        "structuredName": {
                            "firstName": "Heiga",
                            "lastName": "Zen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Zen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34838386"
                        ],
                        "name": "K. Simonyan",
                        "slug": "K.-Simonyan",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Simonyan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Simonyan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689108"
                        ],
                        "name": "Oriol Vinyals",
                        "slug": "Oriol-Vinyals",
                        "structuredName": {
                            "firstName": "Oriol",
                            "lastName": "Vinyals",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oriol Vinyals"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753223"
                        ],
                        "name": "A. Graves",
                        "slug": "A.-Graves",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Graves",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Graves"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2583391"
                        ],
                        "name": "Nal Kalchbrenner",
                        "slug": "Nal-Kalchbrenner",
                        "structuredName": {
                            "firstName": "Nal",
                            "lastName": "Kalchbrenner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Nal Kalchbrenner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33666044"
                        ],
                        "name": "A. Senior",
                        "slug": "A.-Senior",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Senior",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Senior"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 111
                            }
                        ],
                        "text": "Furthermore, advances in convolutional architecture design may be applied to tasks outside of the image domain [38, 20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6254678,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "df0402517a7338ae28bc54acaac400de6b456a46",
            "isKey": false,
            "numCitedBy": 4703,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces WaveNet, a deep neural network for generating raw audio waveforms. The model is fully probabilistic and autoregressive, with the predictive distribution for each audio sample conditioned on all previous ones; nonetheless we show that it can be efficiently trained on data with tens of thousands of samples per second of audio. When applied to text-to-speech, it yields state-of-the-art performance, with human listeners rating it as significantly more natural sounding than the best parametric and concatenative systems for both English and Mandarin. A single WaveNet can capture the characteristics of many different speakers with equal fidelity, and can switch between them by conditioning on the speaker identity. When trained to model music, we find that it generates novel and often highly realistic musical fragments. We also show that it can be employed as a discriminative model, returning promising results for phoneme recognition."
            },
            "slug": "WaveNet:-A-Generative-Model-for-Raw-Audio-Oord-Dieleman",
            "title": {
                "fragments": [],
                "text": "WaveNet: A Generative Model for Raw Audio"
            },
            "tldr": {
                "abstractSimilarityScore": 52,
                "text": "WaveNet, a deep neural network for generating raw audio waveforms, is introduced; it is shown that it can be efficiently trained on data with tens of thousands of samples per second of audio, and can be employed as a discriminative model, returning promising results for phoneme recognition."
            },
            "venue": {
                "fragments": [],
                "text": "SSW"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144108062"
                        ],
                        "name": "Jasper Snoek",
                        "slug": "Jasper-Snoek",
                        "structuredName": {
                            "firstName": "Jasper",
                            "lastName": "Snoek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jasper Snoek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1777528"
                        ],
                        "name": "H. Larochelle",
                        "slug": "H.-Larochelle",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Larochelle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Larochelle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1722180"
                        ],
                        "name": "Ryan P. Adams",
                        "slug": "Ryan-P.-Adams",
                        "structuredName": {
                            "firstName": "Ryan",
                            "lastName": "Adams",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ryan P. Adams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "rovide a viable search strategy, RL does signi\ufb01cantly improve our ability to learn neural architectures. 4. Related Work The proposed method is related to previous work in hyperparameter optimization [43, 4, 5, 53, 54, 6, 39] \u2013 especially recent approaches in designing architectures such as Neural Fabrics [47], DiffRNN [40], MetaQNN [3] and DeepArchitect [42]. A more \ufb02exible class of methods for designing architecture is "
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 632197,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2e2089ae76fe914706e6fa90081a79c8fe01611e",
            "isKey": false,
            "numCitedBy": 5088,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters. Unfortunately, this tuning is often a \"black art\" requiring expert experience, rules of thumb, or sometimes brute-force search. There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. In this work, we consider this problem through the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). We show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expertlevel performance. We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks."
            },
            "slug": "Practical-Bayesian-Optimization-of-Machine-Learning-Snoek-Larochelle",
            "title": {
                "fragments": [],
                "text": "Practical Bayesian Optimization of Machine Learning Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work describes new algorithms that take into account the variable cost of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation and shows that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2206490"
                        ],
                        "name": "Marcin Andrychowicz",
                        "slug": "Marcin-Andrychowicz",
                        "structuredName": {
                            "firstName": "Marcin",
                            "lastName": "Andrychowicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marcin Andrychowicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715051"
                        ],
                        "name": "Misha Denil",
                        "slug": "Misha-Denil",
                        "structuredName": {
                            "firstName": "Misha",
                            "lastName": "Denil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Misha Denil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2016840"
                        ],
                        "name": "Sergio Gomez Colmenarejo",
                        "slug": "Sergio-Gomez-Colmenarejo",
                        "structuredName": {
                            "firstName": "Sergio",
                            "lastName": "Colmenarejo",
                            "middleNames": [
                                "Gomez"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sergio Gomez Colmenarejo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3243579"
                        ],
                        "name": "Matthew W. Hoffman",
                        "slug": "Matthew-W.-Hoffman",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Hoffman",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew W. Hoffman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144846367"
                        ],
                        "name": "D. Pfau",
                        "slug": "D.-Pfau",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Pfau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Pfau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725157"
                        ],
                        "name": "T. Schaul",
                        "slug": "T.-Schaul",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "Schaul",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Schaul"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "The concept of having one neural network interact with a second neural network to aid the learning process, or learning to learn or meta-learning [23, 49] has attracted much attention in recent years [1, 62, 14, 19, 35, 45, 15]. Most of these approaches have not been scaled to large problems like ImageNet. An exception is the recent work focused on learning an optimizer for ImageNet classi\ufb01cation that achieved notable impro"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2928017,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "395dd01c0d24777c660cf195c4cfadcdf51fb7e8",
            "isKey": false,
            "numCitedBy": 1347,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "The move from hand-designed features to learned features in machine learning has been wildly successful. In spite of this, optimization algorithms are still designed by hand. In this paper we show how the design of an optimization algorithm can be cast as a learning problem, allowing the algorithm to learn to exploit structure in the problems of interest in an automatic way. Our learned algorithms, implemented by LSTMs, outperform generic, hand-designed competitors on the tasks for which they are trained, and also generalize well to new tasks with similar structure. We demonstrate this on a number of tasks, including simple convex problems, training neural networks, and styling images with neural art."
            },
            "slug": "Learning-to-learn-by-gradient-descent-by-gradient-Andrychowicz-Denil",
            "title": {
                "fragments": [],
                "text": "Learning to learn by gradient descent by gradient descent"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper shows how the design of an optimization algorithm can be cast as a learning problem, allowing the algorithm to learn to exploit structure in the problems of interest in an automatic way."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34652567"
                        ],
                        "name": "Gustav Larsson",
                        "slug": "Gustav-Larsson",
                        "structuredName": {
                            "firstName": "Gustav",
                            "lastName": "Larsson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gustav Larsson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145854440"
                        ],
                        "name": "M. Maire",
                        "slug": "M.-Maire",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Maire",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Maire"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2490189"
                        ],
                        "name": "Gregory Shakhnarovich",
                        "slug": "Gregory-Shakhnarovich",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Shakhnarovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gregory Shakhnarovich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "In DropPath [33], each path in the cell is stochastically dropped with some fixed probability during training."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 100
                            }
                        ],
                        "text": "Importantly, when training NASNets, we discovered ScheduledDropPath, a modified version of DropPath [33], to be an effective regularization method for NASNet."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3067546,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0156126edbfc524c8d108bdc0cf811cfe3129aa",
            "isKey": false,
            "numCitedBy": 639,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a design strategy for neural network macro-architecture based on self-similarity. Repeated application of a simple expansion rule generates deep networks whose structural layouts are precisely truncated fractals. These networks contain interacting subpaths of different lengths, but do not include any pass-through or residual connections; every internal signal is transformed by a filter and nonlinearity before being seen by subsequent layers. In experiments, fractal networks match the excellent performance of standard residual networks on both CIFAR and ImageNet classification tasks, thereby demonstrating that residual representations may not be fundamental to the success of extremely deep convolutional neural networks. Rather, the key may be the ability to transition, during training, from effectively shallow to deep. We note similarities with student-teacher behavior and develop drop-path, a natural extension of dropout, to regularize co-adaptation of subpaths in fractal architectures. Such regularization allows extraction of high-performance fixed-depth subnetworks. Additionally, fractal networks exhibit an anytime property: shallow subnetworks provide a quick answer, while deeper subnetworks, with higher latency, provide a more accurate answer."
            },
            "slug": "FractalNet:-Ultra-Deep-Neural-Networks-without-Larsson-Maire",
            "title": {
                "fragments": [],
                "text": "FractalNet: Ultra-Deep Neural Networks without Residuals"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "In experiments, fractal networks match the excellent performance of standard residual networks on both CIFAR and ImageNet classification tasks, thereby demonstrating that residual representations may not be fundamental to the success of extremely deep convolutional neural networks."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1934321"
                        ],
                        "name": "Thomas Miconi",
                        "slug": "Thomas-Miconi",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Miconi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Miconi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 200
                            }
                        ],
                        "text": "The proposed method is related to previous work in hyperparameter optimization [44, 4, 5, 54, 55, 6, 40] \u2013 especially recent approaches in designing architectures such as Neural Fabrics [48], DiffRNN [41], MetaQNN [3] and DeepArchitect [43]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14269411,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0441224d76250b03beefae64fa6c6d0879db12a8",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "While gradient descent has proven highly successful in learning connection weights for neural networks, the actual structure of these networks is usually determined by hand, or by other optimization algorithms. Here we describe a simple method to make network structure differentiable, and therefore accessible to gradient descent. We test this method on recurrent neural networks applied to simple sequence prediction problems. Starting with initial networks containing only one node, the method automatically builds networks that successfully solve the tasks. The number of nodes in the final network correlates with task difficulty. The method can dynamically increase network size in response to an abrupt complexification in the task; however, reduction in network size in response to task simplification is not evident for reasonable meta-parameters. The method does not penalize network performance for these test tasks: variable-size networks actually reach better performance than fixed-size networks of higher, lower or identical size. We conclude by discussing how this method could be applied to more complex networks, such as feedforward layered networks, or multiple-area networks of arbitrary shape."
            },
            "slug": "Neural-networks-with-differentiable-structure-Miconi",
            "title": {
                "fragments": [],
                "text": "Neural networks with differentiable structure"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work describes a simple method to make network structure differentiable, and therefore accessible to gradient descent, and test this method on recurrent neural networks applied to simple sequence prediction problems."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116439278"
                        ],
                        "name": "Jane X. Wang",
                        "slug": "Jane-X.-Wang",
                        "structuredName": {
                            "firstName": "Jane",
                            "lastName": "Wang",
                            "middleNames": [
                                "X."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jane X. Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1399114225"
                        ],
                        "name": "Z. Kurth-Nelson",
                        "slug": "Z.-Kurth-Nelson",
                        "structuredName": {
                            "firstName": "Zeb",
                            "lastName": "Kurth-Nelson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Z. Kurth-Nelson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2794457"
                        ],
                        "name": "Hubert Soyer",
                        "slug": "Hubert-Soyer",
                        "structuredName": {
                            "firstName": "Hubert",
                            "lastName": "Soyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hubert Soyer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1700356"
                        ],
                        "name": "Joel Z. Leibo",
                        "slug": "Joel-Z.-Leibo",
                        "structuredName": {
                            "firstName": "Joel",
                            "lastName": "Leibo",
                            "middleNames": [
                                "Z."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joel Z. Leibo"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7794353"
                        ],
                        "name": "Dhruva Tirumala",
                        "slug": "Dhruva-Tirumala",
                        "structuredName": {
                            "firstName": "Dhruva",
                            "lastName": "Tirumala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dhruva Tirumala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1708654"
                        ],
                        "name": "R. Munos",
                        "slug": "R.-Munos",
                        "structuredName": {
                            "firstName": "R\u00e9mi",
                            "lastName": "Munos",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Munos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1723876"
                        ],
                        "name": "C. Blundell",
                        "slug": "C.-Blundell",
                        "structuredName": {
                            "firstName": "Charles",
                            "lastName": "Blundell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Blundell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2106164"
                        ],
                        "name": "D. Kumaran",
                        "slug": "D.-Kumaran",
                        "structuredName": {
                            "firstName": "Dharshan",
                            "lastName": "Kumaran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Kumaran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46378362"
                        ],
                        "name": "M. Botvinick",
                        "slug": "M.-Botvinick",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Botvinick",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Botvinick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 200
                            }
                        ],
                        "text": "The concept of having one neural network interact with a second neural network to aid the learning process, or learning to learn or meta-learning [23, 49] has attracted much attention in recent years [1, 62, 14, 19, 35, 45, 15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13623631,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "282a380fb5ac26d99667224cef8c630f6882704f",
            "isKey": false,
            "numCitedBy": 636,
            "numCiting": 60,
            "paperAbstract": {
                "fragments": [],
                "text": "In recent years deep reinforcement learning (RL) systems have attained superhuman performance in a number of challenging task domains. However, a major limitation of such applications is their demand for massive amounts of training data. A critical present objective is thus to develop deep RL methods that can adapt rapidly to new tasks. In the present work we introduce a novel approach to this challenge, which we refer to as deep meta-reinforcement learning. Previous work has shown that recurrent networks can support meta-learning in a fully supervised context. We extend this approach to the RL setting. What emerges is a system that is trained using one RL algorithm, but whose recurrent dynamics implement a second, quite separate RL procedure. This second, learned RL algorithm can differ from the original one in arbitrary ways. Importantly, because it is learned, it is configured to exploit structure in the training domain. We unpack these points in a series of seven proof-of-concept experiments, each of which examines a key aspect of deep meta-RL. We consider prospects for extending and scaling up the approach, and also point out some potentially important implications for neuroscience."
            },
            "slug": "Learning-to-reinforcement-learn-Wang-Kurth-Nelson",
            "title": {
                "fragments": [],
                "text": "Learning to reinforcement learn"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "This work introduces a novel approach to deep meta-reinforcement learning, which is a system that is trained using one RL algorithm, but whose recurrent dynamics implement a second, quite separate RL procedure."
            },
            "venue": {
                "fragments": [],
                "text": "CogSci"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "12508466"
                        ],
                        "name": "Xavier Gastaldi",
                        "slug": "Xavier-Gastaldi",
                        "structuredName": {
                            "firstName": "Xavier",
                            "lastName": "Gastaldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xavier Gastaldi"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 58
                            }
                        ],
                        "text": "A small version of the state-of-the-art Shake-Shake model [10] with 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 8134165,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "22aa426aeffb77339646cc03da8e94de22396efc",
            "isKey": false,
            "numCitedBy": 53,
            "numCiting": 18,
            "paperAbstract": {
                "fragments": [],
                "text": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem. The idea is to replace, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination. The largest tested model improves on the best single shot published result on CIFAR10 by reaching 2.86% test error. Code is available at https://github.com/ xgastaldi/shake-shake"
            },
            "slug": "Shake-Shake-regularization-of-3-branch-residual-Gastaldi",
            "title": {
                "fragments": [],
                "text": "Shake-Shake regularization of 3-branch residual networks"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "The method introduced in this paper aims at helping computer vision practitioners faced with an overfit problem by replacing, in a 3-branch ResNet, the standard summation of residual branches by a stochastic affine combination."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144581158"
                        ],
                        "name": "Yan Duan",
                        "slug": "Yan-Duan",
                        "structuredName": {
                            "firstName": "Yan",
                            "lastName": "Duan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yan Duan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47971768"
                        ],
                        "name": "J. Schulman",
                        "slug": "J.-Schulman",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Schulman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schulman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41192764"
                        ],
                        "name": "Xi Chen",
                        "slug": "Xi-Chen",
                        "structuredName": {
                            "firstName": "Xi",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xi Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745169"
                        ],
                        "name": "P. Bartlett",
                        "slug": "P.-Bartlett",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Bartlett",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Bartlett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689992"
                        ],
                        "name": "P. Abbeel",
                        "slug": "P.-Abbeel",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Abbeel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Abbeel"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 200
                            }
                        ],
                        "text": "The concept of having one neural network interact with a second neural network to aid the learning process, or learning to learn or meta-learning [21, 41] has attracted much attention in recent years [1, 13, 14, 18, 32, 38, 52]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14763001,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "954b01151ff13aef416d27adc60cd9a076753b1a",
            "isKey": false,
            "numCitedBy": 634,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep reinforcement learning (deep RL) has been successful in learning sophisticated behaviors automatically; however, the learning process requires a huge number of trials. In contrast, animals can learn new tasks in just a few trials, benefiting from their prior knowledge about the world. This paper seeks to bridge this gap. Rather than designing a \"fast\" reinforcement learning algorithm, we propose to represent it as a recurrent neural network (RNN) and learn it from data. In our proposed method, RL$^2$, the algorithm is encoded in the weights of the RNN, which are learned slowly through a general-purpose (\"slow\") RL algorithm. The RNN receives all information a typical RL algorithm would receive, including observations, actions, rewards, and termination flags; and it retains its state across episodes in a given Markov Decision Process (MDP). The activations of the RNN store the state of the \"fast\" RL algorithm on the current (previously unseen) MDP. We evaluate RL$^2$ experimentally on both small-scale and large-scale problems. On the small-scale side, we train it to solve randomly generated multi-arm bandit problems and finite MDPs. After RL$^2$ is trained, its performance on new MDPs is close to human-designed algorithms with optimality guarantees. On the large-scale side, we test RL$^2$ on a vision-based navigation task and show that it scales up to high-dimensional problems."
            },
            "slug": "RL$^2$:-Fast-Reinforcement-Learning-via-Slow-Duan-Schulman",
            "title": {
                "fragments": [],
                "text": "RL$^2$: Fast Reinforcement Learning via Slow Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes to represent a \"fast\" reinforcement learning algorithm as a recurrent neural network (RNN) and learn it from data, encoded in the weights of the RNN, which are learned slowly through a general-purpose (\"slow\") RL algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1846883"
                        ],
                        "name": "Kenneth O. Stanley",
                        "slug": "Kenneth-O.-Stanley",
                        "structuredName": {
                            "firstName": "Kenneth",
                            "lastName": "Stanley",
                            "middleNames": [
                                "O."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kenneth O. Stanley"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1401079497"
                        ],
                        "name": "David B. D'Ambrosio",
                        "slug": "David-B.-D'Ambrosio",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "D'Ambrosio",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David B. D'Ambrosio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3351507"
                        ],
                        "name": "J. Gauci",
                        "slug": "J.-Gauci",
                        "structuredName": {
                            "firstName": "Jason",
                            "lastName": "Gauci",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gauci"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "roaches in designing architectures such as Neural Fabrics [48], DiffRNN [41], MetaQNN [3] and DeepArchitect [43]. A more \ufb02exible class of methods for designing architecture is evolutionary algorithms [65, 16, 57, 30, 46, 42, 67], yet they have not had as much success at large scale. Xie and Yuille [67] also transferred learned architectures from CIFAR-10 to ImageNet but performance of these models (top-1 accuracy 72.1%) are "
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 26390526,
            "fieldsOfStudy": [
                "Biology",
                "Computer Science"
            ],
            "id": "6e744cf0273a84b087e94191fd654210e8fec8e9",
            "isKey": true,
            "numCitedBy": 702,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Research in neuroevolutionthat is, evolving artificial neural networks (ANNs) through evolutionary algorithmsis inspired by the evolution of biological brains, which can contain trillions of connections. Yet while neuroevolution has produced successful results, the scale of natural brains remains far beyond reach. This article presents a method called hypercube-based NeuroEvolution of Augmenting Topologies (HyperNEAT) that aims to narrow this gap. HyperNEAT employs an indirect encoding called connective compositional pattern-producing networks (CPPNs) that can produce connectivity patterns with symmetries and repeating motifs by interpreting spatial patterns generated within a hypercube as connectivity patterns in a lower-dimensional space. This approach can exploit the geometry of the task by mapping its regularities onto the topology of the network, thereby shifting problem difficulty away from dimensionality to the underlying problem structure. Furthermore, connective CPPNs can represent the same connectivity pattern at any resolution, allowing ANNs to scale to new numbers of inputs and outputs without further evolution. HyperNEAT is demonstrated through visual discrimination and food-gathering tasks, including successful visual discrimination networks containing over eight million connections. The main conclusion is that the ability to explore the space of regular connectivity patterns opens up a new class of complex high-dimensional tasks to neuroevolution."
            },
            "slug": "A-Hypercube-Based-Encoding-for-Evolving-Large-Scale-Stanley-D'Ambrosio",
            "title": {
                "fragments": [],
                "text": "A Hypercube-Based Encoding for Evolving Large-Scale Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The main conclusion is that the ability to explore the space of regular connectivity patterns opens up a new class of complex high-dimensional tasks to neuroevolution."
            },
            "venue": {
                "fragments": [],
                "text": "Artificial Life"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3160228"
                        ],
                        "name": "K. Fukushima",
                        "slug": "K.-Fukushima",
                        "structuredName": {
                            "firstName": "Kunihiko",
                            "lastName": "Fukushima",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Fukushima"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206775608,
            "fieldsOfStudy": [
                "Computer Science",
                "Biology"
            ],
            "id": "69e68bfaadf2dccff800158749f5a50fe82d173b",
            "isKey": false,
            "numCitedBy": 3740,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "A neural network model for a mechanism of visual pattern recognition is proposed in this paper. The network is self-organized by \u201clearning without a teacher\u201d, and acquires an ability to recognize stimulus patterns based on the geometrical similarity (Gestalt) of their shapes without affected by their positions. This network is given a nickname \u201cneocognitron\u201d. After completion of self-organization, the network has a structure similar to the hierarchy model of the visual nervous system proposed by Hubel and Wiesel. The network consits of an input layer (photoreceptor array) followed by a cascade connection of a number of modular structures, each of which is composed of two layers of cells connected in a cascade. The first layer of each module consists of \u201cS-cells\u201d, which show characteristics similar to simple cells or lower order hypercomplex cells, and the second layer consists of \u201cC-cells\u201d similar to complex cells or higher order hypercomplex cells. The afferent synapses to each S-cell have plasticity and are modifiable. The network has an ability of unsupervised learning: We do not need any \u201cteacher\u201d during the process of self-organization, and it is only needed to present a set of stimulus patterns repeatedly to the input layer of the network. The network has been simulated on a digital computer. After repetitive presentation of a set of stimulus patterns, each stimulus pattern has become to elicit an output only from one of the C-cell of the last layer, and conversely, this C-cell has become selectively responsive only to that stimulus pattern. That is, none of the C-cells of the last layer responds to more than one stimulus pattern. The response of the C-cells of the last layer is not affected by the pattern's position at all. Neither is it affected by a small change in shape nor in size of the stimulus pattern."
            },
            "slug": "Neocognitron:-A-self-organizing-neural-network-for-Fukushima",
            "title": {
                "fragments": [],
                "text": "Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position"
            },
            "tldr": {
                "abstractSimilarityScore": 86,
                "text": "A neural network model for a mechanism of visual pattern recognition that is self-organized by \u201clearning without a teacher\u201d, and acquires an ability to recognize stimulus patterns based on the geometrical similarity of their shapes without affected by their positions."
            },
            "venue": {
                "fragments": [],
                "text": "Biological Cybernetics"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308557"
                        ],
                        "name": "S. Hochreiter",
                        "slug": "S.-Hochreiter",
                        "structuredName": {
                            "firstName": "Sepp",
                            "lastName": "Hochreiter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hochreiter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145547836"
                        ],
                        "name": "A. S. Younger",
                        "slug": "A.-S.-Younger",
                        "structuredName": {
                            "firstName": "Arthur",
                            "lastName": "Younger",
                            "middleNames": [
                                "Steven"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. S. Younger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2927101"
                        ],
                        "name": "P. R. Conwell",
                        "slug": "P.-R.-Conwell",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Conwell",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. R. Conwell"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "re notably below previous state-of-the-art (Table 2). The concept of having one neural network interact with a second neural network to aid the learning process, or learning to learn or meta-learning [23, 49] has attracted much attention in recent years [1, 62, 14, 19, 35, 45, 15]. Most of these approaches have not been scaled to large problems like ImageNet. An exception is the recent work focused on lea"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 52872549,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "044b2c29e0a54dc689786bd4d029b9ba6e355d58",
            "isKey": false,
            "numCitedBy": 497,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper introduces the application of gradient descent methods to meta-learning. The concept of \"meta-learning\", i.e. of a system that improves or discovers a learning algorithm, has been of interest in machine learning for decades because of its appealing applications. Previous meta-learning approaches have been based on evolutionary methods and, therefore, have been restricted to small models with few free parameters. We make meta-learning in large systems feasible by using recurrent neural networks withth eir attendant learning routines as meta-learning systems. Our system derived complex well performing learning algorithms from scratch. In this paper we also show that our approachp erforms non-stationary time series prediction."
            },
            "slug": "Learning-to-Learn-Using-Gradient-Descent-Hochreiter-Younger",
            "title": {
                "fragments": [],
                "text": "Learning to Learn Using Gradient Descent"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This paper makes meta- learning in large systems feasible by using recurrent neural networks with attendant learning routines as meta-learning systems and shows that the approach to gradient descent methods forms non-stationary time series prediction."
            },
            "venue": {
                "fragments": [],
                "text": "ICANN"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1389041357"
                        ],
                        "name": "David Ha",
                        "slug": "David-Ha",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Ha",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Ha"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2555924"
                        ],
                        "name": "Andrew M. Dai",
                        "slug": "Andrew-M.-Dai",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Dai",
                            "middleNames": [
                                "M."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew M. Dai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 200
                            }
                        ],
                        "text": "The concept of having one neural network interact with a second neural network to aid the learning process, or learning to learn or meta-learning [23, 48] has attracted much attention in recent years [1, 61, 14, 19, 34, 44, 15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 208981547,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "563783de03452683a9206e85fe6d661714436686",
            "isKey": false,
            "numCitedBy": 383,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "This work explores hypernetworks: an approach of using one network, also known as a hypernetwork, to generate the weights for another network. We apply hypernetworks to generate adaptive weights for recurrent networks. In this case, hypernetworks can be viewed as a relaxed form of weight-sharing across layers. In our implementation, hypernetworks are are trained jointly with the main network in an end-to-end fashion. Our main result is that hypernetworks can generate non-shared weights for LSTM and achieve state-of-the-art results on a variety of sequence modelling tasks including character-level language modelling, handwriting generation and neural machine translation, challenging the weight-sharing paradigm for recurrent networks."
            },
            "slug": "HyperNetworks-Ha-Dai",
            "title": {
                "fragments": [],
                "text": "HyperNetworks"
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678656"
                        ],
                        "name": "I. Loshchilov",
                        "slug": "I.-Loshchilov",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Loshchilov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "I. Loshchilov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14337532,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b022f2a277a4bf5f42382e86e4380b96340b9e86",
            "isKey": false,
            "numCitedBy": 2822,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Restart techniques are common in gradient-free optimization to deal with multimodal functions. Partial warm restarts are also gaining popularity in gradient-based optimization to improve the rate of convergence in accelerated gradient schemes to deal with ill-conditioned functions. In this paper, we propose a simple warm restart technique for stochastic gradient descent to improve its anytime performance when training deep neural networks. We empirically study its performance on the CIFAR-10 and CIFAR-100 datasets, where we demonstrate new state-of-the-art results at 3.14% and 16.21%, respectively. We also demonstrate its advantages on a dataset of EEG recordings and on a downsampled version of the ImageNet dataset. Our source code is available at this https URL"
            },
            "slug": "SGDR:-Stochastic-Gradient-Descent-with-Warm-Loshchilov-Hutter",
            "title": {
                "fragments": [],
                "text": "SGDR: Stochastic Gradient Descent with Warm Restarts"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper proposes a simple warm restart technique for stochastic gradient descent to improve its anytime performance when training deep neural networks and empirically studies its performance on the CIFAR-10 and CIFARS datasets."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3308557"
                        ],
                        "name": "S. Hochreiter",
                        "slug": "S.-Hochreiter",
                        "structuredName": {
                            "firstName": "Sepp",
                            "lastName": "Hochreiter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hochreiter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 68,
                                "start": 64
                            }
                        ],
                        "text": "The design of our search space took much inspiration from LSTMs [22], and Neural Architecture Search Cell [71]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1915014,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44d2abe2175df8153f465f6c39b68b76a0d40ab9",
            "isKey": false,
            "numCitedBy": 52390,
            "numCiting": 68,
            "paperAbstract": {
                "fragments": [],
                "text": "Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms."
            },
            "slug": "Long-Short-Term-Memory-Hochreiter-Schmidhuber",
            "title": {
                "fragments": [],
                "text": "Long Short-Term Memory"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A novel, efficient, gradient based method called long short-term memory (LSTM) is introduced, which can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units."
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065953606"
                        ],
                        "name": "Hector Mendoza",
                        "slug": "Hector-Mendoza",
                        "structuredName": {
                            "firstName": "Hector",
                            "lastName": "Mendoza",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hector Mendoza"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145227684"
                        ],
                        "name": "Aaron Klein",
                        "slug": "Aaron-Klein",
                        "structuredName": {
                            "firstName": "Aaron",
                            "lastName": "Klein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aaron Klein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2868444"
                        ],
                        "name": "Matthias Feurer",
                        "slug": "Matthias-Feurer",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Feurer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthias Feurer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2060551"
                        ],
                        "name": "Jost Tobias Springenberg",
                        "slug": "Jost-Tobias-Springenberg",
                        "structuredName": {
                            "firstName": "Jost",
                            "lastName": "Springenberg",
                            "middleNames": [
                                "Tobias"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jost Tobias Springenberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "rovide a viable search strategy, RL does signi\ufb01cantly improve our ability to learn neural architectures. 4. Related Work The proposed method is related to previous work in hyperparameter optimization [43, 4, 5, 53, 54, 6, 39] \u2013 especially recent approaches in designing architectures such as Neural Fabrics [47], DiffRNN [40], MetaQNN [3] and DeepArchitect [42]. A more \ufb02exible class of methods for designing architecture is "
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 17013332,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "06b2a66c86c270e24a2177f816c6bc6e971819ee",
            "isKey": false,
            "numCitedBy": 155,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent advances in AutoML have led to automated tools that can compete with machine learning experts on supervised learning tasks. However, current AutoML tools do not yet support modern neural networks effectively. In this work, we present a first version of AutoNet, which provides automatically-tuned feed-forward neural networks without any human intervention. We report results on datasets from the recent AutoML challenge showing that ensembling Auto-Net with Auto-sklearn can perform better than either approach alone and report the first results on winning competition datasets against human experts with automatically-tuned neural networks."
            },
            "slug": "Towards-Automatically-Tuned-Neural-Networks-Mendoza-Klein",
            "title": {
                "fragments": [],
                "text": "Towards Automatically-Tuned Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A first version of AutoNet is presented, which provides automatically-tuned feed-forward neural networks without any human intervention, and results on datasets from the recent AutoML challenge showing that ensembling Auto-Net with Auto-sklearn can perform better than either approach alone."
            },
            "venue": {
                "fragments": [],
                "text": "AutoML@ICML"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108406634"
                        ],
                        "name": "Jianmin Chen",
                        "slug": "Jianmin-Chen",
                        "structuredName": {
                            "firstName": "Jianmin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jianmin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3089272"
                        ],
                        "name": "R. Monga",
                        "slug": "R.-Monga",
                        "structuredName": {
                            "firstName": "Rajat",
                            "lastName": "Monga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Monga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751569"
                        ],
                        "name": "Samy Bengio",
                        "slug": "Samy-Bengio",
                        "structuredName": {
                            "firstName": "Samy",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Samy Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1944541"
                        ],
                        "name": "R. J\u00f3zefowicz",
                        "slug": "R.-J\u00f3zefowicz",
                        "structuredName": {
                            "firstName": "Rafal",
                            "lastName": "J\u00f3zefowicz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. J\u00f3zefowicz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 593493,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "25fb5a6abcd88ee52bdb3165b844c941e90eb9bf",
            "isKey": false,
            "numCitedBy": 606,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Distributed training of deep learning models on large-scale training data is typically conducted with asynchronous stochastic optimization to maximize the rate of updates, at the cost of additional noise introduced from asynchrony. In contrast, the synchronous approach is often thought to be impractical due to idle time wasted on waiting for straggling workers. We revisit these conventional beliefs in this paper, and examine the weaknesses of both approaches. We demonstrate that a third approach, synchronous optimization with backup workers, can avoid asynchronous noise while mitigating for the worst stragglers. Our approach is empirically validated and shown to converge faster and to better test accuracies."
            },
            "slug": "Revisiting-Distributed-Synchronous-SGD-Chen-Monga",
            "title": {
                "fragments": [],
                "text": "Revisiting Distributed Synchronous SGD"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is demonstrated that a third approach, synchronous optimization with backup workers, can avoid asynchronous noise while mitigating for the worst stragglers and is empirically validated and shown to converge faster and to better test accuracies."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2332513,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4c915c1eecb217c123a36dc6d3ce52d12c742614",
            "isKey": false,
            "numCitedBy": 5268,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units. These algorithms, called REINFORCE algorithms, are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reinforcement tasks, and they do this without explicitly computing gradient estimates or even storing information from which such estimates could be computed. Specific examples of such algorithms are presented, some of which bear a close relationship to certain existing algorithms while others are novel but potentially interesting in their own right. Also given are results that show how such algorithms can be naturally integrated with backpropagation. We close with a brief discussion of a number of additional issues surrounding the use of such algorithms, including what is known about their limiting behaviors as well as further considerations that might be used to help develop similar but potentially more powerful reinforcement learning algorithms."
            },
            "slug": "Simple-statistical-gradient-following-algorithms-Williams",
            "title": {
                "fragments": [],
                "text": "Simple statistical gradient-following algorithms for connectionist reinforcement learning"
            },
            "tldr": {
                "abstractSimilarityScore": 90,
                "text": "This article presents a general class of associative reinforcement learning algorithms for connectionist networks containing stochastic units that are shown to make weight adjustments in a direction that lies along the gradient of expected reinforcement in both immediate-reinforcement tasks and certain limited forms of delayed-reInforcement tasks, and they do this without explicitly computing gradient estimates."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1742820"
                        ],
                        "name": "D. Floreano",
                        "slug": "D.-Floreano",
                        "structuredName": {
                            "firstName": "Dario",
                            "lastName": "Floreano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Floreano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066182179"
                        ],
                        "name": "Peter D\u00fcrr",
                        "slug": "Peter-D\u00fcrr",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "D\u00fcrr",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter D\u00fcrr"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2288013"
                        ],
                        "name": "C. Mattiussi",
                        "slug": "C.-Mattiussi",
                        "structuredName": {
                            "firstName": "Claudio",
                            "lastName": "Mattiussi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Mattiussi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "roaches in designing architectures such as Neural Fabrics [48], DiffRNN [41], MetaQNN [3] and DeepArchitect [43]. A more \ufb02exible class of methods for designing architecture is evolutionary algorithms [65, 16, 57, 30, 46, 42, 67], yet they have not had as much success at large scale. Xie and Yuille [67] also transferred learned architectures from CIFAR-10 to ImageNet but performance of these models (top-1 accuracy 72.1%) are "
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2942634,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cf7bdff21a875e5d043514ed0714fafae77e1492",
            "isKey": true,
            "numCitedBy": 652,
            "numCiting": 119,
            "paperAbstract": {
                "fragments": [],
                "text": "Artificial neural networks (ANNs) are applied to many real-world problems, ranging from pattern classification to robot control. In order to design a neural network for a particular task, the choice of an architecture (including the choice of a neuron model), and the choice of a learning algorithm have to be addressed. Evolutionary search methods can provide an automatic solution to these problems. New insights in both neuroscience and evolutionary biology have led to the development of increasingly powerful neuroevolution techniques over the last decade. This paper gives an overview of the most prominent methods for evolving ANNs with a special focus on recent advances in the synthesis of learning architectures."
            },
            "slug": "Neuroevolution:-from-architectures-to-learning-Floreano-D\u00fcrr",
            "title": {
                "fragments": [],
                "text": "Neuroevolution: from architectures to learning"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper gives an overview of the most prominent methods for evolving ANNs with a special focus on recent advances in the synthesis of learning architectures."
            },
            "venue": {
                "fragments": [],
                "text": "Evol. Intell."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32837403"
                        ],
                        "name": "J. Bergstra",
                        "slug": "J.-Bergstra",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Bergstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Bergstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 79
                            }
                        ],
                        "text": "The proposed method is related to previous work in hyperparameter optimization [4, 5, 6, 33, 37, 45, 46] \u2013 especially recent approaches in designing architectures such as Neural Fabrics [40], DiffRNN [34], MetaQNN [3] and DeepArchitect [36]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15700257,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "188e247506ad992b8bc62d6c74789e89891a984f",
            "isKey": false,
            "numCitedBy": 5726,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Grid search and manual search are the most widely used strategies for hyper-parameter optimization. This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid. Empirical evidence comes from a comparison with a large previous study that used grid search and manual search to configure neural networks and deep belief networks. Compared with neural networks configured by a pure grid search, we find that random search over the same domain is able to find models that are as good or better within a small fraction of the computation time. Granting random search the same computational budget, random search finds better models by effectively searching a larger, less promising configuration space. Compared with deep belief networks configured by a thoughtful combination of manual search and grid search, purely random search over the same 32-dimensional configuration space found statistically equal performance on four of seven data sets, and superior performance on one of seven. A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets. This phenomenon makes grid search a poor choice for configuring algorithms for new data sets. Our analysis casts some light on why recent \"High Throughput\" methods achieve surprising success--they appear to search through a large number of hyper-parameters because most hyper-parameters do not matter much. We anticipate that growing interest in large hierarchical models will place an increasing burden on techniques for hyper-parameter optimization; this work shows that random search is a natural baseline against which to judge progress in the development of adaptive (sequential) hyper-parameter optimization algorithms."
            },
            "slug": "Random-Search-for-Hyper-Parameter-Optimization-Bergstra-Bengio",
            "title": {
                "fragments": [],
                "text": "Random Search for Hyper-Parameter Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid, and shows that random search is a natural baseline against which to judge progress in the development of adaptive (sequential) hyper- parameter optimization algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "J. Mach. Learn. Res."
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688276"
                        ],
                        "name": "Daan Wierstra",
                        "slug": "Daan-Wierstra",
                        "structuredName": {
                            "firstName": "Daan",
                            "lastName": "Wierstra",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daan Wierstra"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145842938"
                        ],
                        "name": "Faustino J. Gomez",
                        "slug": "Faustino-J.-Gomez",
                        "structuredName": {
                            "firstName": "Faustino",
                            "lastName": "Gomez",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Faustino J. Gomez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145341374"
                        ],
                        "name": "J. Schmidhuber",
                        "slug": "J.-Schmidhuber",
                        "structuredName": {
                            "firstName": "J\u00fcrgen",
                            "lastName": "Schmidhuber",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schmidhuber"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "roaches in designing architectures such as Neural Fabrics [48], DiffRNN [41], MetaQNN [3] and DeepArchitect [43]. A more \ufb02exible class of methods for designing architecture is evolutionary algorithms [65, 16, 57, 30, 46, 42, 67], yet they have not had as much success at large scale. Xie and Yuille [67] also transferred learned architectures from CIFAR-10 to ImageNet but performance of these models (top-1 accuracy 72.1%) are "
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 786647,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a149d240ecde338e91ccb2f001074b792be070b2",
            "isKey": true,
            "numCitedBy": 56,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "Existing Recurrent Neural Networks (RNNs) are limited in their ability to model dynamical systems with nonlinearities and hidden internal states. Here we use our general framework for sequence learning, EVOlution of recurrent systems with LINear Outputs (Evolino), to discover good RNN hidden node weights through evolution, while using linear regression to compute an optimal linear mapping from hidden state to output. Using the Long Short-Term Memory RNN Architecture, Evolino outperforms previous state-of-the-art methods on several tasks: 1) context-sensitive languages, 2) multiple superimposed sine waves."
            },
            "slug": "Modeling-systems-with-internal-state-using-evolino-Wierstra-Gomez",
            "title": {
                "fragments": [],
                "text": "Modeling systems with internal state using evolino"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This work uses the general framework for sequence learning, EVOlution of recurrent systems with LINear Outputs (Evolino), to discover good RNN hidden node weights through evolution, while using linear regression to compute an optimal linear mapping from hidden state to output."
            },
            "venue": {
                "fragments": [],
                "text": "GECCO '05"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47971768"
                        ],
                        "name": "J. Schulman",
                        "slug": "J.-Schulman",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Schulman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schulman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143909660"
                        ],
                        "name": "F. Wolski",
                        "slug": "F.-Wolski",
                        "structuredName": {
                            "firstName": "Filip",
                            "lastName": "Wolski",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Wolski"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "6515819"
                        ],
                        "name": "Prafulla Dhariwal",
                        "slug": "Prafulla-Dhariwal",
                        "structuredName": {
                            "firstName": "Prafulla",
                            "lastName": "Dhariwal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Prafulla Dhariwal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "38909097"
                        ],
                        "name": "Alec Radford",
                        "slug": "Alec-Radford",
                        "structuredName": {
                            "firstName": "Alec",
                            "lastName": "Radford",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alec Radford"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2067138712"
                        ],
                        "name": "Oleg Klimov",
                        "slug": "Oleg-Klimov",
                        "structuredName": {
                            "firstName": "Oleg",
                            "lastName": "Klimov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Oleg Klimov"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 72
                            }
                        ],
                        "text": "The controller RNN was trained using Proximal Policy Optimization (PPO) [30] by employing a global workqueue system for generating a pool of child networks controlled by the RNN."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 112
                            }
                        ],
                        "text": "Unlike [44], who used the REINFORCE rule [40] to update the controller, we employ Proximal Policy Optimization (PPO) [30] with learning rate 0.00035 because training with PPO is faster and more stable."
                    },
                    "intents": []
                }
            ],
            "corpusId": 28695052,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dce6f9d4017b1785979e7520fd0834ef8cf02f4b",
            "isKey": true,
            "numCitedBy": 6094,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a \"surrogate\" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time."
            },
            "slug": "Proximal-Policy-Optimization-Algorithms-Schulman-Wolski",
            "title": {
                "fragments": [],
                "text": "Proximal Policy Optimization Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "A new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a \"surrogate\" objective function using stochastic gradient ascent, are proposed."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47971768"
                        ],
                        "name": "J. Schulman",
                        "slug": "J.-Schulman",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Schulman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Schulman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736651"
                        ],
                        "name": "S. Levine",
                        "slug": "S.-Levine",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Levine",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Levine"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1689992"
                        ],
                        "name": "P. Abbeel",
                        "slug": "P.-Abbeel",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Abbeel",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Abbeel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1694621"
                        ],
                        "name": "Michael I. Jordan",
                        "slug": "Michael-I.-Jordan",
                        "structuredName": {
                            "firstName": "Michael",
                            "lastName": "Jordan",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michael I. Jordan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29912342"
                        ],
                        "name": "Philipp Moritz",
                        "slug": "Philipp-Moritz",
                        "structuredName": {
                            "firstName": "Philipp",
                            "lastName": "Moritz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Philipp Moritz"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": " to learn a convolutional cell. In summary, all architecture searches are performed using the CIFAR-10 classi\ufb01cation task [29]. The controller RNN was trained using Proximal Policy Optimization (PPO) [43] by employing a global workqueue system for generating a pool of child networks controlled by the RNN. In our experiments, the pool of workers in the workqueue consisted of 450 GPUs. Please see Append"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16046818,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "66cdc28dc084af6507e979767755e99fe0b46b39",
            "isKey": false,
            "numCitedBy": 3977,
            "numCiting": 44,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article, we describe a method for optimizing control policies, with guaranteed monotonic improvement. By making several approximations to the theoretically-justified scheme, we develop a practical algorithm, called Trust Region Policy Optimization (TRPO). This algorithm is effective for optimizing large nonlinear policies such as neural networks. Our experiments demonstrate its robust performance on a wide variety of tasks: learning simulated robotic swimming, hopping, and walking gaits; and playing Atari games using images of the screen as input. Despite its approximations that deviate from the theory, TRPO tends to give monotonic improvement, with little tuning of hyperparameters."
            },
            "slug": "Trust-Region-Policy-Optimization-Schulman-Levine",
            "title": {
                "fragments": [],
                "text": "Trust Region Policy Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 82,
                "text": "A method for optimizing control policies, with guaranteed monotonic improvement, by making several approximations to the theoretically-justified scheme, called Trust Region Policy Optimization (TRPO)."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059358552"
                        ],
                        "name": "P. Cochat",
                        "slug": "P.-Cochat",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Cochat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cochat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13267685"
                        ],
                        "name": "L. Vaucoret",
                        "slug": "L.-Vaucoret",
                        "structuredName": {
                            "firstName": "L",
                            "lastName": "Vaucoret",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Vaucoret"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2097644863"
                        ],
                        "name": "J. Sarles",
                        "slug": "J.-Sarles",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "Sarles",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sarles"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 180,
                                "start": 176
                            }
                        ],
                        "text": "To further validate the performance of the family of NASNet-A networks, we test whether object detection systems derived from NASNet-A lead to improvements in object detection [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 71
                            }
                        ],
                        "text": "All mini-val results employ the same 8K subset of validation images in [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 31
                            }
                        ],
                        "text": "2% Inception-ResNet-v2 (G-RMI) [18] 600\u00d7 600 35."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 131
                            }
                        ],
                        "text": "NASNet-A networks pretrained on ImageNet into the Faster-RCNN object detection pipeline [28] using an opensource software platform [18]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 152
                            }
                        ],
                        "text": "Example detections showing improvements of object detection over previous state-of-the-art model for Faster-RCNN with Inception-ResNet-v2 featurization [18] (top) and NASNet-A featurization (bottom)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 19
                            }
                        ],
                        "text": ", object detection [18], face detection [29], image localization [39]) derive image features or architectures from ImageNet classification models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "We evaluate the model on the COCO mini-val [18] and test-dev dataset and report the mean average precision (mAP) as computed with the standard COCO metric library [26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11759366,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "bc6dff14a130c57a91d5a21339c23471faf1d46f",
            "isKey": true,
            "numCitedBy": 58258,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "disasters. Plenum, 2001. 11. Haley R, Thomas L, Hom J. Is there a Gulf War Syndrome? Searching for syndromes by factor analysis of symptoms. JAMA 1997;277:215\u201322. 12. Fukuda K, Nisenbaum R, Stewart G, et al. Chronic multi-symptom illness affecting Air Force veterans of the Gulf War. JAMA 1998;280:981\u20138. 13. Ismail K, Everitt B, Blatchley N, et al. Is there a Gulf War Syndrome? Lancet 1999;353:179\u201382. 14. Shapiro S, Lasarev M, McCauley L. Factor analysis of Gulf War illness: what does it add to our understanding of possible health effects of deployment. Am J Epidemiol 2002;156:578\u201385. 15. Doebbeling B, Clarke W, Watson D, et al. Is there a Persian Gulf War Syndrome? Evidence from a large population-based survey of veterans and nondeployed controls. Am J Med 2000;108:695\u2013704. 16. Knoke J, Smith T, Gray G, et al. Factor analysis of self reported symptoms: Does it identify a Gulf War Syndrome? Am J Epidemiol 2000;152:379\u201388. 17. Kang H, Mahan C, Lee K, et al. Evidence for a deployment-related Gulf War syndrome by factor analysis. Arch Environ Health 2002;57:61\u20138."
            },
            "slug": "Et-al-Cochat-Vaucoret",
            "title": {
                "fragments": [],
                "text": "Et al"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A large population-based survey of veterans and nondeployed controls found evidence of a deployment-related Gulf War syndrome by factor analysis in Air Force veterans and controls."
            },
            "venue": {
                "fragments": [],
                "text": "Archives de pediatrie : organe officiel de la Societe francaise de pediatrie"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 367,
                                "start": 351
                            }
                        ],
                        "text": "One inspiration for this search space is the recognition that architecture engineering with CNNs often identifies repeated motifs consisting of combinations of convolutional filter banks, nonlinearities and a prudent selection of connections to achieve state-of-the-art results (such as the repeated modules present in the Inception and ResNet models [35, 11, 36, 34])."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 111
                            }
                        ],
                        "text": "Note the prevalence of separable convolutions and the number of branches compared with competing architectures [32, 35, 11, 36, 34]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 67,
                                "start": 51
                            }
                        ],
                        "text": "Importantly, much like Inception and ResNet models [35, 11, 36, 34], we consider the number of motif repetitions N and the number of initial convolutional filters as free parameters that we tailor to the scale of an image classification problem."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 190,
                                "start": 166
                            }
                        ],
                        "text": "Successive advancements on this benchmark based on convolutional neural networks (CNNs) have achieved impressive results through significant architecture engineering [32, 35, 11, 36, 34, 41]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Inceptionv4"
            },
            "venue": {
                "fragments": [],
                "text": "Inception-Resnet and the impact of residual connections on learning. In International Conference on Learning Representations Workshop Track"
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 167,
                                "start": 163
                            }
                        ],
                        "text": "We evaluate the model on the COCO mini-val [28] and test-dev dataset and report the mean average precision (mAP) as computed with the standard COCO metric library [38]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Microsoft coco: Com- 8705  mon objects in context"
            },
            "venue": {
                "fragments": [],
                "text": "European Conference on Computer Vision, pages 740\u2013755. Springer,"
            },
            "year": 2014
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Result -CIFAR-10 Image Classification Result -ImageNet Image Classification Result Result -Object Detection Deep Speech: Scaling up end-to-end speech recognition Hannun et al"
            },
            "venue": {
                "fragments": [],
                "text": ""
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 185
                            }
                        ],
                        "text": "learning on architecture search on the CIFAR-10 image classification problem as compared to brute-force random search (considered to be a very strong baseline for blackbox optimization [2]) given an equivalent amount of computational resources."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Random search for hyperparameter optimization"
            },
            "venue": {
                "fragments": [],
                "text": "Journal of Machine Learning Research"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 79
                            }
                        ],
                        "text": "The proposed method is related to previous work in hyperparameter optimization [4, 5, 6, 33, 37, 45, 46] \u2013 especially recent approaches in designing architectures such as Neural Fabrics [40], DiffRNN [34], MetaQNN [3] and DeepArchitect [36]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Algorithms for hyperparameter optimization"
            },
            "venue": {
                "fragments": [],
                "text": "In Neural Information Processing Systems,"
            },
            "year": 2011
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Fast and accurate deep network learning by exponential linear units ( elus ) Decaf : A deep convolutional activation feature for generic visual recognition Long short - term memory"
            },
            "venue": {
                "fragments": [],
                "text": "Neural Computation"
            },
            "year": 1997
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 200
                            }
                        ],
                        "text": "The concept of having one neural network interact with a second neural network to aid the learning process, or learning to learn or meta-learning [23, 48] has attracted much attention in recent years [1, 61, 14, 19, 34, 44, 15]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Optimization as a model for fewshot learning"
            },
            "venue": {
                "fragments": [],
                "text": "International Conference on Learning Representations,"
            },
            "year": 2017
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 40,
            "methodology": 41,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 81,
        "totalPages": 9
    },
    "page_url": "https://www.semanticscholar.org/paper/Learning-Transferable-Architectures-for-Scalable-Zoph-Vasudevan/d0611891b9e8a7c5731146097b6f201578f47b2f?sort=total-citations"
}