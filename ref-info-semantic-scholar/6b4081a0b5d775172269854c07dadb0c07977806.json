{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40396597"
                        ],
                        "name": "Toshiyuki Hanazawa",
                        "slug": "Toshiyuki-Hanazawa",
                        "structuredName": {
                            "firstName": "Toshiyuki",
                            "lastName": "Hanazawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toshiyuki Hanazawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9243990"
                        ],
                        "name": "K. Shikano",
                        "slug": "K.-Shikano",
                        "structuredName": {
                            "firstName": "Kiyohiro",
                            "lastName": "Shikano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Shikano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49464494"
                        ],
                        "name": "Kevin J. Lang",
                        "slug": "Kevin-J.-Lang",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Lang",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin J. Lang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9563026,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cd62c9976534a6a2096a38244f6cbb03635a127e",
            "isKey": false,
            "numCitedBy": 2794,
            "numCiting": 92,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors present a time-delay neural network (TDNN) approach to phoneme recognition which is characterized by two important properties: (1) using a three-layer arrangement of simple computing units, a hierarchy can be constructed that allows for the formation of arbitrary nonlinear decision surfaces, which the TDNN learns automatically using error backpropagation; and (2) the time-delay arrangement enables the network to discover acoustic-phonetic features and the temporal relationships between them independently of position in time and therefore not blurred by temporal shifts in the input. As a recognition task, the speaker-dependent recognition of the phonemes B, D, and G in varying phonetic contexts was chosen. For comparison, several discrete hidden Markov models (HMM) were trained to perform the same task. Performance evaluation over 1946 testing tokens from three speakers showed that the TDNN achieves a recognition rate of 98.5% correct while the rate obtained by the best of the HMMs was only 93.7%. >"
            },
            "slug": "Phoneme-recognition-using-time-delay-neural-Waibel-Hanazawa",
            "title": {
                "fragments": [],
                "text": "Phoneme recognition using time-delay neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "The authors present a time-delay neural network (TDNN) approach to phoneme recognition which is characterized by two important properties: using a three-layer arrangement of simple computing units, a hierarchy can be constructed that allows for the formation of arbitrary nonlinear decision surfaces, which the TDNN learns automatically using error backpropagation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40396597"
                        ],
                        "name": "Toshiyuki Hanazawa",
                        "slug": "Toshiyuki-Hanazawa",
                        "structuredName": {
                            "firstName": "Toshiyuki",
                            "lastName": "Hanazawa",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Toshiyuki Hanazawa"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9243990"
                        ],
                        "name": "K. Shikano",
                        "slug": "K.-Shikano",
                        "structuredName": {
                            "firstName": "Kiyohiro",
                            "lastName": "Shikano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Shikano"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49464494"
                        ],
                        "name": "Kevin J. Lang",
                        "slug": "Kevin-J.-Lang",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Lang",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin J. Lang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 12251177,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "834b3738673dacc767563c2714239852a8a6d4b4",
            "isKey": false,
            "numCitedBy": 172,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "A time-delay neural network (TDNN) for phoneme recognition is discussed. By the use of two hidden layers in addition to an input and output layer it is capable of representing complex nonlinear decision surfaces. Three important properties of the TDNNs have been observed. First, it was able to invent without human interference meaningful linguistic abstractions in time and frequency such as formant tracking and segmentation. Second, it has learned to form alternate representations linking different acoustic events with the same higher level concept. In this fashion it can implement trading relations between lower level acoustic events leading to robust recognition performance despite considerable variability in the input speech. Third, the network is translation-invariant and does not rely on precise alignment or segmentation of the input. The TDNNs performance is compared with the best of hidden Markov models (HMMs) on a speaker-dependent phoneme-recognition task. The TDNN achieved a recognition of 98.5% compared to 93.7% for the HMM, i.e., a fourfold reduction in error.<<ETX>>"
            },
            "slug": "Phoneme-recognition:-neural-networks-vs.-hidden-vs.-Waibel-Hanazawa",
            "title": {
                "fragments": [],
                "text": "Phoneme recognition: neural networks vs. hidden Markov models vs. hidden Markov models"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "A time-delay neural network for phoneme recognition that was able to invent without human interference meaningful linguistic abstractions in time and frequency such as formant tracking and segmentation and does not rely on precise alignment or segmentation of the input."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP-88., International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1796273"
                        ],
                        "name": "H. Leung",
                        "slug": "H.-Leung",
                        "structuredName": {
                            "firstName": "Hong",
                            "lastName": "Leung",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Leung"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710543"
                        ],
                        "name": "V. Zue",
                        "slug": "V.-Zue",
                        "structuredName": {
                            "firstName": "Victor",
                            "lastName": "Zue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Zue"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 62276922,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7419fe8bd7c427b36b656e30c78af38d9c3ee102",
            "isKey": false,
            "numCitedBy": 31,
            "numCiting": 1,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper is concerned with the application of artificial neural nets to phonetic recognition. The goal is to investigate how the framework of multilayer perceptrons can be exploited in speech recognition when the are augmented with acoustic-phonetic knowledge. Major issues as the choice of the error metric, the use of contextual information, and determination of the training procedure are investigated within a set of experiments that attempt to recognize the 16 vowels in American English. The results, based on some 10000 vowel tokens excised from 1000 sentences spoken by 200 speakers, indicate that a top-choice accuracy of 54% and 67% can be achieved for the context-independent and -dependent networks, respectively.<<ETX>>"
            },
            "slug": "Some-phonetic-recognition-experiments-using-neural-Leung-Zue",
            "title": {
                "fragments": [],
                "text": "Some phonetic recognition experiments using artificial neural nets"
            },
            "tldr": {
                "abstractSimilarityScore": 59,
                "text": "Investigation of how the framework of multilayer perceptrons can be exploited in speech recognition when the are augmented with acoustic-phonetic knowledge indicates that a top-choice accuracy of 54% and 67% can be achieved for the context-independent and -dependent networks."
            },
            "venue": {
                "fragments": [],
                "text": "ICASSP-88., International Conference on Acoustics, Speech, and Signal Processing"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1724972"
                        ],
                        "name": "A. Waibel",
                        "slug": "A.-Waibel",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Waibel",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Waibel"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "115945547"
                        ],
                        "name": "H. Sawai",
                        "slug": "H.-Sawai",
                        "structuredName": {
                            "firstName": "Hidefumi",
                            "lastName": "Sawai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Sawai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9243990"
                        ],
                        "name": "K. Shikano",
                        "slug": "K.-Shikano",
                        "structuredName": {
                            "firstName": "Kiyohiro",
                            "lastName": "Shikano",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Shikano"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 18990685,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3f5966eba6336438ade570ea57e2e682fa0b5985",
            "isKey": false,
            "numCitedBy": 186,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "The authors train several small time-delay neural networks aimed at all phonemic subcategories (nasals, fricatives, etc.) and report excellent fine phonemic discrimination performance for all cases. Exploiting the hidden structure of these small phonemic subcategory networks, they propose several technique that make it possible to grow larger nets in an incremental and modular fashion without loss in recognition performance and without the need for excessive training time or additional data. The techniques include class discriminatory learning, connectionist glue, selective/partial learning, and all-net fine tuning. A set of experiments shows that stop consonant networks (BDGPTK) constructed from subcomponent BDG- and PTK-nets achieved up to 98.6% correct recognition compared to 98.3 and 98.7% correct for the BDG- and PTK-nets. Similarly, an incrementally trained network aimed at all consonants achieved recognition scores of about 96% correct. These results are comparable to the performance of the subcomponent networks and significantly better than that of several alternative speech recognition methods. >"
            },
            "slug": "Modularity-and-scaling-in-large-phonemic-neural-Waibel-Sawai",
            "title": {
                "fragments": [],
                "text": "Modularity and scaling in large phonemic neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "The authors train several small time-delay neural networks aimed at all phonemic subcategories and report excellent fine phonemic discrimination performance for all cases and propose several technique that make it possible to grow larger nets in an incremental and modular fashion without loss in recognition performance and without the need for excessive training time or additional data."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Trans. Acoust. Speech Signal Process."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2884373"
                        ],
                        "name": "J. Elman",
                        "slug": "J.-Elman",
                        "structuredName": {
                            "firstName": "Jeffrey",
                            "lastName": "Elman",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Elman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1895771"
                        ],
                        "name": "D. Zipser",
                        "slug": "D.-Zipser",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Zipser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Zipser"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 20678424,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c86590e947c28e8791d1e8bab8fc8ab53302341f",
            "isKey": false,
            "numCitedBy": 288,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "In the work described here, the backpropagation neural network learning procedure is applied to the analysis and recognition of speech. This procedure takes a set of input/output pattern pairs and attempts to learn their functional relationship; it develops the necessary representational features during the course of learning. A series of computer simulation studies was carried out to assess the ability of these networks to accurately label sounds, to learn to recognize sounds without labels, and to learn feature representations of continuous speech. These studies demonstrated that the networks can learn to label presegmented test tokens with accuracies of up to 95%. Networks trained on segmented sounds using a strategy that requires no external labels were able to recognize and delineate sounds in continuous speech. These networks developed rich internal representations that included units which corresponded to such traditional distinctions as vowels and consonants, as well as units that were sensitive to novel and nonstandard features. Networks trained on a large corpus of unsegmented, continuous speech without labels also developed interesting feature representations, which may be useful in both segmentation and label learning. The results of these studies, while preliminary, demonstrate that backpropagation learning can be used with complex, natural data to identify a feature structure that can serve as the basis for both analysis and nontrivial pattern recognition."
            },
            "slug": "Learning-the-hidden-structure-of-speech.-Elman-Zipser",
            "title": {
                "fragments": [],
                "text": "Learning the hidden structure of speech."
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "The results of these studies demonstrate that backpropagation learning can be used with complex, natural data to identify a feature structure that can serve as the basis for both analysis and nontrivial pattern recognition."
            },
            "venue": {
                "fragments": [],
                "text": "The Journal of the Acoustical Society of America"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 205001834,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "052b1d8ce63b07fec3de9dbb583772d860b7c769",
            "isKey": false,
            "numCitedBy": 20461,
            "numCiting": 3,
            "paperAbstract": {
                "fragments": [],
                "text": "We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal \u2018hidden\u2019 units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1."
            },
            "slug": "Learning-representations-by-back-propagating-errors-Rumelhart-Hinton",
            "title": {
                "fragments": [],
                "text": "Learning representations by back-propagating errors"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "Back-propagation repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector, which helps to represent important features of the task domain."
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109973472"
                        ],
                        "name": "Subutai Ahmad",
                        "slug": "Subutai-Ahmad",
                        "structuredName": {
                            "firstName": "Subutai",
                            "lastName": "Ahmad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Subutai Ahmad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1699108"
                        ],
                        "name": "G. Tesauro",
                        "slug": "G.-Tesauro",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "Tesauro",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Tesauro"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 15615035,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ee96f5fb7130ce712d4eac4728f0f7ec8b93a203",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 10,
            "paperAbstract": {
                "fragments": [],
                "text": "The issues of scaling and generalization have emerged as key issues in current studies of supervised learning from examples in neural networks. Questions such as how many training patterns and training cycles are needed for a problem of a given size and difficulty, how to represent the input and how to choose useful training exemplars, are of considerable theoretical and practical importance. Several intuitive rules of thumb have been obtained from empirical studies, but as yet there are few rigorous results. In this paper we summarize a study of generalization in the simplest possible case-perceptron networks learning linearly separable functions. The task chosen was the majority function (i.e. return a 1 if a majority of the input units are on), a predicate with a number of useful properties. We find that many aspects of generalization in multilayer networks learning large, difficult tasks are reproduced in this simple domain, in which concrete numerical results and even some analytic understanding can be achieved."
            },
            "slug": "Scaling-and-Generalization-in-Neural-Networks:-A-Ahmad-Tesauro",
            "title": {
                "fragments": [],
                "text": "Scaling and Generalization in Neural Networks: A Case Study"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is found that many aspects of generalization in multilayer networks learning large, difficult tasks are reproduced in this simple domain, in which concrete numerical results and even some analytic understanding can be achieved."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "For the CE expression of [ 6 ], equation (7) simplifies to min CEmiss = 2. For both classifiers these thresholds are overlapping, producing regions in the miss domain of state space that yield more optimal values for the objective function than do some regions in the hit domain of state space."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "The meansquared-error (MSE) and cross entropy (CE) [ 6 ] objective functions compare the actual output activations of the net-"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "In presenting the CFM objective function, we first review therraditional MSE Objective function used in backpropagatkn [4], [5] and the closely related CE objective function [ 6 ]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Equation (3) differs from that given in [ 6 ] by a constant of log ( 2) /N. Both of these objective functions engender output states that tend to mimic an ideal pattern."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 57909018,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3aaa051450b3db30f95918e7901db6f1aba62d41",
            "isKey": true,
            "numCitedBy": 149,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "20-\u2013-CONNECTIONIST-LEARNING-PROCEDURES1-Hinton",
            "title": {
                "fragments": [],
                "text": "20 \u2013 CONNECTIONIST LEARNING PROCEDURES1"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152362221"
                        ],
                        "name": "M. Brady",
                        "slug": "M.-Brady",
                        "structuredName": {
                            "firstName": "Martin L.",
                            "lastName": "Brady",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Brady"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "70761321"
                        ],
                        "name": "R. Raghavan",
                        "slug": "R.-Raghavan",
                        "structuredName": {
                            "firstName": "Raghu",
                            "lastName": "Raghavan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Raghavan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2949045"
                        ],
                        "name": "J. Slawny",
                        "slug": "J.-Slawny",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Slawny",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Slawny"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "Table I and Fig. 3 indicate that it is possible, at least in principle, for a network trained on a representative training set drawn from an infinitely large ensemble with high variance to minimize its MSE or CE objective function for all training tokens without minimizing the number of misclassifications it makes on a disjoint test set [ 9 ]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6430632,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "232e656e1b9e0520c0b9640eb43d522fd988c649",
            "isKey": false,
            "numCitedBy": 22,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "In the context of neural network procedures, it is proved that gradient descent on a surface defined by a sum of squared errors can fail to separate families of vectors. Each output is assumed to be a differentiable monotone transformation (typically the logistic) of a linear combination of inputs. Several examples are given of two families of vectors for which a linear combination exists that will serve to separate the two families. However, the minimum cost solution does not yield the desired combination. The examples include several cases where there are no local minima, as well as a one-layer system showing local minima with a large basin of attraction. In contrast to the perceptron convergence theorem, which proves that the perceptron architecture, there is no convergence theorem for gradient descent which would allow correct classification. The theorem disproves the presumption made in recent years, that barring local minima, gradient descent will find the best set of weights for a given problem.<<ETX>>"
            },
            "slug": "Gradient-descent-fails-to-separate-Brady-Raghavan",
            "title": {
                "fragments": [],
                "text": "Gradient descent fails to separate"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "It is proved that gradient descent on a surface defined by a sum of squared errors can fail to separate families of vectors, and disproves the presumption made in recent years, that barring local minima, gradient descent will find the best set of weights for a given problem."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE 1988 International Conference on Neural Networks"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33340475"
                        ],
                        "name": "A. Oppenheim",
                        "slug": "A.-Oppenheim",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Oppenheim",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Oppenheim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144232606"
                        ],
                        "name": "R. Schaffer",
                        "slug": "R.-Schaffer",
                        "structuredName": {
                            "firstName": "Rudolf",
                            "lastName": "Schaffer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Schaffer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 63180999,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "7e957a5af8b4041be3b3431bafe4fe23126e9724",
            "isKey": false,
            "numCitedBy": 5486,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "For senior/graduate-level courses in Discrete-Time Signal Processing. THE definitive, authoritative text on DSP -- ideal for those with an introductory-level knowledge of signals and systems. Written by prominent, DSP pioneers, it provides thorough treatment of the fundamental theorems and properties of discrete-time linear systems, filtering, sampling, and discrete-time Fourier Analysis. By focusing on the general and universal concepts in discrete-time signal processing, it remains vital and relevant to the new challenges arising in the field --without limiting itself to specific technologies with relatively short life spans."
            },
            "slug": "Discrete-Time-Signal-Pro-cessing-Oppenheim-Schaffer",
            "title": {
                "fragments": [],
                "text": "Discrete-Time Signal Pro-cessing"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The definitive, authoritative text on DSP, written by prominent, DSP pioneers, it provides thorough treatment of the fundamental theorems and properties of discrete- time linear systems, filtering, sampling, and discrete-time Fourier Analysis."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2681887"
                        ],
                        "name": "D. Rumelhart",
                        "slug": "D.-Rumelhart",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Rumelhart",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Rumelhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "104458796"
                        ],
                        "name": "De Rumerhart",
                        "slug": "De-Rumerhart",
                        "structuredName": {
                            "firstName": "De",
                            "lastName": "Rumerhart",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "De Rumerhart"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46831169"
                        ],
                        "name": "G. Hinton",
                        "slug": "G.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Hinton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116648700"
                        ],
                        "name": "Ronald J. Williams",
                        "slug": "Ronald-J.-Williams",
                        "structuredName": {
                            "firstName": "Ronald",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronald J. Williams"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 125302131,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c0900df8d62877a68f052b41cadb3ded6e142785",
            "isKey": false,
            "numCitedBy": 507,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Learning-representations-of-back-propagation-errors-Rumelhart-Rumerhart",
            "title": {
                "fragments": [],
                "text": "Learning representations of back-propagation errors"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1986
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49464494"
                        ],
                        "name": "Kevin J. Lang",
                        "slug": "Kevin-J.-Lang",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Lang",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin J. Lang"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 81
                            }
                        ],
                        "text": "Details of this shift-invariant connectionist architecture can be found in [ 11, [3]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 61002534,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f19ca2336b8a7cc9344ffef5dbe3d3ff17954ab4",
            "isKey": false,
            "numCitedBy": 110,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-time-delay-neural-network-architecture-for-speech-Lang",
            "title": {
                "fragments": [],
                "text": "A time delay neural network architecture for speech recognition"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "118896288"
                        ],
                        "name": "M. Braga",
                        "slug": "M.-Braga",
                        "structuredName": {
                            "firstName": "Maria",
                            "lastName": "Braga",
                            "middleNames": [
                                "Debora"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Braga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48031598"
                        ],
                        "name": "P. Duca",
                        "slug": "P.-Duca",
                        "structuredName": {
                            "firstName": "P",
                            "lastName": "Duca",
                            "middleNames": [
                                "G"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Duca"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 2631707,
            "fieldsOfStudy": [
                "Geology"
            ],
            "id": "3d07e8d62961e6b25869d4d90523157dc94eb484",
            "isKey": false,
            "numCitedBy": 5738,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "[Exploratory-data-analysis].-Braga-Duca",
            "title": {
                "fragments": [],
                "text": "[Exploratory data analysis]."
            },
            "venue": {
                "fragments": [],
                "text": "La Medicina del lavoro"
            },
            "year": 1988
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The meta-pi network: Building distributed knowledge representations for robust pattern recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Camegie-Mellon Univ"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 215,
                                "start": 212
                            }
                        ],
                        "text": "OF THE MSE AND CE OBJECTIVE FUNCTIONS In presenting the CFM objective function, we first review therraditional MSE Objective function used in backpropagatkn [4], [5] and the closely related CE objective function [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 256,
                                "start": 253
                            }
                        ],
                        "text": "\u2026can show the following relationship, assuming that the desired output state of the network is binary: for a hit (4) N -1 N max MSEhit =: max CEhit 00 (5) (6) (7) and for a miss min MSEmiss = 1 /(2N) 2log (2) min CEmiss = ~ N ' For the CE expression of [6], equation (7) simplifies to min CEmiss = 2."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 40
                            }
                        ],
                        "text": "Equation (3) differs from that given in [6] by a constant of log ( 2 ) / N ."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Connectionist learning procedures Camegie-Mel- Lon Univ"
            },
            "venue": {
                "fragments": [],
                "text": "Connectionist learning procedures Camegie-Mel- Lon Univ"
            },
            "year": 1987
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Connectionist architectures for multispeaker phoneme recognition"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Neural Information Processing Systems"
            },
            "year": 1191
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probabiliry and Srarisrics in Engineering and Management Science"
            },
            "venue": {
                "fragments": [],
                "text": "10. 1131 M. DeGroot, Probability and Statisrics"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 125
                            }
                        ],
                        "text": "OF THE MSE AND CE OBJECTIVE FUNCTIONS In presenting the CFM objective function, we first review therraditional MSE Objective function used in backpropagatkn [4], [5] and the closely related CE objective function [6]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "CE = -1/N n = C I { Dn log ((3,) -( 1 -33,) log ( 1"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "2) N"
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning Representations by Backpropagation Errors"
            },
            "venue": {
                "fragments": [],
                "text": "Nature"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Enploratory Data Analysis"
            },
            "venue": {
                "fragments": [],
                "text": "Reading, M A Addison-Wesley,"
            },
            "year": 1977
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "A novel objective function for im- 228"
            },
            "venue": {
                "fragments": [],
                "text": "IEEE TRANSACTIONS ON NEURAL NETWORKS"
            },
            "year": 1990
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Consonant and Phoneme Recognition by Modular Construction of Large Phonemic Time-Delay Neural Networks"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 1989 IEEE International Conference on Acoustics, Speech and Signal Processing"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Consonant and Phoneme Recognition by Modular Construction of Large Phonemic Time - Delay Neural Networks \u201d"
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 1989 IEEE International Conference on Acoustics , Speech and Signal Processing"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Learning Representations by Backpropagation Errors,"
            },
            "venue": {
                "fragments": [],
                "text": "Nature, vol. 323,"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Leaming representations by back-propagation"
            },
            "venue": {
                "fragments": [],
                "text": "errors,\u201d Nature,"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Waihel (S'79-M'80) was born on May 2, 1956 in Heidelberg, West Germany. He received the B.S. degree in 1979 from the Massachusetts Institute of Technology"
            },
            "venue": {
                "fragments": [],
                "text": "Hampshire is a student member of the International Neural Network Society Cambridge. the M.S. degree in 1980 from the Massachusetts Institute of Technology, and the Ph.D. degree in electrical engineering and computer science"
            },
            "year": 1980
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Probability and Statisrics, 2nd ed"
            },
            "venue": {
                "fragments": [],
                "text": "Reading, MA: Addison-Wesley,"
            },
            "year": 1986
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Phoneme recognition: Neural networks versus hidden Markov models"
            },
            "venue": {
                "fragments": [],
                "text": "Proc. 1988IEEEInt. Con$ Acoust., Speech, Signal Processing"
            },
            "year": 1988
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 4,
            "methodology": 3
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 27,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/A-novel-objective-function-for-improved-phoneme-Hampshire-Waibel/6b4081a0b5d775172269854c07dadb0c07977806?sort=total-citations"
}