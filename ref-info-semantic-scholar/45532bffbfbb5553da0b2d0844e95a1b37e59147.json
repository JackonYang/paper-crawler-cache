{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "120805419"
                        ],
                        "name": "Mingxing Tan",
                        "slug": "Mingxing-Tan",
                        "structuredName": {
                            "firstName": "Mingxing",
                            "lastName": "Tan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mingxing Tan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Bo Chen",
                        "slug": "Bo-Chen",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34320634"
                        ],
                        "name": "Ruoming Pang",
                        "slug": "Ruoming-Pang",
                        "structuredName": {
                            "firstName": "Ruoming",
                            "lastName": "Pang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ruoming Pang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053781980"
                        ],
                        "name": "Vijay Vasudevan",
                        "slug": "Vijay-Vasudevan",
                        "structuredName": {
                            "firstName": "Vijay",
                            "lastName": "Vasudevan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vijay Vasudevan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 15
                            }
                        ],
                        "text": "Most recently, [20] explores a stage-level hierarchical search space, allowing different blocks for different stages of a network, while blocks inside a stage are still the same."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 15
                            }
                        ],
                        "text": "Previous works [30, 31, 20] has demonstrated the effectiveness of such methods in finding accurate and efficient ConvNet models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 54
                            }
                        ],
                        "text": "Despite higher accuracy and lower latency than MnasNet[20], we estimate FBNet-B\u2019s search cost is 420x smaller than MnasNet\u2019s, at only 216 GPUhours."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 74
                            }
                        ],
                        "text": "For example, [30, 31] trains the architecture on the CIFAR10 dataset, and [20] trains on ImageNet but only for 5 epochs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 127,
                                "start": 123
                            }
                        ],
                        "text": "Being better than MnasNet, FBNet-B\u2019s search cost is 216 GPU-hours, 421x lower than the cost for MnasNet estimated based on [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 20
                            }
                        ],
                        "text": "Many previous works [30, 31, 20] use reinforcement learning (RL) to guide the search and a typical flow is illustrated in Figure 2(b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "As shown in [20] and in our experiments, allowing different layers to choose different blocks leads to better accuracy and efficiency."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "Following [20], we also allow choosing a kernel size of 3 or 5 for the depthwise convolution."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 31
                            }
                        ],
                        "text": "Most of the early works on NAS [30, 31, 20] follow the paradigm above."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 30
                            }
                        ],
                        "text": "Instead of focusing on FLOPs, [20] aims to optimize the latency on target devices."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 51891697,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "693c97ecedb0a84539b7162c95e89fa3cd84ca73",
            "isKey": true,
            "numCitedBy": 1613,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Designing convolutional neural networks (CNN) for mobile devices is challenging because mobile models need to be small and fast, yet still accurate. Although significant efforts have been dedicated to design and improve mobile CNNs on all dimensions, it is very difficult to manually balance these trade-offs when there are so many architectural possibilities to consider. In this paper, we propose an automated mobile neural architecture search (MNAS) approach, which explicitly incorporate model latency into the main objective so that the search can identify a model that achieves a good trade-off between accuracy and latency. Unlike previous work, where latency is considered via another, often inaccurate proxy (e.g., FLOPS), our approach directly measures real-world inference latency by executing the model on mobile phones. To further strike the right balance between flexibility and search space size, we propose a novel factorized hierarchical search space that encourages layer diversity throughout the network. Experimental results show that our approach consistently outperforms state-of-the-art mobile CNN models across multiple vision tasks. On the ImageNet classification task, our MnasNet achieves 75.2% top-1 accuracy with 78ms latency on a Pixel phone, which is 1.8\u00d7 faster than MobileNetV2 with 0.5% higher accuracy and 2.3\u00d7 faster than NASNet with 1.2% higher accuracy. Our MnasNet also achieves better mAP quality than MobileNets for COCO object detection. Code is at https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet."
            },
            "slug": "MnasNet:-Platform-Aware-Neural-Architecture-Search-Tan-Chen",
            "title": {
                "fragments": [],
                "text": "MnasNet: Platform-Aware Neural Architecture Search for Mobile"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "An automated mobile neural architecture search (MNAS) approach, which explicitly incorporate model latency into the main objective so that the search can identify a model that achieves a good trade-off between accuracy and latency."
            },
            "venue": {
                "fragments": [],
                "text": "2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3130257"
                        ],
                        "name": "Bichen Wu",
                        "slug": "Bichen-Wu",
                        "structuredName": {
                            "firstName": "Bichen",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bichen Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2146020227"
                        ],
                        "name": "Yanghan Wang",
                        "slug": "Yanghan-Wang",
                        "structuredName": {
                            "firstName": "Yanghan",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yanghan Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2918780"
                        ],
                        "name": "Peizhao Zhang",
                        "slug": "Peizhao-Zhang",
                        "structuredName": {
                            "firstName": "Peizhao",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peizhao Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39402399"
                        ],
                        "name": "Yuandong Tian",
                        "slug": "Yuandong-Tian",
                        "structuredName": {
                            "firstName": "Yuandong",
                            "lastName": "Tian",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yuandong Tian"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48682997"
                        ],
                        "name": "P\u00e9ter Vajda",
                        "slug": "P\u00e9ter-Vajda",
                        "structuredName": {
                            "firstName": "P\u00e9ter",
                            "lastName": "Vajda",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P\u00e9ter Vajda"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732330"
                        ],
                        "name": "K. Keutzer",
                        "slug": "K.-Keutzer",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Keutzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Keutzer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 96,
                                "start": 89
                            }
                        ],
                        "text": "The technique of using Gumbel Softmax for neural architecture search is also proposed in [25, 1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "[25, 1] further develop the idea of differentiable neural architecture search combining Gumbel Softmax [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 54441287,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b6b918fd7f5162fe28c88743db276bffc080576b",
            "isKey": false,
            "numCitedBy": 138,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent work in network quantization has substantially reduced the time and space complexity of neural network inference, enabling their deployment on embedded and mobile devices with limited computational and memory resources. However, existing quantization methods often represent all weights and activations with the same precision (bit-width). In this paper, we explore a new dimension of the design space: quantizing different layers with different bit-widths. We formulate this problem as a neural architecture search problem and propose a novel differentiable neural architecture search (DNAS) framework to efficiently explore its exponential search space with gradient-based optimization. Experiments show we surpass the state-of-the-art compression of ResNet on CIFAR-10 and ImageNet. Our quantized models with 21.1x smaller model size or 103.9x lower computational cost can still outperform baseline quantized or even full precision models."
            },
            "slug": "Mixed-Precision-Quantization-of-ConvNets-via-Neural-Wu-Wang",
            "title": {
                "fragments": [],
                "text": "Mixed Precision Quantization of ConvNets via Differentiable Neural Architecture Search"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel differentiable neural architecture search (DNAS) framework is proposed to efficiently explore its exponential search space with gradient-based optimization and surpass the state-of-the-art compression of ResNet on CIFAR-10 and ImageNet."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "10419477"
                        ],
                        "name": "A. Gholami",
                        "slug": "A.-Gholami",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Gholami",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gholami"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34662118"
                        ],
                        "name": "K. Kwon",
                        "slug": "K.-Kwon",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Kwon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kwon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3130257"
                        ],
                        "name": "Bichen Wu",
                        "slug": "Bichen-Wu",
                        "structuredName": {
                            "firstName": "Bichen",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bichen Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "9541802"
                        ],
                        "name": "Zizheng Tai",
                        "slug": "Zizheng-Tai",
                        "structuredName": {
                            "firstName": "Zizheng",
                            "lastName": "Tai",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zizheng Tai"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27577617"
                        ],
                        "name": "Xiangyu Yue",
                        "slug": "Xiangyu-Yue",
                        "structuredName": {
                            "firstName": "Xiangyu",
                            "lastName": "Yue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangyu Yue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32294544"
                        ],
                        "name": "Peter H. Jin",
                        "slug": "Peter-H.-Jin",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Jin",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter H. Jin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755487"
                        ],
                        "name": "Sicheng Zhao",
                        "slug": "Sicheng-Zhao",
                        "structuredName": {
                            "firstName": "Sicheng",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sicheng Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732330"
                        ],
                        "name": "K. Keutzer",
                        "slug": "K.-Keutzer",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Keutzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Keutzer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 34
                            }
                        ],
                        "text": "Following SqueezeNet, SqueezeNext [3] and ShiftNet [23] achieve further parameter size reduction."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 4390700,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5c03413b37f06bd94144ebfae5b2e0632ca604e",
            "isKey": false,
            "numCitedBy": 150,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "One of the main barriers for deploying neural networks on embedded systems has been large memory and power consumption of existing neural networks. In this work, we introduce SqueezeNext, a new family of neural network architectures whose design was guided by considering previous architectures such as SqueezeNet, as well as by simulation results on a neural network accelerator. This new network is able to match AlexNet's accuracy on the ImageNet benchmark with 112\u00d7 fewer parameters, and one of its deeper variants is able to achieve VGG-19 accuracy with only 4.4 Million parameters, (31\u00d7 smaller than VGG-19). SqueezeNext also achieves better top-5 classification accuracy with 1.3\u00d7 fewer parameters as compared to MobileNet, but avoids using depthwise-separable convolutions that are inefficient on some mobile processor platforms. This wide range of accuracy gives the user the ability to make speed-accuracy tradeoffs, depending on the available resources on the target hardware. Using hardware simulation results for power and inference speed on an embedded system has guided us to design variations of the baseline model that are 2.59\u00d7/8.26\u00d7 faster and 2.25\u00d7/7.5\u00d7 more energy efficient as compared to SqueezeNet/AlexNet without any accuracy degradation."
            },
            "slug": "SqueezeNext:-Hardware-Aware-Neural-Network-Design-Gholami-Kwon",
            "title": {
                "fragments": [],
                "text": "SqueezeNext: Hardware-Aware Neural Network Design"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "SqueezeNext is introduced, a new family of neural network architectures whose design was guided by considering previous architectures such as SqueezeNet, as well as by simulation results on a neural network accelerator."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2068605434"
                        ],
                        "name": "Ningning Ma",
                        "slug": "Ningning-Ma",
                        "structuredName": {
                            "firstName": "Ningning",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ningning Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50875121"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "Xiangyu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16215052"
                        ],
                        "name": "Haitao Zheng",
                        "slug": "Haitao-Zheng",
                        "structuredName": {
                            "firstName": "Haitao",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Haitao Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 32
                            }
                        ],
                        "text": "%) better than the MobileNetV2, ShuffleNetV2, and CondenseNet counterparts."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 33
                            }
                        ],
                        "text": "Synetgy [28] combines ideas from ShuffleNetV2 and ShiftNet to co-design hardware friendly ConvNets and FPGA accelerators."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 24
                            }
                        ],
                        "text": "%) than MobileNetV2 and ShuffleNetV2, 20M (relative 8"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "The assumption is valid for many mobile CPUs and DSPs, where operators are computed sequentially one by one."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 179,
                                "start": 169
                            }
                        ],
                        "text": "In the first group, FBNetA achieves 73.0% accuracy, better than 1.0-MobileNetV2\n(+1.0%), 1.5-ShuffleNet V2 (+0.4%), and CondenseNet (+2%), and are on par with DARTS and MnasNet-65."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 65
                            }
                        ],
                        "text": "In the third group, FBNet-C achieves 74.9% accuracy, same as 2.0-ShuffleNetV2 and better than all others."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 127
                            }
                        ],
                        "text": "However, many searched cell structures are very complicated and fragmented and are therefore slow when deployed to mobile CPUs [17, 13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "0 MnasNet-65 [13] RL stage-wise 91K\u2217 / 421x 3."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 40
                            }
                        ],
                        "text": "To improve actual latency, ShuffleNetV2 [13] proposes a series of practical guidelines for efficient ConvNet design."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 51880435,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c02b909a514af6b9255315e2d50112845ca5ed0e",
            "isKey": true,
            "numCitedBy": 1910,
            "numCiting": 48,
            "paperAbstract": {
                "fragments": [],
                "text": "Currently, the neural network architecture design is mostly guided by the indirect metric of computation complexity, i.e., FLOPs. However, the direct metric, e.g., speed, also depends on the other factors such as memory access cost and platform characterics. Thus, this work proposes to evaluate the direct metric on the target platform, beyond only considering FLOPs. Based on a series of controlled experiments, this work derives several practical guidelines for efficient network design. Accordingly, a new architecture is presented, called ShuffleNet V2. Comprehensive ablation experiments verify that our model is the state-of-the-art in terms of speed and accuracy tradeoff."
            },
            "slug": "ShuffleNet-V2:-Practical-Guidelines-for-Efficient-Ma-Zhang",
            "title": {
                "fragments": [],
                "text": "ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work proposes to evaluate the direct metric on the target platform, beyond only considering FLOPs, and derives several practical guidelines for efficient network design, called ShuffleNet V2."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143950636"
                        ],
                        "name": "Hieu Pham",
                        "slug": "Hieu-Pham",
                        "structuredName": {
                            "firstName": "Hieu",
                            "lastName": "Pham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hieu Pham"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152565355"
                        ],
                        "name": "M. Guan",
                        "slug": "M.-Guan",
                        "structuredName": {
                            "firstName": "Melody",
                            "lastName": "Guan",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Guan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2368067"
                        ],
                        "name": "Barret Zoph",
                        "slug": "Barret-Zoph",
                        "structuredName": {
                            "firstName": "Barret",
                            "lastName": "Zoph",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barret Zoph"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48448318"
                        ],
                        "name": "J. Dean",
                        "slug": "J.-Dean",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Dean",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dean"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 15
                            }
                        ],
                        "text": "Previous works [30, 31, 16, 11, 12] focus on cell level architecture search."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "Recent works try to reduce the computational cost by weight sharing [16] or using gradient-based optimization [12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 19
                            }
                        ],
                        "text": "Early works of NAS [31, 16, 12] focus on the cell level architecture search, and the same cell structure is repeated in all layers of a network."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3638969,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fe9b8aac9fa3bfd9724db5a881a578e471e612d7",
            "isKey": false,
            "numCitedBy": 1735,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose Efficient Neural Architecture Search (ENAS), a fast and inexpensive approach for automatic model design. In ENAS, a controller learns to discover neural network architectures by searching for an optimal subgraph within a large computational graph. The controller is trained with policy gradient to select a subgraph that maximizes the expected reward on the validation set. Meanwhile the model corresponding to the selected subgraph is trained to minimize a canonical cross entropy loss. Thanks to parameter sharing between child models, ENAS is fast: it delivers strong empirical performances using much fewer GPU-hours than all existing automatic model design approaches, and notably, 1000x less expensive than standard Neural Architecture Search. On the Penn Treebank dataset, ENAS discovers a novel architecture that achieves a test perplexity of 55.8, establishing a new state-of-the-art among all methods without post-training processing. On the CIFAR-10 dataset, ENAS designs novel architectures that achieve a test error of 2.89%, which is on par with NASNet (Zoph et al., 2018), whose test error is 2.65%."
            },
            "slug": "Efficient-Neural-Architecture-Search-via-Parameter-Pham-Guan",
            "title": {
                "fragments": [],
                "text": "Efficient Neural Architecture Search via Parameter Sharing"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "Efficient Neural Architecture Search is a fast and inexpensive approach for automatic model design that establishes a new state-of-the-art among all methods without post-training processing and delivers strong empirical performances using much fewer GPU-hours."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39838894"
                        ],
                        "name": "Yihui He",
                        "slug": "Yihui-He",
                        "structuredName": {
                            "firstName": "Yihui",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yihui He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46698300"
                        ],
                        "name": "Ji Lin",
                        "slug": "Ji-Lin",
                        "structuredName": {
                            "firstName": "Ji",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ji Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47781592"
                        ],
                        "name": "Zhijian Liu",
                        "slug": "Zhijian-Liu",
                        "structuredName": {
                            "firstName": "Zhijian",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhijian Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35446689"
                        ],
                        "name": "Hanrui Wang",
                        "slug": "Hanrui-Wang",
                        "structuredName": {
                            "firstName": "Hanrui",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanrui Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2040091191"
                        ],
                        "name": "Li-Jia Li",
                        "slug": "Li-Jia-Li",
                        "structuredName": {
                            "firstName": "Li-Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143840275"
                        ],
                        "name": "Song Han",
                        "slug": "Song-Han",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Han"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 55
                            }
                        ],
                        "text": "Besides searching for new architectures, works such as [27, 5] focus on adapting existing models to improve efficiency."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 52048008,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1717255b6aea01fe956cef998abbc3c399b5d7cf",
            "isKey": false,
            "numCitedBy": 843,
            "numCiting": 74,
            "paperAbstract": {
                "fragments": [],
                "text": "Model compression is an effective technique to efficiently deploy neural network models on mobile devices which have limited computation resources and tight power budgets. Conventional model compression techniques rely on hand-crafted features and require domain experts to explore the large design space trading off among model size, speed, and accuracy, which is usually sub-optimal and time-consuming. In this paper, we propose AutoML for Model Compression (AMC) which leverages reinforcement learning to efficiently sample the design space and can improve the model compression quality. We achieved state-of-the-art model compression results in a fully automated way without any human efforts. Under 4\\(\\times \\) FLOPs reduction, we achieved 2.7% better accuracy than the hand-crafted model compression method for VGG-16 on ImageNet. We applied this automated, push-the-button compression pipeline to MobileNet-V1 and achieved a speedup of 1.53\\(\\times \\) on the GPU (Titan Xp) and 1.95\\(\\times \\) on an Android phone (Google Pixel 1), with negligible loss of accuracy."
            },
            "slug": "AMC:-AutoML-for-Model-Compression-and-Acceleration-He-Lin",
            "title": {
                "fragments": [],
                "text": "AMC: AutoML for Model Compression and Acceleration on Mobile Devices"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "This paper proposes AutoML for Model Compression (AMC) which leverages reinforcement learning to efficiently sample the design space and can improve the model compression quality and achieves state-of-the-art model compression results in a fully automated way without any human efforts."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "19317494"
                        ],
                        "name": "Tom V\u00e9niat",
                        "slug": "Tom-V\u00e9niat",
                        "structuredName": {
                            "firstName": "Tom",
                            "lastName": "V\u00e9niat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tom V\u00e9niat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8905591"
                        ],
                        "name": "Ludovic Denoyer",
                        "slug": "Ludovic-Denoyer",
                        "structuredName": {
                            "firstName": "Ludovic",
                            "lastName": "Denoyer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ludovic Denoyer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 10
                            }
                        ],
                        "text": "Following [21], DNAS represents the search space by a super net whose operators execute stochastically."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3383456,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3b8aa7a38bc60f7b42757e53a0801f6e71dcef5c",
            "isKey": true,
            "numCitedBy": 66,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose to focus on the problem of discovering neural network architectures efficient in terms of both prediction quality and cost. For instance, our approach is able to solve the following tasks: learn a neural network able to predict well in less than 100 milliseconds or learn an efficient model that fits in a 50 Mb memory. Our contribution is a novel family of models called Budgeted Super Networks (BSN). They are learned using gradient descent techniques applied on a budgeted learning objective function which integrates a maximum authorized cost, while making no assumption on the nature of this cost. We present a set of experiments on computer vision problems and analyze the ability of our technique to deal with three different costs: the computation cost, the memory consumption cost and a distributed computation cost. We particularly show that our model can discover neural network architectures that have a better accuracy than the ResNet and Convolutional Neural Fabrics architectures on CIFAR-10 and CIFAR-100, at a lower cost."
            },
            "slug": "Learning-Time/Memory-Efficient-Deep-Architectures-V\u00e9niat-Denoyer",
            "title": {
                "fragments": [],
                "text": "Learning Time/Memory-Efficient Deep Architectures with Budgeted Super Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "A novel family of models called Budgeted Super Networks (BSN) is proposed, learned using gradient descent techniques applied on a budgeted learning objective function which integrates a maximum authorized cost, while making no assumption on the nature of this cost."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1950815"
                        ],
                        "name": "Tien-Ju Yang",
                        "slug": "Tien-Ju-Yang",
                        "structuredName": {
                            "firstName": "Tien-Ju",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tien-Ju Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144727050"
                        ],
                        "name": "Andrew G. Howard",
                        "slug": "Andrew-G.-Howard",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Howard",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew G. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Bo Chen",
                        "slug": "Bo-Chen",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115476987"
                        ],
                        "name": "Xiao Zhang",
                        "slug": "Xiao-Zhang",
                        "structuredName": {
                            "firstName": "Xiao",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiao Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2072476561"
                        ],
                        "name": "Alec Go",
                        "slug": "Alec-Go",
                        "structuredName": {
                            "firstName": "Alec",
                            "lastName": "Go",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alec Go"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1691305"
                        ],
                        "name": "V. Sze",
                        "slug": "V.-Sze",
                        "structuredName": {
                            "firstName": "Vivienne",
                            "lastName": "Sze",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Sze"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2595180"
                        ],
                        "name": "Hartwig Adam",
                        "slug": "Hartwig-Adam",
                        "structuredName": {
                            "firstName": "Hartwig",
                            "lastName": "Adam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hartwig Adam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 62,
                                "start": 55
                            }
                        ],
                        "text": "Besides searching for new architectures, works such as [27, 5] focus on adapting existing models to improve efficiency."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4746618,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d16b21f3e99171c86365679435f9f03766750639",
            "isKey": false,
            "numCitedBy": 324,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "This work proposes an algorithm, called NetAdapt, that automatically adapts a pre-trained deep neural network to a mobile platform given a resource budget. While many existing algorithms simplify networks based on the number of MACs or weights, optimizing those indirect metrics may not necessarily reduce the direct metrics, such as latency and energy consumption. To solve this problem, NetAdapt incorporates direct metrics into its adaptation algorithm. These direct metrics are evaluated using empirical measurements, so that detailed knowledge of the platform and toolchain is not required. NetAdapt automatically and progressively simplifies a pre-trained network until the resource budget is met while maximizing the accuracy. Experiment results show that NetAdapt achieves better accuracy versus latency trade-offs on both mobile CPU and mobile GPU, compared with the state-of-the-art automated network simplification algorithms. For image classification on the ImageNet dataset, NetAdapt achieves up to a 1.7$\\times$ speedup in measured inference latency with equal or higher accuracy on MobileNets (V1&V2)."
            },
            "slug": "NetAdapt:-Platform-Aware-Neural-Network-Adaptation-Yang-Howard",
            "title": {
                "fragments": [],
                "text": "NetAdapt: Platform-Aware Neural Network Adaptation for Mobile Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 61,
                "text": "An algorithm that automatically adapts a pre-trained deep neural network to a mobile platform given a resource budget while maximizing the accuracy, and achieves better accuracy versus latency trade-offs on both mobile CPU and mobile GPU, compared with the state-of-the-art automated network simplification algorithms."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50875121"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "Xiangyu",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2148927556"
                        ],
                        "name": "Xinyu Zhou",
                        "slug": "Xinyu-Zhou",
                        "structuredName": {
                            "firstName": "Xinyu",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xinyu Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3287035"
                        ],
                        "name": "Mengxiao Lin",
                        "slug": "Mengxiao-Lin",
                        "structuredName": {
                            "firstName": "Mengxiao",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mengxiao Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "ShuffleNet [29] uses group convolution and shuffle operations to reduce the FLOP count further."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 41
                            }
                        ],
                        "text": "When we use group convolution, we follow [29] to add a channel shuffle operation to mix the information between channel groups."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 24982157,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9da734397acd7ff7c557960c62fb1b400b27bd89",
            "isKey": false,
            "numCitedBy": 3251,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce an extremely computation-efficient CNN architecture named ShuffleNet, which is designed specially for mobile devices with very limited computing power (e.g., 10-150 MFLOPs). The new architecture utilizes two new operations, pointwise group convolution and channel shuffle, to greatly reduce computation cost while maintaining accuracy. Experiments on ImageNet classification and MS COCO object detection demonstrate the superior performance of ShuffleNet over other structures, e.g. lower top-1 error (absolute 7.8%) than recent MobileNet [12] on ImageNet classification task, under the computation budget of 40 MFLOPs. On an ARM-based mobile device, ShuffleNet achieves ~13\u00c3\u2014 actual speedup over AlexNet while maintaining comparable accuracy."
            },
            "slug": "ShuffleNet:-An-Extremely-Efficient-Convolutional-Zhang-Zhou",
            "title": {
                "fragments": [],
                "text": "ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices"
            },
            "tldr": {
                "abstractSimilarityScore": 79,
                "text": "An extremely computation-efficient CNN architecture named ShuffleNet is introduced, which is designed specially for mobile devices with very limited computing power (e.g., 10-150 MFLOPs), to greatly reduce computation cost while maintaining accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108989534"
                        ],
                        "name": "Yifan Yang",
                        "slug": "Yifan-Yang",
                        "structuredName": {
                            "firstName": "Yifan",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yifan Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145391991"
                        ],
                        "name": "Qijing Huang",
                        "slug": "Qijing-Huang",
                        "structuredName": {
                            "firstName": "Qijing",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qijing Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3130257"
                        ],
                        "name": "Bichen Wu",
                        "slug": "Bichen-Wu",
                        "structuredName": {
                            "firstName": "Bichen",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bichen Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1993655237"
                        ],
                        "name": "Tianjun Zhang",
                        "slug": "Tianjun-Zhang",
                        "structuredName": {
                            "firstName": "Tianjun",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tianjun Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109868183"
                        ],
                        "name": "Liang Ma",
                        "slug": "Liang-Ma",
                        "structuredName": {
                            "firstName": "Liang",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liang Ma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1779727"
                        ],
                        "name": "G. Gambardella",
                        "slug": "G.-Gambardella",
                        "structuredName": {
                            "firstName": "Giulio",
                            "lastName": "Gambardella",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Gambardella"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1791399"
                        ],
                        "name": "Michaela Blott",
                        "slug": "Michaela-Blott",
                        "structuredName": {
                            "firstName": "Michaela",
                            "lastName": "Blott",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Michaela Blott"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714574"
                        ],
                        "name": "L. Lavagno",
                        "slug": "L.-Lavagno",
                        "structuredName": {
                            "firstName": "Luciano",
                            "lastName": "Lavagno",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Lavagno"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145732571"
                        ],
                        "name": "K. Vissers",
                        "slug": "K.-Vissers",
                        "structuredName": {
                            "firstName": "Kees",
                            "lastName": "Vissers",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Vissers"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1762709"
                        ],
                        "name": "J. Wawrzynek",
                        "slug": "J.-Wawrzynek",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Wawrzynek",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Wawrzynek"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732330"
                        ],
                        "name": "K. Keutzer",
                        "slug": "K.-Keutzer",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Keutzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Keutzer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "Synetgy [28] combines ideas from ShuffleNetV2 and ShiftNet to co-design hardware friendly ConvNets and FPGA accelerators."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 53791706,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3cc6c2db24a2a14560f151867f2ac0b681ec3238",
            "isKey": false,
            "numCitedBy": 70,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "Using FPGAs to accelerate ConvNets has attracted significant attention in recent years. However, FPGA accelerator design has not leveraged the latest progress of ConvNets. As a result, the key application characteristics such as frames-per-second (FPS) are ignored in favor of simply counting GOPs, and results on accuracy, which is critical to application success, are often not even reported. In this work, we adopt an algorithm-hardware co-design approach to develop a ConvNet accelerator called Synetgy and a novel ConvNet model called DiracDeltaNet. Both the accelerator and ConvNet are tailored to FPGA requirements. DiracDeltaNet, as the name suggests, is a ConvNet with only $1\\times 1$ convolutions while spatial convolutions are replaced by more efficient shift operations. DiracDeltaNet achieves competitive accuracy on ImageNet (89.0% top-5), but with 48\u00d7 fewer parameters and 65\u00d7 fewer OPs than VGG16. We further quantize DiracDeltaNet's weights to 1-bit and activations to 4-bits, with less than 1% accuracy loss. These quantizations exploit well the nature of FPGA hardware. In short, DiracDeltaNet's small model size, low computational OP count, ultra-low precision and simplified operators allow us to co-design a highly customized computing unit for an FPGA. We implement the computing units for DiracDeltaNet on an Ultra96 SoC system through high-level synthesis. Our accelerator's final top-5 accuracy of 88.2% on ImageNet, is higher than all the previously reported embedded FPGA accelerators. In addition, the accelerator reaches an inference speed of 96.5 FPS on the ImageNet classification task, surpassing prior works with similar accuracy by at least 16.9\u00d7."
            },
            "slug": "Synetgy:-Algorithm-hardware-Co-design-for-ConvNet-Yang-Huang",
            "title": {
                "fragments": [],
                "text": "Synetgy: Algorithm-hardware Co-design for ConvNet Accelerators on Embedded FPGAs"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "DiracDeltaNet's small model size, low computational OP count, ultra-low precision and simplified operators allow us to co-design a highly customized computing unit for an FPGA, which achieves competitive accuracy on ImageNet, but with 48\u00d7 fewer parameters and 65\u00d7 fewer OPs than VGG16."
            },
            "venue": {
                "fragments": [],
                "text": "FPGA"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3130257"
                        ],
                        "name": "Bichen Wu",
                        "slug": "Bichen-Wu",
                        "structuredName": {
                            "firstName": "Bichen",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bichen Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3346186"
                        ],
                        "name": "Forrest N. Iandola",
                        "slug": "Forrest-N.-Iandola",
                        "structuredName": {
                            "firstName": "Forrest",
                            "lastName": "Iandola",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Forrest N. Iandola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32294544"
                        ],
                        "name": "Peter H. Jin",
                        "slug": "Peter-H.-Jin",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Jin",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter H. Jin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732330"
                        ],
                        "name": "K. Keutzer",
                        "slug": "K.-Keutzer",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Keutzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Keutzer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 85
                            }
                        ],
                        "text": "It is originally designed for classification, but later extended to object detection [22] and LiDAR point-cloud segmentation [24, 26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206598003,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "804aedfa1d732617cf5b9f59726b7f2e28fbbfb0",
            "isKey": false,
            "numCitedBy": 369,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "Object detection is a crucial task for autonomous driving. In addition to requiring high accuracy to ensure safety, object detection for autonomous driving also requires realtime inference speed to guarantee prompt vehicle control, as well as small model size and energy efficiency to enable embedded system deployment.,,,,,, In this work, we propose SqueezeDet, a fully convolutional neural network for object detection that aims to simultaneously satisfy all of the above constraints. In our network we use convolutional layers not only to extract feature maps, but also as the output layer to compute bounding boxes and class probabilities. The detection pipeline of our model only contains a single forward pass of a neural network, thus it is extremely fast. Our model is fullyconvolutional, which leads to small model size and better energy efficiency. Finally, our experiments show that our model is very accurate, achieving state-of-the-art accuracy on the KITTI [10] benchmark. The source code of SqueezeDet is open-source released."
            },
            "slug": "SqueezeDet:-Unified,-Small,-Low-Power-Fully-Neural-Wu-Iandola",
            "title": {
                "fragments": [],
                "text": "SqueezeDet: Unified, Small, Low Power Fully Convolutional Neural Networks for Real-Time Object Detection for Autonomous Driving"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "SqueezeDet is a fully convolutional neural network for object detection that aims to simultaneously satisfy all of the above constraints, and is very accurate, achieving state-of-the-art accuracy on the KITTI benchmark."
            },
            "venue": {
                "fragments": [],
                "text": "2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2391802"
                        ],
                        "name": "Hanxiao Liu",
                        "slug": "Hanxiao-Liu",
                        "structuredName": {
                            "firstName": "Hanxiao",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hanxiao Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34838386"
                        ],
                        "name": "K. Simonyan",
                        "slug": "K.-Simonyan",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Simonyan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Simonyan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35729970"
                        ],
                        "name": "Yiming Yang",
                        "slug": "Yiming-Yang",
                        "structuredName": {
                            "firstName": "Yiming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yiming Yang"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 15
                            }
                        ],
                        "text": "Previous works [30, 31, 16, 11, 12] focus on cell level architecture search."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 110
                            }
                        ],
                        "text": "Recent works try to reduce the computational cost by weight sharing [16] or using gradient-based optimization [12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 19
                            }
                        ],
                        "text": "Early works of NAS [31, 16, 12] focus on the cell level architecture search, and the same cell structure is repeated in all layers of a network."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 49411844,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c1f457e31b611da727f9aef76c283a18157dfa83",
            "isKey": false,
            "numCitedBy": 2237,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper addresses the scalability challenge of architecture search by formulating the task in a differentiable manner. Unlike conventional approaches of applying evolution or reinforcement learning over a discrete and non-differentiable search space, our method is based on the continuous relaxation of the architecture representation, allowing efficient search of the architecture using gradient descent. Extensive experiments on CIFAR-10, ImageNet, Penn Treebank and WikiText-2 show that our algorithm excels in discovering high-performance convolutional architectures for image classification and recurrent architectures for language modeling, while being orders of magnitude faster than state-of-the-art non-differentiable techniques. Our implementation has been made publicly available to facilitate further research on efficient architecture search algorithms."
            },
            "slug": "DARTS:-Differentiable-Architecture-Search-Liu-Simonyan",
            "title": {
                "fragments": [],
                "text": "DARTS: Differentiable Architecture Search"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "The proposed algorithm excels in discovering high-performance convolutional architectures for image classification and recurrent architectures for language modeling, while being orders of magnitude faster than state-of-the-art non-differentiable techniques."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3346186"
                        ],
                        "name": "Forrest N. Iandola",
                        "slug": "Forrest-N.-Iandola",
                        "structuredName": {
                            "firstName": "Forrest",
                            "lastName": "Iandola",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Forrest N. Iandola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143840275"
                        ],
                        "name": "Song Han",
                        "slug": "Song-Han",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2318023"
                        ],
                        "name": "M. Moskewicz",
                        "slug": "M.-Moskewicz",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Moskewicz",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Moskewicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059241"
                        ],
                        "name": "Khalid Ashraf",
                        "slug": "Khalid-Ashraf",
                        "structuredName": {
                            "firstName": "Khalid",
                            "lastName": "Ashraf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Khalid Ashraf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80724002"
                        ],
                        "name": "W. Dally",
                        "slug": "W.-Dally",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dally",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dally"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732330"
                        ],
                        "name": "K. Keutzer",
                        "slug": "K.-Keutzer",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Keutzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Keutzer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 11
                            }
                        ],
                        "text": "SqueezeNet [8] is one of the early works focusing on reducing the parameter size of ConvNet models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 29683894,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "592d2e65489f23ebd993dbdc0c84eda9ac8aadbe",
            "isKey": false,
            "numCitedBy": 687,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent research on deep convolutional neural networks (CNNs) has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple CNN architectures that achieve that accuracy level. With equivalent accuracy, smaller CNN architectures offer at least three advantages: (1) Smaller CNNs require less communication across servers during distributed training. (2) Smaller CNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller CNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small CNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques, we are able to compress SqueezeNet to less than 0.5MB (510\u00d7 smaller than AlexNet). The SqueezeNet architecture is available for download here: https://github.com/DeepScale/SqueezeNet"
            },
            "slug": "LEVEL-ACCURACY-WITH-50-X-FEWER-PARAMETERS-AND-<-0-.-Iandola-Han",
            "title": {
                "fragments": [],
                "text": "- LEVEL ACCURACY WITH 50 X FEWER PARAMETERS AND < 0 . 5 MB MODEL SIZE"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A small CNN architecture called SqueezeNet is proposed, which achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters and is able to compress to less than 0.5MB (510\u00d7 smaller than AlexNet)."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2368067"
                        ],
                        "name": "Barret Zoph",
                        "slug": "Barret-Zoph",
                        "structuredName": {
                            "firstName": "Barret",
                            "lastName": "Zoph",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barret Zoph"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053781980"
                        ],
                        "name": "Vijay Vasudevan",
                        "slug": "Vijay-Vasudevan",
                        "structuredName": {
                            "firstName": "Vijay",
                            "lastName": "Vasudevan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vijay Vasudevan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789737"
                        ],
                        "name": "Jonathon Shlens",
                        "slug": "Jonathon-Shlens",
                        "structuredName": {
                            "firstName": "Jonathon",
                            "lastName": "Shlens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathon Shlens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1397917613"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc V.",
                            "lastName": "Le",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 15
                            }
                        ],
                        "text": "Previous works [30, 31, 20] has demonstrated the effectiveness of such methods in finding accurate and efficient ConvNet models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 95
                            }
                        ],
                        "text": "\u2020 The search cost is estimated based on the claim from [11] that PNAS [11] is 8x lower than NAS[31]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 13
                            }
                        ],
                        "text": "For example, [30, 31] trains the architecture on the CIFAR10 dataset, and [20] trains on ImageNet but only for 5 epochs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 15
                            }
                        ],
                        "text": "Previous works [30, 31, 16, 11, 12] focus on cell level architecture search."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 20
                            }
                        ],
                        "text": "Many previous works [30, 31, 20] use reinforcement learning (RL) to guide the search and a typical flow is illustrated in Figure 2(b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "For example, NasNetA [31] has a similar FLOP count as MobileNetV1 [6], but its complicated and fragmented cell-level structure is not hardware friendly, so the actual latency is slower [17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 28
                            }
                        ],
                        "text": "Neural Architecture Search: [30, 31] first proposes to use reinforcement learning (RL) to search for neural architectures to achieve competitive accuracy with low FLOPs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 31,
                                "start": 19
                            }
                        ],
                        "text": "Early works of NAS [31, 16, 12] focus on the cell level architecture search, and the same cell structure is repeated in all layers of a network."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 58
                            }
                        ],
                        "text": "To avoid exhaustively iterating through the search space, [30, 31, 20] use reinforcement learning to guide the exploration."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 31
                            }
                        ],
                        "text": "Most of the early works on NAS [30, 31, 20] follow the paradigm above."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12227989,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d0611891b9e8a7c5731146097b6f201578f47b2f",
            "isKey": true,
            "numCitedBy": 3538,
            "numCiting": 81,
            "paperAbstract": {
                "fragments": [],
                "text": "Developing neural network image classification models often requires significant architecture engineering. In this paper, we study a method to learn the model architectures directly on the dataset of interest. As this approach is expensive when the dataset is large, we propose to search for an architectural building block on a small dataset and then transfer the block to a larger dataset. The key contribution of this work is the design of a new search space (which we call the \"NASNet search space\") which enables transferability. In our experiments, we search for the best convolutional layer (or \"cell\") on the CIFAR-10 dataset and then apply this cell to the ImageNet dataset by stacking together more copies of this cell, each with their own parameters to design a convolutional architecture, which we name a \"NASNet architecture\". We also introduce a new regularization technique called ScheduledDropPath that significantly improves generalization in the NASNet models. On CIFAR-10 itself, a NASNet found by our method achieves 2.4% error rate, which is state-of-the-art. Although the cell is not searched for directly on ImageNet, a NASNet constructed from the best cell achieves, among the published works, state-of-the-art accuracy of 82.7% top-1 and 96.2% top-5 on ImageNet. Our model is 1.2% better in top-1 accuracy than the best human-invented architectures while having 9 billion fewer FLOPS - a reduction of 28% in computational demand from the previous state-of-the-art model. When evaluated at different levels of computational cost, accuracies of NASNets exceed those of the state-of-the-art human-designed models. For instance, a small version of NASNet also achieves 74% top-1 accuracy, which is 3.1% better than equivalently-sized, state-of-the-art models for mobile platforms. Finally, the image features learned from image classification are generically useful and can be transferred to other computer vision problems. On the task of object detection, the learned features by NASNet used with the Faster-RCNN framework surpass state-of-the-art by 4.0% achieving 43.1% mAP on the COCO dataset."
            },
            "slug": "Learning-Transferable-Architectures-for-Scalable-Zoph-Vasudevan",
            "title": {
                "fragments": [],
                "text": "Learning Transferable Architectures for Scalable Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This paper proposes to search for an architectural building block on a small dataset and then transfer the block to a larger dataset and introduces a new regularization technique called ScheduledDropPath that significantly improves generalization in the NASNet models."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52435355"
                        ],
                        "name": "Sirui Xie",
                        "slug": "Sirui-Xie",
                        "structuredName": {
                            "firstName": "Sirui",
                            "lastName": "Xie",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sirui Xie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115584569"
                        ],
                        "name": "Hehui Zheng",
                        "slug": "Hehui-Zheng",
                        "structuredName": {
                            "firstName": "Hehui",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hehui Zheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107926923"
                        ],
                        "name": "Chunxiao Liu",
                        "slug": "Chunxiao-Liu",
                        "structuredName": {
                            "firstName": "Chunxiao",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chunxiao Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737218"
                        ],
                        "name": "Liang Lin",
                        "slug": "Liang-Lin",
                        "structuredName": {
                            "firstName": "Liang",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liang Lin"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 56895416,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3f0a2de309f21a957b4741dd68007eb08d9b12e3",
            "isKey": false,
            "numCitedBy": 626,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose Stochastic Neural Architecture Search (SNAS), an economical end-to-end solution to Neural Architecture Search (NAS) that trains neural operation parameters and architecture distribution parameters in same round of back-propagation, while maintaining the completeness and differentiability of the NAS pipeline. In this work, NAS is reformulated as an optimization problem on parameters of a joint distribution for the search space in a cell. To leverage the gradient information in generic differentiable loss for architecture search, a novel search gradient is proposed. We prove that this search gradient optimizes the same objective as reinforcement-learning-based NAS, but assigns credits to structural decisions more efficiently. This credit assignment is further augmented with locally decomposable reward to enforce a resource-efficient constraint. In experiments on CIFAR-10, SNAS takes less epochs to find a cell architecture with state-of-the-art accuracy than non-differentiable evolution-based and reinforcement-learning-based NAS, which is also transferable to ImageNet. It is also shown that child networks of SNAS can maintain the validation accuracy in searching, with which attention-based NAS requires parameter retraining to compete, exhibiting potentials to stride towards efficient NAS on big datasets. We have released our implementation at this https URL."
            },
            "slug": "SNAS:-Stochastic-Neural-Architecture-Search-Xie-Zheng",
            "title": {
                "fragments": [],
                "text": "SNAS: Stochastic Neural Architecture Search"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is proved that this search gradient optimizes the same objective as reinforcement-learning-based NAS, but assigns credits to structural decisions more efficiently, and is further augmented with locally decomposable reward to enforce a resource-efficient constraint."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50557601"
                        ],
                        "name": "Chenxi Liu",
                        "slug": "Chenxi-Liu",
                        "structuredName": {
                            "firstName": "Chenxi",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chenxi Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2368067"
                        ],
                        "name": "Barret Zoph",
                        "slug": "Barret-Zoph",
                        "structuredName": {
                            "firstName": "Barret",
                            "lastName": "Zoph",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barret Zoph"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1789737"
                        ],
                        "name": "Jonathon Shlens",
                        "slug": "Jonathon-Shlens",
                        "structuredName": {
                            "firstName": "Jonathon",
                            "lastName": "Shlens",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathon Shlens"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052830834"
                        ],
                        "name": "Wei Hua",
                        "slug": "Wei-Hua",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Hua",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Hua"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2040091191"
                        ],
                        "name": "Li-Jia Li",
                        "slug": "Li-Jia-Li",
                        "structuredName": {
                            "firstName": "Li-Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145081362"
                        ],
                        "name": "A. Yuille",
                        "slug": "A.-Yuille",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Yuille",
                            "middleNames": [
                                "Loddon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Yuille"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2136435893"
                        ],
                        "name": "Jonathan Huang",
                        "slug": "Jonathan-Huang",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702318"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 97,
                                "start": 93
                            }
                        ],
                        "text": "Among all the automatically searched models, FBNet\u2019s performance is much stronger than DARTS, PNAS, and NAS, and better than MnasNet."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 59,
                                "start": 55
                            }
                        ],
                        "text": "\u2020 The search cost is estimated based on the claim from [11] that PNAS [11] is 8x lower than NAS[31]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 15
                            }
                        ],
                        "text": "Previous works [30, 31, 16, 11, 12] focus on cell level architecture search."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 182
                            }
                        ],
                        "text": "In comparison, the FBNet search takes 8 GPUs for only 27 hours, so the computational cost is only 216 GPU hours, or 421x faster than MnasNet, 222x faster than NAS, 27.8x faster than PNAS, and 1.33x faster than DARTS."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "We do not have the latency of NASNet-A and PNASNet, but the accuracy is comparable, and the FLOP count is 1.9x and 2.0x smaller."
                    },
                    "intents": []
                }
            ],
            "corpusId": 40430109,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5f79398057bf0bbda9ff50067bc1f2950c2a2266",
            "isKey": true,
            "numCitedBy": 1377,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new method for learning the structure of convolutional neural networks (CNNs) that is more efficient than recent state-of-the-art methods based on reinforcement learning and evolutionary algorithms. Our approach uses a sequential model-based optimization (SMBO) strategy, in which we search for structures in order of increasing complexity, while simultaneously learning a surrogate model to guide the search through structure space. Direct comparison under the same search space shows that our method is up to 5 times more efficient than the RL method of Zoph et al. (2018) in terms of number of models evaluated, and 8 times faster in terms of total compute. The structures we discover in this way achieve state of the art classification accuracies on CIFAR-10 and ImageNet."
            },
            "slug": "Progressive-Neural-Architecture-Search-Liu-Zoph",
            "title": {
                "fragments": [],
                "text": "Progressive Neural Architecture Search"
            },
            "tldr": {
                "abstractSimilarityScore": 94,
                "text": "This work proposes a new method for learning the structure of convolutional neural networks (CNNs) that is more efficient than recent state-of-the-art methods based on reinforcement learning and evolutionary algorithms using a sequential model-based optimization (SMBO) strategy."
            },
            "venue": {
                "fragments": [],
                "text": "ECCV"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144727050"
                        ],
                        "name": "Andrew G. Howard",
                        "slug": "Andrew-G.-Howard",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Howard",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew G. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2717876"
                        ],
                        "name": "Menglong Zhu",
                        "slug": "Menglong-Zhu",
                        "structuredName": {
                            "firstName": "Menglong",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Menglong Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Bo Chen",
                        "slug": "Bo-Chen",
                        "structuredName": {
                            "firstName": "Bo",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bo Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2741985"
                        ],
                        "name": "Dmitry Kalenichenko",
                        "slug": "Dmitry-Kalenichenko",
                        "structuredName": {
                            "firstName": "Dmitry",
                            "lastName": "Kalenichenko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dmitry Kalenichenko"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2108301072"
                        ],
                        "name": "Weijun Wang",
                        "slug": "Weijun-Wang",
                        "structuredName": {
                            "firstName": "Weijun",
                            "lastName": "Wang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Weijun Wang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47447630"
                        ],
                        "name": "Tobias Weyand",
                        "slug": "Tobias-Weyand",
                        "structuredName": {
                            "firstName": "Tobias",
                            "lastName": "Weyand",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tobias Weyand"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2612392"
                        ],
                        "name": "M. Andreetto",
                        "slug": "M.-Andreetto",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Andreetto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Andreetto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2595180"
                        ],
                        "name": "Hartwig Adam",
                        "slug": "Hartwig-Adam",
                        "structuredName": {
                            "firstName": "Hartwig",
                            "lastName": "Adam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Hartwig Adam"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 66
                            }
                        ],
                        "text": "For example, NasNetA [31] has a similar FLOP count as MobileNetV1 [6], but its complicated and fragmented cell-level structure is not hardware friendly, so the actual latency is slower [17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 28
                            }
                        ],
                        "text": "MobileNetV1 and MobileNetV2 [6, 17] use depthwise convolutions to replace the more expensive spatial convolutions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 12670695,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3647d6d0f151dc05626449ee09cc7bce55be497e",
            "isKey": false,
            "numCitedBy": 10323,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We present a class of efficient models called MobileNets for mobile and embedded vision applications. MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks. We introduce two simple global hyper-parameters that efficiently trade off between latency and accuracy. These hyper-parameters allow the model builder to choose the right sized model for their application based on the constraints of the problem. We present extensive experiments on resource and accuracy tradeoffs and show strong performance compared to other popular models on ImageNet classification. We then demonstrate the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization."
            },
            "slug": "MobileNets:-Efficient-Convolutional-Neural-Networks-Howard-Zhu",
            "title": {
                "fragments": [],
                "text": "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work introduces two simple global hyper-parameters that efficiently trade off between latency and accuracy and demonstrates the effectiveness of MobileNets across a wide range of applications and use cases including object detection, finegrain classification, face attributes and large scale geo-localization."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144882893"
                        ],
                        "name": "M. Sandler",
                        "slug": "M.-Sandler",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Sandler",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sandler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144727050"
                        ],
                        "name": "Andrew G. Howard",
                        "slug": "Andrew-G.-Howard",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Howard",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew G. Howard"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2717876"
                        ],
                        "name": "Menglong Zhu",
                        "slug": "Menglong-Zhu",
                        "structuredName": {
                            "firstName": "Menglong",
                            "lastName": "Zhu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Menglong Zhu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3422677"
                        ],
                        "name": "A. Zhmoginov",
                        "slug": "A.-Zhmoginov",
                        "structuredName": {
                            "firstName": "Andrey",
                            "lastName": "Zhmoginov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Zhmoginov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34192119"
                        ],
                        "name": "Liang-Chieh Chen",
                        "slug": "Liang-Chieh-Chen",
                        "structuredName": {
                            "firstName": "Liang-Chieh",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Liang-Chieh Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 10
                            }
                        ],
                        "text": "Following [17, 23], we use a hyperparameter, the expansion ratio e, to control"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 28
                            }
                        ],
                        "text": "MobileNetV1 and MobileNetV2 [6, 17] use depthwise convolutions to replace the more expensive spatial convolutions."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 47
                            }
                        ],
                        "text": "The block structure is inspired by MobileNetV2 [17] and ShiftNet [23], and is illustrated in Figure 3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 189,
                                "start": 185
                            }
                        ],
                        "text": "For example, NasNetA [31] has a similar FLOP count as MobileNetV1 [6], but its complicated and fragmented cell-level structure is not hardware friendly, so the actual latency is slower [17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 127
                            }
                        ],
                        "text": "However, many searched cell structures are very complicated and fragmented and are therefore slow when deployed to mobile CPUs [17, 13]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 4555207,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "dd9cfe7124c734f5a6fc90227d541d3dbcd72ba4",
            "isKey": true,
            "numCitedBy": 7406,
            "numCiting": 55,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we describe a new mobile architecture, MobileNetV2, that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes. We also describe efficient ways of applying these mobile models to object detection in a novel framework we call SSDLite. Additionally, we demonstrate how to build mobile semantic segmentation models through a reduced form of DeepLabv3 which we call Mobile DeepLabv3. is based on an inverted residual structure where the shortcut connections are between the thin bottleneck layers. The intermediate expansion layer uses lightweight depthwise convolutions to filter features as a source of non-linearity. Additionally, we find that it is important to remove non-linearities in the narrow layers in order to maintain representational power. We demonstrate that this improves performance and provide an intuition that led to this design. Finally, our approach allows decoupling of the input/output domains from the expressiveness of the transformation, which provides a convenient framework for further analysis. We measure our performance on ImageNet [1] classification, COCO object detection [2], VOC image segmentation [3]. We evaluate the trade-offs between accuracy, and number of operations measured by multiply-adds (MAdd), as well as actual latency, and the number of parameters."
            },
            "slug": "MobileNetV2:-Inverted-Residuals-and-Linear-Sandler-Howard",
            "title": {
                "fragments": [],
                "text": "MobileNetV2: Inverted Residuals and Linear Bottlenecks"
            },
            "tldr": {
                "abstractSimilarityScore": 75,
                "text": "A new mobile architecture, MobileNetV2, is described that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes and allows decoupling of the input/output domains from the expressiveness of the transformation."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143983679"
                        ],
                        "name": "Gao Huang",
                        "slug": "Gao-Huang",
                        "structuredName": {
                            "firstName": "Gao",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gao Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2049404247"
                        ],
                        "name": "Shichen Liu",
                        "slug": "Shichen-Liu",
                        "structuredName": {
                            "firstName": "Shichen",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shichen Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1803520"
                        ],
                        "name": "L. V. D. Maaten",
                        "slug": "L.-V.-D.-Maaten",
                        "structuredName": {
                            "firstName": "Laurens",
                            "lastName": "Maaten",
                            "middleNames": [
                                "van",
                                "der"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. V. D. Maaten"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7446832"
                        ],
                        "name": "Kilian Q. Weinberger",
                        "slug": "Kilian-Q.-Weinberger",
                        "structuredName": {
                            "firstName": "Kilian",
                            "lastName": "Weinberger",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kilian Q. Weinberger"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 31409561,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "efbac99adf8628aae7f070e5b4388a295956f9d2",
            "isKey": false,
            "numCitedBy": 516,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep neural networks are increasingly used on mobile devices, where computational resources are limited. In this paper we develop CondenseNet, a novel network architecture with unprecedented efficiency. It combines dense connectivity with a novel module called learned group convolution. The dense connectivity facilitates feature re-use in the network, whereas learned group convolutions remove connections between layers for which this feature re-use is superfluous. At test time, our model can be implemented using standard group convolutions, allowing for efficient computation in practice. Our experiments show that CondenseNets are far more efficient than state-of-the-art compact convolutional networks such as ShuffleNets."
            },
            "slug": "CondenseNet:-An-Efficient-DenseNet-Using-Learned-Huang-Liu",
            "title": {
                "fragments": [],
                "text": "CondenseNet: An Efficient DenseNet Using Learned Group Convolutions"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "CondenseNet is developed, a novel network architecture with unprecedented efficiency that combines dense connectivity with a novel module called learned group convolution, allowing for efficient computation in practice."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2368067"
                        ],
                        "name": "Barret Zoph",
                        "slug": "Barret-Zoph",
                        "structuredName": {
                            "firstName": "Barret",
                            "lastName": "Zoph",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Barret Zoph"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 15
                            }
                        ],
                        "text": "Previous works [30, 31, 20] has demonstrated the effectiveness of such methods in finding accurate and efficient ConvNet models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 13
                            }
                        ],
                        "text": "For example, [30, 31] trains the architecture on the CIFAR10 dataset, and [20] trains on ImageNet but only for 5 epochs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 35,
                                "start": 15
                            }
                        ],
                        "text": "Previous works [30, 31, 16, 11, 12] focus on cell level architecture search."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 32,
                                "start": 20
                            }
                        ],
                        "text": "Many previous works [30, 31, 20] use reinforcement learning (RL) to guide the search and a typical flow is illustrated in Figure 2(b)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "Starting from [30], recent works adopt neural architecture search (NAS) to explore the design space automatically."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 36,
                                "start": 28
                            }
                        ],
                        "text": "Neural Architecture Search: [30, 31] first proposes to use reinforcement learning (RL) to search for neural architectures to achieve competitive accuracy with low FLOPs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 58
                            }
                        ],
                        "text": "To avoid exhaustively iterating through the search space, [30, 31, 20] use reinforcement learning to guide the exploration."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 31
                            }
                        ],
                        "text": "Most of the early works on NAS [30, 31, 20] follow the paradigm above."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 12713052,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "67d968c7450878190e45ac7886746de867bf673d",
            "isKey": true,
            "numCitedBy": 3482,
            "numCiting": 72,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural networks are powerful and flexible models that work well for many difficult learning tasks in image, speech and natural language understanding. Despite their success, neural networks are still hard to design. In this paper, we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set. On the CIFAR-10 dataset, our method, starting from scratch, can design a novel network architecture that rivals the best human-invented architecture in terms of test set accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is 0.09 percent better and 1.05x faster than the previous state-of-the-art model that used a similar architectural scheme. On the Penn Treebank dataset, our model can compose a novel recurrent cell that outperforms the widely-used LSTM cell, and other state-of-the-art baselines. Our cell achieves a test set perplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than the previous state-of-the-art model. The cell can also be transferred to the character language modeling task on PTB and achieves a state-of-the-art perplexity of 1.214."
            },
            "slug": "Neural-Architecture-Search-with-Reinforcement-Zoph-Le",
            "title": {
                "fragments": [],
                "text": "Neural Architecture Search with Reinforcement Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper uses a recurrent network to generate the model descriptions of neural networks and trains this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2574060"
                        ],
                        "name": "Christian Szegedy",
                        "slug": "Christian-Szegedy",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Szegedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Szegedy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157222093"
                        ],
                        "name": "Wei Liu",
                        "slug": "Wei-Liu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39978391"
                        ],
                        "name": "Yangqing Jia",
                        "slug": "Yangqing-Jia",
                        "structuredName": {
                            "firstName": "Yangqing",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yangqing Jia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3142556"
                        ],
                        "name": "Pierre Sermanet",
                        "slug": "Pierre-Sermanet",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Sermanet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierre Sermanet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144828948"
                        ],
                        "name": "Scott E. Reed",
                        "slug": "Scott-E.-Reed",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Reed",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott E. Reed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1838674"
                        ],
                        "name": "Dragomir Anguelov",
                        "slug": "Dragomir-Anguelov",
                        "structuredName": {
                            "firstName": "Dragomir",
                            "lastName": "Anguelov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dragomir Anguelov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761978"
                        ],
                        "name": "D. Erhan",
                        "slug": "D.-Erhan",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Erhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Erhan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2657155"
                        ],
                        "name": "Vincent Vanhoucke",
                        "slug": "Vincent-Vanhoucke",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Vanhoucke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Vanhoucke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39863668"
                        ],
                        "name": "Andrew Rabinovich",
                        "slug": "Andrew-Rabinovich",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Rabinovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Rabinovich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206592484,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e15cf50aa89fee8535703b9f9512fca5bfc43327",
            "isKey": false,
            "numCitedBy": 29917,
            "numCiting": 278,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection."
            },
            "slug": "Going-deeper-with-convolutions-Szegedy-Liu",
            "title": {
                "fragments": [],
                "text": "Going deeper with convolutions"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "A deep convolutional neural network architecture codenamed Inception is proposed that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14)."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34838386"
                        ],
                        "name": "K. Simonyan",
                        "slug": "K.-Simonyan",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Simonyan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Simonyan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "Using VGG16 [18] as a motivating example: VGG16 contains 16 layers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14124313,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb42cf88027de515750f230b23b1a057dc782108",
            "isKey": false,
            "numCitedBy": 63195,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision."
            },
            "slug": "Very-Deep-Convolutional-Networks-for-Large-Scale-Simonyan-Zisserman",
            "title": {
                "fragments": [],
                "text": "Very Deep Convolutional Networks for Large-Scale Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This work investigates the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting using an architecture with very small convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771551"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3080683"
                        ],
                        "name": "Shaoqing Ren",
                        "slug": "Shaoqing-Ren",
                        "structuredName": {
                            "firstName": "Shaoqing",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoqing Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206594692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "isKey": false,
            "numCitedBy": 97653,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation."
            },
            "slug": "Deep-Residual-Learning-for-Image-Recognition-He-Zhang",
            "title": {
                "fragments": [],
                "text": "Deep Residual Learning for Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work presents a residual learning framework to ease the training of networks that are substantially deeper than those used previously, and provides comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3130257"
                        ],
                        "name": "Bichen Wu",
                        "slug": "Bichen-Wu",
                        "structuredName": {
                            "firstName": "Bichen",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bichen Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144546548"
                        ],
                        "name": "Alvin Wan",
                        "slug": "Alvin-Wan",
                        "structuredName": {
                            "firstName": "Alvin",
                            "lastName": "Wan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alvin Wan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27577617"
                        ],
                        "name": "Xiangyu Yue",
                        "slug": "Xiangyu-Yue",
                        "structuredName": {
                            "firstName": "Xiangyu",
                            "lastName": "Yue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangyu Yue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "32294544"
                        ],
                        "name": "Peter H. Jin",
                        "slug": "Peter-H.-Jin",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "Jin",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Peter H. Jin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755487"
                        ],
                        "name": "Sicheng Zhao",
                        "slug": "Sicheng-Zhao",
                        "structuredName": {
                            "firstName": "Sicheng",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sicheng Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30096597"
                        ],
                        "name": "Noah Golmant",
                        "slug": "Noah-Golmant",
                        "structuredName": {
                            "firstName": "Noah",
                            "lastName": "Golmant",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Noah Golmant"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3647010"
                        ],
                        "name": "A. Gholaminejad",
                        "slug": "A.-Gholaminejad",
                        "structuredName": {
                            "firstName": "Amir",
                            "lastName": "Gholaminejad",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Gholaminejad"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49988044"
                        ],
                        "name": "Joseph E. Gonzalez",
                        "slug": "Joseph-E.-Gonzalez",
                        "structuredName": {
                            "firstName": "Joseph",
                            "lastName": "Gonzalez",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joseph E. Gonzalez"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732330"
                        ],
                        "name": "K. Keutzer",
                        "slug": "K.-Keutzer",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Keutzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Keutzer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 50
                            }
                        ],
                        "text": "Synetgy [28] combines ideas from ShuffleNetV2 and ShiftNet to co-design hardware friendly ConvNets and FPGA accelerators."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 10
                            }
                        ],
                        "text": "Following [17, 23], we use a hyperparameter, the expansion ratio e, to control"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": "The block structure is inspired by MobileNetV2 [17] and ShiftNet [23], and is illustrated in Figure 3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "Following SqueezeNet, SqueezeNext [3] and ShiftNet [23] achieve further parameter size reduction."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 38943488,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "70c810ba62c5ee40d611e134b2ac2ca61c4de16b",
            "isKey": false,
            "numCitedBy": 214,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural networks rely on convolutions to aggregate spatial information. However, spatial convolutions are expensive in terms of model size and computation, both of which grow quadratically with respect to kernel size. In this paper, we present a parameter-free, FLOP-free \"shift\" operation as an alternative to spatial convolutions. We fuse shifts and point-wise convolutions to construct end-to-end trainable shift-based modules, with a hyperparameter characterizing the tradeoff between accuracy and efficiency. To demonstrate the operation's efficacy, we replace ResNet's 3x3 convolutions with shift-based modules for improved CIFAR10 and CIFAR100 accuracy using 60% fewer parameters; we additionally demonstrate the operation's resilience to parameter reduction on ImageNet, outperforming ResNet family members. We finally show the shift operation's applicability across domains, achieving strong performance with fewer parameters on image classification, face verification and style transfer."
            },
            "slug": "Shift:-A-Zero-FLOP,-Zero-Parameter-Alternative-to-Wu-Wan",
            "title": {
                "fragments": [],
                "text": "Shift: A Zero FLOP, Zero Parameter Alternative to Spatial Convolutions"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A parameter-free, FLOP-free \"shift\" operation as an alternative to spatial convolutions, which fuse shifts and point-wise convolutions to construct end-to-end trainable shift-based modules, with a hyperparameter characterizing the tradeoff between accuracy and efficiency."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3130257"
                        ],
                        "name": "Bichen Wu",
                        "slug": "Bichen-Wu",
                        "structuredName": {
                            "firstName": "Bichen",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bichen Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144546548"
                        ],
                        "name": "Alvin Wan",
                        "slug": "Alvin-Wan",
                        "structuredName": {
                            "firstName": "Alvin",
                            "lastName": "Wan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alvin Wan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27577617"
                        ],
                        "name": "Xiangyu Yue",
                        "slug": "Xiangyu-Yue",
                        "structuredName": {
                            "firstName": "Xiangyu",
                            "lastName": "Yue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangyu Yue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732330"
                        ],
                        "name": "K. Keutzer",
                        "slug": "K.-Keutzer",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Keutzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Keutzer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 125
                            }
                        ],
                        "text": "It is originally designed for classification, but later extended to object detection [22] and LiDAR point-cloud segmentation [24, 26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 206853127,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cb8e4bdd69248146bc42aacc45929a9dbfe44081",
            "isKey": false,
            "numCitedBy": 428,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We address semantic segmentation of road-objects from 3D LiDAR point clouds. In particular, we wish to detect and categorize instances of interest, such as cars, pedestrians and cyclists. We formulate this problem as a point-wise classification problem, and propose an end-to-end pipeline called SqueezeSeg based on convolutional neural networks (CNN): the CNN takes a transformed LiDAR point cloud as input and directly outputs a point-wise label map, which is then refined by a conditional random field (CRF) implemented as a recurrent layer. Instance-level labels are then obtained by conventional clustering algorithms. Our CNN model is trained on LiDAR point clouds from the KITTI [1] dataset, and our point-wise segmentation labels are derived from 3D bounding boxes from KITTI. To obtain extra training data, we built a LiDAR simulator into Grand Theft Auto $\\boldsymbol{V}$ (GTA-V), a popular video game, to synthesize large amounts of realistic training data. Our experiments show that SqueezeSeg achieves high accuracy with astonishingly fast and stable runtime ($8.7\\pm 0.5$ ms per frame), highly desirable for autonomous driving. Furthermore, additionally training on synthesized data boosts validation accuracy on real-world data. Our source code is open-source released111https://github.com/BichenWuUCB/SqueezeSeg. The paper is accompanied by a video222https://youtu.be/Xyn5Zd31m6s containing a high level introduction and demonstrations of this work."
            },
            "slug": "SqueezeSeg:-Convolutional-Neural-Nets-with-CRF-for-Wu-Wan",
            "title": {
                "fragments": [],
                "text": "SqueezeSeg: Convolutional Neural Nets with Recurrent CRF for Real-Time Road-Object Segmentation from 3D LiDAR Point Cloud"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "An end-to-end pipeline called SqueezeSeg based on convolutional neural networks (CNN), which takes a transformed LiDAR point cloud as input and directly outputs a point-wise label map, which is then refined by a conditional random field (CRF) implemented as a recurrent layer."
            },
            "venue": {
                "fragments": [],
                "text": "2018 IEEE International Conference on Robotics and Automation (ICRA)"
            },
            "year": 2018
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3130257"
                        ],
                        "name": "Bichen Wu",
                        "slug": "Bichen-Wu",
                        "structuredName": {
                            "firstName": "Bichen",
                            "lastName": "Wu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bichen Wu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2086919"
                        ],
                        "name": "Xuanyu Zhou",
                        "slug": "Xuanyu-Zhou",
                        "structuredName": {
                            "firstName": "Xuanyu",
                            "lastName": "Zhou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xuanyu Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1755487"
                        ],
                        "name": "Sicheng Zhao",
                        "slug": "Sicheng-Zhao",
                        "structuredName": {
                            "firstName": "Sicheng",
                            "lastName": "Zhao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sicheng Zhao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "27577617"
                        ],
                        "name": "Xiangyu Yue",
                        "slug": "Xiangyu-Yue",
                        "structuredName": {
                            "firstName": "Xiangyu",
                            "lastName": "Yue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Xiangyu Yue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732330"
                        ],
                        "name": "K. Keutzer",
                        "slug": "K.-Keutzer",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Keutzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Keutzer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 125
                            }
                        ],
                        "text": "It is originally designed for classification, but later extended to object detection [22] and LiDAR point-cloud segmentation [24, 26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 52815788,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c524a8fe1ae29844627c163dd4efeb0cebc032c1",
            "isKey": false,
            "numCitedBy": 263,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Earlier work demonstrates the promise of deep-learning-based approaches for point cloud segmentation; however, these approaches need to be improved to be practically useful. To this end, we introduce a new model SqueezeSegV2. With an improved model structure, SqueezeSetV2 is more robust against dropout noises in LiDAR point cloud and therefore achieves significant accuracy improvement. Training models for point cloud segmentation requires large amounts of labeled data, which is expensive to obtain. To sidestep the cost of data collection and annotation, simulators such as GTA-V can be used to create unlimited amounts of labeled, synthetic data. However, due to domain shift, models trained on synthetic data often do not generalize well to the real world. Existing domain-adaptation methods mainly focus on images and most of them cannot be directly applied to point clouds. We address this problem with a domain-adaptation training pipeline consisting of three major components: 1) learned intensity rendering, 2) geodesic correlation alignment, and 3) progressive domain calibration. When trained on real data, our new model exhibits segmentation accuracy improvements of 6.0-8.6% over the original SqueezeSeg. When training our new model on synthetic data using the proposed domain adaptation pipeline, we nearly double test accuracy on real-world data, from 29.0% to 57.4%. Our source code and synthetic dataset are open sourced11https://github.com/xuanyuzhou98/SqueezeSegV2"
            },
            "slug": "SqueezeSegV2:-Improved-Model-Structure-and-Domain-a-Wu-Zhou",
            "title": {
                "fragments": [],
                "text": "SqueezeSegV2: Improved Model Structure and Unsupervised Domain Adaptation for Road-Object Segmentation from a LiDAR Point Cloud"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work introduces a new model SqueezeSegV2, which is more robust against dropout noises in LiDAR point cloud and therefore achieves significant accuracy improvement, and a domain-adaptation training pipeline consisting of three major components: learned intensity rendering, geodesic correlation alignment, and progressive domain calibration."
            },
            "venue": {
                "fragments": [],
                "text": "2019 International Conference on Robotics and Automation (ICRA)"
            },
            "year": 2019
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3407277"
                        ],
                        "name": "Adam Paszke",
                        "slug": "Adam-Paszke",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Paszke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Paszke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39793298"
                        ],
                        "name": "S. Gross",
                        "slug": "S.-Gross",
                        "structuredName": {
                            "firstName": "Sam",
                            "lastName": "Gross",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gross"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2127604"
                        ],
                        "name": "Soumith Chintala",
                        "slug": "Soumith-Chintala",
                        "structuredName": {
                            "firstName": "Soumith",
                            "lastName": "Chintala",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Soumith Chintala"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "114250963"
                        ],
                        "name": "Gregory Chanan",
                        "slug": "Gregory-Chanan",
                        "structuredName": {
                            "firstName": "Gregory",
                            "lastName": "Chanan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gregory Chanan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2052812305"
                        ],
                        "name": "E. Yang",
                        "slug": "E.-Yang",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2375710"
                        ],
                        "name": "Zach DeVito",
                        "slug": "Zach-DeVito",
                        "structuredName": {
                            "firstName": "Zach",
                            "lastName": "DeVito",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zach DeVito"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3370429"
                        ],
                        "name": "Zeming Lin",
                        "slug": "Zeming-Lin",
                        "structuredName": {
                            "firstName": "Zeming",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zeming Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3050846"
                        ],
                        "name": "Alban Desmaison",
                        "slug": "Alban-Desmaison",
                        "structuredName": {
                            "firstName": "Alban",
                            "lastName": "Desmaison",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alban Desmaison"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3029482"
                        ],
                        "name": "L. Antiga",
                        "slug": "L.-Antiga",
                        "structuredName": {
                            "firstName": "Luca",
                            "lastName": "Antiga",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Antiga"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1977806"
                        ],
                        "name": "Adam Lerer",
                        "slug": "Adam-Lerer",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Lerer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Lerer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 60
                            }
                        ],
                        "text": "Our architecture search framework is implemented in pytorch [15] and searched models are trained in Caffe2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 40027675,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b36a5bb1707bb9c70025294b3a310138aae8327a",
            "isKey": false,
            "numCitedBy": 10485,
            "numCiting": 7,
            "paperAbstract": {
                "fragments": [],
                "text": "In this article, we describe an automatic differentiation module of PyTorch \u2014 a library designed to enable rapid research on machine learning models. It builds upon a few projects, most notably Lua Torch, Chainer, and HIPS Autograd [4], and provides a high performance environment with easy access to automatic differentiation of models executed on different devices (CPU and GPU). To make prototyping easier, PyTorch does not follow the symbolic approach used in many other deep learning frameworks, but focuses on differentiation of purely imperative programs, with a focus on extensibility and low overhead. Note that this preprint is a draft of certain sections from an upcoming paper covering all PyTorch features."
            },
            "slug": "Automatic-differentiation-in-PyTorch-Paszke-Gross",
            "title": {
                "fragments": [],
                "text": "Automatic differentiation in PyTorch"
            },
            "tldr": {
                "abstractSimilarityScore": 66,
                "text": "An automatic differentiation module of PyTorch is described \u2014 a library designed to enable rapid research on machine learning models that focuses on differentiation of purely imperative programs, with a focus on extensibility and low overhead."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726807"
                        ],
                        "name": "Diederik P. Kingma",
                        "slug": "Diederik-P.-Kingma",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Kingma",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik P. Kingma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 118,
                                "start": 114
                            }
                        ],
                        "text": "The architecture distribution parameter \u03b8 is trained on the rest 20% of ImageNet training set with Adam optimizer [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6628106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "isKey": false,
            "numCitedBy": 91740,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm."
            },
            "slug": "Adam:-A-Method-for-Stochastic-Optimization-Kingma-Ba",
            "title": {
                "fragments": [],
                "text": "Adam: A Method for Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work introduces Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments, and provides a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153302678"
                        ],
                        "name": "Jia Deng",
                        "slug": "Jia-Deng",
                        "structuredName": {
                            "firstName": "Jia",
                            "lastName": "Deng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jia Deng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144847596"
                        ],
                        "name": "Wei Dong",
                        "slug": "Wei-Dong",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Dong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Dong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2166511"
                        ],
                        "name": "R. Socher",
                        "slug": "R.-Socher",
                        "structuredName": {
                            "firstName": "Richard",
                            "lastName": "Socher",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Socher"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2040091191"
                        ],
                        "name": "Li-Jia Li",
                        "slug": "Li-Jia-Li",
                        "structuredName": {
                            "firstName": "Li-Jia",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li-Jia Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "94451829"
                        ],
                        "name": "K. Li",
                        "slug": "K.-Li",
                        "structuredName": {
                            "firstName": "K.",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48004138"
                        ],
                        "name": "Li Fei-Fei",
                        "slug": "Li-Fei-Fei",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Fei-Fei",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Fei-Fei"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 133
                            }
                        ],
                        "text": "To demonstrate the efficacy of our proposed method, we use DNAS to search for ConvNet models on ImageNet 2012 classification dataset [2], and we name the discovered models FBNets."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 57246310,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d2c733e34d48784a37d717fe43d9e93277a8c53e",
            "isKey": false,
            "numCitedBy": 28266,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called \u201cImageNet\u201d, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond."
            },
            "slug": "ImageNet:-A-large-scale-hierarchical-image-database-Deng-Dong",
            "title": {
                "fragments": [],
                "text": "ImageNet: A large-scale hierarchical image database"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new database called \u201cImageNet\u201d is introduced, a large-scale ontology of images built upon the backbone of the WordNet structure, much larger in scale and diversity and much more accurate than the current image datasets."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145116380"
                        ],
                        "name": "Eric Jang",
                        "slug": "Eric-Jang",
                        "structuredName": {
                            "firstName": "Eric",
                            "lastName": "Jang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Eric Jang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2046135"
                        ],
                        "name": "S. Gu",
                        "slug": "S.-Gu",
                        "structuredName": {
                            "firstName": "Shixiang",
                            "lastName": "Gu",
                            "middleNames": [
                                "Shane"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Gu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "16443937"
                        ],
                        "name": "Ben Poole",
                        "slug": "Ben-Poole",
                        "structuredName": {
                            "firstName": "Ben",
                            "lastName": "Poole",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ben Poole"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 38
                            }
                        ],
                        "text": "By using the Gumbel Softmax technique [9], we can directly train the architecture distribution using gradient-based optimization such as SGD."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 134
                            }
                        ],
                        "text": "To sidestep this, we relax the discrete mask variable ml,i to be a continuous random variable computed by the Gumbel Softmax function [9, 14]"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 48,
                                "start": 34
                            }
                        ],
                        "text": "To control the temperature of the Gumbel Softmax from equation (8), we use an exponentially decaying temperature."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 103
                            }
                        ],
                        "text": "[25, 1] further develop the idea of differentiable neural architecture search combining Gumbel Softmax [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 37,
                                "start": 23
                            }
                        ],
                        "text": "The technique of using Gumbel Softmax for neural architecture search is also proposed in [25, 1]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 4
                            }
                        ],
                        "text": "The Gumbel Softmax function is controlled by a temperature parameter \u03c4 ."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 110
                            }
                        ],
                        "text": "To sidestep this, we relax the discrete mask variable ml,i to be a continuous random variable computed by the Gumbel Softmax function [9, 14]\nml,i = GumbelSoftmax(\u03b8l,i|\u03b8l)\n= exp[(\u03b8l,i + gl,i)/\u03c4 ]\u2211 i exp[(\u03b8l,i + gl,i)/\u03c4 ] , (8)\nwhere gl,i \u223c Gumbel(0, 1) is a random noise following the Gumbel distribution."
                    },
                    "intents": []
                }
            ],
            "corpusId": 2428314,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "29e944711a354c396fad71936f536e83025b6ce0",
            "isKey": true,
            "numCitedBy": 2766,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Categorical variables are a natural choice for representing discrete structure in the world. However, stochastic neural networks rarely use categorical latent variables due to the inability to backpropagate through samples. In this work, we present an efficient gradient estimator that replaces the non-differentiable sample from a categorical distribution with a differentiable sample from a novel Gumbel-Softmax distribution. This distribution has the essential property that it can be smoothly annealed into a categorical distribution. We show that our Gumbel-Softmax estimator outperforms state-of-the-art gradient estimators on structured output prediction and unsupervised generative modeling tasks with categorical latent variables, and enables large speedups on semi-supervised classification."
            },
            "slug": "Categorical-Reparameterization-with-Gumbel-Softmax-Jang-Gu",
            "title": {
                "fragments": [],
                "text": "Categorical Reparameterization with Gumbel-Softmax"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "It is shown that the Gumbel-Softmax estimator outperforms state-of-the-art gradient estimators on structured output prediction and unsupervised generative modeling tasks with categorical latent variables, and enables large speedups on semi-supervised classification."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2772217"
                        ],
                        "name": "Chris J. Maddison",
                        "slug": "Chris-J.-Maddison",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Maddison",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chris J. Maddison"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1714004"
                        ],
                        "name": "A. Mnih",
                        "slug": "A.-Mnih",
                        "structuredName": {
                            "firstName": "Andriy",
                            "lastName": "Mnih",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Mnih"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1725303"
                        ],
                        "name": "Y. Teh",
                        "slug": "Y.-Teh",
                        "structuredName": {
                            "firstName": "Yee",
                            "lastName": "Teh",
                            "middleNames": [
                                "Whye"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Teh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 141,
                                "start": 134
                            }
                        ],
                        "text": "To sidestep this, we relax the discrete mask variable ml,i to be a continuous random variable computed by the Gumbel Softmax function [9, 14]"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14307651,
            "fieldsOfStudy": [
                "Computer Science",
                "Mathematics"
            ],
            "id": "515a21e90117941150923e559729c59f5fdade1c",
            "isKey": false,
            "numCitedBy": 1627,
            "numCiting": 64,
            "paperAbstract": {
                "fragments": [],
                "text": "The reparameterization trick enables optimizing large scale stochastic computation graphs via gradient descent. The essence of the trick is to refactor each stochastic node into a differentiable function of its parameters and a random variable with fixed distribution. After refactoring, the gradients of the loss propagated by the chain rule through the graph are low variance unbiased estimators of the gradients of the expected loss. While many continuous random variables have such reparameterizations, discrete random variables lack useful reparameterizations due to the discontinuous nature of discrete states. In this work we introduce Concrete random variables---continuous relaxations of discrete random variables. The Concrete distribution is a new family of distributions with closed form densities and a simple reparameterization. Whenever a discrete stochastic node of a computation graph can be refactored into a one-hot bit representation that is treated continuously, Concrete stochastic nodes can be used with automatic differentiation to produce low-variance biased gradients of objectives (including objectives that depend on the log-probability of latent stochastic nodes) on the corresponding discrete graph. We demonstrate the effectiveness of Concrete relaxations on density estimation and structured prediction tasks using neural networks."
            },
            "slug": "The-Concrete-Distribution:-A-Continuous-Relaxation-Maddison-Mnih",
            "title": {
                "fragments": [],
                "text": "The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Concrete random variables---continuous relaxations of discrete random variables is a new family of distributions with closed form densities and a simple reparameterization, and the effectiveness of Concrete relaxations on density estimation and structured prediction tasks using neural networks is demonstrated."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059358552"
                        ],
                        "name": "P. Cochat",
                        "slug": "P.-Cochat",
                        "structuredName": {
                            "firstName": "P.",
                            "lastName": "Cochat",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Cochat"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13267685"
                        ],
                        "name": "L. Vaucoret",
                        "slug": "L.-Vaucoret",
                        "structuredName": {
                            "firstName": "L",
                            "lastName": "Vaucoret",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Vaucoret"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2097644863"
                        ],
                        "name": "J. Sarles",
                        "slug": "J.-Sarles",
                        "structuredName": {
                            "firstName": "J",
                            "lastName": "Sarles",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Sarles"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "Synetgy [28] combines ideas from ShuffleNetV2 and ShiftNet to co-design hardware friendly ConvNets and FPGA accelerators."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 11759366,
            "fieldsOfStudy": [
                "Medicine"
            ],
            "id": "bc6dff14a130c57a91d5a21339c23471faf1d46f",
            "isKey": false,
            "numCitedBy": 58258,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "disasters. Plenum, 2001. 11. Haley R, Thomas L, Hom J. Is there a Gulf War Syndrome? Searching for syndromes by factor analysis of symptoms. JAMA 1997;277:215\u201322. 12. Fukuda K, Nisenbaum R, Stewart G, et al. Chronic multi-symptom illness affecting Air Force veterans of the Gulf War. JAMA 1998;280:981\u20138. 13. Ismail K, Everitt B, Blatchley N, et al. Is there a Gulf War Syndrome? Lancet 1999;353:179\u201382. 14. Shapiro S, Lasarev M, McCauley L. Factor analysis of Gulf War illness: what does it add to our understanding of possible health effects of deployment. Am J Epidemiol 2002;156:578\u201385. 15. Doebbeling B, Clarke W, Watson D, et al. Is there a Persian Gulf War Syndrome? Evidence from a large population-based survey of veterans and nondeployed controls. Am J Med 2000;108:695\u2013704. 16. Knoke J, Smith T, Gray G, et al. Factor analysis of self reported symptoms: Does it identify a Gulf War Syndrome? Am J Epidemiol 2000;152:379\u201388. 17. Kang H, Mahan C, Lee K, et al. Evidence for a deployment-related Gulf War syndrome by factor analysis. Arch Environ Health 2002;57:61\u20138."
            },
            "slug": "Et-al-Cochat-Vaucoret",
            "title": {
                "fragments": [],
                "text": "Et al"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "A large population-based survey of veterans and nondeployed controls found evidence of a deployment-related Gulf War syndrome by factor analysis in Air Force veterans and controls."
            },
            "venue": {
                "fragments": [],
                "text": "Archives de pediatrie : organe officiel de la Societe francaise de pediatrie"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 50
                            }
                        ],
                        "text": "Synetgy [28] combines ideas from ShuffleNetV2 and ShiftNet to co-design hardware friendly ConvNets and FPGA accelerators."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 10
                            }
                        ],
                        "text": "Following [17, 23], we use a hyperparameter, the expansion ratio e, to control"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 69,
                                "start": 65
                            }
                        ],
                        "text": "The block structure is inspired by MobileNetV2 [17] and ShiftNet [23], and is illustrated in Figure 3."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "Following SqueezeNet, SqueezeNext [3] and ShiftNet [23] achieve further parameter size reduction."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Shift: A zero flop"
            },
            "venue": {
                "fragments": [],
                "text": "zero parameter alternative to spatial convolutions. arXiv preprint arXiv:1711.08141"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49012423"
                        ],
                        "name": "P. Alam",
                        "slug": "P.-Alam",
                        "structuredName": {
                            "firstName": "Parvez",
                            "lastName": "Alam",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Alam"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 239595700,
            "fieldsOfStudy": [],
            "id": "cbe020b715b548694bad73e49c5d72854670d6e7",
            "isKey": false,
            "numCitedBy": 29765,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "\u2018L\u2019-Alam",
            "title": {
                "fragments": [],
                "text": "\u2018L\u2019"
            },
            "venue": {
                "fragments": [],
                "text": "Composites Engineering: An A\u2013Z Guide"
            },
            "year": 2021
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 14,
                                "start": 11
                            }
                        ],
                        "text": "SqueezeNet [8] is one of the early works focusing on reducing the parameter size of ConvNet models."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "and K"
            },
            "venue": {
                "fragments": [],
                "text": "Keutzer. Squeezenet: Alexnet-level accuracy with 50x fewer parameters and\u00a1 0.5 mb model size. arXiv preprint arXiv:1602.07360"
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Squeezenet : Alexnet - level accuracy with 50 x fewer parameters and \u00a1 0 . 5 mb model size Categorical reparameterization with gumbel - softmax"
            },
            "venue": {
                "fragments": [],
                "text": "Condensenet : An efficient densenet using learned group convolutions . group"
            }
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 89,
                                "start": 85
                            }
                        ],
                        "text": "It is originally designed for classification, but later extended to object detection [22] and LiDAR point-cloud segmentation [24, 26]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Squeezedet: Unified"
            },
            "venue": {
                "fragments": [],
                "text": "small, low power fully convolutional neural networks for real-time object detection for autonomous driving. In CVPR Workshops, pages 446\u2013454"
            },
            "year": 2017
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 11,
            "methodology": 26,
            "result": 1
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 37,
        "totalPages": 4
    },
    "page_url": "https://www.semanticscholar.org/paper/FBNet:-Hardware-Aware-Efficient-ConvNet-Design-via-Wu-Dai/45532bffbfbb5553da0b2d0844e95a1b37e59147?sort=total-citations"
}