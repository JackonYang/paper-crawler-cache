{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256269"
                        ],
                        "name": "C. Farabet",
                        "slug": "C.-Farabet",
                        "structuredName": {
                            "firstName": "Cl\u00e9ment",
                            "lastName": "Farabet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Farabet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35130633"
                        ],
                        "name": "Cyril Poulet",
                        "slug": "Cyril-Poulet",
                        "structuredName": {
                            "firstName": "Cyril",
                            "lastName": "Poulet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Cyril Poulet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2183554"
                        ],
                        "name": "Jefferson Y. Han",
                        "slug": "Jefferson-Y.-Han",
                        "structuredName": {
                            "firstName": "Jefferson",
                            "lastName": "Han",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jefferson Y. Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 105
                            }
                        ],
                        "text": "It can also perform onthe-fly subsampling (spatial pooling), and simple dotproducts (linear classifiers) [10]"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 78
                            }
                        ],
                        "text": "The pipelined implementation of this 2D convolver was previously described in [10]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5339694,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "07956c7cf9bf4267b86d52aa4143c17a4aa5d0d6",
            "isKey": false,
            "numCitedBy": 328,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional Networks (ConvNets) are biologicallyinspired hierarchical architectures that can be trained to perform a variety of detection, recognition and segmentation tasks. ConvNets have a feed-forward architecture consisting of multiple linear convolution filters interspersed with pointwise non-linear squashing functions. This paper presents an efficient implementation of ConvNets on a low-end DSPoriented Field Programmable Gate Array (FPGA). The implementation exploits the inherent parallelism of ConvNets and takes full advantage of multiple hardware multiplyaccumulate units on the FPGA. The entire system uses a single FPGA with an external memory module, and no extra parts. A network compiler software was implemented, which takes a description of a trained ConvNet and compiles it into a sequence of instructions for the ConvNet Processor (CNP). A ConvNet face detection system was implemented and tested. Face detection on a 512 \u00d7 384 frame takes 100ms (10 frames per second), which corresponds to an average performance of 3.4\u00d7109 connections per second for this 340 million connection network. The design can be used for low-power, lightweight embedded vision systems for micro-UAVs and other small robots."
            },
            "slug": "CNP:-An-FPGA-based-processor-for-Convolutional-Farabet-Poulet",
            "title": {
                "fragments": [],
                "text": "CNP: An FPGA-based processor for Convolutional Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "The implementation exploits the inherent parallelism of ConvNets and takes full advantage of multiple hardware multiplyaccumulate units on the FPGA and can be used for low-power, lightweight embedded vision systems for micro-UAVs and other small robots."
            },
            "venue": {
                "fragments": [],
                "text": "2009 International Conference on Field Programmable Logic and Applications"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144638694"
                        ],
                        "name": "Adam Coates",
                        "slug": "Adam-Coates",
                        "structuredName": {
                            "firstName": "Adam",
                            "lastName": "Coates",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Adam Coates"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3128990"
                        ],
                        "name": "P. Baumstarck",
                        "slug": "P.-Baumstarck",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Baumstarck",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Baumstarck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2827616"
                        ],
                        "name": "Quoc V. Le",
                        "slug": "Quoc-V.-Le",
                        "structuredName": {
                            "firstName": "Quoc",
                            "lastName": "Le",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Quoc V. Le"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34699434"
                        ],
                        "name": "A. Ng",
                        "slug": "A.-Ng",
                        "structuredName": {
                            "firstName": "A.",
                            "lastName": "Ng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Ng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 129
                            }
                        ],
                        "text": "Graphics Processing Units (GPUs) are becoming a common alternative to custom hardware in vision applications, as demonstrated in [4]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1971409,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1828eaa8750ee188111b92deae5c7f67323e723f",
            "isKey": false,
            "numCitedBy": 51,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "We consider the problem of robotic object detection of such objects as mugs, cups, and staplers in indoor environments. While object detection has made significant progress in recent years, many current approaches involve extremely complex algorithms, and are prohibitively slow when applied to large scale robotic settings. In this paper, we describe an object detection system that is designed to scale gracefully to large data sets and leverages upward trends in computational power (as exemplified by Graphics Processing Unit (GPU) technology) and memory. We show that our GPU-based detector is up to 90 times faster than a well-optimized software version and can be easily trained on millions of examples. Using inexpensive off-the-shelf hardware, it can recognize multiple object types reliably in just a few seconds per frame."
            },
            "slug": "Scalable-learning-for-object-detection-with-GPU-Coates-Baumstarck",
            "title": {
                "fragments": [],
                "text": "Scalable learning for object detection with GPU hardware"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper describes an object detection system that is designed to scale gracefully to large data sets and leverages upward trends in computational power (as exemplified by Graphics Processing Unit (GPU) technology) and memory."
            },
            "venue": {
                "fragments": [],
                "text": "2009 IEEE/RSJ International Conference on Intelligent Robots and Systems"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2256269"
                        ],
                        "name": "C. Farabet",
                        "slug": "C.-Farabet",
                        "structuredName": {
                            "firstName": "Cl\u00e9ment",
                            "lastName": "Farabet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Farabet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1940285"
                        ],
                        "name": "B. Martini",
                        "slug": "B.-Martini",
                        "structuredName": {
                            "firstName": "Berin",
                            "lastName": "Martini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Martini"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2447628"
                        ],
                        "name": "Polina Akselrod",
                        "slug": "Polina-Akselrod",
                        "structuredName": {
                            "firstName": "Polina",
                            "lastName": "Akselrod",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Polina Akselrod"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39576799"
                        ],
                        "name": "S. Talay",
                        "slug": "S.-Talay",
                        "structuredName": {
                            "firstName": "Sel\u00e7uk",
                            "lastName": "Talay",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Talay"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2889774"
                        ],
                        "name": "E. Culurciello",
                        "slug": "E.-Culurciello",
                        "structuredName": {
                            "firstName": "Eugenio",
                            "lastName": "Culurciello",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Culurciello"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 110,
                                "start": 107
                            }
                        ],
                        "text": "Figure 1 shows a dataflow architecture that we designed to process homogeneous streams of data in parallel [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6542026,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c3c82b476162d2d006e02180530875a64af18154",
            "isKey": false,
            "numCitedBy": 223,
            "numCiting": 11,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we present a scalable hardware architecture to implement large-scale convolutional neural networks and state-of-the-art multi-layered artificial vision systems. This system is fully digital and is a modular vision engine with the goal of performing real-time detection, recognition and segmentation of mega-pixel images. We present a performance comparison between a software, FPGA and ASIC implementation that shows a speed up in custom hardware implementations."
            },
            "slug": "Hardware-accelerated-convolutional-neural-networks-Farabet-Martini",
            "title": {
                "fragments": [],
                "text": "Hardware accelerated convolutional neural networks for synthetic vision systems"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This system is fully digital and is a modular vision engine with the goal of performing real-time detection, recognition and segmentation of mega-pixel images."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of 2010 IEEE International Symposium on Circuits and Systems"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144153718"
                        ],
                        "name": "H. T. Kung",
                        "slug": "H.-T.-Kung",
                        "structuredName": {
                            "firstName": "H.",
                            "lastName": "Kung",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. T. Kung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 54
                            }
                        ],
                        "text": "Several types of grids have been proposed in the past [8, 14, 17], often trying to solve the dual latency/throughput problem, and often providing a computing fabric that is too rigid."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1858965,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "256bbe8e9fa3f5b72c24f1037ab734f9e7dd01c4",
            "isKey": false,
            "numCitedBy": 2228,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "f High-performance, special-purpose computer systems are typically used to meet specific application requirements or to off-load computations that are especially taxing to general-purpose computers. As hardware cost and size continue to drop and processing requirements become well-understood in areas such as signal and image processing, more special-purpose systems are being constructed. However, since most of these systems are built on an ad hoc basis for specific tasks, methodological work in this area is rare. Because the knowledge gaited from individual experiences is neither accumulated nor properly organized, the same errors are repeated. I/O and computation imbalance is a notable example-often, the fact that I/O interfaces cannot keep up with device speed is discovered only after constructing a high-speed, special-purpose device. We intend to help correct this ad hoc approach by providing a general guideline-specifically, the concept of systolic architecture, a general methodology for mapping high-level computations into hardware structures. In a systolic system, data flows from the computer memcory in a rhythmic fashion, passing through many processing elements before it returns to memory, much as blood circulates to and from the heart. The system works like an autombbile assembly line where different people work on the same car at different times and many cars are assembled simultaneously. An assembly line is always linear, however, and systolic systems are sometimes two-dimensional. They can be rectangular, triangular, or hexagonal to make use of higher degrees of parallelism. Moreover, to implement a variety of computations, data flow in a systolic system may be at multiple speeds in multiple directions-both inputs and (partial) results flow, whereas only results flow in classical pipelined systems. Generally speaking, a systolic system is easy to implement because of its regularity and easy to reconfigure (to meet various outside constraints) because of its modularity. The systolic architectural concept was developed at Carnegie-Mellon University,'17 and versions of systolic processors are being designed and built by several industrial and governmental organizations.840 This article reviews the basic principle of systolic architectures and explains why they should result in cost-effective, highperformance special-purpose systems for a wide range of problems."
            },
            "slug": "Why-systolic-architectures-Kung",
            "title": {
                "fragments": [],
                "text": "Why systolic architectures?"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The basic principle of systolic architectures is reviewed and it is explained why they should result in cost-effective, highperformance special-purpose systems for a wide range of problems."
            },
            "venue": {
                "fragments": [],
                "text": "Computer"
            },
            "year": 1982
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2110033447"
                        ],
                        "name": "Joo-Young Kim",
                        "slug": "Joo-Young-Kim",
                        "structuredName": {
                            "firstName": "Joo-Young",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joo-Young Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2141319767"
                        ],
                        "name": "Minsu Kim",
                        "slug": "Minsu-Kim",
                        "structuredName": {
                            "firstName": "Minsu",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minsu Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47090124"
                        ],
                        "name": "Seungjin Lee",
                        "slug": "Seungjin-Lee",
                        "structuredName": {
                            "firstName": "Seungjin",
                            "lastName": "Lee",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Seungjin Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3216445"
                        ],
                        "name": "Jinwook Oh",
                        "slug": "Jinwook-Oh",
                        "structuredName": {
                            "firstName": "Jinwook",
                            "lastName": "Oh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jinwook Oh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3079378"
                        ],
                        "name": "Kwanho Kim",
                        "slug": "Kwanho-Kim",
                        "structuredName": {
                            "firstName": "Kwanho",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kwanho Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1678901"
                        ],
                        "name": "H. Yoo",
                        "slug": "H.-Yoo",
                        "structuredName": {
                            "firstName": "Hoi-Jun",
                            "lastName": "Yoo",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Yoo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3857871,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a0e781acb1b7511cee9444fcda775855e87cb02",
            "isKey": false,
            "numCitedBy": 126,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "A 201.4 GOPS real-time multi-object recognition processor is presented with a three-stage pipelined architecture. Visual perception based multi-object recognition algorithm is applied to give multiple attentions to multiple objects in the input image. For human-like multi-object perception, a neural perception engine is proposed with biologically inspired neural networks and fuzzy logic circuits. In the proposed hardware architecture, three recognition tasks (visual perception, descriptor generation, and object decision) are directly mapped to the neural perception engine, 16 SIMD processors including 128 processing elements, and decision processor, respectively, and executed in the pipeline to maximize throughput of the object recognition. For efficient task pipelining, proposed task/power manager balances the execution times of the three stages based on intelligent workload estimations. In addition, a 118.4 GB/s multi-casting network-on-chip is proposed for communication architecture with incorporating overall 21 IP blocks. For low-power object recognition, workload-aware dynamic power management is performed in chip-level. The 49 mm2 chip is fabricated in a 0.13 \u00bfm 8-metal CMOS process and contains 3.7 M gates and 396 KB on-chip SRAM. It achieves 60 frame/sec multi-object recognition up to 10 different objects for VGA (640 \u00d7 480) video input while dissipating 496 mW at 1.2 V. The obtained 8.2 mJ/frame energy efficiency is 3.2 times higher than the state-of-the-art recognition processor."
            },
            "slug": "A-201.4-GOPS-496-mW-Real-Time-Multi-Object-With-Kim-Kim",
            "title": {
                "fragments": [],
                "text": "A 201.4 GOPS 496 mW Real-Time Multi-Object Recognition Processor With Bio-Inspired Neural Perception Engine"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "In the proposed hardware architecture, three recognition tasks (visual perception, descriptor generation, and object decision) are directly mapped to the neural perception engine, 16 SIMD processors including 128 processing elements, and decision processor and executed in the pipeline to maximize throughput of the object recognition."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Journal of Solid-State Circuits"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2109828167"
                        ],
                        "name": "Sang Kyun Kim",
                        "slug": "Sang-Kyun-Kim",
                        "structuredName": {
                            "firstName": "Sang",
                            "lastName": "Kim",
                            "middleNames": [
                                "Kyun"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sang Kyun Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "20957879"
                        ],
                        "name": "Lawrence C. McAfee",
                        "slug": "Lawrence-C.-McAfee",
                        "structuredName": {
                            "firstName": "Lawrence",
                            "lastName": "McAfee",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lawrence C. McAfee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2970971"
                        ],
                        "name": "P. McMahon",
                        "slug": "P.-McMahon",
                        "structuredName": {
                            "firstName": "Peter",
                            "lastName": "McMahon",
                            "middleNames": [
                                "Leonard"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. McMahon"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746638"
                        ],
                        "name": "K. Olukotun",
                        "slug": "K.-Olukotun",
                        "structuredName": {
                            "firstName": "Kunle",
                            "lastName": "Olukotun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Olukotun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 132
                            }
                        ],
                        "text": "Other groups are currently working on custom architectures for convolutional networks or similar algorithms: NEC Labs [2], Stanford [16], Kaist [15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18727865,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0b94894ad7d364fced3921d4291ff90feb45b6e7",
            "isKey": false,
            "numCitedBy": 77,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Restricted BoltzmannMachines (RBMs)\u2014 the building block for newly popular Deep Belief Networks (DBNs) \u2014 are a promising new tool for machine learning practitioners. However, future research in applications of DBNs is hampered by the considerable computation that training requires. In this paper, we describe a novel architecture and FPGA implementation that accelerates the training of general RBMs in a scalable manner, with the goal of producing a system that machine learning researchers can use to investigate ever-larger networks. Our design uses a highly efficient, fully-pipelined architecture based on 16-bit arithmetic for performing RBM training on an FPGA. We show that only 16-bit arithmetic precision is necessary, and we consequently use embedded hardware multiply-and-add (MADD) units. We present performance results to show that a speedup of 25\u201330X can be achieved over an optimized software implementation on a high-end CPU."
            },
            "slug": "A-highly-scalable-Restricted-Boltzmann-Machine-FPGA-Kim-McAfee",
            "title": {
                "fragments": [],
                "text": "A highly scalable Restricted Boltzmann Machine FPGA implementation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper describes a novel architecture and FPGA implementation that accelerates the training of general RBMs in a scalable manner, with the goal of producing a system that machine learning researchers can use to investigate ever-larger networks."
            },
            "venue": {
                "fragments": [],
                "text": "2009 International Conference on Field Programmable Logic and Applications"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1752242"
                        ],
                        "name": "S. Chakradhar",
                        "slug": "S.-Chakradhar",
                        "structuredName": {
                            "firstName": "Srimat",
                            "lastName": "Chakradhar",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Chakradhar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2329060"
                        ],
                        "name": "M. Sankaradass",
                        "slug": "M.-Sankaradass",
                        "structuredName": {
                            "firstName": "Murugan",
                            "lastName": "Sankaradass",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Sankaradass"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2101580"
                        ],
                        "name": "V. Jakkula",
                        "slug": "V.-Jakkula",
                        "structuredName": {
                            "firstName": "Venkata",
                            "lastName": "Jakkula",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "V. Jakkula"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2468150"
                        ],
                        "name": "S. Cadambi",
                        "slug": "S.-Cadambi",
                        "structuredName": {
                            "firstName": "Srihari",
                            "lastName": "Cadambi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Cadambi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 118
                            }
                        ],
                        "text": "Other groups are currently working on custom architectures for convolutional networks or similar algorithms: NEC Labs [2], Stanford [16], Kaist [15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3350152,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e1c4e2fa071046569a05e9cfdf13496d094025dd",
            "isKey": false,
            "numCitedBy": 350,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional neural networks (CNN) applications range from recognition and reasoning (such as handwriting recognition, facial expression recognition and video surveillance) to intelligent text applications such as semantic text analysis and natural language processing applications. Two key observations drive the design of a new architecture for CNN. First, CNN workloads exhibit a widely varying mix of three types of parallelism: parallelism within a convolution operation, intra-output parallelism where multiple input sources (features) are combined to create a single output, and inter-output parallelism where multiple, independent outputs (features) are computed simultaneously. Workloads differ significantly across different CNN applications, and across different layers of a CNN. Second, the number of processing elements in an architecture continues to scale (as per Moore's law) much faster than off-chip memory bandwidth (or pin-count) of chips. Based on these two observations, we show that for a given number of processing elements and off-chip memory bandwidth, a new CNN hardware architecture that dynamically configures the hardware on-the-fly to match the specific mix of parallelism in a given workload gives the best throughput performance. Our CNN compiler automatically translates high abstraction network specification into a parallel microprogram (a sequence of low-level VLIW instructions) that is mapped, scheduled and executed by the coprocessor. Compared to a 2.3 GHz quad-core, dual socket Intel Xeon, 1.35 GHz C870 GPU, and a 200 MHz FPGA implementation, our 120 MHz dynamically configurable architecture is 4x to 8x faster. This is the first CNN architecture to achieve real-time video stream processing (25 to 30 frames per second) on a wide range of object detection and recognition tasks."
            },
            "slug": "A-dynamically-configurable-coprocessor-for-neural-Chakradhar-Sankaradass",
            "title": {
                "fragments": [],
                "text": "A dynamically configurable coprocessor for convolutional neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This is the first CNN architecture to achieve real-time video stream processing (25 to 30 frames per second) on a wide range of object detection and recognition tasks."
            },
            "venue": {
                "fragments": [],
                "text": "ISCA"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690704"
                        ],
                        "name": "Edward A. Lee",
                        "slug": "Edward-A.-Lee",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Lee",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Edward A. Lee"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815712"
                        ],
                        "name": "D. Messerschmitt",
                        "slug": "D.-Messerschmitt",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Messerschmitt",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Messerschmitt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 111
                            }
                        ],
                        "text": "org/category/xlearn/ Extensive research has been done on the question of how to schedule dataflow computations [22], and how to represent streams and computations on streams [18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9981963,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "840546d540c4f090851c426fe823dc5b655002f9",
            "isKey": false,
            "numCitedBy": 1427,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "Large grain data flow (LGDF) programming is natural and convenient for describing digital signal processing (DSP) systems, but its runtime overhead is costly in real time or cost-sensitive applications. In some situations, designers are not willing to squander computing resources for the sake of programmer convenience. This is particularly true when the target machine is a programmable DSP chip. However, the runtime overhead inherent in most LGDF implementations is not required for most signal processing systems because such systems are mostly synchronous (in the DSP sense). Synchronous data flow (SDF) differs from traditional data flow in that the amount of data produced and consumed by a data flow node is specified a priori for each input and output. This is equivalent to specifying the relative sample rates in signal processing system. This means that the scheduling of SDF nodes need not be done at runtime, but can be done at compile time (statically), so the runtime overhead evaporates. The sample rates can all be different, which is not true of most current data-driven digital signal processing programming methodologies. Synchronous data flow is closely related to computation graphs, a special case of Petri nets. This self-contained paper develops the theory necessary to statically schedule SDF programs on single or multiple processors. A class of static (compile time) scheduling algorithms is proven valid, and specific algorithms are given for scheduling SDF systems onto single or multiple processors."
            },
            "slug": "Static-Scheduling-of-Synchronous-Data-Flow-Programs-Lee-Messerschmitt",
            "title": {
                "fragments": [],
                "text": "Static Scheduling of Synchronous Data Flow Programs for Digital Signal Processing"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This self-contained paper develops the theory necessary to statically schedule SDF programs on single or multiple processors, and a class of static (compile time) scheduling algorithms is proven valid, and specific algorithms are given for scheduling SDF systems onto single ormultiple processors."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Computers"
            },
            "year": 1987
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34644975"
                        ],
                        "name": "J. Dennis",
                        "slug": "J.-Dennis",
                        "structuredName": {
                            "firstName": "Jack",
                            "lastName": "Dennis",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Dennis"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2227315"
                        ],
                        "name": "David Misunas",
                        "slug": "David-Misunas",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Misunas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Misunas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 65,
                                "start": 54
                            }
                        ],
                        "text": "Several types of grids have been proposed in the past [8, 14, 17], often trying to solve the dual latency/throughput problem, and often providing a computing fabric that is too rigid."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 100
                            }
                        ],
                        "text": "First dataflow architectures were introduced by [1], and quickly became an active field of research [8, 14, 18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 3245749,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3046dfe3c1fa75108bddc75c1f11c55ece818a0e",
            "isKey": false,
            "numCitedBy": 273,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "A processor is described which can achieve highly parallel execution of programs represented in data-flow form. The language implemented incorporates conditional and iteration mechanisms, and the processor is a step toward a practical data-flow processor for a Fortran-level data-flow language. The processor has a unique architecture which avoids the problems of processor switching and memory/processor interconnecion that usually limit the degree of realizable concurrent processing. The architecture offers an unusual solution to the problem of structuring and managing a two-level memory system."
            },
            "slug": "A-preliminary-architecture-for-a-basic-data-flow-Dennis-Misunas",
            "title": {
                "fragments": [],
                "text": "A preliminary architecture for a basic data-flow processor"
            },
            "tldr": {
                "abstractSimilarityScore": 62,
                "text": "A processor is described which can achieve highly parallel execution of programs represented in data-flow form and has a unique architecture which avoids the problems of processor switching and memory/processor interconnecion that usually limit the degree of realizable concurrent processing."
            },
            "venue": {
                "fragments": [],
                "text": "ISCA '75"
            },
            "year": 1974
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144910704"
                        ],
                        "name": "Myong Hyon Cho",
                        "slug": "Myong-Hyon-Cho",
                        "structuredName": {
                            "firstName": "Myong",
                            "lastName": "Cho",
                            "middleNames": [
                                "Hyon"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Myong Hyon Cho"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2099588"
                        ],
                        "name": "Chih-Chi Cheng",
                        "slug": "Chih-Chi-Cheng",
                        "structuredName": {
                            "firstName": "Chih-Chi",
                            "lastName": "Cheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Chih-Chi Cheng"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726383"
                        ],
                        "name": "M. Kinsy",
                        "slug": "M.-Kinsy",
                        "structuredName": {
                            "firstName": "Michel",
                            "lastName": "Kinsy",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Kinsy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145691878"
                        ],
                        "name": "G. Suh",
                        "slug": "G.-Suh",
                        "structuredName": {
                            "firstName": "G.",
                            "lastName": "Suh",
                            "middleNames": [
                                "Edward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Suh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695217"
                        ],
                        "name": "S. Devadas",
                        "slug": "S.-Devadas",
                        "structuredName": {
                            "firstName": "Srinivas",
                            "lastName": "Devadas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Devadas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "Layer Kernels: dims [nb] Maps: dims [nb] Input image 32\u00d7 32 [3] N0 (Norm) 32\u00d7 32 [3] C1 (Conv) 5\u00d7 5 [48] 28\u00d7 28 [12] P2 (Pool) 2\u00d7 2 [1] 14\u00d7 14 [12] C3 (Conv) 5\u00d7 5 [384] 10\u00d7 10 [32] P4 (Pool) 2\u00d7 2 [1] 5\u00d7 5 [32] C5 (Conv) 5\u00d7 5 [1536] 1\u00d7 1 [48] L (Linear) 1\u00d7 1 [960] 1\u00d7 1 [20] Table 1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "Layer Kernels: dims [nb] Maps: dims [nb] Input image 60\u00d7 60 [3] N0 (Norm) 60\u00d7 60 [3] C1 (Conv) 9\u00d7 9 [48] 52\u00d7 52 [12] P2 (Pool) 2\u00d7 2 [1] 26\u00d7 26 [12] C3 (Conv) 9\u00d7 9 [384] 18\u00d7 18 [32] P4 (Pool) 2\u00d7 2 [1] 9\u00d7 9 [32] C5 (Conv) 9\u00d7 9 [1536] 1\u00d7 1 [48] L (Linear) 1\u00d7 1 [960] 1\u00d7 1 [20] Table 2."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 3,
                                "start": 0
                            }
                        ],
                        "text": "[3] presents one of the latest dataflow architectures that shares several similarities to the approach presented here: while both architectures rely on a grid of compute tiles, which communicate via FIFOs, the grid presented here also provides a runtime configuration bus, which allows efficient runtime reconfiguration of the hardware (as opposed to static, offline synthesis)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 63,
                                "start": 60
                            }
                        ],
                        "text": "Layer Kernels: dims [nb] Maps: dims [nb] Input image 92\u00d7 92 [3] N0 (Norm) 92\u00d7 92 [3] C1 (Conv) 9\u00d7 9 [48] 84\u00d7 84 [12] P2 (Pool) 2\u00d7 2 [1] 42\u00d7 42 [12] C3 (Conv) 9\u00d7 9 [384] 34\u00d7 34 [32] P4 (Pool) 2\u00d7 2 [1] 17\u00d7 17 [32] C5 (Conv) 9\u00d7 9 [1536] 9\u00d7 9 [48] C6 (Conv) 9\u00d7 9 [1024] 1\u00d7 1 [128] L (Linear) 1\u00d7 1 [960] 1\u00d7 1 [20] Table 3."
                    },
                    "intents": []
                }
            ],
            "corpusId": 593092,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "af4deb53428742bce2971bdbe63bb4d10af2f254",
            "isKey": true,
            "numCitedBy": 10,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "Diastolic arrays are arrays of processing elements that communicate exclusively through First-In First-Out (FIFO) queues. FIFO virtualization units enable relaxed timing of data transfers, and include hardware support to guarantee bandwidth and buffer space for all data transfers, which may follow composite paths through the network. We show that the architecture of diastolic arrays enables efficient synthesis from high-level specifications of communicating finite state machines so average throughput is maximized. Preliminary results are presented on an H.264 decoding benchmark."
            },
            "slug": "Diastolic-arrays:-Throughput-driven-reconfigurable-Cho-Cheng",
            "title": {
                "fragments": [],
                "text": "Diastolic arrays: Throughput-driven reconfigurable computing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "It is shown that the architecture of diastolic arrays enables efficient synthesis from high-level specifications of communicating finite state machines so average throughput is maximized."
            },
            "venue": {
                "fragments": [],
                "text": "2008 IEEE/ACM International Conference on Computer-Aided Design"
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065453750"
                        ],
                        "name": "James E. Hicks",
                        "slug": "James-E.-Hicks",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Hicks",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James E. Hicks"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2000338"
                        ],
                        "name": "Derek Chiou",
                        "slug": "Derek-Chiou",
                        "structuredName": {
                            "firstName": "Derek",
                            "lastName": "Chiou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Derek Chiou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35042850"
                        ],
                        "name": "B. S. Ang",
                        "slug": "B.-S.-Ang",
                        "structuredName": {
                            "firstName": "Boon",
                            "lastName": "Ang",
                            "middleNames": [
                                "Seong"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. S. Ang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3285866"
                        ],
                        "name": "Arvind",
                        "slug": "Arvind",
                        "structuredName": {
                            "firstName": "",
                            "lastName": "Arvind",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Arvind"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 45065961,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "ec363bc062d612b564116d0a801e418f1836d30d",
            "isKey": false,
            "numCitedBy": 66,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract In this paper, we examine the performance of Id, an implicitly parallel language, on Monsoon, an experimental dataflow machine. One of the precepts of our work is that the Id run-time system and compiled Id programs should run on any number of Monsoon processors without change. Our experiments running Id programs on Monsoon show that speedups of more than 7 are easily achieved on 8 processors for most of the applications that we studied. We explain the sources of overhead that limit the speedup of each of our benchmark programs. We also compare the performance of Id on a single Monsoon processor with C/Fortran on a DEC Station 5000 (MIPS R3000 processor), to establish a baseline for the efficiency of Id execution on Monsoon. We find that the execution of Id programs on one Monsoon processor takes up to three times as many cycles as the corresponding C or Fortran programs executing on a MIPS R3000 processor. We identify the sources of inefficiency on Monsoon and suggest improvements, where possible. In many cases, however, improving single processor performance will reduce parallel processor performance."
            },
            "slug": "Performance-Studies-of-Id-on-the-Monsoon-Dataflow-Hicks-Chiou",
            "title": {
                "fragments": [],
                "text": "Performance Studies of Id on the Monsoon Dataflow System"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "The performance of Id, an implicitly parallel language, on Monsoon, an experimental dataflow machine, is examined, finding that the execution of Id programs on one Monsoon processor takes up to three times as many cycles as the corresponding C or Fortran programs executing on a MIPS R3000 processor."
            },
            "venue": {
                "fragments": [],
                "text": "J. Parallel Distributed Comput."
            },
            "year": 1993
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2243801"
                        ],
                        "name": "Jim Mutch",
                        "slug": "Jim-Mutch",
                        "structuredName": {
                            "firstName": "Jim",
                            "lastName": "Mutch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jim Mutch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35238678"
                        ],
                        "name": "D. Lowe",
                        "slug": "D.-Lowe",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Lowe",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Lowe"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 35
                            }
                        ],
                        "text": "Other models like HMAX-type models [27, 24] and convolutional networks use two or more layers of successive feature extractors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1427294,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f9e65fcb0e04174577f211d702d3f837e3624c5b",
            "isKey": false,
            "numCitedBy": 548,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We apply a biologically inspired model of visual object recognition to the multiclass object categorization problem. Our model modifies that of Serre, Wolf, and Poggio. As in that work, we first apply Gabor filters at all positions and scales; feature complexity and position/scale invariance are then built up by alternating template matching and max pooling operations. We refine the approach in several biologically plausible ways, using simple versions of sparsification and lateral inhibition. We demonstrate the value of retaining some position and scale information above the intermediate feature level. Using feature selection we arrive at a model that performs better with fewer features. Our final model is tested on the Caltech 101 object categories and the UIUC car localization task, in both cases achieving state-of-the-art performance. The results strengthen the case for using this class of model in computer vision."
            },
            "slug": "Multiclass-Object-Recognition-with-Sparse,-Features-Mutch-Lowe",
            "title": {
                "fragments": [],
                "text": "Multiclass Object Recognition with Sparse, Localized Features"
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "A biologically inspired model of visual object recognition to the multiclass object categorization problem, modifies that of Serre, Wolf, and Poggio, and demonstrates the value of retaining some position and scale information above the intermediate feature level."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "30017846"
                        ],
                        "name": "N. Pinto",
                        "slug": "N.-Pinto",
                        "structuredName": {
                            "firstName": "Nicolas",
                            "lastName": "Pinto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Pinto"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2042941"
                        ],
                        "name": "D. Cox",
                        "slug": "D.-Cox",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Cox",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Cox"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1865831"
                        ],
                        "name": "J. DiCarlo",
                        "slug": "J.-DiCarlo",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "DiCarlo",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. DiCarlo"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 66
                            }
                        ],
                        "text": "Some recognition systems use a single stage of feature extractors [19, 7, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 5955557,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "688b6fbc3c5c06e254961f70de9d855d3d008d09",
            "isKey": false,
            "numCitedBy": 586,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "Progress in understanding the brain mechanisms underlying vision requires the construction of computational models that not only emulate the brain's anatomy and physiology, but ultimately match its performance on visual tasks. In recent years, \u201cnatural\u201d images have become popular in the study of vision and have been used to show apparently impressive progress in building such models. Here, we challenge the use of uncontrolled \u201cnatural\u201d images in guiding that progress. In particular, we show that a simple V1-like model\u2014a neuroscientist's \u201cnull\u201d model, which should perform poorly at real-world visual object recognition tasks\u2014outperforms state-of-the-art object recognition systems (biologically inspired and otherwise) on a standard, ostensibly natural image recognition test. As a counterpoint, we designed a \u201csimpler\u201d recognition test to better span the real-world variation in object pose, position, and scale, and we show that this test correctly exposes the inadequacy of the V1-like model. Taken together, these results demonstrate that tests based on uncontrolled natural images can be seriously misleading, potentially guiding progress in the wrong direction. Instead, we reexamine what it means for images to be natural and argue for a renewed focus on the core problem of object recognition\u2014real-world image variation."
            },
            "slug": "Why-is-Real-World-Visual-Object-Recognition-Hard-Pinto-Cox",
            "title": {
                "fragments": [],
                "text": "Why is Real-World Visual Object Recognition Hard?"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown that a simple V1-like model\u2014a neuroscientist's \u201cnull\u201d model\u2014outperforms state-of-the-art object recognition systems (biologically inspired and otherwise) on a standard, ostensibly natural image recognition test."
            },
            "venue": {
                "fragments": [],
                "text": "PLoS Comput. Biol."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "13919023"
                        ],
                        "name": "F. Huang",
                        "slug": "F.-Huang",
                        "structuredName": {
                            "firstName": "Fu",
                            "lastName": "Huang",
                            "middleNames": [
                                "Jie"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 26
                            }
                        ],
                        "text": "Multiple object detection [21] or online learning for adaptive robot guidance [13] are tasks that are currently being developed around neuFlow, using and extending the convolutional network framework."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 712708,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f354310098e09c1e1dc88758fca36767fd9d084d",
            "isKey": false,
            "numCitedBy": 1321,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "We assess the applicability of several popular learning methods for the problem of recognizing generic visual categories with invariance to pose, lighting, and surrounding clutter. A large dataset comprising stereo image pairs of 50 uniform-colored toys under 36 azimuths, 9 elevations, and 6 lighting conditions was collected (for a total of 194,400 individual images). The objects were 10 instances of 5 generic categories: four-legged animals, human figures, airplanes, trucks, and cars. Five instances of each category were used for training, and the other five for testing. Low-resolution grayscale images of the objects with various amounts of variability and surrounding clutter were used for training and testing. Nearest neighbor methods, support vector machines, and convolutional networks, operating on raw pixels or on PCA-derived features were tested. Test error rates for unseen object instances placed on uniform backgrounds were around 13% for SVM and 7% for convolutional nets. On a segmentation/recognition task with highly cluttered images, SVM proved impractical, while convolutional nets yielded 16/7% error. A real-time version of the system was implemented that can detect and classify objects in natural scenes at around 10 frames per second."
            },
            "slug": "Learning-methods-for-generic-object-recognition-to-LeCun-Huang",
            "title": {
                "fragments": [],
                "text": "Learning methods for generic object recognition with invariance to pose and lighting"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "A real-time version of the system was implemented that can detect and classify objects in natural scenes at around 10 frames per second and proved impractical, while convolutional nets yielded 16/7% error."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004."
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1749609"
                        ],
                        "name": "S. Lazebnik",
                        "slug": "S.-Lazebnik",
                        "structuredName": {
                            "firstName": "Svetlana",
                            "lastName": "Lazebnik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Lazebnik"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2462253"
                        ],
                        "name": "C. Schmid",
                        "slug": "C.-Schmid",
                        "structuredName": {
                            "firstName": "Cordelia",
                            "lastName": "Schmid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Schmid"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144189388"
                        ],
                        "name": "J. Ponce",
                        "slug": "J.-Ponce",
                        "structuredName": {
                            "firstName": "Jean",
                            "lastName": "Ponce",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ponce"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 66
                            }
                        ],
                        "text": "Some recognition systems use a single stage of feature extractors [19, 7, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2421251,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6dbaff29d3898cf60f63f5a34cb9610ebb75220c",
            "isKey": false,
            "numCitedBy": 8359,
            "numCiting": 38,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence. This technique works by partitioning the image into increasingly fine sub-regions and computing histograms of local features found inside each sub-region. The resulting \"spatial pyramid\" is a simple and computationally efficient extension of an orderless bag-of-features image representation, and it shows significantly improved performance on challenging scene categorization tasks. Specifically, our proposed method exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories. The spatial pyramid framework also offers insights into the success of several recently proposed image descriptions, including Torralba\u2019s \"gist\" and Lowe\u2019s SIFT descriptors."
            },
            "slug": "Beyond-Bags-of-Features:-Spatial-Pyramid-Matching-Lazebnik-Schmid",
            "title": {
                "fragments": [],
                "text": "Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories"
            },
            "tldr": {
                "abstractSimilarityScore": 67,
                "text": "This paper presents a method for recognizing scene categories based on approximate global geometric correspondence that exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories."
            },
            "venue": {
                "fragments": [],
                "text": "2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1981539"
                        ],
                        "name": "Thomas Serre",
                        "slug": "Thomas-Serre",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Serre",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Thomas Serre"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145128145"
                        ],
                        "name": "Lior Wolf",
                        "slug": "Lior-Wolf",
                        "structuredName": {
                            "firstName": "Lior",
                            "lastName": "Wolf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lior Wolf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685292"
                        ],
                        "name": "T. Poggio",
                        "slug": "T.-Poggio",
                        "structuredName": {
                            "firstName": "Tomaso",
                            "lastName": "Poggio",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Poggio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 35
                            }
                        ],
                        "text": "Other models like HMAX-type models [27, 24] and convolutional networks use two or more layers of successive feature extractors."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 260426,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "040c23e5a409fbdedd5032263dfcb1a4d7dfd200",
            "isKey": false,
            "numCitedBy": 970,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a novel set of features for robust object recognition. Each element of this set is a complex feature obtained by combining position- and scale-tolerant edge-detectors over neighboring positions and multiple orientations. Our system's architecture is motivated by a quantitative model of visual cortex. We show that our approach exhibits excellent recognition performance and outperforms several state-of-the-art systems on a variety of image datasets including many different object categories. We also demonstrate that our system is able to learn from very few examples. The performance of the approach constitutes a suggestive plausibility proof for a class of feedforward models of object recognition in cortex."
            },
            "slug": "Object-recognition-with-features-inspired-by-visual-Serre-Wolf",
            "title": {
                "fragments": [],
                "text": "Object recognition with features inspired by visual cortex"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The performance of the approach constitutes a suggestive plausibility proof for a class of feedforward models of object recognition in cortex and exhibits excellent recognition performance and outperforms several state-of-the-art systems on a variety of image datasets including many different object categories."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2315504"
                        ],
                        "name": "R. Hadsell",
                        "slug": "R.-Hadsell",
                        "structuredName": {
                            "firstName": "Raia",
                            "lastName": "Hadsell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Hadsell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3142556"
                        ],
                        "name": "Pierre Sermanet",
                        "slug": "Pierre-Sermanet",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Sermanet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierre Sermanet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144050629"
                        ],
                        "name": "J. Ben",
                        "slug": "J.-Ben",
                        "structuredName": {
                            "firstName": "Jan",
                            "lastName": "Ben",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Ben"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1767093"
                        ],
                        "name": "A. Erkan",
                        "slug": "A.-Erkan",
                        "structuredName": {
                            "firstName": "Ayse",
                            "lastName": "Erkan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Erkan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2085624"
                        ],
                        "name": "Marco Scoffier",
                        "slug": "Marco-Scoffier",
                        "structuredName": {
                            "firstName": "Marco",
                            "lastName": "Scoffier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marco Scoffier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2645384"
                        ],
                        "name": "K. Kavukcuoglu",
                        "slug": "K.-Kavukcuoglu",
                        "structuredName": {
                            "firstName": "Koray",
                            "lastName": "Kavukcuoglu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Kavukcuoglu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145636949"
                        ],
                        "name": "Urs Muller",
                        "slug": "Urs-Muller",
                        "structuredName": {
                            "firstName": "Urs",
                            "lastName": "Muller",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Urs Muller"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 78
                            }
                        ],
                        "text": "Multiple object detection [21] or online learning for adaptive robot guidance [13] are tasks that are currently being developed around neuFlow, using and extending the convolutional network framework."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 5277920,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d8f527d1a96b0dae209daa6a241cf3255a6ec0d",
            "isKey": false,
            "numCitedBy": 227,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Most vision\u2010based approaches to mobile robotics suffer from the limitations imposed by stereo obstacle detection, which is short range and prone to failure. We present a self\u2010supervised learning process for long\u2010range vision that is able to accurately classify complex terrain at distances up to the horizon, thus allowing superior strategic planning. The success of the learning process is due to the self\u2010supervised training data that are generated on every frame: robust, visually consistent labels from a stereo module; normalized wide\u2010context input windows; and a discriminative and concise feature representation. A deep hierarchical network is trained to extract informative and meaningful features from an input image, and the features are used to train a real\u2010time classifier to predict traversability. The trained classifier sees obstacles and paths from 5 to more than 100 m, far beyond the maximum stereo range of 12 m, and adapts very quickly to new environments. The process was developed and tested on the LAGR (Learning Applied to Ground Robots) mobile robot. Results from a ground truth data set, as well as field test results, are given. \u00a9 2009 Wiley Periodicals, Inc."
            },
            "slug": "Learning-long\u2010range-vision-for-autonomous-off\u2010road-Hadsell-Sermanet",
            "title": {
                "fragments": [],
                "text": "Learning long\u2010range vision for autonomous off\u2010road driving"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This work presents a self\u2010supervised learning process for long\u2010range vision that is able to accurately classify complex terrain at distances up to the horizon, thus allowing superior strategic planning."
            },
            "venue": {
                "fragments": [],
                "text": "J. Field Robotics"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48950628"
                        ],
                        "name": "N. Dalal",
                        "slug": "N.-Dalal",
                        "structuredName": {
                            "firstName": "Navneet",
                            "lastName": "Dalal",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Dalal"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1756114"
                        ],
                        "name": "B. Triggs",
                        "slug": "B.-Triggs",
                        "structuredName": {
                            "firstName": "Bill",
                            "lastName": "Triggs",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Triggs"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 66
                            }
                        ],
                        "text": "Some recognition systems use a single stage of feature extractors [19, 7, 25]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206590483,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cec734d7097ab6b1e60d95228ffd64248eb89d66",
            "isKey": false,
            "numCitedBy": 29465,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds."
            },
            "slug": "Histograms-of-oriented-gradients-for-human-Dalal-Triggs",
            "title": {
                "fragments": [],
                "text": "Histograms of oriented gradients for human detection"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "It is shown experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection, and the influence of each stage of the computation on performance is studied."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1735300"
                        ],
                        "name": "S. Haykin",
                        "slug": "S.-Haykin",
                        "structuredName": {
                            "firstName": "Simon",
                            "lastName": "Haykin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Haykin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1713858"
                        ],
                        "name": "B. Kosko",
                        "slug": "B.-Kosko",
                        "structuredName": {
                            "firstName": "Bart",
                            "lastName": "Kosko",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Kosko"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 96
                            }
                        ],
                        "text": "First: we started with a simple model, CN1 (table 1), similar to the one originally proposed in [20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 273,
                                "start": 269
                            }
                        ],
                        "text": "Layer Kernels: dims [nb] Maps: dims [nb] Input image 32\u00d7 32 [3] N0 (Norm) 32\u00d7 32 [3] C1 (Conv) 5\u00d7 5 [48] 28\u00d7 28 [12] P2 (Pool) 2\u00d7 2 [1] 14\u00d7 14 [12] C3 (Conv) 5\u00d7 5 [384] 10\u00d7 10 [32] P4 (Pool) 2\u00d7 2 [1] 5\u00d7 5 [32] C5 (Conv) 5\u00d7 5 [1536] 1\u00d7 1 [48] L (Linear) 1\u00d7 1 [960] 1\u00d7 1 [20] Table 1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 273,
                                "start": 269
                            }
                        ],
                        "text": "Layer Kernels: dims [nb] Maps: dims [nb] Input image 60\u00d7 60 [3] N0 (Norm) 60\u00d7 60 [3] C1 (Conv) 9\u00d7 9 [48] 52\u00d7 52 [12] P2 (Pool) 2\u00d7 2 [1] 26\u00d7 26 [12] C3 (Conv) 9\u00d7 9 [384] 18\u00d7 18 [32] P4 (Pool) 2\u00d7 2 [1] 9\u00d7 9 [32] C5 (Conv) 9\u00d7 9 [1536] 1\u00d7 1 [48] L (Linear) 1\u00d7 1 [960] 1\u00d7 1 [20] Table 2."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 308,
                                "start": 304
                            }
                        ],
                        "text": "Layer Kernels: dims [nb] Maps: dims [nb] Input image 92\u00d7 92 [3] N0 (Norm) 92\u00d7 92 [3] C1 (Conv) 9\u00d7 9 [48] 84\u00d7 84 [12] P2 (Pool) 2\u00d7 2 [1] 42\u00d7 42 [12] C3 (Conv) 9\u00d7 9 [384] 34\u00d7 34 [32] P4 (Pool) 2\u00d7 2 [1] 17\u00d7 17 [32] C5 (Conv) 9\u00d7 9 [1536] 9\u00d7 9 [48] C6 (Conv) 9\u00d7 9 [1024] 1\u00d7 1 [128] L (Linear) 1\u00d7 1 [960] 1\u00d7 1 [20] Table 3."
                    },
                    "intents": []
                }
            ],
            "corpusId": 64294544,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f42b865e20e61a954239f421b42007236e671f19",
            "isKey": true,
            "numCitedBy": 3561,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer Neural Networks trained with the backpropagation algorithm constitute the best example of a successful Gradient-Based Learning technique. Given an appropriate network architecture, Gradient-Based Learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional Neural Networks, that are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation, recognition, and language modeling. A new learning paradigm, called Graph Transformer Networks (GTN), allows such multi-module systems to be trained globally using Gradient-Based methods so as to minimize an overall performance measure. Two systems for on-line handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of Graph Transformer Networks. A Graph Transformer Network for reading bank check is also described. It uses Convolutional Neural Network character recognizers combined with global training techniques to provides record accuracy on business and personal checks. It is deployed commercially and reads several million checks per day."
            },
            "slug": "GradientBased-Learning-Applied-to-Document-Haykin-Kosko",
            "title": {
                "fragments": [],
                "text": "GradientBased Learning Applied to Document Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Various methods applied to handwritten character recognition are reviewed and compared and Convolutional Neural Networks, that are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1721248"
                        ],
                        "name": "P. Haffner",
                        "slug": "P.-Haffner",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Haffner",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Haffner"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "First: we started with a simple model, CN1 (table 1), similar to the one originally proposed in [20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Layer Kernels: dims [nb] Maps: dims [nb] Input image 32\u00d7 32 [3] N0 (Norm) 32\u00d7 32 [3] C1 (Conv) 5\u00d7 5 [48] 28\u00d7 28 [12] P2 (Pool) 2\u00d7 2 [1] 14\u00d7 14 [12] C3 (Conv) 5\u00d7 5 [384] 10\u00d7 10 [32] P4 (Pool) 2\u00d7 2 [1] 5\u00d7 5 [32] C5 (Conv) 5\u00d7 5 [1536] 1\u00d7 1 [48] L (Linear) 1\u00d7 1 [960] 1\u00d7 1 [20] Table 1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [],
                        "text": "Layer Kernels: dims [nb] Maps: dims [nb] Input image 92\u00d7 92 [3] N0 (Norm) 92\u00d7 92 [3] C1 (Conv) 9\u00d7 9 [48] 84\u00d7 84 [12] P2 (Pool) 2\u00d7 2 [1] 42\u00d7 42 [12] C3 (Conv) 9\u00d7 9 [384] 34\u00d7 34 [32] P4 (Pool) 2\u00d7 2 [1] 17\u00d7 17 [32] C5 (Conv) 9\u00d7 9 [1536] 9\u00d7 9 [48] C6 (Conv) 9\u00d7 9 [1024] 1\u00d7 1 [128] L (Linear) 1\u00d7 1 [960] 1\u00d7 1 [20] Table 3."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14542261,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "162d958ff885f1462aeda91cd72582323fd6a1f4",
            "isKey": false,
            "numCitedBy": 35623,
            "numCiting": 246,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day."
            },
            "slug": "Gradient-based-learning-applied-to-document-LeCun-Bottou",
            "title": {
                "fragments": [],
                "text": "Gradient-based learning applied to document recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task, and Convolutional neural networks are shown to outperform all other techniques."
            },
            "venue": {
                "fragments": [],
                "text": "Proc. IEEE"
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2529182"
                        ],
                        "name": "David Grangier",
                        "slug": "David-Grangier",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Grangier",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "David Grangier"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52184096"
                        ],
                        "name": "L. Bottou",
                        "slug": "L.-Bottou",
                        "structuredName": {
                            "firstName": "L\u00e9on",
                            "lastName": "Bottou",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Bottou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2939803"
                        ],
                        "name": "Ronan Collobert",
                        "slug": "Ronan-Collobert",
                        "structuredName": {
                            "firstName": "Ronan",
                            "lastName": "Collobert",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ronan Collobert"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 112
                            }
                        ],
                        "text": "Layer Kernels: dims [nb] Maps: dims [nb] Input image 92\u00d7 92 [3] N0 (Norm) 92\u00d7 92 [3] C1 (Conv) 9\u00d7 9 [48] 84\u00d7 84 [12] P2 (Pool) 2\u00d7 2 [1] 42\u00d7 42 [12] C3 (Conv) 9\u00d7 9 [384] 34\u00d7 34 [32] P4 (Pool) 2\u00d7 2 [1] 17\u00d7 17 [32] C5 (Conv) 9\u00d7 9 [1536] 9\u00d7 9 [48] C6 (Conv) 9\u00d7 9 [1024] 1\u00d7 1 [128] L (Linear) 1\u00d7 1 [960] 1\u00d7 1 [20] Table 3."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[12] showed that using a deep convolutional network with a greedy layer-wise learning (up to 6 convolutional layers) could yield significantly better results than simpler 2 or 3-layer systems."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 112
                            }
                        ],
                        "text": "Layer Kernels: dims [nb] Maps: dims [nb] Input image 32\u00d7 32 [3] N0 (Norm) 32\u00d7 32 [3] C1 (Conv) 5\u00d7 5 [48] 28\u00d7 28 [12] P2 (Pool) 2\u00d7 2 [1] 14\u00d7 14 [12] C3 (Conv) 5\u00d7 5 [384] 10\u00d7 10 [32] P4 (Pool) 2\u00d7 2 [1] 5\u00d7 5 [32] C5 (Conv) 5\u00d7 5 [1536] 1\u00d7 1 [48] L (Linear) 1\u00d7 1 [960] 1\u00d7 1 [20] Table 1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 112
                            }
                        ],
                        "text": "Layer Kernels: dims [nb] Maps: dims [nb] Input image 60\u00d7 60 [3] N0 (Norm) 60\u00d7 60 [3] C1 (Conv) 9\u00d7 9 [48] 52\u00d7 52 [12] P2 (Pool) 2\u00d7 2 [1] 26\u00d7 26 [12] C3 (Conv) 9\u00d7 9 [384] 18\u00d7 18 [32] P4 (Pool) 2\u00d7 2 [1] 9\u00d7 9 [32] C5 (Conv) 9\u00d7 9 [1536] 1\u00d7 1 [48] L (Linear) 1\u00d7 1 [960] 1\u00d7 1 [20] Table 2."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 123,
                                "start": 119
                            }
                        ],
                        "text": "Street scene parsing: a convolutional network was trained on the LabelMe spanish dataset [26] with a method similar to [12]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7296318,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1ecc15c576b54d17f7900b073e19edb2db2554f1",
            "isKey": true,
            "numCitedBy": 85,
            "numCiting": 4,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a deep learning strategy for scene parsing, i.e. to asssign a class label to each pixel of an image. We investigate the use of deep convolutional network for modeling the complex scene label structures, relying on a supervised greedy learning strategy. Compared to standard approaches based on CRFs, our strategy does not need hand-crafted features, allows modeling more complex spatial dependencies and has a lower inference cost. Experiments over the MSRC benchmark and the LabelMe dataset show the effectiveness of our approach."
            },
            "slug": "Deep-Convolutional-Networks-for-Scene-Parsing-Grangier-Bottou",
            "title": {
                "fragments": [],
                "text": "Deep Convolutional Networks for Scene Parsing"
            },
            "tldr": {
                "abstractSimilarityScore": 68,
                "text": "This work proposes a deep learning strategy for scene parsing, i.e. to asssign a class label to each pixel of an image, which does not need hand-crafted features, allows modeling more complex spatial dependencies and has a lower inference cost."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145160921"
                        ],
                        "name": "Bryan C. Russell",
                        "slug": "Bryan-C.-Russell",
                        "structuredName": {
                            "firstName": "Bryan",
                            "lastName": "Russell",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Bryan C. Russell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143805211"
                        ],
                        "name": "A. Torralba",
                        "slug": "A.-Torralba",
                        "structuredName": {
                            "firstName": "Antonio",
                            "lastName": "Torralba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Torralba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1768236"
                        ],
                        "name": "W. Freeman",
                        "slug": "W.-Freeman",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Freeman",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Freeman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1900911,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "092c275005ae49dc1303214f6d02d134457c7053",
            "isKey": false,
            "numCitedBy": 3100,
            "numCiting": 82,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract\nWe seek to build a large collection of images with ground truth labels to be used for object detection and recognition research. Such data is useful for supervised learning and quantitative evaluation. To achieve this, we developed a web-based tool that allows easy image annotation and instant sharing of such annotations. Using this annotation tool, we have collected a large dataset that spans many object categories, often containing multiple instances over a wide variety of images. We quantify the contents of the dataset and compare against existing state of the art datasets used for object recognition and detection. Also, we show how to extend the dataset to automatically enhance object labels with WordNet, discover object parts, recover a depth ordering of objects in a scene, and increase the number of labels using minimal user supervision and images from the web.\n"
            },
            "slug": "LabelMe:-A-Database-and-Web-Based-Tool-for-Image-Russell-Torralba",
            "title": {
                "fragments": [],
                "text": "LabelMe: A Database and Web-Based Tool for Image Annotation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A web-based tool that allows easy image annotation and instant sharing of such annotations is developed and a large dataset that spans many object categories, often containing multiple instances over a wide variety of images is collected."
            },
            "venue": {
                "fragments": [],
                "text": "International Journal of Computer Vision"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1644050191"
                        ],
                        "name": "G. LoweDavid",
                        "slug": "G.-LoweDavid",
                        "structuredName": {
                            "firstName": "G",
                            "lastName": "LoweDavid",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. LoweDavid"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "For example, the scale-invariant feature transform (SIFT [23]) operator applies oriented edge filters to a small patch and determines the dominant orientation through a winner-take-all operation."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 174065,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4cab9c4b571761203ed4c3a4c5a07dd615f57a91",
            "isKey": false,
            "numCitedBy": 25753,
            "numCiting": 75,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are ..."
            },
            "slug": "Distinctive-Image-Features-from-Scale-Invariant-LoweDavid",
            "title": {
                "fragments": [],
                "text": "Distinctive Image Features from Scale-Invariant Keypoints"
            },
            "tldr": {
                "abstractSimilarityScore": 100,
                "text": "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2069619574"
                        ],
                        "name": "D. Adams",
                        "slug": "D.-Adams",
                        "structuredName": {
                            "firstName": "Duane",
                            "lastName": "Adams",
                            "middleNames": [
                                "Albert"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Adams"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 132
                            }
                        ],
                        "text": "Layer Kernels: dims [nb] Maps: dims [nb] Input image 32\u00d7 32 [3] N0 (Norm) 32\u00d7 32 [3] C1 (Conv) 5\u00d7 5 [48] 28\u00d7 28 [12] P2 (Pool) 2\u00d7 2 [1] 14\u00d7 14 [12] C3 (Conv) 5\u00d7 5 [384] 10\u00d7 10 [32] P4 (Pool) 2\u00d7 2 [1] 5\u00d7 5 [32] C5 (Conv) 5\u00d7 5 [1536] 1\u00d7 1 [48] L (Linear) 1\u00d7 1 [960] 1\u00d7 1 [20] Table 1."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 48
                            }
                        ],
                        "text": "First dataflow architectures were introduced by [1], and quickly became an active field of research [8, 14, 18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 132
                            }
                        ],
                        "text": "Layer Kernels: dims [nb] Maps: dims [nb] Input image 60\u00d7 60 [3] N0 (Norm) 60\u00d7 60 [3] C1 (Conv) 9\u00d7 9 [48] 52\u00d7 52 [12] P2 (Pool) 2\u00d7 2 [1] 26\u00d7 26 [12] C3 (Conv) 9\u00d7 9 [384] 18\u00d7 18 [32] P4 (Pool) 2\u00d7 2 [1] 9\u00d7 9 [32] C5 (Conv) 9\u00d7 9 [1536] 1\u00d7 1 [48] L (Linear) 1\u00d7 1 [960] 1\u00d7 1 [20] Table 2."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 132
                            }
                        ],
                        "text": "Layer Kernels: dims [nb] Maps: dims [nb] Input image 92\u00d7 92 [3] N0 (Norm) 92\u00d7 92 [3] C1 (Conv) 9\u00d7 9 [48] 84\u00d7 84 [12] P2 (Pool) 2\u00d7 2 [1] 42\u00d7 42 [12] C3 (Conv) 9\u00d7 9 [384] 34\u00d7 34 [32] P4 (Pool) 2\u00d7 2 [1] 17\u00d7 17 [32] C5 (Conv) 9\u00d7 9 [1536] 9\u00d7 9 [48] C6 (Conv) 9\u00d7 9 [1024] 1\u00d7 1 [128] L (Linear) 1\u00d7 1 [960] 1\u00d7 1 [20] Table 3."
                    },
                    "intents": []
                }
            ],
            "corpusId": 60952942,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "df2464da7814c0a5356427198a9b9cd97f5bebd7",
            "isKey": true,
            "numCitedBy": 63,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "A-computation-model-with-data-flow-sequencing-Adams",
            "title": {
                "fragments": [],
                "text": "A computation model with data flow sequencing"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 1969
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 121
                            }
                        ],
                        "text": "LuaFlow is a full-blown compiler that takes sequential, tree-like or flow-graph descriptions of algorithms in the Torch5 [5] environment, and parses them to extract different levels of parallelism."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Torch. presented at the Workshop on Machine Learning"
            },
            "venue": {
                "fragments": [],
                "text": "Open Source Software,"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 178,
                                "start": 174
                            }
                        ],
                        "text": "org/category/xlearn/ Extensive research has been done on the question of how to schedule dataflow computations [22], and how to represent streams and computations on streams [18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 100
                            }
                        ],
                        "text": "First dataflow architectures were introduced by [1], and quickly became an active field of research [8, 14, 18]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Stream data types for signal processing"
            },
            "venue": {
                "fragments": [],
                "text": "Advances in Dataflow Architecture and Multithreading . IEEE Computer Society Press"
            },
            "year": 1994
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Torch. presented at the Workshop on Machine Learning Open Source Software, NIPS"
            },
            "venue": {
                "fragments": [],
                "text": "Torch. presented at the Workshop on Machine Learning Open Source Software, NIPS"
            },
            "year": 2008
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "sifier [6] and a complete street scene parser, as shown on Figure 5."
                    },
                    "intents": []
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Building heterogeneous platforms for end-to-end online learning based on dataflow computing design"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2010
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 14,
            "methodology": 11
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 28,
        "totalPages": 3
    },
    "page_url": "https://www.semanticscholar.org/paper/NeuFlow:-A-runtime-reconfigurable-dataflow-for-Farabet-Martini/204710a6a6d935150b5b16daf74493dea6d1b7a2?sort=total-citations"
}