{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 55,
                                "start": 51
                            }
                        ],
                        "text": "These general MIP features have been introduced in [11] as a generalization of features for the combinatorial winner determination problem in [30]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 58,
                                "start": 41
                            }
                        ],
                        "text": ", discrete-valued and unordered) domains [7, 8, 9, 10, 11]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 64427497,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "08c4fdd974d874c87ea87faa6b404a7b8eb72c73",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 182,
            "paperAbstract": {
                "fragments": [],
                "text": "The best-performing algorithms for many hard problems are highly parameterized. Selecting the best heuristics and tuning their parameters for optimal overall performance is often a difficult, tedious, and unsatisfying task. This thesis studies the automation of this important part of algorithm design: the configuration of discrete algorithm components and their continuous parameters to construct an algorithm with desirable empirical performance characteristics. Automated configuration procedures can facilitate algorithm development and be applied on the end user side to optimize performance for new instance types and optimization objectives. The use of such procedures separates high-level cognitive tasks carried out by humans from tedious low-level tasks that can be left to machines. We introduce two alternative algorithm configuration frameworks: iterated local search in parameter configuration space and sequential optimization based on response surface models. To the best of our knowledge, our local search approach is the first that goes beyond local optima. Our model-based search techniques significantly outperform existing techniques and extend them in ways crucial for general algorithm configuration: they can handle categorical parameters, optimization objectives defined across multiple instances, and tens of thousands of data points. We study how many runs to perform for evaluating a parameter configuration and how to set the cutoff time, after which algorithm runs are terminated unsuccessfully. We introduce data-driven approaches for making these choices adaptively, most notably the first general method for adaptively setting the cutoff time. Using our procedures\u2014to the best of our knowledge still the only ones applicable to these complex configuration tasks\u2014we configured state-of-the-art tree search and local search algorithms for SAT, as well as CPLEX, the most widely-used commercial optimization tool for solving mixed integer programs (MIP). In many cases, we achieved improvements of orders of magnitude over the algorithm default, thereby substantially improving the state of the art in solving a broad range of problems, including industrially relevant instances of SAT and MIP. Based on these results, we believe that automated algorithm configuration procedures, such as ours, will play an increasingly crucial role in the design of high-performance algorithms and will be widely used in academia and industry."
            },
            "slug": "Automated-configuration-of-algorithms-for-solving-Hutter",
            "title": {
                "fragments": [],
                "text": "Automated configuration of algorithms for solving hard computational problems"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This thesis studies the automation of this important part of algorithm design: the configuration of discrete algorithm components and their continuous parameters to construct an algorithm with desirable empirical performance characteristics and introduces data-driven approaches for making these choices adaptively."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2856003"
                        ],
                        "name": "Ashiqur R. KhudaBukhsh",
                        "slug": "Ashiqur-R.-KhudaBukhsh",
                        "structuredName": {
                            "firstName": "Ashiqur",
                            "lastName": "KhudaBukhsh",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ashiqur R. KhudaBukhsh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152895903"
                        ],
                        "name": "Lin Xu",
                        "slug": "Lin-Xu",
                        "structuredName": {
                            "firstName": "Lin",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lin Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388404060"
                        ],
                        "name": "Kevin Leyton-Brown",
                        "slug": "Kevin-Leyton-Brown",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Leyton-Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Leyton-Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 108
                            }
                        ],
                        "text": "Our own group has used PARAMILS to configure highly parameterized tree search [10] and local search solvers [11] for the propositional satisfiability problem (SAT), as well as several solvers for mixed integer programming (MIP), substantially advancing the state of the art for various types of instances."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 115098,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33b542c9ae18ae155f7919c326dcf4838bcf8c11",
            "isKey": false,
            "numCitedBy": 132,
            "numCiting": 158,
            "paperAbstract": {
                "fragments": [],
                "text": "Designing high-performance algorithms for computationally hard problems is a difficult and often time-consuming task. In this work, we demonstrate that this task can be automated in the context of stochastic local search (SLS) solvers for the propositional satisfiability problem (SAT). We first introduce a generalised, highly parameterised solver framework, dubbed SATenstein, that includes components gleaned from or inspired by existing high-performance SLS algorithms for SAT. The parameters of SATenstein control the selection of components used in any specific instantiation and the behaviour of these components. SATenstein can be configured to instantiate a broad range of existing high-performance SLS-based SAT solvers, and also billions of novel algorithms. We used an automated algorithm configuration procedure to find instantiations of SATenstein that perform well on several well-known, challenging distributions of SAT instances. Overall, we consistently obtained significant improvements over the previously best-performing SLS algorithms, despite expending minimal manual effort."
            },
            "slug": "SATenstein:-Automatically-Building-Local-Search-SAT-KhudaBukhsh-Xu",
            "title": {
                "fragments": [],
                "text": "SATenstein: Automatically Building Local Search SAT Solvers from Components"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work introduces a generalised, highly parameterised solver framework, dubbed SATenstein, that includes components gleaned from or inspired by existing high-performance SLS algorithms for SAT, and configuration procedure to find instantiations of SATenstein that perform well on several well-known, challenging distributions of SAT instances."
            },
            "venue": {
                "fragments": [],
                "text": "IJCAI"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388404060"
                        ],
                        "name": "Kevin Leyton-Brown",
                        "slug": "Kevin-Leyton-Brown",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Leyton-Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Leyton-Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684799"
                        ],
                        "name": "T. St\u00fctzle",
                        "slug": "T.-St\u00fctzle",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "St\u00fctzle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. St\u00fctzle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 130
                            }
                        ],
                        "text": "The most prominent configuration methods are the racing algorithm F-RACE [5] and our own iterated local search algorithm PARAMILS [7, 8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 36
                            }
                        ],
                        "text": "Similar to the FOCUSEDILS algorithm [7, 8], \u03b8inc and \u03b8new are always compared using only instances on which they have both been run."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 100,
                                "start": 97
                            }
                        ],
                        "text": "7 The proof is very simple and uses the same arguments as a previous proof about FocusedILS (see [8]); we omit it here and refer the reader to the extended version of this paper [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 47
                            }
                        ],
                        "text": "6 This search is similar in spirit to PARAMILS [7, 8], but instead of algorithm performance it optimizes EI(\u03b8) (see Equation 1), which can be evaluated based on the model predictions \u03bc\u03b8 and \u03c3(2) \u03b8 without running the target algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 43,
                                "start": 40
                            }
                        ],
                        "text": ", PARAMILS\u2019s adaptive capping mechanism [8]); thus, so far we expect them to perform poorly on some configuration scenarios with large captimes."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 162
                            }
                        ],
                        "text": "We considered a diverse set of 17 algorithm configuration problem instances (so-called configuration scenarios) that had been used previously to analyze PARAMILS [8, 1] and TB-SPO [15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 41
                            }
                        ],
                        "text": ", discrete-valued and unordered) domains [6, 7, 8, 9]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 115,
                                "start": 112
                            }
                        ],
                        "text": "We believe that for such large captimes, an adaptive capping mechanism, such as the one implemented in ParamILS [8], is essential; we are currently working on"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 328,
                                "start": 322
                            }
                        ],
                        "text": "In a thorough experimental analysis for a wide range of 17 scenarios with small captimes (involving the optimization of local search and tree search SAT solvers, as well as the commercial MIP solver CPLEX), SMAC indeed compared favourably to the two most prominent approaches for general algorithm configuration: PARAMILS [7, 8] and GGA [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 3
                            }
                        ],
                        "text": "3) [8] for a range of configuration scenarios that involve minimizing the runtime of SAT and MIP solvers."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1034056,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "23105024da063b7ee62840e7c869721d12335e4a",
            "isKey": false,
            "numCitedBy": 923,
            "numCiting": 71,
            "paperAbstract": {
                "fragments": [],
                "text": "The identification of performance-optimizing parameter settings is an important part of the development and application of algorithms. We describe an automatic framework for this algorithm configuration problem. More formally, we provide methods for optimizing a target algorithm's performance on a given class of problem instances by varying a set of ordinal and/or categorical parameters. We review a family of local-search-based algorithm configuration procedures and present novel techniques for accelerating them by adaptively limiting the time spent for evaluating individual configurations. We describe the results of a comprehensive experimental evaluation of our methods, based on the configuration of prominent complete and incomplete algorithms for SAT. We also present what is, to our knowledge, the first published work on automatically configuring the CPLEX mixed integer programming solver. All the algorithms we considered had default parameter settings that were manually identified with considerable effort. Nevertheless, using our automated algorithm configuration procedures, we achieved substantial and consistent performance improvements."
            },
            "slug": "ParamILS:-An-Automatic-Algorithm-Configuration-Hutter-Hoos",
            "title": {
                "fragments": [],
                "text": "ParamILS: An Automatic Algorithm Configuration Framework"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "An automatic framework for this algorithm configuration problem is described and methods for optimizing a target algorithm's performance on a given class of problem instances by varying a set of ordinal and/or categorical parameters are provided."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388404060"
                        ],
                        "name": "Kevin Leyton-Brown",
                        "slug": "Kevin-Leyton-Brown",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Leyton-Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Leyton-Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 120
                            }
                        ],
                        "text": "To enable a comparison with our previous SMBO instantiation TB-SPO, we used the 6 configuration scenarios introduced in [15], which aim to minimize SAPS\u2019s runtime on 6 single SAT-encoded instances, 3 each from quasigroup completion (QCP) and small world graph colouring (SWGCP)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": "cesses (GPs), or the projected process (PP) approximation to GPs we used in TB-SPO [15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 12
                            }
                        ],
                        "text": "5 In TB-SPO [15], we used fmin = \u03bc(\u03b8inc) + \u03c3(\u03b8inc)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 95,
                                "start": 91
                            }
                        ],
                        "text": "The time budget for each algorithm configuration run was 30 CPU minutes, exactly following [15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 184,
                                "start": 180
                            }
                        ],
                        "text": "We considered a diverse set of 17 algorithm configuration problem instances (so-called configuration scenarios) that had been used previously to analyze PARAMILS [8, 1] and TB-SPO [15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 22
                            }
                        ],
                        "text": "Previous SMBO methods [13, 14, 15] simply applied random sampling for this task (in particular, they evaluated EI for 10 000 random samples), which is unlikely to be sufficient in high-dimensional configuration spaces, especially if promising configurations are sparse."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 57,
                                "start": 53
                            }
                        ],
                        "text": "We now compare the performance of SMAC, ROAR, TB-SPO [15], GGA [9], and PARAMILS (in particular, FOCUSEDILS 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 37
                            }
                        ],
                        "text": "Despite considerable recent advances [13, 14, 15], all published work on SMBO still has three key limitations that prevent its use for general algorithm configuration tasks: (1) it only supports numerical parameters; (2) it only optimizes target algorithm performance for"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1012160,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "33e78ecd04700581efe665843e8d9035533d4356",
            "isKey": false,
            "numCitedBy": 80,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "The optimization of algorithm performance by automatically identifying good parameter settings is an important problem that has recently attracted much attention in the discrete optimization community. One promising approach constructs predictive performance models and uses them to focus attention on promising regions of a design space. Such methods have become quite sophisticated and have achieved significant successes on other problems, particularly in experimental design applications. However, they have typically been designed to achieve good performance only under a budget expressed as a number of function evaluations (e.g., target algorithm runs). In this work, we show how to extend the Sequential Parameter Optimization framework [SPO; see 5] to operate effectively under time bounds. Our methods take into account both the varying amount of time required for different algorithm runs and the complexity of model building and evaluation; they are particularly useful for minimizing target algorithm runtime. Specifically, we avoid the up-front cost of an initial design, introduce a time-bounded intensification mechanism, and show how to reduce the overhead incurred by constructing and using models. Overall, we show that our method represents a new state of the art in model-based optimization of algorithms with continuous parameters on single problem instances."
            },
            "slug": "Time-Bounded-Sequential-Parameter-Optimization-Hutter-Hoos",
            "title": {
                "fragments": [],
                "text": "Time-Bounded Sequential Parameter Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work shows how to extend the Sequential Parameter Optimization framework [SPO; see 5] to operate effectively under time bounds and represents a new state of the art in model-based optimization of algorithms with continuous parameters on single problem instances."
            },
            "venue": {
                "fragments": [],
                "text": "LION"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684799"
                        ],
                        "name": "T. St\u00fctzle",
                        "slug": "T.-St\u00fctzle",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "St\u00fctzle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. St\u00fctzle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 136,
                                "start": 130
                            }
                        ],
                        "text": "The most prominent configuration methods are the racing algorithm F-RACE [5] and our own iterated local search algorithm PARAMILS [7, 8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 42,
                                "start": 36
                            }
                        ],
                        "text": "Similar to the FOCUSEDILS algorithm [7, 8], \u03b8inc and \u03b8new are always compared using only instances on which they have both been run."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 47
                            }
                        ],
                        "text": "6 This search is similar in spirit to PARAMILS [7, 8], but instead of algorithm performance it optimizes EI(\u03b8) (see Equation 1), which can be evaluated based on the model predictions \u03bc\u03b8 and \u03c3(2) \u03b8 without running the target algorithm."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 74
                            }
                        ],
                        "text": "(This is the same problem faced by the PARAMILS instantiation BASICILS(N) [7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 158,
                                "start": 152
                            }
                        ],
                        "text": "Comparing the left vs the right side of Table 1, we note that the SAPS discretization (the same we used to optimize SAPS with PARAMILS in previous work [7, 8]) left substantial room for improvement when exploring the full space: roughly 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 41
                            }
                        ],
                        "text": ", discrete-valued and unordered) domains [6, 7, 8, 9]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 328,
                                "start": 322
                            }
                        ],
                        "text": "In a thorough experimental analysis for a wide range of 17 scenarios with small captimes (involving the optimization of local search and tree search SAT solvers, as well as the commercial MIP solver CPLEX), SMAC indeed compared favourably to the two most prominent approaches for general algorithm configuration: PARAMILS [7, 8] and GGA [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14512352,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e4776b8295629c8e74eb7503b3d6364caa026bb6",
            "isKey": false,
            "numCitedBy": 311,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "The determination of appropriate values for free algorithm parameters is a challenging and tedious task in the design of effective algorithms for hard problems. Such parameters include categorical choices (e.g., neighborhood structure in local search or variable/value ordering heuristics in tree search), as well as numerical parameters (e.g., noise or restart timing). In practice, tuning of these parameters is largely carried out manually by applying rules of thumb and crude heuristics, while more principled approaches are only rarely used. In this paper, we present a local search approach for algorithm configuration and prove its convergence to the globally optimal parameter configuration. Our approach is very versatile: it can, e.g., be used for minimising run-time in decision problems or for maximising solution quality in optimisation problems. It further applies to arbitrary algorithms, including heuristic tree search and local search algorithms, with no limitation on the number of parameters. Experiments in four algorithm configuration scenarios demonstrate that our automatically determined parameter settings always outperform the algorithm defaults, sometimes by several orders of magnitude. Our approach also shows better performance and greater flexibility than the recent CALIBRA system. Our ParamILS code, along with instructions on how to use it for tuning your own algorithms, is available on-line at http://www.cs.ubc.ca/labs/beta/Projects/ParamILS."
            },
            "slug": "Automatic-Algorithm-Configuration-Based-on-Local-Hutter-Hoos",
            "title": {
                "fragments": [],
                "text": "Automatic Algorithm Configuration Based on Local Search"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper presents a local search approach for algorithm configuration and proves its convergence to the globally optimal parameter configuration, which can be used for minimising run-time in decision problems or for maximising solution quality in optimisation problems."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388404060"
                        ],
                        "name": "Kevin Leyton-Brown",
                        "slug": "Kevin-Leyton-Brown",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Leyton-Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Leyton-Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 197,
                                "start": 194
                            }
                        ],
                        "text": "Notably, by optimizing the 76 parameters of CPLEX\u2014the most prominent MIP solver\u2014we achieved up to 50-fold speedups over the defaults and over the configuration returned by the CPLEX tuning tool [1]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 116
                            }
                        ],
                        "text": "We also list performance of the default configuration, and of the configuration found by the CPLEX tuning tool (see [1]); note that on the test set this can be worse than the default."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 187,
                                "start": 184
                            }
                        ],
                        "text": "In previous work, we have also applied PARAMILS to optimize MIP solvers with very large per-run captimes (up to \u03bamax = 10 000s), and obtained better results than the CPLEX tuning tool [1]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 162
                            }
                        ],
                        "text": "We considered a diverse set of 17 algorithm configuration problem instances (so-called configuration scenarios) that had been used previously to analyze PARAMILS [8, 1] and TB-SPO [15]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 78,
                                "start": 75
                            }
                        ],
                        "text": "9 In fact, preliminary experiments for configuration scenario CORLAT (from [1], with \u03bamax = 10 000s) highlight the importance of developing an adaptive capping mechanism for SMAC:"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 144,
                                "start": 141
                            }
                        ],
                        "text": "As one prominent example, the commercial mixed integer programming solver IBM ILOG CPLEX has 76 parameters pertaining to its search strategy [1]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1105261,
            "fieldsOfStudy": [
                "Computer Science",
                "Business"
            ],
            "id": "5552bcf12caf0e12541cc07a285a3c70470563d3",
            "isKey": false,
            "numCitedBy": 178,
            "numCiting": 29,
            "paperAbstract": {
                "fragments": [],
                "text": "State-of-the-art solvers for mixed integer programming (MIP) problems are highly parameterized, and finding parameter settings that achieve high performance for specific types of MIP instances is challenging. We study the application of an automated algorithm configuration procedure to different MIP solvers, instance types and optimization objectives. We show that this fully-automated process yields substantial improvements to the performance of three MIP solvers: Cplex, Gurobi, and lpsolve. Although our method can be used \u201cout of the box\u201d without any domain knowledge specific to MIP, we show that it outperforms the Cplex special-purpose automated tuning tool."
            },
            "slug": "Automated-Configuration-of-Mixed-Integer-Solvers-Hutter-Hoos",
            "title": {
                "fragments": [],
                "text": "Automated Configuration of Mixed Integer Programming Solvers"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work studies the application of an automated algorithm configuration procedure to different MIP solvers, instance types and optimization objectives, and shows that this fully-automated process yields substantial improvements to the performance of three MIPsolvers: Cplex, Gurobi, and lpsolve."
            },
            "venue": {
                "fragments": [],
                "text": "CPAIOR"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144659218"
                        ],
                        "name": "C. Gomes",
                        "slug": "C.-Gomes",
                        "structuredName": {
                            "firstName": "Carla",
                            "lastName": "Gomes",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Gomes"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1744679"
                        ],
                        "name": "B. Selman",
                        "slug": "B.-Selman",
                        "structuredName": {
                            "firstName": "Bart",
                            "lastName": "Selman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Selman"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 241,
                                "start": 237
                            }
                        ],
                        "text": "To enable a comparison with our previous SMBO instantiation TB-SPO, we used the 6 configuration scenarios introduced in [18], which aim to minimize SAPS\u2019s runtime on 6 single SAT-encoded instances, 3 each from quasigroup completion (QCP [35]) and from small world graph colouring (SWGCP [36])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 235,
                                "start": 232
                            }
                        ],
                        "text": "To enable a comparison with our previous SMBO instantiation TB-SPO, we used the 6 configuration scenarios introduced in [15], which aim to minimize SAPS\u2019s runtime on 6 single SAT-encoded instances, 3 each from quasigroup completion (QCP) and small world graph colouring (SWGCP)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 280,
                                "start": 277
                            }
                        ],
                        "text": "Comparing the left vs the right side of Table 1, we note that the SAPS discretization (the same we used to optimize SAPS with PARAMILS in previous work [7, 8]) left substantial room for improvement when exploring the full space: roughly 1.15-fold and 1.55-fold speedups on the QCP and SWGCP instances, respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 80,
                                "start": 76
                            }
                        ],
                        "text": "These instances come from the following domains: quasigroup completion, QCP [35]; small world graph colouring, SWGCP [36]; winner determination in combinatorial auctions, REGIONS100 [39]; mixed integer knapsack, MIK [40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 106,
                                "start": 103
                            }
                        ],
                        "text": "Speedups for SAPS were similar to those observed in the single-instance case (about 1.15-fold for SAPS-QCP and 1.65-fold for SAPS-SWGCP), but now we also observed a 1.17-fold improvement for SPEAR-QCP."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10639512,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "417ed2405c04afa0dee56b8812b8ddd9e850177f",
            "isKey": true,
            "numCitedBy": 158,
            "numCiting": 37,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent progress on search and reasoning procedures has been driven by experimentation on computationally hard problem instances. Hard random problem distributions are an important source of such instances. Challenge problems from the area of finite algebra have also stimulated research on search and reasoning procedures. Nevertheless, the relation of such problems to practical applications is somewhat unclear. Realistic problem instances clearly have more structure than the random problem instances, but, on the other hand, they are not as regular as the structured mathematical problems. We propose a new benchmark domain that bridges the gap between the purely random instances and the highly structured problems, by introducing perturbations into a structured domain. We will show how to obtain interesting search problems in this manner, and how such problems can be used to study the robustness of search control mechanisms. Our experiments demonstrate that the performance of search strategies designed to mimic direct constructive methods degrade surprisingly quickly in the presence of even minor perturbations."
            },
            "slug": "Problem-Structure-in-the-Presence-of-Perturbations-Gomes-Selman",
            "title": {
                "fragments": [],
                "text": "Problem Structure in the Presence of Perturbations"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "This work proposes a new benchmark domain that bridges the gap between the purely random instances and the highly structured problems, by introducing perturbations into a structured domain and demonstrates that the performance of search strategies designed to mimic direct constructive methods degrade surprisingly quickly in the presence of even minor perturbation."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1997
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152895903"
                        ],
                        "name": "Lin Xu",
                        "slug": "Lin-Xu",
                        "structuredName": {
                            "firstName": "Lin",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lin Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388404060"
                        ],
                        "name": "Kevin Leyton-Brown",
                        "slug": "Kevin-Leyton-Brown",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Leyton-Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Leyton-Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 129
                            }
                        ],
                        "text": "Most notably, such predictions have been exploited to construct portfolio-based algorithm selection mechanisms, such as SATzilla [20]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 129,
                                "start": 125
                            }
                        ],
                        "text": "Previous work on predicting algorithm runtime has found that logarithmic transformations substantially improve model quality [20] and we thus use log-transformed runtime data throughout this paper; that is, for runtime ri, we use oi = ln(ri)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 10987043,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "72489f377f08ac720cd31d9eed20706abfed58bb",
            "isKey": false,
            "numCitedBy": 876,
            "numCiting": 99,
            "paperAbstract": {
                "fragments": [],
                "text": "It has been widely observed that there is no single \"dominant\" SAT solver; instead, different solvers perform best on different instances. Rather than following the traditional approach of choosing the best solver for a given class of instances, we advocate making this decision online on a per-instance basis. Building on previous work, we describe SATzilla, an automated approach for constructing per-instance algorithm portfolios for SAT that use so-called empirical hardness models to choose among their constituent solvers. This approach takes as input a distribution of problem instances and a set of component solvers, and constructs a portfolio optimizing a given objective function (such as mean runtime, percent of instances solved, or score in a competition). The excellent performance of SATzilla was independently verified in the 2007 SAT Competition, where our SATzilla07 solvers won three gold, one silver and one bronze medal. In this article, we go well beyond SATzilla07 by making the portfolio construction scalable and completely automated, and improving it by integrating local search solvers as candidate solvers, by predicting performance score instead of runtime, and by using hierarchical hardness models that take into account different types of SAT instances. We demonstrate the effectiveness of these new techniques in extensive experimental results on data sets including instances from the most recent SAT competition."
            },
            "slug": "SATzilla:-Portfolio-based-Algorithm-Selection-for-Xu-Hutter",
            "title": {
                "fragments": [],
                "text": "SATzilla: Portfolio-based Algorithm Selection for SAT"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "SATzilla is described, an automated approach for constructing per-instance algorithm portfolios for SAT that use so-called empirical hardness models to choose among their constituent solvers and is improved by integrating local search solvers as candidate solvers, by predicting performance score instead of runtime, and by using hierarchical hardness models that take into account different types of SAT instances."
            },
            "venue": {
                "fragments": [],
                "text": "J. Artif. Intell. Res."
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3051003"
                        ],
                        "name": "C. Nell",
                        "slug": "C.-Nell",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Nell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Nell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49830161"
                        ],
                        "name": "C. Fawcett",
                        "slug": "C.-Fawcett",
                        "structuredName": {
                            "firstName": "Chris",
                            "lastName": "Fawcett",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Fawcett"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388404060"
                        ],
                        "name": "Kevin Leyton-Brown",
                        "slug": "Kevin-Leyton-Brown",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Leyton-Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Leyton-Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 27,
                                "start": 23
                            }
                        ],
                        "text": "We ran GGA through HAL [23], using parameter settings recommended by GGA\u2019s author, Kevin Tierney, in e-mail communication: we set the population size to 70, the number of generations to 100, the number of runs to perform in the first generation to 5, and the number of runs to perform in the last generation to 70."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 81,
                                "start": 78
                            }
                        ],
                        "text": "Thanks also to Chris Fawcett and Chris Nell for help with running GGA through HAL, to Kevin Tierney\nfor help with GGA\u2019s parameters, and to James Styles and Mauro Vallati for comments on an earlier draft of this paper."
                    },
                    "intents": []
                }
            ],
            "corpusId": 290448,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "626276f6bae7be775ab1d270f2c3ed2adee28594",
            "isKey": false,
            "numCitedBy": 23,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Sophisticated empirical methods drive the development of high-performance solvers for an increasing range of problems from industry and academia. However, automated tools implementing these methods are often difficult to develop and to use. We address this issue with two contributions. First, we develop a formal description of meta-algorithmic problems and use it as the basis for an automated algorithm analysis and design framework called the High-performance Algorithm Laboratory. Second, we describe HAL 1.0, an implementation of the core components of this framework that provides support for distributed execution, remote monitoring, data management, and analysis of results. We demonstrate our approach by using HAL 1.0 to conduct a sequence of increasingly complex analysis and design tasks on state-of-the-art solvers for SAT and mixed-integer programming problems."
            },
            "slug": "HAL:-A-Framework-for-the-Automated-Analysis-and-of-Nell-Fawcett",
            "title": {
                "fragments": [],
                "text": "HAL: A Framework for the Automated Analysis and Design of High-Performance Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work develops a formal description of meta-algorithmic problems and uses it as the basis for an automated algorithm analysis and design framework called the High-performance Algorithm Laboratory and describes HAL 1.0, an implementation of the core components of this framework that provides support for distributed execution, remote monitoring, data management, and analysis of results."
            },
            "venue": {
                "fragments": [],
                "text": "LION"
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69372472"
                        ],
                        "name": "Prasanna Balaprakash",
                        "slug": "Prasanna-Balaprakash",
                        "structuredName": {
                            "firstName": "Prasanna",
                            "lastName": "Balaprakash",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Prasanna Balaprakash"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690903"
                        ],
                        "name": "M. Birattari",
                        "slug": "M.-Birattari",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Birattari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Birattari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684799"
                        ],
                        "name": "T. St\u00fctzle",
                        "slug": "T.-St\u00fctzle",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "St\u00fctzle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. St\u00fctzle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 95
                            }
                        ],
                        "text": "The most prominent configuration methods are the racing algorithm F-RACE [5] and our own iterated local search algorithm PARAMILS [7, 8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 121
                            }
                        ],
                        "text": "Some methods focus on optimizing numerical (i.e., either integer- or real-valued) parameters (see, e.g., [4, 5]), while others also target categorical (i.e., discrete-valued and unordered) domains [6, 7, 8, 9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 9476027,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c6bb1a2a3285be50a6b703fea94878e08d1e0025",
            "isKey": false,
            "numCitedBy": 262,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "Finding appropriate values for the parameters of an algorithm is a challenging, important, and time consuming task. While typically parameters are tuned by hand, recent studies have shown that automatic tuning procedures can effectively handle this task and often find better parameter settings. F-Race has been proposed specifically for this purpose and it has proven to be very effective in a number of cases. F-Race is a racing algorithm that starts by considering a number of candidate parameter settings and eliminates inferior ones as soon as enough statistical evidence arises against them. In this paper, we propose two modifications to the usual way of applying F-Race that on the one hand, make it suitable for tuning tasks with a very large number of initial candidate parameter settings and, on the other hand, allow a significant reduction of the number of function evaluations without any major loss in solution quality. We evaluate the proposed modifications on a number of stochastic local search algorithms and we show their effectiveness. \u00a9 Springer-Verlag Berlin Heidelberg 200"
            },
            "slug": "Improvement-Strategies-for-the-F-Race-Algorithm:-Balaprakash-Birattari",
            "title": {
                "fragments": [],
                "text": "Improvement Strategies for the F-Race Algorithm: Sampling Design and Iterative Refinement"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper proposes two modifications to the usual way of applying F-Race that make it suitable for tuning tasks with a very large number of initial candidate parameter settings and allow a significant reduction of the number of function evaluations without any major loss in solution quality."
            },
            "venue": {
                "fragments": [],
                "text": "Hybrid Metaheuristics"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35250057"
                        ],
                        "name": "D. Babic",
                        "slug": "D.-Babic",
                        "structuredName": {
                            "firstName": "Domagoj",
                            "lastName": "Babic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Babic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741933"
                        ],
                        "name": "A. Hu",
                        "slug": "A.-Hu",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Hu",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 82,
                                "start": 78
                            }
                        ],
                        "text": "Our own group has used PARAMILS to configure highly parameterized tree search [10] and local search solvers [11] for the propositional satisfiability problem (SAT), as well as several solvers for mixed integer programming (MIP), substantially advancing the state of the art for various types of instances."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6677203,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d8c48a95e2c8b69af408f29d65e244d6604e69aa",
            "isKey": false,
            "numCitedBy": 92,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Parameterized heuristics abound in computer aided design and verification, and manual tuning of the respective parameters is difficult and time-consuming. Very recent results from the artificial intelligence (AI) community suggest that this tuning process can be automated, and that doing so can lead to significant performance improvements; furthermore, automated parameter optimization can provide valuable guidance during the development of heuristic algorithms. In this paper, we study how such an AI approach can improve a state-of-the-art SAT solver for large, real-world bounded model-checking and software verification instances. The resulting, automatically-derived parameter settings yielded runtimes on average 4.5 times faster on bounded model checking instances and 500 times faster on software verification problems than extensive hand-tuning of the decision procedure. Furthermore, the availability of automatic tuning influenced the design of the solver, and the automatically-derived parameter settings provided a deeper insight into the properties of problem instances."
            },
            "slug": "Boosting-Verification-by-Automatic-Tuning-of-Hutter-Babic",
            "title": {
                "fragments": [],
                "text": "Boosting Verification by Automatic Tuning of Decision Procedures"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper study how an AI approach can improve a state-of-the-art SAT solver for large, real-world bounded model-checking and software verification instances, and finds that the availability of automatic tuning influenced the design of the solver, and the automatically-derived parameter settings provided a deeper insight into the properties of problem instances."
            },
            "venue": {
                "fragments": [],
                "text": "Formal Methods in Computer Aided Design (FMCAD'07)"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "26602711"
                        ],
                        "name": "Steven N. Minton",
                        "slug": "Steven-N.-Minton",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Minton",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven N. Minton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "37994193"
                        ],
                        "name": "M. Johnston",
                        "slug": "M.-Johnston",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Johnston",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Johnston"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2648787"
                        ],
                        "name": "Andrew B. Philips",
                        "slug": "Andrew-B.-Philips",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Philips",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew B. Philips"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "29961301"
                        ],
                        "name": "P. Laird",
                        "slug": "P.-Laird",
                        "structuredName": {
                            "firstName": "Philip",
                            "lastName": "Laird",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Laird"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 43
                            }
                        ],
                        "text": "This research goes back to the early 1990s [2, 3] and has lately been gaining momentum."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14830518,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "be41652987acff408e1b9d699a8e78ab3ae11932",
            "isKey": false,
            "numCitedBy": 996,
            "numCiting": 80,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Minimizing-Conflicts:-A-Heuristic-Repair-Method-for-Minton-Johnston",
            "title": {
                "fragments": [],
                "text": "Minimizing Conflicts: A Heuristic Repair Method for Constraint Satisfaction and Scheduling Problems"
            },
            "venue": {
                "fragments": [],
                "text": "Artif. Intell."
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388404060"
                        ],
                        "name": "Kevin Leyton-Brown",
                        "slug": "Kevin-Leyton-Brown",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Leyton-Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Leyton-Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48942559"
                        ],
                        "name": "E. Nudelman",
                        "slug": "E.-Nudelman",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Nudelman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Nudelman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701353"
                        ],
                        "name": "Y. Shoham",
                        "slug": "Y.-Shoham",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Shoham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Shoham"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 47,
                                "start": 43
                            }
                        ],
                        "text": "Existing work on empirical hardness models [21] has demonstrated that it is possible to predict algorithm runtime based on features of a given problem instance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9223857,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2609f23364b0611e75d69ac5d311ebe6fcd75f44",
            "isKey": false,
            "numCitedBy": 130,
            "numCiting": 113,
            "paperAbstract": {
                "fragments": [],
                "text": "Is it possible to predict how long an algorithm will take to solve a previously-unseen instance of an NP-complete problem? If so, what uses can be found for models that make such predictions? This article provides answers to these questions and evaluates the answers experimentally.\n We propose the use of supervised machine learning to build models that predict an algorithm's runtime given a problem instance. We discuss the construction of these models and describe techniques for interpreting them to gain understanding of the characteristics that cause instances to be hard or easy. We also present two applications of our models: building algorithm portfolios that outperform their constituent algorithms, and generating test distributions that emphasize hard problems.\n We demonstrate the effectiveness of our techniques in a case study of the combinatorial auction winner determination problem. Our experimental results show that we can build very accurate models of an algorithm's running time, interpret our models, build an algorithm portfolio that strongly outperforms the best single algorithm, and tune a standard benchmark suite to generate much harder problem instances."
            },
            "slug": "Empirical-hardness-models:-Methodology-and-a-case-Leyton-Brown-Nudelman",
            "title": {
                "fragments": [],
                "text": "Empirical hardness models: Methodology and a case study on combinatorial auctions"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The use of supervised machine learning is proposed to build models that predict an algorithm's runtime given a problem instance and techniques for interpreting them are described to gain understanding of the characteristics that cause instances to be hard or easy."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2152895903"
                        ],
                        "name": "Lin Xu",
                        "slug": "Lin-Xu",
                        "structuredName": {
                            "firstName": "Lin",
                            "lastName": "Xu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lin Xu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388404060"
                        ],
                        "name": "Kevin Leyton-Brown",
                        "slug": "Kevin-Leyton-Brown",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Leyton-Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Leyton-Brown"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 8234226,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2feb2d275e645da448ac0c3f91ffcc9a222d325d",
            "isKey": false,
            "numCitedBy": 54,
            "numCiting": 39,
            "paperAbstract": {
                "fragments": [],
                "text": "Empirical studies often observe that the performance of algorithms across problem domains can be quite uncorrelated. When this occurs, it seems practical to investigate the use of algorithm portfolios that draw on the strengths of multiple algorithms. SATzilla is such an algorithm portfolio for SAT problems; it was first deployed in the 2004 SAT competition [12], and recently an updated version, SATzilla2007, won a number of prizes in the 2007 SAT competition [21], including the gold medals for the SAT+UNSAT categories of both the random and handmade categories. SATzilla2008, submitted to the 2008 SAT Race, did not perform as well. We attribute this mainly to the lack of publicly available high-performance component solvers as well as to overheads in computing instance features for huge industrial instances; we addressed this latter point in SATzilla2009. SATzilla is based on empirical hardness models [10, 13], learned predictors that estimate each algorithm\u2019s performance on a given SAT instance. Over the years, we have added several features to SATzilla. We integrated regression methods based on partly censored data, probabilistic prediction of instance satisfiability, and hierarchical hardness models [21, 22]. We also almost entirely automated the portfolio construction process based on automatic procedures for selecting pre-solvers and candidate component solvers [23]. The new features in SATzilla2009 are as follows:"
            },
            "slug": "SATzilla2009:-an-Automatic-Algorithm-Portfolio-for-Xu-Hutter",
            "title": {
                "fragments": [],
                "text": "SATzilla2009: an Automatic Algorithm Portfolio for SAT"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "SATzilla is an algorithm portfolio for SAT problems that is based on empirical hardness models, learned predictors that estimate each algorithm\u2019s performance on a given SAT instance and almost entirely automated the portfolio construction process based on automatic procedures for selecting pre-solvers and candidate component solvers."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "8388443"
                        ],
                        "name": "Pascal Van Hentenryck",
                        "slug": "Pascal-Van-Hentenryck",
                        "structuredName": {
                            "firstName": "Pascal",
                            "lastName": "Hentenryck",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pascal Van Hentenryck"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736128"
                        ],
                        "name": "L. Wolsey",
                        "slug": "L.-Wolsey",
                        "structuredName": {
                            "firstName": "Laurence",
                            "lastName": "Wolsey",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Wolsey"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                }
            ],
            "citationContexts": [],
            "corpusId": 36144073,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "6bba3174162d510a3265825cd5759e0c04921f63",
            "isKey": false,
            "numCitedBy": 498,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "Minimum Cardinality Matrix Decomposition into Consecutive-Ones Matrices: CP and IP Approaches.- Connections in Networks: Hardness of Feasibility Versus Optimality.- Modeling the Regular Constraint with Integer Programming.- Hybrid Local Search for Constrained Financial Portfolio Selection Problems.- The \"Not-Too-Heavy Spanning Tree\" Constraint.- Eliminating Redundant Clauses in SAT Instances.- Cost-Bounded Binary Decision Diagrams for 0-1 Programming.- YIELDS: A Yet Improved Limited Discrepancy Search for CSPs.- A Global Constraint for Total Weighted Completion Time.- Computing Tight Time Windows for RCPSPWET with the Primal-Dual Method.- Necessary Condition for Path Partitioning Constraints.- A Constraint Programming Approach to the Hospitals / Residents Problem.- Best-First AND/OR Search for 0/1 Integer Programming.- A Position-Based Propagator for the Open-Shop Problem.- Directional Interchangeability for Enhancing CSP Solving.- A Continuous Multi-resources cumulative Constraint with Positive-Negative Resource Consumption-Production.- Replenishment Planning for Stochastic Inventory Systems with Shortage Cost.- Preprocessing Expression-Based Constraint Satisfaction Problems for Stochastic Local Search.- The Deviation Constraint.- The Linear Programming Polytope of Binary Constraint Problems with Bounded Tree-Width.- On Boolean Functions Encodable as a Single Linear Pseudo-Boolean Constraint.- Solving a Stochastic Queueing Control Problem with Constraint Programming.- Constrained Clustering Via Concavity Cuts.- Bender's Cuts Guided Large Neighborhood Search for the Traveling Umpire Problem.- A Large Neighborhood Search Heuristic for Graph Coloring.- Generalizations of the Global Cardinality Constraint for Hierarchical Resources.- A Column Generation Based Destructive Lower Bound for Resource Constrained Project Scheduling Problems."
            },
            "slug": "Integration-of-AI-and-OR-Techniques-in-Constraint-Hentenryck-Wolsey",
            "title": {
                "fragments": [],
                "text": "Integration of AI and OR Techniques in Constraint Programming for Combinatorial Optimization Problems, 4th International Conference, CPAIOR 2007, Brussels, Belgium, May 23-26, 2007, Proceedings"
            },
            "tldr": {
                "abstractSimilarityScore": 98,
                "text": "Minimum Cardinality Matrix Decomposition into Consecutive-Ones Matrices: CP and IP Approaches and Connections in Networks: Hardness of Feasibility Versus Optimality."
            },
            "venue": {
                "fragments": [],
                "text": "CPAIOR"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733142"
                        ],
                        "name": "Brahim Hnich",
                        "slug": "Brahim-Hnich",
                        "structuredName": {
                            "firstName": "Brahim",
                            "lastName": "Hnich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brahim Hnich"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144273342"
                        ],
                        "name": "R. Rossi",
                        "slug": "R.-Rossi",
                        "structuredName": {
                            "firstName": "R.",
                            "lastName": "Rossi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Rossi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1746581"
                        ],
                        "name": "Armagan Tarim",
                        "slug": "Armagan-Tarim",
                        "structuredName": {
                            "firstName": "Armagan",
                            "lastName": "Tarim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Armagan Tarim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1709865"
                        ],
                        "name": "S. Prestwich",
                        "slug": "S.-Prestwich",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Prestwich",
                            "middleNames": [
                                "David"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Prestwich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2204643,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2b0dea44f65f19f883e9708b20b8730306eb4e0f",
            "isKey": false,
            "numCitedBy": 131,
            "numCiting": 12,
            "paperAbstract": {
                "fragments": [],
                "text": "Stochastic Constraint Satisfaction Problems (SCSPs) are a powerful modeling framework for problems under uncertainty. To solve them is a P-Space task. The only solution approach to date compiles down SCSPs into classical CSPs. This allows the reuse of classical constraint solvers to solve SCSPs, but at the cost of increased space requirements and weak constraint propagation. This paper tries to overcome some of these drawbacks by automatically synthesizing filtering algorithms for global chance-constraints. These filtering algorithms are parameterized by propagators for the deterministic version of the chance-constraints. This approach allows the reuse of existing propagators in current constraint solvers and it enhances constraint propagation. Experiments show the benefits of this novel approach."
            },
            "slug": "Synthesizing-Filtering-Algorithms-for-Global-Hnich-Rossi",
            "title": {
                "fragments": [],
                "text": "Synthesizing Filtering Algorithms for Global Chance-Constraints"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This paper automatically synthesizes filtering algorithms for global chance-constraints that allow the reuse of existing propagators in current constraint solvers and it enhances constraint propagation."
            },
            "venue": {
                "fragments": [],
                "text": "CP"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48942559"
                        ],
                        "name": "E. Nudelman",
                        "slug": "E.-Nudelman",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Nudelman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Nudelman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388404060"
                        ],
                        "name": "Kevin Leyton-Brown",
                        "slug": "Kevin-Leyton-Brown",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Leyton-Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Leyton-Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2883187"
                        ],
                        "name": "Alex Devkar",
                        "slug": "Alex-Devkar",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Devkar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alex Devkar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701353"
                        ],
                        "name": "Y. Shoham",
                        "slug": "Y.-Shoham",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Shoham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Shoham"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 64,
                                "start": 52
                            }
                        ],
                        "text": "11 groups of SAT features; these were introduced in [28, 26, 29]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 75,
                                "start": 67
                            }
                        ],
                        "text": "Note that in contrast to per-instance approaches, such as SATzilla [28, 26], instance features are only needed for the training instances: the end result of algorithm configuration is a single parameter configuration that is used without a need to compute features for test instances."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 129
                            }
                        ],
                        "text": "Most notably, such predictions have been exploited to construct portfolio-based algorithm selection mechanisms, such as SATzilla [28, 26]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 120
                            }
                        ],
                        "text": "Most notably, such predictions have been exploited to construct portfolio-based algorithm selection mechanisms, such as SATzilla [20]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6487916,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "cdaaff55fd2f1b63f8952dbc9bf81e8f5e706357",
            "isKey": false,
            "numCitedBy": 204,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "It is well known that the ratio of the number of clauses to the number of variables in a random k-SAT instance is highly correlated with the instance's empirical hardness. We consider the problem of identifying such features of random SAT instances automatically using machine learning. We describe and analyze models for three SAT solvers - kcnfs, oksolver and satz - and for two different distributions of instances: uniform random 3-SAT with varying ratio of clauses-to-variables, and uniform random 3-SAT with fixed ratio of clauses-to-variables. We show that surprisingly accurate models can be built in all cases. Furthermore, we analyze these models to determine which features are most useful in predicting whether an instance will be hard to solve. Finally we discuss the use of our models to build SATzilla, an algorithm portfolio for SAT."
            },
            "slug": "Understanding-Random-SAT:-Beyond-the-Ratio-Nudelman-Leyton-Brown",
            "title": {
                "fragments": [],
                "text": "Understanding Random SAT: Beyond the Clauses-to-Variables Ratio"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work describes and analyzes models for three SAT solvers and for two different distributions of instances, showing that surprisingly accurate models can be built in all cases and determining which features are most useful in predicting whether an instance will be hard to solve."
            },
            "venue": {
                "fragments": [],
                "text": "CP"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1398717619"
                        ],
                        "name": "B. Adenso-D\u00edaz",
                        "slug": "B.-Adenso-D\u00edaz",
                        "structuredName": {
                            "firstName": "Belarmino",
                            "lastName": "Adenso-D\u00edaz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Adenso-D\u00edaz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144853029"
                        ],
                        "name": "M. Laguna",
                        "slug": "M.-Laguna",
                        "structuredName": {
                            "firstName": "Manuel",
                            "lastName": "Laguna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Laguna"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 2
                            }
                        ],
                        "text": ", [4, 5]), while others also target categorical (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 8902300,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "d2d9b1bf324a124d27bfa2cc79be039d26e926b9",
            "isKey": false,
            "numCitedBy": 427,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "Researchers and practitioners frequently spend more time fine-tuning algorithms than designing and implementing them. This is particularly true when developing heuristics and metaheuristics, where the right choice of values for search parameters has a considerable effect on the performance of the procedure. When testing metaheuristics, performance typically is measured considering both the quality of the solutions obtained and the time needed to find them. In this paper, we describe the development of CALIBRA, a procedure that attempts to find the best values for up to five search parameters associated with a procedure under study. Because CALIBRA uses Taguchis fractional factorial experimental designs coupled with a local search procedure, the best values found are not guaranteed to be optimal. We test CALIBRA on six existing heuristic-based procedures. These experiments show that CALIBRA is able to find parameter values that either match or improve the performance of the procedures resulting from using the parameter values suggested by their developers. The latest version of CALIBRA can be downloaded for free from the website that appears in the online supplement of this paper at http://or.pubs.informs.org/Pages.collect.html."
            },
            "slug": "Fine-Tuning-of-Algorithms-Using-Fractional-Designs-Adenso-D\u00edaz-Laguna",
            "title": {
                "fragments": [],
                "text": "Fine-Tuning of Algorithms Using Fractional Experimental Designs and Local Search"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The development of CALIBRA is described, a procedure that attempts to find the best values for up to five search parameters associated with a procedure under study and is able to find parameter values that either match or improve the performance of the procedures resulting from using the parameter values suggested by their developers."
            },
            "venue": {
                "fragments": [],
                "text": "Oper. Res."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1393588417"
                        ],
                        "name": "T. Bartz-Beielstein",
                        "slug": "T.-Bartz-Beielstein",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Bartz-Beielstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Bartz-Beielstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2565835"
                        ],
                        "name": "S. Markon",
                        "slug": "S.-Markon",
                        "structuredName": {
                            "firstName": "Sandor",
                            "lastName": "Markon",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Markon"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "SelectConfigurations returns a single configuration sampled uniformly at random from the parameter space, and Intensify is as described in Procedure 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 7041566,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9cee220298e83d4d04cce622067eac93b5552bff",
            "isKey": false,
            "numCitedBy": 84,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "The optimization of complex real-world problems might benefit from well tuned algorithm's parameters. We propose a methodology that performs this tuning in an effective and efficient algorithmical manner. This approach combines methods from statistical design of experiments, regression analysis, design and analysis of computer experiments methods, and tree-based regression. It can also be applied to analyze the influence of different operators or to compare the performance of different algorithms. An evolution strategy and a simulated annealing algorithm that optimize an elevator supervisory group controller system are used to demonstrate the applicability of our approach to real-world optimization problems."
            },
            "slug": "Tuning-search-algorithms-for-real-world-a-tree-Bartz-Beielstein-Markon",
            "title": {
                "fragments": [],
                "text": "Tuning search algorithms for real-world applications: a regression tree based approach"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This approach combines methods from statistical design of experiments, regression analysis, design and analysis of computer experiments methods, and tree-based regression to perform algorithmical tuning of parameters of well tuned algorithm."
            },
            "venue": {
                "fragments": [],
                "text": "Proceedings of the 2004 Congress on Evolutionary Computation (IEEE Cat. No.04TH8753)"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690903"
                        ],
                        "name": "M. Birattari",
                        "slug": "M.-Birattari",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Birattari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Birattari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145836976"
                        ],
                        "name": "Zhi Yuan",
                        "slug": "Zhi-Yuan",
                        "structuredName": {
                            "firstName": "Zhi",
                            "lastName": "Yuan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhi Yuan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "69372472"
                        ],
                        "name": "Prasanna Balaprakash",
                        "slug": "Prasanna-Balaprakash",
                        "structuredName": {
                            "firstName": "Prasanna",
                            "lastName": "Balaprakash",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Prasanna Balaprakash"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684799"
                        ],
                        "name": "T. St\u00fctzle",
                        "slug": "T.-St\u00fctzle",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "St\u00fctzle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. St\u00fctzle"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 4
                            }
                        ],
                        "text": "Our own group has used PARAMILS to configure highly parameterized tree search [10] and local search solvers [11] for the propositional satisfiability problem (SAT), as well as several solvers for mixed integer programming (MIP), substantially advancing the state of the art for various types of\u2026"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2769235,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2fae91efed5573379669d40d6e9ae9625a4a3861",
            "isKey": false,
            "numCitedBy": 380,
            "numCiting": 69,
            "paperAbstract": {
                "fragments": [],
                "text": "Algorithms for solving hard optimization problems typically have several parameters that need to be set appropriately such that some aspect of performance is optimized. In this chapter, we review F-Race, a racing algorithm for the task of automatic algorithm configuration. F-Race is based on a statistical approach for selecting the best configuration out of a set of candidate configurations under stochastic evaluations. We review the ideas underlying this technique and discuss an extension of the initial F-Race algorithm, which leads to a family of algorithms that we call iterated F-Race. Experimental results comparing one specific implementation of iterated F-Race to the original F-Race algorithm confirm the potential of this family of algorithms."
            },
            "slug": "F-Race-and-Iterated-F-Race:-An-Overview-Birattari-Yuan",
            "title": {
                "fragments": [],
                "text": "F-Race and Iterated F-Race: An Overview"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "This chapter reviews F-Race, a racing algorithm for the task of automatic algorithm configuration based on a statistical approach for selecting the best configuration out of a set of candidate configurations under stochastic evaluations and discusses an extension of this algorithm, which leads to a family of algorithms that are called iterated F- race."
            },
            "venue": {
                "fragments": [],
                "text": "Experimental Methods for the Analysis of Optimization Algorithms"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388404060"
                        ],
                        "name": "Kevin Leyton-Brown",
                        "slug": "Kevin-Leyton-Brown",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Leyton-Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Leyton-Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48942559"
                        ],
                        "name": "E. Nudelman",
                        "slug": "E.-Nudelman",
                        "structuredName": {
                            "firstName": "Eugene",
                            "lastName": "Nudelman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Nudelman"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701353"
                        ],
                        "name": "Y. Shoham",
                        "slug": "Y.-Shoham",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Shoham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Shoham"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 146,
                                "start": 142
                            }
                        ],
                        "text": "These general MIP features have been introduced in [11] as a generalization of features for the combinatorial winner determination problem in [30]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 14498800,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5580b7fda70be1dacb2d9424d13b5f0ca2cd51c8",
            "isKey": false,
            "numCitedBy": 207,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a new approach for understanding the algorithm-specific empiricalh ardness of NP-Hard problems. In this work we focus on the empirical hardness of the winner determination problem--an optimization problem arising in combinatorial auctions--when solved by ILOG's CPLEX software. We consider nine widely-used problem distributions and sample randomly from a continuum of parameter settings for each distribution. We identify a large number of distribution-nonspecific features of data instances and use statisticalregression techniques to learn, evaluate and interpret a function from these features to the predicted hardness of an instance."
            },
            "slug": "Learning-the-Empirical-Hardness-of-Optimization-The-Leyton-Brown-Nudelman",
            "title": {
                "fragments": [],
                "text": "Learning the Empirical Hardness of Optimization Problems: The Case of Combinatorial Auctions"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This work focuses on the empirical hardness of the winner determination problem--an optimization problem arising in combinatorial auctions--when solved by ILOG's CPLEX software."
            },
            "venue": {
                "fragments": [],
                "text": "CP"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1690903"
                        ],
                        "name": "M. Birattari",
                        "slug": "M.-Birattari",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Birattari",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Birattari"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1684799"
                        ],
                        "name": "T. St\u00fctzle",
                        "slug": "T.-St\u00fctzle",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "St\u00fctzle",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. St\u00fctzle"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2036913"
                        ],
                        "name": "L. Paquete",
                        "slug": "L.-Paquete",
                        "structuredName": {
                            "firstName": "Lu\u00eds",
                            "lastName": "Paquete",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Paquete"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1961192"
                        ],
                        "name": "Klaus Varrentrapp",
                        "slug": "Klaus-Varrentrapp",
                        "structuredName": {
                            "firstName": "Klaus",
                            "lastName": "Varrentrapp",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Klaus Varrentrapp"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 222
                            }
                        ],
                        "text": "F-RACE and its extensions have been used to optimize various high-performance algorithms, including iterated local search and ant colony optimization procedures for timetabling tasks and the travelling salesperson problem [6, 5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 41
                            }
                        ],
                        "text": ", discrete-valued and unordered) domains [6, 7, 8, 9]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 5194351,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "64247308dd5d534d37174feb6315043b233e49a8",
            "isKey": false,
            "numCitedBy": 597,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper describes a racing procedure for finding, in a limited amount of time, a configuration of a metaheuristic that performs as good as possible on a given instance class of a combinatorial optimization problem. Taking inspiration from methods proposed in the machine learning literature for model selection through cross-validation, we propose a procedure that empirically evaluates a set of candidate configurations by discarding bad ones as soon as statistically sufficient evidence is gathered against them. We empirically evaluate our procedure using as an example the configuration of an ant colony optimization algorithm applied to the traveling salesman problem. The experimental results show that our procedure is able to quickly reduce the number of candidates, and allows to focus on the most promising ones."
            },
            "slug": "A-Racing-Algorithm-for-Configuring-Metaheuristics-Birattari-St\u00fctzle",
            "title": {
                "fragments": [],
                "text": "A Racing Algorithm for Configuring Metaheuristics"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "A procedure that empirically evaluates a set of candidate configurations by discarding bad ones as soon as statistically sufficient evidence is gathered against them and allows to focus on the most promising ones is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "GECCO"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143854701"
                        ],
                        "name": "D. Tompkins",
                        "slug": "D.-Tompkins",
                        "structuredName": {
                            "firstName": "Dave",
                            "lastName": "Tompkins",
                            "middleNames": [
                                "A.",
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tompkins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 99,
                                "start": 95
                            }
                        ],
                        "text": "GGA did not benefit as much from being allowed to explore the full configuration space for the SAPS scenarios; however, in one of the SPEAR scenarios (SPEAR-IBM-MED), it did perform 1.15 times better for the full space (albeit still worse than SMAC)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 152,
                                "start": 148
                            }
                        ],
                        "text": "To enable a comparison with our previous SMBO instantiation TB-SPO, we used the 6 configuration scenarios introduced in [15], which aim to minimize SAPS\u2019s runtime on 6 single SAT-encoded instances, 3 each from quasigroup completion (QCP) and small world graph colouring (SWGCP)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 264,
                                "start": 260
                            }
                        ],
                        "text": "We considered a diverse set of 17 algorithm configuration problem instances (so-called configuration scenarios) that had been used previously to analyze PARAMILS [8, 1] and TB-SPO [15].8 These scenarios involve the configuration of the local search SAT solver SAPS (4 parameters), the tree search solver SPEAR (26 parameters), and the most widely used commercial mixed integer programming (MIP)\n7 This proof does not cover continuous parameters, since they lead to infinite configuration spaces; in that case, we would require additional smoothness assumptions to prove convergence."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "Comparing the left vs the right side of Table 1, we note that the SAPS discretization (the same we used to optimize SAPS with PARAMILS in previous work [7, 8]) left substantial room for improvement when exploring the full space: roughly 1.15-fold and 1.55-fold speedups on the QCP and SWGCP instances, respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 169,
                                "start": 165
                            }
                        ],
                        "text": "ROAR performed well for small but not for large configuration spaces: it was among the best (i.e., best or not significantly different from the best) in most of the SAPS scenarios (4 parameters) but only for one of the SPEAR scenarios (26 parameters)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 71,
                                "start": 67
                            }
                        ],
                        "text": "Both GGA and FOCUSEDILS performed slightly worse than ROAR for the SAPS scenarios, and slightly (but statistically significantly) worse than SMAC for most SPEAR configuration scenarios."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 196,
                                "start": 192
                            }
                        ],
                        "text": "In order to evaluate our new general algorithm configuration procedures ROAR and SMAC one component at a time, we first evaluated their performance for optimizing the continuous parameters of SAPS and the mixed numerical/categorical parameters of SPEAR on single SAT instances; multi-instance scenarios are studied in the next section."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 124,
                                "start": 120
                            }
                        ],
                        "text": "We used 17 configuration scenarios from the literature, involving the configuration of the local search SAT solver SAPS [32] (4 parameters), the tree search solver SPEAR [33] (26 parameters), and the most widely used commercial mixed integer programming solver, IBM ILOG CPLEX6 (76 parameters)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 17,
                                "start": 13
                            }
                        ],
                        "text": "Speedups for SAPS were similar to those observed in the single-instance case (about 1.15-fold for SAPS-QCP and 1.65-fold for SAPS-SWGCP), but now we also observed a 1.17-fold improvement for SPEAR-QCP."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 156,
                                "start": 152
                            }
                        ],
                        "text": "We now compare the performance of SMAC, ROAR, GGA, and FOCUSEDILS on six general algorithm configuration tasks that aim to minimize the mean runtime of SAPS, SPEAR, and CPLEX for various sets of instances."
                    },
                    "intents": []
                }
            ],
            "corpusId": 9775270,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1c2bf16428fa29cfb58e15f6c731e13e8c33d2bd",
            "isKey": false,
            "numCitedBy": 237,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we study the approach of dynamic local search for the SAT problem. We focus on the recent and promising Exponentiated Sub-Gradient (ESG) algorithm, and examine the factors determining the time complexity of its search steps. Basedon the insights gained from our analysis, we developed Scaling and Probabilistic Smoothing (SAPS), an efficient SAT algorithm that is conceptually closely related to ESG. We also introduce a reactive version of SAPS (RSAPS) that adaptively tunes one of the algorithm's important parameters. We show that for a broadra nge of standard benchmark problems for SAT, SAPS andR SAPS achieve significantly better performance than both ESG and the state-of-the-art WalkSAT variant, Novelty+."
            },
            "slug": "Scaling-and-Probabilistic-Smoothing:-Efficient-for-Hutter-Tompkins",
            "title": {
                "fragments": [],
                "text": "Scaling and Probabilistic Smoothing: Efficient Dynamic Local Search for SAT"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "Scaling and Probabilistic Smoothing (SAPS), an efficient SAT algorithm that is conceptually closely related to ESG, is developed, and a reactive version of SAPS (RSAPS) is introduced that adaptively tunes one of the algorithm's important parameters."
            },
            "venue": {
                "fragments": [],
                "text": "CP"
            },
            "year": 2002
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1393588417"
                        ],
                        "name": "T. Bartz-Beielstein",
                        "slug": "T.-Bartz-Beielstein",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Bartz-Beielstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Bartz-Beielstein"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2278193"
                        ],
                        "name": "C. Lasarczyk",
                        "slug": "C.-Lasarczyk",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Lasarczyk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lasarczyk"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1950379"
                        ],
                        "name": "M. Preuss",
                        "slug": "M.-Preuss",
                        "structuredName": {
                            "firstName": "Mike",
                            "lastName": "Preuss",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Preuss"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 37
                            }
                        ],
                        "text": "Despite considerable recent advances [13, 14, 15], all published work on SMBO still has three key limitations that prevent its use for general algorithm configuration tasks: (1) it only supports numerical parameters; (2) it only optimizes target algorithm performance for"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 22
                            }
                        ],
                        "text": "Previous SMBO methods [13, 14, 15] simply applied random sampling for this task (in particular, they evaluated EI for 10 000 random samples), which is unlikely to be sufficient in high-dimensional configuration spaces, especially if promising configurations are sparse."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[13] were the first to use the EGO approach to optimize algorithm performance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 6815175,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1a99e54554731bda87e72024bb58da8c902d9800",
            "isKey": false,
            "numCitedBy": 325,
            "numCiting": 63,
            "paperAbstract": {
                "fragments": [],
                "text": "Sequential parameter optimization is a heuristic that combines classical and modern statistical techniques to improve the performance of search algorithms. To demonstrate its flexibility, three scenarios are discussed: (1) no experience how to choose the parameter setting of an algorithm is available, (2) a comparison with other algorithms is needed, and (3) an optimization algorithm has to be applied effectively and efficiently to a complex real-world optimization problem. Although sequential parameter optimization relies on enhanced statistical techniques such as design and analysis of computer experiments, it can be performed algorithmically and requires basically the specification of the relevant algorithm's parameters"
            },
            "slug": "Sequential-parameter-optimization-Bartz-Beielstein-Lasarczyk",
            "title": {
                "fragments": [],
                "text": "Sequential parameter optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 53,
                "text": "Although sequential parameter optimization relies on enhanced statistical techniques such as design and analysis of computer experiments, it can be performed algorithmically and requires basically the specification of the relevant algorithm's parameters."
            },
            "venue": {
                "fragments": [],
                "text": "2005 IEEE Congress on Evolutionary Computation"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2118096690"
                        ],
                        "name": "Donald R. Jones",
                        "slug": "Donald-R.-Jones",
                        "structuredName": {
                            "firstName": "Donald",
                            "lastName": "Jones",
                            "middleNames": [
                                "R."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Donald R. Jones"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1815604"
                        ],
                        "name": "M. Schonlau",
                        "slug": "M.-Schonlau",
                        "structuredName": {
                            "firstName": "Matthias",
                            "lastName": "Schonlau",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Schonlau"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145228938"
                        ],
                        "name": "W. Welch",
                        "slug": "W.-Welch",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Welch",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Welch"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 2
                            }
                        ],
                        "text": ", [12]), SMBO has inherited a range of limitations inappropriate to the automated algorithm configuration setting."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[12], which is, however, limited to optimizing continuous parameters for noise-free functions (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "(EI(\u03b8)) [12] over the best configuration seen so far (the incumbent)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 13068209,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "daa63f57c3fbe994c4356f8d986a22e696e776d2",
            "isKey": true,
            "numCitedBy": 5764,
            "numCiting": 51,
            "paperAbstract": {
                "fragments": [],
                "text": "In many engineering optimization problems, the number of function evaluations is severely limited by time or cost. These problems pose a special challenge to the field of global optimization, since existing methods often require more function evaluations than can be comfortably afforded. One way to address this challenge is to fit response surfaces to data collected by evaluating the objective and constraint functions at a few points. These surfaces can then be used for visualization, tradeoff analysis, and optimization. In this paper, we introduce the reader to a response surface methodology that is especially good at modeling the nonlinear, multimodal functions that often occur in engineering. We then show how these approximating functions can be used to construct an efficient global optimization algorithm with a credible stopping rule. The key to using response surfaces for global optimization lies in balancing the need to exploit the approximating surface (by sampling where it is minimized) with the need to improve the approximation (by sampling where prediction error may be high). Striking this balance requires solving certain auxiliary problems which have previously been considered intractable, but we show how these computational obstacles can be overcome."
            },
            "slug": "Efficient-Global-Optimization-of-Expensive-Jones-Schonlau",
            "title": {
                "fragments": [],
                "text": "Efficient Global Optimization of Expensive Black-Box Functions"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper introduces the reader to a response surface methodology that is especially good at modeling the nonlinear, multimodal functions that often occur in engineering and shows how these approximating functions can be used to construct an efficient global optimization algorithm with a credible stopping rule."
            },
            "venue": {
                "fragments": [],
                "text": "J. Glob. Optim."
            },
            "year": 1998
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143854701"
                        ],
                        "name": "D. Tompkins",
                        "slug": "D.-Tompkins",
                        "structuredName": {
                            "firstName": "Dave",
                            "lastName": "Tompkins",
                            "middleNames": [
                                "A.",
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Tompkins"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3118503,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2a9a0c587df01ea7b78d0356592f19846b797fa1",
            "isKey": false,
            "numCitedBy": 190,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we introduce UBCSAT, a new implementation and experimentation environment for Stochastic Local Search (SLS) algorithms for SAT and MAX-SAT. Based on a novel triggered procedure architecture, UBCSAT provides implementations of numerous well-known and widely used SLS algorithms for SAT and MAX-SAT, including GSAT, WalkSAT, and SAPS; these implementations generally match or exceed the efficiency of the respective original reference implementations. Through numerous reporting and statistical features, including the measurement of run-time distributions, UBCSAT facilitates the advanced empirical analysis of these algorithms. New algorithm variants, SLS algorithms, and reporting features can be added to UBCSAT in a straightforward and efficient way. UBCSAT is implemented in C and runs on numerous platforms and operating systems; it is publicly and freely available at www.satlib.org/ubcsat."
            },
            "slug": "UBCSAT:-An-Implementation-and-Experimentation-for-&-Tompkins-Hoos",
            "title": {
                "fragments": [],
                "text": "UBCSAT: An Implementation and Experimentation Environment for SLS Algorithms for SAT & MAX-SAT"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "UBCSAT provides implementations of numerous well-known and widely used SLS algorithms for SAT and MAX-SAT, including GSAT, WalkS AT, and SAPS; these implementations generally match or exceed the efficiency of the respective original reference implementations."
            },
            "venue": {
                "fragments": [],
                "text": "SAT"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2107327555"
                        ],
                        "name": "D. Huang",
                        "slug": "D.-Huang",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Huang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Huang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "115429409"
                        ],
                        "name": "T. Allen",
                        "slug": "T.-Allen",
                        "structuredName": {
                            "firstName": "Theodore",
                            "lastName": "Allen",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Allen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50238440"
                        ],
                        "name": "W. Notz",
                        "slug": "W.-Notz",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Notz",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Notz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2065868465"
                        ],
                        "name": "N. Zheng",
                        "slug": "N.-Zheng",
                        "structuredName": {
                            "firstName": "Ning",
                            "lastName": "Zheng",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Zheng"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 227,
                                "start": 223
                            }
                        ],
                        "text": "\u2026\u03c0\u2032\u2032 \u2208 \u03a0} 5 \u03c0 \u2190 instance sampled uniformly at random from \u03a0 \u2032 6 s\u2190 seed, drawn uniformly at random 7 R\u2190 ExecuteRun(R, \u03b8inc, \u03c0, s) 8 N \u2190 1 9 while true do\n10 Smissing \u2190 \u3008instance, seed\u3009 pairs for which \u03b8inc was run before, but not \u03b8new 11 Storun \u2190random subset of Smissing of size min(N, |Smissing"
                    },
                    "intents": []
                }
            ],
            "corpusId": 14688276,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "0c51104c58c3e05f487d87ee94ce2e3b2d11dce6",
            "isKey": false,
            "numCitedBy": 584,
            "numCiting": 70,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a new method that extends the efficient global optimization to address stochastic black-box systems. The method is based on a kriging meta-model that provides a global prediction of the objective values and a measure of prediction uncertainty at every point. The criterion for the infill sample selection is an augmented expected improvement function with desirable properties for stochastic responses. The method is empirically compared with the revised simplex search, the simultaneous perturbation stochastic approximation, and the DIRECT methods using six test problems from the literature. An application case study on an inventory system is also documented. The results suggest that the proposed method has excellent consistency and efficiency in finding global optimal solutions, and is particularly useful for expensive systems."
            },
            "slug": "Global-Optimization-of-Stochastic-Black-Box-Systems-Huang-Allen",
            "title": {
                "fragments": [],
                "text": "Global Optimization of Stochastic Black-Box Systems via Sequential Kriging Meta-Models"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "The proposed method is based on a kriging meta-model that provides a global prediction of the objective values and a measure of prediction uncertainty at every point and has excellent consistency and efficiency in finding global optimal solutions."
            },
            "venue": {
                "fragments": [],
                "text": "J. Glob. Optim."
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2170858"
                        ],
                        "name": "C. Ans\u00f3tegui",
                        "slug": "C.-Ans\u00f3tegui",
                        "structuredName": {
                            "firstName": "Carlos",
                            "lastName": "Ans\u00f3tegui",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Ans\u00f3tegui"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687333"
                        ],
                        "name": "Meinolf Sellmann",
                        "slug": "Meinolf-Sellmann",
                        "structuredName": {
                            "firstName": "Meinolf",
                            "lastName": "Sellmann",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Meinolf Sellmann"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143780836"
                        ],
                        "name": "Kevin Tierney",
                        "slug": "Kevin-Tierney",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Tierney",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Tierney"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 38
                            }
                        ],
                        "text": "We note that in a previous comparison [9] of GGA and FOCUSEDILS, capping was disabled in FOCUSEDILS; this explains its poor performance there and its better performance here."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 49
                            }
                        ],
                        "text": "A recent competitor is the genetic algorithm GGA [9]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 53,
                                "start": 41
                            }
                        ],
                        "text": ", discrete-valued and unordered) domains [6, 7, 8, 9]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 340,
                                "start": 337
                            }
                        ],
                        "text": "In a thorough experimental analysis for a wide range of 17 scenarios with small captimes (involving the optimization of local search and tree search SAT solvers, as well as the commercial MIP solver CPLEX), SMAC indeed compared favourably to the two most prominent approaches for general algorithm configuration: PARAMILS [7, 8] and GGA [9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 66,
                                "start": 63
                            }
                        ],
                        "text": "We now compare the performance of SMAC, ROAR, TB-SPO [15], GGA [9], and PARAMILS (in particular, FOCUSEDILS 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15810538,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "997dd6c2d49f6d89a4f9b28729163dc18549f3d3",
            "isKey": true,
            "numCitedBy": 332,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "A problem that is inherent to the development and efficient use of solvers is that of tuning parameters. The CP community has a long history of addressing this task automatically. We propose a robust, inherently parallel genetic algorithm for the problem of configuring solvers automatically. In order to cope with the high costs of evaluating the fitness of individuals, we introduce a gender separation whereby we apply different selection pressure on both genders. Experimental results on a selection of SAT solvers show significant performance and robustness gains over the current state-of-the-art in automatic algorithm configuration."
            },
            "slug": "A-Gender-Based-Genetic-Algorithm-for-the-Automatic-Ans\u00f3tegui-Sellmann",
            "title": {
                "fragments": [],
                "text": "A Gender-Based Genetic Algorithm for the Automatic Configuration of Algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "A robust, inherently parallel genetic algorithm is proposed for the problem of configuring solvers automatically and a gender separation is introduced to cope with the high costs of evaluating the fitness of individuals."
            },
            "venue": {
                "fragments": [],
                "text": "CP"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2771092"
                        ],
                        "name": "S. Coy",
                        "slug": "S.-Coy",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Coy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Coy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761717"
                        ],
                        "name": "B. Golden",
                        "slug": "B.-Golden",
                        "structuredName": {
                            "firstName": "Bruce",
                            "lastName": "Golden",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Golden"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2426318"
                        ],
                        "name": "G. Runger",
                        "slug": "G.-Runger",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Runger",
                            "middleNames": [
                                "C."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Runger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1807684"
                        ],
                        "name": "E. Wasil",
                        "slug": "E.-Wasil",
                        "structuredName": {
                            "firstName": "Edward",
                            "lastName": "Wasil",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Wasil"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 116,
                                "start": 113
                            }
                        ],
                        "text": "Some methods focus on optimizing numerical (i.e., either integer- or real-valued) parameters (see, e.g., [4, 5]), while others also target categorical (i.e., discrete-valued and unordered) domains [6, 7, 8, 9]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 3117668,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "14584c9dbac190c4e7d05d3d8cb1b3e1ccef9fb2",
            "isKey": false,
            "numCitedBy": 237,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper, we propose a procedure, based on statistical design of experiments and gradient descent, that finds effective settings for parameters found in heuristics. We develop our procedure using four experiments. We use our procedure and a small subset of problems to find parameter settings for two new vehicle routing heuristics. We then set the parameters of each heuristic and solve 19 capacity-constrained and 15 capacity-constrained and route-length-constrained vehicle routing problems ranging in size from 50 to 483 customers. We conclude that our procedure is an effective method that deserves serious consideration by both researchers and operations research practitioners."
            },
            "slug": "Using-Experimental-Design-to-Find-Effective-for-Coy-Golden",
            "title": {
                "fragments": [],
                "text": "Using Experimental Design to Find Effective Parameter Settings for Heuristics"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "A procedure, based on statistical design of experiments and gradient descent, that finds effective settings for parameters found in heuristics that deserves serious consideration by both researchers and operations research practitioners is proposed."
            },
            "venue": {
                "fragments": [],
                "text": "J. Heuristics"
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145438097"
                        ],
                        "name": "J. Gratch",
                        "slug": "J.-Gratch",
                        "structuredName": {
                            "firstName": "J.",
                            "lastName": "Gratch",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Gratch"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1802807"
                        ],
                        "name": "G. DeJong",
                        "slug": "G.-DeJong",
                        "structuredName": {
                            "firstName": "Gerald",
                            "lastName": "DeJong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. DeJong"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 43
                            }
                        ],
                        "text": "This research goes back to the early 1990s [2, 3] and has lately been gaining momentum."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 9870367,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d6ffb023aa22682afefc096142dd6fac51da4c3",
            "isKey": false,
            "numCitedBy": 104,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "In machine learning there is considerable interest in techniques which improve planning ability. Initial investigations have identified a wide variety of techniques to address this issue. Progress has been hampered by the utility problem, a basic tradeoff between the benefit of learned knowledge and the cost to locate and apply relevant knowledge. In this paper we describe the COMPOSER system which embodies a probabilistic solution to the utility problem. We outline the statistical foundations of our approach and compare it against four other approaches which appear in the literature."
            },
            "slug": "COMPOSER:-A-Probabilistic-Solution-to-the-Utility-Gratch-DeJong",
            "title": {
                "fragments": [],
                "text": "COMPOSER: A Probabilistic Solution to the Utility Problem in Speed-Up Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "The COMPOSER system is described, which embodies a probabilistic solution to the utility problem, and the statistical foundations of the approach are outlined and it is compared against four other approaches which appear in the literature."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144661829"
                        ],
                        "name": "F. Hutter",
                        "slug": "F.-Hutter",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Hutter",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Hutter"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388404060"
                        ],
                        "name": "Kevin Leyton-Brown",
                        "slug": "Kevin-Leyton-Brown",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Leyton-Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Leyton-Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2056417995"
                        ],
                        "name": "K. Murphy",
                        "slug": "K.-Murphy",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Murphy",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Murphy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 49,
                                "start": 37
                            }
                        ],
                        "text": "Despite considerable recent advances [13, 14, 15], all published work on SMBO still has three key limitations that prevent its use for general algorithm configuration tasks: (1) it only supports numerical parameters; (2) it only optimizes target algorithm performance for"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "Specifically, we use the E[Iexp] criterion introduced in [14] for log-transformed costs; given the predictive mean \u03bc\u03b8 and variance \u03c3(2) \u03b8 of the log-transformed cost of a configuration \u03b8, this is defined as"
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 159,
                                "start": 155
                            }
                        ],
                        "text": "We studied the components of this automated procedure, demonstrated that its intensification mechanism mattered most, and improved it in our SPO algorithm [14]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 34,
                                "start": 22
                            }
                        ],
                        "text": "Previous SMBO methods [13, 14, 15] simply applied random sampling for this task (in particular, they evaluated EI for 10 000 random samples), which is unlikely to be sufficient in high-dimensional configuration spaces, especially if promising configurations are sparse."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1863673,
            "fieldsOfStudy": [
                "Business"
            ],
            "id": "eaa44ec117af3e45ffedd0028b3cc208469ab50f",
            "isKey": false,
            "numCitedBy": 96,
            "numCiting": 28,
            "paperAbstract": {
                "fragments": [],
                "text": "This work experimentally investigates model-based approaches for optimising the performance of parameterised randomised algorithms. We restrict our attention to procedures based on Gaussian process models, the most widely-studied family of models for this problem. We evaluated two approaches from the literature, and found that sequential parameter optimisation (SPO) [4] offered the most robust performance. We then investigated key design decisions within the SPO paradigm, characterising the performance consequences of each. Based on these findings, we propose a new version of SPO, dubbed SPO+, which extends SPO with a novel intensification procedure and log-transformed response values. Finally, in a domain for which performance results for other (model-free) parameter optimisation approaches are available, we demonstrate that SPO+ achieves state-of-the-art performance."
            },
            "slug": "An-experimental-investigation-of-model-based-SPO-Hutter-Hoos",
            "title": {
                "fragments": [],
                "text": "An experimental investigation of model-based parameter optimisation: SPO and beyond"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A new version of SPO is proposed, dubbed SPO+, which extends SPO with a novel intensification procedure and log-transformed response values, and it is demonstrated that SPO+ achieves state-of-the-art performance."
            },
            "venue": {
                "fragments": [],
                "text": "GECCO"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3014279"
                        ],
                        "name": "E. Zarpas",
                        "slug": "E.-Zarpas",
                        "structuredName": {
                            "firstName": "Emmanuel",
                            "lastName": "Zarpas",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "E. Zarpas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 204,
                                "start": 200
                            }
                        ],
                        "text": "We also used 5 similar new configuration scenarios, which aim to optimize SPEAR for 5 further SAT-encoded instances: 3 from software verification (SWV [37]) and 2 from IBM bounded model checking (IBM [38]; we only used 2 low quantiles of this hard distribution since SPEAR could not solve the instance at the 75% quantile within the cutoff time)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 18724746,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "28f4bdd0ddb49a11ad80bbbe2878f497625ff3c4",
            "isKey": false,
            "numCitedBy": 36,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "Modern SAT solvers are highly dependent on heuristics. Therefore, benchmarking is of prime importance in evaluating the performances of different solvers. However, relevant benchmarking is not necessarily straightforward. We present our experiments using the IBM CNF Benchmark on several SAT solvers. Using the results, we attempt to define guidelines for a relevant benchmarking methodology, using SAT solvers for real life BMC applications."
            },
            "slug": "Benchmarking-SAT-Solvers-for-Bounded-Model-Checking-Zarpas",
            "title": {
                "fragments": [],
                "text": "Benchmarking SAT Solvers for Bounded Model Checking"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work attempts to define guidelines for a relevant benchmarking methodology, using SAT solvers for real life BMC applications, using the IBM CNF Benchmark on several SATsolvers."
            },
            "venue": {
                "fragments": [],
                "text": "SAT"
            },
            "year": 2005
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50238440"
                        ],
                        "name": "W. Notz",
                        "slug": "W.-Notz",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Notz",
                            "middleNames": [
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Notz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2011917"
                        ],
                        "name": "T. Santner",
                        "slug": "T.-Santner",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Santner",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Santner"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "50475322"
                        ],
                        "name": "B. Williams",
                        "slug": "B.-Williams",
                        "structuredName": {
                            "firstName": "Brian",
                            "lastName": "Williams",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 128,
                                "start": 124
                            }
                        ],
                        "text": "For GP models, there exists an approach from the statistics literature to predict mean performance across problem instances [20]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 131,
                                "start": 127
                            }
                        ],
                        "text": "Follow-up work in the statistics community included an approach to optimize functions across multiple environmental conditions [20] as well as the sequential kriging optimization (SKO) algorithm for handling noisy functions (i."
                    },
                    "intents": []
                }
            ],
            "corpusId": 10069227,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9ef6e6f619e84ceb990fa62a3f57548b02c14c3a",
            "isKey": false,
            "numCitedBy": 184,
            "numCiting": 46,
            "paperAbstract": {
                "fragments": [],
                "text": "In the last ten to fifteen years many phenomena that could be studied only using physical experiments can now be studied by computer experiments. Advances in the mathematical modeling of many physical processes, in algorithms for solving mathematical systems, and in computer speeds, have combined to make it possible to augment or replace physical experiments with computer experiments. In a computer experiment, a response z( x), usually deterministic, is computed for each set of input variables, x, according to an experimental design strategy. This strategy is determined by the goal of the experiment and depends, for example, on whether response prediction at unsampled input sites or response optimization is of primary interest. \nWe are concerned with the commonly occuring situation in which there are two types of input variables: suppose x = ( xc, x e) where xc is a set of \u201ccontrol\u201d (manufacturing) variables and xe is a set of \u201cenvironmental\u201d (noise) variables. Manufacturing variables can be controlled while noise variables are not controllable but have values governed by some probability distribution. \nFor single response settings, we introduce a sequential experimental design for finding the optimum of e(x c) = E[z(x c, Xe)], where the expectation is taken over the distribution of the environmental variables. For bivariate response settings, we introduce a sequential experimental design for finding the constrained optimum of e1( xc)) = E[z( xc, X e)], subject to e2 (x c) = E[z2(x c, Xe)] \u2264 U. The approach is Bayesian; the prior information is that the responses are a draw from a stationary Gaussian stochastic process with correlation function belonging to a parametric family with unknown parameters. The idea of the methods is to compute the posterior expected \u201cimprovement\u201d over the current optimum for each untested site; the design selects the next site to maximize the expected improvement. Both procedures are illustrated by examples utilizing test functions from the numerical optimization literature."
            },
            "slug": "Sequential-design-of-computer-experiments-to-Notz-Santner",
            "title": {
                "fragments": [],
                "text": "Sequential design of computer experiments to minimize integrated response functions"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "The idea of the methods is to compute the posterior expected \u201cimprovement\u201d over the current optimum for each untested site; the design selects the next site to maximize the expected improvement."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1692083"
                        ],
                        "name": "K. Etessami",
                        "slug": "K.-Etessami",
                        "structuredName": {
                            "firstName": "Kousha",
                            "lastName": "Etessami",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Etessami"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1748179"
                        ],
                        "name": "M. Yannakakis",
                        "slug": "M.-Yannakakis",
                        "structuredName": {
                            "firstName": "Mihalis",
                            "lastName": "Yannakakis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Yannakakis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14287817,
            "fieldsOfStudy": [
                "Mathematics",
                "Computer Science"
            ],
            "id": "3939ab4498e35f8404fddbe42ae5bb1d4e62258f",
            "isKey": false,
            "numCitedBy": 484,
            "numCiting": 108,
            "paperAbstract": {
                "fragments": [],
                "text": "We define Recursive Markov Chains (RMCs), a class of finitely presented denumerable Markov chains, and we study algorithms for their analysis. Informally, an RMC consists of a collection of finite-state Markov chains with the ability to invoke each other in a potentially recursive manner. RMCs offer a natural abstract model for probabilistic programs with procedures. They generalize, in a precise sense, a number of well-studied stochastic models, including Stochastic Context-Free Grammars (SCFG) and Multi-Type Branching Processes (MT-BP).\n We focus on algorithms for reachability and termination analysis for RMCs: what is the probability that an RMC started from a given state reaches another target state, or that it terminates? These probabilities are in general irrational, and they arise as (least) fixed point solutions to certain (monotone) systems of nonlinear equations associated with RMCs. We address both the qualitative problem of determining whether the probabilities are 0, 1 or in-between, and the quantitative problems of comparing the probabilities with a given bound, or approximating them to desired precision.\n We show that all these problems can be solved in PSPACE using a decision procedure for the Existential Theory of Reals. We provide a more practical algorithm, based on a decomposed version of multi-variate Newton's method, and prove that it always converges monotonically to the desired probabilities. We show this method applies more generally to any monotone polynomial system. We obtain polynomial-time algorithms for various special subclasses of RMCs. Among these: for SCFGs and MT-BPs (equivalently, for 1-exit RMCs) the qualitative problem can be solved in P-time; for linearly recursive RMCs the probabilities are rational and can be computed exactly in P-time.\n We show that our PSPACE upper bounds cannot be substantially improved without a breakthrough on long standing open problems: the square-root sum problem and an arithmetic circuit decision problem that captures P-time on the unit-cost rational arithmetic RAM model. We show that these problems reduce to the qualitative problem and to the approximation problem (to within any nontrivial error) for termination probabilities of general RMCs, and to the quantitative decision problem for termination (extinction) of SCFGs (MT-BPs)."
            },
            "slug": "Recursive-Markov-chains,-stochastic-grammars,-and-Etessami-Yannakakis",
            "title": {
                "fragments": [],
                "text": "Recursive Markov chains, stochastic grammars, and monotone systems of nonlinear equations"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown that the PSPACE upper bounds cannot be substantially improved without a breakthrough on long standing open problems: the square-root sum problem and an arithmetic circuit decision problem that captures P-time on the unit-cost rational arithmetic RAM model."
            },
            "venue": {
                "fragments": [],
                "text": "JACM"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1388404060"
                        ],
                        "name": "Kevin Leyton-Brown",
                        "slug": "Kevin-Leyton-Brown",
                        "structuredName": {
                            "firstName": "Kevin",
                            "lastName": "Leyton-Brown",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kevin Leyton-Brown"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053221855"
                        ],
                        "name": "Mark Pearson",
                        "slug": "Mark-Pearson",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Pearson",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Pearson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701353"
                        ],
                        "name": "Y. Shoham",
                        "slug": "Y.-Shoham",
                        "structuredName": {
                            "firstName": "Yoav",
                            "lastName": "Shoham",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Y. Shoham"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 186,
                                "start": 182
                            }
                        ],
                        "text": "These instances come from the following domains: quasigroup completion, QCP [35]; small world graph colouring, SWGCP [36]; winner determination in combinatorial auctions, REGIONS100 [39]; mixed integer knapsack, MIK [40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 6114062,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "102edd6b6ec078daa064ec8bda142aa7bc60431d",
            "isKey": false,
            "numCitedBy": 413,
            "numCiting": 27,
            "paperAbstract": {
                "fragments": [],
                "text": "General combinatorial auctions\u2014auctions in which bidders place unrestricted bids for bundles of goods\u2014are the subject of increasing study. Much of this work has focused on algorithms for finding an optimal or approximately optimal set of winning bids. Comparatively little attention has been paid to methodical evaluation and comparison of these algorithms. In particular, there has not been a systematic discussion of appropriate data sets that can serve as universally accepted and well motivated benchmarks. In this paper we present a suite of distribution families for generating realistic, economically motivated combinatorial bids in five broad real-world domains. We hope that this work will yield many comments, criticisms and extensions, bringing the community closer to a universal combinatorial auction test suite."
            },
            "slug": "Towards-a-universal-test-suite-for-combinatorial-Leyton-Brown-Pearson",
            "title": {
                "fragments": [],
                "text": "Towards a universal test suite for combinatorial auction algorithms"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This paper presents a suite of distribution families for generating realistic, economically motivated combinatorial bids in five broad real-world domains, and hopes that this work will yield many comments, criticisms and extensions, bringing the community closer to a universal combinatorsial auction test suite."
            },
            "venue": {
                "fragments": [],
                "text": "EC '00"
            },
            "year": 2000
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "52531606"
                        ],
                        "name": "Babi\u0107 Domagoj",
                        "slug": "Babi\u0107-Domagoj",
                        "structuredName": {
                            "firstName": "Babi\u0107",
                            "lastName": "Domagoj",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Babi\u0107 Domagoj"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 56628722,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e3fbb73f4bf4ad228d8312b6a87f14ce82cc9a98",
            "isKey": false,
            "numCitedBy": 35,
            "numCiting": 107,
            "paperAbstract": {
                "fragments": [],
                "text": "Software bugs are expensive. Recent estimates by the US National Institute of Standards and Technology claim that the cost of software bugs to the US economy alone is approximately 60 billion USD annually. As society becomes increasingly software-dependent, bugs also reduce our productivity and threaten our safety and security. Decreasing these direct and indirect costs represents a significant research challenge as well as an opportunity for businesses. Automatic software bug-finding and verification tools have a potential to completely revolutionize the software engineering industry by improving reliability and decreasing development costs. Since software analysis is in general undecidable, automatic tools have to use various abstractions to make the analysis computationally tractable. Abstraction is a double-edged sword: coarse abstractions, in general, yield easier verification, but also less precise results. This thesis focuses on exploiting the structure of software for abstracting away irrelevant behavior. Programmers tend to organize code into objects and functions, which effectively represent natural abstraction boundaries. Humans use such structural abstractions to simplify their mental models of software and for constructing informal explanations of why a piece of code should work. A natural question to ask is: How can automatic bug-finding tools exploit the same natural abstractions? This thesis offers possible answers. More specifically, I present three novel ways to exploit structure at three different steps of the software analysis process. First, I show how symbolic execution can preserve the data-flow dependencies of the original code while constructing compact symbolic representations of programs. Second, I propose 1For details, see [1]."
            },
            "slug": "Exploiting-structure-for-scalable-software-Domagoj",
            "title": {
                "fragments": [],
                "text": "Exploiting structure for scalable software verification"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Three novel ways to exploit structure at three different steps of the software analysis process are presented, showing how symbolic execution can preserve the data-flow dependencies of the original code while constructing compact symbolic representations of programs."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2008
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35250057"
                        ],
                        "name": "D. Babic",
                        "slug": "D.-Babic",
                        "structuredName": {
                            "firstName": "Domagoj",
                            "lastName": "Babic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Babic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1741933"
                        ],
                        "name": "A. Hu",
                        "slug": "A.-Hu",
                        "structuredName": {
                            "firstName": "Alan",
                            "lastName": "Hu",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Hu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 1649108,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "c4779792130b50e3739438df86bd52317f6abca8",
            "isKey": false,
            "numCitedBy": 75,
            "numCiting": 34,
            "paperAbstract": {
                "fragments": [],
                "text": "Precise software analysis and verification require tracking the exact path along which a statement is executed (path-sensitivity), the different contexts from which a function is called (context-sensitivity), and the bit-accurate operations performed. Previously, verification with such precision has been considered too inefficient to scale to large software. In this paper, we present a novel approach to solving such verification conditions, based on an automatic abstraction-checking-refinement framework that exploits natural abstraction boundaries present in software. Experimental results show that our approach easily scales to over 200,000 lines of real C/C++ code."
            },
            "slug": "Structural-Abstraction-of-Software-Verification-Babic-Hu",
            "title": {
                "fragments": [],
                "text": "Structural Abstraction of Software Verification Conditions"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "A novel approach to solving verification conditions, based on an automatic abstraction-checking-refinement framework that exploits natural abstraction boundaries present in software, is presented."
            },
            "venue": {
                "fragments": [],
                "text": "CAV"
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33923775"
                        ],
                        "name": "M. Baz",
                        "slug": "M.-Baz",
                        "structuredName": {
                            "firstName": "Mustafa",
                            "lastName": "Baz",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Baz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39914721"
                        ],
                        "name": "Brady Hunsaker",
                        "slug": "Brady-Hunsaker",
                        "structuredName": {
                            "firstName": "Brady",
                            "lastName": "Hunsaker",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Brady Hunsaker"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [],
                        "text": "SelectConfigurations returns a single configuration sampled uniformly at random from the parameter space, and Intensify is as described in Procedure 2."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16050697,
            "fieldsOfStudy": [
                "Materials Science"
            ],
            "id": "dfe1774fc1be81fc62ad489a96ce4f24fc0714ab",
            "isKey": false,
            "numCitedBy": 24,
            "numCiting": 14,
            "paperAbstract": {
                "fragments": [],
                "text": "Mustafa Baz, Brady Hunsaker Department of Industrial Engineering, University of Pittsburgh, 1048 Benedum Hall, Pittsburgh, PA 15261, USA, {mub3@pitt.edu, hunsaker@engr.pitt.edu} J. Paul Brooks Department of Statistical Sciences and Operations Research, Virginia Commonwealth University, Richmond, VA 23284, USA, jpbrooks@vcu.edu Abhijit Gosavi Department of Industrial & Systems Engineering, University at Buffalo, State University of New York, Buffalo, NY 14260, USA, agosavi@buffalo.edu"
            },
            "slug": "Automated-Tuning-of-Optimization-Software-Baz-Hunsaker",
            "title": {
                "fragments": [],
                "text": "Automated Tuning of Optimization Software Parameters"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2007
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2953896"
                        ],
                        "name": "Alper Atamt\u00fcrk",
                        "slug": "Alper-Atamt\u00fcrk",
                        "structuredName": {
                            "firstName": "Alper",
                            "lastName": "Atamt\u00fcrk",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alper Atamt\u00fcrk"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 220,
                                "start": 216
                            }
                        ],
                        "text": "These instances come from the following domains: quasigroup completion, QCP [35]; small world graph colouring, SWGCP [36]; winner determination in combinatorial auctions, REGIONS100 [39]; mixed integer knapsack, MIK [40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14683451,
            "fieldsOfStudy": [
                "Mathematics"
            ],
            "id": "4421a6d4840d9047accc1e1c80bf36f97689c8f9",
            "isKey": false,
            "numCitedBy": 111,
            "numCiting": 42,
            "paperAbstract": {
                "fragments": [],
                "text": "Abstract.We study the mixed\u2013integer knapsack polyhedron, that is, the convex hull of the mixed\u2013integer set defined by an arbitrary linear inequality and the bounds on the variables. We describe facet\u2013defining inequalities of this polyhedron that can be obtained through sequential lifting of inequalities containing a single integer variable. These inequalities strengthen and/or generalize known inequalities for several special cases. We report computational results on using the inequalities as cutting planes for mixed\u2013integer programming."
            },
            "slug": "On-the-facets-of-the-mixed\u2013integer-knapsack-Atamt\u00fcrk",
            "title": {
                "fragments": [],
                "text": "On the facets of the mixed\u2013integer knapsack polyhedron"
            },
            "tldr": {
                "abstractSimilarityScore": 47,
                "text": "Facet\u2013defining inequalities of this polyhedron are described that can be obtained through sequential lifting of inequalities containing a single integer variable that strengthen and/or generalize known inequalities for several special cases."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Program."
            },
            "year": 2003
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3472959"
                        ],
                        "name": "C. Rasmussen",
                        "slug": "C.-Rasmussen",
                        "structuredName": {
                            "firstName": "Carl",
                            "lastName": "Rasmussen",
                            "middleNames": [
                                "Edward"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Rasmussen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145715698"
                        ],
                        "name": "Christopher K. I. Williams",
                        "slug": "Christopher-K.-I.-Williams",
                        "structuredName": {
                            "firstName": "Christopher",
                            "lastName": "Williams",
                            "middleNames": [
                                "K.",
                                "I."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christopher K. I. Williams"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 205,
                                "start": 201
                            }
                        ],
                        "text": "EI(\u03b8) is large for configurations \u03b8 with low predicted cost and for those with high predicted uncertainty; thereby, it offers an automatic tradeoff between exploitation (focusing on known good parts of the space) and exploration (gathering more information in unknown parts of the space)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 110
                            }
                        ],
                        "text": "In principle, our ROAR and SMAC methods also apply to optimizing other cost metrics, such as the solution quality an algorithm can achieve in a fixed time budget; we plan on studying their empirical performance for this case in the near future."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 170,
                                "start": 166
                            }
                        ],
                        "text": "\u2026(SPO) toolbox\u2014which has received considerable attention in the evolutionary algorithms community\u2014provides many features that facilitate the manual analysis and optimization of algorithm parameters; it also includes an automated SMBO procedure for optimizing numerical parameters on single instances."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 1430472,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "82266f6103bade9005ec555ed06ba20b5210ff22",
            "isKey": true,
            "numCitedBy": 18076,
            "numCiting": 231,
            "paperAbstract": {
                "fragments": [],
                "text": "Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received growing attention in the machine learning community over the past decade. The book provides a long-needed, systematic and unified treatment of theoretical and practical aspects of GPs in machine learning. The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics. The book deals with the supervised learning problem for both regression and classification, and includes detailed algorithms. A wide variety of covariance (kernel) functions are presented and their properties discussed. Model selection is discussed both from a Bayesian and classical perspective. Many connections to other well-known techniques from machine learning and statistics are discussed, including support vector machines, neural networks, splines, regularization networks, relevance vector machines and others. Theoretical issues including learning curves and the PAC-Bayesian framework are treated, and several approximation methods for learning with large datasets are discussed. The book contains illustrative examples and exercises. Code and datasets can be obtained on the web. Appendices provide mathematical background and a discussion of Gaussian Markov processes."
            },
            "slug": "Gaussian-Processes-for-Machine-Learning-Rasmussen-Williams",
            "title": {
                "fragments": [],
                "text": "Gaussian Processes for Machine Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics, and deals with the supervised learning problem for both regression and classification."
            },
            "venue": {
                "fragments": [],
                "text": "Adaptive computation and machine learning"
            },
            "year": 2009
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2423230"
                        ],
                        "name": "L. Breiman",
                        "slug": "L.-Breiman",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Breiman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Breiman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "SMAC\u2019s models are based on random forests [16], a standard machine learning tool for regression and classification."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 84,
                                "start": 80
                            }
                        ],
                        "text": "Random forests share this benefit and typically yield more accurate predictions [16]; they also allow us to quantify our uncertainty in a given prediction."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 89141,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "13d4c2f76a7c1a4d0a71204e1d5d263a3f5a7986",
            "isKey": false,
            "numCitedBy": 65885,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund & R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148\u2013156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression."
            },
            "slug": "Random-Forests-Breiman",
            "title": {
                "fragments": [],
                "text": "Random Forests"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the forest, and are also applicable to regression."
            },
            "venue": {
                "fragments": [],
                "text": "Machine Learning"
            },
            "year": 2004
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726451"
                        ],
                        "name": "Ian P. Gent",
                        "slug": "Ian-P.-Gent",
                        "structuredName": {
                            "firstName": "Ian",
                            "lastName": "Gent",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ian P. Gent"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2470869"
                        ],
                        "name": "H. Hoos",
                        "slug": "H.-Hoos",
                        "structuredName": {
                            "firstName": "Holger",
                            "lastName": "Hoos",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Hoos"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1702467"
                        ],
                        "name": "Patrick Prosser",
                        "slug": "Patrick-Prosser",
                        "structuredName": {
                            "firstName": "Patrick",
                            "lastName": "Prosser",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Patrick Prosser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1733716"
                        ],
                        "name": "T. Walsh",
                        "slug": "T.-Walsh",
                        "structuredName": {
                            "firstName": "Toby",
                            "lastName": "Walsh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Walsh"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 291,
                                "start": 287
                            }
                        ],
                        "text": "To enable a comparison with our previous SMBO instantiation TB-SPO, we used the 6 configuration scenarios introduced in [18], which aim to minimize SAPS\u2019s runtime on 6 single SAT-encoded instances, 3 each from quasigroup completion (QCP [35]) and from small world graph colouring (SWGCP [36])."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 275,
                                "start": 270
                            }
                        ],
                        "text": "To enable a comparison with our previous SMBO instantiation TB-SPO, we used the 6 configuration scenarios introduced in [15], which aim to minimize SAPS\u2019s runtime on 6 single SAT-encoded instances, 3 each from quasigroup completion (QCP) and small world graph colouring (SWGCP)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 290,
                                "start": 285
                            }
                        ],
                        "text": "Comparing the left vs the right side of Table 1, we note that the SAPS discretization (the same we used to optimize SAPS with PARAMILS in previous work [7, 8]) left substantial room for improvement when exploring the full space: roughly 1.15-fold and 1.55-fold speedups on the QCP and SWGCP instances, respectively."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 117
                            }
                        ],
                        "text": "These instances come from the following domains: quasigroup completion, QCP [35]; small world graph colouring, SWGCP [36]; winner determination in combinatorial auctions, REGIONS100 [39]; mixed integer knapsack, MIK [40]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 135,
                                "start": 130
                            }
                        ],
                        "text": "Speedups for SAPS were similar to those observed in the single-instance case (about 1.15-fold for SAPS-QCP and 1.65-fold for SAPS-SWGCP), but now we also observed a 1.17-fold improvement for SPEAR-QCP."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6341757,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "9694f836677154b5788ebda81199a8b785892f5e",
            "isKey": false,
            "numCitedBy": 100,
            "numCiting": 13,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce a mechanism called \"morphing\" for introducing structure or randomness into a wide variety of problems. We illustrate the usefulness of morphing by performing several different experimental studies. These studies identify the impact of a \"small-world\" topology on the cost of coloring graphs, of asymmetry on the cost of finding the optimal TSP tour, and of the dimensionality of space on the cost of finding the optimal TSP tour. We predict that morphing will find many other uses."
            },
            "slug": "Morphing:-Combining-Structure-and-Randomness-Gent-Hoos",
            "title": {
                "fragments": [],
                "text": "Morphing: Combining Structure and Randomness"
            },
            "tldr": {
                "abstractSimilarityScore": 77,
                "text": "This work introduces a mechanism called \"morphing\" for introducing structure or randomness into a wide variety of problems by performing several different experimental studies, and predicts that morphing will find many other uses."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI/IAAI"
            },
            "year": 1999
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1393588417"
                        ],
                        "name": "T. Bartz-Beielstein",
                        "slug": "T.-Bartz-Beielstein",
                        "structuredName": {
                            "firstName": "Thomas",
                            "lastName": "Bartz-Beielstein",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Bartz-Beielstein"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 294,
                                "start": 290
                            }
                        ],
                        "text": "\u2026\u03c0\u2032\u2032 \u2208 \u03a0} 5 \u03c0 \u2190 instance sampled uniformly at random from \u03a0 \u2032 6 s\u2190 seed, drawn uniformly at random 7 R\u2190 ExecuteRun(R, \u03b8inc, \u03c0, s) 8 N \u2190 1 9 while true do\n10 Smissing \u2190 \u3008instance, seed\u3009 pairs for which \u03b8inc was run before, but not \u03b8new 11 Storun \u2190random subset of Smissing of size min(N, |Smissing"
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 73,
                                "start": 69
                            }
                        ],
                        "text": "Despite considerable recent advances [13, 14, 15], all published work on SMBO still has three key limitations that prevent its use for general algorithm configuration tasks: (1) it only supports numerical parameters; (2) it only optimizes target algorithm performance for single instances; and (3)\u2026"
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 57129918,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "3c871e59b63f625846185092843f1358f673bfdc",
            "isKey": false,
            "numCitedBy": 290,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": "This book introduces the new experimentalism in evolutionary computation, providing tools to understand algorithms and programs and their interaction with optimization problems. It develops and applies statistical techniques to analyze and compare modern search heuristics such as evolutionary algorithms and particle swarm optimization. The book bridges the gap between theory and experiment by providing a self-contained experimental methodology and many examples."
            },
            "slug": "Experimental-Research-in-Evolutionary-Computation-Bartz-Beielstein",
            "title": {
                "fragments": [],
                "text": "Experimental Research in Evolutionary Computation - The New Experimentalism"
            },
            "tldr": {
                "abstractSimilarityScore": 83,
                "text": "This book introduces the new experimentalism in evolutionary computation, providing tools to understand algorithms and programs and their interaction with optimization problems, and provides a self-contained experimental methodology and many examples."
            },
            "venue": {
                "fragments": [],
                "text": "Natural Computing Series"
            },
            "year": 2006
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1404459229"
                        ],
                        "name": "J. Shawe-Taylor",
                        "slug": "J.-Shawe-Taylor",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Shawe-Taylor",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Shawe-Taylor"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1685083"
                        ],
                        "name": "N. Cristianini",
                        "slug": "N.-Cristianini",
                        "structuredName": {
                            "firstName": "Nello",
                            "lastName": "Cristianini",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. Cristianini"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 35730151,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a0f9f3c338dd84b054dabcbd50b725f2b3609ad9",
            "isKey": false,
            "numCitedBy": 4727,
            "numCiting": 184,
            "paperAbstract": {
                "fragments": [],
                "text": "Kernel methods provide a powerful and unified framework for pattern discovery, motivating algorithms that can act on general types of data (e.g. strings, vectors or text) and look for general types of relations (e.g. rankings, classifications, regressions, clusters). The application areas range from neural networks and pattern recognition to machine learning and data mining. This book, developed from lectures and tutorials, fulfils two major roles: firstly it provides practitioners with a large toolkit of algorithms, kernels and solutions ready to use for standard pattern discovery problems in fields such as bioinformatics, text analysis, image analysis. Secondly it provides an easy introduction for students and researchers to the growing field of kernel-based pattern analysis, demonstrating with examples how to handcraft an algorithm or a kernel for a new specific application, and covering all the necessary conceptual and mathematical tools to do so."
            },
            "slug": "Kernel-Methods-for-Pattern-Analysis-Shawe-Taylor-Cristianini",
            "title": {
                "fragments": [],
                "text": "Kernel Methods for Pattern Analysis"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "This book provides an easy introduction for students and researchers to the growing field of kernel-based pattern analysis, demonstrating with examples how to handcraft an algorithm or a kernel for a new specific application, and covering all the necessary conceptual and mathematical tools to do so."
            },
            "venue": {
                "fragments": [],
                "text": "ICTAI"
            },
            "year": 2003
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 381,
                                "start": 377
                            }
                        ],
                        "text": "8 These scenarios involve the configuration of the local search SAT solver SAPS (4 parameters), the tree search solver SPEAR (26 parameters), and the most widely used commercial mixed integer programming (MIP) solver, IBM ILOG CPLEX (76 parameters); references for these algorithms, as well as details on their parameter spaces, are given in the extended version of this paper [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 4
                            }
                        ],
                        "text": "see [17]), we evaluated a version of SMAC based on PP instead of RF models; its median performance was slightly better than TB-SPO\u2019s, but the two were statistically indistinguishable in all 6 scenarios."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 182,
                                "start": 178
                            }
                        ],
                        "text": "7 The proof is very simple and uses the same arguments as a previous proof about FocusedILS (see [8]); we omit it here and refer the reader to the extended version of this paper [17]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 77,
                                "start": 73
                            }
                        ],
                        "text": "Both sets of features are detailed in the extended version of this paper [17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 72,
                                "start": 68
                            }
                        ],
                        "text": "For more information and references for these instances, please see [17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 151,
                                "start": 147
                            }
                        ],
                        "text": "Further information, including the definition of the weighted Hamming distance kernel function, can be found in the extended version of this paper [17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": ") However, we note that in some models such transformations implicitly change the cost metric users aim to optimize [17]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": true,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Sequential model-based optimization for general algorithm configuration (extended version)"
            },
            "venue": {
                "fragments": [],
                "text": "Technical Report TR-2010-10, UBC Computer Science"
            },
            "year": 2010
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1784682"
                        ],
                        "name": "T. Hastie",
                        "slug": "T.-Hastie",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Hastie",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "T. Hastie"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761784"
                        ],
                        "name": "R. Tibshirani",
                        "slug": "R.-Tibshirani",
                        "structuredName": {
                            "firstName": "Robert",
                            "lastName": "Tibshirani",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Tibshirani"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3056361"
                        ],
                        "name": "J. Friedman",
                        "slug": "J.-Friedman",
                        "structuredName": {
                            "firstName": "Jerome",
                            "lastName": "Friedman",
                            "middleNames": [
                                "H."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Friedman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 2
                            }
                        ],
                        "text": ", [22]), to project the feature matrix into a lower-dimensional subspace spanned by the seven orthogonal vectors along which it has maximal variance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 58068920,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "44d71e0ec9f68d8eb802b9ab1dde8368efeac42e",
            "isKey": false,
            "numCitedBy": 12272,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "The-Elements-of-Statistical-Learning-Hastie-Tibshirani",
            "title": {
                "fragments": [],
                "text": "The Elements of Statistical Learning"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2001
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145744238"
                        ],
                        "name": "Julia Couto",
                        "slug": "Julia-Couto",
                        "structuredName": {
                            "firstName": "Julia",
                            "lastName": "Couto",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Julia Couto"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 12,
                                "start": 8
                            }
                        ],
                        "text": "2 Couto [22] gives a recursive kernel function for categorical data that is related since it is also based on a Hamming distance."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 42550563,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2d558f4c4797ce2b5f8d974bd23375077d8b642f",
            "isKey": false,
            "numCitedBy": 28,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "Clustering categorical data is an important and challenging data analysis task. In this paper, we explore the use of kernel K-means to cluster categorical data. We propose a new kernel function based on Hamming distance to embed categorical data in a constructed feature space where the clustering is conducted. We experimentally evaluated the quality of the solutions produced by kernel K-means on real datasets. Results indicated the feasibility of kernel K-means using our proposed kernel function to discover clusters embedded in categorical data."
            },
            "slug": "Kernel-K-Means-for-Categorical-Data-Couto",
            "title": {
                "fragments": [],
                "text": "Kernel K-Means for Categorical Data"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This paper proposes a new kernel function based on Hamming distance to embed categorical data in a constructed feature space where the clustering is conducted and experimentally evaluated the quality of the solutions produced by kernel K-means on real datasets."
            },
            "venue": {
                "fragments": [],
                "text": "IDA"
            },
            "year": 2005
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 228,
                                "start": 222
                            }
                        ],
                        "text": "F-RACE and its extensions have been used to optimize various high-performance algorithms, including iterated local search and ant colony optimization procedures for timetabling tasks and the travelling salesperson problem [6, 5]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 8,
                                "start": 2
                            }
                        ],
                        "text": ", [4, 5]), while others also target categorical (i."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 76,
                                "start": 73
                            }
                        ],
                        "text": "The most prominent configuration methods are the racing algorithm F-RACE [5] and our own iterated local search algorithm PARAMILS [7, 8]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Empirical Methods for the Analysis of Optimization Algorithms"
            },
            "venue": {
                "fragments": [],
                "text": "chapter F-race and iterated F-race: an overview. Springer, Berlin, Germany"
            },
            "year": 2010
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 6,
                                "start": 2
                            }
                        ],
                        "text": ", [22]), to project the feature matrix into a lowerdimensional subspace spanned by the seven orthogonal vectors along which it has maximal variance."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "The Elements of Statistical Learning, 2nd edn"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2009
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 25,
            "methodology": 28,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 49,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/Sequential-Model-Based-Optimization-for-General-Hutter-Hoos/728744423ff0fb7e327664ed4e6352a95bb6c893?sort=total-citations"
}