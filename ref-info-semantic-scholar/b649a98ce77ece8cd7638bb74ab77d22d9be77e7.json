{
    "links": [
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2064160"
                        ],
                        "name": "A. Krizhevsky",
                        "slug": "A.-Krizhevsky",
                        "structuredName": {
                            "firstName": "Alex",
                            "lastName": "Krizhevsky",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Krizhevsky"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1701686"
                        ],
                        "name": "Ilya Sutskever",
                        "slug": "Ilya-Sutskever",
                        "structuredName": {
                            "firstName": "Ilya",
                            "lastName": "Sutskever",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ilya Sutskever"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1695689"
                        ],
                        "name": "Geoffrey E. Hinton",
                        "slug": "Geoffrey-E.-Hinton",
                        "structuredName": {
                            "firstName": "Geoffrey",
                            "lastName": "Hinton",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Geoffrey E. Hinton"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 98,
                                "start": 95
                            }
                        ],
                        "text": "We adopt three different CNN architectures as our base architectures for binarization: AlexNet [1], Residual Networks (known as ResNet) [4], and a variant of GoogleNet [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 20
                            }
                        ],
                        "text": "We evaluate AlexNet [1] and two deeper architectures in our experiments."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 121,
                                "start": 118
                            }
                        ],
                        "text": "Classification Accuracy(%) Binary-Weight Binary-Input-Binary-Weight Full-Precision BWN BC[11] XNOR-Net BNN[11] AlexNet[1] Top-1 Top-5 Top-1 Top-5 Top-1 Top-5 Top-1 Top-5 Top-1 Top-5 53."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 157
                            }
                        ],
                        "text": "In computer vision, a particular type of DNN, known as Convolutional Neural Networks (CNN), have demonstrated state-of-the-art results in object recognition [1,2,3,4] and detection [5,6,7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 23,
                                "start": 20
                            }
                        ],
                        "text": "For example, AlexNet[1] has 61M parameters (249MB of memory) and performs 1."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 11,
                                "start": 8
                            }
                        ],
                        "text": "AlexNet [1] is a CNN architecture with 5 convolutional layers and two fully-connected layers."
                    },
                    "intents": []
                }
            ],
            "corpusId": 195908774,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "abd1c342495432171beb7ca8fd9551ef13cbd0ff",
            "isKey": true,
            "numCitedBy": 82046,
            "numCiting": 50,
            "paperAbstract": {
                "fragments": [],
                "text": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry."
            },
            "slug": "ImageNet-classification-with-deep-convolutional-Krizhevsky-Sutskever",
            "title": {
                "fragments": [],
                "text": "ImageNet classification with deep convolutional neural networks"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "A large, deep convolutional neural network was trained to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes and employed a recently developed regularization method called \"dropout\" that proved to be very effective."
            },
            "venue": {
                "fragments": [],
                "text": "Commun. ACM"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144366108"
                        ],
                        "name": "S. Anwar",
                        "slug": "S.-Anwar",
                        "structuredName": {
                            "firstName": "Sajid",
                            "lastName": "Anwar",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Anwar"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2549369"
                        ],
                        "name": "Kyuyeon Hwang",
                        "slug": "Kyuyeon-Hwang",
                        "structuredName": {
                            "firstName": "Kyuyeon",
                            "lastName": "Hwang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyuyeon Hwang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145057126"
                        ],
                        "name": "Wonyong Sung",
                        "slug": "Wonyong-Sung",
                        "structuredName": {
                            "firstName": "Wonyong",
                            "lastName": "Sung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wonyong Sung"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 111,
                                "start": 107
                            }
                        ],
                        "text": "Quantizing a network with L2 error minimization achieved better accuracy on MNIST and CIFAR-10 datasets in [33]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15178138,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6373454105df0c5511ca5f6cae4d20c48214272",
            "isKey": false,
            "numCitedBy": 181,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep convolutional neural networks have shown promising results in image and speech recognition applications. The learning capability of the network improves with increasing depth and size of each layer. However this capability comes at the cost of increased computational complexity. Thus reduction in hardware complexity and faster classification are highly desired. This work proposes an optimization method for fixed point deep convolutional neural networks. The parameters of a pre-trained high precision network are first directly quantized using L2 error minimization. We quantize each layer one by one, while other layers keep computation with high precision, to know the layer-wise sensitivity on word-length reduction. Then the network is retrained with quantized weights. Two examples on object recognition, MNIST and CIFAR-10, are presented. Our results indicate that quantization induces sparsity in the network which reduces the effective number of network parameters and improves generalization. This work reduces the required memory storage by a factor of 1/10 and achieves better classification results than the high precision networks."
            },
            "slug": "Fixed-point-optimization-of-deep-convolutional-for-Anwar-Hwang",
            "title": {
                "fragments": [],
                "text": "Fixed point optimization of deep convolutional neural networks for object recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "The results indicate that quantization induces sparsity in the network which reduces the effective number of network parameters and improves generalization, and reduces the required memory storage by a factor of 1/10 and achieves better classification results than the high precision networks."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2388466"
                        ],
                        "name": "Matthieu Courbariaux",
                        "slug": "Matthieu-Courbariaux",
                        "structuredName": {
                            "firstName": "Matthieu",
                            "lastName": "Courbariaux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthieu Courbariaux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 20,
                                "start": 17
                            }
                        ],
                        "text": "For XNOR-Net and BNN we used ADAM [42]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 46,
                                "start": 42
                            }
                        ],
                        "text": "tion of BinaryConnect propsed by BinaryNet[11], where both weights and activations are binarized."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 19,
                                "start": 16
                            }
                        ],
                        "text": "BinaryNeuralNet(BNN) is a neural network with binary weights and activations during inference and gradient computation in training."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 108
                            }
                        ],
                        "text": "We compare our method with two recent works on binarizing neural networks; BinaryConnect [38] and BinaryNet [11]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 129
                            }
                        ],
                        "text": "We compare our Binary-weight-network (BWN) with BinaryConnect(BC) [38] and our XNOR-Networks(XNOR-Net) with BinaryNeuralNet(BNN) [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "Dot product between two binary vectors can be implemented by XNOR-Bitcounting operations [11]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 168,
                                "start": 164
                            }
                        ],
                        "text": "Our experimental results show that our proposed method for binarizing convolutional neural networks outperforms the state-of-the-art network binarization method of [11] by a large margin (16."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "[11,38] also employed this strategy to train a binary network."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "Classification Accuracy(%) Binary-Weight Binary-Input-Binary-Weight Full-Precision BWN BC[11] XNOR-Net BNN[11] AlexNet[1] Top-1 Top-5 Top-1 Top-5 Top-1 Top-5 Top-1 Top-5 Top-1 Top-5 53."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 133,
                                "start": 129
                            }
                        ],
                        "text": "If all of the operands of the convolutions are binary, then the convolutions can be estimated by XNOR and bitcounting operations [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 10,
                                "start": 7
                            }
                        ],
                        "text": "BC and BNN showed near state-of-the-art performance on CIFAR-10, MNIST, and SVHN dataset."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 90,
                                "start": 86
                            }
                        ],
                        "text": "To compute the gradient for sign function q = sign(r), we follow the same approach as [11], where gr = gq1|r|\u22641."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 119,
                                "start": 116
                            }
                        ],
                        "text": "In concept, this is a similar approach to our XNOR-Network but the binarization method and the network structure in BNN is different from ours."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 32
                            }
                        ],
                        "text": "We also compare our method with BinaryNet on ImageNet, and our method outperforms BinaryNet by large margin."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 48
                            }
                        ],
                        "text": "Table 1 compares our final accuracy with BC and BNN.\nResidual Net [4] is a recent CNN architecture with large number of convolutional layers (varies from 18-151)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 54,
                                "start": 51
                            }
                        ],
                        "text": "In all of the epochs our method outperforms BC and BNN by large margin (\u223c17%)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 51,
                                "start": 42
                            }
                        ],
                        "text": "The exten-\ntion of BinaryConnect propsed by BinaryNet[11], where both weights and activations are binarized."
                    },
                    "intents": []
                }
            ],
            "corpusId": 6564560,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "123ae35aa7d6838c817072032ce5615bb891652d",
            "isKey": true,
            "numCitedBy": 563,
            "numCiting": 56,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce BinaryNet, a method which trains DNNs with binary weights and activations when computing parameters\u2019 gradient. We show that it is possible to train a Multi Layer Perceptron (MLP) on MNIST and ConvNets on CIFAR-10 and SVHN with BinaryNet and achieve nearly state-of-the-art results. At run-time, BinaryNet drastically reduces memory usage and replaces most multiplications by 1-bit exclusive-not-or (XNOR) operations, which might have a big impact on both general-purpose and dedicated Deep Learning hardware. We wrote a binary matrix multiplication GPU kernel with which it is possible to run our MNIST MLP 7 times faster than with an unoptimized GPU kernel, without suffering any loss in classification accuracy. The code for BinaryNet is available."
            },
            "slug": "BinaryNet:-Training-Deep-Neural-Networks-with-and-1-Courbariaux-Bengio",
            "title": {
                "fragments": [],
                "text": "BinaryNet: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1"
            },
            "tldr": {
                "abstractSimilarityScore": 58,
                "text": "BinaryNet, a method which trains DNNs with binary weights and activations when computing parameters\u2019 gradient is introduced, which drastically reduces memory usage and replaces most multiplications by 1-bit exclusive-not-or (XNOR) operations, which might have a big impact on both general-purpose and dedicated Deep Learning hardware."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2388466"
                        ],
                        "name": "Matthieu Courbariaux",
                        "slug": "Matthieu-Courbariaux",
                        "structuredName": {
                            "firstName": "Matthieu",
                            "lastName": "Courbariaux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthieu Courbariaux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145719986"
                        ],
                        "name": "J. David",
                        "slug": "J.-David",
                        "structuredName": {
                            "firstName": "Jean-Pierre",
                            "lastName": "David",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. David"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 18,
                                "start": 14
                            }
                        ],
                        "text": "BinaryConnect [38] extended the probablistic idea behind the EBP."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 93,
                                "start": 89
                            }
                        ],
                        "text": "We compare our method with two recent works on binarizing neural networks; BinaryConnect [38] and BinaryNet [11]."
                    },
                    "intents": [
                        {
                            "id": "result"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "We compare our Binary-weight-network (BWN) with BinaryConnect(BC) [38] and our XNOR-Networks(XNOR-Net) with BinaryNeuralNet(BNN) [11]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 25
                            }
                        ],
                        "text": "Similar to our approach, BinaryConnect uses the real-valued version of the weights as a key reference for the binarization process."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 7,
                                "start": 0
                            }
                        ],
                        "text": "[11,38] also employed this strategy to train a binary network."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "BinaryConnect(BC) is a method for training a deep neural\nnetwork with binary weights during forward and backward propagations."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 13,
                                "start": 0
                            }
                        ],
                        "text": "BinaryConnect achieved state-ofthe-art results on small datasets (e.g.,CIFAR-10, SVHN)."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 30,
                                "start": 17
                            }
                        ],
                        "text": "The exten-\ntion of BinaryConnect propsed by BinaryNet[11], where both weights and activations are binarized."
                    },
                    "intents": []
                }
            ],
            "corpusId": 1518846,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a5733ff08daff727af834345b9cfff1d0aa109ec",
            "isKey": true,
            "numCitedBy": 2134,
            "numCiting": 52,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep Neural Networks (DNN) have achieved state-of-the-art results in a wide range of tasks, with the best results obtained with large training sets and large models. In the past, GPUs enabled these breakthroughs because of their greater computational speed. In the future, faster computation at both training and test time is likely to be crucial for further progress and for consumer applications on low-power devices. As a result, there is much interest in research and development of dedicated hardware for Deep Learning (DL). Binary weights, i.e., weights which are constrained to only two possible values (e.g. -1 or 1), would bring great benefits to specialized DL hardware by replacing many multiply-accumulate operations by simple accumulations, as multipliers are the most space and power-hungry components of the digital implementation of neural networks. We introduce BinaryConnect, a method which consists in training a DNN with binary weights during the forward and backward propagations, while retaining precision of the stored weights in which gradients are accumulated. Like other dropout schemes, we show that BinaryConnect acts as regularizer and we obtain near state-of-the-art results with BinaryConnect on the permutation-invariant MNIST, CIFAR-10 and SVHN."
            },
            "slug": "BinaryConnect:-Training-Deep-Neural-Networks-with-Courbariaux-Bengio",
            "title": {
                "fragments": [],
                "text": "BinaryConnect: Training Deep Neural Networks with binary weights during propagations"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "BinaryConnect is introduced, a method which consists in training a DNN with binary weights during the forward and backward propagations, while retaining precision of the stored weights in which gradients are accumulated, and near state-of-the-art results with BinaryConnect are obtained on the permutation-invariant MNIST, CIFAR-10 and SVHN."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "5115386"
                        ],
                        "name": "Yunchao Gong",
                        "slug": "Yunchao-Gong",
                        "structuredName": {
                            "firstName": "Yunchao",
                            "lastName": "Gong",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yunchao Gong"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144117143"
                        ],
                        "name": "L. Liu",
                        "slug": "L.-Liu",
                        "structuredName": {
                            "firstName": "L.",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "41216159"
                        ],
                        "name": "Ming Yang",
                        "slug": "Ming-Yang",
                        "structuredName": {
                            "firstName": "Ming",
                            "lastName": "Yang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ming Yang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1769383"
                        ],
                        "name": "Lubomir D. Bourdev",
                        "slug": "Lubomir-D.-Bourdev",
                        "structuredName": {
                            "firstName": "Lubomir",
                            "lastName": "Bourdev",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Lubomir D. Bourdev"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 6251653,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e7bf9803705f2eb608db1e59e5c7636a3f171916",
            "isKey": false,
            "numCitedBy": 878,
            "numCiting": 32,
            "paperAbstract": {
                "fragments": [],
                "text": "Deep convolutional neural networks (CNN) has become the most promising method for object recognition, repeatedly demonstrating record breaking results for image classification and object detection in recent years. However, a very deep CNN generally involves many layers with millions of parameters, making the storage of the network model to be extremely large. This prohibits the usage of deep CNNs on resource limited hardware, especially cell phones or other embedded devices. In this paper, we tackle this model storage issue by investigating information theoretical vector quantization methods for compressing the parameters of CNNs. In particular, we have found in terms of compressing the most storage demanding dense connected layers, vector quantization methods have a clear gain over existing matrix factorization methods. Simply applying k-means clustering to the weights or conducting product quantization can lead to a very good balance between model size and recognition accuracy. For the 1000-category classification task in the ImageNet challenge, we are able to achieve 16-24 times compression of the network with only 1% loss of classification accuracy using the state-of-the-art CNN."
            },
            "slug": "Compressing-Deep-Convolutional-Networks-using-Gong-Liu",
            "title": {
                "fragments": [],
                "text": "Compressing Deep Convolutional Networks using Vector Quantization"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper is able to achieve 16-24 times compression of the network with only 1% loss of classification accuracy using the state-of-the-art CNN, and finds in terms of compressing the most storage demanding dense connected layers, vector quantization methods have a clear gain over existing matrix factorization methods."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33752120"
                        ],
                        "name": "Minje Kim",
                        "slug": "Minje-Kim",
                        "structuredName": {
                            "firstName": "Minje",
                            "lastName": "Kim",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Minje Kim"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1718742"
                        ],
                        "name": "P. Smaragdis",
                        "slug": "P.-Smaragdis",
                        "structuredName": {
                            "firstName": "Paris",
                            "lastName": "Smaragdis",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Smaragdis"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[41] retraine a previously trained neural network with binary weights and binary inputs."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 15604580,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8fcfd67f21738eff12d853fdf2b31ee192e2312a",
            "isKey": false,
            "numCitedBy": 186,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Based on the assumption that there exists a neural network that efficiently represents a set of Boolean functions between all binary inputs and outputs, we propose a process for developing and deploying neural networks whose weight parameters, bias terms, input, and intermediate hidden layer output signals, are all binary-valued, and require only basic bit logic for the feedforward pass. The proposed Bitwise Neural Network (BNN) is especially suitable for resource-constrained environments, since it replaces either floating or fixed-point arithmetic with significantly more efficient bitwise operations. Hence, the BNN requires for less spatial complexity, less memory bandwidth, and less power consumption in hardware. In order to design such networks, we propose to add a few training schemes, such as weight compression and noisy backpropagation, which result in a bitwise network that performs almost as well as its corresponding real-valued network. We test the proposed network on the MNIST dataset, represented using binary features, and show that BNNs result in competitive performance while offering dramatic computational savings."
            },
            "slug": "Bitwise-Neural-Networks-Kim-Smaragdis",
            "title": {
                "fragments": [],
                "text": "Bitwise Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "The proposed Bitwise Neural Network (BNN) is especially suitable for resource-constrained environments, since it replaces either floating or fixed-point arithmetic with significantly more efficient bitwise operations."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1771551"
                        ],
                        "name": "X. Zhang",
                        "slug": "X.-Zhang",
                        "structuredName": {
                            "firstName": "X.",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "X. Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3080683"
                        ],
                        "name": "Shaoqing Ren",
                        "slug": "Shaoqing-Ren",
                        "structuredName": {
                            "firstName": "Shaoqing",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoqing Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 137,
                                "start": 134
                            }
                        ],
                        "text": "While changing one parameter, we fix other parameters as follow: c = 256, nI = 14(2) and nW = 3(2) (majority of convolutions in ResNet[4] architecture have this structure)."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 139,
                                "start": 136
                            }
                        ],
                        "text": "We adopt three different CNN architectures as our base architectures for binarization: AlexNet [1], Residual Networks (known as ResNet) [4], and a variant of GoogleNet [3]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 16,
                                "start": 13
                            }
                        ],
                        "text": "Residual Net [4] is a recent CNN architecture with large number of convolutional layers (varies from 18-151)."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 154,
                                "start": 151
                            }
                        ],
                        "text": "Replacing the fully connected layer with global average pooling was examined in the Network in Network architecture [26], GoogLenet[3] and Residual-Net[4], which achieved state-of-the-art results on several benchmarks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 157
                            }
                        ],
                        "text": "In computer vision, a particular type of DNN, known as Convolutional Neural Networks (CNN), have demonstrated state-of-the-art results in object recognition [1,2,3,4] and detection [5,6,7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 44,
                                "start": 41
                            }
                        ],
                        "text": "The bottleneck structure in Residual-Net [4] has been proposed to reduce the number of parameters and improve speed."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206594692,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2c03df8b48bf3fa39054345bafabfeff15bfd11d",
            "isKey": true,
            "numCitedBy": 97653,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8\u00d7 deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation."
            },
            "slug": "Deep-Residual-Learning-for-Image-Recognition-He-Zhang",
            "title": {
                "fragments": [],
                "text": "Deep Residual Learning for Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 63,
                "text": "This work presents a residual learning framework to ease the training of networks that are substantially deeper than those used previously, and provides comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth."
            },
            "venue": {
                "fragments": [],
                "text": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "34838386"
                        ],
                        "name": "K. Simonyan",
                        "slug": "K.-Simonyan",
                        "structuredName": {
                            "firstName": "Karen",
                            "lastName": "Simonyan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Simonyan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 166,
                                "start": 157
                            }
                        ],
                        "text": "In computer vision, a particular type of DNN, known as Convolutional Neural Networks (CNN), have demonstrated state-of-the-art results in object recognition [1,2,3,4] and detection [5,6,7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14124313,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "eb42cf88027de515750f230b23b1a057dc782108",
            "isKey": false,
            "numCitedBy": 63195,
            "numCiting": 57,
            "paperAbstract": {
                "fragments": [],
                "text": "In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision."
            },
            "slug": "Very-Deep-Convolutional-Networks-for-Large-Scale-Simonyan-Zisserman",
            "title": {
                "fragments": [],
                "text": "Very Deep Convolutional Networks for Large-Scale Image Recognition"
            },
            "tldr": {
                "abstractSimilarityScore": 73,
                "text": "This work investigates the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting using an architecture with very small convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3093886"
                        ],
                        "name": "Max Jaderberg",
                        "slug": "Max-Jaderberg",
                        "structuredName": {
                            "firstName": "Max",
                            "lastName": "Jaderberg",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Max Jaderberg"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1687524"
                        ],
                        "name": "A. Vedaldi",
                        "slug": "A.-Vedaldi",
                        "structuredName": {
                            "firstName": "Andrea",
                            "lastName": "Vedaldi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Vedaldi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688869"
                        ],
                        "name": "Andrew Zisserman",
                        "slug": "Andrew-Zisserman",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Zisserman",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Zisserman"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 45,
                                "start": 38
                            }
                        ],
                        "text": "Matrix factorization has been used by [24,25]."
                    },
                    "intents": []
                }
            ],
            "corpusId": 17864746,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "021fc345d40d3e6332cd2ef276e2eaa5e71102e4",
            "isKey": false,
            "numCitedBy": 1154,
            "numCiting": 45,
            "paperAbstract": {
                "fragments": [],
                "text": "The focus of this paper is speeding up the application of convolutional neural networks. While delivering impressive results across a range of computer vision and machine learning tasks, these networks are computationally demanding, limiting their deployability. Convolutional layers generally consume the bulk of the processing time, and so in this work we present two simple schemes for drastically speeding up these layers. This is achieved by exploiting cross-channel or filter redundancy to construct a low rank basis of filters that are rank-1 in the spatial domain. Our methods are architecture agnostic, and can be easily applied to existing CPU and GPU convolutional frameworks for tuneable speedup performance. We demonstrate this with a real world network designed for scene text character recognition [15], showing a possible 2.5\u00d7 speedup with no loss in accuracy, and 4.5\u00d7 speedup with less than 1% drop in accuracy, still achieving state-of-the-art on standard benchmarks."
            },
            "slug": "Speeding-up-Convolutional-Neural-Networks-with-Low-Jaderberg-Vedaldi",
            "title": {
                "fragments": [],
                "text": "Speeding up Convolutional Neural Networks with Low Rank Expansions"
            },
            "tldr": {
                "abstractSimilarityScore": 51,
                "text": "Two simple schemes for drastically speeding up convolutional neural networks are presented, achieved by exploiting cross-channel or filter redundancy to construct a low rank basis of filters that are rank-1 in the spatial domain."
            },
            "venue": {
                "fragments": [],
                "text": "BMVC"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3080683"
                        ],
                        "name": "Shaoqing Ren",
                        "slug": "Shaoqing-Ren",
                        "structuredName": {
                            "firstName": "Shaoqing",
                            "lastName": "Ren",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shaoqing Ren"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39353098"
                        ],
                        "name": "Kaiming He",
                        "slug": "Kaiming-He",
                        "structuredName": {
                            "firstName": "Kaiming",
                            "lastName": "He",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kaiming He"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2983898"
                        ],
                        "name": "Ross B. Girshick",
                        "slug": "Ross-B.-Girshick",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Girshick",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross B. Girshick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2032184078"
                        ],
                        "name": "Jian Sun",
                        "slug": "Jian-Sun",
                        "structuredName": {
                            "firstName": "Jian",
                            "lastName": "Sun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jian Sun"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 181
                            }
                        ],
                        "text": "In computer vision, a particular type of DNN, known as Convolutional Neural Networks (CNN), have demonstrated state-of-the-art results in object recognition [1,2,3,4] and detection [5,6,7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 10328909,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "424561d8585ff8ebce7d5d07de8dbf7aae5e7270",
            "isKey": false,
            "numCitedBy": 33308,
            "numCiting": 53,
            "paperAbstract": {
                "fragments": [],
                "text": "State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features---using the recently popular terminology of neural networks with 'attention' mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model, our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available"
            },
            "slug": "Faster-R-CNN:-Towards-Real-Time-Object-Detection-Ren-He",
            "title": {
                "fragments": [],
                "text": "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "This work introduces a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals and further merge RPN and Fast R-CNN into a single network by sharing their convolutionAL features."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2115913164"
                        ],
                        "name": "Min Lin",
                        "slug": "Min-Lin",
                        "structuredName": {
                            "firstName": "Min",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Min Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "35370244"
                        ],
                        "name": "Qiang Chen",
                        "slug": "Qiang-Chen",
                        "structuredName": {
                            "firstName": "Qiang",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Qiang Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143653681"
                        ],
                        "name": "Shuicheng Yan",
                        "slug": "Shuicheng-Yan",
                        "structuredName": {
                            "firstName": "Shuicheng",
                            "lastName": "Yan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Shuicheng Yan"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 120,
                                "start": 116
                            }
                        ],
                        "text": "Replacing the fully connected layer with global average pooling was examined in the Network in Network architecture [26], GoogLenet[3] and Residual-Net[4], which achieved state-of-the-art results on several benchmarks."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16636683,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "5e83ab70d0cbc003471e87ec306d27d9c80ecb16",
            "isKey": false,
            "numCitedBy": 4255,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a novel deep network structure called \"Network In Network\" (NIN) to enhance model discriminability for local patches within the receptive field. The conventional convolutional layer uses linear filters followed by a nonlinear activation function to scan the input. Instead, we build micro neural networks with more complex structures to abstract the data within the receptive field. We instantiate the micro neural network with a multilayer perceptron, which is a potent function approximator. The feature maps are obtained by sliding the micro networks over the input in a similar manner as CNN; they are then fed into the next layer. Deep NIN can be implemented by stacking mutiple of the above described structure. With enhanced local modeling via the micro network, we are able to utilize global average pooling over feature maps in the classification layer, which is easier to interpret and less prone to overfitting than traditional fully connected layers. We demonstrated the state-of-the-art classification performances with NIN on CIFAR-10 and CIFAR-100, and reasonable performances on SVHN and MNIST datasets."
            },
            "slug": "Network-In-Network-Lin-Chen",
            "title": {
                "fragments": [],
                "text": "Network In Network"
            },
            "tldr": {
                "abstractSimilarityScore": 44,
                "text": "With enhanced local modeling via the micro network, the proposed deep network structure NIN is able to utilize global average pooling over feature maps in the classification layer, which is easier to interpret and less prone to overfitting than traditional fully connected layers."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1782282"
                        ],
                        "name": "Evan Shelhamer",
                        "slug": "Evan-Shelhamer",
                        "structuredName": {
                            "firstName": "Evan",
                            "lastName": "Shelhamer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Evan Shelhamer"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2117314646"
                        ],
                        "name": "Jonathan Long",
                        "slug": "Jonathan-Long",
                        "structuredName": {
                            "firstName": "Jonathan",
                            "lastName": "Long",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jonathan Long"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 147,
                                "start": 143
                            }
                        ],
                        "text": "1 fully connected layers can be implemented by convolution, therefore, in the rest of the paper, we refer to them also as convolutional layers [10]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1629541,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "317aee7fc081f2b137a85c4f20129007fd8e717e",
            "isKey": false,
            "numCitedBy": 16125,
            "numCiting": 77,
            "paperAbstract": {
                "fragments": [],
                "text": "Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, improve on the previous best result in semantic segmentation. Our key insight is to build \u201cfully convolutional\u201d networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional networks achieve improved segmentation of PASCAL VOC (30% relative improvement to 67.2% mean IU on 2012), NYUDv2, SIFT Flow, and PASCAL-Context, while inference takes one tenth of a second for a typical image."
            },
            "slug": "Fully-Convolutional-Networks-for-Semantic-Shelhamer-Long",
            "title": {
                "fragments": [],
                "text": "Fully Convolutional Networks for Semantic Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 49,
                "text": "It is shown that convolutional networks by themselves, trained end- to-end, pixels-to-pixels, improve on the previous best result in semantic segmentation."
            },
            "venue": {
                "fragments": [],
                "text": "IEEE Transactions on Pattern Analysis and Machine Intelligence"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143840275"
                        ],
                        "name": "Song Han",
                        "slug": "Song-Han",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "47325862"
                        ],
                        "name": "Jeff Pool",
                        "slug": "Jeff-Pool",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Pool",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeff Pool"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2066786849"
                        ],
                        "name": "J. Tran",
                        "slug": "J.-Tran",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Tran",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Tran"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80724002"
                        ],
                        "name": "W. Dally",
                        "slug": "W.-Dally",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dally",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dally"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 2238772,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1ff9a37d766e3a4f39757f5e1b235a42dacf18ff",
            "isKey": false,
            "numCitedBy": 4076,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural networks are both computationally intensive and memory intensive, making them difficult to deploy on embedded systems. Also, conventional networks fix the architecture before training starts; as a result, training cannot improve the architecture. To address these limitations, we describe a method to reduce the storage and computation required by neural networks by an order of magnitude without affecting their accuracy by learning only the important connections. Our method prunes redundant connections using a three-step method. First, we train the network to learn which connections are important. Next, we prune the unimportant connections. Finally, we retrain the network to fine tune the weights of the remaining connections. On the ImageNet dataset, our method reduced the number of parameters of AlexNet by a factor of 9x, from 61 million to 6.7 million, without incurring accuracy loss. Similar experiments with VGG-16 found that the number of parameters can be reduced by 13x, from 138 million to 10.3 million, again with no loss of accuracy."
            },
            "slug": "Learning-both-Weights-and-Connections-for-Efficient-Han-Pool",
            "title": {
                "fragments": [],
                "text": "Learning both Weights and Connections for Efficient Neural Network"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "A method to reduce the storage and computation required by neural networks by an order of magnitude without affecting their accuracy by learning only the important connections, and prunes redundant connections using a three-step method."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2657155"
                        ],
                        "name": "Vincent Vanhoucke",
                        "slug": "Vincent-Vanhoucke",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Vanhoucke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Vanhoucke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33666044"
                        ],
                        "name": "A. Senior",
                        "slug": "A.-Senior",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Senior",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "A. Senior"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715548"
                        ],
                        "name": "Mark Z. Mao",
                        "slug": "Mark-Z.-Mao",
                        "structuredName": {
                            "firstName": "Mark",
                            "lastName": "Mao",
                            "middleNames": [
                                "Z."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Mark Z. Mao"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 104,
                                "start": 100
                            }
                        ],
                        "text": "A fixedpoint implementation of 8-bit integer was compared with 32-bit floating point activations in [31]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 15196840,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "fbeaa499e10e98515f7e1c4ad89165e8c0677427",
            "isKey": false,
            "numCitedBy": 692,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent advances in deep learning have made the use of large, deep neural networks with tens of millions of parameters suitable for a number of applications that require real-time processing. The sheer size of these networks can represent a challenging computational burden, even for modern CPUs. For this reason, GPUs are routinely used instead to train and run such networks. This paper is a tutorial for students and researchers on some of the techniques that can be used to reduce this computational cost considerably on modern x86 CPUs. We emphasize data layout, batching of the computation, the use of SSE2 instructions, and particularly leverage SSSE3 and SSE4 fixed-point instructions which provide a 3\u00d7 improvement over an optimized floating-point baseline. We use speech recognition as an example task, and show that a real-time hybrid hidden Markov model / neural network (HMM/NN) large vocabulary system can be built with a 10\u00d7 speedup over an unoptimized baseline and a 4\u00d7 speedup over an aggressively optimized floating-point baseline at no cost in accuracy. The techniques described extend readily to neural network training and provide an effective alternative to the use of specialized hardware."
            },
            "slug": "Improving-the-speed-of-neural-networks-on-CPUs-Vanhoucke-Senior",
            "title": {
                "fragments": [],
                "text": "Improving the speed of neural networks on CPUs"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper uses speech recognition as an example task, and shows that a real-time hybrid hidden Markov model / neural network (HMM/NN) large vocabulary system can be built with a 10\u00d7 speedup over an unoptimized baseline and a 4\u00d7 speed up over an aggressively optimized floating-point baseline at no cost in accuracy."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2011
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143840275"
                        ],
                        "name": "Song Han",
                        "slug": "Song-Han",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3123774"
                        ],
                        "name": "Huizi Mao",
                        "slug": "Huizi-Mao",
                        "structuredName": {
                            "firstName": "Huizi",
                            "lastName": "Mao",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Huizi Mao"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80724002"
                        ],
                        "name": "W. Dally",
                        "slug": "W.-Dally",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dally",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dally"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 21,
                                "start": 17
                            }
                        ],
                        "text": "Deep compression [22] reduces the storage and energy required to run inference on large networks so they can be deployed on mobile devices."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2134321,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "642d0f49b7826adcf986616f4af77e736229990f",
            "isKey": false,
            "numCitedBy": 5732,
            "numCiting": 41,
            "paperAbstract": {
                "fragments": [],
                "text": "Neural networks are both computationally intensive and memory intensive, making them difficult to deploy on embedded systems with limited hardware resources. To address this limitation, we introduce \"deep compression\", a three stage pipeline: pruning, trained quantization and Huffman coding, that work together to reduce the storage requirement of neural networks by 35x to 49x without affecting their accuracy. Our method first prunes the network by learning only the important connections. Next, we quantize the weights to enforce weight sharing, finally, we apply Huffman coding. After the first two steps we retrain the network to fine tune the remaining connections and the quantized centroids. Pruning, reduces the number of connections by 9x to 13x; Quantization then reduces the number of bits that represent each connection from 32 to 5. On the ImageNet dataset, our method reduced the storage required by AlexNet by 35x, from 240MB to 6.9MB, without loss of accuracy. Our method reduced the size of VGG-16 by 49x from 552MB to 11.3MB, again with no loss of accuracy. This allows fitting the model into on-chip SRAM cache rather than off-chip DRAM memory. Our compression method also facilitates the use of complex neural networks in mobile applications where application size and download bandwidth are constrained. Benchmarked on CPU, GPU and mobile GPU, compressed network has 3x to 4x layerwise speedup and 3x to 7x better energy efficiency."
            },
            "slug": "Deep-Compression:-Compressing-Deep-Neural-Network-Han-Mao",
            "title": {
                "fragments": [],
                "text": "Deep Compression: Compressing Deep Neural Network with Pruning, Trained Quantization and Huffman Coding"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "This work introduces \"deep compression\", a three stage pipeline: pruning, trained quantization and Huffman coding, that work together to reduce the storage requirement of neural networks by 35x to 49x without affecting their accuracy."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3146592"
                        ],
                        "name": "Zhouhan Lin",
                        "slug": "Zhouhan-Lin",
                        "structuredName": {
                            "firstName": "Zhouhan",
                            "lastName": "Lin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Zhouhan Lin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2388466"
                        ],
                        "name": "Matthieu Courbariaux",
                        "slug": "Matthieu-Courbariaux",
                        "structuredName": {
                            "firstName": "Matthieu",
                            "lastName": "Courbariaux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthieu Courbariaux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1710604"
                        ],
                        "name": "R. Memisevic",
                        "slug": "R.-Memisevic",
                        "structuredName": {
                            "firstName": "Roland",
                            "lastName": "Memisevic",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Memisevic"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 109,
                                "start": 105
                            }
                        ],
                        "text": "Back-propagation process by quantizing the representations at each layer of the network was presented in [34] to convert some of the remaining multiplications into binary shifts by restricting the neuron values of power-of-two integers."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2753399,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "67c191bcce6821f736798cb9b31472bcdd1e52a6",
            "isKey": false,
            "numCitedBy": 280,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "For most deep learning algorithms training is notoriously time consuming. Since most of the computation in training neural networks is typically spent on floating point multiplications, we investigate an approach to training that eliminates the need for most of these. Our method consists of two parts: First we stochastically binarize weights to convert multiplications involved in computing hidden states to sign changes. Second, while back-propagating error derivatives, in addition to binarizing the weights, we quantize the representations at each layer to convert the remaining multiplications into binary shifts. Experimental results across 3 popular datasets (MNIST, CIFAR10, SVHN) show that this approach not only does not hurt classification performance but can result in even better performance than standard stochastic gradient descent training, paving the way to fast, hardware-friendly training of neural networks."
            },
            "slug": "Neural-Networks-with-Few-Multiplications-Lin-Courbariaux",
            "title": {
                "fragments": [],
                "text": "Neural Networks with Few Multiplications"
            },
            "tldr": {
                "abstractSimilarityScore": 48,
                "text": "Experimental results show that this approach to training that eliminates the need for floating point multiplications can result in even better performance than standard stochastic gradient descent training, paving the way to fast, hardware-friendly training of neural networks."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2574060"
                        ],
                        "name": "Christian Szegedy",
                        "slug": "Christian-Szegedy",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Szegedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Szegedy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2157222093"
                        ],
                        "name": "Wei Liu",
                        "slug": "Wei-Liu",
                        "structuredName": {
                            "firstName": "Wei",
                            "lastName": "Liu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wei Liu"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39978391"
                        ],
                        "name": "Yangqing Jia",
                        "slug": "Yangqing-Jia",
                        "structuredName": {
                            "firstName": "Yangqing",
                            "lastName": "Jia",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yangqing Jia"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3142556"
                        ],
                        "name": "Pierre Sermanet",
                        "slug": "Pierre-Sermanet",
                        "structuredName": {
                            "firstName": "Pierre",
                            "lastName": "Sermanet",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Pierre Sermanet"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144828948"
                        ],
                        "name": "Scott E. Reed",
                        "slug": "Scott-E.-Reed",
                        "structuredName": {
                            "firstName": "Scott",
                            "lastName": "Reed",
                            "middleNames": [
                                "E."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Scott E. Reed"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1838674"
                        ],
                        "name": "Dragomir Anguelov",
                        "slug": "Dragomir-Anguelov",
                        "structuredName": {
                            "firstName": "Dragomir",
                            "lastName": "Anguelov",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dragomir Anguelov"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1761978"
                        ],
                        "name": "D. Erhan",
                        "slug": "D.-Erhan",
                        "structuredName": {
                            "firstName": "D.",
                            "lastName": "Erhan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Erhan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2657155"
                        ],
                        "name": "Vincent Vanhoucke",
                        "slug": "Vincent-Vanhoucke",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Vanhoucke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Vanhoucke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39863668"
                        ],
                        "name": "Andrew Rabinovich",
                        "slug": "Andrew-Rabinovich",
                        "structuredName": {
                            "firstName": "Andrew",
                            "lastName": "Rabinovich",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Andrew Rabinovich"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 206592484,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e15cf50aa89fee8535703b9f9512fca5bfc43327",
            "isKey": false,
            "numCitedBy": 29917,
            "numCiting": 278,
            "paperAbstract": {
                "fragments": [],
                "text": "We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection."
            },
            "slug": "Going-deeper-with-convolutions-Szegedy-Liu",
            "title": {
                "fragments": [],
                "text": "Going deeper with convolutions"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "A deep convolutional neural network architecture codenamed Inception is proposed that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14)."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054165706"
                        ],
                        "name": "S. Ioffe",
                        "slug": "S.-Ioffe",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Ioffe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ioffe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2574060"
                        ],
                        "name": "Christian Szegedy",
                        "slug": "Christian-Szegedy",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Szegedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Szegedy"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 5808102,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "4d376d6978dad0374edfa6709c9556b42d3594d3",
            "isKey": false,
            "numCitedBy": 29648,
            "numCiting": 33,
            "paperAbstract": {
                "fragments": [],
                "text": "Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization, and in some cases eliminates the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.82% top-5 test error, exceeding the accuracy of human raters."
            },
            "slug": "Batch-Normalization:-Accelerating-Deep-Network-by-Ioffe-Szegedy",
            "title": {
                "fragments": [],
                "text": "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2388466"
                        ],
                        "name": "Matthieu Courbariaux",
                        "slug": "Matthieu-Courbariaux",
                        "structuredName": {
                            "firstName": "Matthieu",
                            "lastName": "Courbariaux",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthieu Courbariaux"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145719986"
                        ],
                        "name": "J. David",
                        "slug": "J.-David",
                        "structuredName": {
                            "firstName": "Jean-Pierre",
                            "lastName": "David",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. David"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 101,
                                "start": 97
                            }
                        ],
                        "text": ",binarized) were believed to be very poor due to the destructive property of binary quantization [35]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 16349374,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1b82d54e9a3b06c603d7987ba3ecf437425f6330",
            "isKey": false,
            "numCitedBy": 469,
            "numCiting": 36,
            "paperAbstract": {
                "fragments": [],
                "text": "Multipliers are the most space and power-hungry arithmetic operators of the digital implementation of deep neural networks. We train a set of state-of-the-art neural networks (Maxout networks) on three benchmark datasets: MNIST, CIFAR-10 and SVHN. They are trained with three distinct formats: floating point, fixed point and dynamic fixed point. For each of those datasets and for each of those formats, we assess the impact of the precision of the multiplications on the final error after training. We find that very low precision is sufficient not just for running trained networks but also for training them. For example, it is possible to train Maxout networks with 10 bits multiplications."
            },
            "slug": "Training-deep-neural-networks-with-low-precision-Courbariaux-Bengio",
            "title": {
                "fragments": [],
                "text": "Training deep neural networks with low precision multiplications"
            },
            "tldr": {
                "abstractSimilarityScore": 40,
                "text": "It is found that very low precision is sufficient not just for running trained networks but also for training them, and it is possible to train Maxout networks with 10 bits multiplications."
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "40081727"
                        ],
                        "name": "Emily L. Denton",
                        "slug": "Emily-L.-Denton",
                        "structuredName": {
                            "firstName": "Emily",
                            "lastName": "Denton",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Emily L. Denton"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2563432"
                        ],
                        "name": "Wojciech Zaremba",
                        "slug": "Wojciech-Zaremba",
                        "structuredName": {
                            "firstName": "Wojciech",
                            "lastName": "Zaremba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wojciech Zaremba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143627859"
                        ],
                        "name": "Joan Bruna",
                        "slug": "Joan-Bruna",
                        "structuredName": {
                            "firstName": "Joan",
                            "lastName": "Bruna",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Joan Bruna"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7340116,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e5ae8ab688051931b4814f6d32b18391f8d1fa8d",
            "isKey": false,
            "numCitedBy": 1281,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "We present techniques for speeding up the test-time evaluation of large convolutional networks, designed for object recognition tasks. These models deliver impressive accuracy, but each image evaluation requires millions of floating point operations, making their deployment on smartphones and Internet-scale clusters problematic. The computation is dominated by the convolution operations in the lower layers of the model. We exploit the redundancy present within the convolutional filters to derive approximations that significantly reduce the required computation. Using large state-of-the-art models, we demonstrate speedups of convolutional layers on both CPU and GPU by a factor of 2 x, while keeping the accuracy within 1% of the original model."
            },
            "slug": "Exploiting-Linear-Structure-Within-Convolutional-Denton-Zaremba",
            "title": {
                "fragments": [],
                "text": "Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Using large state-of-the-art models, this work demonstrates speedups of convolutional layers on both CPU and GPU by a factor of 2 x, while keeping the accuracy within 1% of the original model."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2983898"
                        ],
                        "name": "Ross B. Girshick",
                        "slug": "Ross-B.-Girshick",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Girshick",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross B. Girshick"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 188,
                                "start": 181
                            }
                        ],
                        "text": "In computer vision, a particular type of DNN, known as Convolutional Neural Networks (CNN), have demonstrated state-of-the-art results in object recognition [1,2,3,4] and detection [5,6,7]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 206770307,
            "fieldsOfStudy": [
                "Computer Science",
                "Environmental Science"
            ],
            "id": "7ffdbc358b63378f07311e883dddacc9faeeaf4b",
            "isKey": false,
            "numCitedBy": 14349,
            "numCiting": 35,
            "paperAbstract": {
                "fragments": [],
                "text": "This paper proposes a Fast Region-based Convolutional Network method (Fast R-CNN) for object detection. Fast R-CNN builds on previous work to efficiently classify object proposals using deep convolutional networks. Compared to previous work, Fast R-CNN employs several innovations to improve training and testing speed while also increasing detection accuracy. Fast R-CNN trains the very deep VGG16 network 9x faster than R-CNN, is 213x faster at test-time, and achieves a higher mAP on PASCAL VOC 2012. Compared to SPPnet, Fast R-CNN trains VGG16 3x faster, tests 10x faster, and is more accurate. Fast R-CNN is implemented in Python and C++ (using Caffe) and is available under the open-source MIT License at https://github.com/rbgirshick/fast-rcnn."
            },
            "slug": "Fast-R-CNN-Girshick",
            "title": {
                "fragments": [],
                "text": "Fast R-CNN"
            },
            "tldr": {
                "abstractSimilarityScore": 97,
                "text": "This paper proposes a Fast Region-based Convolutional Network method (Fast R-CNN) for object detection that builds on previous work to efficiently classify object proposals using deep convolutional networks."
            },
            "venue": {
                "fragments": [],
                "text": "2015 IEEE International Conference on Computer Vision (ICCV)"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2574060"
                        ],
                        "name": "Christian Szegedy",
                        "slug": "Christian-Szegedy",
                        "structuredName": {
                            "firstName": "Christian",
                            "lastName": "Szegedy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Christian Szegedy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2054165706"
                        ],
                        "name": "S. Ioffe",
                        "slug": "S.-Ioffe",
                        "structuredName": {
                            "firstName": "Sergey",
                            "lastName": "Ioffe",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Ioffe"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2657155"
                        ],
                        "name": "Vincent Vanhoucke",
                        "slug": "Vincent-Vanhoucke",
                        "structuredName": {
                            "firstName": "Vincent",
                            "lastName": "Vanhoucke",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Vincent Vanhoucke"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "122113652"
                        ],
                        "name": "Alexander A. Alemi",
                        "slug": "Alexander-A.-Alemi",
                        "structuredName": {
                            "firstName": "Alexander",
                            "lastName": "Alemi",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alexander A. Alemi"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 61,
                                "start": 57
                            }
                        ],
                        "text": "Decomposing 3 \u00d7 3 convolutions with two 1 \u00d7 1 is used in [27] and resulted in state-of-the-art performance on object recognition."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1023605,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "b5c26ab8767d046cb6e32d959fdf726aee89bb62",
            "isKey": false,
            "numCitedBy": 8225,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "\n \n Very deep convolutional networks have been central to the largest advances in image recognition performance in recent years. One example is the Inception architecture that has been shown to achieve very good performance at relatively low computational cost. Recently, the introduction of residual connections in conjunction with a more traditional architecture has yielded state-of-the-art performance in the 2015 ILSVRC challenge; its performance was similar to the latest generation Inception-v3 network. This raises the question: Are there any benefits to combining Inception architectures with residual connections? Here we give clear empirical evidence that training with residual connections accelerates the training of Inception networks significantly. There is also some evidence of residual Inception networks outperforming similarly expensive Inception networks without residual connections by a thin margin. We also present several new streamlined architectures for both residual and non-residual Inception networks. These variations improve the single-frame recognition performance on the ILSVRC 2012 classification task significantly. We further demonstrate how proper activation scaling stabilizes the training of very wide residual Inception networks. With an ensemble of three residual and one Inception-v4 networks, we achieve 3.08% top-5 error on the test set of the ImageNet classification (CLS) challenge.\n \n"
            },
            "slug": "Inception-v4,-Inception-ResNet-and-the-Impact-of-on-Szegedy-Ioffe",
            "title": {
                "fragments": [],
                "text": "Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "Clear empirical evidence that training with residual connections accelerates the training of Inception networks significantly is given and several new streamlined architectures for both residual and non-residual Inception Networks are presented."
            },
            "venue": {
                "fragments": [],
                "text": "AAAI"
            },
            "year": 2017
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2983898"
                        ],
                        "name": "Ross B. Girshick",
                        "slug": "Ross-B.-Girshick",
                        "structuredName": {
                            "firstName": "Ross",
                            "lastName": "Girshick",
                            "middleNames": [
                                "B."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Ross B. Girshick"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7408951"
                        ],
                        "name": "Jeff Donahue",
                        "slug": "Jeff-Donahue",
                        "structuredName": {
                            "firstName": "Jeff",
                            "lastName": "Donahue",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jeff Donahue"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1753210"
                        ],
                        "name": "Trevor Darrell",
                        "slug": "Trevor-Darrell",
                        "structuredName": {
                            "firstName": "Trevor",
                            "lastName": "Darrell",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Trevor Darrell"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "153652147"
                        ],
                        "name": "J. Malik",
                        "slug": "J.-Malik",
                        "structuredName": {
                            "firstName": "Jitendra",
                            "lastName": "Malik",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Malik"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 215827080,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "2f4df08d9072fc2ac181b7fced6a245315ce05c8",
            "isKey": false,
            "numCitedBy": 17379,
            "numCiting": 66,
            "paperAbstract": {
                "fragments": [],
                "text": "Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012 -- achieving a mAP of 53.3%. Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also present experiments that provide insight into what the network learns, revealing a rich hierarchy of image features. Source code for the complete system is available at http://www.cs.berkeley.edu/~rbg/rcnn."
            },
            "slug": "Rich-Feature-Hierarchies-for-Accurate-Object-and-Girshick-Donahue",
            "title": {
                "fragments": [],
                "text": "Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation"
            },
            "tldr": {
                "abstractSimilarityScore": 38,
                "text": "This paper proposes a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012 -- achieving a mAP of 53.3%."
            },
            "venue": {
                "fragments": [],
                "text": "2014 IEEE Conference on Computer Vision and Pattern Recognition"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3346186"
                        ],
                        "name": "Forrest N. Iandola",
                        "slug": "Forrest-N.-Iandola",
                        "structuredName": {
                            "firstName": "Forrest",
                            "lastName": "Iandola",
                            "middleNames": [
                                "N."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Forrest N. Iandola"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2318023"
                        ],
                        "name": "M. Moskewicz",
                        "slug": "M.-Moskewicz",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Moskewicz",
                            "middleNames": [
                                "W."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Moskewicz"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2059241"
                        ],
                        "name": "Khalid Ashraf",
                        "slug": "Khalid-Ashraf",
                        "structuredName": {
                            "firstName": "Khalid",
                            "lastName": "Ashraf",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Khalid Ashraf"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143840275"
                        ],
                        "name": "Song Han",
                        "slug": "Song-Han",
                        "structuredName": {
                            "firstName": "Song",
                            "lastName": "Han",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Song Han"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "80724002"
                        ],
                        "name": "W. Dally",
                        "slug": "W.-Dally",
                        "structuredName": {
                            "firstName": "William",
                            "lastName": "Dally",
                            "middleNames": [
                                "J."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Dally"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1732330"
                        ],
                        "name": "K. Keutzer",
                        "slug": "K.-Keutzer",
                        "structuredName": {
                            "firstName": "Kurt",
                            "lastName": "Keutzer",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "K. Keutzer"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 14136028,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "969fbdcd0717bec06228053788c2ff78bbb4daac",
            "isKey": false,
            "numCitedBy": 4092,
            "numCiting": 62,
            "paperAbstract": {
                "fragments": [],
                "text": "Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet). \nThe SqueezeNet architecture is available for download here: this https URL"
            },
            "slug": "SqueezeNet:-AlexNet-level-accuracy-with-50x-fewer-Iandola-Moskewicz",
            "title": {
                "fragments": [],
                "text": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <1MB model size"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "This work proposes a small DNN architecture called SqueezeNet, which achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters and is able to compress to less than 0.5MB (510x smaller than AlexNet)."
            },
            "venue": {
                "fragments": [],
                "text": "ArXiv"
            },
            "year": 2016
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2549369"
                        ],
                        "name": "Kyuyeon Hwang",
                        "slug": "Kyuyeon-Hwang",
                        "structuredName": {
                            "firstName": "Kyuyeon",
                            "lastName": "Hwang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kyuyeon Hwang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "66936521"
                        ],
                        "name": "W. Sung",
                        "slug": "W.-Sung",
                        "structuredName": {
                            "firstName": "Wonyong",
                            "lastName": "Sung",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "W. Sung"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 16104422,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a4db2d26b5d169de6b64de361dc7d4fd5b1f61a3",
            "isKey": false,
            "numCitedBy": 221,
            "numCiting": 19,
            "paperAbstract": {
                "fragments": [],
                "text": "Feedforward deep neural networks that employ multiple hidden layers show high performance in many applications, but they demand complex hardware for implementation. The hardware complexity can be much lowered by minimizing the word-length of weights and signals, but direct quantization for fixed-point network design does not yield good results. We optimize the fixed-point design by employing backpropagation based retraining. The designed fixed-point networks with ternary weights (+1, 0, and -1) and 3-bit signal show only negligible performance loss when compared to the floating-point coun-terparts. The backpropagation for retraining uses quantized weights and fixed-point signal to compute the output, but utilizes high precision values for adapting the networks. A character recognition and a phoneme recognition examples are presented."
            },
            "slug": "Fixed-point-feedforward-deep-neural-network-design-Hwang-Sung",
            "title": {
                "fragments": [],
                "text": "Fixed-point feedforward deep neural network design using weights +1, 0, and \u22121"
            },
            "tldr": {
                "abstractSimilarityScore": 46,
                "text": "The designed fixed-point networks with ternary weights (+1, 0, and -1) and 3-bit signal show only negligible performance loss when compared to the floating-point coun-terparts."
            },
            "venue": {
                "fragments": [],
                "text": "2014 IEEE Workshop on Signal Processing Systems (SiPS)"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [],
                        "name": "Wenlin Chen",
                        "slug": "Wenlin-Chen",
                        "structuredName": {
                            "firstName": "Wenlin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Wenlin Chen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "152983984"
                        ],
                        "name": "James T. Wilson",
                        "slug": "James-T.-Wilson",
                        "structuredName": {
                            "firstName": "James",
                            "lastName": "Wilson",
                            "middleNames": [
                                "T."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "James T. Wilson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2342481"
                        ],
                        "name": "Stephen Tyree",
                        "slug": "Stephen-Tyree",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Tyree",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Stephen Tyree"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "7446832"
                        ],
                        "name": "Kilian Q. Weinberger",
                        "slug": "Kilian-Q.-Weinberger",
                        "structuredName": {
                            "firstName": "Kilian",
                            "lastName": "Weinberger",
                            "middleNames": [
                                "Q."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Kilian Q. Weinberger"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2116664181"
                        ],
                        "name": "Yixin Chen",
                        "slug": "Yixin-Chen",
                        "structuredName": {
                            "firstName": "Yixin",
                            "lastName": "Chen",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yixin Chen"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 15,
                                "start": 11
                            }
                        ],
                        "text": "HashedNets [23] uses a hash function to reduce model size by randomly grouping the weights, such that connections in a hash bucket use a single parameter value."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 543597,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "efb5032e6199c80f83309fd866b25be9545831fd",
            "isKey": false,
            "numCitedBy": 948,
            "numCiting": 61,
            "paperAbstract": {
                "fragments": [],
                "text": "As deep nets are increasingly used in applications suited for mobile devices, a fundamental dilemma becomes apparent: the trend in deep learning is to grow models to absorb ever-increasing data set sizes; however mobile devices are designed with very little memory and cannot store such large models. We present a novel network architecture, HashedNets, that exploits inherent redundancy in neural networks to achieve drastic reductions in model sizes. HashedNets uses a low-cost hash function to randomly group connection weights into hash buckets, and all connections within the same hash bucket share a single parameter value. These parameters are tuned to adjust to the HashedNets weight sharing architecture with standard backprop during training. Our hashing procedure introduces no additional memory overhead, and we demonstrate on several benchmark data sets that HashedNets shrink the storage requirements of neural networks substantially while mostly preserving generalization performance."
            },
            "slug": "Compressing-Neural-Networks-with-the-Hashing-Trick-Chen-Wilson",
            "title": {
                "fragments": [],
                "text": "Compressing Neural Networks with the Hashing Trick"
            },
            "tldr": {
                "abstractSimilarityScore": 43,
                "text": "This work presents a novel network architecture, HashedNets, that exploits inherent redundancy in neural networks to achieve drastic reductions in model sizes, and demonstrates on several benchmark data sets that HashingNets shrink the storage requirements of neural networks substantially while mostly preserving generalization performance."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145727186"
                        ],
                        "name": "R. Caruana",
                        "slug": "R.-Caruana",
                        "structuredName": {
                            "firstName": "Rich",
                            "lastName": "Caruana",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Caruana"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 11536917,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "d770060812fb646b3846a7d398a3066145b5e3c8",
            "isKey": false,
            "numCitedBy": 1549,
            "numCiting": 25,
            "paperAbstract": {
                "fragments": [],
                "text": "Currently, deep neural networks are the state of the art on problems such as speech recognition and computer vision. In this paper we empirically demonstrate that shallow feed-forward nets can learn the complex functions previously learned by deep nets and achieve accuracies previously only achievable with deep models. Moreover, in some cases the shallow nets can learn these deep functions using the same number of parameters as the original deep models. On the TIMIT phoneme recognition and CIFAR-10 image recognition tasks, shallow nets can be trained that perform similarly to complex, well-engineered, deeper convolutional models."
            },
            "slug": "Do-Deep-Nets-Really-Need-to-be-Deep-Ba-Caruana",
            "title": {
                "fragments": [],
                "text": "Do Deep Nets Really Need to be Deep?"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "This paper empirically demonstrate that shallow feed-forward nets can learn the complex functions previously learned by deep nets and achieve accuracies previously only achievable with deep models."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2357931"
                        ],
                        "name": "Steven K. Esser",
                        "slug": "Steven-K.-Esser",
                        "structuredName": {
                            "firstName": "Steven",
                            "lastName": "Esser",
                            "middleNames": [
                                "K."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Steven K. Esser"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2730753"
                        ],
                        "name": "R. Appuswamy",
                        "slug": "R.-Appuswamy",
                        "structuredName": {
                            "firstName": "Rathinakumar",
                            "lastName": "Appuswamy",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Appuswamy"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2408151"
                        ],
                        "name": "P. Merolla",
                        "slug": "P.-Merolla",
                        "structuredName": {
                            "firstName": "Paul",
                            "lastName": "Merolla",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "P. Merolla"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2100344"
                        ],
                        "name": "J. Arthur",
                        "slug": "J.-Arthur",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Arthur",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Arthur"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1944330"
                        ],
                        "name": "D. Modha",
                        "slug": "D.-Modha",
                        "structuredName": {
                            "firstName": "Dharmendra",
                            "lastName": "Modha",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Modha"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 52,
                                "start": 48
                            }
                        ],
                        "text": "A fully binary network at run time presented in [37] using a similar approach to EBP, showing significant improvement in energy efficiency."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 16801562,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "04105898efe96c7f2d876e6bcb9e19afd3e23635",
            "isKey": false,
            "numCitedBy": 255,
            "numCiting": 24,
            "paperAbstract": {
                "fragments": [],
                "text": "Solving real world problems with embedded neural networks requires both training algorithms that achieve high performance and compatible hardware that runs in real time while remaining energy efficient. For the former, deep learning using backpropagation has recently achieved a string of successes across many domains and datasets. For the latter, neuromorphic chips that run spiking neural networks have recently achieved unprecedented energy efficiency. To bring these two advances together, we must first resolve the incompatibility between backpropagation, which uses continuous-output neurons and synaptic weights, and neuromorphic designs, which employ spiking neurons and discrete synapses. Our approach is to treat spikes and discrete synapses as continuous probabilities, which allows training the network using standard backpropagation. The trained network naturally maps to neuromorphic hardware by sampling the probabilities to create one or more networks, which are merged using ensemble averaging. To demonstrate, we trained a sparsely connected network that runs on the TrueNorth chip using the MNIST dataset. With a high performance network (ensemble of 64), we achieve 99.42% accuracy at 108 \u03bcJ per image, and with a high efficiency network (ensemble of 1) we achieve 92.7% accuracy at 0.268 \u03bcJ per image."
            },
            "slug": "Backpropagation-for-Energy-Efficient-Neuromorphic-Esser-Appuswamy",
            "title": {
                "fragments": [],
                "text": "Backpropagation for Energy-Efficient Neuromorphic Computing"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This work treats spikes and discrete synapses as continuous probabilities, which allows training the network using standard backpropagation and naturally maps to neuromorphic hardware by sampling the probabilities to create one or more networks, which are merged using ensemble averaging."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1726807"
                        ],
                        "name": "Diederik P. Kingma",
                        "slug": "Diederik-P.-Kingma",
                        "structuredName": {
                            "firstName": "Diederik",
                            "lastName": "Kingma",
                            "middleNames": [
                                "P."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Diederik P. Kingma"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2503659"
                        ],
                        "name": "Jimmy Ba",
                        "slug": "Jimmy-Ba",
                        "structuredName": {
                            "firstName": "Jimmy",
                            "lastName": "Ba",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Jimmy Ba"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": "For XNOR-Net and BNN we used ADAM [42]."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 113,
                                "start": 109
                            }
                        ],
                        "text": "Lastly, the parameters and the learning rate gets updated by an update rule e.g.,SGD update with momentum or ADAM [42]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "ADAM converges faster and usually achieves better accuracy for binary inputs [11]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 38,
                                "start": 34
                            }
                        ],
                        "text": ",SGD update with momentum or ADAM [42]."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 459,
                                "start": 455
                            }
                        ],
                        "text": "1: Binarizing weight filters: 2: for l = 1 to L do 3: for kth filter in lth layer do 4: Alk = 1n\u2016W t lk\u2016`1\n5: Blk = sign(Wtlk) 6: W\u0303lk = AlkBlk 7: Y\u0302 = BinaryForward(I,B,A) // standard forward propagation except that convolutions are computed\nusing equation 1 or 11\n8: \u2202C \u2202W\u0303 = BinaryBackward( \u2202C \u2202Y\u0302 , W\u0303) // standard backward propagation except that gradients are computed\nusing W\u0303 instead ofWt\n9: W\u0303 = UpdateParameters(W\u0303t, \u2202C \u2202W\u0303 , \u03b7t) // Any update rules (e.g.,SGD or ADAM) 10: \u03b7t+1 = UpdateLearningrate(\u03b7t, t) // Any learning rate scheduling function"
                    },
                    "intents": []
                }
            ],
            "corpusId": 6628106,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a6cb366736791bcccc5c8639de5a8f9636bf87e8",
            "isKey": true,
            "numCitedBy": 91740,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm."
            },
            "slug": "Adam:-A-Method-for-Stochastic-Optimization-Kingma-Ba",
            "title": {
                "fragments": [],
                "text": "Adam: A Method for Stochastic Optimization"
            },
            "tldr": {
                "abstractSimilarityScore": 69,
                "text": "This work introduces Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments, and provides a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2053671127"
                        ],
                        "name": "Li Wan",
                        "slug": "Li-Wan",
                        "structuredName": {
                            "firstName": "Li",
                            "lastName": "Wan",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Li Wan"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "48799969"
                        ],
                        "name": "Matthew D. Zeiler",
                        "slug": "Matthew-D.-Zeiler",
                        "structuredName": {
                            "firstName": "Matthew",
                            "lastName": "Zeiler",
                            "middleNames": [
                                "D."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Matthew D. Zeiler"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "33551113"
                        ],
                        "name": "Sixin Zhang",
                        "slug": "Sixin-Zhang",
                        "structuredName": {
                            "firstName": "Sixin",
                            "lastName": "Zhang",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sixin Zhang"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2276554"
                        ],
                        "name": "R. Fergus",
                        "slug": "R.-Fergus",
                        "structuredName": {
                            "firstName": "Rob",
                            "lastName": "Fergus",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Fergus"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 112,
                                "start": 108
                            }
                        ],
                        "text": "We also compare our method with BinaryNet on ImageNet, and our method outperforms BinaryNet by large margin.[39] argued that the noise introduced by weight binarization provide a form of regularization, which could help to improve test accuracy."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 2936324,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "38f35dd624cd1cf827416e31ac5e0e0454028eca",
            "isKey": false,
            "numCitedBy": 2105,
            "numCiting": 15,
            "paperAbstract": {
                "fragments": [],
                "text": "We introduce DropConnect, a generalization of Dropout (Hinton et al., 2012), for regularizing large fully-connected layers within neural networks. When training with Dropout, a randomly selected subset of activations are set to zero within each layer. DropConnect instead sets a randomly selected subset of weights within the network to zero. Each unit thus receives input from a random subset of units in the previous layer. We derive a bound on the generalization performance of both Dropout and DropConnect. We then evaluate DropConnect on a range of datasets, comparing to Dropout, and show state-of-the-art results on several image recognition benchmarks by aggregating multiple DropConnect-trained models."
            },
            "slug": "Regularization-of-Neural-Networks-using-DropConnect-Wan-Zeiler",
            "title": {
                "fragments": [],
                "text": "Regularization of Neural Networks using DropConnect"
            },
            "tldr": {
                "abstractSimilarityScore": 71,
                "text": "This work introduces DropConnect, a generalization of Dropout, for regularizing large fully-connected layers within neural networks, and derives a bound on the generalization performance of both Dropout and DropConnect."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1912398"
                        ],
                        "name": "Daniel Soudry",
                        "slug": "Daniel-Soudry",
                        "structuredName": {
                            "firstName": "Daniel",
                            "lastName": "Soudry",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Daniel Soudry"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2477463"
                        ],
                        "name": "Itay Hubara",
                        "slug": "Itay-Hubara",
                        "structuredName": {
                            "firstName": "Itay",
                            "lastName": "Hubara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Itay Hubara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1766683"
                        ],
                        "name": "R. Meir",
                        "slug": "R.-Meir",
                        "structuredName": {
                            "firstName": "Ron",
                            "lastName": "Meir",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Meir"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 41,
                                "start": 37
                            }
                        ],
                        "text": "Expectation BackPropagation (EBP) in [36] showed high performance can be achieved by a network with binary weights and binary activations."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 14245558,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "feaa7e295c7a43ec52091ed9ade1a9a1e5d9bed2",
            "isKey": false,
            "numCitedBy": 206,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "Multilayer Neural Networks (MNNs) are commonly trained using gradient descent-based methods, such as BackPropagation (BP). Inference in probabilistic graphical models is often done using variational Bayes methods, such as Expectation Propagation (EP). We show how an EP based approach can also be used to train deterministic MNNs. Specifically, we approximate the posterior of the weights given the data using a \"mean-field\" factorized distribution, in an online setting. Using online EP and the central limit theorem we find an analytical approximation to the Bayes update of this posterior, as well as the resulting Bayes estimates of the weights and outputs. \n \nDespite a different origin, the resulting algorithm, Expectation BackPropagation (EBP), is very similar to BP in form and efficiency. However, it has several additional advantages: (1) Training is parameter-free, given initial conditions (prior) and the MNN architecture. This is useful for large-scale problems, where parameter tuning is a major challenge. (2) The weights can be restricted to have discrete values. This is especially useful for implementing trained MNNs in precision limited hardware chips, thus improving their speed and energy efficiency by several orders of magnitude. \n \nWe test the EBP algorithm numerically in eight binary text classification tasks. In all tasks, EBP outperforms: (1) standard BP with the optimal constant learning rate (2) previously reported state of the art. Interestingly, EBP-trained MNNs with binary weights usually perform better than MNNs with continuous (real) weights - if we average the MNN output using the inferred posterior."
            },
            "slug": "Expectation-Backpropagation:-Parameter-Free-of-with-Soudry-Hubara",
            "title": {
                "fragments": [],
                "text": "Expectation Backpropagation: Parameter-Free Training of Multilayer Neural Networks with Continuous or Discrete Weights"
            },
            "tldr": {
                "abstractSimilarityScore": 39,
                "text": "It is shown how an EP based approach can also be used to train deterministic MNNs, and an analytical approximation to the Bayes update of this posterior is found, as well as the resulting Bayes estimates of the weights and outputs."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "21226067"
                        ],
                        "name": "H. Nguyen",
                        "slug": "H.-Nguyen",
                        "structuredName": {
                            "firstName": "Hien",
                            "lastName": "Nguyen",
                            "middleNames": [
                                "Van"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "H. Nguyen"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145668226"
                        ],
                        "name": "S. Zhou",
                        "slug": "S.-Zhou",
                        "structuredName": {
                            "firstName": "Shaohua",
                            "lastName": "Zhou",
                            "middleNames": [
                                "Kevin"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Zhou"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "39963722"
                        ],
                        "name": "Raviteja Vemulapalli",
                        "slug": "Raviteja-Vemulapalli",
                        "structuredName": {
                            "firstName": "Raviteja",
                            "lastName": "Vemulapalli",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Raviteja Vemulapalli"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[21] proposed to reduce the number of activations for compression and acceleration."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2767949,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "524cef2efdbed2af694ffb0c8f83e6890e178f16",
            "isKey": false,
            "numCitedBy": 107,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Cross-modality image synthesis has recently gained significant interest in the medical imaging community. In this paper, we propose a novel architecture called location-sensitive deep network LSDN for synthesizing images across domains. Our network integrates intensity feature from image voxels and spatial information in a principled manner. Specifically, LSDN models hidden nodes as products of features and spatial responses. We then propose a novel method, called ShrinkConnect, for reducing the computations of LSDN without sacrificing synthesis accuracy. ShrinkConnect enforces simultaneous sparsity to find a compact set of functions that accurately approximates the responses of all hidden nodes. Experimental results demonstrate that LSDN+ShrinkConnect outperforms the state of the art in cross-domain synthesis of MRI brain scans by a significant margin. Our approach is also computationally efficient, e.g. 26\u00d7 faster than other sparse representation based methods."
            },
            "slug": "Cross-Domain-Synthesis-of-Medical-Images-Using-Deep-Nguyen-Zhou",
            "title": {
                "fragments": [],
                "text": "Cross-Domain Synthesis of Medical Images Using Efficient Location-Sensitive Deep Network"
            },
            "tldr": {
                "abstractSimilarityScore": 55,
                "text": "A novel architecture called location-sensitive deep network LSDN is proposed for synthesizing images across domains that integrates intensity feature from image voxels and spatial information in a principled manner and is computationally efficient, e.g. 26\u00d7 faster than other sparse representation based methods."
            },
            "venue": {
                "fragments": [],
                "text": "MICCAI"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736279"
                        ],
                        "name": "B. Hassibi",
                        "slug": "B.-Hassibi",
                        "structuredName": {
                            "firstName": "Babak",
                            "lastName": "Hassibi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Hassibi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2586918"
                        ],
                        "name": "D. Stork",
                        "slug": "D.-Stork",
                        "structuredName": {
                            "firstName": "David",
                            "lastName": "Stork",
                            "middleNames": [
                                "G."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "D. Stork"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 7057040,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "a42954d4b9d0ccdf1036e0af46d87a01b94c3516",
            "isKey": false,
            "numCitedBy": 1594,
            "numCiting": 21,
            "paperAbstract": {
                "fragments": [],
                "text": "We investigate the use of information from all second order derivatives of the error function to perform network pruning (i.e., removing unimportant weights from a trained network) in order to improve generalization, simplify networks, reduce hardware or storage requirements, increase the speed of further training, and in some cases enable rule extraction. Our method, Optimal Brain Surgeon (OBS), is Significantly better than magnitude-based methods and Optimal Brain Damage [Le Cun, Denker and Solla, 1990], which often remove the wrong weights. OBS permits the pruning of more weights than other methods (for the same error on the training set), and thus yields better generalization on test data. Crucial to OBS is a recursion relation for calculating the inverse Hessian matrix H-1 from training data and structural information of the net. OBS permits a 90%, a 76%, and a 62% reduction in weights over backpropagation with weight decay on three benchmark MONK's problems [Thrun et al., 1991]. Of OBS, Optimal Brain Damage, and magnitude-based methods, only OBS deletes the correct weights from a trained XOR network in every case. Finally, whereas Sejnowski and Rosenberg [1987] used 18,000 weights in their NETtalk network, we used OBS to prune a network to just 1560 weights, yielding better generalization."
            },
            "slug": "Second-Order-Derivatives-for-Network-Pruning:-Brain-Hassibi-Stork",
            "title": {
                "fragments": [],
                "text": "Second Order Derivatives for Network Pruning: Optimal Brain Surgeon"
            },
            "tldr": {
                "abstractSimilarityScore": 41,
                "text": "Of OBS, Optimal Brain Damage, and magnitude-based methods, only OBS deletes the correct weights from a trained XOR network in every case, and thus yields better generalization on test data."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1992
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3066793"
                        ],
                        "name": "Carlo Baldassi",
                        "slug": "Carlo-Baldassi",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "Baldassi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Carlo Baldassi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3407416"
                        ],
                        "name": "Alessandro Ingrosso",
                        "slug": "Alessandro-Ingrosso",
                        "structuredName": {
                            "firstName": "Alessandro",
                            "lastName": "Ingrosso",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Alessandro Ingrosso"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1975555"
                        ],
                        "name": "C. Lucibello",
                        "slug": "C.-Lucibello",
                        "structuredName": {
                            "firstName": "Carlo",
                            "lastName": "Lucibello",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "C. Lucibello"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "49186258"
                        ],
                        "name": "Luca Saglietti",
                        "slug": "Luca-Saglietti",
                        "structuredName": {
                            "firstName": "Luca",
                            "lastName": "Saglietti",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Luca Saglietti"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1719010"
                        ],
                        "name": "R. Zecchina",
                        "slug": "R.-Zecchina",
                        "structuredName": {
                            "firstName": "Riccardo",
                            "lastName": "Zecchina",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "R. Zecchina"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "UNPAYWALL"
                },
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[40] proposed fully binary training and testing in an array of committee machines with randomized input."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 2595906,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "599e769b65ab64f247926f38c9c080c45a12271a",
            "isKey": false,
            "numCitedBy": 95,
            "numCiting": 30,
            "paperAbstract": {
                "fragments": [],
                "text": "We show that discrete synaptic weights can be efficiently used for learning in large scale neural systems, and lead to unanticipated computational performance. We focus on the representative case of learning random patterns with binary synapses in single layer networks. The standard statistical analysis shows that this problem is exponentially dominated by isolated solutions that are extremely hard to find algorithmically. Here, we introduce a novel method that allows us to find analytical evidence for the existence of subdominant and extremely dense regions of solutions. Numerical experiments confirm these findings. We also show that the dense regions are surprisingly accessible by simple learning protocols, and that these synaptic configurations are robust to perturbations and generalize better than typical solutions. These outcomes extend to synapses with multiple states and to deeper neural architectures. The large deviation measure also suggests how to design novel algorithmic schemes for optimization based on local entropy maximization."
            },
            "slug": "Subdominant-Dense-Clusters-Allow-for-Simple-and-in-Baldassi-Ingrosso",
            "title": {
                "fragments": [],
                "text": "Subdominant Dense Clusters Allow for Simple Learning and High Computational Performance in Neural Networks with Discrete Synapses."
            },
            "tldr": {
                "abstractSimilarityScore": 74,
                "text": "It is shown that discrete synaptic weights can be efficiently used for learning in large scale neural systems, and lead to unanticipated computational performance, and that these synaptic configurations are robust to perturbations and generalize better than typical solutions."
            },
            "venue": {
                "fragments": [],
                "text": "Physical review letters"
            },
            "year": 2015
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "145563465"
                        ],
                        "name": "Sanjeev Arora",
                        "slug": "Sanjeev-Arora",
                        "structuredName": {
                            "firstName": "Sanjeev",
                            "lastName": "Arora",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Sanjeev Arora"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1736564"
                        ],
                        "name": "Aditya Bhaskara",
                        "slug": "Aditya-Bhaskara",
                        "structuredName": {
                            "firstName": "Aditya",
                            "lastName": "Bhaskara",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Aditya Bhaskara"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144804200"
                        ],
                        "name": "Rong Ge",
                        "slug": "Rong-Ge",
                        "structuredName": {
                            "firstName": "Rong",
                            "lastName": "Ge",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Rong Ge"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1901958"
                        ],
                        "name": "Tengyu Ma",
                        "slug": "Tengyu-Ma",
                        "structuredName": {
                            "firstName": "Tengyu",
                            "lastName": "Ma",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Tengyu Ma"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[30] proposed a provably polynomial time algorithm for training a sparse networks with +1/0/-1 weights."
                    },
                    "intents": []
                }
            ],
            "corpusId": 8049057,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "1d6e6adc7a841393fc10b78dc0018e550aff589d",
            "isKey": false,
            "numCitedBy": 289,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "We give algorithms with provable guarantees that learn a class of deep nets in the generative model view popularized by Hinton and others. Our generative model is an n node multilayer network that has degree at most n\u03b3 for some \u03b3 < 1 and each edge has a random edge weight in [-1, 1]. Our algorithm learns almost all networks in this class with polynomial running time. The sample complexity is quadratic or cubic depending upon the details of the model. \n \nThe algorithm uses layerwise learning. It is based upon a novel idea of observing correlations among features and using these to infer the underlying edge structure via a global graph recovery procedure. The analysis of the algorithm reveals interesting structure of neural nets with random edge weights."
            },
            "slug": "Provable-Bounds-for-Learning-Some-Deep-Arora-Bhaskara",
            "title": {
                "fragments": [],
                "text": "Provable Bounds for Learning Some Deep Representations"
            },
            "tldr": {
                "abstractSimilarityScore": 65,
                "text": "This work gives algorithms with provable guarantees that learn a class of deep nets in the generative model view popularized by Hinton and others, based upon a novel idea of observing correlations among features and using these to infer the underlying edge structure via a global graph recovery procedure."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2014
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727849"
                        ],
                        "name": "S. Hanson",
                        "slug": "S.-Hanson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Hanson",
                            "middleNames": [
                                "Jose"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hanson"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144442133"
                        ],
                        "name": "L. Pratt",
                        "slug": "L.-Pratt",
                        "structuredName": {
                            "firstName": "Lorien",
                            "lastName": "Pratt",
                            "middleNames": [
                                "Y."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "L. Pratt"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 9344018,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "f4ea5a6ff3ffcd11ec2e6ed7828a7d41279fb3ad",
            "isKey": false,
            "numCitedBy": 518,
            "numCiting": 5,
            "paperAbstract": {
                "fragments": [],
                "text": "Rumelhart (1987), has proposed a method for choosing minimal or \"simple\" representations during learning in Back-propagation networks. This approach can be used to (a) dynamically select the number of hidden units, (b) construct a representation that is appropriate for the problem and (c) thus improve the generalization ability of Back-propagation networks. The method Rumelhart suggests involves adding penalty terms to the usual error function. In this paper we introduce Rumelhart's minimal networks idea and compare two possible biases on the weight search space. These biases are compared in both simple counting problems and a speech recognition problem. In general, the constrained search does seem to minimize the number of hidden units required with an expected increase in local minima."
            },
            "slug": "Comparing-Biases-for-Minimal-Network-Construction-Hanson-Pratt",
            "title": {
                "fragments": [],
                "text": "Comparing Biases for Minimal Network Construction with Back-Propagation"
            },
            "tldr": {
                "abstractSimilarityScore": 42,
                "text": "This paper introduces Rumelhart's minimal networks idea and compares two possible biases on the weight search space that are compared in both simple counting problems and a speech recognition problem."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1988
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2921469"
                        ],
                        "name": "Yann Dauphin",
                        "slug": "Yann-Dauphin",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "Dauphin",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann Dauphin"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1751762"
                        ],
                        "name": "Yoshua Bengio",
                        "slug": "Yoshua-Bengio",
                        "structuredName": {
                            "firstName": "Yoshua",
                            "lastName": "Bengio",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yoshua Bengio"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 4,
                                "start": 0
                            }
                        ],
                        "text": "[15] trains a shallow network on SIFT features to classify the ImageNet dataset."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "corpusId": 14228101,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "306c7cd74beda5a09662b5f289bba50a2b5ea308",
            "isKey": false,
            "numCitedBy": 69,
            "numCiting": 16,
            "paperAbstract": {
                "fragments": [],
                "text": "This article exposes the failure of some big neural networks to leverage added capacity to reduce underfitting. Past research suggest diminishing returns when increasing the size of neural networks. Our experiments on ImageNet LSVRC-2010 show that this may be due to the fact there are highly diminishing returns for capacity in terms of training error, leading to underfitting. This suggests that the optimization method - first order gradient descent - fails at this regime. Directly attacking this problem, either through the optimization method or the choices of parametrization, may allow to improve the generalization error on large datasets, for which a large capacity is required."
            },
            "slug": "Big-Neural-Networks-Waste-Capacity-Dauphin-Bengio",
            "title": {
                "fragments": [],
                "text": "Big Neural Networks Waste Capacity"
            },
            "tldr": {
                "abstractSimilarityScore": 45,
                "text": "The experiments on ImageNet LSVRC-2010 show that this may be due to the fact there are highly diminishing returns for capacity in terms of training error, leading to underfitting, suggesting that the optimization method - first order gradient descent - fails at this regime."
            },
            "venue": {
                "fragments": [],
                "text": "ICLR"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2416462"
                        ],
                        "name": "G. Cybenko",
                        "slug": "G.-Cybenko",
                        "structuredName": {
                            "firstName": "George",
                            "lastName": "Cybenko",
                            "middleNames": [
                                "V."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "G. Cybenko"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [],
            "corpusId": 3958369,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "8da1dda34ecc96263102181448c94ec7d645d085",
            "isKey": false,
            "numCitedBy": 6455,
            "numCiting": 26,
            "paperAbstract": {
                "fragments": [],
                "text": "In this paper we demonstrate that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube; only mild conditions are imposed on the univariate function. Our results settle an open question about representability in the class of single hidden layer neural networks. In particular, we show that arbitrary decision regions can be arbitrarily well approximated by continuous feedforward neural networks with only a single internal, hidden layer and any continuous sigmoidal nonlinearity. The paper discusses approximation properties of other possible types of nonlinearities that might be implemented by artificial neural networks."
            },
            "slug": "Approximation-by-superpositions-of-a-sigmoidal-Cybenko",
            "title": {
                "fragments": [],
                "text": "Approximation by superpositions of a sigmoidal function"
            },
            "tldr": {
                "abstractSimilarityScore": 95,
                "text": "It is demonstrated that finite linear combinations of compositions of a fixed, univariate function and a set of affine functionals can uniformly approximate any continuous function ofn real variables with support in the unit hypercube."
            },
            "venue": {
                "fragments": [],
                "text": "Math. Control. Signals Syst."
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1715051"
                        ],
                        "name": "Misha Denil",
                        "slug": "Misha-Denil",
                        "structuredName": {
                            "firstName": "Misha",
                            "lastName": "Denil",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Misha Denil"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "3355894"
                        ],
                        "name": "B. Shakibi",
                        "slug": "B.-Shakibi",
                        "structuredName": {
                            "firstName": "Babak",
                            "lastName": "Shakibi",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "B. Shakibi"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "46573521"
                        ],
                        "name": "Laurent Dinh",
                        "slug": "Laurent-Dinh",
                        "structuredName": {
                            "firstName": "Laurent",
                            "lastName": "Dinh",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Laurent Dinh"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1706809"
                        ],
                        "name": "Marc'Aurelio Ranzato",
                        "slug": "Marc'Aurelio-Ranzato",
                        "structuredName": {
                            "firstName": "Marc'Aurelio",
                            "lastName": "Ranzato",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Marc'Aurelio Ranzato"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1737568"
                        ],
                        "name": "N. D. Freitas",
                        "slug": "N.-D.-Freitas",
                        "structuredName": {
                            "firstName": "Nando",
                            "lastName": "Freitas",
                            "middleNames": [
                                "de"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "N. D. Freitas"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 70,
                                "start": 66
                            }
                        ],
                        "text": "This typically results in inefficient computation and memory usage[12]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 1639981,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e8650503ab80ad7299f0845b1843abf3a97f313a",
            "isKey": false,
            "numCitedBy": 1009,
            "numCiting": 40,
            "paperAbstract": {
                "fragments": [],
                "text": "We demonstrate that there is significant redundancy in the parameterization of several deep learning models. Given only a few weight values for each feature it is possible to accurately predict the remaining values. Moreover, we show that not only can the parameter values be predicted, but many of them need not be learned at all. We train several different architectures by learning only a small number of weights and predicting the rest. In the best case we are able to predict more than 95% of the weights of a network without any drop in accuracy."
            },
            "slug": "Predicting-Parameters-in-Deep-Learning-Denil-Shakibi",
            "title": {
                "fragments": [],
                "text": "Predicting Parameters in Deep Learning"
            },
            "tldr": {
                "abstractSimilarityScore": 72,
                "text": "It is demonstrated that there is significant redundancy in the parameterization of several deep learning models and not only can the parameter values be predicted, but many of them need not be learned at all."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 2013
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1688882"
                        ],
                        "name": "Yann LeCun",
                        "slug": "Yann-LeCun",
                        "structuredName": {
                            "firstName": "Yann",
                            "lastName": "LeCun",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Yann LeCun"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1747317"
                        ],
                        "name": "J. Denker",
                        "slug": "J.-Denker",
                        "structuredName": {
                            "firstName": "John",
                            "lastName": "Denker",
                            "middleNames": [
                                "S."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "J. Denker"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1759839"
                        ],
                        "name": "S. Solla",
                        "slug": "S.-Solla",
                        "structuredName": {
                            "firstName": "Sara",
                            "lastName": "Solla",
                            "middleNames": [
                                "A."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Solla"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 25,
                                "start": 21
                            }
                        ],
                        "text": "Optimal Brain Damage [18] and Optimal Brain Surgeon [19] use the Hessian of the loss function to prune a network by reducing the number of connections."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 7785881,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "e7297db245c3feb1897720b173a59fe7e36babb7",
            "isKey": false,
            "numCitedBy": 3518,
            "numCiting": 31,
            "paperAbstract": {
                "fragments": [],
                "text": "We have used information-theoretic ideas to derive a class of practical and nearly optimal schemes for adapting the size of a neural network. By removing unimportant weights from a network, several improvements can be expected: better generalization, fewer training examples required, and improved speed of learning and/or classification. The basic idea is to use second-derivative information to make a tradeoff between network complexity and training set error. Experiments confirm the usefulness of the methods on a real-world application."
            },
            "slug": "Optimal-Brain-Damage-LeCun-Denker",
            "title": {
                "fragments": [],
                "text": "Optimal Brain Damage"
            },
            "tldr": {
                "abstractSimilarityScore": 60,
                "text": "A class of practical and nearly optimal schemes for adapting the size of a neural network by using second-derivative information to make a tradeoff between network complexity and training set error is derived."
            },
            "venue": {
                "fragments": [],
                "text": "NIPS"
            },
            "year": 1989
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1745715"
                        ],
                        "name": "F. Seide",
                        "slug": "F.-Seide",
                        "structuredName": {
                            "firstName": "Frank",
                            "lastName": "Seide",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "F. Seide"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "143736623"
                        ],
                        "name": "Gang Li",
                        "slug": "Gang-Li",
                        "structuredName": {
                            "firstName": "Gang",
                            "lastName": "Li",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Gang Li"
                    }
                ],
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "144580027"
                        ],
                        "name": "Dong Yu",
                        "slug": "Dong-Yu",
                        "structuredName": {
                            "firstName": "Dong",
                            "lastName": "Yu",
                            "middleNames": []
                        }
                    },
                    {
                        "fragments": [],
                        "text": "Dong Yu"
                    }
                ]
            ],
            "badges": [
                {
                    "id": "OPEN_ACCESS"
                }
            ],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 87,
                                "start": 83
                            }
                        ],
                        "text": ",vision and speech), however, shallow networks cannot compete with the deep models [14]."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 398770,
            "fieldsOfStudy": [
                "Computer Science"
            ],
            "id": "473f0739666af2791ad6592822118240ed968b70",
            "isKey": false,
            "numCitedBy": 878,
            "numCiting": 20,
            "paperAbstract": {
                "fragments": [],
                "text": "Context-Dependent Deep-Neural-Network HMMs, or CD-DNN-HMMs, combine the classic artificial-neural-network HMMs with traditional context-dependent acoustic modeling and deep-belief-network pre-training. CD-DNN-HMMs greatly outperform conventional CD-GMM (Gaussian mixture model) HMMs: The word error rate is reduced by up to one third on the difficult benchmarking task of speaker-independent single-pass transcription of telephone conversations."
            },
            "slug": "Conversational-Speech-Transcription-Using-Deep-Seide-Li",
            "title": {
                "fragments": [],
                "text": "Conversational Speech Transcription Using Context-Dependent Deep Neural Networks"
            },
            "tldr": {
                "abstractSimilarityScore": 96,
                "text": "Context-Dependent Deep-Neural-Network HMMs, or CD-DNN-HMMs, combine the classic artificial-neural-network HMMs with traditional context-dependent acoustic modeling and deep-belief-network pre-training to greatly outperform conventional CD-GMM (Gaussian mixture model) HMMs."
            },
            "venue": {
                "fragments": [],
                "text": "ICML"
            },
            "year": 2012
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "1727849"
                        ],
                        "name": "S. Hanson",
                        "slug": "S.-Hanson",
                        "structuredName": {
                            "firstName": "Stephen",
                            "lastName": "Hanson",
                            "middleNames": [
                                "Jose"
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "S. Hanson"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [],
            "corpusId": 60565534,
            "fieldsOfStudy": [
                "Biology"
            ],
            "id": "69d7086300e7f5322c06f2f242a565b3a182efb5",
            "isKey": false,
            "numCitedBy": 4734,
            "numCiting": 22,
            "paperAbstract": {
                "fragments": [],
                "text": "Bill Baird { Publications References 1] B. Baird. Bifurcation analysis of oscillating neural network model of pattern recognition in the rabbit olfactory bulb. In D. 3] B. Baird. Bifurcation analysis of a network model of the rabbit olfactory bulb with periodic attractors stored by a sequence learning algorithm. 5] B. Baird. Bifurcation theory methods for programming static or periodic attractors and their bifurcations in dynamic neural networks."
            },
            "slug": "In-Advances-in-Neural-Information-Processing-Hanson",
            "title": {
                "fragments": [],
                "text": "In Advances in Neural Information Processing Systems"
            },
            "venue": {
                "fragments": [],
                "text": "NIPS 1990"
            },
            "year": 1990
        },
        {
            "authors": [
                [
                    {
                        "bitmap$0": false,
                        "ids": [
                            "2101743969"
                        ],
                        "name": "M. Gottmer",
                        "slug": "M.-Gottmer",
                        "structuredName": {
                            "firstName": "M.",
                            "lastName": "Gottmer",
                            "middleNames": [
                                "L."
                            ]
                        }
                    },
                    {
                        "fragments": [],
                        "text": "M. Gottmer"
                    }
                ]
            ],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 172,
                                "start": 169
                            }
                        ],
                        "text": "Concurrent to the recent progress in recognition, interesting advancements have been happening in virtual reality (VR by Oculus) [8], augmented reality (AR by HoloLens) [9], and smart wearable devices."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "corpusId": 193554665,
            "fieldsOfStudy": [
                "Art"
            ],
            "id": "11b775f96ee78f82572b59c13a2c035dc558afa6",
            "isKey": false,
            "numCitedBy": 12,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "Merging-Reality-and-Virtuality-with-Microsoft-Gottmer",
            "title": {
                "fragments": [],
                "text": "Merging Reality and Virtuality with Microsoft HoloLens"
            },
            "venue": {
                "fragments": [],
                "text": ""
            },
            "year": 2015
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Big neural networks waste capacity. arXiv preprint arXiv:1301"
            },
            "venue": {
                "fragments": [],
                "text": "Big neural networks waste capacity. arXiv preprint arXiv:1301"
            },
            "year": 2013
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 132,
                                "start": 129
                            }
                        ],
                        "text": "Concurrent to the recent progress in recognition, interesting advancements have been happening in virtual reality (VR by Oculus) [8], augmented reality (AR by HoloLens) [9], and smart wearable devices."
                    },
                    "intents": [
                        {
                            "id": "background"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Oculus rift-virtual reality headset for 3d gaming"
            },
            "venue": {
                "fragments": [],
                "text": "URL: http://www. oculusvr. com"
            },
            "year": 2012
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Comparing biases for minimal network construction with backpropagation . In: Advances in neural information processing systems"
            },
            "venue": {
                "fragments": [],
                "text": "Comparing biases for minimal network construction with backpropagation . In: Advances in neural information processing systems"
            },
            "year": 1989
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 114,
                                "start": 107
                            }
                        ],
                        "text": "We run the\n4 We used the Torch implementation in https://github.com/facebook/fb.resnet.torch 5 We used the Darknet [44] implementation: http://pjreddie.com/darknet/imagenet/#extraction\ntraining algorithm for 80 epochs with batch size of 128."
                    },
                    "intents": []
                },
                {
                    "context": {
                        "fragments": [
                            {
                                "end": 26,
                                "start": 22
                            }
                        ],
                        "text": "5 We used the Darknet [44] implementation: http://pjreddie."
                    },
                    "intents": [
                        {
                            "id": "methodology"
                        }
                    ]
                }
            ],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Darknet: Open source neural networks in c"
            },
            "venue": {
                "fragments": [],
                "text": "http://pjreddie.com/ darknet/"
            },
            "year": 2016
        },
        {
            "authors": [],
            "badges": [],
            "citationContexts": [],
            "fieldsOfStudy": [],
            "isKey": false,
            "numCitedBy": 0,
            "numCiting": 0,
            "paperAbstract": {
                "fragments": [],
                "text": ""
            },
            "slug": "+",
            "title": {
                "fragments": [],
                "text": "Optimal brain damage. In: NIPs. Volume 89"
            },
            "venue": {
                "fragments": [],
                "text": "Optimal brain damage. In: NIPs. Volume 89"
            },
            "year": 1989
        }
    ],
    "meta_info": {
        "citationIntent": "all",
        "citationIntentCount": {
            "background": 20,
            "methodology": 14,
            "result": 2
        },
        "citationType": "citedPapers",
        "pageNumber": 1,
        "requestedPageSize": 10,
        "sort": "relevance",
        "totalCitations": 48,
        "totalPages": 5
    },
    "page_url": "https://www.semanticscholar.org/paper/XNOR-Net:-ImageNet-Classification-Using-Binary-Rastegari-Ordonez/b649a98ce77ece8cd7638bb74ab77d22d9be77e7?sort=total-citations"
}